<?xml version="1.0" ?>
<root>
  <title>話し言葉解析のためのコーパスに基づく優先度計算法</title>
  <author>*-0.5mm</author>
  <jabstract>*-1mm</jabstract>
  <jkeywords>話し言葉の解析，優先度計算,コーパスに基づく手法</jkeywords>
  <subsubsection title="">*構造解析の誤り言い直しの解析において，訂正部分に係るべき文節が誤って修復対象に係るように解析されると，修復対象の範囲の同定に失敗する．例えば，()では，「今回の会議の」が「テーマ」ではなく「主旨」に係るように誤って解析され，その結果，修復対象の範囲に含まれてしまう．今回の会議の主旨といいますか，テーマといったようなもの([今回の会議の主旨][今回の会議のテーマ])この種の誤りは，心理言語学などで研究されてきた構造的な選好を利用すれば，なくすことができると思われる．</subsubsection>
  <section title="はじめに">近年の音声認識技術の進歩によって，話し言葉の解析は自然言語処理の中心的なテーマの1つになりつつある．音声翻訳，音声対話システム，マルチモーダル・インターフェースなどの領域で，自然な発話を扱うための手法が研究され出している．しかし，話し言葉の特徴である，言い淀み，言い直し，省略などのさまざまな不適格性,(ill-formedness)のために，従来の適格文の解析手法はそのままでは話し言葉の解析には適用できない．我々は，適格文と不適格文を統一的に扱う統一モデル,(uniformmodel)に基づく話し言葉の解析手法を提案した．そこでは，テキスト(漢字仮名混じり文)に書き起こされた日本語の話し言葉の文からその文の格構造を取り出す構文・意味解析処理の中で，言い淀み，言い直しなどの不適格性を適切に扱う手法について述べた．統一モデルを採用することにより，適格文におけるさまざまな問題(構造の決定や文法・意味関係の付与といった問題)を解決するための手法を拡張することで，不適格性の問題も同じ枠組の中で扱える．より具体的には，言い淀み，言い直しなどを語と語の間のある種の依存関係と考えることにより，係り受け解析の拡張として，適格性と不適格性を統一的に扱う手法が実現される．我々の手法においては，適格文の最適な解釈を求める処理と不適格性を検出・修正する処理がいずれも，最も優先度,(preference)の大きい依存関係解釈を求めるという形で実現される．そこで，不適格性による依存関係まで考慮した優先度の計算方法を開発することがキーとなる．本稿では，この統一モデルに基づく話し言葉の解析手法で用いるための優先度計算法について述べる．優先度の概念は，これまでにも，適格文の曖昧性を解消し最適な解釈を求める手法の中に取り入れられている．これらは以下の3つのアプローチに大別できる．本稿では，以下にあげる理由により，コーパスに基づく手法を用いる．心理言語学的な知見として得られているのは，構造的な選好など一部のものに限られ，特に，話し言葉の不適格性に関しては，ヒューリスティクスとして利用できる知見は得られていない．広範囲な意味知識や世界知識を人手で構築するのは困難である．また，世界知識の利用は構文・意味解析の範囲を越える．これに対し，コーパスからの優先度情報の獲得は，加工されたコーパスからであれば，容易に行なえ，かつ，情報の種類も限定されない．コーパスの加工を自ら行なう必要がある場合でも，知識自身を人手で構築するよりは負担が少ない．コーパスに基づく我々の優先度計算法では，依存関係解釈の優先度は，その解釈が学習データ中でどのくらいの頻度で生じているかに応じて与えられる．この際，学習データの希薄性(data-sparseness)の問題を回避するために，解釈の候補と完全に一致する事例だけでなく類似した事例も考慮される．類似性を適当に定義することにより，適格な文法・意味関係の優先度だけでなく，不適格性による依存関係の優先度も，同じ方法で計算できる．以下，まず,節では，統一モデルに基づく話し言葉の解析手法の概略を説明する．次に,節で，本稿で提案するコーパスに基づく優先度計算法を説明する．,節では，本手法を話し言葉の構文・意味解析システム上に実装し，その性能を評価することで本手法の有効性を検討する．最後に，,節でまとめを述べる．</section>
  <section title="統一モデルに基づく話し言葉の解析"/>
  <subsection title="話し言葉の解析">日本語の話し言葉では，言い淀み，言い直し，省略などのさまざまな不適格性が生じる．例えば，()には，(i),言い直し(「ほん」が「翻訳」に言い直されている)，(ii),助詞省略(「翻訳」の後の格助詞「を」が省略されている)の2つの不適格性がある．ほん，翻訳入れます．我々が提案した話し言葉の解析手法は，適格文と不適格文を統一的に扱う統一モデルに基づいている．不適格文を扱う手法としては，従来，二段階モデル,(two-stagemodel)に基づいたものが多かった．これは，まず，通常の適格文の解析手法で入力文を解析し，それが失敗した場合に，不適格性を扱うための処理を起動する，というものである．しかし，統一モデルは，以下の点において二段階モデルに優る．不適格文の処理はしばしば，適格文の処理と同等な能力を必要とする．不適格文を扱うために，従来適格文の処理に使われてきた手法を拡張して使えることが望ましい．不適格文と適格文とが曖昧な場合がある(()の「ほん」は「本」と同じ字面なので「本(に)翻訳(を)入れます」のような適格文としての解釈が可能)．適格文と不適格文が統一的に扱えないと，このような曖昧性は解消できない．話し言葉(特に音声言語)の解析に必要な実時間処理は，不適格文を処理するのに二段階の過程を経る二段階モデルでは実現できないが，統一モデルでは漸時的な処理が可能なので，実時間処理を実現しやすい．統一モデルは人間の言語処理モデルとしても妥当である．人間がしばしば文の途中で不適格性に気づくことは，人間が適格文の処理と並行して，不適格性の検出のための処理を行なっていることを示唆する．以下では，この統一モデルに基づく話し言葉の解析手法の概略を説明する．</subsection>
  <subsection title="解析手法の概要">本手法は，基本的には，係り受け解析の拡張である．入力文の依存構造を生成するために，各語(文節)の間の依存関係を調べる．例えば，()に対する依存構造と各文節の間の文法・意味関係は()のようになる．会議では翻訳も入れます．[loct&amp;de会議では[obje&amp;accAct翻訳も入れます]]ここで，loct,objeは意味関係(それぞれ「場所」「対象」)を表し，de,accActは文法関係(それぞれ「デ格」「目的格・能動態」)を表す．依存構造の決定と文法・意味関係の付与は，係り文節と受け文節の間の意味的な結合の強さや文法関係の実現のしやすさ(例えば「も」は「主格」になりやすいか「目的格」になりやすいか)などを考慮して，さまざまな候補に優先度を与え，最終的に最も優先度の高い組合せを見つけることによって行なう．本手法では，通常の係り受け解析を拡張し，言い淀み，言い直しなども語と語(文節と文節)の間の依存関係ととらえる．例えば，言い直しを含む文()の依存構造は()のようになる．ほん，翻訳入れます．[obje&amp;accAct[phonRepairほん翻訳]入れます]ここで，phonRepairは「ほん」と「翻訳」の間に音韻的な原因による言い直し(以下「音韻的言い直し」)によって依存関係が生じていることを表す．このように，不適格性を扱えるよう係り受け解析を拡張することによって，適格文の最適な解釈を求める処理と不適格性を検出・修正する処理が同じ道具だてで実現できるだけでなく，適格文と不適格文との間の曖昧性にも対処できる．</subsection>
  <subsection title="構文・意味解析の過程">本手法による構文・意味解析の過程を簡単な例題を用いて説明する．図,,は()の解析過程である．この文は，言い直しと助詞省略の2つの不適格性を含む．さらに，言い直しは適格文との間で曖昧である(「ほん」は「本」と同じ字面)．解析過程は以下の4つのステップからなる．この例では，Bの文節列に対して，Cの2つの依存構造が可能であり，その中に3つの依存関係が含まれる．それぞれの依存関係に対する解釈の候補はDのようになり，下線を引いたものが最も優先度の大きい組合せとして選択される．この過程において，助詞省略は「目的格」に解釈され，言い直しと適格文(「本(に)入れます」)との曖昧性も解消されている．</subsection>
  <section title="コーパスに基づく優先度計算法"/>
  <subsection title="本手法の概要">係り受け解析を基本とする我々の構文・意味解析手法においては，依存関係解釈の候補のおのおのに[0,1]間の実数値で表される優先度が与えられる．以下では，優先度の計算法を説明する．我々の優先度計算法は，コーパスに基づく手法である．優先度は，その依存関係解釈が学習データ中でどのくらいの頻度で生じているかに応じて与える．すなわち，係り文節と受け文節の間の依存関係解釈の優先度P(,,)は，次式で与えられる(係り文節と受け文節の間に依存関係解釈が成り立つことを,で表す)．分子は依存関係解釈,の事例の頻度であり，分母は学習データ中のすべての事例の頻度の総和である．しかし，このままでは学習データの希薄性の問題を避けられないので，分子の,の頻度を計算する際に，完全に一致する事例だけでなく類似した事例の頻度も考慮する．例えば，obje翻訳,入れるの頻度を計算する際に，これと類似した事例obje通訳,行なうが学習データ中にあれば，その頻度を考慮に入れるという具合である．これを類似性に基づくスムージング,(similarity-basedsmoothing)とよぶ．同じ方法が言い直しなどの不適格な依存関係の解釈の優先度計算においても利用できる．例えば，音韻的言い直しのパターン「ほん」「翻訳」は別のパターン「どうじ」「同時通訳」に似ているので，前者の頻度を計算する際に，後者の頻度も考慮する．このように，さまざまな類似性を考えることによって，適格な文法・意味関係の優先度だけでなく，不適格性による依存関係の優先度も，同じ方法で計算できる．</subsection>
  <subsection title="依存関係解釈の事例">依存関係解釈の頻度情報を獲得するために，学習データに対し人手で依存構造を付与し，そこから依存関係解釈の事例を抽出する．これらの事例は表,,のような表の形で書ける．例えば，表の1行めは，「通訳」と「行なう」の間の依存関係を「対象」に解釈する事例が学習データ中に3例あったことを表す．表中の係り文節，受け文節の欄には，解釈候補と事例との類似度を計算する際に参照される情報が書かれている．これらは，(a),意味関係(表の第1群)では意味情報(概念，属性)，(b),文法関係(表の第2群)では統語情報(語彙，範疇，形，態)であり，(c),言い直しの関係(表の第3群)では言い直しの種類(音韻的，統語的，意味的)に応じて異なる．</subsection>
  <subsection title="優先度">係り文節と受け文節の間の依存関係解釈の優先度P(,,)は，類似性に基づくスムージングを用いると，次式のようになる．ここで，S_(x,y,,)は解釈候補,と事例x,yの類似度,(similarity)であり，w_(s)は解釈候補に対して類似度sを持つ事例の貢献度を決める重みづけ関数,(weightingfunction)である．類似度と重みづけ関数の定義はいずれも，解釈に依存して与える．()より，依存関係解釈の優先度はその解釈が学習データ中で生じる頻度確率によって与えられ，この際，解釈の頻度はそれと似た事例の頻度を(類似度に応じて重みづけして)足し合わせることによって得られる(図,)．これは，クラスに基づくスムージング(class-basedsmoothing)の一般化になっているx,yの頻度の和によって与えられる．我々の類似性に基づくスムージングでは，クラスへの帰属性を類似度によって連続的に表現している．．</subsection>
  <subsection title="類似度">解釈候補,と事例x,yの類似度S_(x,y,,)は，解釈の種類に応じて以下のように定義される．解釈が意味関係もしくは文法関係の場合には，候補と事例に関して，係り文節同士，受け文節同士のそれぞれについて類似度を求め，その相乗平均をとる．しかし，が言い直しの関係の場合には同じ方法は使えない．例えば，音韻的言い直しのパターン「ほん」「翻訳」と別のパターン「どうじ」「同時通訳」は，直観的に似ていると感じるが，係り文節同士(「ほん」と「どうじ」)は似ていない．この場合，係り文節同士，受け文節同士の類似性を独立に調べるのは適当でない．むしろ，言い直しパターン全体としての類似性を調べる必要がある．そのために，まず，言い直しパターンを数値によってコード化する．言い直しでは通常，係り文節(修復対象)と受け文節(訂正部分)が何らかの点において類似している．ここで，「何らかの点」とは言い直しの種類に依存して決まる(例えば「音韻的言い直し」では音韻情報に関して類似している)．したがって，修復対象と訂正部分の類似度によって，その言い直しのパターンをコード化することができる．修復対象と訂正部分の類似性が大きい(あるいは小さい)言い直し同士は互いに似ていると考えることにすると，2つの言い直しパターンのコードの差によってそれらの間の類似度を定義することができる．例えば，上記の2つの音韻的言い直しのパターンでは，S_phon(ほん,ほんやく)=2/3(=22/(2+4))およびS_phon(どおじ,どおじつうやく)=3/5(=23/(3+7))より，両者の類似度は0.933(=1-|,2/3-3/5,|)となる．</subsection>
  <subsection title="重みづけ関数">解釈候補に対して類似度sを持つ事例の貢献度を決める重みづけ関数w_(s)は以下の3条件を満たすべきである．(i),貢献度は0以上1以下であり(w_の値域は[0,1])，(ii),類似度が1の事例の貢献度は最大値1をとり(w_(1)=1)，(iii),類似度が大きい事例ほど貢献度も大きい(w_は単調増加関数)．おのおのの解釈ごとに，この3条件を満たす重みづけ関数w_(s)を，次のような単純な多項式形式で与える．ここで，Nはある正の定数であり，係数a_,kは次式を満たす．係数a_,kは以下のようにして決める．類似性に基づくスムージングは，別の見方をすると，学習データによって部分的に与えられた事例の分布から真の分布を推定しているとみることができる．いま，事例,の真の頻度をf(,,)，推定された頻度をf(,,)とすると，類似性に基づくスムージングによる推定では，f(,,)は()の分子で与えられる．したがって，推定値の二乗誤差|,f(,,)-f(,,),|^2のすべての事例,にわたる和を最小にするように，重みづけ関数の係数を決めればよい．これを行なうためには，すべての事例の真の頻度がわかっている必要がある．ここでは，これを近似的に行なうために，学習データ中の各事例の頻度そのものが真の頻度を与えていると考え，その代わりに，各事例の推定頻度は学習データ中でその事例を除いた残りの部分から類似性に基づくスムージングによって与えられると考える(ジャックナイフ式の推定)．簡単な計算により，この二乗誤差最小化の問題は二次計画問題に帰着できることがわかり，したがって解析的に解ける．</subsection>
  <subsection title="文法関係解釈の優先度">最後に，文法関係の解釈の優先度について注意を述べる．(),()に見られるように，適格な依存関係は意味関係と文法関係の両面から解釈される．一般に，両者の解釈は独立ではない．すなわち，どの意味関係解釈が選択されたかに依存して，可能な文法関係の解釈の範囲が異なる．したがって，文法関係の優先度は条件つき,(conditional)の形で与えなければならない．係り文節と受け文節の間の依存関係を意味関係と文法関係に解釈する際の優先度は，確率論にしたがうと，次式のようになる．ここで，文法関係解釈の優先度P(,,,|,^*,^*)は条件つきの形で与えられており，条件は意味関係解釈と係り文節^*，受け文節^*によって課される．ただし，意味関係解釈は統語情報のうち形と態は制限しない(意味関係が「対象」であっても係り文節の形は「を」「も」「無」のいずれでもあり得る)ので，^*,^*ではこれらの情報が「関知せず(don'tcare)」になっている．類似性に基づくスムージングを用いた条件つき優先度は，次式で与えられる．ただし，分子のx,yと分母のs^*,^*はいずれも意味関係解釈と共起するものだけを対象とする．しかし，()では，今度は，分母に関して学習データの希薄性が問題になる．そこで，分母に対しても類似性に基づくスムージングを用いる．その結果，優先度は次式のようになる．()がどのように働くかを簡単な例で説明する．助詞省略を含む依存関係[obje&amp;accAct翻訳入れます]において，文法関係解釈accActの優先度を計算することを考える(図,)．分子は，解釈候補accAct翻訳,入れますと似た事例の頻度の加重和によって与えられる．ここで，統語情報の類似度は形が一致するときのみ非ゼロの値をとる(図,,でS_1はゼロ，S_2は非ゼロ)ように定義されており，よって，係り文節の形が「無」のもの(つまり助詞省略を含むもの)だけが分子の計算に貢献する．一方，分母は，係り文節と受け文節がそれぞれ「サ変名詞」「がを動詞」に類似したすべての事例の頻度の加重和である．したがって，この文法関係解釈の優先度は，概言すると，「係り文節と受け文節がそれぞれ「サ変名詞」「がを動詞」に似ている事例において，目的格の助詞が省略される確率」によって与えられる．</subsection>
  <section title="評価"/>
  <subsection title="実験">統一モデルに基づく話し言葉の構文・意味解析システムに本稿で提案した優先度計算法を実装し，その性能を評価した．学習・試験データにはATR対話データベース(ADD),の10対話(662文，2913依存関係，平均文長5.4文節，平均文字数26.4文字)を用いた．実験は次の2つの場合を調べた．依存関係と文全体の解析の正解率を表,,に示す(あらかじめ人手で付与したものと完全に一致したときのみ正解)．オープン試験での構造解析の正解率は依存関係ごとで78%，文全体で67%であり，関係解釈の正解率は依存関係ごとで66%，文全体で49%である．日本語において，依存関係解釈(深層格解釈)の性能を実例に対する実験で評価した研究はほとんど見られず，ましてや，話し言葉を対象としたものは皆無である．したがって，本実験結果を他の研究のものと比較するのは難しいが，が技術文書を対象として行なった係り受け解析実験の比較的短い文(平均文字数30〜50文字)に対する文全体の構造正解率が78%であることを考えると，決してよい成績とはいえない．しかし，本研究が対象としている文には，さまざまな不適格性が含まれており，また，構造解析が最終的な目的ではなく依存関係解釈が目的であるから，構造正解率の10%あまりの劣りはそれほど大きいとは思わない．いずれにせよ，日本語の話し言葉を対象とした依存関係解釈の実験結果を初めて提供できたことは非常に意義深い．次に，依存関係ごとの関係解釈の再現率(recall)と適合率(precision)を表,,に示す．「適格な依存関係(等位)」は等位構造をなす文法・意味関係解釈の総計であり，「適格な依存関係(従属)」は等位以外の文法・意味関係解釈の総計である．言い直しに注目すると，統語的言い直し(synRepair)では再現率90%，適合率47%であり，意味的言い直し(semRepair)では再現率88%，適合率32%である(オープン試験)．再現率は十分に高いが，適合率はかなり低い．これは，適格な依存関係がしばしば言い直しとして誤って解釈されたことを意味する．実際，適格な依存関係(等位)の再現率の低さは，言い直しが等位構造と間違われやすいことを示している．これは，適格文と不適格文を統一的に扱う統一モデルの欠点のようにみえる．この点について議論する前に，まず，誤りの実例を見る．</subsection>
  <subsection title="誤りの例">解析誤りは，(i),構造解析の誤りと(ii),関係解釈の誤りの2つのタイプに分類できる．</subsection>
  <subsection title="二段階モデルとの比較">言い直しの解析の適合率の低さが統一モデルに起因するものかどうか調べるために，我々の優先度計算法を二段階モデルに組み込んで比較した．すなわち，言い直しに対する解釈規則を除いた規則群で第一段階の解析を行ない，それが失敗した場合に，言い直しに対する解釈規則を加えて再解析を行なう．依存関係解釈の再現率と適合率を表,,に示す．適合率は，統語的言い直しでは47%から75%と大きく改善されたが，意味的言い直しでは32%から33%に改善されたに過ぎなかった．逆に，再現率はそれぞれ，90%,88%から30%,12%と大きく低下した(オープン試験)．これは，統一モデルとは逆に，二段階モデルでは言い直しの多くが適格文として誤って解析されたことを意味する．実際，適格な依存関係(従属，等位とも)の解釈の適合率が二段階モデルでは低下している．これは，が観察した不適格文と適格文との曖昧性が二段階モデルでは大きな問題となることを示している．これに対し，統一モデルでは，音響的・韻律的情報を用いることによって，誤って言い直しと判断される例を除去できる可能性がある．最後に，二段階モデルにおける依存関係と文全体の解析の解釈正解率(表,)は，オープン試験でそれぞれ65.5%，48%であり，いずれも統一モデルのものを下回る．結論として，二段階モデルによって言い直しの解析の精度が改善されることはなく(適合率は一部よくなるが再現率が悪くなる)，構文・意味解析の総合性能においても統一モデルが二段階モデルに優る．</subsection>
  <section title="おわりに">本稿では，我々が提案した統一モデルに基づく話し言葉の解析手法で用いるための優先度計算法について述べた．本手法は，コーパスに基づく手法であり，解釈の優先度はその解釈が学習データ中でどのくらいの頻度で生じているかに応じて与えられる．この際，学習データの希薄性の問題を回避するために，解釈の候補と完全に一致する事例だけでなく類似した事例も考慮される．本稿では，まず，統一モデルに基づく話し言葉の解析手法の概略を説明し，次に，本手法の詳細を説明した後，本手法を話し言葉の構文・意味解析システム上に実装し，その性能を評価することで本手法の有効性を示した．その結果，オープン試験で，約半数の文に完全に正しい依存構造が与えられることが示された．また，言い直しの解析の精度は若干悪いが，これは二段階モデルによっては改善できず，結論として，構文・意味解析の総合性能においては統一モデルが二段階モデルに優ることが示された．今後の課題としては，構造的な選好の利用ならびに音響的・韻律的情報を用いた不適格性の解析の高精度化があげられる．</section>
</root>
