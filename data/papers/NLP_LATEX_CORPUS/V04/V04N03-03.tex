\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{51}
\setcounter{巻数}{4}
\setcounter{号数}{3}
\setcounter{年}{1997}
\setcounter{月}{7}
\受付{1996}{9}{24}
\再受付{1997}{1}{11}
\採録{1997}{3}{27}

\setcounter{secnumdepth}{3}

\title{意味的類似性と多義解消を用いた文書検索手法}
\author{大井 耕三\affiref{SANYO} \and 隅田 英一郎\affiref{ATR} \and 飯田 仁\affiref{ATR}}

\headauthor{大井 耕三・隅田 英一郎・飯田 仁}
\headtitle{意味的類似性と多義解消を用いた文書検索手法}

\affilabel{SANYO}{エイ・ティ・アール音声翻訳通信研究所}
{ATR Interpreting Telecommunications Research Laboratories(現在, 三洋電
機株式会社 ハイパーメディア研究所, Hypermedia Research Center, SANYO
Electric Co., Ltd.)}
\affilabel{ATR}{エイ・ティ・アール音声翻訳通信研究所}
{ATR Interpreting Telecommunications Research Laboratories}

\jabstract{
 単語間の意味的類似性に基づく検索(以下，類似検索と呼ぶ)は
 文書検索技術において，重要な課題の一つである．
 類似性に関する従来研究では，階層構造が平衡しているシソーラスを
 使った単語間の類似度が提案され，言語翻訳，文書検索などの応用における
 有効性が示されている．
 本論文では，階層構造が平衡していないシソーラスにも適用できる，
 より一般的な単語間の意味的類似度を提案する．
 本提案では
 各単語が担う概念間の最下位共通上位概念が有する下位概念の総数が少ないほど，
   単語間の類似度が大きくなる．
 筆者らは，この意味的類似度と大規模シソーラスの一つであるEDR
 シソーラスを使って，類似検索システムを実装した．
 さらに，精度を向上させるために，単語の多義解消手法を
 この検索システムに導入した．
 本類似検索システムは，単語間の物理的近さと単語の重要度を用いた
 拡張論理型の従来システムに基づいている．
 この従来システムとの比較実験を行ない，
 意味的類似性と多義解消を用いた提案の類似検索手法によって
 再現率・適合率が向上したことを確認した． 
}

\jkeywords{意味的類似度，多義解消，文書検索，シソーラス，EDR辞書}

\etitle{Document Retrieval Method Using Semantic Similarity\\
 and Word Sense Disambiguation}
\eauthor{Kozo OI\affiref{SANYO} \and Eiichiro Sumita\affiref{ATR} \and Hitoshi Iida\affiref{ATR}} 

\eabstract{
 Retrieval based on semantic similarity between words (hereafter, 
similarity-based retrieval) is one of the important problems in
document retrieval technologies.
 In previous research on semantic similarity, measures of word-similarity
using the thesaurus whose hierarhical structure is balanced, were
used and thier effectiveness were shown in applications 
such as language translation and document retrieval.
 This paper proposes a general measure of similarity which is
applicable for both balanced and unbalanced thesauri.
In this proposed measure, the lesser the number of concepts under the
most specific common abstraction between concepts of words,
the larger the similarity between words.
 The authors have implemented a similarity-based retrieval system 
using this semantic similarity and one of  large-scale thesauri, EDR
thesaurus.
 Moreover, in order to improve its accuracy, they have incorporated 
word sense disambiguation method into the retrieval system.
 This retrieval system is based on a conventional system, an extended 
boolean retrieval system using the phisical nearness between words and
the weight of words.
 Through contrastive experiments with the extended boolean system, the
authors have shown the improvement in both recall and precision by the 
proposed similarity-based method.
}

\ekeywords{Semantic Similarity, Word Sense Disambiguation, Document Retrieval,
Thesaurus, EDR Dictionary}

\setcounter{topnumber}{4}
\setcounter{totalnumber}{4}
\renewcommand{\topfraction}{}
\renewcommand{\textfraction}{}

\def\labelenumii{} 

\begin{document}
\maketitle



\section{はじめに} \label{sec:intro}
 近年，膨大な電子化された情報の中から必要な情報を検索する技術の必要性
 が高まっている．
  インターネットの爆発的な普及に伴って，ユーザが求める情報を持つwwwサー
バを検索するシステムが，実際，数多く出現してきている．
  しかし，これらの検索システムのほとんどは，ユーザが入力した検索キーワー
  ドそのものを含むテキスト
(に対応したwwwサーバ)を検索するシステムである．
検索キーワードに意味的に類似している単語まで考慮した
\footnote{単に，キーワードを同義語・類義語のリストを使って
展開する従来手法では，不十分であり，類似の度合に従って文書を整列させて
上位のものだけユーザに提示出来なくてはならない．
キーワード「画家」に対して，同義語「画伯」や類義語「イラストレーター」,
「デザイナー」や上位概念である「絵描き」, 「芸術家」などまでも含むもの
を検索し，類似度順に出力することが望まれる． 
}
検索(以下，類似検索と呼ぶ)は出来ない．

  一方，シソーラスに基づく意味的類似性を使った，翻訳，解析，
文書検索などの研究が行なわれてきている．
 ただ，これらの先行研究には
(1)シソーラスの階層構造が平衡していると仮定しているという問題と
(2)単語の多義性の解消を行なっていないという問題があった．

 本論文では，階層構造が平衡していないシソーラスにも適用できる，
 より一般的な単語間の意味的類似度を提案する．
 本提案では
 各単語が担う概念間の最下位共通上位概念が有する下位概念の総数が少ないほど，
   単語間の類似度が大きくなる．
 筆者らは，この意味的類似度と大規模シソーラスの一つであるEDR
 シソーラスを使って，類似検索システムを実装した．
 さらに，精度を向上させるために，単語の多義解消手法を
 この検索システムに導入した．
 本類似検索システムは，単語間の物理的近さと単語の重要度を用いた
 拡張論理型の従来システムに基づいている．
 この従来システムとの比較実験を行ない，
 意味的類似性と多義解消を用いた提案の類似検索手法\footnote{本手法では，類
 義語を検索可能にすることによって再現率を上げ，その範囲内で，多義によるノ
 イズを排除し適合率を上げることを目指している．さらに再現率を重視する場合
 には関連語まで含めて検索することが必要と考えられる．} 
 によって再現率・適合率が向上したことを確認した． 

以下，
\ref{sec:method}節で，
提案した意味的類似度，採用した多義解消手法，それらを用い
た類似検索，ベースとなる拡張論理型検索について示し，
\ref{sec:experiment}節で前節で述べた
類似検索手法による適合率・再現率の改善及び
多義解消手法の比較について示し，
\ref{sec:conclusion}節でまとめる．

\section{類似検索} \label{sec:method}
  提案する文書検索手法は，各文書に対して質問との関連度を求め，
関連度の大きい順に文書を整列させる．
先ず，意味的類似度計算法と
多義解消法について述べ，さらに，これらを組み込むベースとなる従来システムの
関連度及び検索手順について説明する．


\subsection{意味的類似度}\label{sec:sim-word-main}
  単語間の意味的類似度は，単語に付与されている
概念間の関係に基づいて計算する．
まず，オンラインのシソーラスを概観し，
次に，概念間・単語間の類似度について説明する．

\subsubsection{シソーラス}\label{sec:thesaurus}
  オンラインのシソーラスには，
分類語彙表\cite{Kokugoken64}，
角川類語新辞典\cite{Ohno81}，
Rogetシソーラス\cite{Chapman77}，
WordNet\cite{Miller90}，
EDR電子化辞書\cite{EDR93}の概念辞書(以下，EDRシソーラスと称する)
などがあり，
いずれも概念を上位・下位の関係で階層的に構成している．
  これらのシソーラスの特徴
\footnote{角川類語新辞典は1981
年版，分類語彙表は1964年版，
EDR概念辞書は評価版2.1版，
WordNetはVersion 1.5，
RogetシソーラスはVersion 1.02に関するデータである．}
を表\ref{tbl:thesaurus}に示す．
WordNetとEDRシソーラスは比較的規模が大きい．
また，EDRシソーラスは，概念の階層関係が，
日本語・英語共通となっており両言語で利用できる．

\begin{table}[htb]
\caption{各種シソーラスの特徴}
\label{tbl:thesaurus}
\small
\begin{center}
\renewcommand{\arraystretch}{}
\begin{tabular}{|c||c|c|r|r|c|l|}\hline
 シソーラス      & 階層構造 & 階層数 &  概念数 &   単語数 & 言語 \\\hline\hline
 分類語彙表      & 平衡 & 5  & 約1,000   & 約33,000  & 日本語 \\\hline
 角川類語新辞典  & 平衡 & 3  & 約1,000   & 約50,000  & 日本語 \\\hline
 Rogetシソーラス & 平衡 & 3  & 約1,000   & 約40,000  & 英語   \\\hline\hline
 WordNet         & 非平衡 & 10 & 約91,000  & 約120,000 & 英語 \\\hline
 EDRシソーラス   & 非平衡 & 18 & 約450,000\footnotemark\hspace*{-0.45em} & 約200,000 & 日本語・英語 \\\hline
\end{tabular}
\end{center}
\end{table}

\footnotetext{
「中間ノード」(下位概念をもつノード)の数は約6,000\cite{Ogino95}であるが，
ここでの概念数は末端概念を含み，かつ，多重継承を別に数えた数字である．}

また，シソーラスはその階層構造によって2種類に分けることができる．
\begin{itemize}
\item 分類語彙表, 角川類語新辞典, Rogetシソーラスのように，
ルート概念から末端概念までの階層の深さがほぼ一定である．
\item WordNet，EDRシソーラスのように，階層の深さが一定でない．
\end{itemize}
本論文ではそれぞれ「平衡シソーラス」，
「非平衡シソーラス」と呼ぶことにする．

\subsubsection{概念間の類似度}\label{sec:sim-con}
先行研究\cite{Sato90,Sumita92,Kurohashi92,Mima96}では「平衡シソー
ラス」を扱っている．
例えば，隅田ら\cite{Sumita92}は，平衡シソーラス上での概念間の類似度を用
例に基づく翻訳に応用している． 
そこでは，階層の深さが一定であることを利用して，最下位の共通上
位概念の位置に基づいて類似度を決定している．

本論文では，EDRシソーラスのような
「非平衡シソーラス」にも適用可能な
概念間の{\dg 類似度}を定義する． 

\begin{itemize}
 \item 各概念に対して，その概念の{\dg 具体度}を割り
     当てる(詳細は後述)．
     具体度は，0から$NL-1$までの$NL$個の値の中で，
     下位になるほど大きな値をとる．
     図\ref{fig:similarity}に$NL$が9の場合を示す．
 \item 概念$A,B$の間の類似度$Sim$は，$A$と$B$の相対的な位
       置関係(3種類)に応じて，具体度を使って
       次のように定義する．$A,B$の最下位共通上位概念を
     $C$とし，その$C$の具体度を\\$LC$とする．
\begin{itemize}
\item $A$と$B$が同じ場合($C=A=B$)，$Sim=1.0$．
\item $C$が$A$でも$B$でもない場合，
      $Sim=LC/NL$．
\item $A$が$B$の上位概念の場合($C=A$)またはその逆の場合($C=B$)，\\
      $Sim=$ $(LC+1)/NL$．
\end{itemize}
\end{itemize}

\begin{figure}[bht]
 
 \vspace*{0mm}
 \centerline{
 \vspace*{-2.5mm}
   \epsfile{file=similarity+.eps,scale=1.0}
 }
 \vspace*{3mm}
 \caption[]{非平衡シソーラスにおける概念間の意味的類似度の例\\
 ($Sim$: 概念$A,B$の間の類似度, $C$: $A$と$B$の最下位の共通上位概念)}
 \label{fig:similarity}
\end{figure}

従って，類似度$Sim$は，0, 1/$NL$, 2/$NL$, $\cdots$, $(NL-1)/NL$, 
1の離散値をとり，
0は最も似ていないことを意味し，1は最も似ていることを意味する．

\paragraph{具体度の割り当て}
  「下位概念(末端までの概念すべて)の総数が少ない概念ほど，概念の具体度
  が高い」という考えで具体度を割り当てる．
   深さが$NL-1$(ルート概念の深さを0とする) 
   で，各概念から下位概念への分岐数が一定で，
   概念数が原非平衡シソーラスに近い仮想の平衡シソーラスを想定する．

   各概念の具体度の割り当て手順を次に示す．

\begin{enumerate}
 \item 原非平衡シソーラスの概念数$TC$を求める\hspace{-0.2mm}(但し，\hspace{-0.5mm}$TC$は2以
   上とする)．\hspace{-0.5mm}直上位の概念を複数持つ概念は，その数だけ別個の概念が存在している
     と考えて，概念数を求める．
 \item $NL(\ge 2)$を任意に決める．
 \item 各概念から下位概念への分岐数$NB$を，
       次式を満たす最小の自然数とする．
\begin{eqnarray*}
  TC \leq \displaystyle \sum_{k=0}^{NL-1}NB^k 
\end{eqnarray*}
 \item 階層の深さが$NL-1$(ルート概念の深さを0とする)で，
     各概念から下位概念への分岐数$NB$である平衡シソーラスを想定する．\hspace{-0.5mm}平衡シソーラスにおいて，
     深さが$d$の概念の下位概念の総数$TLD(d)$は次式となる．
     \begin{eqnarray*}
       TLD(d) = \left\{
       \begin{array}{ll}
         \displaystyle \sum_{k=1}^{NL-1-d}NB^k & (d < NL-1)\\
         0                     & (d = NL-1)
       \end{array}
     \right.
   \end{eqnarray*}
 \item 原非平衡シソーラスの各概念に対して，
 \begin{enumerate}
  \item その概念の下位概念総数$TLC$を求める．
  \item $TLC \leq TLD(d)$である最小の$d$をその概念に{\dg 具体度}とし
        て割り当てる．
 \end{enumerate}
\end{enumerate}

概念数$TC$が45万であるEDRの非平衡シソーラスに対して，\hspace{-0.3mm}実験では，\hspace{-0.3mm}具体度の数$NL$を9に，$NB$は5とした
\footnote{
シソーラスが与えられたときの，NLとNBの選択には幅がある．
以下の2点を考慮し，EDRシソーラス(概念数45万)に対して$NL$=9, $NB$=5とした．
角川類語辞典は$NL$=4, $NB$=10で，分類語彙表は$NL$=6, $NB$=4である．
また，$NB$を大きくすると，元のシソーラスの概念数とのズレが大
きくなりがちである．}．
図\ref{fig:thesaurus_level}に，この時の仮想平衡シソーラスに
おける深さ$d$と下位概念総数$TLC$の関係を示す．

\subsubsection{単語間の類似度}\label{sec:sim-word-sub}
  単語$w1$, $w2$間の類似度$Sim(w1,w2)$は次のように求める．

\begin{itemize}
\item  単語(見出しと品詞)一致の場合，
       類似度は$(NL+1)/NL$とする．
\item  単語一致以外の場合，
     類似度は，2単語の概念のすべての組合せに対する2概念間
     の類似度の最大値とする．
\end{itemize}

\begin{figure}[ht]
\vspace*{12mm}
 
 \centerline{\epsfile{file=thesaurus_level+.eps,scale=1.0}}
\vspace*{5mm}
 \caption{仮想平衡シソーラスにおける深さと下位概念総数}
 \label{fig:thesaurus_level}
\vspace*{10mm}
\end{figure}



\subsection{多義解消手法}
  多くの単語は多義である．すなわち，複数の概念を持っている．
\ref{sec:sim-word-sub}節で述べたように，
単語間の類似度は，概念のすべての組合せにおける類似度の最大値としている．
この場合，実際にその文書で用いられている概念と異なった概念
に基づく類似度が高くなることにより，
誤って関連文書として検索されてしまうことがある．
 
  実際に文書中で使われている概念を同定することができれば，
検索の精度は向上できる．
  そこで，単語の多義を解消する手法を導入することにした．

多義解消の手法は多数提案されているが，
本論文では，(1)情報検索に適用され逆効果であったと報告されているVoorheesの手
法と(2)典型的な少数の多義語に関して高精度な
結果が報告されてはいるが，情報検索といった実際的な応用における
効果が検証されていないYarowskyの手法を取り上げる．
両手法は他の多くの手法とは違って正解データを仮定しないという点で，
大規模な制限のないテキストを扱う情報検索に向いた手法である．

\subsubsection{Voorheesの手法}\label{sec:voorhees-apply}
\vspace*{-1mm}
  Voorheesは，次に述べる多義解消法を提案し，
文書検索の実験を行なっている\cite{Voorhees93}．
  文書$D$中の単語$dt$の各概念に対して，
{\boldmath $hood$}(その概念を含み，単語$dt$の他の概念を含まない最も上位
の概念)を求めた後，式(\ref{eqn:score-voorhees})で定義される
{\dg 差異}を求め，差異が正(の最大)\footnote{
\topsep=0mm
\topskip=0mm
\partopsep=0mm
\parskip=0mm
\parsep=0mm
VoorheesはシソーラスとしてWordNetを使い，
多義解消された単語の概念をベクトル要素とした
ベクトル空間モデルに基づいた手法により文書検索を行なっている．
一方，筆者らはEDRシソーラスを使い，意味的類似度を使った
拡張論理型検索手法により文書検索を行なっている．
また，前者は名詞だけを対象とし，後者はストップリストに属さない単語
全体を対象としている．
この二つのシステムは相違点が多く，それぞれの検索結果を直接比較することはできない．
しかし，本研究において，以下のことを確認した．
\begin{itemize}
\topsep=0mm
\partopsep=0mm
\parskip=0mm
\parsep=0mm
\itemsep=0mm
\item 
Voorheesの多義解消手法は，誤った選択をすることが多く，
概念を高精度に「1つ」に絞り込めるほど性能が
良いとはいえない．
ただ，差異による{\dg 絞り込み条件を「正の最大」から「正」に変更}すれば，
副作用少なく「尤もらしくない」概念の数を減らすことは出来る．
今回の実験で正解を含む率では，前者は後者の1/2から
1/3と著しく悪かった．
\item
また，本類似検索法のように多義性を許容する場合には，
この程度の性能でも情報検索の検索精度を向上できる．
\end{itemize}
}
である概念を単語$dt$の概念として選択する
\footnote{
さらに，本実験では以下の変更を行なった．
\begin{itemize}
\topsep=0mm
\partopsep=0mm
\parskip=0mm
\parsep=0mm
\itemsep=0mm
\item 
EDRのシソーラスがWordNetに比べて，分類の粒度が細かい(
深さが約2倍，概念数が約5倍)であることを考慮して，
概念の中で似ている概念をまとめるために，各概念をある具体度
(本実験では6以下とした)の上位概念に置き換える．
\item
抽象的すぎる概念まで含むことを避けるため
$hood$もある具体度(本実験では3以上とした)によって制限する．
\end{itemize}
}
．
\begin{eqnarray}
 差異 & = & \displaystyle 
\frac{hood下の概念を持つ単語の文書D内出現数}{文書Dの延べ語数}\nonumber\\[1ex]
       & - & \frac{hood下の概念を持つ単語の全文書内出現数}{全文書の延べ語数}\label{eqn:score-voorhees}
\end{eqnarray}


\subsubsection{Yarowskyの手法}\label{sec:yarowsky-apply}
\vspace*{-1mm}
  Yarowskyは，Rogetシソーラスと大量のコーパス
  を用いて多義解消の実験を行なっている\cite{Yarowsky92}． 
  文書中の単語$dt$の多義解消手法の概要は次のとおりである．
  コーパス中の各単語に対して，前後$W$語ずつ合計$2W$語(文脈と呼ぶ)を抽出し，
  単語$dt$が属するシソーラス中の概念$C$毎に，
  単語$dt$の文脈中の単語のうち
     式(\ref{eqn:score-yarowsky1})がある
     しきい値$Y$以上の
  単語$ct$に対して，式(\ref{eqn:score-yarowsky2})の
  $Score$を求め，$Score$が正(の最大)
  \footnote{
Voorheesの手法の変更と同様に
$Score$による{\dg 絞り込み条件を「正の最大」から「正」に変更}した．}
となる概念を単語$dt$の概念としている
\footnote{
さらに，本実験では以下の変更を行なった．
\begin{itemize}
\topsep=0mm
\partopsep=0mm
\parskip=0mm
\parsep=0mm
\itemsep=0mm
\item 
  Yarowskyは，しきい値$Y$を1.0と設定しているが，こ
  れだと特定文脈中での出現確率が全文脈中の出現確率に近い単語も$Score$に
  寄与することになる．筆者らは特定文脈中での出現の度合が顕著な単語だけ
  を選択した方が多義解消の精度が良くなると考え，しきい値$Y$を2.0と
  大きく設定した．
\item   
  概念をVoorheesの手法における$hood$に置き換えた．
  EDRシソーラスの概念は，
     特に最下位概念はそのほとんどが非常に具体的な概念であるため，各概念に属する
     単語の文脈は非常にスパースとなるからである．
\item
本実験では文脈幅$W$を4とした．以下に精度と速度の両面から理由を述べる．
\begin{itemize}
\item 精度
\begin{itemize}
\item 
Yarowsky等\cite{Yarowsky92,Gale93}は特に名詞に関して広い文脈($W$=50)の有
用性を主張しているが，同時に狭い文脈($W$=6)の有用性も認めている．
可能なら広い文脈を使った方が良いという主張である．
但し，彼らの実験では，狭い文脈に対する広い文脈のgainは，86\%か
ら90\%への4\%に過ぎなかった．また，本実験では，動詞や
形容詞など，名詞以外の語も対象としている．
\item 
予備実験では，$W$=4と$W$=5とで結果に大きな差は生じなかった．
\item 
本検索実験では，Yarowsky等\cite{Yarowsky92,Gale93}と違って，文脈幅
はストップワードを省いて数えることになるので，文脈幅の値が同じなら，
実質的には本論文の文脈の方が広い．
\end{itemize}
\item 速度
\begin{itemize}
\item 
Yarowskyの手続きは文脈幅に依存して大変な処理時間がかかるので，
$W$=4で本実験を行なった．今回の実験で
多義解消に要した時間はDEC AlphaStation 600 5/333
上で約330時間(2週間)である．
\item Yarowskyの実験が広い文脈幅で実施出来たのは，特定の単語だけを扱っ
ているからである．一方本実験は文書数約3,000の中に含まれ
る全て多義語を対象としている．
\end{itemize}
\end{itemize}
\end{itemize}
}
．

\begin{eqnarray}
 Score & = & \sum_{ct}\log\frac{Pr(ct|C)}{Pr(ct)}\label{eqn:score-yarowsky2}\\[1ex]
 &  & Cに属する単語の文脈中の\nonumber\\[0zh]
 \frac{Pr(ct|C)}{Pr(ct)} & = & \frac{単語ctの出現確率}{単語ctの全文脈中の出現確率}\label{eqn:score-yarowsky1}
\end{eqnarray}


\subsubsection{多義解消の例}
Voorheesの多義解消の例として，後述のベンチマークテスト中の
文書番号1719の文書(図\ref{fig:disamb-voo-exm-doc})中の
単語``evaluating''の結果を表\ref{tbl:disamb-voo-exm-res}に，
Yarowskyの多義解消の例として，同テスト中の文書番号
1411の文書(図\ref{fig:disamb-yar-exm-doc})中の
単語``formulas''の結果を表\ref{tbl:disamb-yar-exm-res}に示す．
表中，「概念」の欄に示している文字列は，EDRシソーラスに記述されてい
る概念説明である\footnote{EDRシソーラスの各概念には，
少なくても英語概念説明または日本語概念説明のいずれかが付与さ
れている．しかし，必ずしも，両者が付与されているとは限らないので，表
には基本的に英語概念説明を記し，英語概念説明が付与されていないも
のについては日本語概念説明を記している．}．
「文書(または文脈)内貢献語」は，Voorheesの手法では$hood$下の概念
をもつ文書内の単語を，Yarowskyの手法
では文脈中の単語のうち\ref{sec:yarowsky-apply}節の
式(\ref{eqn:score-yarowsky1})のしきい値$Y$が2.0以上の単語を示す．

\begin{figure}[ht]
\begin{center}
\fbox{
\begin{minipage}{120mm}
\renewcommand{\baselinestretch}{}
\tt
\vspace*{1.2ex}
\hspace*{0.5em}...........................................................\\
Real-time data processing systems as typified by the automated\\
airline reservation system are discussed in this paper.\\
Criteria for \underline{evaluating} performance are described; a methodology\\
for calculating and optimizing is outlined; and the method is\\[-0.5ex]
\hspace*{0.5em}...........................................................\\[-2ex]
\end{minipage}
}
\vspace*{-1ex}
\end{center}
\caption{単語``evaluating''が出現する文書(文書番号1719)}
\label{fig:disamb-voo-exm-doc}
\end{figure}
\begin{table}[ht]
\caption{Voorheesの手法による単語``evaluating''の多義解消}
\label{tbl:disamb-voo-exm-res}
\small
\begin{center}
\vspace*{-1ex}
\renewcommand{\arraystretch}{}
\begin{tabular}{|l|r|p{70mm}|}\hline
 \multicolumn{1}{|c|}{概念} & 
 \multicolumn{1}{|c|}{スコア} & 
 \multicolumn{1}{|c|}{文書内貢献語} \\\hline\hline
 ``評価する'' & 
   {\dg 0.123} &
  calculation, calculating, cost, outlined, types, optimizing, optimization \\\hline 
 ``{\dg the act of calculating}'' & 
  {\dg 0.079} & 
  calculation, calculating \\\hline
 ``いろいろな思考的活動'' & 
 -0.063 & 
 typified, illustrated, reservation \\\hline
\end{tabular}
\end{center}
\end{table}
\begin{figure}[ht]
\begin{center}
\fbox{
\begin{minipage}{120mm}
\renewcommand{\baselinestretch}{}
\tt
\vspace*{1.2ex}
\hspace*{0.5em}...........................................................\\
For each statistic, the algorithm included the usual computing\\
 formulas, correction due to an accumulated error term, and a\\
 recursive computation of the current value of the statistic.\\
 The usual computing \underline{formulas} were also evaluated in double\\
 precision. Large errors were noted for some calculation using\\[-0.5ex]
\hspace*{0.5em}...........................................................\\[-2ex]
\end{minipage}
}
\vspace*{-1ex}
\end{center}
\caption{単語``formulas''が出現する文書(文書番号1411)}
\label{fig:disamb-yar-exm-doc}
\end{figure}
\begin{table}[ht]
\caption{Yarowskyの手法による単語``formulas''の多義解消}
\label{tbl:disamb-yar-exm-res}
\small
\begin{center}
\vspace*{-1ex}
\renewcommand{\arraystretch}{}
\begin{tabular}{|l|r|l|}\hline
 \multicolumn{1}{|c|}{概念} & 
 \multicolumn{1}{|c|}{スコア} & 
 \multicolumn{1}{|c|}{文脈内貢献語} \\\hline\hline
 ``数や記号の組合せからなる式'' & 
 3.033 & 
 value, evaluate \\\hline
 ``規則'' & 
 0.000 &
 \\\hline  
 ``nourishment for a person's body'' & 
 0.000 & 
 \\\hline
 ``書物'' & 
 0.000 & 
 \\\hline 
 ``a group of words that express a complete thought'' & 
 0.000 & 
 \\\hline
 ``伝達内容'' & 
 0.000 & 
 \\\hline
 ``情報媒体'' & 
 0.000 & 
 \\\hline
 ``抽象的生産物'' & 
 0.000 & 
 \\\hline
\end{tabular}
\end{center}
\end{table}


\subsection{拡張論理型検索}\label{sec:process}
本論文では，前節までに説明した意味的類似度計算法と多義解消法の
有効性を検証するため，その手法を
従来の拡張論理型検索システムに組み込む．
拡張論理型検索システムは
論理型の質問を受理し，この質問と文書間の関連度によって文書を
整列させて出力する．関連度は以下に述べる「物理的な近さ」と「単語の重要度」
と前節までの「意味的類似度」とから計算される．

\subsubsection{単語間の物理的近さ}\label{sec:nearness}
質問中に複合語が指定された場合は，その複合語中の各単語(または
最も類似している単語)の文書中の物理的近さを，
質問・文書間の関連度に反映させる\cite{Oi95}．

物理的近さは，例えば，複合語が``parallel algorithm''の場合，
``parallel''と``algorithm''それぞれに類似した単語が文書中に出現しているとき，
その類似した単語間の物理的距離が近いほど大きい値になるよう定義する．
 この尺度は，質問中の複合語と文書間の関連度の乗
数(\ref{sec:similarity}節参照)として用いる．

  物理的近さ$PN$の定義式を次に示す．
\begin{eqnarray}
  PN & = & c_1\times \frac{\displaystyle 1}{\displaystyle
        \frac{\displaystyle c_1-1}{\displaystyle c_2}\times (Dis+1-N)+1}\label{eqn:nearness}
\end{eqnarray}
ここで\footnote{$PN$は複合語の構成単語に類似した語が現れた時に，その間の物理的距離に反比例させ
て重み付けするための乗数である．隣接している時に最大値2をとり，物理的
距離が10で1とした．物理的距離が10より小さいものは複合語として扱い，
大きいものは複合語と見倣さないということになる．$c_1$=2, $c_2$=10とした 
背景は以上の通りであるが，このパラメータの最適化は今後の検討課題の一
つである．}，
\begin{center}
\begin{tabular}[t]{rp{115mm}}
 $c_1, c_2$: & 定数(実験時の設定値は
$c_1=2$, $c_2=10$)\\
 $Dis$: & (類似)単語間の物理的距離(単語間に存在する単語数+1)の最小値．\\
 $N$: & 複合語の単語数．
\end{tabular}
\end{center}

\subsubsection{単語の文書毎の重要度}\label{sec:term-weight}
  単語の重要度に関しては様々な尺度が提案されている．
  本実験では，単語の文書内の出現頻度と全文書中の出現文書数に基づいた
重要度\cite{Turtle91}を使う．
  文書$D$内の単語$dt$の重要度$w$は，次のように定義される．
\begin{eqnarray}
  w & = & \displaystyle \frac{tf}{max\_tf}\times
        \frac{\log{\frac{\displaystyle ND}{\displaystyle f}}}{\log{ND}}\label{eqn:weight}
\end{eqnarray}
ここで，
\begin{center}
\begin{tabular}[t]{rl}
  $tf$:      & 文書$D$内の単語$dt$の出現頻度．\\
  $max\_tf$: & 文書$D$内の単語の出現頻度の最大．\\
  $f$:       & 単語$dt$が出現している文書の数．\\
  $ND$:      & 全文書数．
\end{tabular}
\end{center}

\subsubsection{質問・文書間の関連度}

\paragraph{質問}\label{sec:query}

  本手法では，次に示すような論理型質問$Q$を受理する．
\begin{eqnarray}
  Q & = & q_1\ |\ q_2\ |\ \cdots\ |\ q_K\label{eqn:query}\\[0.5ex]
  q & = & 
        \underbrace{qt_{11}, \cdots , qt_{1N_1}}_{}\&
        \cdots \& 
        \underbrace{qt_{M1}, \cdots , qt_{MN_M}}_{}
        \label{eqn:query-and}\\[-1.5ex]
    &   & \hspace*{1.3zw} 質問語~qc_1 \hspace*{6zw} 質問語~qc_M \nonumber
\end{eqnarray}
ここで，`$|$'と`\&'はそれぞれ`{\small OR}'と`{\small AND}'のオペレーションを表す．
 この形式は，$K$個の$q$が\\`{\small OR}'オペレーションで結合され，\hspace{-0.4mm}各$q$は
$M$個の質問語$qc$(単語または複合語)\hspace{-0.03mm}が`{\small AND}'オペレー\\ションで結合
され，各質問語$qc_i$は$N_{i}$個の単語$qt$から成っている．
\vspace*{-1mm}

\paragraph{関連度}\label{sec:similarity}
\vspace*{-1mm}

  質問$Q$と文書$D$との間の関連度$Rel(Q, D)$は次式のように定義する．
\begin{eqnarray}
  Rel(Q, D) & = & max\{Rel(q_1, D), Rel(q_2, D),\cdots, Rel(q_K, D)\}\label{eqn:sim-qda}\\[1ex]
  Rel(q, D) & = & \frac{\displaystyle 
        \sum_{i=1}^{M}\sum_{j=1}^{N_i}{\left\{Rel(qt_{ij}, D)\times PN(qc_i, D)\right\}}^2}
        {\displaystyle \sum_{i=1}^{M}\sum_{j=1}^{N_i}\left\{Rel(qt_{ij}, D)\times PN(qc_i, D)\right\}}\nonumber\\[1ex]
  Rel(qt, D) & = & max(w_1, w_2, \cdots, w_L)\times max\left\{Sim(qt,dt)\right\}\nonumber
\end{eqnarray}
ここで，
\begin{center}
\begin{tabular}[t]{rp{110mm}}
  $L$: & $qt$に最も類似している単語($Sim(qt,dt)$が最大の単語)の数．\\
  $w$: & $qt$に最も類似している単語の重要度．\\
  $PN(qc, D)$: & 文書$D$内での，\hspace{-0.3mm}$qc$中の各$qt$に最も類似している単語間の物理的近さ\hspace{-0.2mm}(\ref{sec:nearness}節の式(\ref{eqn:nearness}))．\\
  $Sim(qt,dt)$: &   質問$Q$中の1つの単語$qt$と文書中の1つの単語$dt$と
  の間の類似度(\ref{sec:sim-word-sub}節)．
\end{tabular}
\end{center}

 $Rel(Q, D)$の計算は，$q_1, q_2, \cdots, q_K$のうち，少なくとも1つの$q$に含まれ
る単語それぞれに対して{\dg 類似している単語}が出現している文書に対してのみ行なう．
  「類似している単語」とは，
あらかじめ指定されたしきい値$T$に対して
{\boldmath $Sim(qt,dt)\ge$}
{\boldmath $T$}である単語$dt$を意味する．

  $Rel(q, D)$は，\hspace{-0.3mm}単に$q$中の単語$qt_{ij}$すべてに対する$Rel(qt_{ij},
D)\times PN(qc_i, D)$の値の平均とするよりも，$Rel(qt_{ij}, D)\times PN(qc_i, D)$が大きい値ほどその値の重要度が大きくなるようになっている．

\subsubsection{検索手順}\label{sec:step}
  実際の検索処理に先だって，(a)質問中の単語への概念の付与
\footnote{本実験では予め筆者が手作業で付与した．システム
運用時には，ユーザとシステムが会話的に決定することを仮定している．}，
(b)全文書に対
するインデックスファイル(各文書の見出し語・品詞からなる
各ペアに対して，文書番号，重要度，
出現位置が付与されたファイル)の作成を行なった．

  インデックスファイルの作成手順は次のようになる．

\begin{enumerate}
 \renewcommand{\labelenumi}{}
 \item 文書の中から，ストップリスト(冠詞や前置詞など文書検索にとって
       重要と考えられない単語のリス
       ト)に属する単語を除き，すべてのアルファベットを小文字化する
       \cite{FoxC92}． 
 \item 形態素解析\footnote{本論文の実験では，\cite{Karp92}の
          形態素解析プログラムを使用した．}により，各単語に対して，見
        出し語・品詞の可能なペア，出現位置の情報を付与する．  
 \item 類似検索の場合は，ここで，見出し語・品詞の各ペアに対してシソー
   ラスに従って，取りうる概念を付与する． この概念集合に対して，多義解
   消を行なう．
 \item \ref{sec:term-weight}節の式(\ref{eqn:weight})に従って，各文書の
   見出し語・品詞の各ペア対して，重要度を計算し付与する．  
\end{enumerate}

  質問に対する検索処理手順は次のとおり．

\begin{enumerate}
 \item 質問を\ref{sec:query}節の式(\ref{eqn:query}), (\ref{eqn:query-and}) 
       の形に変換する． 
 \item 式(\ref{eqn:query})の少なくとも1つの$q$中の単語$qt$それぞれに対して，\\
       $Sim(qt,dt)\ge T(しきい値)$を満たす単語$dt$が出現している文書を検索する． 
 \item 検索された文書毎に，質問・文書間の関連度$Rel(Q, D)$を
       \ref{sec:similarity}節の式(\ref{eqn:sim-qda})から求める．
 \item 検索された文書を関連度順に整列させる．
\end{enumerate}


\section{実験}\label{sec:experiment}
ここでは，非平衡シソーラスにも適用できる意味的類似度と
単語の多義解消を組み合わせた提案の類似検索手法を
従来の検索法と比較し，適合率・再現率の向上を確認する．
また，適合率向上に貢献した多義解消法の精度に関する実験結果について示す．

\subsection{ベンチマークテスト}
  情報検索システム評価用ベンチマークテスト
  の1つにFoxのVirginia Disk\cite{FoxE90}がある．
  実験では，その中のCACMと呼ばれるセットを使った．
CACMには，コンピュータサイエンスに関する3,204の文書(タイトルと
アブストラクト，1文書当たり約125語)，3
種類の質問セット(自然言語文からなる{\small NLQ}, ブーリアン形式の{\small BLQ1,
BLQ2})，質問ごとの関連文書の文書番号が含まれている．
 各質問セットには64個の質問が含まれている．{\small NLQ}はオリジナルの質問セット
で，{\small BLQ1, BLQ2}は{\small NLQ}を基にして作られている．

  実験では，{\small NLQ}の質問文中の単語が比較的多く使われている{\small BLQ2}の
中で，{\small NOT}オペレーションを含むものと正解の関連文書がないものを
除く47個の質問に複合語を指定する変更を加えたもの(以下では，変更版{\small BLQ2}と呼ぶ)を用いた．
  {\small NLQ}, {\small BLQ2}, 変更版{\small BLQ2}の質問番号35の質問内容を下に示す．
  変更版{\small BLQ2}において，シングルクウォート(')で囲まれた部分が1つの質問語
を表している．

{
\parindent=0mm
[NLQ]
\begin{verbatim}
   Probabilistic algorithms especially those dealing with algebraic
   and symbolic manipulation.
   Some examples: Rabiin, "Probabilistic algorithm on finite field", SIAM.
   Waztch, "Probabilistic testing of polynomial identities", SIAM.
\end{verbatim}
[BLQ2]
\begin{verbatim}
    #q35= #and( 'probabilistic', 'algorithm',
                #or( 'algebraic', 'symbolic'), 'manipulation');
\end{verbatim}
[変更版BLQ2]
\begin{verbatim}
    #q35= #and( 'probabilistic algorithm',
                #or( 'algebraic manipulation', 'symbolic manipulation'));
\end{verbatim}
}


\subsection{評価方法および実験条件}\label{sec:evaluation}
  評価は，情報検索の分野で一般的に使われている{\dg 再現率}と{\dg 適
合率}を用いた．
  再現率および適合率は次式で定義される．
\begin{eqnarray}
 再現率 & = & \frac{ランクN位までの検索文書中の関連文書数}{関連文書数}\label{eqn:rec-pre-1}\\[1ex]
 適合率 & = & \frac{ランクN位までの検索文書中の関連文書数}{ランクN位までの検索文書数}\label{eqn:rec-pre-2}
\end{eqnarray}

再現率・適合率グラフは次に示す手順で作成した．

\begin{enumerate}
 \item 式(\ref{eqn:rec-pre-1}), (\ref{eqn:rec-pre-2})の値$N$を任意に複数個決める．
 \item 質問ごとに，式(\ref{eqn:rec-pre-1}), (\ref{eqn:rec-pre-2})により
       $N$における再現率と適合率を求める．
 \item $N$における再現率と適合率の全質問に対する平均を求め，プロットする．
\end{enumerate}

次節の結果では，$N$を10, 20, 30, $\cdots$, 200に設定した．

表\ref{tbl:experiment-condition}に示した条件設定
\footnote{本論文で提案した方法は多くのパラメータを含んでいる．
表\ref{tbl:experiment-condition}にまとめてある設定は，
経験的に定めたものであり，パラメータの最適値を求めることは，
今後の課題の一つである．
}の元で，
表\ref{tbl:experiment-method}に示す4種類の手法
{\bf WM}, {\bf AM}, {\bf DM(Voo)}, {\bf DM(Yar)}を比較し，
非平衡シソーラスにも適用できる意味的類似度と単語の多義解消を組み合わせ
た提案の類似検索手法{\bf DM(Voo)}及び{\bf DM(Yar)}の有効性を確認する． 

\subsection{実験結果}
ここでは多義解消を伴った類似検索の有効性と多義解消法の比較について述べる．

\subsubsection{文書検索の比較}
 図\ref{fig:recall-precision-th-99}--\ref{fig:recall-precision-th-69}は，
検索時にシステムが許容する単語間の類似度を制御するためのしきい値
$T$(\ref{sec:similarity}，\ref{sec:step}節参照)が，
高い方から順に，9/9, 8/9, 7/9, 6/9 の場合の再現率・適合率グラフである．

\begin{table}[t]
\caption{実験条件}
\label{tbl:experiment-condition}
\small
\begin{center}
\renewcommand{\arraystretch}{}
\begin{tabular}{|l|c|}\hline
 \multicolumn{1}{|c|}{項目(関連する節)} & 設定 \\\hline\hline
 シソーラスの具体度の$NL$ (\ref{sec:sim-con}節) & 9  \\\hline\hline
 概念の粒度を制限するための具体度
 (\ref{sec:voorhees-apply}節) &
    6以下 \\\hline
 $hood$の粒度を制限するための具体度 (\ref{sec:voorhees-apply}節) & 3以
 上 \\\hline\hline 
 文脈幅$W$(\ref{sec:yarowsky-apply}節) &   {4} \\\hline 
 単語$ct$を選択するためのしきい値$Y$ (\ref{sec:yarowsky-apply}節) &
   {2.0} \\\hline
 Yarowskyの手法で使用したコーパス (\ref{sec:yarowsky-apply}節) & TIPSTERのZIFF文書\footnotemark
 \\\hline\hline
 物理的近さの定義式の定数$c_1$ (\ref{sec:nearness}節) & 2 \\\hline
 物理的近さの定義式の定数$c_2$ (\ref{sec:nearness}節) & 10 \\\hline
\end{tabular}
\end{center}
\end{table}

\footnotetext{Yarowskyの手法において使用したコーパス「TIPSTERのZIFF文書」は，米国
ARPA(Advanced Research Projects Agency)が主導した情報検索のプロジェク
トTIPSTERで使われてた文書の1つである．
ZIFF文書の総単語数は約9,600万語であるが，
Yarowskyの手法は使用
するコーパスのサイズが大きくなると処理時間も増えていくので，
実験では多義解消の処理時間を短
縮するためにそのうちの約800万語を使用した．}

\begin{table}[t]
\vspace{-6mm}
\caption{比較した4種類の手法}
\label{tbl:experiment-method}
\small
\begin{center}
\renewcommand{\arraystretch}{}
\begin{tabular}{|c||c|c|c|c|c|}\hline
         & \multicolumn{5}{|c|}{使用する尺度または多義解消手法}\\\cline{2-6}
  手法名 &
  意味的類似度 &
  Voorheesの &
  Yarowskyの &
  物理的近さ &
  単語の重要度 \\[-0.2zh]
   &
  \small(\ref{sec:sim-word-main}節) &
  手法\small(\ref{sec:voorhees-apply}節) &
  手法\small(\ref{sec:yarowsky-apply}節) &
  \small(\ref{sec:nearness}節) &
  \small(\ref{sec:term-weight}節) \\\hline\hline
  {\bf WM}     &    &    &    & ○ & ○\\\hline\hline
  {\bf AM}     & ○ &    &    & ○ & ○\\\hline\hline
 {\bf DM(Voo)} & ○ & ○ &    & ○ & ○\\\hline
 {\bf DM(Yar)} & ○ &    & ○ & ○ & ○\\\hline
\end{tabular}
\end{center}
\end{table}
\vspace*{-1mm}

\begin{itemize}
\item いずれのしきい値$T$においても，
{\dg\bf AMは，WMと比べて，適合率は減少しているが再現率は向上している．}
適合率減少の原因の1つに単語の多義性がある．単語間の類似度を求める際にすべて
の概念を考慮しているので，実際に文書中で使われている概念とは異なる概念に起因して
多くの非関連文書が検索されてしまうのである．

\item  {\dg\bf 多義解消手法を導入したDMをAMと比べた場合，概ね，再
    現率は若干減少しながらも適合率が改善している．} 
  これは，AMで検索されていた非関連文書がDMでは多義解消の効果により検索されなくなったためである．
但し，$T$=7/9(図\ref{fig:recall-precision-th-79}), 
$T$=6/9(図\ref{fig:recall-precision-th-69})では，
多義解消の失敗の影響で再現率が減少しているのが目立つ．

\item  {\dg\bf DMをWMと比べると，ある程度しきい値$T$が大きい場合には，
大略，再現率・適合率ともに向上している．}
\footnote{
一方，\ref{sec:evaluation}節の評価方法の他に，再現率=適合率となる値につ
      いても求めた．\cite{Salton83a}のp.164--172に従って，$T$=9/9における
      質問全体に対する再現率ごとの平均を求めた結果，再現率=適合率となる
      値は，DM(Voo), DM(Yar), AM, WMの順に，0.220, 0.220, 0.225, 0.230となった．
      また，再現率0.1を境として，より低い再現率では，適合率の高い方から，
      DM(Voo), DM(Yar), WM, AMの順になり，より高い再現率では，
      WM, AM, DM(Voo), DM(Yar)の順となった．}
\end{itemize}

\clearpage

\begin{figure}[ht]
 
 \centerline{\epsfile{file=new_tr_99.ps,scale=1.0}}
 \caption{再現率・適合率[しきい値$T$=9/9]}
 \label{fig:recall-precision-th-99}
\end{figure}

\begin{figure}
 
 \centerline{\epsfile{file=new_tr_89.ps,scale=1.0}}
 \caption{再現率・適合率[しきい値$T$=8/9]}
 \label{fig:recall-precision-th-89}
\end{figure}

\begin{figure}
 
 \centerline{\epsfile{file=new_tr_79.ps,scale=1.0}}
 \caption{再現率・適合率[しきい値$T$=7/9]}
 \label{fig:recall-precision-th-79}
\end{figure}


\begin{figure}
 
 \centerline{\epsfile{file=new_tr_69.ps,scale=1.0}}
 \caption{再現率・適合率[しきい値$T$=6/9]}
 \label{fig:recall-precision-th-69}
\end{figure}

\clearpage
\subsubsection{多義解消法の比較}\label{sec:vy}
Voorheesの多義解消の文書検索における有効性に関しては，Voorheesの報告とは逆に，
Voorheesの手法を若干変更し，類似検索に適用して，その有効性を確認できた．
また，Yarowskyの手法も，同程度の有効性が確認できた．
但し，しきい値$T$が9/9の時にはDM(Voo)の方が\\性能が良く，
しきい値$T$が8/9以下ではDM(Yar)の方が性能が良く，しきい値$T$が小さくな
れ\\ばなるほど両者とも性能が悪くなる．

  次に，多義解消手法単独の精度
\footnote{処理時間の観点からは，
Yarowskyの手法はVoorheesの手法に比べ劣っている．
Yarowskyの手法の処理時間は，文脈の幅，学習コーパス，検索文書中の多義語
の量と多義の度合などに支配される．
実装に依存するので，参考に過ぎないが，800万語
のZIFF文書をコーパスとして多義解消に要した時間はDEC AlphaStation 600 5/333
上で約330時間(2週間)であった．
一方，Voorheesの手法の場合の多義解消時間は検索文書中の多義語
の量と多義の度合などに支配されており，約3時間であった．}
について述べる．
  図\ref{fig:recall-precision-th-99}に対応する$T$=9/9と
  図\ref{fig:recall-precision-th-69}に対応する$T$=6/9の
  条件を
  代表として取り上げ，質問中の単語と類似している関連文書内の単語
\footnote{参考のために，$T$=6/9のDA(Yar)の多義解消結果における 
単語(出現形と頻度)を3つに分類して示す．
\begin{itemize}
\topsep=0mm
\partopsep=0mm
\parskip=0mm
\parsep=0mm
\itemsep=0mm
\item 選択され成功した語(延べ34語)\\
appropriate 1,
calculation 1,
computer 2,
described 3,
describes 1,
dictionary 4,
divide 1,
fitting 3,
formulas 1,
gauging 1,
loop 1,
loops 1,
management 1,
measurements 1,
patterns 1,
person 1,
picture 1,
pictures 4,
procedure 1,
retrieving 1,
secure 1,
serial 1,
transmitting 1.
\item 選択はされたが失敗した語(延べ21語)\\
analysis 1,
capacity 2,
compare 1,
computer 1,
entries 1,
entry 1,
evaluate 1,
handling 1,
loop 1,
measurement 1,
operate 1,
operating 1,
picture 1,
representation 1,
serial 2,
set 2,
shared 1,
utilization 1.
\item 選択されなかった語(延べ50語)\\
allocate 1,
allocating 1,
allocation 6,
applications 1,
computer 2,
described 5,
describes 1,
describing 1,
dictionaries 3,
directory 1,
divided 1,
entries 1,
evaluating 2,
fitting 1,
hardware 1,
management 3,
measure 1,
measuring 1,
operated 1,
operating 2,
organization 2,
pattern 1,
programmers 1,
representation 3,
serial 1,
set 1,
shared 1,
sharing 3,
time 1.
\end{itemize}
}
(延べ数は前者が59，後者が105である)の多義解消の結果を調べた
(表\ref{tbl:disamb-result9/9}, \ref{tbl:disamb-result6/9})．

{
\small
\begin{table}[h]
\caption{多義解消結果[しきい値$T$=9/9]}
\label{tbl:disamb-result9/9}
\small
\begin{center}
\renewcommand{\arraystretch}{}
\tabcolsep=1.5mm
\begin{tabular}{|c||c|c||c|c||c|c|c|}\hline
         & A:選択単語 & A/59: & B:成功単語 & B/A:   & C:選択前     & D:
         選択後 & D/C:多義 \\[-0.2zh]
 \raisebox{0.8zh}[0pt]{手法} & 延べ数  & 選択率& 延べ数     & 成功率 & 概念数     & 概念数 & 圧縮率 \\\hline\hline
 DA(Voo) &  59       & 1.00  & 39         & 0.66   &  644       & 354    & 0.55 \\\hline 
 DA(Yar) &   45       & 0.76  & 23         & 0.51   &  581       & 202    & 0.35 \\\hline 
\end{tabular}
\end{center}
\end{table}

\vspace{-3mm}

\begin{table}[h]
\caption{多義解消結果[しきい値$T$=6/9]}
\label{tbl:disamb-result6/9}
\small
\begin{center}
\renewcommand{\arraystretch}{}
\tabcolsep=1.5mm
\begin{tabular}{|c||c|c||c|c||c|c|c|}\hline
         & A:選択単語 & A/105: & B:成功単語 & B/A:   & C:選択前     & D:
         選択後 & D/C:多義 \\[-0.2zh]
 \raisebox{0.8zh}[0pt]{手法} & 延べ数     & 選択率& 延べ数     & 成功率 & 概念数     & 概念数 & 圧縮率 \\\hline\hline
 DA(Voo) &  104       & 0.99  & 73         & 0.70   &  938       & 530    & 0.57 \\\hline 
 DA(Yar) &   55       & 0.52  & 34         & 0.62   &  672       & 142    & 0.21 \\\hline 
\end{tabular}
\end{center}
\end{table}
}

  選択単語は1つ以上の概念を選択できた単語である．
  選択率は多義解消手続きの汎用性を示す．
  成功単語は選択した概念の中に正解概念(文書中で使われている概念)が含ま
  れている単語である．
  成功率は多義解消が働いた場合の精度を示す．
  本実験ではスコアが正である概念を選択しているので，選択され排除されな
  い概念数が多ければ成功率も高くなりうるので，
  多義解消手続きで選択され排除されない
  概念の割合も考えなくてはな
  らない．
  これを多義圧縮率と呼ぶことにする．いずれのしきい値の場合でも，選択率，
  成功率ともに，Voorheesの手法，DA(Voo)が優っており，逆に，多義圧縮率
  はYarowskyの手法，DA(Yar)が優っている．

  選択率と成功率が同じなら，多義圧縮率によって検索への効果が決まるが，
  それ以外は単純に比較できない．
  多義解消法の性能が必ずしも高くなくても，検索性能は上げられ
  ることがわかったが，両者の関係は必ずしも単純ではなく，
  今後さらに検討を続ける必要がある．

\section{おわりに}\label{sec:conclusion}
  本論文では，シソーラスが平衡または非平衡，どちらの場合にも適用できる
 意味的類似度を提案した． 本提案では
 各単語が担う概念間の最下位共通上位概念が有する下位概念の総数が少ないほど，
 大きくなるように単語間の類似度を決定する．

 さらに，
 この類似度と多義解消を用いた類似検索手法を提案した．
 比較実験により，本類似検索手法は従来の検索手法に比べて，
 適合率・再現率ともに改善していることを確認した．

 今後の研究課題としては，
   本手法で用いたパラメータの最適化，
   応用や言語やシソーラスを変えた場合の有効性の検証，
   多義解消アルゴリズムの高精度化・高速化，
   未知語対策または応用への適用を目指したシソーラスの拡張・修正・生成手法などがある．


\acknowledgment
本研究ではEDR電子化辞書の英語単語辞書・概念辞書(評価版第2.1版)を
使用している．関係各位に深謝する．


\bibliographystyle{jnlpbbl}
\bibliography{jpaper81}

\clearpage

\begin{biography}
\biotitle{略歴}
\bioauthor{大井 耕三}{
1984年同志社大学工学部電子工学科卒業．
同年，三洋電機(株)入社．
1992年より4年間，エイ・ティ・アール自動翻訳電話研究所・音声翻訳通信研究所
に出向．
現在，三洋電機(株)ハイパーメディア研究所にて，自然言語処理・自然音声合成 
の研究開発に従事．
情報処理学会会員．
}

\bioauthor{隅田 英一郎}{
1982年電気通信大学大学院計算機科学専攻修士課程修了．
エイ・ティ・アール音声翻訳通信研究所主任研究員．
自然言語処理，並列処理，機械翻訳，情報検索の研究に従事．
情報処理学会，電子情報通信学会各会員．
}

\bioauthor{飯田 仁}{
1972年早稲田大学理工学部数学科卒業．74年同大学院修士課程(数学専攻)修了．
同年日本電信電話公社武蔵野電気通信研究所入社．日本電信電話株式会社基礎
研究所を経て86年4月よりエイ・ティ・アール自動翻訳電話研究所に出向．同研究
所終了に伴い93年3月よりエイ・ティ・アール音声翻訳通信研究所に再出向．現在，
音声対話の理解・翻訳の研究に従事．平成7年度科学技術庁長官賞受賞．言語処
理学会，情報処理学会，電子情報通信学会，人工知能学会，日本認知科学会，
ACL 各会員．
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}










































