<?xml version="1.0" ?>
<root>
  <title>コーパスに基づく動詞の多義解消</title>
  <author>福本文代辻井潤一</author>
  <jabstract>本稿では,コーパスから抽出した動詞の語義情報を利用し,文中に含まれる多義語の曖昧性を解消する手法を提案する.先ずコーパスから動詞の多義解消に必要な情報を抽出する手法について述べる.本手法では,多義を判定しながら意味的なクラスタリングを行なうことで多義解消に必要な情報を抽出する.そこで,表層上は一つの要素である多義語動詞を,多義が持つ各意味がまとまった複数要素であると捉え,これを一つ一つの意味に対応させた要素(仮想動詞べクトルと呼ぶ)に分解した上でクラスタを作成するという手法を用いた.本手法の有効性を検証するため,丹羽らの提案した単語ベクトルを用いた多義語の解消手法と比較実験を行なった結果,14種類の多義語動詞を含む1,226文に対し,丹羽らの手法が平均62.7%の正解率に対し,本手法では71.1%の正解率を得た.</jabstract>
  <jkeywords>コーパス,統計手法,語義の曖昧性解消,意味</jkeywords>
  <section title="まえがき">自然言語処理における重要な問題の一つに,形態構文意味といった言語に関する様々な曖昧性の問題がある.一般に,意味的な曖昧性を解消するためには,意味に関するさまざまな情報を規則化し記述しておく必要がある.しかし,意味は文脈に依存して決まるため,あらゆる文脈に対応できるすべての意味を予め規則として網羅的に記述しておくことは難しい.CollinsEnglishDictionary,Rogetのシソーラス,分類語彙表など,機械可読辞書として電子化されたものがあるが,辞書の記述は語の定義が言語学者によりまちまちであるため,現実の文に対処できる有用な意味情報を得ることは難しい.そこで,意味的な曖昧性を解消するためには,解消手法と同時に,文脈に依存した情報をどのように獲得するかが重要となる.こうしたことを背景に,最近コーパスから意味的に近い語群の情報や,共起関係の情報などを抽出する研究が盛んに行なわれている.これらのアプローチは知識獲得のためのアルゴリズムを提案することで,コーパスからその分野に依存した知識を自動的に抽出するというものである.本稿では,単一言語コーパスから抽出した動詞の語義情報を利用し,文中に含まれる多義語の曖昧性を解消する手法について述べる.2章では,関連した研究について述べる.3章ではコーパスから多義解消に必要な情報を抽出する手法について述べる.4章では得られた情報を基に,文中に含まれる多義語の曖昧性を解消する手法について述べる.5章では丹羽らの提案した文脈ベクトルを用いた名詞の多義解消手法を動詞に適用した結果と比較することで,本手法の有効性を検証する.</section>
  <section title="関連した研究">近年,大量のコーパスが利用可能になったことを背景に,コーパスから得られた情報を用いて語義の曖昧性を解消する研究が多数行なわれている.Yarowskyらは,Rogetのシソーラスカテゴリを利用し,統計手法を用いることでテキスト中に現れる多義語の曖昧性を解消する手法を提案した.彼らの手法は,統計情報を用いてシソーラスカテゴリに出現する単語に重み付けを行なった後,その結果を利用して多義語の周辺語の重みの和から多義語がどのシソーラスカテゴリに属するかを決定するというものである.この手法を12の多義語名詞に適用し実験を行なった結果,平均解消率92%という高い正解率が得られることが報告されている.しかし,Yarowskyらのシソーラスを用いる問題として,データスパースネスの問題が指摘されている.すなわち,シソーラスカテゴリに示されている語が抽象的な語で定義されているため,文書の種類によっては,その語が文書に出現しない場合がある.また,Yarowskyらは彼らの手法が動詞の多義解消については名詞と同様の正解率が得られないことを指摘している.丹羽らは,文脈を構成する単語をベクトルで表現し,文脈をそれらベクトルの和で表した.任意の文脈Aにおける単語の意味は,多義の各意味を表す文脈例を各意味に応じてあらかじめ用意しておき,各々の例と文脈Aにおける単語の意味との類似度(内積)を計算し,その値が最も大きい文脈が示す意味であるとした.この手法を名詞の多義判定に適用した結果,平均80%の正解率が得られている.Brownらは対訳テキストを用い,一方の言語の語義の曖昧性を他方の語の情報を利用することで解消する手法を提案している.彼らは実際に英仏機械翻訳システムにこの手法を適用し,検証を行なっている.しかし彼らは問題点として,(1)多義語の持つ意味を予め高々2つに限定している.(2)語が,ターゲット言語の2つの異なる訳に翻訳できないとき,語義の解消ができない.(3)膨大な対訳テキストを必要とする,を挙げている.ZernikやSch&quot;utzeらは,動詞の多義を判定するための情報として名詞と動詞の共起関係を利用している.任意の動詞がどの意味を持つかは,動詞と共起する名詞の集合に応じて決定される.しかし,名詞の集合を意味に応じて分割する処理は人手で行なっているため,語の分類は人間の言語的な直観に頼ることになってしまう.本稿では,Yarowskyらがシソーラスカテゴリを利用しているのに対し,単一言語コーパスから抽出した動詞の語義情報を利用し,文中に含まれる多義語の曖昧性を解消する手法について述べる.我々の手法は名詞の集合を意味に応じて人手により分割するZernikやSch&quot;utzeらの手法,と異なり,多義解消に必要な情報は,与えられた多義語を含む動詞グループに対し,クラスタリングアルゴリズムを適用することで自動的に得られるため,人間の介在を必要としない.また,Brownらが多義語の持つ意味を予め高々2つに限定しているのに対し,本手法では,多義語を含む動詞グループに対し,クラスタリングアルゴリズムを適用するため,2つ以上の意味を持つ語に対しても曖昧性の解消が可能である.</section>
  <section title="多義解消に必要な情報の抽出">一般に,意味的に近い2つの動詞は同じ名詞と共起して現れる.*2mm*2mm例えば,WallStreetJournalから抽出した例文(s1)(s2')において,(s1),(s1')に現れるtakeとbuyは共にstakeと共起して現れ,ほぼ同じ意味を持つ.同様に(s2),(s2')に現れる!take!と!spend!は共に!time!と共起して現れ,両者は同じ意味を持つ.従って多義語!take!がもつ複数の意味は,各意味に対応した動詞buy,spendと共起して現れる名詞stake,timeと特徴づけて考えることができる.すなわち,多義語を含む文において,もし多義語と共起する名詞のうち少なくとも一つが多義語の意味を特徴づける名詞と同じ(あるいは名詞の集合に属する)ならば,文中の多義語の意味はその名詞と共起する動詞の意味に同定することができる.我々は文中に現れる多義語の曖昧性を,その語と共起する名詞を用いることで解消した.以下,3.1節では仮想動詞について述べる.3.2節では語の意味的な偏差を計算する手法について述べ,3.3節では3.2節で述べた偏差の値を用いてクラスタリングを行なうためのアルゴリズムについて説明する.多義語を含む動詞グループに対し,クラスタリングアルゴリズムを適用することで多義語の各意味を示す動詞(仮想動詞)と共起する名詞の集合が,動詞の個数分得られる.3.4節では仮想動詞,及びそれと共起する名詞との相互情報量を求める手法について述べる.仮想動詞と名詞の相互情報量は,文中に現れる名詞が複数の(名詞の)集合に含まれる場合にどの集合に含まれるかを一意に決定するために用いられる.</section>
  <subsection title="仮想動詞">本手法では,多義を判定しながら意味的なクラスタリングを行なうことで多義語の曖昧性解消に必要な情報,すなわち,多義語の意味を特徴づける名詞の集合を抽出する.そこで,表層上は一つの要素である多義語を,多義が持つ各意味がまとまった複数要素であると捉え,これを一つ一つの意味に対応させた要素(本稿ではこの要素を仮想動詞ベクトルと呼ぶ)に分解した上でクラスタを作成するという手法を用いた.我々は,動詞をベクトルと捉え,動詞と共起するn個の名詞を軸とするn次元名詞空間上でこれを表した.軸i(1in)における動詞ベクトルの長さは,i軸で示される名詞と動詞の相互情報量の値を用いた.仮に2つの動詞に多義性がなく,かつこの2つの動詞が意味的に近いとすると,これらの動詞はこの空間上で互いに距離が近いため,同一のクラスタに含まれることになる.一方,(s1)と(s2)に現れるtakeは多義であるため,各意味を表す動詞ベクトルbuy,spendのいずれともクラスタを構成しなければならない.そこで,ベクトルtakeを各軸に従って(この場合,stakeとtimeの2軸)分割することを考える.ベクトルtakeをstakeとtimeの軸に従って分割した結果を図に示す.図において,ベクトルtakeは,stakeとtimeの軸上でベクトルtake1とtake2に分割されている.take1とtake2を仮想動詞ベクトルと呼ぶ.図は仮想動詞ベクトルを導入することで,各々意味的に近い要素を持つ2つのクラスタtake1,buy,take2,spendが得られることを示す.</subsection>
  <subsection title="動詞グループの偏差">クラスタリングアルゴリズムは動詞グループの意味的な偏差を比較し,偏差の少ない順にクラスタを生成する.今m個から成る動詞グループをVG=v_1,,v_mとすると,VGの偏差Dev()は式()で示される.ただし,nは動詞と共起する名詞の個数とする.Dev()&amp;=&amp;1g(m+)_i=1^m_j=1^n(v_ij-g_j)^2eqnarray()のg_j(=1m_i=1^mv_ij)は,j軸での重心の値を示す.また,g(=1m_j=1^n(_i^mv_ij)^2)は重心ベクトルの長さを示す.()のv_ijは,とする.ここで,Mu(v_i,n_j)は動詞v_i(1im)と名詞n_j(1jn)の相互情報量の値を表し,式()で示される.Mu(x,y)&amp;=&amp;log_2P(x,y)P(x)P(y)eqnarrayP(x),P(y)は,x,yの頻度数f(x),f(y)をそれぞれコーパスに出現する語の総数Nで正規化したものであり,P(x,y)はxとyの共起頻度数f(x,y)をNで正規化したものである.また,式()におけるは閾値とする.式()のm+は,動詞の偏差を示す値が動詞の個数に比例して増加することを防ぐために最小2乗法を用いて行なった正規化であるを用いた実験では,を3に設定し,,それぞれ0.964,-0.495を得た..式()はその値が小さいほどより偏差が少ないことを示す.</subsection>
  <subsection title="クラスタリング手法">クラスタリングアルゴリズムは,non-overlappingとoverlappingアルゴリズムに大別できる.本手法はoverlappingクラスタリングアルゴリズムに含まれる.Overlappingアルゴリズムの代表的なものとしてB_k(k=1,2,)手法がある.本手法とB_k手法との違いは,B_k手法では要素が複数のクラスタに属すか否かはkの個数に依存して決まるのに対し,我々の手法は,複数のクラスタに属すか否かを判定する条件をアルゴリズムの中に導入している点が異なる.我々の手法では,動詞ベクトルを分割して仮想動詞ベクトルを作成し,その仮想動詞ベクトルを含むクラスタの偏差を比較することで,要素が複数のクラスタに属すか否か,すなわち多義であるかどうかの判定を行なっている.例えば,takeがbuyとspendの意味を持つかどうかを判定するために,ベクトルtakeをstakeとtimeの軸に従い分割し,仮想動詞ベクトルtake1とtake2を作成する.takeが多義であるか否かは,take1,buy,take2,spend及び,take,buy,spendのクラスタの偏差を比較することにより決定される.</subsection>
  <subsubsection title="Splitting と Lumping">今vとw_pを動詞とし,w_1,,w_nを動詞,または仮想動詞とする.また,Dev(v,w_i)Dev(v,w_j)(1ijn)かつ,Dev(v,w_1)Dev(v,w_p)とする.本手法ではvがw_1とw_pで示される2つの意味を持つか否かを判定するために,()と()で示されるクラスタを作成し,それぞれの偏差を比較する.v_x,w_p,v_y,w_1,,w_nv,w_1,,w_p,,w_neqnarrayただし,()のw_1,,w_p,,w_nはDev(v,w_i)Dev(v,w_j)(1ijn)を満たすとする.()のv_xとv_yはvの仮想動詞を示す.以下では,(4)で示されるクラスタを作成するために,v,w_1,w_pを入力とし,仮想動詞v_xとv_yを出力する関数split,及び,(5)で示されるクラスタを作成する過程で仮想動詞v_x,v_yが現れた場合にそれらをマージする関数lumpを定義する.関数splitは入力v,w_1,w_pに対し,v_xとv_yを出力する.ただしベクトルvは,(v_1,,v_n)で示されるとする.split(v,w_p,w_1)&amp;=&amp;(v_x,v_y)Dev(v,w_1)&amp;&amp;Dev(v,w_p)eqnarray*-2mm[	v_x=[]s.t._xj=.][v_y=[]s.t._yj=.]equation2式(8),(9)においてvと共起するn_jが,w_pとw_1の両方と共起する場合には,v_xjとv_yjは共にv_j=Mu(v,n_j)とした.また式(9)においてvと共起するn_jが,w_1とw_pのいずれとも共起しない場合には,v_yjの値はv_jの値とした.これは,v_jがv_xとv_yの両方に含まれない場合,v_y,w_1の偏差は常に,v_x,w_pよりも小さくなる.よって,v_xとv_yの偏差をできるだけ均等にするため,v_yjの値は,v_jの値とした.関数lumpは仮想動詞v_xとv_yを入力としwを出力する.*-5mmlump(v_x,v_y)&amp;=&amp;weqnarray*-7mm実験では,()で示される二つのクラスタの偏差の値が共に()で示されるクラスタの偏差の値よりも小さい場合に動詞vは多義とみなした.</subsubsection>
  <subsubsection title="クラスタリングアルゴリズム">クラスタリングアルゴリズムの流れを図に示す.図の`('はその上で示される関数の処理を示す.図において,関数Make-Initial-Cluster-Setは,動詞グループVGを入力とし,VGの任意の動詞対の組合せに対し,意味的な偏差の値を計算し,任意の動詞対と偏差の値をその値が昇順になるように出力する.この結果をICS(InitialClusterSet)と呼ぶ.CCS(CreatedClusterSet)は作成されたクラスタの集合を示す.関数-Temporary-Cluster-SetはSet_iのどちらか一方の動詞を含むクラスタをCCSから抽出する.その結果であるSet_が関数-of-Polysemyに渡される.関数Recognition-of-Polysemyは動詞が多義か否かを判定する関数である.今Set_iとSet_の両方に属する動詞をvとする.vが多義でありw_p(ただしw_pはSet_iの要素とする)とw_1(ただしw_1はSet_の要素とする)の意味を持つか否かを判定するために,()と()で示されるクラスタが作成される.具体的には関数()がv,w_1,とw_pに適用されv_xとv_yが作成される.もしv_xとv_yが()で示されるクラスタを作成する過程で存在する場合,関数()がv_xとv_yに適用され,wが作成される.この処理は新しく得られるクラスタSet_がVGと等しくなるか,あるいはICSの要素がなくなるまで適用される.</subsubsection>
  <subsection title="仮想動詞と名詞の相互情報量">多義語を含む動詞グループに対し,前節で述べたアルゴリズムを適用することで,多義語の各意味を示す動詞と共起する名詞の集合が動詞の個数分得られる.*-0.5cm表は,多義語takeを含む動詞グループtake,obtain,spend,buyに対し,クラスタリングアルゴリズムを適用した結果を示す.クラスタリングの結果得られるこのテーブルをpvn(polysemousverbnoun)テーブルと呼ぶ.v_iは仮想動詞take1,take2,3を示し,それぞれ,`buy',`spend',`obtain'を示す.v_rはv_i以外の意味を示す仮想動詞`residue'を示す.n_ijは,仮想動詞v_iと共起する名詞を示し,n_rjは仮想動詞v_rと共起する名詞を示す.f(n_ij)とf(n_rj)はそれぞれn_ij,n_rjの頻度を示し,f(v,n_ij)とf(v,n_rj)はそれぞれ`take'とn_ij,`take'とn_rjの共起頻度数を示す.文中に現れる動詞の多義解消は基本的に名詞n_ij及びn_rjを用いて行なわれる.すなわち,文中に現れる動詞と共起する名詞が表に示されているとき,文中の動詞は,その名詞と共起する仮想動詞の意味となる.例えば,(s3)において,stakeは表に示されている.従って(s3)のtakenの意味は,take1が示す意味である`buy'と判定される.*2mm*2mm名詞の中には,例えば表の`lot'のように複数の集合に属する名詞が存在する.この場合は,各仮想動詞と`lot'との相互情報量の中で大きい値を持つ仮想動詞の意味とした.ただし,表のMu(v,n_ij)及びMu(v,n_rj)は,`take'と各名詞との相互情報量を示す.そこで,仮想動詞v_i及びv_rと各名詞との相互情報量Mu(v_i,n_ij)及びMu(v_r,n_rj)を以下のようにして求めた.v_i(1ik)を仮想動詞とし,v_rをvにおける各仮想動詞以外の意味を示す仮想動詞とする.num(i)(1ik)をv_iと共起する名詞の個数とし,n_ij(1ik,1jnum(i))をv_iと共起するj軸の名詞とする.v_iの頻度f(v_i)とv_rの頻度f(v_r)は以下の式で示される.f(v_i)&amp;=&amp;f(v)_j=1^num(i)f(v,n_ij)_p=1^k(_q=1^num(p)f(v,n_pq))(v_r)&amp;=&amp;f(v)-_i=1^kf(v_i)eqnarray式()と(),及び()と()を用いて,Mu(v_i,n_ij)とMu(v_r,n_rj)を求める.表のMu(v_i,n_ij)とMu(v_r,n_rj)はそれぞれ仮想動詞v_iと名詞n_ij,仮想動詞v_rと名詞n_rjとの相互情報量を示す.</subsection>
  <section title="多義語の解消">文中の多義語vの意味は,vのpvnテーブルを用いて以下のように決定される</section>
  <section title="実験">実験では,14の動詞グループに対しクラスタリングアルゴリズムを適用した結果得られたpvnテーブルを用い,pvnテーブルが曖昧性の解消にどの程度有効であるかの検証を行なった.さらに丹羽らの提案した文脈ベクトルを用いた名詞の多義解消手法を動詞に適用した結果と,本手法とを比較することで,本手法の有効性を検証した.先ず,実験で用いたデータについて述べ,実験とその結果を示す.次に丹羽らの多義解消手法の概略を示し,比較を行なった結果について述べる.*-2mm</section>
  <subsection title="データ">コーパスはタグ付けされたWallStreetJournalであり,182,992文,総数2,878,688語(総異なり数73,225語)から成る.実験では,このコーパスからウィンドウサイズを5語にとり,総数5,940,193個から成る任意の2語対(総異なり数2,743,974組)を得た.ここで単語xとyのウィンドウサイズが5語であるとは,xの出現位置からxの後方5語以内に現れる単語yとxとの組を示す.我々は,動詞xと名詞yの組を使用した.これは5語という比較的小さいウィンドウサイズでは,動詞と目的語という観点から動詞と名詞の意味的な関係が顕著に現れると考えられるためである.また,動詞の中には,特定の副詞,例えば様態を示す副詞と共起することで,その動詞の意味が決まる場合も存在する.そこで,名詞と動詞の組で正解が得られなかった多義(表の(11)(14)のグループ)に対しては,動詞xと副詞yの組を使用することで正解が得られたpvnテーブルを用いて文中における多義語の解消を行なった.総異なり数2,743,974組に対し相互情報量を計算し,一定の閾値(動詞と名詞,及び動詞と副詞の共起頻度数の閾値を5,相互情報量の閾値を3)以上である動詞と名詞,動詞と副詞の組を抽出した結果,それぞれ6,768,1,200の組を得た.実験では14種類の多義語を用いた.テスト文として,各々の多義語に対しランダムに100文,総計1,400文を抽出し,これらからdelexicalusage,イディオム,メタファ,多義語の意味が曖昧で人間が一意に決定できないものを除く1,226文を対象とし実験を行なった.</subsection>
  <subsection title="曖昧性解消実験の結果">実験で用いた動詞グループと実験結果を表に示す.*-0.6cm表で示される動詞グループにおいて,多義語は下線で示されている.`Procedures'の`withinthepvntable'と`withoutthepvntable'はそれぞれ4章で示した決定法における1と2を示す.`disambiguated'は各`Procedures'で正しく判定できる文数を示す.`correct'は実際に正しく判定できた文数を示す.</subsection>
  <subsection title="他手法との比較">表の結果から,本手法の正解率が71.1%であるのに対し,丹羽らの提案した手法は,62.7%(文脈サイズ5)であることから,本手法の方が良い正解率が得られることがわかる.一般にある文章の話題抽出には名詞が用いられていることから,名詞同士の意味的な関係は広いウィンドウサイズが適切である.一方,動詞と名詞の意味的な関係は比較的狭いウィンドウサイズを用いた方が(動詞と目的語という観点から)顕著に現れる.このことは,表においてウィンドウサイズが10のときよりもの方が良い結果が得られていることからも明らかである.ところがウィンドウサイズを狭くとるとデータスパースネスの問題が生じる.すなわち丹羽らの手法では文脈中の各単語と基準単語との相互情報量の値を用いてベクトルの内積を計算しているが,ウィンドウサイズを狭くとると基準単語と共起する単語数が相対的に減少する.その結果,内積がゼロになり類似度が計算できない場合が生じた.さらに丹羽らの手法では,基準単語はCollinsEnglishDictionaryの語義文における頻度をカウントし,最上位50単語を除いて1000語を抽出しこれを用いている.しかし,これは辞書から得られた一般的な情報であり,WallStreetJournalのような分野依存のコーパスにおいて同様に高頻度に現れるとは限らない.実際,CollinsEnglishDictionaryの見出し語約6万2千語の内,少なくともWallStreetJournalに一回以上出現した単語は約半数であり,単語と基準単語1000語との総組数のうち,実際に一回以上共起したのは約15.8%であった.丹羽らの手法において,このことが本手法よりも高い正解率が得られなかった要因と考えられる.</subsection>
  <section title="考察"/>
  <subsection title="曖昧性解消実験">表によると,4章で示した決定法の2は解消に重要な役割を果たし,名詞間に意味的な近さを示す尺度を導入する必要があることを示している.また総正解数は,総数1,226文のうち872文であり正解率が71.1%に達していること,特に`withinthepvntable'の正解は,総数606文のうち539文であり,正解率が88.9%に達していることから,クラスタリングの結果得られた情報が有効であることを示す.1と2における正解率を比較すると,全ての動詞のグループに対し,2の方が正解率が低かった.例えば,(1)の動詞グループ\underlineclose,open,endにおいて,1である`withinthepvn'における正解率が76.4%(26/34=76.4)であるのに対し,である`withoutthepvn'における正解率は47.6%(31/65=47.6%)であった.式()中のDis(x,n)を用いて偏差を計算した結果例を表に示す.表は,`month',`loss',`stake',`profit',`loan',`money'との偏差が少ない語をそれぞれ上位10語抽出した結果を示す.数値は偏差の値を示す.表によると,Dis(x,n)によりほぼ意味的に近いものを抽出できていることがわかる.このことから,式()中のDis(x,n)は,妥当であると言える.2における正解率が1よりも低かった原因として,積関数である式()が考えられる.すなわち,2において,文中に現れる名詞xがpvnに存在しない場合,pvnに示される名詞の要素一つ一つに対して,式()を適用し,xとの意味的な関係を求めた.しかし多義語の各意味は,名詞の部分集合全体で特徴づけられていることから,文中における名詞xと部分集合全体との偏差を考慮に入れるよう式()を改良する必要がある.</subsection>
  <section title="むすび">本稿では,コーパスから抽出した動詞の語義情報を利用し,文中に含まれる多義語の曖昧性を解消する手法を提案した.本手法の基本的なアイデアは,表層上は一つの要素である多義語動詞を,多義が持つ各意味がまとまった複数要素であると捉え,これを一つ一つの意味に対応させた要素に分解した上でクラスタを作成すれば,多義を判定しながら意味的なクラスタリングが行なえるということである.本手法の有効性を検証するため,丹羽らの提案した単語ベクトルを用いた多義語の解消手法と比較した結果,14種類の多義語動詞を含む1,226文に対し,丹羽らの手法が平均62.7%の正解率に対し,本手法では,71.1%の正解率を得た.本手法では動詞の多義を判定するため,動詞をn次元(nは名詞の個数)名詞空間で,ベクトルとして表現した.しかし,名詞にも多義性があることを考慮していない.軸となる名詞の多義性をどのように扱うかは今後の課題である.document</section>
</root>
