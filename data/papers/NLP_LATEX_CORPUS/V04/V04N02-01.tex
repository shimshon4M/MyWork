\documentstyle[jnlpbbl]{jnlp_j_b5}
\setcounter{page}{3}
\setcounter{巻数}{4}
\setcounter{号数}{2}
\setcounter{年}{1997}
\setcounter{月}{4}
\受付{1996}{4}{24}
\再受付{1996}{8}{20}
\採録{1996}{9}{19}


\setcounter{secnumdepth}{2}

\title{文節間係り受け距離の統計的性質を用いた\\日本語文の係り受け解析}
\author{張 玉潔\affiref{KUEE} \and 尾関 和彦\affiref{KUEE}}
\headauthor{張 玉潔・尾関 和彦}
\headtitle{文節間係り受け距離の統計的性質を用いた日本語文の係り受け解析}
\affilabel{KUEE}{電気通信大学  情報工学専攻}
{\\Course in Computer Science and Information Mathematics,The
University of Electro-Communications}
\jabstract{
日本語における2文節間の係り受け頻度は,\ その距離に依存することが
知られている．\ すなわち,\ 文中の文節はその直後の文節に係るこ
とが最も多く,\ 文末の文節に係る場合を除いては,\ 距離が離れるにし
たがってその頻度が減少する．\ この統計的性質は,\ 日本語文の係り受け解析
においてしばしば用いられるヒューリスティクス：「文中の文節は係り得る文節の中で最も近
いものに係る」の根拠となっている．\ しかし,\  このヒューリスティクスは,
\ 日本語に見られるこのような統計的性質の一部しか利用
していない．\ したがって,\ 係り受け距離の頻度分布をもっと有効に利用
することにより,\ 解析性能が向上する可能性がある．\ 本研究では,\ ATR 
503文コーパスから抽出した係り受け距離の頻度分布に基づいて2文節間の
係り受けペナルティ関数を定義し,\ 「総ペナルティ最小化法」を用いて係り
受け解析実験を行なった．\ その結果を,\ 上のヒューリスティクスに基づく
決定論的解析法による解析結果と比較したところ,\ かなりの解析性能向上が認めら
れた．\ また,\ 係り文節を分類し,\ その種類別に抽出した係り受け頻度の情報を
用いることにより,\ さらに解析性能を改善できることが明らかになった．}
\jkeywords{係り受け解析,係り受けの整合性,係り受け距離,
係り受け規則,統計的言語知識,総ペナルティ最小化}
\etitle{Dependency  Analysis of Japanese Sentences \\Using 
the Statistical  Property of \\ Dependency Distance between Phrases}
\eauthor{Yujie ZHANG \affiref{KUEE} \and Kazuhiko OZEKI\affiref{KUEE}}
\eabstract{
It is well known  that the   frequency  of  phrase-pairs  in  
modifier-modified 
relation   de- \\ pends \  on  the  distance  between \  the 
phrases \  constituting \  the  pair \ in the Japanese\\ 
language.  That is,  a  phrase  in  a  sentence  modifies
 its  immediate  successor most frequently, and the frequency of modification
decreases as the distance between the modifier   phrase and the   modified
phrase   increases   unless the modified phrase is the last one in the
sentence.  This paper discusses a method of exploiting this statistical knowledge
for dependency analysis of Japanese sentences. The $minimum\ total
\ penalty\ method$ was used for  dependency   analysis in this work.
 The  method requires  a penalty function, which specifies the
association strength between phrases.\ Several penalty functions were 
defined based on the frequency distribution of dependency
distance extracted from ATR 503-sentence corpus, and the analysis performances
were compared.\ Another experiment was conducted by using a deterministic dependency
analysis method for comparison.\ It is concluded that the knowledge of the 
dependency distance distribution is effective,\ and that detailed knowledge of the 
dependency distance distribution extracted for each modifier phrase group is
 still more effective for improving the analysis performance.}

\ekeywords{dependency analysis , degree of dependency , dependency 
distance , dependency rule , statistical linguistic knowledge ,
 minimization of total penalty }

\begin{document}
\thispagestyle{myheadings}
\maketitle
\section{まえがき}
日本語文の表層的な解析には,\ 係り受け解析がしばしば用いられる．\ 係り受け解析とは
,\ 一つの文の中で,\ どの文節がどの文節に係る(広義に修飾する)かを定めることであるが,\ 
実際に我々が用いる文について調べて見ると,\ 2文節間の距離とそれらが係り受け関係に
あるか否かということの間に統計的な関係のあることが知られている．\ すなわち,\ 
文中の文節はその直後の文節に係ることがもっとも多く,\ 文末の文節に係る場合を除いては
距離が離れるにしたがって係る頻度が減少する\cite{maruyama}．

係り受け距離に関するこのような統計的性質は「どの文節も係り得る最も近い文節に係る」という
ヒューリスティクス\cite{kurohashi}の根拠になっていると思われる． しかし実際には
「最も近い文節に係ることが多い」とは言え,\ 「最も近い文節にしか係らない」というわけではない．
\ したがって,\ 係り受け距離の統計的性質をもっと有効に利用することにより,\ 係り受け解析の性能を
改善できる可能性がある\cite{maruyama}．

本論文では, 総ペナルティ最小化法\cite{matsu,ozeki}を用いて, 係り受け距離に関する統計的知識の
, 係り受け解析における有効性を調べた結果について報告する． 総ペナルティ最小化法に
おいては, 2文節間の係り受けペナルティの総和を最小化する係り受け構造が解析結果として
得られる． ここでは, 係り受け距離に関する統計的知識を用いない場合と, そのような知識を用いて
係り受けペナルティ関数を設定するいくつかの方法について, 解析結果を比較
した． また, 「係り得る最も近い文節に係る」というヒューリスティクスを
用いた決定論的解析法\cite{kurohashi}についても
解析結果を求め, 上の結果との比較を行った． 学習データとテストデータを分離したオープン実験の結果や
統計的知識を抽出するための学習データの量が解析結果に与える効果についても検討した\cite{tyou}．

\section{係り受け距離の統計的知識}
丸山らは新聞記事データベースを用いて係り受け距離とその頻度の関係を調査
し, それを表す近似式を見い出した\cite{maruyama}．

我々はATR 音声データベース(セットB)\cite{ATR}に含まれる503文コーパスについて丸山らと
同様の調査を行った． コーパスの概要を表1に示す． 全体の503文は\hspace{-0.25mm}$A〜J$\hspace{-0.25mm}までの10グループに分割されており,
\hspace{-0.5mm}$A〜I$のグループには各50文, グループ$J$には53文が含まれている．
 各文節には, それを受ける文節との間の距離を表すラベルが付けられている．
 文の係り受け構造はこれらの値によって知ることができる．
\begin{center}
{表1\ \ \ ATR 音声データベース(セットB)中のコーパス}
\vspace*{2mm}
\\
\begin{tabular}{|c|c|c|c|}
\hline
文体           & 文数&文節数/文&\ \ 係り受け数\ \ \\ \hline
\hline
新聞記事\ ,\ 教科書   & 5\ 0\ 3 & 6\ .\ 8  &  2\ 9\ 2\ 3   \\ \hline
\end{tabular}
\end{center}
\subsection{係り受け距離の頻度分布}
文$x_1 x_2 ... x_N$\ ($x_k$は文節)において\ $x_i$\ が\ $x_j$\ に係るとき,\ $x_i$\ と\ $x_j$\ の係り受け距離を
\ $j-i$\ と定義する．また, $N-i$\ を\ $x_i$\ のレンジと呼ぶ．


表2は係り受け距離の頻度分布を距離4以下について示したものである．
レンジ は考慮していない．距離が11以上の係り受けは存在しなかった．このコーパスでは
距離が1の係り受けが全体の64.\ 6\%を占めている．
文の構成要素(日本語における文節や英語における単語など)が,隣接する構成要素を修飾する
傾向は他の言語においても見られる．例えば, 英語においても, 文中の単語が
直後の単語を修飾する$(Right\  Association)$頻度は
$67\%$\ に及ぶことが報告されている\cite{Don}．
\begin{center}
{表2\ \ \  係り受け距離の頻度分布}
\vspace*{2mm}
\\
\begin{tabular}{|c|c|}
\hline
係り受け距離 &       係り受け数(相対頻度)       \\ \hline
\hline
   1         &         1889 ( 64.6\% ) \\ \hline
   2         &          487 ( 16.7\% )  \\ \hline
   3         &          243 ( 8.3\% )   \\ \hline
   4         &          136 ( 4.7\% )   \\ \hline
\end{tabular}
\end{center}

\subsection{係り受け距離の頻度を表す近似式}
レンジごとに求めた係り受け距離の頻度分布を表3に示す．

\begin{center}
{\hspace*{10mm}表3\ \ \ レンジごとの係り受け距離の頻度分布}
\vspace*{2mm}\\
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\makebox[10mm]{}&\multicolumn{6}{c|}{係り受け距離}\\ 
\cline{2-7}
\makebox[10mm]{\raisebox{1.0ex}{レンジ}}&\makebox[10mm]{1}&\makebox[10mm]{2}&\makebox[10mm]{3}&\makebox[10mm]{4}&\makebox[10mm]{5}&\makebox[10mm]{6}\\  
\hline
   2   & 278(55.7\%) & 221(44.3\%) &     &     &    &    \\ \hline
   3   & 268(55.6\%) &  51(10.6\%) & 163(33.8\%) &     &    &    \\ \hline
   4   & 260(58.6\%) &  66(14.9\%) &  12(2.7\%) & 106(23.8\%) &    &    \\ \hline
   5   & 209(57.4\%) &  54(14.8\%) &  21(5.8\%) &  10(2.8\%) & 79(19.2\%) &    \\ \hline
   6   & 141(55.5\%) &  37(14.6\%) &  23(9.1\%) &   6(2.4\%) &  1(0.4\%) & 46(18\%) \\ \hline
\end{tabular}
\vspace*{3mm}
\\
\end{center}

ただし, レンジが6以下のものだけを
掲げた．このデータを用いて文献\cite{maruyama}と同じ方法により
距離頻度の近似式\bigskip
\[
\hspace*{5mm} P\ (k)\ ＝\left\{
\begin{array}{lll}
\raisebox{2.5ex}{$\ ak^{b}\ , $}& \mbox{\raisebox{2.5ex}{$1≦k\ ≦r-1$ のとき;} }& \\                   
\raisebox{-0.5ex}{$\  1-\sum_{j=1}^{r-1}P\ (j)\ ,$}&\mbox{\raisebox{-0.5ex}{$k=r$ のとき}} & \hspace*{15mm}{\raisebox{1.7ex}{(1)}}
\end{array}
\right.
\]
\\
\hspace*{20mm}(\ $k$\ は係り受け距離,\ \ $r$\ は係り文節のレンジ )
\vspace*{3.9mm}
\\
\noindent
をあてはめたところ $a=0.58$, $b=-1.886$が得られた．これは, 丸山らの結果$a=0.54$, $b=-1.\ 896$と
近いものである．
\vspace{-0.1mm}
\subsection{係り文節の種類による係り受け距離の頻度分布のちがい}
\vspace{-0.1mm}
前節に述べた係り受け距離の頻度分布は, 文節の種類を考慮に入れずに求めた, 全文節に対する平均的なものであるが,
 係り受け距離の頻度分布は係り文節の種類に依存する
ことが予想される．そこで, ここでは係り文節をその末尾の形態素によって
表4に示す基準により約100種類に分類し, その種類別に頻度分布を求めた．
品詞属性はコーパスの説明書\cite{ATR}によった．
\begin{center}
表4\ \ \ 係り文節の分類基準
\vspace*{2mm}
\\
\begin{tabular}{|l|l|l|}
\hline
            &       & 活用語\ :\ 品詞属性と活用形により分類\\
\cline{3-3}
末尾の&{\raisebox{1.5ex}{自立語}} &  非活用語\ :\ 品詞属性により分類 \\
\cline{2-3}
形態素&  &  活用語\ :\  品詞属性と活用形により分類\\
\cline{3-3}
            & {\raisebox{1.5ex}{附属語}}&  非活用語\ :\ 形態素と品詞属性により分類\\
\hline
\end{tabular}
\end{center}
\vspace*{4mm}

また, 受け文節はそれが文末であるか非文末であるか
によって区別した．そして係り文節の種類別に, また受け文節が文末か非文末かを区別して
係り受け距離の頻度を求めた．具体的な計算は4.2の{\bf 3}に述べる
定義式によって行なう．

距離の頻度分布が係り文節の種類に大きく依存する例を表5に示す．
格助詞「が」の 係り受け距離の頻度分布は式(1)\ ($a=0.58$, $b=-1.886$)に近いが,
 接続助詞「が」の場合には距離2で頻度最大になり, ほかの距離の頻度は
一様になっている．このような頻度分布を式(1)のような単調減少関数で
近似することには無理がある．したがって, 本研究では係り文節の種類別に求めた
頻度分布を, そのまま係り受け解析のための情報として用いた．

\begin{center}
表5\ \  係り文節の種類により係り受け距離の頻度分布が異なる例
\vspace*{2mm}
\\
\begin{tabular}{|c|c|c|c|c|}
\hline
\ \ 係り文節の種類\ \  &\ \  距離\ 1\ \ &\ \ 距離\ 2\ \ &\ \  距離\ 3\ \ &\ \  距離\ 4\ \ \\ \hline
\hline
 格助詞「が」       & 67.9\% & 21.9\% & 5.4 \%  & 3.1\%  \\ \hline
 接続助詞「が」     & 11.8\% & 35.3\% &11.8 \%  & 11.8\% \\ \hline
\end{tabular}
\end{center}
\section{係り受け解析法}
係り受け距離の統計的性質を利用することにより, どの程度, 解析性能が向上するかを調べるため,
総ペナルティ最小化法\cite{matsu,ozeki}を用いて係り受け解析の実験を行った．また,
 これと比較するため, 決定論的解析法による解析も行った．ここでは
これらの解析法について簡単に説明する．
\subsection{総ペナルティ最小化法}
文節列が “正しい”文を構成するためには文節間に以下の条件を満たす係り受けが存在する
必要があると考えられている\cite{yoshida}．

\begin{description}
\item[唯一性] 文末の文節以外は, 必ずそれより後ろにある文節のいずれか唯一に係る．
\item[非交差性] 係り受けは交差しない．
\item[整合性] 2文節間に係り受けが成立するためには, それらを構成
              する形態素の品詞や活用形, 意味などが整合しなくてはならない．
\end{description}

総ペナルティ最小化法においては2文節間の整合性を程度の問題と考え, それをペナルティ関数で表す．
そして, 唯一性と非交差性を満たす係り受け構造の中でペナルティの総和が最小になるものすべてを
解析結果として出力する．この計算は動的計画法の原理を用いることにより
効率よく実行できる\cite{ozeki}．
ペナルティ関数を適切に設定することにより, 2文節間の種々の関係を係り受け解析に
利用することができると考えられる．本研究では, 後で述べるように係り受け距離の
頻度分布に基づいてペナルティ関数を設定した．
\subsection{決定論的解析法}
この解析法\cite{kurohashi}においては, 整合性を程度の問題とは捉えず, 整合するかしないかのいずれか
であると考える．解析は文末から順に, その文節を受ける文節を決定することにより
行われる．非交差性, 整合性を満たす受け文節の候補が複数個ある時は,
 最も距離が近い文節を採用する．解析の途中で受け文節が見出せない時には, その時点で解析不能となる．
本研究で用いたアルゴリズムを図1に示す．

\section{実験と結果}  
係り受け距離の頻度情報に基づいて, いくつかのぺナルティ関数を定義し, 総ペナルティ最小化法に
よる係り受け解析を行った．結果を正解検出率, 一意正解率, 曖昧度減少率お
よび平均候補数によって評価し, ぺナルティ関数に
よる結果の違いを比較検討した．また, 決定論的解析法による解析も行い, 総ペナルティ最小化法の
結果と比較した．

\begin{center}\begin{minipage}{120mm}
\vspace*{3mm}
\noindent N\ :\ 文の文節数\ ; \\
kakari\_n\ :\ 係り文節番号 ( 1≦ kakari\_n ≦  N−1)\ ;\\
uke\_n\ :\ 受け文節番号 ( 2≦ uke\_n ≦  N)\ ;\\
uke\_number\ [\ i\ ]\ :\ 文節番号iの文節を受ける文節の番号\ ;\\
kakari\_uke\_if\ (\ i\ ,\ j\ )\ :\ 文節番号iの文節が文節番号j\ の文節に係り得るか否かをチェックする関数\ .
\bigskip

\noindent program  \ \ \ deterministic\_analysis\ ;    \\
\hspace*{7mm}    var\ \ \ \   kakari\_n\ ,  uke\_n\ :\ integer\ ;\\
\hspace*{16mm}               uke\_number\ [\ i\ ]\ :\ array\ [\ 1\ .\ .\ N\ ] \ \ of\ \  integer\ ;\\
                  begin    \\
\hspace*{10mm}         uke\_number\ [\ N\ ]\  :＝ N\ ＋\  1\ ; \\
\hspace*{10mm}         uke\_number\ [\ N−1\ ]\  :＝ N\ ; \\
\hspace*{10mm}         for \ \ \ kakari\_n :＝ N−2 \ \ \   downto \ \ \ 1 \ \ \ do\\
\hspace*{15mm}         begin \\
\hspace*{20mm}               uke\_n\ :＝ kakari\_n\ ＋\  1\ ;\\
\hspace*{20mm}               while \ \ (uke\_n\ $<=$\ N)\ and \\ 
\hspace*{35mm}(kakari\_uke\_if\ (\ kakari\_n\ ,\ uke\_n)＝ false)\ \ \\
\hspace*{20mm}          do \ \ \ uke\_n :＝ uke\_number\ [\ uke\_n\ ]\ ; \\
\hspace*{20mm}               if   \hspace*{1mm} \ uke\_n ＝ N\ ＋\  1\ \hspace*{3mm}\\
\hspace*{20mm}                    then\ \  \ begin \\ 
\hspace*{37mm}                                 write\ (\ '\ failed\ '\ )\ ;\\
\hspace*{37mm}                                 uke\_number\ [\ kakari\_n\ ]\  :＝ kakari\_n\ ＋\ 1\ \\
\hspace*{33mm}                               end\\
\hspace*{20mm}                    else\ \ \ \ uke\_number\ [\ kakari\_n\ ]\  :＝ uke\_n\\      
\hspace*{15mm}         end\\
                 end\ .
\bigskip

\begin{center}
  図1\ \ \  本研究で用いた決定論的解析アルゴリズム
\end{center}
\end{minipage}\end{center}
\subsection{係り受け規則}
文献\cite{kurohashi}を参考にして, 2文節間の形態素による整合条件を表6に示すように定めた．
\begin{center}
{\hspace*{15mm}表6 \ \ \ 係り受け規則}
\vspace*{2mm}
\\
\footnotesize
\begin{tabular}{|l|c|c|c|c|c|c|c|}
\hline
{} &\multicolumn{7}{c|}{受け文節の頭部の形態素}\\ 
\cline{2-8}
    &    &     &     &{\raisebox{-1.0ex}{述語の}}      &{\raisebox{-1.0ex}{連体形の}} &{\raisebox{-1.0ex}{連体形の}} &{\raisebox{-1.0ex}{連用形の}}    \\
{\raisebox{0.5ex}{係り文節の後部の形態素}}&名詞&{\raisebox{1.5ex}{名詞＋}}&動詞&イ・ナ&イ&ナ&イ・ナ\\
  &                        &{\raisebox{1.5ex}{判定詞}}&                            &{\raisebox{0.8ex}{形容詞}}&{\raisebox{0.8ex}{形容詞}}&{\raisebox{0.8ex}{形容詞}}&{\raisebox{0.8ex}{形容詞}}\\
\hline 
連体詞                  &＋  &            &    &        &        &        &        \\ \hline 
活用語の連用形          &    &  ＋        &  ＋&    ＋  &        &        &        \\ \hline 
活用語の基本形・タ形    &  ＋&            &    &        &        &        &        \\ \hline 
  副詞                  &    &          ＋&  ＋&      ＋&      ＋&      ＋&      ＋\\ \hline 
  助詞                  &    &            &    &        &        &        &        \\ \hline 
\hspace*{10mm}      の                &＋  &  ＋        & ＋ &  ＋    &   ＋   &        &        \\ \hline  
\hspace*{10mm} が、に、より           &    &  ＋        & ＋ &  ＋    &   ＋   &   ＋   &        \\ \hline 
\hspace*{10mm}    へ                  &    &  ＋        & ＋ &        &        &        &        \\ \hline 
\hspace*{10mm}     を                 &    &            & ＋ &        &        &        &        \\ \hline 
\hspace*{10mm}    他の助詞              &    &  ＋        & ＋ &  ＋    &        &        &        \\ \hline 
\end{tabular}
\end{center}
\vspace*{3mm}

実際には, この条件を, 
「受け文節の頭部の形態素」としての「名詞」,「名詞＋判定詞」,「動詞」の
さまざまな変形に対処できるように補強して用いる．
例えば, 「二時半ごろだった」(「数詞＋接尾語＋名詞＋名詞＋助動詞＋助動詞」)は
「名詞＋判定詞」として認識されるようにしている．
ここではこの条件を係り受け規則と呼ぶ．この規則は総ペナルティ最小化法と
決定論的解析法の両方において共通に使用した．
\subsection{ぺナルティ関数の定義}      
係り文節$x$, 受け文節$y$\ に対してぺナルティ関数 $F\ (x ,y)$を次のように定義する．

\[\hspace*{5mm}  F\ (x ,y)＝\left\{
\begin{array}{lll}
\raisebox{2.5ex}{$- \log P\ (x ,y)\ ,\ $}&\mbox{\raisebox{2.5ex}{$P\ (x,y)>0$\  のとき\ ;}}& \\
\mbox{\raisebox{-1.0ex}{c\ ,\ }}&\mbox{\raisebox{-1.0ex}{$P\ (x,y)=0$\  のとき\ }}& \hspace*{15mm}{\raisebox{1.7ex}{(2)}}
\end{array}
\right.
\]

ここで,\ $P\ (x ,y)$\ は\ $x$\ が\ $y$\ に係る頻度から定まる値である．
その具体的な定め方は後で述べる．文節$x,\ y$\ が係り受け規則を      
満たさない場合には $P\ (x ,y)=0$\ と定義する．
このときのぺナルティ値\ c\ は非零の$P\ (x ,y)$で生成される
最大ぺナルティ値より十分大きな値に設定する．

これにより, 文節\ $x,\ y$\ が係り受け規則を満たさない場合には
大きなぺナルティが課せられる．また, 係り受け規則を満たす場合には,\ 
$P\ (x ,y)$が大きい程, ぺナルティは小さくなる．
$P\ (x ,y)$として次の4種類の関数を考え, それぞれに対して実験を行った．
\begin{description}
\item[1] 距離情報なし
    \[P_1\ (x ,y)＝α\] 
$α$は正の定数である．すなわち,\ $(x ,y)$\ が一様分布することを仮定する．
\item[2] 距離の頻度近似式
\[P_2\ (x ,y)＝P\ (d\ (x,y)\ )\] 
ここで,\ $d\ (x,y)$は$x$と$y$\ の係り受け距離であり,\ $P\ (\ ・\ )$は
式(1)である．

\item[3] 係り文節の種類別に求めた頻度分布 

2.3で述べたように,\ 係り受け距離の頻度分布は係り文節の種類に依存する．
また, 係り受け距離が同じでも受け文節が文末か非文末かによって係り受
け頻度は大きく異る\cite{maruyama}．そこで係り文節の種類別に,
 また受け文節が文末か非文末かを区別して, 以下のように
係り受け距離の頻度分布を求めた．

係り文節の種類(表4)を番号\ $m$\ で表す．そして,\ 
\ $T\ (m)$\ を係り文節が第\ $m$\ 種の文節であるような 
係り受け文節対の全体とする:
\vspace*{2mm}\\
\hspace*{12mm}$T(m)\ =\ \{\ (u,v)\ |\ 文節\ u\ は文節\ v\ に係る,\ u\ は第\ $m$\ 種の係り文節 \}$
\vspace*{2mm}\\
\ $T\ (m)$\ の中で,\ 係り文節と受け文節の距離が\ $k$\ であり,\
受け文節が文末であるようなものの全体を$S_l^{m}\ (k)$,\ 同じく
受け文節が非文末であるようなものの全体を$S_n^{m}\ (k)$
とする:
\vspace*{2mm}\\
\hspace*{10mm}$S_l^{m}\ (k)=\ \{\ (u,v)\ |\ (u,v) \in T\ (m),\ d\
(u,v)=k\ ,\ v\ は文末文節\}$\ \ ,
\vspace*{2mm}\\
\hspace*{10mm}$S_n^{m}\ (k)=\ \{\ (u,v)\ |\ (u,v) \in T\ (m),\ d\ (u,v)=k\ ,\ v\ は非文末文節\}$ 
\vspace*{2mm}\\
当然,\ 次の関係がある:
\[\ T\ (m)＝\  \cup_{k}\ (S_l^{m}\ (k)\ \cup\ S_n^{m}\ (k)\ )\]
  そして,\ 以下の式により文節$x$が文節$y$に
係る相対頻度の推定値$P_3\ (x ,y)$を計算する:
\vspace*{1mm}
\[P_3\ (x ,y)＝\left\{
\begin{array}{l}
\mbox{\raisebox{3.0ex}{$|\ S_l^{m(x)}\ (d\ (x,y))｜\ \ /\ ｜T\ (m(x))｜$\ ,\ yが文末文節のとき\ ;}}\\
\mbox{\raisebox{-0.5ex}{$|\ S_n^{m(x)}\ (d\ (x,y))｜\ \ /\ ｜T\ (m(x))｜$\ ,\ yが非文末文節のとき\ }}\\
\end{array}
\right.
\]
\vspace*{1mm}\\
ここで\ $m(x)$\ は係り文節\ $x$\ の種類を表し,\ $|・|$は集合の要素数を表す．
すなわち,\ $P_3\ (x ,y)$は,\ \ $d\ (x,y)=\ k$とするとき,\ $x$\ と同じ種
類の文節を係り文節とする係り受け文節対の中で, 距離が\ $k$\ であるよう
なものが, どれだけの割合で存在するかを示す量であり,\ $y$ が文末か非文
末かに分けて計算される．ここでは, 係り受け文節対の出現頻度が,
 係り文節の種類, 係り受け距離, および受け文節が文末か非文末かの三つの
変数に依存して定まる分布モデルが仮定されていることになる．
\item[4] 補間した頻度分布\\
\hspace*{4mm}
係り受け規則がコーパスを完全にカバーしていないため, ある文節を受ける文節が文末までに存在しない
ことがある．また係り受け規則で許されても, コーパスの希薄性によって,
 係り受け頻度が0となる場合がある．そこで,\ $P_3$\ に次のような一種の補間を施し,その結果を\ $P_4\ (x,y)$とする．
\begin{description}
\item[(1)]\ 上のような問題がない場合\ :
     \[P_4\ (x,y)＝P_3\ (x,y)\]
\item[(2)]\ 上のような問題がある場合\ :
\begin{description}
\item[(a)]  文節 $x$を受ける文節が文末までに存在しない場合:\\
   文節$x$がどの文節に係るかを係り受け距離の頻度
分布に基づくヒューリスティクスで定める．\\
すなわち, 文節$x$に対して, 上の\ {\bf 3}\ で推定された係り受け頻度が
最大となる後続文節を求め,\ $x$がその文節に係ることを許す．また, 他
の文節に係ることは許さない．これは, 文節\ $x$が後続文節\ $y$\ に係る
ことが係り受け規則の上では許されなくても, もし文節間距離が\ $d\ (x,y)$に
等しい係り受け文節対の出現頻度が大きければ, それを許そうという考え方であ
る．その際, 出現頻度が最も大きい後続文節だけに対して文節\ $x$が
係ることを許し, 他の文節に対しては許さないことにする．

実際の計算は次のように行なう．

文節\ $x$に対して, 最大係り受け頻度を与える後続文節を\ $z$ とする:
 \[z=\arg\max\{\ P_3\ (x,y)\ |\ y\ は\ xの後続文節\}\]
このような\ $z$\ が複数個あるときは,\ それらをすべて求める．\ 
そして,\ 文節$x$が後続文節\ $y$\ に係る頻度$P_4\ (x,y)$を
次のように設定する:
\[P_4\ (x,y)=\left\{
\begin{array}{ll}
\raisebox{2.0ex}{$\ P_3\ (x,y)$\ ,}&\mbox{\raisebox{2.0ex}{$y=z$\ のとき;}}\\      
\raisebox{-1.0ex}{\ 0\ ,  }&\mbox{\raisebox{-1.0ex}{$y≠z$\ のとき}}\\                   
\end{array}
\right.
\]

\item[(b)]  $xがy$\ に係ることが,\ 係り受け規則で許されるにもかかわらず,\ $P_{3}\ (x,y)$が0になる場合:
\[P_4\ (x,y)=β\] 
ただし,$β$は
\[\max_{u,\ v}\{- \log P_3\ (u,v)\ \}<- \log β<<\mbox{\ c}\hspace*{20mm}(3)\]  
を満たすような値に設定する．ここで,\ 最左辺の最大値は文節$\ u\ が文節\ v\ $に係ることが係り受け規則で許されるような$u\ ,\ v$\ のすべての組についてとる．
これはいわゆる底上げ(flooring)の技法である．このとき,\ $x$\ が\
$y$\ に係るペナルティは\ $- \log β$\ となるが, 式(3)は, このペ
ナルティが係り受け規則により係り受けが許されない文節対のペナルティより
ははるかに小さく, また, 係り受け頻度から定まる最大ペナルティよりは大
きくなるように\ $β$\ の値を設定することを意味する． 
\end{description}
\end{description}
\end{description}
\subsection{解析実験}
解析実験は学習データから係り受け距離の頻度情報を抽出する学習ステップと
, その頻度情報に基づいて設定したペナルティ関数を用いてテストデータを
係り受け解析し, 結果を評価する解析ステップから成る．\\
まず学習法と各種のパラメータ設定法について説明する．

$P_1$を用いる場合には, 頻度情報は全く使用しない, したがって学習は不
要である．αはどのような値に設定しても解析結果は同じになる．

$P_2$\ はパラメトリックな分布モデルである．学習ステップにおいては,
 学習データを用いてパラメータ\ $a$,\ $b$\ を推定する．

$P_3$\ はノンパラメトリックな分布モデルである．学習ステップにおいて
は, 学習データを用いて, 係り文節の種類\ $m$\ と\ 係り受け距離\ $k$\ に対して$S_l^{m}\ (k)$と
$S_n^{m}\ (k)$を求め,\ 記憶する．
解析ステップにおいては, 各文節\ $x$,\ $y$\ に対し,\ $S_l^{m(x)}\ (k)$と
$S_n^{m(x)}\ (k)$から定義式に基づいて\ $P_3\ (x,y)$\ の値を
計算し,ペナルティ関数の値を設定する．

$P_4$\ は基本的には$P_3$\ から定まるので学習する必要はない．
βの値は式(3)を満たす限りどのような値に設定しても結果に
大きな差はないと考えられるので, 式(3)を満たす値を任意
に選んで使用した．

ペナルティ関数を式(2)によって定義するとき, 定数\ $c$\ を定める
必要がある．これは文節\ $x$\ が文節\ $y$\ に係ることが係り受け
規則により許されないとき, あるいは文節\  $x$\ が文節\ $y$\ に係る
頻度が\ 0\ になるとき\ (\ $P_4$\ によって補間されない限り)文節
\ $x$\ が文節\ $y$\ に係ることを禁止するような大きなペナルティ
を与えるためのものである．したがって, これは  $\infty$ 
とも言うべきものであり, 十分大きな値に設定すれば, どの
ような値に設定しても解析結果に差はない．

このような学習法およびパラメータ設定法を用いて
次のような3種類の実験を行った．

\begin{description}
\item[実験1] $P_1$〜$P_4$を用いてぺナルティ関数を定義し,
総ペナルティ最小化法による解析実験を行った．
この実験では係り受け距離の頻度情報を抽出するための
学習データとテストデータを分離せず,どちらも503文すべてを用いた．
比較のため同じデータを用いた決定論的解析法による解析実験
も併せて行った．

\item[実験2] 実験1で総合的に最も良い結果が得られたのは$P_4$\hspace{-0.25mm}で
定めたぺナルティ関数である．これを用いて,学習データとテストデータを分離した解析実験を行った．
10グループ$A〜J$\ の一つをテストデータとし,残りを学習データとした．
テストデータを$AからJ$\ まで変えて10回の実験を行った．

\item[実験3] 学習データの量と解析結果との関係を調べるため,
テストデータをグループ$J$\ に固定し,学習データを$A,A \cup B,A \cup  B \cup C, \cdots  $
と漸次増加させる実験を行った．純粋に学習データの量が解析結果に与える効果を見い出すため,補間していない$P_3$を用いてぺナルティ関数を定めた．
\end{description}
\subsection{解析結果}
解析結果について述べるため,まず記法と用語を定義する．

\begin{itemize}
\item $M$\ :\ 評価に用いるテスト文の総数\ ;
\item $S_i$\ :\ 番号$i$のテスト文\ ;
\item $L_i$\ :\ 文$S_i$ の文節数\ ;\\
\hspace*{7mm}文$S_i$\ に対する係り受け構造の中の係り受けの総数は\ $L_i-1$\ に等しい．
\item $D_i$\ :\ 長さ$L_i$\ の文節列上に存在し得る係り受け
構造の総数;\\
\hspace*{7mm} $D_i$\ はカタラン数と呼ばれる数列になり,\ 次の式によって計算することができる:
\[D_i＝\frac{1}{L_i}\ _{2(L_i-1)}C_{(L_i-1)}\] 
\hspace*{8mm}ここで\ $_{2(L_i-1)}C_{(L_i-1)}$\ は\ $2(L_i-1)$
個のものから\ $(L_i-1)$\ 個のものをとる組合せの数を表す．\ この式は再帰式
\[D_i\ =\left\{
\begin{array}{ll}
\ {\raisebox{2.0ex}{1,}}&\mbox{\raisebox{2.0ex}{$i=1$\ のとき;}}\\      
\ \sum_{1≦j≦i-1}{D_{i-j}D_j}\ ,  &\mbox{$i≧2$\ のとき}\\                   
\end{array}
\right.
\]
\newline
が成り立つ\cite{ozeki}ことと\ ,母関数の手法\cite{JCC}を用いることにより示すことができる．
\item $R_i$\ :\ 文$S_i$の解析結果\ ,\ すなわち係り受け構造候補の集合\ ;
\item $K_{ij}$\ :\ 文$S_i$に対する$j\ (\ 1≦ j ≦ |R_i|\ )$番目の解析候補の中でコーパスのラベルに示されるものと一致する係り受けの数\ ．
\bigskip
\end{itemize}
{\bf 評価方法}
\vspace*{1mm}

\noindent
結果の評価は,\ \ (1)\ \ 2文節間の係り受けがどの程度正しく検出されたか,\ \ (2)\ \ 係り受け構造が
どの程度正しく検出されたか, という二つの観点から行った．また, 文の検出率が高くても一つの文に
対する解析結果の候補数が多ければ良い解析法とは言えない．このため, 候補数がどれだけ絞られるかを
評価することとした．さらに, 解析を行うことにより, 情報理論的な曖昧さがどれだけ減少するかを
調べ, 全体的な解析効率を評価した．これらの評価を行うため, 以下のようないくつかの評価尺度を定義した． 

\noindent
(1) 係り受けの正しさに着目した評価尺度\bigskip
     \[\ \  文S_i\ の係り受け検出率\ ＝\ \frac{\sum_{j=1}^{|R_i|}K_{ij}}{(L_i-1)×|R_i|}\]
\bigskip
  \[係り受け検出率\ ＝\ \frac{\sum_{i=1}^{M}\sum_{j=1}^{|R_i|}K_{ij}}{\sum_{i=1}^{M}(L_i-1)×|R_i|}\]
\newline
係り受け検出率は,解析結果がラベルと部分的に一致する度合を示す数字である．このような部分的一致も
,結果を意味理解に利用する場合などには有用と思われる．

        
決定論的解析法を用いた解析実験においては,解析の途中で,ある文節を受ける文節が存在しない時には,
直後の文節を受け文節として解析を続けた．その結果をもとにして係り受け検出率を計算した．
\vspace*{3mm}
\\
(2) 係り受け構造の正しさに着目した評価尺度

\noindent(a)文検出数と文検出率
\[  文検出数_k\ ＝\sum_{i\ :\ |R_i|≦k}I_i \]
ここで
\[I_i\ ＝\left\{
\begin{array}{ll}
{\raisebox{2.0ex}{1\ ,}}&\mbox{\raisebox{2.0ex}{$R_i$の中にラベルで指定される係り受け構造と一致する候補が存在する場合;}}\\      
{\raisebox{-0.5ex}{0\ ,}}&  \mbox{\raisebox{-0.5ex}{ 他の場合 }}
\end{array}
\right.
\]
\vspace*{2mm}

$文検出数_k$\ は, 出力された解析結果の候補数が\ $k$\ 以下であり,\ かつ,\ その中に
コーパス中のラベルで指定される係り受け構造と一致するものが含まれるような
テスト文の数である．また, これをテスト文の総数に対する比で表わしたものを,
 $文検出率_k$\ と呼ぶ\ : \bigskip
\[文検出率_k\  ＝\ \frac{文検出数_k}{M}\]
\newline
$文検出数_\infty$ ,\ $文検出率_\infty$\ をそれぞれ単に文検出数,\ 文検出率という．また,\ 
$文検出数_1$ ,\ $文検出率_1$\ をそれぞれ一意正解数,\ 一意正解率と呼ぶことにする．
\ 一意正解数は解析結果が一意的に決定し,\ それがコーパスのラベルと一致したテスト文の数である．

\noindent (b)平均候補数
\[平均候補数\ ＝\ \frac{ \sum_{i=1}^{M}|R_i|×I_i}{\sum_{i=1}^{M}I_i}\]
\newline
\noindent(c)曖昧度減少率\\
      文$S_i$ の係り受け構造の候補数の対数をその文の曖昧度と定義すると,
\begin{table}[b]
\begin{center}
表7 {\ \ \ \ 実験1の結果}
\vspace*{2mm}
\\
\begin{tabular}{ |c|c|c|c|c|c|} 
\hline
\makebox[30mm]{}&\makebox[26mm]{\raisebox{-0.5ex}{文検出数}} &\makebox[14mm]{\raisebox{-0.5ex}{平均}}&\makebox[14mm]{\raisebox{-0.5ex}{曖昧度}}&\makebox[24mm]{\raisebox{-0.5ex}{係り受け}} \\[-2mm]
\makebox[30mm]{\raisebox{1.5ex}{ペナルティ関数}}&\makebox[26mm]{ 文検出率(\%)} &\makebox[14mm]{候補数}&\makebox[14mm]{減少率}&\makebox[24mm]{検出率(\%)} \\\hline
\makebox[30mm]{$P_1(距離情報なし)$}&\makebox[26mm]{432(85.9) } &\makebox[14mm]{41.3}&\makebox[14mm]{0.40}&\makebox[24mm]{61.5} \\
\hline
\makebox[30mm]{$P_2(近似式)$}&\makebox[26mm]{247 (49.1)} &\makebox[14mm]{2.5}&\makebox[14mm]{0.36}&\makebox[24mm]{75.2} \\\hline
\makebox[30mm]{$P_3(種類別)$}&\makebox[26mm]{321(63.8)} &\makebox[14mm]{2.9}&\makebox[14mm]{0.52}&\makebox[24mm]{74.4} \\\hline
\makebox[30mm]{$P_4(補間)$}&\makebox[26mm]{287(57.1)} &\makebox[14mm]{1.1}&\makebox[14mm]{0.47}&\makebox[24mm]{87.1} \\\hline
\hline
\makebox[30mm]{決定論的解析法}&\makebox[26mm]{193(38.4)} &\makebox[14mm]{1.0}&\makebox[14mm]{0.28}&\makebox[24mm]{81.9} \\\hline
\end{tabular}
\end{center}
\end{table}
\vspace*{2mm}

\[解析前の曖昧度＝\log D_i\]

\[解析後の曖昧度＝\left\{
\begin{array}{ll}
\mbox{\raisebox{1.0ex}{$ \log |R_i|\ ,$}}&\mbox{\raisebox{1.0ex}{$R_i$の中にラベルで指定される係り受け構造と}}\\      
             &\mbox{\raisebox{1.0ex}{一致する候補が存在する場合\ ; }}\\      
\raisebox{-0.5ex}{$\log D_i\ ,$  }&\mbox{\raisebox{-0.5ex} {他の場合 }}
\end{array}
\right.
\]
\vspace*{1mm}\\
\hspace*{36mm}$   
＝\log\ (D_i+(\ |R_i|-D_i\ )\ I_i) $ 
\vspace*{2mm}\\
となる．これを用いて,\ 次の量を定義する．\bigskip
\[曖昧度減少率＝\frac{ \sum_{i=1}^{M}\log D_i - \sum_{i=1}^{M}\log\ (D_i+(\ |R_i|-D_i)\ I_i)}{\sum_{i=1}^{M}\log D_i}\]
\newline
曖昧度減少率は文の統語的な曖昧さが解析により減少する度合を表す．
\vspace*{1mm}\\
{\bf 実験結果と分析}
\vspace*{1mm}\\
(1)\ 実験1の結果を表7に示す．また,\ 同実験において候補数を制
限したときの文
検出数(率)を表8に示す．
\begin{table}[t]
\begin{center}
表8 \ \ \ \ {候補数を制限したときの文検出数(率)}
\vspace*{2mm}
\\
\begin{tabular}{ |c|c|c|c|} 
\hline
\makebox[30mm]{}&\multicolumn{3}{c|}{$文検出数_k$\ (率\%)} \\
\cline{2-4}
\makebox[30mm]{ペナルティ関数}&\makebox[20mm]{}&\makebox[20mm]{} &\makebox[28mm]{\raisebox{-1.0ex}{一意正解数(率) }}\\ 
\makebox[30mm]{}&\makebox[20mm]{\raisebox{1.5ex}{$k＝50 $}} &\makebox[20mm]{\raisebox{1.5ex}{$k＝10$}} &\makebox[28mm]{\raisebox{0.5ex}{ ($k＝1$)}}\\\hline
\makebox[30mm]{$P_1(距離情報なし)$}&\makebox[20mm]{364(72.4) }&\makebox[20mm]{235(46.7) }&\makebox[28mm]{31(6.2) }\\
\hline
\makebox[30mm]{$P_2(近似式)$}&\makebox[20mm]{246(48.9)}&\makebox[20mm]{244(48.5) }&\makebox[28mm]{195(38.8)}\\\hline
\makebox[30mm]{$P_3(種類別)$}&\makebox[20mm]{319(63.4)}&\makebox[20mm]{315(62.6) }&\makebox[28mm]{237(47.1)}\\\hline
\makebox[30mm]{$P_4(補間)$}&\makebox[20mm]{287(57.1)}&\makebox[20mm]{287(57.1) }&\makebox[28mm]{264(52.5)}\\\hline
\hline
\makebox[30mm]{決定論的解析法}&\makebox[20mm]{193(38.4)} &\makebox[20mm]{193(38.4)}&\makebox[28mm]{193(38.4)}\\ \hline
\end{tabular}
\end{center}
\end{table}

$P_1$を用いた場合は,\ 他の場合と比べて,\ 文検出率が高い反面,\ 平均候
補数が非常に大きい．また,\ 表8から$文検出率_k$\ (\ $k=10,\ 1$)は$P_2$〜$P_4$を用いた場合の方が,\ $P_1$を用いた場合より高い．したがって,\ 係り受け距離の情報は候補数を絞るのに有効であることがわかった．

$P_3$を用いた場合は,\ $P_2$を用いた場合と比較して,
\ 表7における文検出率,\ および表8における$文検出率_k$\ (\ $k=50,\ 10,\ 1$)が高い．
したがって,\ 係り文節の種類別に求めた係り受け距離の頻度情報は,\ 係り文節を分類せず全体で求めた情報よりも,\ 
各文検出率$_k$を高めるのに有効である．また,\ その結果,\ 曖昧度が減少し
ている．

$P_4$を用いた場合は,\ $P_3$を用いた場合と比べて,\ 表7における係り受け検出率と表8における一意正解率が高くなっている．
したがって,\ 補間は係り受け検出率と一意正解率を上げる効果があることが検証された．
文検出率は低下したが,\ $P_2$を用いた場合よりは高く,
\ 平均候補数は$P_3$を用いた場合の半分以下になっている．したがって,\ 
距離の頻度分布を補間することにより,\ ある程度係り受け規則の不完全さとコーパスの
希薄性の問題を軽減できることがわかった．また,\ 平均候補数は1.1まで絞られており,\ 87.1\%\ というかなり高い
係り受け検出率が得られることから,
\ この解析法を意味理解のための部分解析法として使用できる可能性がある．

\hspace{0.25mm}決定論的解析法を用いた解析実験と比較すると,\ $P_1〜P_4$を用いた場合は表7\hspace{0.1mm}の平均候補数が大きくなったかわりに文検出率がかなり向上している．さらに,\ 表8において,
\ $P_2$〜$P_4$を用いた場合は決定論的解析法を用いた場合の一意正解率を越えるともに
各$文検出率_k$\ が高くなっている．とくに$P_4$を用いた場合は
決定論的解析法を用いた場合と平均候補数がほとんど等しく,
\ 各$文検出率_k$\ ,\ 曖昧度減少率,\ および係り受け検出
率が高くなっている．したがって,\ 係り受け距離の統計的知識を利用した
総ペナルティ最小化法により,\ 決定論的解析法を用いた場合に比べて
解析性能を向上させることができる．
\\
(2)\ 実験2の結果を表9に示す．
\begin{table}[b]
\hspace*{50mm}表9  \ \ \ \ {実験2の結果}
\vspace*{2mm}
{\small
\begin{center}
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|} \hline
    \begin{tabular}[c]{@{}c@{}} テスト\\[-1.1mm]グループ\\\end{tabular}&
      \makebox[6mm]{A} & \makebox[6mm]{B} &\makebox[6mm]{C} &
      \makebox[6mm]{D} & \makebox[6mm]{E} &\makebox[6mm]{F} &
      \makebox[6mm]{G} & \makebox[6mm]{H} &\makebox[6mm]{I} &
      \makebox[6mm]{J} & 合計 \\ \hline
    文数 &
      50 & 50 & 50 & 50 & 50 & 50 & 50 & 50 & 50 & 53 & 503 \\\hline\hline
    \begin{tabular}[c]{@{}c@{}} 文検出数\\[-1.1mm](率)\\\end{tabular}&
      25 & 27 & 20 & 26 & 25 & 16 & 26 & 26 & 29 & 41 & 261(52\%) \\\hline
    \begin{tabular}[c]{@{}c@{}} 一意正解数\\[-1.1mm](率)\\\end{tabular}&
      21 & 22 & 19 & 19 & 22 & 13 & 18 & 24 & 23 & 37 & 218(43\%) \\\hline
    \begin{tabular}[c]{@{}c@{}} 平均\\[-1.1mm]候補数\\\end{tabular}&
      1.3 & 1.3 & 1.1 & 1.5 & 1.1 & 1.2 & 1.4 & 1.1 & 1.2 & 1.1 &
      1.2 \\\hline
    \begin{tabular}[c]{@{}c@{}} 曖昧度\\[-1.1mm]減少率\\\end{tabular}&
      0.39 & 0.41 & 0.30 & 0.49 & 0.33 & 0.28 & 0.41 & 0.42 & 0.44 & 0.68 &
      0.42 \\\hline
  \end{tabular}
\end{center}
}
\end{table}
この実験は学習データとテストデータを分離した, いわゆるオープン実験である．
文検出率と一意正解率はクローズ実験である実験1の結果に比べると若干低下し,
平均候補数もやや増加している．しかし,\ 1.2という平均候補数は, この解
析結果に対してさらに何らかの後続処理を行う場合, 処理量の上で問題となる
数ではなく,\ 表7に示される決定論的解析法の結果と比べると,文検出数,一意正解数,
曖昧度減少率など全てが高い．したがって,\ 未知文の係り受け解析に対しても
(1)と同様の結論が導かれる．
\\
(3)\ 実験3の結果を表10に示す．これもオープン実験である．学習データの量
が増加するに従って, 一意正解数, 曖昧度減少率が向上するともに, 平均候補数は減少する．
文検出数はほぼ一定に保たれる．
したがって, 学習データ量を増加させることはこのような解析法の性能向上に有効である．
より大きなコーパスを使用することによって, 更に解析性能が向上すること
が期待される．
\begin{center}
表10 \ \ \ \ {実験3の結果}
\vspace*{2mm}
\\
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline 
学習データの量&{\raisebox{-1.0ex}{50}} &{\raisebox{-1.0ex}{100}} &{\raisebox{-1.0ex}{150}}  &{\raisebox{-1.0ex}{200}}&{\raisebox{-1.0ex}{250}}&{\raisebox{-1.0ex}{300}} &{\raisebox{-1.0ex}{350}} &{\raisebox{-1.0ex}{400}}&{\raisebox{-1.0ex}{450}} \\[-2mm]
（文数）      &     &     &      &     &      &      &     &     &  \\  \hline
\hline  
53文の文検出数&  43 & 43  &  42  &  41 &   42 &   41 &  40 &  43 &   43 \\  \hline 
一意正解数    &  16 & 24  &   25 &   25&   28 &   29 &  29 &  29 &   31 \\  \hline 
平均候補数    & 3.8 &2.2  &  2.0 & 1.9 & 1.7  & 1.5  & 1.5 & 1.5 & 1.5  \\  \hline
曖昧度減少率& 0.53&0.61 & 0.62 &0.60 & 0.63 & 0.63 &0.60 &0.67 &0.68\\  \hline
\end{tabular}
\\
\end{center}
\section{むすび}
本研究の結論は次のようにまとめることができる．
\begin{enumerate}
\item  係り受け距離の頻度分布は係り受け解析におけるヒューリスティクスとして有効である．
\item 係り受け距離の頻度分布は,係り文節の種類別に求めた方がよい．
\item  頻度分布の補間により,係り受け規則の不完全さとコーパスの希薄性をある程度補うことが
  できる．
\item  頻度分布を抽出する学習データ量を増加することにより解析性能が向上する．ここで用いた学習データより
もっと多くのデータを使用することにより,解析性能がさらに向上する可能性がある．
\end{enumerate}

\noindent
問題点としては,\ 以下のことが挙げられる．
\begin{description}
\item {(a)}係り文節の分類は, 自立語が非活用語の場合にはその品詞属性に基づいて行っている．
しかし, これには次のような問題がある．コーパス中に高頻度で出現する「名詞」は,
 その半数程度が「連体詞」のような働きをして名詞に係る．
また,「前」,「ため」などの「名詞」は「副詞」のような働きをして動詞に係ることがある．
「連体詞」と「副詞」では, それを受ける文節との距離の頻度分布が大きく異なる．
このような問題があるので, 係り受け距離の頻度分布を求めるときの係り文節
の分類基準をもっと工夫する必要がある．
\item {(b)}ここで用いた係り受け規則はまだ不完全である．
$P_1$を用いたときの文検出率がこの係り受け規則のカバー率を示している
が,\ 表7に見られるように100\%\ には達していない．
したがって, 実際のコーパスをよりよくカバーする係り受け規則を設定する必要がある．
\item {(c)}
 文中の部分文節列に対して, 係り受け構造に曖昧さがあっても, それによる意味の曖昧さがほとんど生じない場合もある．
    例えば,\ 
「両手の\ \ 十本の\ \ 指を」に対して,\ 図2の二つの係り受
け構造から得られる意味の違いが実際にどれ程問題となるであろうか．
\vspace*{1mm}\\
\hspace*{25mm}\underline{両手の}\hspace*{25mm}\underline{十本の}\hspace*{25mm}\underline{指を}\\
\put(185,20){\line(0,1){10}}
\put(185,20){\line(1,0){95}}
\put(280,20){\line(0,1){10}}
\put(85,10){\line(0,1){20}}
\put(85,10){\line(1,0){146}}
\put(230,10){\line(0,1){10}}
\vspace*{1mm}
\\
\hspace*{25mm}\underline{両手の}\hspace*{25mm}\underline{十本の}\hspace*{25mm}\underline{指を}\\
\put(85,20){\line(0,1){10}}
\put(85,20){\line(1,0){100}}
\put(185,20){\line(0,1){10}}
\put(140,10){\line(0,1){10}}
\put(140,10){\line(1,0){141}}
\put(280,10){\line(0,1){20}}
\begin{center}
図\ 2
\end{center}
本研究で行った評価法では, 出力される係り受け構造がコーパスのラベルと完全に一致しない限り,
 文としては検出されなかったことになる．しかし, このような曖昧性を解消
する意義がどれくらいあるかを考える必要があると思われる．
\item {(d)}「は」のような係り助詞で終る文節がどの文節に係るとするかは,
 微妙な問題を含んでいる．例えば, 図3は,「インタビューは」が主文の述語「及んだ」に係るような
係り受け構造を示しているが, これに対して, 図4のように「インタビューは」が「始まり」に係るとする
係り受け構造を考えることもできる．図3は, 文を文末まで見てから係り受け構造を定めたものであり,
 図4は, 文を左から見て行き, 可能な係り受けを定めて行ったものと言えるであろう．
\vspace*{1mm}\\
\hspace*{15mm}\underline{インタビューは}\hspace*{5mm}\underline{午後十
時から}\hspace*{5mm}\underline{始まり}\hspace*{5mm}\underline{四時間に}
\hspace*{5mm}\underline{及んだ}\\
\put(155,30){\line(0,1){10}}
\put(155,30){\line(1,0){55}}
\put(210,30){\line(0,1){10}}
\put(260,30){\line(0,1){10}}
\put(260,30){\line(1,0){46}}
\put(306,30){\line(0,1){10}}
\put(183,20){\line(0,1){10}}
\put(183,20){\line(1,0){100}}
\put(283,20){\line(0,1){10}}
\put(80,10){\line(0,1){30}}
\put(80,10){\line(1,0){161}}
\put(240,10){\line(0,1){10}}
\begin{center}
図\ 3
\vspace*{1mm}\\
\end{center}
\hspace*{15mm}\underline{インタビューは}\hspace*{5mm}\underline{午後十
時から}\hspace*{5mm}\underline{始まり}\hspace*{5mm}\underline{四時間に}
\hspace*{5mm}\underline{及んだ}\\
\put(155,30){\line(0,1){10}}
\put(155,30){\line(1,0){55}}
\put(210,30){\line(0,1){10}}
\put(260,30){\line(0,1){10}}
\put(260,30){\line(1,0){46}}
\put(306,30){\line(0,1){10}}
\put(80,20){\line(0,1){20}}
\put(80,20){\line(1,0){103}}
\put(183,20){\line(0,1){10}}
\put(130,10){\line(0,1){10}}
\put(130,10){\line(1,0){153}}
\put(283,10){\line(0,1){20}}
\begin{center}
図\ 4
\end{center}
いずれか正しいかは別にして, 使用したコーパスにはこの2種類の考え方に基づくラベル付けが混在しており,
 統一性を欠いている．これが, 係り受け距離の頻度分布の推定や, 解析
結果の評価に影響を与えていると思われる． 
\end{description}

以上の結果と問題点を踏まえて, 今後は文節間の係り受けに関する言語現象を
詳しく調査し, 係り受け解析に対するより優れた
ぺナルティ関数の設定法について研究を進める予定である．
\bibliographystyle{jnlpbbl}
\bibliography{jpaper}
\begin{biography}
\biotitle{略歴}
\bioauthor{張 玉潔}{
1983年北方交通大学情報工学科卒業. 
1986年中国科学技術大学大学院修士課程修了.  
同年中国科学院計算技術研究所に勤務. 
機械翻訳の研究開発に従事.国家科学技術進歩一等賞受賞. 
現在, 電気通信大学情報工学専攻博士課程在学中.自然言語処理に興味があ
る.}
\bioauthor{尾関 和彦}{
1965年東京大学工学部電気工学科卒業. 同年NHK入社. 1968年より1年間
エジンバラ大学客員研究員. 
音声言語処理, パターン認識などの研究に従事. 
電子通信学会 第41回論文賞受賞. 
現在, 電気通信大学情報工学科教授. 工学博士. 
電子情報通信学会, 情報処理学会, 日本音響学会, IEEE各会員.}
\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}
\end{biography}
\end{document}
