<?xml version="1.0" ?>
<root>
  <title>確率的言語モデルに基づく多言語コーパスからの言語系統樹の再構築</title>
  <author>北研二</author>
  <jabstract>本論文では，言語のクラスタリングに関する新しい手法を提案する．提案する手法では，まず各言語の言語データから確率的言語モデルを構築し，次に確率的言語モデルの間に導入した距離に基づき，元の言語に対するクラスタリングを実行する．本論文では，以上の手法をN-gramモデルの場合について詳しく述べている．また，提案した手法を用いて，ECI多言語コーパス(EuropeanCorpusInitiativeMultilingualCorpus)中の19ヶ国語のテキスト・データから，言語の系統樹を再構築する実験を行った．本実験で得られた結果は，言語学で確立された言語系統樹と非常に似ており，提案した手法の有効性を示すことができた．</jabstract>
  <jkeywords>言語モデル，N-gramモデル，多言語コーパス，クラスタリング，言語系統樹</jkeywords>
  <subsection title="N-gram モデル">たとえば，英語では文字qには文字uが後続するとか，ドイツ語においては文字cに後続するのはhやkであるなど，文字の連鎖には確率・統計的な性質が存在する．N-gramモデルは，このような文字の連鎖をモデル化するために適した確率モデルである．文字のN-gramモデルは，文字の生起をN-1重マルコフ過程により近似したモデルであり，文字の生起は直前に出現したN-1文字にのみ依存すると考える．すなわち，n文字から成る文字列c_1,,c_nに対し，となる．N-gramモデルを用いた場合，文字列c_1,,c_nの生成確率は，次のようにして計算することができる．P(c_1,,c_n)&amp;=&amp;_i=1^nP(c_i|c_1,,c_i-1)&amp;&amp;_i=1^nP(c_i|c_i-N+1,,c_i-1)eqnarray上式において，最初の等式は，確率論の基本定理から導かれる．また，２番目の近似式は，式()による．いま，文字列c_1,,c_nが言語データ中に出現する回数をF(c_1c_n)で表すことにする．N-gramの確率は，言語データ中に出現する文字のN個組と(N-1)個組の出現回数から，次のように推定することができる．Nの値が大きい場合には，統計的に信頼性のある確率値をコーパスから推定することが難しくなるため，通常はN=3あるいはN=2のモデルが用いられることが多い．なお，N=3の場合をtrigramモデル，N=2の場合をbigramモデル，N=1の場合をunigramモデルと呼ぶ．</subsection>
  <section title="はじめに">近年，大量の機械可読なテキスト(コーパス)が利用可能になったことや，計算機の性能が大幅に向上したことから，コーパス・データを利用した確率的言語モデルの研究が活発に行われてきている．確率的言語モデルは，従来，自然言語処理や音声処理などの工学分野で用いられ，その有効性を実証してきたが，比較言語学，方言研究，言語類型論，社会言語学など，言語学の諸分野においても有用な手法を提供するものと思われる．本稿では，言語学の分野での確率的言語モデルの有用性を示す一例として，言語のクラスタリングを取り上げる．ここでは，言語を文字列を生成する情報源であるとみなし，この情報源の確率・統計的な性質を確率モデルによりモデル化する．次に，確率モデル間に距離尺度を導入し，この距離尺度に基づき言語のクラスタリングを行なう方法を提案する．以下では，まず２節で先行研究について概説し，３節で確率的言語モデルに基づく言語のクラスタリング手法を提案する．４節では，提案した手法の有効性を示すために行った実験について述べる．ここでは，ECI多言語コーパス(EuropeanCorpusInitiativeMultilingualCorpus)中の19ヶ国語のテキスト・データから，言語の系統樹を再構築する．また，実験により得られた結果を，言語学的な観点から考察する．最後に，他分野への応用および今後の課題などについて述べる．</section>
  <section title="従来の研究">統計的手法に基づき，言語の比較を計量的に行う研究は，従来から広く行われてきている．KroeberおよびChr'etienは，1930年代に，音韻や語形等の言語的特徴から言語間の相関係数を求め，これに基づきインド・ヨーロッパ諸言語9ヶ国語およびヒッタイト語の間の類似性を求める研究を行っている．また，クラスター分析に基づき，自動的に言語や方言を分類する研究に関しても，いくつかの先行研究がある．文献には，これらの研究の古典的な諸方法が概説されている．また，数学的手法に基づく言語のクラスタリングに関する最近の研究として，Batageljらの研究があり，そこでは65ヵ国語の言語に対するクラスタリング結果が示されている．ここで，従来研究では，言語間の距離(あるいは類似度)を導入するために，どのような方法が用いられてきたかを若干紹介する．文献の４章で述べられている方法では，インド・ヨーロッパ諸言語の一致度を調べるために，２つの言語の対応する数詞の最初の子音が一致しているか否かを調べている．たとえば，ドイツ語とスペイン語の数詞``1''はそれぞれ``eins''および``uno''であるが，これらの２単語において，最初に出現する子音は共に``n''であるので，数詞``1''に関しては，ドイツ語とスペイン語は一致していると考える．10個の数詞のうち，何個の数詞について最初の子音が一致しているかを調べ，これをもとに言語間の距離を導入している．また，Batageljらの研究では，２つの言語の対応する単語の文字列間距離に基づき，言語間の距離を定義している．いま，２つの文字列uおよびvが与えられたとき，文字列u中に文字を追加したり，あるいはu中の文字を削除したりして，文字列uを文字列vに変換することを考える．このとき，文字列uを文字列vに変換するために必要な最小の追加および削除文字数で，２つの文字列間の距離を定義する．たとえば，u=,v=に対しては，まずuから``elly''を削除し，次に``auch''を追加することにより，uをvに変換することができるので，この場合の文字列間距離は８(削除４文字＋追加４文字)である．以上の文字列間距離を各言語から抽出した16個の単語について求め，これらの距離の和により，言語間距離を定義している．以上のように，従来の研究では，あらかじめ人間が言語を分類する上で有用であると思われる音韻や語形等の言語的特徴を抽出したり，あるいは比較のための基礎語彙を選定するなどの作業が必要であった．また，言語間距離の定義にも恣意的な部分が残されていたということができる．</section>
  <section title="確率モデルに基づく言語のクラスタリング">本稿で提案する方法の概略を図に示す．この方法では，まず各言語の言語データから確率的言語モデルを自動的に学習し，次に確率モデル間に距離を導入することにより，言語間の距離を定義する．このように，本稿の方法は，自己組織的(self-organizing)であり，あらかじめ人間が各言語の言語的特徴を抽出したり，基礎語彙を選定する必要はない．また，本稿の方法の利点として，各言語のデータを独立に選ぶことができるという点をあげることができる．たとえば，言語によって違うジャンルのテキストであったり，あるいはデータのサイズが異なっていても，これらのデータの揺れを確率モデルの中に吸収することができる．確率モデルとしては，様々なものが考えられるが，４節で述べる評価実験では文字のtrigramモデルを用いた．trigramモデルは，N-gramモデルの特別な場合(N=3の場合)であり，以下ではN-gramモデルについて簡単に説明する．N-gramモデルに関する詳細な説明は，たとえば文献などを参照せよ．</section>
  <subsection title="言語モデル間の距離">次に，言語モデル間に距離を導入する．我々の用いた距離は，文献において提案されているものと同一である．上記文献においては，隠れマルコフ・モデル(HiddenMarkovModel;HMM)間の距離として定義されているが，一般の言語モデルに対しても同様に用いることができる．いま，言語L_1および言語L_2の言語データとして，それぞれD_1，D_2が与えられているとする．D_i(i=1,2)は，文字列データであり，その長さ(文字数)を|D_i|と表記する．また，言語データD_iから作成された言語モデルをM_iで表す．まず，言語モデルM_1およびM_2に対し，距離尺度d_0(M_1,M_2)を次のように定義する．式()では，言語L_1とL_2の間の距離を，言語L_1のモデルM_1からデータD_2が生成される確率と，言語L_2のモデルM_2から同一のデータD_2が生成される確率の差に基づいて決めている．もし，言語L_1とL_2が類似していれば，モデルからのデータの生成確率も似た値になるので距離は小さくなるし，類似していなければ，データの生成確率が大きく違うので距離は大きくなる．式()は，言語モデルM_1およびM_2に対し，非対称である(すなわちd_0(M_1,M_2)d_0(M_2,M_1))．対称形にするために，d_0(M_1,M_2)とd_0(M_2,M_1)の平均を取る．従って，言語モデルM_1とM_2の間の距離d(M_1,M_2)は，最終的に次のように定義される．</subsection>
  <section title="評価実験"/>
  <subsection title="言語データ">以上で提案した方法の有効性を実証するために，ECI多言語コーパス(EuropeanCorpusInitiativeMultilingualCorpus)中の言語データを用いて，言語の系統樹を再構築する実験を行った．ECIコーパスは，ELSNET(EuropeanNetworkinLanguageandSpeech)からCD-ROMにより提供されているもので，総語数約１億語から成る．ECIコーパス中には，主要なヨーロッパ各国語およびトルコ語，日本語，ロシア語，中国語，マレー語等の言語データが含まれている．本実験では，このうち，ISOLatin-1文字セットでコード化されている19言語のデータを用いた．表は，本実験で用いた言語の種類，各言語データのECIコーパス中での識別子，言語データのジャンルを示している．表のジャンル欄において，「並行テキスト」と記されているのは，同一の内容を多言語で記述したものであることを示している．ECIコーパス中のテキストはSGMLによりコード化されているが，本評価実験では，まずSGMLのタグを除去し，テキスト部分のみを抽出した．次に，多言語の言語データ間に均質性を持たせるために，単語表記中にアルファベット大文字が使われている場合は小文字に変換し，言語によってはウムラウトやアクセント記号等を表す特殊符号が入っていたが，英語式アルファベット26文字以外の特殊文字は，すべて対応するアルファベットに変換した．たとえば，~aはaに変換した．また，文字のtrigramは，表の識別子欄に示されているテキストの最初の1,000単語を用いた．</subsection>
  <subsection title="実験結果および考察">上記により作成した文字trigramモデルに対し，階層的(凝集型)クラスター分析を行ない，言語のデンドログラム(dendrogram;樹状図)を作成した．クラスタリング・アルゴリズムには，群平均法UPGMA(UnweightedPair-GroupMethodusingAverage)と呼ばれる方法を用いた．群平均法は，広い範囲においてよい結果を与えるクラスター分析法であるといわれている．図に，19言語のクラスタリング結果を示す．言語名の左側の樹状図が実験により得られた結果であり，右側には各言語のおおまかな分類を記している．以下では，言語学的な観点から，クラスタリング結果の妥当性について考察する．なお，言語の分類および諸言語間の関係に関しては，文献を参考にした．まず，評価実験で用いた言語は，以下のように大きく分類される．インド・ヨーロッパ語族アルバニア語派(アルバニア語)スラブ語派(チェコ語，クロアチア語，セルビア語，スロベニア語)バルト語派(リトアニア語)イタリック語派(ラテン語，フランス語，ポルトガル語，スペイン語，イタリア語)ゲルマン語派北ゲルマン語派(ノルウェー語，デンマーク語)西ゲルマン語派(オランダ語，ドイツ語，英語)アルタイ諸語(トルコ語，ウズベク語)オーストロネシア語族(マレー語)図の右側に示すように，実験により得られた結果は，上記の大分類を反映したものになっている．次に，言語間のより細かな関係について調べる．まず，実験結果では，スラブ語派に属するクロアチア語とセルビア語を，最初に一つのクラスタとしてまとめている．クロアチア語とセルビア語はともに，南スラブ語群に属し，両者の差異は方言的なものであるとされている．従って，両者を一つのクラスタとすることは，きわめて妥当であるといえる．また，実験結果では，スラブ語派とバルト語派を併合した後に，これをアルバニア語派と併合している．スラブ語派とバルト語派の諸言語には，多くの類似点が見られ，バルト・スラブ祖語の存在を考えている研究者もいる．アルバニア語は，同一の語派に属する言語がなく，１言語で１語派の扱いを受けているが，南スラブ語等の言語からの影響を受けている．実験結果は，以上の点を反映しているということができる．西ゲルマン語派に関しては，オランダ語とドイツ語を，まず併合しているが，ドイツ語学では，オランダ語をドイツ語の１方言，低地フランク語として扱っており，この２言語はきわめて類似している．以上のように，実験結果は，言語の細分類に関しても，かなりの部分で言語学での分類と一致しており，提案したクラスタリング手法が有効なものであることを示している．また，文字trigramモデルにおけるスムージングの効果を調べるために，スムージングを行わない場合についても実験を行った．スムージングを行わない場合には，トルコ語，ウズベク語，マレー語が１つのクラスタを形成するという結果が得られた(図から分かるように，スムージングを行った場合には，マレー語は単独で１つのクラスタを形成している)．しかし，それ以外には，クラスタを形成する順序が多少違うだけで，結果に大きな違いを見いだすことはできなかった．この結果より，言語系統樹の構築では，言語モデルを多少精密化しても，精密化の影響を受けるまでには至らなかったということができる．</subsection>
  <subsection title="言語識別の実験">上記実験により，確率的言語モデルは言語のクラスタリングにきわめて有効であることを示したが，クラスタリング以外の分野での確率的言語モデルの有用性を示すために，追加実験として言語識別の実験を行った．この実験では，上記で作成した各言語の文字trigramモデルを用いて，未知のテキストから，そのテキストの使用言語を特定するということを行った．以下に，本実験の手順を示す．各言語に対し，２つの未知テキストを評価データとして用意する．未知テキストは，表に示したものとは別のテキスト・データである．言語によっては，表以外のテキスト・データがないものもあり，言語識別用の評価データは26個(13言語)となった．なお，未知テキストとして用いた言語データは，以下の通りである．チェコ語(cze01a02,cze01a03)，ラテン語(lat01a02,lat01a03)，マレー語(mal01a02,mal01a03)，ノルウェー語(nor01a02,nor01a03)，セルビア語(ser01a01,ser01a02)，デンマーク語(mda12a,mda12b)，オランダ語(dut01a01,dut01a02)，英語(eng01a,eng01b)，フランス語(fre01a01,fre01a02)，ドイツ語(ger02a,ger02b)，イタリア語(ita01a,ita03a)，ポルトガル語(por01a,por01b)，スペイン語(spa02a,spa02b)．各未知テキストから，4.1節に示した手順と同様にして，未知テキストに対する言語モデル(文字trigramモデル)を作成する．3.3節で導入した距離を用いて，未知テキストの言語モデルと各言語の言語モデルとの間の距離を計算する．最も小さな距離を与える言語を，未知テキストの使用言語と判断する．上記による実験において，未知テキストの最初の10単語，20単語，30単語，40単語，50単語，100単語，1000単語を用いた場合について，言語識別率を求めた．実験結果を，図に示す．図から分かるように，未知テキストからの使用言語の特定には，20単語程度あれば十分であるということができる．20単語を用いたときには，26個の未知テキストのうち，25個についてその言語を正確に推定できた(識別率96.2%)．なお，識別に失敗したものは，例えばセルビア語のテキストをクロアチア語と間違うなど，近親関係の言語間での間違いが主であった．なお，N-gramに基づいた言語識別に関する研究としては，CavnarおよびTrenkleの研究などがある．Cavnarらは，テキスト中に頻出するN-gram文字列の出現順位に基づいた距離を用いて，高い精度で言語の自動識別ができることを示している．彼らの実験では，8ヶ国語のネットニュースの記事を用いており，未知テキストが300文字以上与えられた場合には，99.8%の識別率を達成したと報告している．実験に用いた言語データや対象言語の数などが異なることから，本論文の結果と直接比較することはできないが，Cavnarらの結果も本論文の結果も，N-gramが言語の自動識別に非常に有効であることを示している．</subsection>
  <section title="おわりに">本稿では，確率的言語モデルに基づいた言語のクラスタリング手法を提案した．また，ECI多言語コーパス中の19ヶ国語のテキスト・データから言語の系統樹を再構築する実験を行ない，実験結果を言語学での分類と比較することにより，提案した手法の有効性を示した．本稿では，確率的言語モデルとして文字のN-gramモデルを用いたため，文字の連鎖という観点からのクラスタリング結果が得られた．言語類型論の分野では，言語の語順等により諸言語間の比較を行うことなどが行われているが，語順等に対する言語モデルを設定することができれば，言語類型性という観点から見たクラスタリングを行うことができるであろう．今後の課題として，(1)他の言語モデルを用いたときの言語のクラスタリング，(2)より多くの言語を対象としたクラスタリング実験を行いたいと考えている．また，本稿で述べた実験では，クラスタリング手法として群平均法UPGMAを用いたが，クラスタリング手法には他にも様々なものがあり，他の手法を用いた場合についても検討していく必要があろう．本稿では，言語のクラスタリングを中心に扱ったが，提案した手法はテキストの分類(TextCategorization)などにも応用可能であると考えられる．また，本稿で述べた基本的な手法は，比較言語学，方言研究，言語類型論，社会言語学などの幅広い分野で役立つものと期待される．本論文で提案した手法を，これらの分野において広く用いて頂くために，プログラムおよび実験に用いたデータを公開する．+kita@is.tokushima-u.ac.jp+宛に電子メイルで問い合わせられたい．document</section>
</root>
