\documentstyle[jnlpbbl,eclepsf,boxit,version]{jnlp_j}

\setcounter{page}{181}
\setcounter{巻数}{7}
\setcounter{号数}{4}
\setcounter{年}{2000}
\setcounter{月}{10}
\受付{2000}{2}{25}
\再受付{2000}{5}{10}
\採録{2000}{6}{30}
\setcounter{secnumdepth}{2}

\begin{document}

\title{複数決定木を用いた入力誤りに頑健な省略補完手法}
\author{山本 和英\affiref{ATR}\and 隅田 英一郎\affiref{ATR}}

\headtitle{複数決定木を用いた入力誤りに頑健な省略補完手法}
\headauthor{山本, 隅田}

\affilabel{ATR}{ATR音声言語通信研究所}
    {ATR Spoken Language Translation Research Laboratories}

\jabstract{
  日本語は主語などの要素がしばしば省略されるため，これらの補完は対話処
  理において重要である．さらに音声対話処理においては，実際に対話を処理
  する際に入力となるのは音声であり，一部誤りを含んだ音声認識結果が処理
  対象となるため，言語処理部においても不正確な入力に対する頑健性が要求
  される．このため，入力の一部に誤りのある状況下における格要素補完問題
  を考え，以前に提案した決定木を使用した補完手法を改良したモデルを提案
  する．このモデルは，複数の決定木を使用することで複数解候補を出力し，
  その中から学習時の終端節点事例数によって解の選好を行なうことで入力誤
  りに対する頑健性を強化した．音声認識の実誤りと人工的な誤りの2種類で
  評価実験を行なった結果，提案手法が誤りを含む入力に対し頑健であること
  を確認した．また人工的な問題に対するシミュレーションの結果，本提案手
  法は問題非依存であり，入力誤りの多さに応じた決定木の組み合わせでモデ
  ルを構成することで有効に機能することが明らかとなった．
}

\jkeywords{省略補完，頑健性，音声言語処理，対話処理，決定木}

\etitle{Multiple Decision-Tree Strategy for Ellipsis\\ Resolution
    with Input-Error Robustness}

\eauthor{
    Kazuhide Yamamoto\affiref{ATR}\and
    Eiichiro Sumita\affiref{ATR}}

\eabstract{
  In Japanese spoken language processing, the subject and other cases
  are often omitted.  Several approaches to resolve such an ellipsis
  have been proposed so far, but none of them have considered
  robustness against noisy input.  It is important to also have some
  robustness in an ellipsis resolution module, since the inputs of the
  process are the results of a speech recognition module, which may
  have some recognition errors in spoken dialogue processing.  We thus
  propose a robust model of ellipsis resolution which utilizes a
  multiple decision tree (MDT) model.  Experimental results have
  proven its robustness, and have also shown that the model is
  task-independent and works more effectively if we provide decision
  trees with the number of attributes corresponding to the amount of
  noise.
}

\ekeywords{ellipsis resolution, robustness, spoken-language
processing, dialogue processing, decision tree}

\maketitle
\thispagestyle{empty}

\newpage
\section{はじめに}

人と人，または人と計算機が音声を介してコミュニケーションを行なう際に必
要となる音声対話処理における頑健性を議論する．例えば，音声を入力として
これを翻訳し音声出力する音声翻訳などが本論文の想定する対象である．

音声対話処理においては，不明瞭な発声や雑音，音声認識処理部の誤りに起因
する誤りによって，言語処理部に対して誤りのない正確な入力が得られない場
合があり，この結果従来の自然言語処理では問題とならなかった入力の不正確
性が生じる．これに対し，従来行なわれてきた言語処理研究の主眼は，
\vspace*{\baselineskip}

\begin{itemize}
\item 如何にして入力の不正確性を除去するか
\end{itemize}
\vspace*{\baselineskip}

\noindent
という一点に集中していた．すなわち，言語処理として如何に音声認識の誤り
を発見し，また訂正するか，という捉え方をしてきた．あるいはそもそも入力
の不正確性は音声認識器に起因する問題であるので，理想の音声認識器を考え
ることで入力の不正確性に伴う問題を回避してきた．

これに対し本研究では，現実的な環境を考えた場合に，音声認識誤りのない状
況を仮定して言語処理を行なうことは今後しばらく賢明でないという立場を取
る．あるいは音声認識の誤り訂正技術の進歩によっても，音声言語処理におい
て誤入力のない状況を想定することは現実的な仮定でないと考える．よって，
音声認識後の各処理部がこれら不正確な入力に対して性能を劣化させないとい
う頑健性の考慮，すなわち，
\vspace*{\baselineskip}

\begin{itemize}
\item 如何にして不正確な入力に対して言語処理を行なうか
\end{itemize}
\vspace*{\baselineskip}

\noindent
が，音声言語処理においては重要である．

ところで，対話においては相手と互いにコミュニケーションを取りながら進行
していく．このため発話によって伝達される情報は自己完結的でなく，その結
果発話の様々な要素の省略がより頻繁に起こりやすい．特に，本論文の対象で
ある日本語対話では，その言語的性質から多くの場合に文の主語が省略される．
日本語における主語の省略は，主語が必須格である英語やドイツ語などへの翻
訳の際には大きな問題となり，主語の補完処理は必須の処理となる．

以上のように，音声対話処理における入力誤りへの頑健性を考慮した主語補完
処理は音声対話処理の実現のための重要な処理の一つである．これは田中の分
類による言語表現の多様性分類\cite{田中穂積}に従えば，音響レベルにおけ
るエラー\footnote{田中の分類は言語表現の分類であるため音声認識誤りは考
慮されていないが，処理の観点では誤発声や言い淀みと同様に考えてよいであ
ろう．}を考慮しながら統語レベルの情報不足(省略)の問題解決をしなければ
ならないことを意味している．実際の音声言語システムにおいてはこのように
異なるレベルの多様性を同時に考慮する必要があるにもかかわらず，このよう
な研究は従来行なわれていない．

主語の補完手法に関しては，次節で述べるようにこれまで様々な手法が提案さ
れてきた．ところが従来の主語補完手法は，誤りのない文に対して形態素解析，
構文解析が成功した後に処理されることを仮定していた．このため誤りを含む
可能性のある文に対する処理は考慮外であった．これに対し本論文では，入力
の一部に誤りがある状況において，性能劣化を如何に最小限に抑えるかについ
て議論する．誤り部分が入力のどこなのかは明らかでなく，入力に誤りがない
かもしれない．ただし，本研究では述語に誤りはなく，また省略の検出は正し
く行なわれることを仮定する\footnote{述語が誤っている場合，及び入力文に
省略があるという認識がない場合はそもそも省略補完問題として成立しないた
めである．}．また，属性として使用している言語外情報も，音声認識結果と
は無関係の情報であるので，これも誤りはないと仮定する．

本論文ではまず，本問題に関係する文献の紹介を行なった後，既提案の決定木
学習に基づく主語補完手法\cite{主語補完}\footnote{文献\cite{主語補完}で
は主語以外の格要素に関しても考察を行なっているが，本論文では議論を主語
に限定する．ただし，本論文において行なう議論はそのまま他の格要素につい
ても同様に有効である．}を概観し，この頑健性について考察する．次に，よ
り頑健性を持ったモデルを提案し，実験結果からこの有効性を議論する
{}\cite{NLPRS99}．最後に，人工的な問題によるシミュレーションを行ない，
モデルの問題依存性と属性組み合わせに関して議論する\cite{ICSLP2000}．



\section{関連研究}

前述したように，音声認識誤りを含む要素列を入力とした主語補完
{}\footnote{文献によっては問題を「ゼロ代名詞補完」と呼んでいるものもあ
るが，ここでは「主語補完」と呼称を統一する．}手法は，これまで知られて
いない．最近では，河原らが音声言語処理における頑健性について\cite{河原}，
丸山が話し言葉の諸相について\cite{丸山}，それぞれ議論を行なっているが，
本論文で取り扱う音響レベル，すなわち不正確な音声認識結果に対する自然言
語処理の頑健性に関しては議論されていない．

本研究では，音声認識誤りを修復，訂正するのではなく，入力のどこかに誤り
があるという状況下でどのように言語処理を行なうかという議論を行なう．同
様の状況を想定して言語処理を進めている研究として，脇田ら\cite{脇田}の
研究が知られている．脇田らは，本研究と同様，誤りを含む入力に対して機械
翻訳させるという問題に対し，音声認識誤りを訂正するのではなく，翻訳結果
の意味的な尤度を計算することで音声認識の誤り部分を特定し，その部分を翻
訳結果からはずすことで翻訳する手法を提案している．

照応処理の頑健性に関しては Aone and Benett\cite{Aone}が議論している．
ここでは語彙，文法あるいは意味知識の網羅が現実では不可能なことに対処す
る頑健性の必要性を議論している．ただし，この論文で議論されている頑健性
はすべて，利用する情報が不足している場合における頑健性であり，音声言語
処理にとって重要な入力の不正確性に関しては考慮されていない．

日本語の主語補完に関しては従来から様々な研究がなされてきているが，その
多くは書き言葉を対象にしたものであり，話し言葉もしくは対話を対象にした
ものは比較的少ない．書き言葉を対象にしたものでは，Nakaiwa et
al.{}\cite{Nakaiwa}の用言意味属性と語用論的，意味論的制約を用いて外界
省略の解消を行なったものがある．また村田ら\cite{村田}は物語を対象に，
補完に関係する表層的な言語現象をヒューリスティックスで得点を付与し，そ
れらの合計によって最尤の省略内容を補完している．また，江原らの研究
\cite{江原}はニュース原稿を対象にしている．ここでは，複文を単文に分割
した際に生じる省略主語を補完するという人工的に問題に対して，経験的に8
項目の特徴パラメータを設定して，確率モデルによる手法を提案している．
Dohsaka{}\cite{Dohsaka}は，日本語において発話から語用論的制約を抽出し，
制約充足プロセスに基づいて文脈の下で解釈することによる文脈省略の補完手
法を提案している．



\section{主語補完手法}

本節では，日本語の格要素省略を補完する問題に対して我々が文献\cite{主語
補完}において提案した手法の概要を紹介する．本論文では，このモデルを
SDT(Single Decision Tree)モデルと呼び，入力の不確かさに対する頑健性と
いう観点から，SDTモデルがどの程度の頑健性を持つのかについて定性的な議
論を行なう．さらに，入力の誤りに対して頑健な主語補完モデルを作成するた
めにはどうすればよいかについて検討する．


\subsection{決定木を用いた補完手法}
\label{節:SDTの頑健性}

SDT モデルでは，決定木 (Decision Tree)による知識表現手法を用いて主語補
完知識の構築を行なう．決定木の学習では，(誤りのない)入力と正解となる主
語情報を持った事例から，事前に用意した属性の有無によって質問を行ない，
エントロピー基準によって事例の分類を行なっていく．論文\cite{主語補完}
においては，一般的な決定木学習手法の一つである C4.5\cite{Quinlan} のア
ルゴリズムによって二分木を作成した．

本論文の設定する問題では，補完すべき主語を6種類に分類した．すなわち，
一人称単数<1sg>，一人称複数<1pl>，二人称単数<2sg>，二人称複数<2pl>，照
応的省略<a>，一般<g>である．決定木は，与えられた入力に対して当該省略が
このどのクラスに属するかを決定する．

\begin{figure}
\begin{center}
\renewcommand{\baselinestretch}{}\large\normalsize
\begin{boxit}
\begin{verbatim}
[1-1]:sem-code :here 43
    [2-1]:sem-code :here 78
        [3-1]:regexp :after (ておる 助動詞)
            [4-1]:regexp :after (する 補助動詞)
                [5-1]:speaker :here 情報提供者
                    [6-1]:regexp :before (を 格助詞)
                        ...
                    [6-2]<1pl> (5)
                [5-2]<1pl> (12)
            [4-2]:regexp :after (てる 助動詞)
                [5-3]<1sg> (2)
                [5-4]:regexp :forward (ている 助動詞)
                    ...
        [3-2]:regexp :after (か 終助詞)
            [4-3]:regexp :before (に 格助詞)
                [5-5]<1sg> (1)
                [5-6]:regexp :after (できる 補助動詞)
                    ...
            [4-4]:regexp :after (できる 補助動詞)
                [5-7]<1pl> (9)
                [5-8]:sem-code :before 93
                    ...
    [2-2]:sem-code :here 41
        [3-3]:regexp :after (た 助動詞)
            [4-5]:regexp :before (を 格助詞)
                ...

\end{verbatim}
\end{boxit}
\renewcommand{\baselinestretch}{}\large\normalsize
\vspace{3mm}
\caption{決定木の例}
\label{表:決定木}
\end{center}
\end{figure}

表\ref{表:決定木}に，本問題に対して作成された決定木の例を示す
\footnote{図中において，説明のため決定木の各節点に[3-5]などのように識
別番号を付与した．また決定木の一部を...と表記して省略した．}．この決定
木では，木の根にあたる節点[1-1]で :sem-code :here 43 すなわち対象とす
る述語の意味属性(角川類語新辞典における分類番号上位2けた)が 43 かどう
かによって学習事例が分岐し，これを満たす場合は[2-1]へ，満たさない場合
は[2-2]へ進む．節点[6-2]は終端節点であり，解が <1pl> すなわち一人称複
数であり，学習事例は 5 であったことを示す．


表\ref{表:決定木}の各属性に見られるように，各属性は (属性の種類, 照合
位置, 属性値) の三つ組によって表現される\footnote{後述するように，属性
が言語外情報の場合は照合位置は必要ないが形式的に :here という照合位置
を与えている．}．以下の節では，属性の種類，照合位置について簡単に述べ
る．


\subsection{属性集合}
\label{節:属性}

本論文では論文\cite{主語補完}と同様に，以下の3種類の属性を用いた．


\begin{description}
\item[内容語の意味属性(:sem-code)]

省略の対象となる文において，どのような内容語が含まれているかに関する情
報．内容語は大きく，用言に関する情報と格要素(体言)に関する情報に分かれ
る．内容語の意味属性としては角川類語新辞典\cite{角川類語}における中分
類(100属性)を使用した．後述する照合位置が :here と :before の2種類ある
ため，属性数は 200である．

\item[機能語(:regexp)]

用言に後接する付属語群や終助詞，及び格助詞や接頭辞などの機能語の出現に
関する情報．前述の内容語と異なり，これらの機能語は当該品詞に属する単語
を直接参照した．属性数は 166である．

\item[言語外情報(:speaker)]

言語外情報としては，発話された文の話者情報を利用した．本論文で使用する
コーパスは話者が情報提供者か情報享受者の二者による対話を仮定している．
例えば，ホテルにおける対話では，情報提供者であるフロントと情報享受者の
客の二者による対話となる．話者によって主語省略の振る舞いが影響すると考
えたため使用した．属性数は 1である．

\end{description}

以上をまとめたものを表\ref{表:属性}に示す．全属性を用いて決定木を作成
した場合，属性数は 367 となる．


\begin{table}
\begin{center}
\caption{使用属性とその要素数}
\label{表:属性}
\vspace{3mm}
\begin{tabular}{llr}
\hline\hline
対象           & 属性       & 属性数 \\
\hline
内容語(用言)   & 意味属性   & 100 \\
内容語(格要素) & 意味属性   & 100 \\
\hline
機能語(格助詞)   & が，に，を    &   9 \\
機能語(接続助詞) & ので，たら    &  21 \\
機能語(助動詞群) & れる，ている  & 132 \\
機能語(その他)   & お，敬語動詞  &   4 \\
\hline
言語外情報     & 話者情報     &   1 \\
\hline
合計           &              & 367 \\
\hline
\end{tabular}
\end{center}
\end{table}


\subsection{属性の照合方法}

決定木学習時に行なう属性照合は，形態素列とのマッチングによって属性の照
合を行なう．すなわち，補完対象の用言を中心にして，表\ref{表:照合位置}
に示す5種類のうちどの位置に出現するかという情報をすべての属性に予め与
えておく．

\begin{table}
\begin{center}
\caption{属性の照合位置}
\label{表:照合位置}
\vspace{3mm}
\begin{tabular}{ll}
\hline\hline
記号    & 照合位置 \\
\hline
:before &  用言の前(直前を含む)に$\cdots$という形態素を含む． \\
:latest &  用言の直前に$\cdots$という形態素を含む． \\
:here &  その用言が$\cdots$である． \\
:next &  用言の直後に$\cdots$という形態素を含む． \\
:after &  用言の後(直後を含む)に$\cdots$という形態素を含む． \\
\hline
\end{tabular}
\end{center}
\end{table}

例えば，用言に関する属性は :here，格助詞に対しては :before，接頭辞に対
しては :latest の位置情報を与える．意味属性に関しては，ある位置にある
意味属性を持つ語が含まれているかどうかによって照合を行なう．


\subsection{SDTモデルの頑健性}

以上のSDTモデルの頑健性を考えた場合，以下の点において頑健性があると予
想される．すなわち，入力に対して，本来の入力にはない形態素列が誤って挿
入された場合における頑健性である．例えば，間投詞や言い淀みなど，音声言
語に頻出する冗長語が入力の途中に挿入された場合に，SDTモデルにおいては
全く悪影響を与えない．あるいは，音声認識の誤りにより内容語や機能語が挿
入された場合であっても，それが偶然に決定木で照合される語句である場合以
外は，補完結果が変化することはない．

以上の頑健性は，属性照合の際に，ある照合範囲における特定の語句の有無の
みを考慮しているために生じる．これにより，照合範囲に対象と無関係の語句
が挿入された場合にも影響はなく，また照合対象である語句が照合範囲に偶然
挿入される可能性は，一般には低い．ただし，以上は挿入誤りに対するある程
度の頑健性のみであり，欠落誤り，置換誤りに対しては影響が出る可能性が高
い．なぜなら，前述の照合方法は照合に不要な要素をいくら含んでも影響は少
ないが，照合に必要な要素が欠落した場合には対応できないからである．



\section{複数決定木モデル}

\subsection{頑健性を強化するための方策}

前節に示した省略補完モデルに対し，入力の不正確性に対して頑健なモデルに
するにはどうすればいいかを考える．既存のモデルがある場合，このモデルに
頑健性を持たせる手段として，本論文では複数の解答候補を用意し，そのうち
の一つを何らかの方法によって最終的に選択する，という方策を取る．複数の
解答候補を生成するには，解答に至るための情報源を別個にすればよい．すな
わち，同一のモデルを使用してそのモデルの入力となる情報源を変化させるこ
とによって，各モデルに独自の判断をさせることが可能になる．これはちょう
ど，ある事象に対して，同一の道具で観察する視点を変化させることに相当す
る．

ここで，以上の方策を取るためには以下の二つの問題を解決しなければならな
い．すなわち，
\vspace*{\baselineskip}

\begin{enumerate}
\item どのように別個の情報源を用意するか
\item 複数の解答候補からどのように最終解を選択するか
\end{enumerate}
\vspace*{\baselineskip}

\noindent
である．以上の問題点については，次節以降で述べる．


\subsection{複数決定木モデル}

本論文では入力の不正確性に対する頑健性を持った主語補完モデルを提案する．
このモデルは，我々が文献\cite{主語補完}で提案した格要素省略補完モデル 
SDT を拡張したものであり，複数決定木モデルまたは MDT (Multiple
Decision Tree)モデルと呼ぶ．
概要を図{}\ref{fig:mdt-model}に示す．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=model.prn,width=130mm}
    \end{epsf}
    \begin{draft}
    \atari(129,89)
    \end{draft}
\caption{SDTモデルとMDTモデルの比較}
\label{fig:mdt-model}
\end{center}
\end{figure}

MDT モデルは，複数の決定木を使用することによって頑健性を持たせたモデル
である．このモデルでは，決定木学習の際に使用する属性集合を変化させるこ
とによって決定木を作成し，複数の解答候補を得る．図
{}\ref{fig:mdt-model}に示すように，従来SDTでは単一の解$D_0$のみが得ら
れるため，この解の信頼性が低い場合にも代替解を得ることができなかった．
これに対し，本論文で提案するMDTモデルでは，複数の解，例えば($D_1$,
$D_2$, $\cdots$, $D_n$) の解を得ることでき，この中から最も信頼性の高い
解を選択することによって，MDTモデル全体としての頑健性が増す．ここで，
各決定木の学習は，全く同一の学習事例集合に対して行なう．

以下，どのように使用属性を変化させるかについては{}\ref{節:組合せ}節で，
複数の解候補の中からどのようにして最終解を選択するかについては，
{}\ref{節:選好}節で述べる．
\vspace{2\baselineskip}


\subsection{属性集合の組合せ}
\label{節:組合せ}

複数決定木モデルにおいては，各決定木の作成時に使用する属性を変化させる
必要がある．我々は文献\cite{主語補完}における実験で，属性の種類が減少
して同一種類の属性のみで決定木を作成した場合，補完精度の劣化が大きいこ
とを確認した．すなわち主語補完のためには，様々な属性を総合的に考慮して
補完する必要がある．このため表\ref{表:属性}で使用した3種類の属性をその
まま使用して各種類ごとに決定木を作成しても，(入力の不正確性とは関係な
く)補完精度の劣化が大きいことが容易に予想される．

そこで本論文では，これら属性集合を組み合わせることによって各決定木の属
性集合を構成することにした．本論文の使用する属性は前述したように3種類
であるので，図\ref{図:属性集合}に示すようにこれらの組合せによって3種類
の属性集合を作成した．これにより，使用属性数の減少による各決定木の補完
精度の劣化を抑えることができ，同時に複数解候補を作成することが可能にな
る．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=attribute.prn,width=130mm}
    \end{epsf}
    \begin{draft}
    \atari(129,89)
    \end{draft}
\vspace{-10mm}
\caption{3種類の属性集合の関係}
\label{図:属性集合}
\end{center}
\end{figure}


\subsection{補完候補の選好基準}
\label{節:選好}

前節に示すように複数の属性を用意して複数の解答候補が得られたとき，この
うちどれを最終的な解答とするかが第二の問題である．本節では，この問題に
ついて検討する．

複数の解から一つの解を選択する際には多数決基準などが一般的であるが，本
問題のように属性の組合せによって決定木を作成している場合に，多数決基準
を使用するのは適当ではない．なぜなら，仮に図\ref{図:属性集合}のような
状況で言語外情報が誤りを含んでいると仮定すると\footnote{前述したように，
実際には言語外情報が誤ることはないという仮定をおいている．}，3種類の決
定木すべてが誤った解を出力する可能性があるからである．このように一属性
が複数の解に影響するような組み合わせ方を行なった場合，解の多数決を取る
ことは適当ではないと考えた．そこで本論文では，各解答に対して信頼性を計
算し，それの比較によって行なう選好基準を提案する．この際，解の信頼性に
相当する値として，以下に述べる理由により，決定木学習時に解と同一の終端
節点に辿り着いた事例数を用い，これが最多である解を選択する．

いま，決定木のある属性において属性照合を誤ったと仮定する．この場合，本
来到達すべき終端節点には到達せずに別の節点に到達する．この際，どの節点
に到達したかは，これ以上の情報がない場合，一般にすべての節点が同一の確
率である．ここで，誤って到達した節点の学習時の事例数を予想すると，全節
点への到達可能性が同等なのだから，終端節点の学習事例数に関して最も頻出
する事例数が最も可能性が高い．例えば，学習事例数$i$の終端節点が最も多
い場合には，誤って到達した節点の学習時事例数は$i$の可能性が最も高いと
予想するのが自然である．

それでは実際にどのような事例数の終端節点が多いのかを調査したのが図
\ref{fig:freq}である．図\ref{fig:freq}では，次節で述べる3種類の決定木
それぞれについて，終端節点の事例数別に統計をとったものである\footnote
{学習時事例数14以上はほとんど頻度がないため省略した．}．この図から明ら
かなように，どの決定木においても，学習時の事例数が1の節点が最も多く，
その後漸減の傾向にある．すなわちこれらの決定木に関しては，学習時の事例
数が少ない節点ほど誤って辿り着く確率が高い．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=freq1.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\caption{学習時事例数と節点数の関係}
\label{fig:freq}
\end{center}
\end{figure}

次に，図\ref{fig:mdt-model}に示すように，同一の学習事例集合に対して属
性集合を($S_1$, $S_2$, $\cdots$, $S_n$) の$n$種類に変化させ，複数の決
定木を作成することを考える．図\ref{fig:mdt-model}において，属性集合
$S_1$による補完結果候補$D_1$よりも，属性集合$S_2$による補完結果候補
$D_2$のほうが解の信頼性が高いと考えるのは自然である．なぜならば，これ
までの議論により，属性照合を誤って解候補$D_2$に到達する可能性よりも属
性照合を誤って解候補$D_1$に到達する可能性のほうが高いからである．入力
に誤りがあるために本来の属性の照合ができなかった場合には，学習事例数の
より少ない節点に到達する確率がより高いため，例のように学習事例数の多い
節点に到達した場合には，確率的に解の信頼性が高いと見做すことができる．

以上の理由により，我々は決定木学習時の終端節点の事例数によって解の選好
を行なう．これにより，各決定木が出力した解答候補のうち，決定木が出力し
た終端節点の学習時事例数が最大の解答をMDTにおける解答とする．例えば図
\ref{fig:mdt-model}では属性集合$S_2$における解答の学習時終端節点事例数
が最も多いので，$D_2$を MDT としての解答とする．


\subsection{提案手法の頑健性}
\label{節:定性議論}

本手法の挙動を定性的に考察する．本論文の提案する手法によって入力に若干
の誤りがあり，誤り箇所を特定できない場合に対して本手法は有効に機能する
ことが予想できる．ただし選好基準から明らかなように，本手法は学習時にお
いて事例が集中した「大きな」節点に対してのみ有効に機能する．あるいはあ
る節点に極端に事例が集中するような場合に，本論文の選好がより有効に機能
する．

この一方，学習時に事例数が1であった節点は，属性に誤りがあった場合に本
手法では本来の正しい解を出力することが期待できない．すなわち，本手法は
すべての事例に対して頑健になるわけではないが，事例が集中した節点を対象
にしていることから多くの事例に対して頑健になることが予想できる．
以上の議論の定量的な検証は\ref{節:定量議論}節において行なう．




\section{主語補完実験}

本論文で提案したモデルの有効性を議論するため，主語補完実験を行なった．
実験は，実際の音声認識結果を入力とした実誤りに対する精度と，人工的に誤
りを作成した人工誤りに対する主語補完精度を評価した．本論文では6種類の
クラスによる補完精度の違いを議論するのが目的ではないため，以下の実験結
果ではクラス別の補完精度を示さず，全評価事例に対する平均を示す．

実験では，性能評価尺度としてF値(F-measure)を用いた．F値は，再現率
(recall)と適合率(precision)の調和平均であり，$R$を再現率，$P$を適合率
としたとき，以下の式で定義する．

\begin{equation}
F = \frac{(\beta^2 + 1) \times P \times R}{\beta^2 \times P + R}
\end{equation}
\vspace{3mm}

ここで，パラメータ$\beta$ は適合率の再現率に対する相対的な重要性である．
本論文では前述の理由によりこのパラメータを$\beta=1$として，再現率と適
合率の重要性を同等に扱う．



\subsection{音声認識結果に対する頑健性}

本稿で提案したモデルの有効性を確認するため，実際の音声認識結果を入力と
した実誤りに対する補完精度を測定した．また比較のため，音声認識誤りのな
い正解入力に対する補完精度も測定した．訓練事例数は1401事例，実験事例数
は訓練に含まれない303事例である．対象ドメインはホテルの予約もしくは解
約時の二者会話であり，ATR旅行会話コーパス\cite{Takezawa98}を使用した．

音声認識装置は日英音声翻訳システムATR-MATRIXにおける音声認識用音響・言
語モデル\cite{内藤}を使用した．実験では，認識装置の音響尤度と言語尤度
の相対的重みを変化させることによって3種類の異なる誤り傾向をもつ音声認
識結果を用いて行なった．各パラメータの音声認識精度を表\ref{表:認識器}
に示す．なお，表に示した 3種類のパラメータのうち，パラメータ P2 は使用
した音声認識器において最高性能を示すパラメータであり，P1 と P3 は局所
的に最大の音声認識性能を示すパラメータである．


\begin{table}
\begin{center}
\caption{音声認識結果の特徴}
\label{表:認識器}
\begin{tabular}{l|rrr}
\hline\hline
パラメータ      &  P1  &  P2 & P3 \\
\hline
発話数          &  968  &  968  &  968 \\
発話平均形態素  & 14.9  & 14.9  & 14.9 \\
単語認識率(\%)  & 78.48 & 78.89 & 72.09 \\
\hline
発話平均誤り     & 3.44 & 3.49 & 4.09 \\
(挿入誤り) & 0.56 & 0.51 & 0.64 \\
(欠落誤り) & 0.76 & 0.84 & 0.88 \\
(置換誤り) & 2.12 & 2.14 & 2.57 \\
\hline
\end{tabular}
\end{center}
\end{table}


実験は，音声認識誤りのない正解入力と，その同一の文集合の音声認識結果の
2種類について行なった．実験文数は448文である．表\ref{表:実誤り}に，実
誤りに対する性能を示す．実験の結果，用意したパラメータのいずれにおいて
も MDT が最高性能を示した．また，誤りのない入力に対しても，MDTは最も高
い主語補完性能を示した．

実験は，単独の決定木を使用して補完を行なう SDT モデルによる実験と，本
稿の提案する MDT モデルの両者について行なった． SDT モデルにおける属性
集合は，図\ref{図:属性集合}における集合 A，集合 F，集合 C の三種類に対
して行なった．以下では，これをそれぞれ，SDT/A，SDT/F，SDT/C と表記する．
また，MDT モデルは，上記の属性集合 A，C，F の三つから SDT を構成した．


\begin{table}
\begin{center}
\caption{実認識に対する主語補完性能}
\label{表:実誤り}
\begin{tabular}{c|ccc|c}
\hline\hline
パラメータ &  P1  & P2  & P3 & 正解入力 \\
認識精度   & 78.48 & 78.89 & 72.09 & 100 \\
\hline
SDT/A & 77.2 & 76.5 & 76.2 & 81.8 \\
SDT/C & 73.9 & 74.9 & 73.2 & 80.8 \\
SDT/F & 75.5 & 74.2 & 72.2 & 79.5 \\
\hline
 MDT  & 78.2 & 78.8 & 77.5 & 83.5 \\
\hline
\end{tabular}
\end{center}
\end{table}



\subsection{人工誤りに対する実験}

次に，モデルの頑健性と誤りの傾向との関連を議論するために，以下のような
人工誤りに対してモデルがどのような特性を示すのかを実験した．
実験は，以下の4種類の誤りについて行なった．

\begin{itemize}
\item 挿入誤り
\item 欠落誤り
\item 置換誤り
\item (挿入，欠落，置換の)混合誤り
\end{itemize}


\subsubsection{挿入誤り}

挿入誤りは以下のように作成した．まず，誤りのない形態素列に対して，誤り
を挿入する位置を無作為に一ヶ所決定する．この位置に対し，決定木学習を行
なった訓練会話の形態素集合から任意の一語を無作為に選択し，この語を挿入
する．挿入される語は，訓練会話の各形態素の出現割合と同一の期待値で決定
されるため，格助詞などの高頻出語が挿入される可能性が高くなる．以上が一
語を挿入する過程であり，$N$語を挿入する場合には以上の過程を$N$回繰り返
す．

挿入誤りの個数と性能との関係を図\ref{fig:insert}に示す．図より，MDTモ
デルは挿入誤りに対してほとんど性能劣化のないことが明らかになった．また
三種のSDTモデルに関しても，若干の精度低下はあるものの誤り語数増加に伴
う程度低下割合はゆるやかである．SDTモデルが挿入誤りに対してあまり性能
が落ちないのは，\ref{節:SDTの頑健性}節で議論した要素照合手法が頑健性を
持っていたことを示し，挿入誤りに関してはSDTモデルにもある程度の頑健性
を持っていることが確認された．また，MDTモデルにほとんど性能劣化がない
のは，上記SDTが持つ頑健性に加え，意思決定を複数行なった後に選択する本
手法が有効に機能しているためと考えられる．


\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=insert.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{挿入誤りに対する補完性能}
\label{fig:insert}
\end{center}
\end{figure}


\subsubsection{欠落誤り}

欠落誤りは以下のように作成した．誤りのない形態素を入力として，欠落させ
る形態素を無作為に選択する．ただし，省略された主語に対する動詞もしくは
サ変名詞は選択の対象からはずす．なぜなら，もし当該動詞もしくはサ変名詞
が欠落された形態素が音声認識結果となった場合には，省略の検出が不可能と
なり，補完の対象とはならないからである．このため，省略の検出を処理の対
象外とする本論文の立場では，このような欠落誤りを考慮対象から除外するこ
とは妥当である．

欠落誤りの個数と性能との関係を図\ref{fig:delete}に示す．欠落誤りは補完
に必要な情報の一部が欠ける誤りであるため，手がかりが欠如し，挿入誤りよ
りも性能の劣化をもたらす．図からわかるように，MDTモデルは三種類のSDTの
うち最も高精度である SDT/C よりも常に高精度である．

なお，図においては SDT/C モデルがほとんど性能劣化がないが，これは欠落
誤りの対象に述語が含まれていないためである．SDT/C モデルではこの情報を
主要な情報として主語を決定しているため，述語以外の形態素の欠落に対して
はあまり性能劣化を起こさない．これに対し，SDT/C モデルの精度が相対的に
優れているという情報を MDT は何ら持たないにもかかわらず MDT が SDT/C 
の出力する解を比較的多く採用している点から，本論文で提案した選好の有効
性を確認することができる．


\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=delete.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{欠落誤りに対する補完性能}
\label{fig:delete}
\end{center}
\end{figure}


\subsubsection{置換誤り}

置換誤りは以下のように作成した．誤りのない形態素を入力として，欠落させ
る形態素を無作為に選択する．ただし，省略された主語に対する動詞もしくは
サ変名詞は欠落誤りと同様の理由で，欠落の対象からはずす．この後，この欠
落の位置に，挿入誤りと同様，決定木学習を行なった訓練会話の形態素集合か
ら任意の一語を無作為に選択し，この語を挿入する．以上が一語を挿入する過
程であり，$N$語を挿入する場合には以上の過程を$N$回繰り返す．

置換誤りの個数と性能との関係を図\ref{fig:substitute}に示す．置換誤りに
対する性能は，欠落誤りと類似の傾向を示した．これは，本実験での置換作成
過程が(欠落＋挿入)であり，前述のように挿入誤りに対しては各モデルともか
なり頑健であるためであると考えられる．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=substitute.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{置換誤りに対する補完性能}
\label{fig:substitute}
\end{center}
\end{figure}


\subsubsection{混合誤り}

混合誤りは以下のように作成した．正解入力に対して，まず誤りの種類を決定
する．誤りは，挿入，欠落，置換の三種類が同じ確率で出現するように，無作
為に決定する．誤り種類が決定した後は，前述した挿入，欠落，置換誤りの処
理を行なう．複数形態素の誤りの場合は，以上の処理を複数回繰り返し，その
都度誤り種類を無作為に選択する．混合誤りの個数と性能との関係を図
{}\ref{fig:mix}に示す．図から，混合誤りに対してもMDTモデルの優位性を見
ることができる．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=mix.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{混合誤りに対する補完性能}
\label{fig:mix}
\end{center}
\end{figure}



\subsection{考察}
\label{節:考察}

まず，入力誤りに対する頑健性を議論する．図\ref{fig:insert}〜図
\ref{fig:mix}より，本論文で提案するMDTモデルが比較手法(SDT)よりも頑健
であることがわかる．特に，MDTモデルは挿入誤りに対して非常に頑健であり，
10個に満たない形態素の挿入に対してはほとんど補完性能の劣化がないことが
確認された．また表\ref{表:実誤り}より，実際の音声認識の結果，誤りを含
んだ入力に対しても，SDTに比較して優位であることを確認した．

MDTの精度は常にどのようなSDTよりも高精度であることから，MDTで採用した
選好基準は，ある一定の条件下で最尤のSDTの出力を解とする性質を持ってい
る可能性がある．もしこの仮説が正しければ，より高精度のSDTモデルを用意
することでMDTとしての精度も向上することが期待できる．本研究では3種類の
属性集合を用意したが，これは3種類である必要はなく，むしろ高性能である
と予想されるSDTをできるだけ多く用意することで，MDT全体としてより頑健性
が増すことが期待できる．どのような SDT をどの程度用意すればよいのかに
ついては，次節のシミュレーションで議論する．


次に，入力の誤り傾向との関係を議論する．表\ref{table:recogerror}に，音
声認識実験で誤った語の品詞別挿入誤りと欠落誤り数をパラメータ別に示した．
この表と表\ref{表:実誤り}の比較から，内容語による SDT/C は普通名詞や本
動詞の欠落の最も少なかったパラメータ P2 が，機能語による SDT/F は格助
詞の欠落が最も少なかったパラメータ P1 が最も高い精度を示したと説明でき
る．

表\ref{表:認識器}から，3種類の SDT の中で最も良好な SDT/A は P2 よりも 
P1 のほうが補完精度が高いが，MDT の補完精度は P2 が P1 を上回っている．
これは，MDT が必ずしも SDT/A の解を選好しているわけではないことを示し
ている．たとえ音声認識精度が十分でなくても，ある特定の音声認識の誤りに
あまり影響されない SDT を用意することができれば，それによって正解に至
る解答候補を得ることができ，かつ正しく選好できる可能性が高い．


\begin{table}
\begin{center}
\caption{各パラメータにおける誤り傾向}
\label{table:recogerror}
\begin{tabular}{c|rr|rr|rr}
\hline\hline
パラメータ & \multicolumn{2}{c|}{P1} 
           & \multicolumn{2}{c|}{P2} 
           & \multicolumn{2}{c}{P3} \\
誤り種類   & 挿入 & 欠落 & 挿入 & 欠落 & 挿入 & 欠落 \\
\hline
普通名詞   &  336 &  277 &  270 &  254 &  335 &  302 \\
本動詞     &  130 &   99 &  128 &  107 &  138 &  119 \\
数詞       &   55 &  115 &   47 &  108 &   78 &  101 \\
\hline
格助詞     &  102 &   76 &  104 &   85 &  123 &  101 \\
助動詞     &   71 &   63 &   68 &   60 &   65 &   73 \\
接頭辞     &   46 &   37 &   44 &   37 &   46 &   36 \\
\hline
\end{tabular}
\end{center}
\end{table}


\section{シミュレーション}

前節の評価実験で，誤りを含む入力に対して\ref{節:属性}節の属性集合から
なるMDTモデルが主語補完問題に対し有効に機能することを確認した．しかし，
以上の結果はいかなる問題に対してもMDTモデルが有効なのか，あるいは本論
文における属性集合の組み合わせ方が偶然有効に機能したのかは明確でない．
そこで，MDTモデルの問題依存性，並びに属性集合の組み合わせ方がモデルの
精度にどのような影響を与えるのか，の2点を検証，議論するため，人工的な
問題を設定してMDTモデルのシミュレーションを行なった\cite{ICSLP2000}．
本節ではこの内容及び結果について述べる．


\subsection{問題設定とMDTの設定}

問題は以下のように設定した．まず，問題の全属性数は10，分類すべきクラス
数は10とした．属性値は二値としたため作成される決定木は二分木であり，枝
刈りは行なわない．学習事例は，以下の2種類の方法で順に作成した．

\begin{description}
\item[重複事例集合($S_D$)]
まず1事例を無作為に作成する．ただし既作成の事例と矛盾しないようにする．
すなわち各属性の値はすべて同一であるがクラスが異なる事例は新規事例に追
加しない．この事例と属性値及びクラスが全く同一のコピー事例を(1〜100)事
例の範囲で作成する．(1〜100)のうちいくつ重複させるかは無作為に決定する．
以上の処理を，$S_D$ 全体で1000事例を越えるまで繰り返す．

\item[単独事例集合($S_S$)]
無作為に1事例を作成する．ただし，作成される事例は $S_D$ と $S_S$ 内の
どの事例とも矛盾しない．以上の処理を1000回繰り返す．
\end{description}

以上のような方法で，本シミュレーションでは $S_D$ が 1084事例，$S_S$ が 
1000事例の合計($S$) 2084 事例を作成した．各決定木は，事例集合 $S$ を用
いて作成する．

次に，使用したMDTについて述べる．MDT は以下のように SDT を組み合わせて
構成した．すなわち，使用属性数が$i$以上の全属性組み合わせについてSDTを
すべて作成し，これを組み合わることで構成した．以下ではこれを MDT($i$)
と記述する．例えば，MDT(9) は9属性の全組み合わせ(10種類)と10属性の全組
み合わせ(1種類)に対してそれぞれ作成した11個の SDT を組み合わせたモデル
である．同様に MDT(8)は 56個，MDT(7)は 176個の SDT からなり，最多の
MDT(1)は 1023 個の SDT から構成される．

実験は以下のように行なった．学習時に使用した事例集合 $S$ に対し，各事
例について1ヶ所(後述の\ref{節:誤り数との関係}節では2または3ヶ所，
{}\ref{節:正解入力}節では0ヶ所)の属性を無作為に選び，その属性値に誤り
を起こさせたものを入力とした．すなわち，今回作成する二分木は属性が2値
であるため，無作為に選ばれた属性の属性値を反転させたものを入力とした．
実験は，10属性以下で構成される全組み合わせの SDT (1023個)に対して精度
を測定し，これをもとに 10種類の MDT($i$) ($i=1〜10$)の精度を計算した．
また比較対象として，多数決基準，すなわち$i$属性以上のすべての SDT が返
す解のうち最多のものを解とする選考基準での精度も測定した．


\subsection{シミュレーション結果}

ある乱数におけるシミュレーションの結果を図\ref{図:1誤り}に示す．異なる
乱数でシミュレーションを行なった場合も全く同様の傾向が見られた．図で，
実線はMDT，点線は多数決基準の精度を示し，SDT単独の精度は点で表した．任
意の1属性に誤りがある入力に対し，使用可能な全10属性からなる SDT は 
10.4\%，9属性以上のSDTによる多数決基準は 16.0\% の正解率であるのに対し，
MDT(9)は 57.6\% の正解率を得ることができ，MDTの優位性を確認した．また 
MDT(9) は9属性以上で可能な全組み合わせに対して作成した SDT を用いてい
ることより，どうやって不要な属性を減らすか，あるいはどのような組み合わ
せが適当かを考慮する必要がないため，MDTモデルはこの点において，SDT モ
デルで使用属性を吟味して精度向上を目指すアプローチよりも優位である．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=one.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{シミュレーション結果(誤り数: 1)}
\label{図:1誤り}
\end{center}
\end{figure}

ただし，図が示す通り，MDTモデルは少数属性の SDT を追加していくに従い精
度が低下する．逆に多数決基準は精度が向上し7属性以下の決定木を使用した
場合には両者の精度が逆転した．このことから，MDTはどのような属性数の決
定木を加えても精度向上するわけではないことがわかる．最高の精度は 5属性
以上による多数決基準によって得られた(58.7\%)が，現実的には少数属性の決
定木を大量に作成して多数決を取ることは計算量の面で有利ではない
\footnote{理論上，MDT(9)に対して 5属性以上の多数決基準は58倍
  ($=638/11$)，全属性の多数決基準は 93倍($=1023/11$)の処理時間と記憶容
  量が必要である．}ため，1誤りの場合はMDT(9) が最も実用的なモデルであ
ると言える．

図において各 SDT がどのような精度であるかを観察すると，属性数が減少す
るに伴い，平均的に徐々に精度は向上している．一方，MDT($i$) が選択する 
SDT を観察すると，SDT の中で最少属性のもののうちから選択されている場合
が圧倒的に多い．例えば，MDT(6) は 6属性の SDT のうちの一つの解を選択し
ている場合が圧倒的に多い．一般的に，終端節点の学習事例数は，多数属性で
作成した決定木のそれよりも少数属性のほうが平均的に多いためこのように少
数属性の SDT が選択されやすくなるのであろうが，相対的に精度の高い少数
属性の SDT を選択しても MDT の精度が低下する理由は不明である．これは今
後の課題としたい．


\subsection{事例集合との関係}
\label{節:定量議論}

\ref{節:定性議論}節で議論したように，MDTモデルは事例が集中した節点を得
るのに用いた属性に誤りがある場合に有効に機能すると予想される．ここでは
これを検証する．

本シミュレーションでは，終端節点に集中する事例 $S_D$ とそれ以外の事例 
$S_S$ の2種類の方法で事例集合 $S$ を作成した．事例集合 $S$ に誤りを含
めた場合に，図\ref{図:1誤り}に示すようにMDT(9)は全体で 57.6\% の精度が
得られたが，これを事例集合別に分類して集計すると，$S_D$ は 96.5\%，
$S_S$ は 15.5\% の精度であり，極端に精度が異なる．この結果は，頻出する
現象に対しては入力に誤りがあってもかなり高い精度で正解を得ることができ
るのに対し，稀に出現する現象は正解を得ることが期待できないことを示し，
\ref{節:定性議論}節で行なった議論が正しいことを確認した．

以上の結果から本手法が有効に機能する状況が推測できる．すなわち，決定木
において一部の終端節点に事例が集中するような構造を持つ場合ほど，MDT は
誤りを含む入力に対して頑健であることが予想される．



\subsection{誤り数との関係}
\label{節:誤り数との関係}

図\ref{図:1誤り}において MDT(9)の精度が最も高いのは，各事例に対して1個
の属性値に誤りを起こしているためである可能性がある．ではもし誤りが1で
はなく，2もしくは3である場合，MDTはどのような傾向を示すであろうか．こ
れを示したのが図\ref{図:2誤り}(2誤りの場合)および図\ref{図:3誤り} (3誤
りの場合)である．このシミュレーションにおいては，誤り数以外の条件は全
く同じであり，誤りを含める対象の事例集合$S$も，図\ref{図:1誤り}と全く
同一のものを使用した．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=two.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{シミュレーション結果(誤り数: 2)}
\label{図:2誤り}
\end{center}

\begin{center}
    \begin{epsf}
\epsfile{file=three.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{シミュレーション結果(誤り数: 3)}
\label{図:3誤り}
\end{center}
\end{figure}

図が示すように，各属性に無作為に2誤りを与えた場合は MDT(8)が，3誤りの
場合は MDT(7) が最も高い精度を示していることがわかる．すなわち，誤りの
数と用意する SDT との間には相関関係がありそうである．すなわち，図\ref
{図:1誤り}，図\ref{図:2誤り}，図\ref{図:3誤り}から類推すると，属性数が
$N$で誤りが高々$i$ならば属性数が ($N-i$) 以上のすべての SDT で MDT を
構成するのが最善であろう．


\subsection{正解入力での特性}
\label{節:正解入力}

最後に，誤りがない場合に MDT がどのような挙動を示すのかを検証する．図
\ref{図:正解入力}に，事例集合$S$に誤りを与えずに各モデルに入力した場合，
すなわち学習事例と入力が全く同一の場合のテスト(closed test)を行なった
結果を示す．

\begin{figure}
\begin{center}
    \begin{epsf}
\epsfile{file=closed.eps,scale=0.6}
    \end{epsf}
    \begin{draft}
    \atari(76,53)
    \end{draft}
\vspace{1mm}
\caption{正解入力での特性}
\label{図:正解入力}
\end{center}
\end{figure}

この図から明らかなように，一般に属性数の減少に伴い精度は低下していくが，
本提案モデルの精度の低下が最も激しい．ただし，正解入力は誤り0の入力で
あるので，これを前節で議論した誤り数と使用属性数の関係にあてはめると，
全属性数で決定木を作成するのが最も適切であろうという予想が得られ，シミュ
レーション結果と一致する．本シミュレーションでは矛盾のないように属性を
作成しているので，このような状況においては全属性による決定木が一つあれ
ば十分で，入力に誤りのない場合は複数決定木モデルを使用する必要がない．
ただし，主語補完問題のようにこのような状況が成立しない場合には，実験結
果が示すように誤りが0であっても複数決定木モデルが有効に機能する可能性
がある．これがどのような場合に有効なのかはシミュレーションでも究明する
ことができなかった．今後の課題としたい．



\section{結論と今後の課題}

音声言語処理では，従来の自然言語処理ではほとんど問題にならなかった入力
の不正確性が生じる．これに対し，入力の誤り訂正技術への努力だけでは不十
分であり，入力に誤りが含まれていることを前提とした問題解決モデルの構築
が，これからの音声言語処理において重要である．

本論文では，対話に頻出する主語省略の補完問題を取り上げ，複数の決定木を
用いたモデル(MDT モデル)による問題解決手法を提案した．また同時に，複数
の補完候補からの選好基準として，学習時の終端節点事例数を使用することを
提案した．実験では，音声認識結果に対して正解テキスト入力と比べて数\%程
度の性能低下で抑えられ，特に挿入誤りに対して頑健であることを示した．ま
た，問題依存性および属性組み合わせに関する議論を行なうため人工的な問題
を設定したシミュレーションを行なった．この結果，本モデルは問題非依存の
モデルであり，主語補完にのみ有効に機能するわけではないことを示した．

本論文で行なった主語補完実験とシミュレーションにより，MDT モデルの特性
が明らかになった．これをまとめると，MDTモデルは以下の状況が満たされた
場合においてより有効に機能する．

\begin{enumerate}
\item 決定木内に学習事例が集中する節点が多く存在する問題(\ref{節:定量議論}節)
\item (全属性数−誤り数)以上の属性から構成される決定木の全組み合わせを
  モデルの構成要素とした場合(\ref{節:誤り数との関係}節)
\item 入力に若干の誤りのある場合(\ref{節:正解入力}節)
\end{enumerate}


複数決定木モデルは，特に入力列の挿入誤りに対して頑健であると結論づける
ことができるが，欠落，置換誤りに関しては相対的に脆弱である．これらの誤
りによる性能劣化は情報の欠落が原因であるのでやむを得ない面もあるが，今
後の課題として情報欠落に伴う精度劣化を最小限に抑えることを目指す．また，
主語補完実験においては無誤りでも MDT のほうが高性能であったが，これが
どのような状況であったためかは明確でなく，実験においても結論を出すに至
らなかった．今後はこの点に関しても検証してみたい．


\section*{謝辞}
本研究で，シソーラスに使用した「角川類語新辞典」\cite{角川類語}を機械
可読辞書の形で提供いただき，その使用許可をいただいた(株)角川書店に深謝
する．


\bibliographystyle{jnlpbbl}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Aone \BBA\ Bennett}{Aone \BBA\ Bennett}{1995}]{Aone}
Aone, C.\BBACOMMA\  \BBA\ Bennett, S.~W. \BBOP 1995\BBCP.
\newblock \BBOQ Evaluating Automated and Manual Acquisition of Anaphora
  Resolution Strategies\BBCQ\
\newblock In {\Bem Proc. of 33rd Annual Meeting of the ACL}, \BPGS\ 122--129.

\bibitem[\protect\BCAY{Dohsaka}{Dohsaka}{1990}]{Dohsaka}
Dohsaka, K. \BBOP 1990\BBCP.
\newblock \BBOQ Identifying the Referents of Zero-Pronouns in Japanese based on
  Pragmatic Constraint Interpretation\BBCQ\
\newblock In {\Bem Proc. of European Conference on Artificial Intelligence
  (ECAI)}.

\bibitem[\protect\BCAY{江原, 金}{江原, 金}{1996}]{江原}
江原暉将, 金淵培 \BBOP 1996\BBCP.
\newblock \JBOQ 確率モデルによるゼロ主語の補完\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 3}  (4), 67--86.

\bibitem[\protect\BCAY{河原, 松本}{河原, 松本}{1995}]{河原}
河原達也, 松本裕治 \BBOP 1995\BBCP.
\newblock \JBOQ 音声言語処理における頑健性\JBCQ\
\newblock \Jem{情報処理}, {\Bbf 36}  (11), 1027--1032.

\bibitem[\protect\BCAY{丸山}{丸山}{1996}]{丸山}
丸山直子 \BBOP 1996\BBCP.
\newblock \JBOQ 話しことばの諸相\JBCQ\
\newblock \Jem{第2回年次大会チュートリアル資料}, \BPGS\ 41--58. 言語処理学会.

\bibitem[\protect\BCAY{村田, 長尾}{村田, 長尾}{1997}]{村田}
村田真樹, 長尾眞 \BBOP 1997\BBCP.
\newblock \JBOQ 用例や表層表現を用いた日本語文章中の指示詞・代名詞・
  ゼロ代名詞の指示対象の推定\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 4}  (1), 87--109.

\bibitem[\protect\BCAY{内藤, 政瀧, Harald, 塚田, 匂坂}{内藤\Jetal
  }{1998}]{内藤}
内藤正樹, 政瀧浩和, HaraldSinger, 塚田元, 匂坂芳典 \BBOP 1998\BBCP.
\newblock \JBOQ 日英音声翻訳システムATR-MATRIXにおける音声認識用音響・
  言語モデル\JBCQ\
\newblock \Jem{春期講演論文集}, \BPGS\ 2--Q--20. 日本音響学会.

\bibitem[\protect\BCAY{Nakaiwa \BBA\ Shirai}{Nakaiwa \BBA\
  Shirai}{1996}]{Nakaiwa}
Nakaiwa, H.\BBACOMMA\  \BBA\ Shirai, S. \BBOP 1996\BBCP.
\newblock \BBOQ Anaphora Resolution of Japanese Zero Pronouns with Deictic
  Reference\BBCQ\
\newblock In {\Bem Proc. of COLING-96}, \BPGS\ 812--817.

\bibitem[\protect\BCAY{大野, 浜西}{大野, 浜西}{1981}]{角川類語}
大野晋, 浜西正人 \BBOP 1981\BBCP.
\newblock \Jem{角川類語新辞典}.
\newblock 角川書店.

\bibitem[\protect\BCAY{Quinlan}{Quinlan}{1993}]{Quinlan}
Quinlan, J.~R. \BBOP 1993\BBCP.
\newblock {\Bem C4.5: Programs for Machine Learning}.
\newblock Morgan Kaufmann.

\bibitem[\protect\BCAY{Takezawa, Morimoto, \BBA\ Sagisaka}{Takezawa
  et~al.}{1998}]{Takezawa98}
Takezawa, T., Morimoto, T., \BBA\ Sagisaka, Y. \BBOP 1998\BBCP.
\newblock \BBOQ Speech and Language Database for Speech Translation Research in
  {ATR}\BBCQ\
\newblock In {\Bem Proc. of 1st International Workshop on East-Asian Language
  Resources and Evaluation -- Oriental COCOSDA Workshop}, \BPGS\ 148--155.

\bibitem[\protect\BCAY{田中}{田中}{1996}]{田中穂積}
田中穂積 \BBOP 1996\BBCP.
\newblock \JBOQ 音声対話表現における多様性\JBCQ\
\newblock \Jem{人工知能学会全国大会(第10回)論文集}, \BPGS\ 47--50.

\bibitem[\protect\BCAY{脇田, 河井, 飯田}{脇田\Jetal }{1998}]{脇田}
脇田由実, 河井淳, 飯田仁 \BBOP 1998\BBCP.
\newblock \JBOQ 意味的類似性を用いた音声認識正解部分の特定法と正解部
  分のみ翻訳する音声翻訳手法\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 5}  (4), 111--125.

\bibitem[\protect\BCAY{山本, 隅田}{山本, 隅田}{1999}]{主語補完}
山本和英, 隅田英一郎 \BBOP 1999\BBCP.
\newblock \JBOQ 決定木学習による日本語対話文の格要素省略補完\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 6}  (1), 3--28.

\bibitem[\protect\BCAY{Yamamoto \BBA\ Sumita}{Yamamoto \BBA\
  Sumita}{1999}]{NLPRS99}
Yamamoto, K.\BBACOMMA\  \BBA\ Sumita, E. \BBOP 1999\BBCP.
\newblock \BBOQ Multiple Decision-Tree Strategy for Error-Tolerant Ellipsis
  Resolution\BBCQ\
\newblock In {\Bem Proc. of Natural Language Processing Pacific-Rim Symposium
  (NLPRS'99)}, \BPGS\ 292--297.

\bibitem[\protect\BCAY{Yamamoto \BBA\ Sumita}{Yamamoto \BBA\
  Sumita}{2000}]{ICSLP2000}
Yamamoto, K.\BBACOMMA\  \BBA\ Sumita, E. \BBOP 2000\BBCP.
\newblock \BBOQ Multiple Decision-Tree Strategy for Input-Error Robustness: A
  Simulation of Tree Combinations\BBCQ\
\newblock In {\Bem Proc. of 6th International Conference on Spoken Language
  Processing(ICSLP 2000)}.

\end{thebibliography}



\begin{biography}
\biotitle{略歴}
\bioauthor{山本 和英}{
1996年豊橋技術科学大学大学院博士後期課程システム情報工学専攻修了．
博士(工学)．
1996年〜2000年ATR音声翻訳通信研究所客員研究員，
2000年〜ATR音声言語通信研究所客員研究員，現在に至る．
1998年中国科学院自動化研究所国外訪問学者．
要約処理，機械翻訳，韓国語及び中国語処理の研究に従事．
1995年 NLPRS'95 Best Paper Awards．
言語処理学会，情報処理学会，ACL各会員．
{\tt E-mail: yamamoto@slt.atr.co.jp}
}

\bioauthor{隅田 英一郎}{
1982年電気通信大学大学院計算機科学専攻修士課程修了．
ATR音声言語通信研究所主任研究員．
博士(工学)．
自然言語処理，並列処理，機械翻訳，情報検索の研究に従事．
言語処理学会，情報処理学会，電子情報通信学会各会員．
{\tt E-mail: sumita@slt.atr.co.jp}
}


\bioreceived{受付}
\biorevised{再受付}

\end{biography}



\end{document}
