\documentstyle[a4j,12pt,twoside,epsf]{jarticle}
\setlength{\oddsidemargin}{20pt}
\setlength{\evensidemargin}{20pt}
\setlength{\textwidth}{140mm}
\setlength{\topmargin}{20pt}
\setlength{\textheight}{220mm}
\setlength{\columnsep}{8mm}
\pagestyle{plain} 
\begin {document}
\baselineskip 7mm
\noindent
論文\\
Technical Paper\\
決定木による日本語長文の短文分割\\
The Application of Decision Trees to  Segmentation of Long
Japanese Sentences \\
張玉潔${}^{*1}$\\
Yujie ZHANG${}^{*1}$\\
尾関和彦${}^{*2}$\\
Kazuhiko OZEKI${}^{*2}$\\
${}^{*}$1\ 〒 182-8585  東京都調布市調布ヶ丘1-5-1,\ 電気通信大学  情報
通信工学
科\\
${}^{*}$1\ Department of Computer Science and Information
Mathematics,\\ 
\hspace*{4mm} The University of Electro-Communications,\\
\hspace*{4mm} 1-5-1 Chofugaoka,\ Chofu,\ Tokyo,\ 182-8585 \
Japan\\
${}^{*}$2\ 〒 182-8585  東京都調布市調布ヶ丘1-5-1,電気通信大学  情報通信工学科
\\
${}^{*}$2\ Department of Computer Science and Information
Mathematics,\\
\hspace*{4mm} The University of Electro-Communications,\\
\hspace*{4mm} 1-5-1 Chofugaoka,\ Chofu,\ Tokyo,\ 182-8585 \
Japan\\
{\sf キーワード}\\
\hspace*{4mm}決定木, 機械学習, 言語知識, コーパス, 長文分割\\
{\sf Keywords}\\
\hspace*{4mm}decision tree,\ machine learning,\
linguistic knowledge,\ corpus,\\
\hspace*{3mm} segmentation of long sentences
\newpage
\noindent
Summary\\
It is well known that direct parsing of
a long Japanese sentence, including many conjunctive clauses,
is extremely difficult.
Therefore, it is preferable to segment such a sentence into
 shorter, simpler ones prior to parsing.
 Some methods for sentence segmentation have been reported
 so far. However,  
because those conventional methods are based on handmade segmentation
 patterns or rules, they have problems in keeping consistency of
 the patterns, and
in deciding the optimal order of applying those rules.
This paper proposes a new method of sentence segmentation
 using a decision tree,  which acquires optimal segmentation
 patterns and the optimal order of their application
automatically from a corpus,
taking both linguistic phenomena and their occurrence
 frequencies into account. 
Generation and evaluation of a decision tree for sentence
segmentation were conducted on
an EDR corpus. For 400 evaluation sentences, precision and recall
were both 84\%, and the percentage of correctly segmented sentences
was 77\%.
It was also confirmed that pruning  reduces the
tree size significantly without deteriorating the performance.

\newpage
\noindent
内容の概要\\
多数の接続節を含む日本語長文をそのまま係り受け解析することは大変困難である
ことが知られている．そのため，係り受け解析の補助手段として，文をより単純で
短い文に分割することが研究されている．従来の方法は，
分割パターンや分割規則を人手で作成しなければならないという問題がある．
本論文では，決定木を用いて，分割点を推定するためのパターンを
コーパスから自動的に獲得する方法を提案する．この方法に
よれば，学習データ中に現われる言語現象とその出現頻度に応じて，最適分割
パターンとその適用順序が自動的に決定される．
EDRコーパスを用いて，分割パターンの自動抽出と，それを用いた分割点推定の実験を行なった．
400文の評価データに対し，84\%の適合率と再現率，また77\%の文正解率
が得られた．さらに，決定木を生成する過程で枝苅りを行うことにより，
決定木の分割精度を保ちながら，その節点数を大きく削減できることが確かめ
られた．
\newpage
\section{まえがき}
日本語文章には，しばしば非常に長い文が現れる．長文は多数の接続節を含むため
係り受け構造の曖昧さが膨大に増加し，そのまま係り受け解析する
ことは困難になる．
そのため，係り受け解析の補助手段として，長文を短文に分割することが試みられ，そ
の有効性が示されている(金，江原\ 1994)．
また，長文は人にとっても理解しにくい悪文であることが多いため，
推敲支援の観点からも短文分割の研究がなされている(武石，林 \ 1992)．
このような従来の手法の要点は，次のようにまとめることができる．
\begin{itemize}
\item 形態素解析により得られる品詞や表記情報を用いて，分割点を推定するための
分割パターンを表現する．そして，入力文と分割パターンとのマッチングにより，
分割点を推定する(金，江原\ 1994)．
\item 接続節の間の包含関係(南\ 1974)により述語間の係り受け構造の候補を挙げ，さらに
述語間の係り易さを表すヒューリスティックなスコアを用いて，それらに順
位を付ける．そして，順位の高い構造を選ぶことにより，分割点を推定する
(武石，林\ 1992)．
\end{itemize}
これらの手法は，それぞれに有効であることが報告されているが，分割パターンや
述語間の係り易さを表すスコアなどを人手で作成・設定しなければならないという
問題がある．
言語現象には人の直感では把握しにくい規則性も含まれているので，
このような手法がデータに含まれる情報を十分に利用し切っているかどうかは疑問である．また，
これらの分割パターンやスコアは対象領域に依存する可能性があり，それが
変わると作成し直さなければならない恐れもある．

本論文では，形態素解析から得られる表層情報に基づき，決定木
(Breiman, Friedman, Olshen and Stone\ 1984;\ Kuhn\ and De Mori\ 1995;\ Zhang and Ozeki\ 1998)の手法を
用いて，分割パターンをコーパスから自動的に獲得する方法(張，尾関\ 1998)を
提案する．この方法によれば，学習データ中に現われる言語現象とその出現頻度に応じて，最適分割パターンとその適用順序が自動的に決定される．

以下では，まず{\bf 2}節で
この研究に用いた決定木について簡単に説明する.
次に{\bf 3}節で決定木を短文分割問題に応
用する方法について述べる．続いて{\bf 4}節ではEDRコーパスを用いた短文分割
パターンの獲得と短文分割点推定の実験結果を記述する．
さらに，{\bf 5}節で分割精度の向上と，よりコンパクトな決定木を得ることを
目的として行った枝苅りについて報告する．最後に{\bf 6}節で本論文をまと
め，残された問題について述べる．
\section{決定木}
決定木は，いくつかのテストを逐次的に行うことにより，データを
複数のクラスに分類するための手法であり，パターン認識や機械学習の
分野でよく研究されている(Breiman, Friedman, Olshen and Stone\ 1984)．
また，最近では自然言語処理への応用も報告されている
(Kuhn\ and De Mori\ 1995;\ 田中\ 1997;\ 春野，白井，大山\ 1998)．決定木を自動的に生成する
ことにより，大量のデータに内在する，人の直感では捉えにくい
規則性を高速に発見することができる．

ここでは，次のような基準により決定木を生成する(Zhang\ and Ozeki\ 1998)．
\begin{description}
\item[(1)]クラス数は二つとする．
\item[(2)]節点に到達した学習データの不純度を,
 Gini\,指数(Breiman, Friedman, Olshen and Stone 1984) により計量する.
\item[(3)]決定木を生成する際，不純度がゼロでない節点において，予め定め
られた有限個のテストを枚挙的に試みる．そして，その不純度を
減少できるようなテストのうち，減少量が一番大きいものを見い出し，その節点のテストとする.
\item[(4)]もし節点の不純度がゼロであるか，あるいはその不純度を減少できるようなテストが存在しなければ，
その節点を葉とする．葉には，そこに到達した学習データの多数決により「分割点である」か
「分割点でない」かのクラスを割当てる.
\end{description}
決定木を長文の短文分割の問題に応用するとき,
データとして何を考えるか，また，各節点でどのようなテストを行なうか
が主な問題である.これらの問題について次節で詳しく説明する.

\section{短文分割への決定木の応用}
\subsection{短文分割点の定義}
長文を短文に分割するためには，「短文」とは何かを明確に定義しなければならない．
ここでは，目的が係り受け
解析をより容易にすることであることを考慮し，
以下のような定義を設ける．

日本語文の構造は述語を中心に論じることができる．
述語を中心としたまとまりを「節」と呼び，
二つ以上の節からなる文において，
文末の述語を中心とした節を「主節」，それ以外の節を「接続節」
と呼ぶ．長文は常に多数の「接続節」を含んでいる．
短文分割の目的は係り受け解析をより容易にすることであるから，
ここでは「接続節」の中で，その末
尾の文節が「主節」の末尾の文節，すなわち文末の文節に係るような「接続節」
に着目する．
このような「接続節」は，その末尾の文節以外の文節がその内部の文節にしか係
らないような係り受け構造を持ち，その末尾の文節が文末の文節に係る．
これにより文全体の係り受け構造が構成される．
そして，このような「接続節」を検出すれば，長文の係り受け
解析をより短い「接続節」と「主節」の係り受け解析の問題に帰着させ，
係り受け解析をより容易にすることができると考えられる．
本論文では短文分割の問題をこのような「接続節」を検出する問題と考える．
また，その末尾の文節が文末の文節に係るような「接続節」を短文と呼ぶ．


さて，上に述べたことから，短文境界を見出すには，まず，文末の文節に係る用言文節
を検出することが必要である．しかし，文末の文節は，通常，主節の述語であり，
これには主節に含まれる
用言の連用形が係っていることがあ
る．これらを短文の末尾とするのは適当ではない．そこで，文末の文節に係る用言文
節の中から主節に含まれないものだけを選んで，短文の末尾とし，
それらの直後を短文分割点と定義する．
主節の範囲の認定は次の方法によって行った．すなわち，
文末文節との間に，用言文節，副詞，係助詞「は」，「も」で終る文節，
格助詞「が」，「を」，「に」などで終る文節の中の少な
くとも一つが存在するような用言文節の中で最も文末に近いものを検出する．
そして，その次の文節から文末までを主節と認定する．このような定義により，
コーパスに係り受け構造のラベルが付けられていれば，機械的に短文分割点を
定めることができる．

次に短文分割の例を示す．添字は文中の文節番号を示す．例文1において，
最後の文節に係る用言文節は，第9，
第13文節であるが，第13文節は主節に含まれる．したがって，第13文節の直後
は分割点とはならず，“$\parallel$”で示される一つの点が分割点となる．
そして，この例文は二つの短文に分割される．本論文では以後
真の分割点を“$\parallel$”で表す．
\vspace*{2mm}\\
\noindent
${\bf ［例文1］}
 最高^1\ \   税率の^2\ \   緩和を^3\ \   含む^4\ \   今の^5\ \   減税
案が^6\ \   必ずしも^7\ \   ベストとは^8\ \   思わないが，^9\  ||\ \ 
よい^{10}\ \   形での^{11}\ \   所得税減税を^{12}\ \  早く^{13}\ \  の
ぞみたい．$
\subsection{データ}
\subsubsection{要素文節}
文中の文節には，短文分割点を推定する上で重要な働きをするものと，あまり重要な
働きをしないものがある．節を構成するためには用言文節が必要であり，
また，節の中には主語がよく現れるので，
末尾が係助詞「は」，「も」，格助詞 「が」である文節
も重要な働きをすると考えられる．そこでこのような文節を取り出して要素文節
とし，それらの属性を抽出する．
属性としては，次のものを考える．
\vspace*{2mm}\\
\noindent
{\bf (a)\,接続属性\\}
接続属性の属性値は，文節の主辞と末尾の形態により，
表1 のように定める．
主辞欄の「体言判定」は，体言に判定詞が付属したものを
表す．
また，「用言」 は「動詞」，「形容詞」，「形容動詞」，
「体言判定」を含んでいる．
南は接続節の末尾の形態によってその独立性が変化することに着目し，接続節
を三種類に分類した(南\  1974)．表1の
 「A類」，「B類」，「C類」 は，ほぼその分類に対応している．
しかし南の分類では，
「て」と「連用形」は「A類」，「B類」，「C類」の複数の類に属するため，
実際に使い分けられない．
そこで，ここでは「て」を一つの類とする．また，形容詞と形容動詞の「連用形」
は，それ自身が述語ではなく述語の修飾語となる場合が多い(益岡，田窪\  1992)
ので，動詞の「連
用形」とは異なる特徴を持っていると予想し，
それぞれ「形連用」と「形動連用」に分類する．
\begin{table}[p]
\begin{center}
{\bf 表1\ \ }要素文節の接続属性
\vspace*{2mm}\\
\hspace*{-10mm}\begin{tabular}{|c|c|l|}
\hline
属性値&主辞の品詞&末尾の品詞，表記，活用形\\ \hline \hline
動連用&動詞，体言判定& 連用形\\ \hline
て&用言&接続助詞「て」，「で」\\ \hline
& & 「ため」，「際」，「時」，「とき」，「現在」，\\
& & 「今」，「あと」，「後」，「同時に」，\\
ため&用言 & 「ともに」，「とも」，「とたん」，「まま」，\\
& & 「間」，「以来」，「場合」，「うえ」，\\ 
& & 「ほか」，「結果」，「以上」\\ \hline
A類&用言&接続助詞「ながら」，「つつ」，「たり」\\ \hline
 & &接続助詞「ば」，「と」，「ので」，「まで」，\\
{\raisebox{0.0ex}{B類}}  &{\raisebox{0.0ex}{用言}}  &「のに」，「ば」，「たら」，「なら」，「ず」，\\
&&「ないで」，「ても」\\\hline
 & &接続助詞「が」，「から」，「けれど」，\\ 
{\raisebox{1.0ex}{C類}}&{\raisebox{1.0ex}{用言}}&「けれ」，「けれど
も」，「し」\\ \hline
形動連用&形容動詞&連用形\\ \hline
形連用&形容詞&連用形\\ \hline
動連体&動詞，体言判定&連体形\\ \hline
用言&用言&接続助詞以外の助詞\\ \hline
形連体&形容詞，形容動詞&連体形\\ \hline
は&体言&助詞「は」\\ \hline
も&体言&助詞「も」\\ \hline
が&体言&助詞「が」\\ \hline
終止&用言&記号「．」\\ \hline
\end{tabular}
\end{center}
\end{table}
\vspace*{2mm}\\ 
\noindent
{\bf (b)\,スコープ属性\\}
用言文節に形式名詞「こと」や引用助詞「と」などが含まれていると，
それより前にある文節がそれを飛び越して文末の文節に係ることは少ない
(黒橋，長尾\ 1994)．
このような現象を利用するため
「スコープ」属性を設け，その属性値は，文節に引用助詞「と」，助動詞「よう」，形式名詞 「こと」，
「もの」，「の」，「ところ」，「など」のいずれか
が含まれる場合には「スコープ」，ない場合には{\sf 「NULL」}と定める．
\vspace*{2mm}\\
{\bf (c)\,読点属性\\}
読点を伴う文節はそこに構文的な区切りが存在し
，離れた文節に係ることを示していると考えられる(黒橋，長尾\ 1994)．
このように読点を伴うかどうかによって接続節の独立性が
変化することを考慮し，「読点」属性を設ける．
読点属性の属性値は，文節直後に読点 「，」がある場合には 「読点」，
ない場合には {\sf 「NULL」}と定める．
\vspace*{2mm}

要素文節をこのような三つの属性値の組で表す．
次に通常の文から要素文節列への変換例を示す．
\vspace*{2mm}\\
${\bf［例文2］}\ 
16日に^{1}\ \ \ 米^{2}\ \ \ \ 船籍^{3}\ \ \ \ タンカーが^{4}\ \ \ \ 被
弾した^{5}\ \ \ \ 時，^{6}\ \ \ クウェート軍は^{7}\ \  ミサイルの^{8}\ \   飛来を^{9}\ \   探知，
^{10}\ \ \   自軍の^{11}\ \ \   地対空ミサイルで^{12}\ \ \   迎撃しよ
うとしたが，^{13}\ \  失敗に^{14}\ \   終わった．^{15}$
\vspace*{2mm}\\
${\bf ［要素文節列］}$\ 
$(が，{\sf NULL，NULL})^{4}\ \ (動連体，{\sf NULL，NULL})^{5}\ \ (ため，
{\sf NULL}，読点)^{6}$\ \ \ 
$(は，{\sf NULL，NULL})^{7}\ \ \ (動連用，{\sf NULL}，読点)^{10}\ \ \ ({\sf C類}，スコープ，読点)
^{13}\ \ \ (終止，$  ${\sf NULL，NULL})^{15}$\\
ここで6番目の文節は用言文節ではないが，直前の文節の末尾が連体形であり，
かつ自身の主辞が時詞であることから，5番目と6番目の文節が連結し一つの
文節になるものと考えて，ここではこのような文節も要素文節として取り出し，「ため」の接続属性を付与
する．
\subsubsection{短文分割点候補}
要素文節の中で，接続属性の値が「動連用」，「て」，「ため」，「A類」，「B類」，「C類」，
「形動連用」，「形連用」のいずれかであるものは，その直後
が短文の分割点になる可能性がある．そこで，これらの文節
を分割文節候補とし，
その直後を分割点候補とする．ただし，直後の文節が文末の文節
である場合には，それが分割点であるかどうかを判定する必要がないので，
分割点候補としない．
\subsubsection{決定木の入力データ}
分割点を推定する上で，分割文節候補の属性値が重要であることは明らかである．
また，分割点候補が
分割点になるか否かは，分割文節候補が
どの文節に係るかによって決まる．したがって，分割文節候補より後に現われる
要素文節も重要である．
しかし，分割文節候補より前に現われる文節は，あまり重要でないと考えられる．
そこで，本研究では，分割文節候補以降の要素文節のみをテストの対象とし，
分割文節候補以降の要素文節列を決定木の入力データとする．
したがって，$N$ 個の分割文節候補を持つ要素文節列からは，$N$個あるいは
$N-1$個(文末文節の直前文節が分割文節候補の場合にそれを除外する)のデー
タが作られる．
学習データと評価データには，分割点候補が真の分割点であるか否かによって，
“YES”，“NO” のラベルが付けられる．
\subsection{テスト集合}
\subsubsection{テスト項目の構成}
まず，テスト項目の集合 $V$ を
\[ V=(接続属性値の集合 \cup \{*\}) \times \{スコープ，{\sf NULL}，*\} \times
 \{読点，{\sf NULL}，*\}\] と定義する．
ここで，“$*$”はどのような属性値にも整合するワイルドカードを表す記
号である．
また，「長さ1以上の任意の要素文節列」を表す記号“$+$”を導入する．そう
すると，
テストは $[X]<Y>$という形で表される．$X$ は $V\cup \{+\}$ の
要素，$Y$ は$V\cup \{+\}$ の要素の列で，“$+$”が連続しないものである．
$[X]$ は
分割文節候補がパターン$X$に整合するかどうかをテストすることを表し，ま
た，
$<Y>$ は分割点候補より後の要素文節列がパターン $Y$ に整合するかどう
かをテストすることを表わす．

 例えば，テスト 
\[ [({\sf A}類，*，読点)] <(て，*，*) + (*，スコープ，*)\,+ > \]
 に合格するデータは，
分割文節候補の接続属性が「A類」であって「読点」属性を持ち，かつ，分割点候補
直後の要素文節の接続属性が「て」であり，
かつ，分割点候補直後の要素文節と最後の要素文節の中間に
「スコープ」属性を持つ要素文節が存在するようなものである．
“$*$”の部分の属性値は問われない．
\subsubsection{節点におけるテストの生成と選択}
決定木を生成する過程で，各節点におけるテストは次のように
定められる．ある節点に到達する学習データがそれ以前の段階で既に合格して
いるテストを，
その節点の既知テストと呼ぶ．
既知テスト $[X]<Y>$ における $[X]$ の中の “$+$” を
“$v$”$(v \in V)$ に，また，$<Y>$ の中の“$+$”を
 “$v$”，“$+v$”，“$v+$”，“$+v+$”$(v \in V)$
に順次置き換えることにより，新たなテストを生成する．
生成されたこれらのテストの中から
節点の不純度減少規準
により最適なものを選択し，この節点のテストとする．
この節点を，テストに合格するデータが集まる$Yes$子節点と，
テストに合格しないデータが集まる$No$子節点に展開する．
$Yes$子節点の既知テストは親のテストに等しく設定し，$No$ 子節点の
既知テストは親の既知テストに等しく設定する．

根の既知テストを 
$[+]<+>$
に初期設定し，上のような手続きを停止条件が満たされるまで再帰的に繰り返
すことにより，決定木が生成され，各節点のテストが決定される．

「長さ1以上の任意の要素文節列」を表す記号“$+$”の導入により，
分割文節候補と文末までのそれぞれ要素文節との関
係を考慮に入れることができる．また，属性値が「何でもよい」ことを表す
“$*$”の使用により，データの希薄性をある程度補うこともできる．
このように構成した決定木生成の枠組により，分割点候補が
分割点になるかど
うかを判定するための，分割文節候補と後続する要素文節の接続属性，スコープ
属性，読点属性の間の相互関係がコーパスから自動的に抽出できるようになる．
\section{決定木の生成と分割点の推定実験}
EDRコーパス(日本電子化辞書研究所\ 1996)に対し，上に述べた方法によって，
短文分割のための決定木の生成と分割点推定実験を行う．
\subsection{データの作成}
まずコーパスから長さが30形態素以上の2000文をランダムに選んだ．
EDRコーパスには構文情報が括弧付構造の形で与えられている．このような
構造から文節間の係り受け関係を求め，係り文節に対する受け文節の唯一性と
係り受けの非交差性を満たす1835文を抽出した．
また同様の構文情報を用いて各文節の主辞を定めた．
さらに，文節末の活用語に対して，
付属単語辞書の活用情報により活用形を抽出した．
EDRコーパスでは助詞の品詞分類が粗く，
形態素「と」は全て「助詞」に分類されている．そこで，「と」が，現れる文
脈の
中で引用，接続，並列のいずれの働きをするかにより
品詞の細分類を行った．これらの結果を用いて，1835文を要素文節列に変換
し，分割文節候補を検出し，データを作成した．さらに，もう一度
構文情報を用いて，分割文節候補が文末の述語に係るか否かにより
各データに “YES”，“NO”のラベルを付与した．
これらの処理はすべて自動的に行った．求められた文節間係り受け関係の精
度はコーパスのラベルの精度に依存するが，もしそれが正しければ“YES”，
“NO”のラベルの精度は100\%である．

総データ数は2484個となった．
1835文のうちランダムに選んだ400文から作られた555データを評価データとし，
残りの1435文から作られた1929データを学習データとした．
\subsection{評価尺度}
決定木の分割精度を評価するため以下の尺度を用いる(Hindle\ and Rooth\ 1993):

\[文正解率＝\frac{完全に正しく分割された文数}{評価文数}\]
\[\sf 適合率＝\frac{正しく“YES”と判定されたデータ数}{“YES”と判定されたデータ数}\vspace*{5mm}\]
\[\sf 再現率＝\frac{正しく“YES”と判定されたデータ数}{“YES”のラベルが付与されたデータ数}\]
\vspace*{0.2mm}\\
適合率と再現率を一つの尺度として表現するために，それらの調和平均である
$F$値(永田\ 1997)も用いる:
\[F＝\frac{2\times 適合率 \times 再現率}{適合率 ＋再現率}\vspace*{4mm}\]
このように定義した$F$値では，適合率と再現率は同じ重みで評価される．

\subsection{非用言文節の属性値の選択と決定木の生成}
要素文節の中で接続属性値「は」，「も」，「が」を持つ非用言文節の
短文分割における効果を調べるため，それらを用いない場合と，用いた場合のそ
れぞれについて
決定木を生成し，短文分割実験を行った．

評価データに対する
分割精度を表2に示す．この結果から，非用言文節の属性値「は」，「も」，「が」の中で，
「は」と「も」の併用は短文分割の精度を上げるのに効果があり，
「が」はあ
まり効果のないことが分かった．この結果から，以後の実験では
テスト項目の集合から「が」の接続
属性値を除く．
\begin{table}[b]
\begin{center}
{\bf 表2\ \ }異なる非用言文節属性値を用いて生成した決定木の分割精度(\%)
\vspace*{1mm}\\
\hspace*{-10mm}\begin{tabular}{|c|c|c|c|c|}
\hline
非用言文節属性値&適合率 & 再現率& $F$値& 文正解率 \\ \hline
なし & 81.9  & 82.4 & 82.1& 74.0 \\ \hline
「が」& 81.9  & 82.1 &82.1 & 74.3 \\ \hline
「も」& 81.1   &  83.6 & 82.3&  73.8 \\ \hline
「は」& 83.4  & 84.2 & 83.8& 76.8 \\ \hline
「は」，「も」& 84.2   & 84.2 &84.2  & 76.8 \\ \hline
「は」，「も」，「が」& 82.0  & 83.0 & 82.5 & 75.0 \\ \hline
\end{tabular}
\end{center}
\end{table}

新たに設定したテスト項目の集合を用いて生成した
決定木の節点数は771個で，葉は386個になった．根に近い「C類」接続属性に
関する部分を図1に示す．
\begin{table}[t]
\begin{center}
\epsfile{file=tgiffig4.ps2,scale=1.0}
\vspace*{2mm}\\
{\bf 図1\ \ }決定木の根に近い「C類」接続属性に関する部分\\
\end{center}
\end{table}

この決定木により，例えば，
分割文節候補が接続属性 「C類」と読点属性「読点」を持つデータは，
最上部の節点におけるテスト
\[ [({\sf C}類，*，読点)]<+> \]
に合格し，その節点の$Yes$子節点に振り分けられる．そこで，分割点候補の後の要素文節列がチェックされ，
もし直後の要素文節と文末の要素文節の中間に「スコープ」と「読点」を持つ要素文節が
あれば，“NO”というクラスを持っ
た葉に到達する．これにより，そのデータの分割点候補は分割点ではないと判定さ
れる．

決定木の全体の771個の節点には，
学習データ中に現われる言語現象と
その出現頻度に応じて，不純度最小化規準のもとでの
最適分割パターンとその適用順序が決定されている．このような知識を
人の直感によってコーパスから抽出することは困難である．
\subsection{短文分割点の推定}
生成した決定木を用いて，400文の評価データに対し分割点の推定を行った．
分割結果の例を以下に示す．{\sf (Y)}と{\sf (N)}は検出された分割点候
補が，それぞれ「分割点である」か「分割点でない」かの判定結果を表す．また，
“$\parallel$”は
真の 分割点を表す．
\vspace*{1mm}	\\
${\bf ［例文2］}(前出)\ 
１６日に^{1}\ \   米^{2}\ \   船籍^{3}\,\,\,  タンカーが^{4} \ \  被弾し
た^{5}\ \   時，^{6}\ \  {\sf (N)}  クウェート軍は^{7}\ \  ミサイ
ル の^{8}\ \   飛来を^{9}\ \   探知，^{10}\ \ {\sf (N)} \ \  自軍の^{11}\ \   地対空ミサイル
で^{12}\ \   迎撃しようとしたが，^{13}\ \ {\sf  (Y)}\  
 \parallel \ \ 失敗に^{14}\ \    終わった．^{15}
\vspace*{1mm}  \\
{\bf  ［例文3］}\  
病が^{1}\hspace*{2mm}進み，^{2}\hspace*{2mm}{\sf (Y)}\hspace*{2mm}スタジオの^{3}\hspace*{2mm}ソファに^{4}\hspace*{2mm}横に^{5}\hspace*{2mm}なりながら^{6}\ \ {\sf  (N)}\ \ \ 指示を^{7}\ \   出
していた^{8}\ \   亀井さんは，^{9}\ \   最後の^{10}\ \   ロールが^{11}\ \   終わったとき，^{12}
\ \  涙ぐん
だ．^{13}
\vspace*{1mm}\\
{\bf ［例文4］}\
休みを^{1}\hspace*{2mm}取らなければ，^{2}\hspace*{2mm}{\sf  (N)}\hspace*{2mm}次々に^{3}\hspace*{2mm}加算されていくの
で，^{4}\hspace*{2mm}{\sf (Y)}\hspace*{2mm}まとめ
て^{5}\hspace*{2mm}{\sf (N)}\hspace*{2mm}木，^{6}\hspace*{2mm}金曜を^{7}\hspace*{2mm}休みに^{8}\hspace*{2mm}して，
^{9}\hspace*{2mm}{\sf (Y)}\hspace*{2mm}週休と^{10}\hspace*{2mm}合わせて^{11}\hspace*{2mm}{\sf (N)}\hspace*{2mm}４連休に^{12}\hspace*{2mm}することも^{13}\hspace*{2mm}できる．^{14}
$\vspace*{1mm}	\\
例文2では，すべての分割点候補における判定結果がラベルと一致したが，
例文5の$文節^2$，例文6の$文節^4$，$文節^9$
の直後は誤って分割点と判定されている．
しかし，例文6において，
もし「でき」を付属語と考え，
「することも」と「できる．」を一つの文節としてラベル付けすれば
「することもできる．」が最後
の文節になり，$文節^4$と$文節^9$が文末の文節に係ることになって，
そこの二つの誤りとされた結果は正しい判定結果に変る．
EDRコーパスには，「でき」を付属語と考えて
ラベル付けしている文もあるので，上の理由から例文6における誤りは許容できる誤りで
あると考えられる．
\begin{table}[t]
\begin{center}
{\bf 表3\ \ }400文の評価データに対する分割精度(\%)
\vspace*{2mm}\\
\begin{tabular}{|c|c|c|c|c|}
\hline
\ \  適合率\ \  &\ \  再現率\ \  &\ \  $F$値\ \  &\ \  文正解率\ \ \\ \hline
84.2 &84.2 &84.2& 76.8\\ \hline
\end{tabular}
\end{center}
\end{table}

400文の評価データに対する分割精度を表3に示す．

\subsection{誤分割結果の分析}
誤分割された例を調査したところ，次のような問題があることが分かった．
\vspace*{2mm}\\
\noindent
{\bf (1)}分割点候補より後に接続属性「動連体」，
あるいはスコープ属性「スコープ」を持つ要素文節が存在
する場合は誤りが多く，全体の誤りの約7割を占めている．これは，
連体節や引用節の範囲を推定するのが難しいことを示している．\\
例文5において$文節^2$の直後は誤って分割点と判定されたが，実際には
$文節^2$は$文節^8$の「動連体」の範囲に属している．\ 
次の例文7において，\ $文節^8$は後ろの「動連体」属性を持つ$文節^9$と$文節
^{12}$のどちらの範囲に属するか，またどちらにも属しないか，という判定は
かなり難しい．\\
\noindent
${\bf [例文5]}
８月^1\ \   １４日ごろ，^2\ \   ツチ族の^3\ \   元兵士が^4\ \  
 少なくとも^5\ \   ２人の^6\ \   フツ族を^7\ \   殺し，^8\ \  || 怒っ
た^9\ \   フツ族が ^{10}\ \  周囲に^{11}\ \   住む^{12}\ \   
ツチ族の^{13}\ \   全家族を^{14}\ \   攻撃し始めたらしい．^{15}$

解決策の一つとして，述語の表記のような表層情報
を利用することが考えられる．
次の例文8の分割文節候補である$文節^6$と後ろの「動連体」属性を持つ$文節^8$が同じ
表記「売る」を含む
ことは$文節^6$が$文節^8$の修飾範囲に属し分割点にならない根拠になり
得ると思われる．\\
\noindent
${\bf [例文6]} このことでも^1\ \   わかるように，^2\ \   近ごろの^3\ \ 
民放は，^4\ \   番組を^5\ \ 売るのでなく，^6 \ \   時間を^7\ \   売る
^8\ \   傾向が^9\ \   強い．^{10}  
$
\vspace*{2mm}\\
\noindent
{\bf (2)}学習データの量が十分ではない．\\
${\bf [例文7]}\
１９８２年，^1\ \   製造^2\ \   部門の^3\ \   トヨタ^4\ \   自動車^5\
\   工業と^6\ \   販売の^7\ \ トヨタ^8\ \   自動車^9\ \   販売が^{10}\ 
\ 合併して，^{11}\ \   いまの^{12}\ \   トヨタに^{13}\ \ 
  なったとき，^{14}\ \  || 社長には^{15}\ \  本家の^{16}\ \  
 章一郎が^{17}\ \  就任した．^{18} 
$

例文9において$文節^{11}$は「て」の接続属性を持
ち，その直後が分割点候補である．後に「ため」の接続属性を持
つ$文節^{14}$がある．
$文節^{11}$のところの分割点候補が誤って分割点と判定されたことから，
そのデータが決定木に沿って到達した葉は“YES”というクラスを持っている
ことが分かる．
その葉を生成した学習データを調べると，全部で三つあり，すべて“YES”
のラベルが付与されていた．
これらのデータから抽出されたテストは
\[ [+]<(ため，*，読点)+> \]
になっている．すなわち，どんな分割文節候補でも直後に「ため」と「読点」
属性を持つ要
素文節さえあれば分割点候補は分割点と判定される．

こういうことになったのは学習データの中に，分割点候補の直後に「ため」の
接続属性を持つ
要素文節があり，かつその分割点候補が真の分割点ではないようなデータが現れなかったからである．

このように学習データの量が十分ではないため誤った結果は全体の誤りのほぼ1割
になっている．
\vspace*{2mm}\\
\noindent
{\bf (3)}情報の抽出処理が不完全である．
\vspace*{2mm}\\
\noindent
{\bf (a)}主辞のみによる要素文節の抽出は十分ではない．\\
$
{\bf [例文8]}
 一時は^1\ \ \   健康・^2\ \  \ 自然食^3\ \   ブームに^4\ \  \  乗って
^5\ \ 
東南アジアから^6\ \   低コストのものの^7\ \ \   輸入量が^8\ \ \   急増し，
^9\ \ \  米が^{10}\ \  \  自由化になったら^{11}\ \   かくや，の^{12}\ \ 
  様相を^{13}\ \  垣間見せた．^{13}  $

$文節^{9}$は動詞「なる」を含んでいるのに，主辞が「自由化」で普通名詞
であるというラベルが付けられているので，
現在の処理によりこの文節が要素文節として取り出されなかった．
\vspace*{2mm}\\
\noindent
{\bf (b)}EDRコーパスでは助詞の
分類が粗いので，
助詞「と」 を文脈に応じて引用助詞，接続助詞，並列助詞へ
細分類する必要がある．しかしこの処理はまだ不完全である．

「と」の直後の文節が「思う」，「指摘」などの
動詞であれば，その「と」は「引用助詞」と考えられる．そこで，まず
「と」を含む一定数の例文に対し，人手で
「と」を「引用助詞」と判定するときその直後の文節の主辞を収集した．
それに基づいて「と」を含む文に対し，直後の文節の主辞が収集したリストに含
まれればその「と」を「引用助詞」に細分類する．しかし，この動詞リストは
まだ完全になっていない．
次の例文11において，$文節^{15}$の主辞「訴える」が収集したリスト
に載っていなかったため$文節^{14}$の「と」は「引用助詞」としての細分類がさ
れなかった．そして「スコープ」の属性値も抽出されなかった．
\\
\noindent
${\bf [例文9]}ボーク^1\ \   判事が^2\ \   最高裁に^3\ \   入れば^4\ \  
 ６０年代から^5\ \   ７０年代にかけて^6\ \   勝ち取った^7\ \   公民権
^8\ \ \  拡大や^9\ \ \  婦人の^{10}\ \ \  権利の^{11}\ \   尊重を^{12}\ \ 
台なしに^{13}\ \   されかねない，と^{14}\ \   訴えた．^{15} 
$

また，「と」の直後の文節の主辞が「動詞」ではなく，副
詞や連用形の形容詞の場合には，第二番目以降の文節まで調べないといけない．
\vspace*{2mm}\\
\noindent
{\bf (c)}「ため」の接続属性の抽出が十分でない．\\
現在の処理では，
文節の主辞が動詞で末尾が表1に示される，「ため」，「とき」のようなもの
であると「ため」の接続属性が抽出される． また， 例文2の$文節^6$のように
文節の主辞が表1の「ため」属性に対する「末尾の品詞，表記，活用形」リ
ストに示されるもので直前文節の末尾が連体形である場合に，
「ため」の接続属性が抽出される．
ところが，次の例文12において$文節^{11}$の末尾が連体形で$文節^{12}$が「ため」を含んでいる
のに，主辞の「時分割多重方式」が上記リストに属していないので「ため」の接続属性が抽出されな
かった．
$\\
\noindent
{\bf [例文10]}\ 
アクセス^1\ \   方式は^2\ \   １個の^3\ \   伝送^4\ \   チャネルに^5\
\   複数^6\ \   端末を^7\ \   接続し，^8\ \   時分割に^9\ \   メッセージを
^{10}\ \   送る^{11}\ \   時分割多重方式なため，^{12}\ \  || あらゆる
^{13}\ \   通信^{14}\ \   メディアを^{15}\ \   有機的に^{16}\ \  
 結合できる．^{17}
$

以上のように情報の抽出処理が不完全であるため誤った結果は全体の誤りの約
1割になっている．この研究においては，
分割点を判定するのに用いられる中間情報を表層情報から抽出することが非常
に
重要であり，さらに精密化する必要があると考えられる．
\vspace*{2mm}\\
\noindent 
{\bf (4)}EDRコーパスに記述されている構文情報の不統一によって，作成したデー
タが誤りとなった例がある．
\vspace*{2mm}\\
\noindent 
{\bf (a)}品詞のラベル付けが誤っている．\\
次の例文13において$文節^9$の「捜査」は「動詞」の品詞ラベルが付けられてい
るため
この文節は要素文節として取り出された．そして$文節^7$のところの分割点候補が
分割点ではないと誤って判定された．\\
${\bf [例文11]}さしあたりは^1\ \ \ 中曽根^2\ \ \  前首相の^3\ \ \  証人喚
問^4\ \ 問題などで^5\ \   時間を^6\ \   かせぎ，^7\ \ || 東京地検の^8\ 
\ 捜査の^9\ \   行方を^{10}\ \   じっくり^{11}\ \  見守ろうとしている．^{12}  
$\vspace*{2mm}\\
\noindent 
{\bf (b)} 文節のラベル付けに不統一がある．\\
上の$例文6$においては「することも\ \ \ できる．」のように二つの文節として
ラベルが付けられている．しかし，次の例文14においては「示すことができたのか．」の
ように一つの文節としてラベルが付けられている．\\
\noindent
${\bf [例文12]}
ナポレオンは，^1\ \  もし^2 \ \ 環境が ^3\ \  彼に^4\ \  生涯，^5\ \  洋服屋を^6\ 
\ 強要していたとしたら，^7\ \  ||    
彼の^8\ \  軍事的^9\ \  熟達を^{10}\ \  示すことができたのか．^{11}  
$

また次の例もあった．\\
\noindent
${\bf [例文13]}
陛下は，^1\ \   ベッドの^2\ \  上で^3\ \   少し^4\ \   お体も^5\ \   
動かされるように^6\ \   なり，^7\ \  || 同日^8\ \   午後には，^9\ \ 
 ５分間ほど^{10}\ \ 起きて，^{11}\ \  || ベッドに^{12}\ \ 
腰を^{13}\ \  かけられたという．^{14} 
$\\
\noindent
${\bf [例文14]}
この^1\ \   動きに^2\ \  加担していると^3\ \   みられる^4\ \ 
ＣＩＡと^5\ \ \  ＭＩ5，^6\ \   ＭＩ6の^7\ \   要員^8\ \   名を^9\ \ \  
調べ上げ，^{10}\ \ \  親書の^{11}\ \  形で^{12}\ \   １９７６年に
^{13}\ \   米国に^{14}\ \   通報したと^{15}\ \   いう．^{16}
$\\
\noindent
例文15においては$文節^7$と$文節^{11}$は文末の述語「いう」の前の述語
「かけられた」に係り，それに「かけられたという」のように一つの
文節としてラベルが付けられているので，$文節^7$と$文節^{11}$の直後はそれぞれ
真の分割点である．
一方， 例文16においては$文節^{10}$が同様に文末の述語「いう」の前の述語
「通報した」に係るが，
「通報したと」が後ろの「いう」と別の文節としてラベ
ルが付けられ，最後の文節ではないので，$文節^{10}$の直後は真の分割点ではない．
 
上のようなラベル付けの誤りやラベル付けの不統一は
決定木の生成や判定結果の評価に影響を与えていると思われる．これにより
誤った結果は全体の誤りの1割程度と推測される．
\section{決定木の枝苅り}
枝苅りは，決定木が学習データに過適応することを抑制し，
未知データに対する性能を向上させること，また決定木の節点数を抑え，よりコンパ
クトな決定木を生成することなどの効果を持つことが期待される．
種々の枝苅り技法が研究されている(Breiman, Friedman, Olshen and Stone\
1984;\ Gelfand, Ravishankar  and Delp\ 1991)が，
ここでは$\rm Gelfand$らにより提案された考え方に基づく方法を
用いた．
枝苅りは通常誤り率と
葉の数に着目して行われるが，この方法では誤り率のみを考慮する．
\subsection{枝苅り法}

2セットの学習データ$D^1$，$D^2$を用意する．これらの一方は，決定木を成長させる
ため(成長用)，また，他方は枝苅りをする際の誤りの評価のため(枝苅り用)
に交互に用いられる．
成長と枝苅りの繰り返しにより決定木を生成する．
このアルゴリズムを図2に示す．
\begin{table}
{\bf 記法}
\begin{itemize}
\item $E(T,D)$: 決定木$T$をデータセット$D$
で評価したときの誤り率
\item $T'\leq  T$: $T'$は決定木$T$の枝苅り部分木であることを表す．
\item $T^*$: 
決定木$T$の
最小誤り枝苅り部分木で，次の式により定義される．
\[T^*=\arg \min_{T' \leq T} E(T',D)\]
また，$\arg \min_{T' \leq T}E(T',D)$
を実際に求めるアルゴリズムは文献(Gelfand, Ravishankar  and Delp\ 1991)によった．
\vspace*{5mm}\\
\end{itemize}

\noindent {\bf [初期化]}\ 初期最小誤り枝苅り部分木$T_0^*$を求める:
\begin{description}
\item[(1)]セット$D^1$\,を成長用データとし，
{\bf 2}節に述べた方法により決定木$T_0$\,を生成する．
\item[(2)]セット$D^2$\,を枝苅り用データとし，
  $T_0$\,の最小誤り枝苅り部分木$T_0^*$\,を求める: 
   \[T_0^*:=\arg \min_{T_0' \leq T_0} E(T_0',D^2) \]
\end{description}
\noindent {\bf [繰り返し]}\ $k=1$から始め，次の{\bf (1)}$\sim${\bf (4)}を予め定めた停止条件が
満されるまで繰り返す:
\begin{description}
\item[(1)]   
  \[(i,j):=\left\{\begin{array}{ll}
\ (1,2), \ k が偶数のとき;\\      
\ (2,1), \ k が奇数のとき\\ 
\end{array}
\right.
\]
\item[(2)]セット$D^i$\,を成長用データとして，{\bf 2}節に述べた方法により
$T_{k-1}^*$\,の葉から枝を成
長させ，
決定木$T_k$\,を生成する．
\item[(3)]
セット$D^j$\,を枝苅り用データとし，$T_k$\,の最小誤り枝苅り部分木$T_k^*$\,を求
める: 
  \[T_k^*:=\arg \min_{T_k' \leq T_k} E(T_k',D^j) \]
\item[(4)]$k:=k+1$
\end{description}
\begin{center} 
{\bf 図2\ \ }成長と枝苅りの繰り返しによる決定木の生成アルゴリズム\vspace*{4mm}
\end{center}
\end{table}
\subsection{実験と結果}
ここでは，{\bf 4.1}で作成したデータと{\bf 4.3}で新たに設定したテスト項
目の集合を用いる．
{\bf 4.1}では1435文から作られた1929個のデータを学習データとした．その中に
は，分割文節候補と文
末文節の間に用言文節が存在しないデータがある．このような分割文節候補
は必ず文末文節に係るから，曖昧さがないデータであり，
枝苅りに用いないことにする．
1435文の中で，曖昧さがある文は921文であり，それらから作られるデータは
1339個である．これを$D^1(670個)$と$D^2(669個)$に分割する．

図{\bf 2}のアルゴリズムにより，
決定木の成長と枝苅りを繰り返した．そのときの
決定木の大きさと枝苅り用データに対する誤り率の変化を表4に示す．
$k=3$以降は，$k=1,2$と同じ結果が交互に現われた．
\begin{table}[t]
\begin{center}
{\bf 表4\ \ }枝苅りによる決定木の大きさと枝苅り用データに対する誤り率．\\
$|T|$は決定木$T$の大きさ(節点数)を表す．
\vspace*{1mm}\\
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\makebox[14mm]{繰り返し} &\makebox[26mm]{枝苅り用データ} &\multicolumn{2}{c|}{枝苅り前}
&\multicolumn{2}{c|}{枝苅り後}\\
\cline{3-6}
\makebox[10mm]{$回数k$ }&\makebox[20mm]{$セット番号j$}
&\makebox[10mm]{$|T_k|$}&
\makebox[18mm]{$E(T_k,D^j)$} &\makebox[10mm]{$|T_k^*|$}
&\makebox[18mm]{$E(T_k^*,D^j)$} \\
\hline
0& $2$ &431&0.283&167&0.214\\ \hline
1& $1$ &519&0.312&183&0.175\\ \hline
2& $2$ &457&0.275&201&0.197\\ \hline
3& $1$ &519&0.312&183&0.175\\ \hline
4& $2$ &457&0.275&201&0.197\\ \hline
\end{tabular}
\vspace*{2mm}\\
\end{center}
\end{table}

さらに，$T_k^*$\,($k$=0,\,1,\,2,\,3,\,4)のそれぞれを用いて，
{\bf 4.1}の400文の評価データ
に対し，短文分割実験を行った．その結果を表5に示す．
また，比較のため，表3の学習データをすべて用い，枝苅りな
しで生成した決定木による分割結果を共に表5に示す．
\begin{table}[t]
\begin{center}
{\bf 表5\ \ }400文の評価データを分割した結果の比較
\vspace*{1mm}\\
\hspace*{-10mm}\begin{tabular}{|c|c|c|c|c|c|}
\hline
枝苅りあり &$|T_k^*|$&適合率(\%)&再現率(\%)& $F値(\%)$ &文
正解率(\%)\\ \hline
$T_0^*$ &167& 84.6 &  83.3&83.9 &76.3\\
\hline
$T_1^*$ & 183&84.0 & 84.8 &84.4 & 76.2\\
\hline
$T_2^*$ & 201&84.1& 85.1 &84.6 & 76.8\\
\hline
$T_3^*$ &183& 84.0& 84.8&84.4 &76.2\\
\hline
\hline
枝苅りなし & 771&84.2& 84.2 &84.2 & 76.8\\
\hline
\end{tabular}
\vspace*{1mm}\\
\end{center}
\end{table}

表5において，枝苅りありの決定木$T_2^*$と枝苅りなしの決定木
を比較すると，前者の節点数は後者の1/3以下であるが，ほとんど同じ分割精度が得られ
ている．400文の評価データ中には曖昧さがないデータがあり，
そのようなデータに対する結果は決定木により得られたものではない．
純粋に決定木により得られた結果を見出すため，
400文の評価データ中の曖昧さがあるデータ
のみに対し，
枝苅りありの決定木$T_2^*$と枝苅りなし決定木のそれぞれを用いて，
評価を行った．その結果,いずれも$F$値は$69.6\%$であり,
両者は同等の性能を持つことが分かった.
これによりここで用いた枝苅り法は確かに，分割精度を保ちながら
決定木の大きさを減少させるのに有効であることが明らかになった．
\section{むすび}
 表層情報による短文分割問題に対し，決定木の手法を提案した．
EDRコーパスを用いて，提案した方法により，短文分割のパターンの獲得と，獲得
した分割パターンに基づく短文分割の実験を行った．
また，決定木の生成過程に枝苅りを導入することを試みた． 
本論文の結論は次のようにまとめることができる．
\begin{itemize}
\item  
提案した手法により，コーパスから短文分割パターンを自動的に獲得できる
ことが実験的に検証された．ここで考案したテスト集合の生成法により，
重要な働きをする要素文節を文の全範囲か
ら自動的に抽出できることが示された．
\item テスト項目の集合を変えることにより，関連情報の短文分割における働き
を調べることができる．実際，この方法により，
非用言文節の末尾の形態素「は」，「も」，「が」の中で，
「は」と「も」の併用は短文分割の精度を上げるのに効果があり，「が」はあ
まり効果のないことが分かった．
\item 決定木を生成する過程で枝苅りを行うことにより，評価データに対
する分割精度を保ちながら，決定木の節点数を大きく減少できることが分かった．
\end{itemize}
今後の課題として，以下のことが挙げられる．
\begin{itemize}
\item 連体節や引用節の範囲に関係する分割点候補は判定誤りが多かった．
文正解率が$76.8\%$に留まったのは，多くはこのためである．
本提案手法の分割精度をさらに向上させるためには，
連体節や引用節に関係する表層情報のより有効な利用
法や，他の表層情報の利用などについて検討する必要がある．
\item  短文分割に必要な表層情報が形態素解析によって十分与えられないこ
とがある．これは使用する形態素解析システムにもよるが，ここで使用したEDR
コーパスにおいては，例えば形態素「と」の品詞はすべて単に「助詞」となっ
ている．しかし，「と」には引用，接続，並列などの機能があり，「と」が文中
に現れるとき，そのいずれの機能を持つかによって，短文分割における働きが変っ
てくる．そのため，本研究では，「と」が現れる文脈からそれを推定し，
その品詞を自動的に細分類する処理を行った．しかし，
その処理
はまだ不完全である．したがって，この問題を改善するためにはその処理をさら
に強化するか，あるいは形態素の機能に応じて細い品詞分類を行うような
形態素解析システムを使用する必要がある．
\end{itemize}
\begin{list}{}{}
\item[{\large \bf \hspace*{1mm}参考文献\\}]
\item[Breiman, L., Friedman, J.H., Olshen, R.A. and Stone, C.J.](1984).\ \ 
{\it Classification  and Regression Trees.}\ \ {\rm Chapman \& Hall}.

\item[Gelfand, S.B., Ravishankar, C.S., and  Delp, E.J.](1991).
\ “An\ \ Iterative\ \ Growing\ \ and\ Pruning\ Algorithm\ for\
Classification\ Tree\ Design.”\ {\it IEEE Trans. Pattern Analysis
and Machine Intelligence,}\ 13(2),\ 163-174.

\item[春野雅彦,白井諭,大山芬史](1998). \ “決定木の混合を利用した日本
語係り受け解析.”\  言語処理学会第4回年次大会発表論文集,\ 217-220.

\item[Hindle, D. and \ Rooth, M.](1993).\ “Structural Ambiguity
and Lexical Relations.”\ \ {\it Computational Linguistics,}\ 19(1),\ 103-120.

\item[金淵培,\ 江原暉将](1994). \ “日英機械翻訳のための
日本語長文自動短文分割と主語の補完.” {\it 情報処理学会論文誌},\
\ 35(6)\ , 1018-1028.

\item[Kuhn, R. and De Mori, R.](1995).\ “The
Application of Semantic Classification Trees to Natural Language
Understanding.”\ \ {\it IEEE Trans.  Pattern Analysis and Machine
Intelligence,}\ 17(5),\ 449-460.

\item[黒橋禎夫,長尾真](1994)\ .\ “並列構造の検出に基づく長い日本語
文の構文解析.”\ \ 自然言語処理,\ 1(1),\ 35-57.

\item[益岡隆志,田窪行則](1992).\ \ 基礎日本語文法.\ \ くろしお出版.

\item[南不二男](1974).\ \ {\it 現代日本語の構造.} \ 大修館書店.

\item[森岡健二](1994).\ \  {\it 日本文法体系論.}\ \ 明治書院.

\item[日本電子化辞書研究所](1996).\ “EDR 電子化辞書 1.5 版仕様説
明書.”

\item[武石英二,\ 林良彦](1992).\ “接続構造解析に基づく日本語複文の
分割.” {\it 情報処理学会論文誌},\ 33(5),\ 652-663.

\item[田中英輝](1997).\ “木構造の属性を許す決定木学習アルゴリズム.”
\ 情報処理学会論文誌,\ 38(11),\ 2122-2133.


\item[張玉潔,尾関和彦](1998).\ “分類木を用いた日本語長文の自動分割.”
\  言語処理学会第4回年次大会発表論文集,\ 390-393. 

\item[Zhang, Y. and Ozeki, K.](1998).\ “The Application of
Classification Trees to Bunsetsu Segmentation of Japanese Sentences.” 
\ {\it Journal of Natural Language Processing},\ 5(4),\ 17-33.
\end{list}
\end{document}
