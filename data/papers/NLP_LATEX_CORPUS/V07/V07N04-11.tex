



\documentstyle[epsf,jnlpbbl,version]{jnlp_j}

\def\atari(#1,#2,#3){}

\setcounter{page}{229}
\setcounter{巻数}{7}
\setcounter{号数}{4}
\setcounter{年}{2000}
\setcounter{月}{10}
\受付{2000}{4}{4}
\再受付{2000}{6}{6}
\採録{2000}{6}{30}

\setcounter{secnumdepth}{2}

\title{複数決定リストの順次適用による文節まとめあげ}
\author{白木 伸征\affiref{chuken} \and 梅村 祥之\affiref{chuken} \and 原田 義久\affiref{chuken}\affiref{nagoya}}

\headauthor{白木, 梅村, 原田}
\headtitle{複数決定リストの順次適用による文節まとめあげ}

\affilabel{chuken}{株式会社 豊田中央研究所}{Toyota Central Research and Development Laboratories Incorporated}
\affilabel{nagoya}{現在，名古屋商科大学，商学部}{Faculty of Commerce and Business Administration, Nagoya University of Commerce and Business Administration}

\jabstract{
  近年の高度情報化の流れにより，自動車にも種々の情報機器が搭載
  されるようになり，その中で音声認識・合成の必要性が高まってい
  る．本研究は音声合成を行うための日本語解析の中で基本となる，
  文節まとめあげに関する研究報告である．
  従来の文節まとめあげは，人手規則による手法と機械学習による手
  法の二つに大きく分けられる．前者は，長年の努力により非常に高
  い精度を得られているが，入力データ形式が固定であるために柔軟
  性に欠け，人手で規則を作成・保守管理するため多大な労力を要し，
  車載情報機器へ実装するには問題が大きい．また後者は，それらの
  問題に柔軟に対処できるが，精度を向上させるためにアルゴリズム
  が複雑化しており，その結果開発期間が延長するなどの問題が生じ，
  車載情報機器には不向きである．
  そこで本研究は，決定リストを用いる手法を発展させ，複数の決定
  リストを順に適用するだけという非常に簡明な文節まとめあげの手
  法を提案する．決定リストの手法は非常に単純であるが，それだけ
  では高い精度が得られない．そこで，決定リストを一つではなく複
  数作成し，それぞれのリストを最適な順序に並べて利用することに
  より精度向上を図った．この結果，京大コーパスの最初の10000文
  を学習コーパス，残りの約10000文をテストコーパスとして実験を
  行ったところ，非常に簡明な手法ながら，99.38\%という高い精度
  を得られた．
}

\jkeywords{文節まとめあげ, 決定リスト}

\etitle{Bunsetsu Identification with \\ Sequential Use of Plural Decision Lists}
\eauthor{Nobuyuki Shiraki\affiref{chuken} \and Yoshiyuki Umemura\affiref{chuken} \and Yoshihisa Harata\affiref{chuken}\affiref{nagoya}} 

\eabstract{
  Recent information-oriented society becomes to need Car-Multi-Media
  systems. In the systems, speech recognition and synthesis systems are
  also necessary. We aimed to improve Bunsetsu Identification which
  is important for them.
  There are two types of traditional Bunsetsu Identification methods:
  one is a method which uses handmade rules and the other is a method 
  which uses machine learning.
  The former has high accuracy rate, but there are some problems
  especially for Car-Multi-Media systems.
  For example, the method is not flexible because it needs fixed inputs,
  and the method needs a lot of efforts to keep identification rules
  because all rules are made by hand.
  The latter is robust for these problems, but the algorithms are
  much more complex to improve accuracy, so there are some problems for
  Car-Multi-Media systems.
  Therefore, we propose a new method that uses plural decision lists
  sequentially. The Decision List method is very simple, but
  it does not have very high accuracy rate. Then, we use not 'one'
  decision list but 'plural' decision lists 'sequentially'.
  We made some experiments using 10,000 sentences as a training corpus,
  and 10,000 sentences as a test corpus in Kyoto-University-Corpus.
  As the result, the accuracy rate was 99.38\%.
}

\ekeywords{bunsetsu identification, decision list}


\def\dfrac#1#2{}
\def\bm#1{}
\def\bold{}


\begin{document}
\thispagestyle{empty}
\maketitle



\section{はじめに}

近年の高度情報化の流れにより，種々の情報機器が自動車にも搭載されるようになり，さまざまな情報通信サービスが広がりつつある．
このような車載情報機器は，自動車に搭載するためにCPUの速度やRAM，ROMなどのメモリ容量の制約が非常に厳しく，また，開発期間がより短いことや保守管理の労力の低減も同時に求められている．

自動車内で提供される情報通信サービスには，交通情報，観光情報，電子メール，一般情報(例えばニュース)などが含まれるが，このような情報はディスプレイ上に文字で表示するよりも，音声により提供する方が望ましいとされている．

文字情報を音声に変換する技術の研究開発は進んでいるが，その合成音声の韻律は不自然という問題がある．
その原因として大きな割合を占めるものはポーズ位置の誤りであり，これを改善することにより韻律の改善が可能となる．

ポーズ位置を制御する手法として，係り受け解析を利用する方法が研究されている
\cite{Suzuki1995,Umiki1996,Sato1999,Shimizu1999}
．
これらの手法の中で，海木ら
\cite{Umiki1996}
や清水ら
\cite{Shimizu1999}
の手法は係り受けの距離が2以上の文節の後にポーズを挿入するという方法であり，その有効性がすでに示されている．
そしてこの手法を実現するためには，高精度な係り受け解析が必要となる．

文節まとめあげは図\ref{fig:文節まとめあげ}のように，形態素解析された日本語文を文節にまとめあげる処理のことをいう．
この処理は，日本語文の係り受け解析に重要となるものであるため，文節まとめあげの精度が高いことが望まれる
\footnote{
  形態素解析の精度は，既に十分高い精度を得られている．
  }
．
本研究はこのように，係り受け解析にとって重要な位置を占めている文節まとめあげに関する研究報告である．

\begin{figure}
  \begin{center}
    \begin{tabular}{cl}
      \fbox{日本語文}             & うまく日本語文を解析する．\\
      $\downarrow$                & 　　　　　　$\downarrow$\\
      \fbox{形態素解析}           & うまく, 日本語, 文, を, 解析, する, ．\\
      $\downarrow$                & 　　　　　　$\downarrow$\\
      \fbox{\bold 文節まとめあげ} & うまく｜日本語文を｜解析する．\\
      $\downarrow$                & 　　　　　　$\downarrow$\\
      \fbox{係り受け解析}         & うまく｜日本語文を｜解析する．\\[-2mm]
      ~                           & 　│　　　　│　　　　↑↑　　\\[-3mm]
      ~                           & 　│　　　　└────┘│　　\\[-3mm]
      ~                           & 　└──────────┘　　\\
    \end{tabular}
    \caption{文節まとめあげの処理}
    
    
    
    \label{fig:文節まとめあげ}
  \end{center}
\end{figure}

従来の文節まとめあげは，人手によりまとめあげ規則を書き下す方法と，機械学習によって得た統計情報を利用する方法の二通りに大きく分けられる．
人手により作成した規則を用いる方法としてはknp
\cite{knp2.0b4}
があり，高い精度を得られているが，人手により規則を保守管理することは容易ではなく，車載情報機器には不向きであるといえる．
機械学習を用いる方法としては村田らによる方法
\cite{Murata2000}
があるが，まとめあげのための情報を152通りも利用しているなど非常に複雑なアルゴリズムになっている．
このため新たに車載情報機器に実装するためには長い開発期間を要し，また規則の学習にも長い時間を要するため保守管理にも時間がかかり，さらにデータ量が膨大になるなどの問題も生じるため，車載情報機器には不向きであるといえる．

本研究ではこれらの問題を解決し，従来手法と比べて遜色ない精度を持ち，保守管理が容易でかつ車載情報機器の求める厳しい条件に適した，複数決定リストの順次適用による文節まとめあげという新しい手法を考案した．
そしてこの手法を用いて文節まとめあげを行ったところ，最高で99.38\%という非常に高い精度が得られたことを報告する．



\section{従来の研究}\label{sec:従来の研究}

文節まとめあげに関する従来の研究は，人手により文節まとめあげの規則を書き下す方法と，大規模コーパスから機械学習により得た統計情報を利用する方法の2種類に大きく分けられる．
これらの手法について以下で説明する．


\subsection{人手規則による文節まとめあげ}

人手により作成した文節まとめあげの規則を利用する最もよく知られているツールに，knpがある．
knpは文節に関する規則を人手で網羅することにより，99\%以上という非常に高精度な文節まとめあげを実現している．
knpの文節まとめあげの規則は906行のファイルに148種類の規則が記述されている
\footnote{
  knpは係り受け解析ツールであるが，係り受け解析の前に文節まとめあげを行っているため，その部分だけの数値を利用した．
  }
．
knpへの入力は形態素解析ツールjuman
\cite{juman3.5}
の出力に限定されており，文節まとめあげの規則もその形式に基づいて作成されている．
そのため，juman以外の形態素解析ツールの出力形式で利用するためには，規則をすべて書き直す必要がある．
人手規則による文節まとめあげは，このように多数の規則を人手で修正・追加を繰り返さなければならず，大きな労力が必要という問題がある．

しかしながら，車載情報機器の形態素解析部の出力形式はそれぞれ機種によって異なり，knpを車載情報機器に実装するためには規則をすべて書き直さなければならず，規則の保守管理も容易ではないため，問題が大きい．


\subsection{機械学習による文節まとめあげ}\label{subsec:機械学習手法}

人手規則による文節まとめあげの持つ問題に対処でき，最近最も盛んに研究されているのが，大規模コーパスから機械学習により得た統計情報を利用して文節まとめあげを行う手法である
\cite{Zhang1998,Asahara1999,Murata2000}
．
機械学習による手法は，大規模コーパスから文節区切りの規則を学習し，それにより文節まとめあげを行う．
そのため人手により規則を保守管理する必要がなく，また形態素解析ツールの出力形式に依存しないという利点がある
．

ただし機械学習の手法でも，学習用のコーパスを準備するという労力は必要である．
しかし，京大コーパス
\cite{KyotoCorpus}
などの大規模コーパスの構文情報を，形態素解析ツールの各出力形式に変換するのは，文節区切りの情報だけに限定するため容易である．
また人手により規則を作成する場合，プログラミングの専門的な知識が必要であるうえ，規則を改良するためには多くの試行錯誤が必要となる．
それに対し，コーパスの作成を行う場合は，コーパスの原文を形態素解析した結果がほぼ100\%に近い精度であり，それを文節に区切るだけでコーパスが得られるので特別に専門的知識は必要ない．
また，単にコーパスの量を増やすだけで精度を向上させることができる．
これらのことから，機械学習の手法は必要な労力が少ないといえる．

機械学習を用いる文節まとめあげには様々な種類があるが，これまでに最も精度の高い結果を得ているのが，村田らによる研究である
\cite{Murata2000}
．
村田らは，決定リストを用いた文節まとめあげの手法に排反な規則を組み合わせた手法を提案している．

決定リストは，規則をある優先順位を決めて1次元に並べたリストのことである．
そしてそのリストを順に探索して一番最初に適用された規則のみを用いて解析を行う手法である．
決定リストの要素としてよく用いられるのは，大規模コーパスから学習した結果であり，それを並べる優先順位としては確率が主に用いられる．

例えば，図\ref{fig:決定リスト}のような決定リストにより，「うまく, 日本語, 文, を, 解析, する, ．」という形態素解析済みの文を処理する方法について考える．
「うまく(形容詞)」と「日本語(名詞)」という情報から，「うまく」＋「日本語」という規則が最初に適用されるため，この部分は「文節に区切る」と決定される．
リストの下位に「形容詞」＋「名詞」は「文節に区切らない」という規則があるが，決定リストはリストの上位の要素から適用するため，この規則は無視される．

\begin{figure}
  \begin{center}
    \begin{tabular}{r@{ }c@{ }l|c|c}
      \multicolumn{3}{c|}{規則} & 確率 & 文節区切り\\
      \hline
      「うまく」 & ＋ & 「日本語」 & 100\% & 区切る\\
      「うまい」 & ＋ & 「日本語」 &  95\% & 区切らない\\
      & $\vdots$ & & $\vdots$ & $\vdots$\\
      「形容詞」 & ＋ & 「名詞」   &  70\% & 区切らない\\
      & $\vdots$ & & $\vdots$ & $\vdots$\\
    \end{tabular}
    \caption{決定リストの例}
    
    
    
    \label{fig:決定リスト}
  \end{center}
\end{figure}

村田らの手法は，文節に区切るあるいは区切らない確率が100\%である規則を排反な規則と呼び，決定リストの手法に排反な規則を組み合わせて文節まとめあげを行う．
確率が100\%でない規則を適用するのは，あらかじめ誤る可能性のあるものを利用するということになるため，高い精度を望むことができない．
そのため排反な規則を重要視しなければならない，と主張している．
図\ref{fig:村田手法}のような前後4つの形態素の4種類の情報を152種類組み合わせて，それにより決定リストを作成する．
決定リストの要素を並べる順序は，まず確率でソートして，同じ確率のものは頻度順にソートする．

\begin{figure}
  \begin{center}
    \begin{tabular}{cccc}
      二つ前 & 一つ前  & 一つ後 & 二つ後\\
      \hline
            & 情報A & 情報A &\\
      情報A & 情報B & 情報B & 情報A\\
      情報B & 情報C & 情報C & 情報B\\
            & 情報D & 情報D &\\
    \end{tabular}

    素性 
    $ \cdots ~~ \left(
      \begin{array}{ll}
        情報A: & 品詞\\
        情報B: & 品詞＋品詞細分類\\
        情報C: & 品詞＋品詞細分類＋意味情報\\
        情報D: & 品詞＋品詞細分類＋意味情報＋単語表記\\
      \end{array}
      \right)
    $
    \caption{村田らの手法で用いる情報}
    
    
    
    \label{fig:村田手法}
  \end{center}
\end{figure}

例えば，ある形態素の隙間の文節区切りを決定する時に図\ref{fig:村田リスト}のような規則のパターンが一致して適用可能である場合，決定リストの手法であれば，最初の規則Aが適用されるため「文節に区切らない」と決定される．
しかし規則B，C，Dを見ると，各規則ごとの頻度は規則Aと比べると小さいが，それぞれの頻度を足しあわせると規則Aの頻度よりも大きい．
そのため，規則B，C，Dに従って「文節に区切る」と決定する方が望ましいと考えられる．
このように，排反な規則，つまり確率が100\%となる規則の頻度を足しあわせ，その頻度により文節区切りの決定を行う．

\begin{figure}
  \begin{center}
    \begin{tabular}{cccrrc}
      \hline
      規則  & パターン  &               & 確率 & 頻度 & 文節区切り\\
      \hline
      A & a & $\Rightarrow$ & 100\%  & 34  & 区切らない\\
      B & b & $\Rightarrow$ & 100\%  & 33  & 区切る\\
      C & c & $\Rightarrow$ & 100\%  & 25  & 区切る\\
      D & d & $\Rightarrow$ & 100\%  & 19  & 区切る\\
      E & e & $\Rightarrow$ & 81.3\% & 123 & 区切る\\
      F & f & $\Rightarrow$ & 76.9\% & 13  & 区切る\\
      G & g & $\Rightarrow$ & 57.4\% & 540 & 区切らない\\
      $\vdots$ & $\vdots$\\
    \end{tabular}
    \caption{村田らの手法の説明}
    
    
    
    \label{fig:村田リスト}
  \end{center}
\end{figure}

この手法による文節まとめあげは，最高で99.17\%という高い精度を得ている．
しかしこの手法は，図\ref{fig:村田手法}のような情報の組み合わせが152種類もある．
京大コーパス中のデータは，1文平均約23の形態素の隙間があるため，1つの形態素の隙間に対して152種類の組み合せを考慮すると，1文あたり$152\times23=約3500回$もの処理をしなければならない．
このようにアルゴリズムが複雑なため，新たに車載情報機器に実装するためには長い開発期間を要し，また規則の学習に長い時間を要するため保守管理にも時間がかかり，さらにデータ量が膨大になるなど様々な問題がある．
そのため，車載情報機器には不向きであるといえる．

\ref{sec:文節まとめあげ}章では，これらの問題を解決するために考案した新しい手法について述べる．



\section{本研究の文節まとめあげの手法}\label{sec:文節まとめあげ}

\subsection{複数決定リストの順次適用による文節まとめあげ}\label{subsec:複数決定リスト}

本研究では，従来手法の問題点を解決するために次の点に着目した．

\begin{itemize}
\item 学習が容易で用いる情報の数が少ないこと
\item 学習結果を利用して文節をまとめる方法が従来手法より簡明であること
\item 精度が従来手法と同程度かそれ以上となること
\end{itemize}
これらを実現するために，{\bold 複数決定リストの順次適用による文節まとめあげ}という新しい手法を考案した．

機械学習を用いる従来手法では，大規模コーパスから得られた様々なn-gram(主に2-gramから4-gram)が利用されている．
本手法では，1つの形態素の隙間に対して6種類のn-gramのそれぞれの決定リストだけを考慮するという非常に簡明な方法を用いる．
具体的には，品詞，単語表記，品詞細分類，単語表記＋品詞の4種類の形態素2-gramと，品詞，単語表記の2種類の形態素3-gramを要素とする決定リストを利用する
\footnote{
  品詞細分類の3-gramと単語表記＋品詞の3-gramは，予備実験を行ったところ結果に変化がなかったため用いなかった．
  }
(図\ref{fig:本手法})．
以下では，これらのn-gramを要素とする決定リストを，n-gramリストと呼ぶ．
文節まとめあげの処理は，村田らと同様に形態素解析済みのテキストに対して行い，形態素の隙間ごとにその前後の形態素の情報からn-gramリストを調べて文節を区切るか区切らないかを決定する処理とした．

\begin{figure}
  \begin{center}
    \begin{tabular}{l|ccccc}
      &
      二つ前   &     & 一つ前         &     & 一つ後\\
      \hline
      単語表記 2-gram &
      ~        &     & 単語表記       & --- & 単語表記\\
      品詞 2-gram &
      ~        &     & 品詞           & --- & 品詞\\
      品詞細分類 2-gram &
      ~        &     & 品詞細分類     & --- & 品詞細分類\\
      単語表記＋品詞 2-gram &
      ~        &     & 単語表記＋品詞 & --- & 単語表記＋品詞\\
      単語表記 3-gram &
      単語表記 & --- & 単語表記       & --- & 単語表記\\
      品詞 3-gram &
      品詞     & --- & 品詞           & --- & 品詞\\
    \end{tabular}
    \caption{本手法で用いる情報}
    
    
    
    \label{fig:本手法}
  \end{center}
\end{figure}

例えば，2-gramの場合には$Y$，$Z$という連続する2つの単語の$Y$と$Z$の間，3-gramの場合には$X$，$Y$，$Z$という連続する3つの単語の$Y$と$Z$の間に注目し，その間の文節区切りを次のように決定する
\footnote{
  3-gramを考慮する場合，$X$，$Y$，$Z$という3つの単語の$X$と$Y$の間も考慮する必要があると思われるが，本手法は処理が簡明であることを最大の目標としたため，ここでは考慮しない．
  }
．

\begin{enumerate}
\item $X$，$Y$，$Z$の形態素を得る．
\item 図\ref{fig:本手法}の6種類のn-gramリストを順番に調べる
  \footnote{
    n-gramリストの適用順は\ref{sec:実験}章の実験で最適化を行う．
    }
  ．
  \begin{enumerate}
  \item n-gramリスト中に規則が見つかり，文節に区切る数が区切らない数よりも多い場合には区切りを入れ，少ない場合には区切らないこととする．
    この段階で$Y$と$Z$の文節区切りを確定し，処理を終了する．
  \item n-gramリスト中に規則が見つからない場合，または文節に区切る数と区切らない数が等しい場合には，次のn-gramリストを調べる．
  \end{enumerate}
\item 6種類すべてのn-gramリストを調べた結果，文節に区切るか区切らないか確定しない場合，デフォルト処理として文節に区切るものとする
\footnote{
  デフォルト処理を文節に区切らないとした場合は，予備実験により精度が下がることがわかったため，文節に区切るものとした．
  }
．
\end{enumerate}

本手法の最大の特徴は，このように{\bold 6種類のn-gramリストを順番に調べるだけで文節まとめあげを行う}，という非常に簡明な点である．
村田らの手法では\ref{subsec:機械学習手法}節で示したように，1つの形態素の隙間に対して約3500回もの処理をしなければならない．
しかし，本手法では最大で$6\times23=138回$の処理でよいため，村田らの手法と比べて約$\dfrac{1}{25}$の処理量で文節まとめあげを行うことができる．


\subsection{n-gramリストの取得方法}\label{subsec:n-gramリスト取得}

各n-gramリストの要素は，大規模コーパスから機械学習によって得る．
本研究では，学習コーパスとして京大コーパス
\cite{KyotoCorpus}
を利用した．
京大コーパスにはあらかじめ詳細な形態素の情報と文節区切りの情報が付与されているので，形態素の隙間ごとに文節に区切る数と区切らない数を数えて，それを確率の高い順に並べて保持する．
ただし，確率には文節に区切る確率か文節に区切らない確率の2種類があるが，高い方の確率を基準としてリストに並べた．
つまり，リストの最下位は確率50\%となる．

以上のようにして得られた品詞2-gramの学習結果の決定リストの例を図\ref{tab:学習結果例}に示す．

\begin{figure}
  \begin{center}
    \begin{tabular}{rr@{ }c@{ }lc}
      確率 & \multicolumn{3}{c}{規則} & 区切り\\
      \hline
      100\% & 「連体詞」 & ＋ & 「連体詞」 & 区切る\\
      100\% & 「連体詞」 & ＋ & 「名詞」   & 区切る\\
      $\vdots$ & & $\vdots$ & & $\vdots$\\
      55\% & 「特殊」 & ＋ & 「特殊」   & 区切る\\
      52\% & 「特殊」 & ＋ & 「接続詞」 & 区切らない\\
    \end{tabular}
    \caption{品詞2-gramの決定リスト}
    
    
    
    \label{tab:学習結果例}
  \end{center}
\end{figure}



\section{実験と考察}\label{sec:実験}

\subsection{実験方法}\label{subsec:実験方法}

本手法の性能を評価するため，評価システムを作成して以下の実験を行った．

\begin{enumerate}
\item 6種類のn-gramリストを適用する数や順序を変化させる実験
\item 学習コーパスの量を変化させる実験
\item 学習結果の一部分だけ利用する実験
\item 比較実験
\item n-gramや条件の追加実験
\end{enumerate}

1.,3.,4.,5.の実験の学習コーパスには，京大コーパスの最初の10000文を利用し，2.の実験には，京大コーパスを最初から1000文ずつ10000文まで変化させて利用した．
また，すべての実験のテストコーパスは京大コーパスの10001文目からの残り9956文を利用した．

学習コーパス，テストコーパスの内容は表\ref{tab:京大コーパス}の通りである．

\begin{table}
  \begin{center}
    \caption{京大コーパスの内容}
    
    
    
    \label{tab:京大コーパス}
    \begin{tabular}{l||r|r}
      \hline
      & 学習コーパス   & テストコーパス\\
      \hline
      \hline
      文の数           & 10,000  &   9,956\\
      \hline
      形態素の隙間の数 & 240,682 & 227,053\\
      \hline
      文節区切りの数   &  98,395 &  93,971\\
      \hline
    \end{tabular}
  \end{center}
\end{table}


\subsection{評価基準}\label{subsec:評価基準}

本研究の文節まとめあげの評価基準には，村田らが用いたF値を採用した．
F値はF-measureを意味し，適合率と再現率の調和平均から得られる．

適合率と再現率は，評価システムの出力とテストコーパスの内容を比較して，次のように計算する．
\begin{eqnarray}\label{eq:Eval}
  \begin{array}{rcl}
    適合率 & = & \dfrac{right}{result}\\[4mm]
    再現率 & = & \dfrac{right}{correct}
  \end{array}
\end{eqnarray}
ここで，$result$を評価システムが文節に区切った数，$correct$をテストコーパスで文節に区切られている数(正解の区切り)，$right$を両者の文節区切りが一致している数とする．
これらの調和平均を以下のように計算すると，F値が得られる．
\begin{displaymath}
  F = \left(\dfrac{\dfrac{1}{適合率}+\dfrac{1}{再現率}}{2}\right)^{-1}\times100(\%)
\end{displaymath}

例えば，次のようなテストコーパスの文節区切りと評価システムの出力がある時のF値の計算例を示す．
文中「｜」により文節の区切りを表すものとする．

\begin{quote}
  {\bold テストコーパス}：

  \hspace{10mm}昨日｜政府　は　，｜国会　移転　の｜候補地　を｜発表　した　．

  {\bold 評価システム}　：

  \hspace{10mm}昨日　政府　は　，｜国会｜移転　の｜候補地　を｜発表｜した　．

  \begin{displaymath}
    right=3,~~result=5,~~correct=4
  \end{displaymath}
  \begin{displaymath}
    適合率=\dfrac{3}{5},~~再現率=\dfrac{3}{4}
  \end{displaymath}
  \begin{displaymath}
    F=\dfrac{2}{\dfrac{5}{3}+\dfrac{4}{3}}\times100=66.67(\%)
  \end{displaymath}
\end{quote}


\subsection{実験結果}\label{subsec:実験結果}

\subsubsection{n-gramリストを用いる数や適用する順序を変化させる実験}\label{subsubsec:n-gramの数}

6種類のn-gramリストを用いる時に，n-gramリストを用いる数や適用する順序により精度が変化すると考えられる．
そこで，6種類のn-gramリストを用いる数や順序を変化させて実験したところ，図\ref{fig:n-gramの数}のような結果を得た．
ただし図中，n-gramリストを用いた数が1,2,3,4は4種類の2-gramリストだけを用いた結果で，数が5,6はさらに2種類の3-gramリストを加えた結果である．
n-gramリストを用いた数ごとのF値は，その数における最も精度の高かった順序の結果のみを示した．
また，それぞれn-gramリストを1つだけ用いた結果を表\ref{tab:n-gram1つ}に，最も精度の高かった時のn-gramリストの適用順を表\ref{tab:適用順}に示した．
表\ref{tab:n-gram1つ}中のデフォルト処理とは，n-gramリスト中で規則を見つけられなかった場合に適用する処理のことを表す．
本手法ではデフォルト処理として「区切る」を用いるが，比較のため「区切らない」場合の精度も示した．
また，表\ref{tab:n-gram1つ}中の被覆率は，規則を適用できた割合を示す．

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=graph-1-10000-jis.eps,scale=0.8}
    \end{epsf}
    \begin{draft}
    \atari(216,152,1bp)
    \end{draft}
    \caption{n-gramリストを用いる数や順序による精度の変化}
    
    
    
    \label{fig:n-gramの数}
  \end{center}
\end{figure}

\begin{table}
  \begin{center}
    \caption{各n-gramリストの精度}
    
    
    
    \label{tab:n-gram1つ}
    \begin{tabular}{l|c|c|c|c|c|c|c|}
      ~                    & \multicolumn{3}{c|}{デフォルト処理：区切る}
      &                      \multicolumn{3}{c|}{デフォルト処理：区切らない}\\
      \cline{2-7}
      n-gramリスト         & 適合率  & 再現率  & F値
      &                      適合率  & 再現率  & F値     & 被覆率\\
      \hline
      品詞2-gram           & 92.91\% & 96.52\% & 94.68\%
      &                      92.91\% & 96.51\% & 94.68\% & 99.99\%\\
      単語表記2-gram       & 63.08\% & 99.79\% & 77.30\%
      &                      99.06\% & 55.20\% & 70.89\% & 62.08\%\\
      品詞細分類2-gram     & 96.73\% & 99.48\% & 98.08\%
      &                      98.27\% & 98.08\% & 98.17\% & 98.88\%\\
      単語表記＋品詞2-gram & 62.78\% & 99.95\% & 77.12\%
      &                      99.51\% & 54.90\% & 70.76\% & 61.51\%\\
      品詞3-gram           & 86.38\% & 96.09\% & 90.97\%
      &                      94.66\% & 93.78\% & 94.21\% & 95.49\%\\
      単語表記3-gram       & 44.78\% & 99.96\% & 61.85\%
      &                      99.84\% & 11.70\% & 20.95\% & 21.73\%\\
    \end{tabular}
  \end{center}
\end{table}

\begin{table}
  \begin{center}
    \caption{n-gramリストの最適な適用順}
    
    
    
    \label{tab:適用順}
    \begin{tabular}{c|l}
      \begin{minipage}[b]{5zw}n-gram\\リストの数\end{minipage}  &\\
      \hline
      1 & 品詞細分類 2-gram\\
      2 & 品詞細分類 2-gram → 品詞 2-gram\\
      3 & 単語表記＋品詞 2-gram → 品詞細分類 2-gram → 品詞 2-gram\\
      4 & 単語表記＋品詞 2-gram → 単語表記 2-gram → 品詞細分類 2-gram → 品詞 2-gram\\
      5 &
      \begin{tabular}{c}
        単語表記 3-gram → 単語表記＋品詞 2-gram → 単語表記 2-gram\\
        → 品詞細分類 2-gram → 品詞 2-gram
      \end{tabular}\\
      6 &
      \begin{tabular}{c}
        単語表記 3-gram → 単語表記＋品詞 2-gram → 単語表記 2-gram\\
         → 品詞細分類 2-gram → 品詞 3-gram → 品詞 2-gram\\
      \end{tabular}\\
    \end{tabular}
  \end{center}
\end{table}

この結果から，使用するn-gramリストの数が多いほど精度が上がるが，3つ以上のn-gramリストを用いるとほぼ精度が飽和することがわかった．


\subsubsection{学習コーパスの量を変化させる実験}\label{subsubsec:学習コーパス}

学習コーパスの量を変化させた時に，精度がどのように変化するか調べた．
学習コーパスは京大コーパスの最初から1000文ずつ増やし10000文まで変化させ，テストコーパスは京大コーパスの10001文目からの9956文で固定して実験を行った．
その結果を図\ref{fig:学習量}に示した．
図中，4種類は2-gramリストのみ，6種類はすべてのn-gramリストを利用した時の結果である
\footnote{
  適用順は表\ref{tab:適用順}の結果を利用している．
  }
．

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=graph-2-10000-jis.eps,scale=0.8}
    \end{epsf}
    \begin{draft}
    \atari(232,152,1bp)
    \end{draft}
    \caption{学習コーパスの量による精度の変化}
    
    
    
    \label{fig:学習量}
  \end{center}
\end{figure}

この結果から，学習量が増すにつれて精度が向上することがわかった．
しかし，10000文学習した段階でほぼ飽和していると考えられる．


\subsubsection{学習結果の一部分だけ利用する実験}\label{subsubsec:一部利用}

学習をした結果は確率順に並べられており，リストの上位は確率が高いので確信度が高いといえ，逆にリストの下位は確率が50\%に近いので確信度が低いといえる．
そこで，確率の高いものだけを利用すると精度がどのように変化するか調べた．
この実験で調べる内容は，車載情報機器はメモリ容量の要求が厳しいため，学習結果のデータ量はできるだけ少ないことが求められるが，データ量を減らす時にどれだけの精度が得られるか，ということである．

学習結果を利用する割合を，10000文を学習した各n-gramリストの上位から10\%，20\%と10\%ずつ増やし100\%まで変化させて実験を行ったところ，図\ref{fig:一部利用}の結果を得た．
図中，4種類は2-gramリストのみ，6種類はすべてのn-gramリストを利用した時の結果である

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=graph-3-10000-jis.eps,scale=0.8}
    \end{epsf}
    \begin{draft}
    \atari(232, 168,1bp)
    \end{draft}
    \caption{学習結果の一部利用による精度の変化}
    
    
    
    \label{fig:一部利用}
  \end{center}
\end{figure}

この結果，およそ60\%のデータを利用すれば100\%利用した時とほぼ同等の精度を得られることがわかった．

以上の
実験から，車載情報機器が要求する速度・データ容量などに柔軟に対応できることを示すことができた．


\subsubsection{比較実験}\label{subsubsec:比較実験}

本手法は，複数の決定リストを順次適用するというものであるが，これらの複数の決定リストを大きな一つの決定リストにまとめて考えると，n-gramの種類(素性)によりソートしてから確率でソートしたリストと考えることもできる．
このソートの順序は村田らの提案する手法とは逆で，村田らの手法では確率，頻度，素性という順序でソートしたリストを用いている．
そこで，本手法，村田らの手法，決定リストの手法の3手法を比較するために，本手法の決定リストを大きな1つの決定リストにまとめ，それを用いて比較実験を行った．
決定リストの手法では，確率，頻度，素性という順序でソートして用い，村田らの手法では，この決定リスト中の同じ確率となる規則の各頻度を足しあわせた結果により文節の区切りを判定した．
これらの実験結果を表\ref{tab:比較実験}に示した．

\begin{table}
  \begin{center}
    \caption{比較実験の結果}
    
    
    
    \label{tab:比較実験}
    \begin{tabular}{l|c|c|c|c}
      & n-gramリストの数 & 適合率  & 再現率  & F値\\
      \hline
      本手法         & 4 & 98.92\% & 99.41\% & 99.16\%\\
      本手法         & 6 & 99.07\% & 99.38\% & 99.23\%\\
      決定リスト手法 & 4 & 98.88\% & 99.16\% & 99.02\%\\
      決定リスト手法 & 6 & 99.07\% & 99.16\% & 99.12\%\\
      村田手法       & 4 & 98.90\% & 99.18\% & 99.04\%\\
      村田手法       & 6 & 99.10\% & 99.18\% & 99.14\%\\
    \end{tabular}
  \end{center}
\end{table}

この結果から，同じ評価基準で実験を行った場合には，本手法が最も優れていることが示された．


\subsubsection{n-gramや条件の追加実験}\label{subsubsec:追加実験}

本手法の最大の特徴は，非常に簡明な方法で充分な精度を得られることである．
非常に簡明であるので，従来手法の長所だけを組み合わせることも容易である．
そのことを示すため，京大コーパスの最初の10000文を学習コーパス，残りの9956文をテストコーパスとして以下のような2種類の追加実験を行った．

\begin{itemize}
\item 1-gramを利用する方法

  2-gramや3-gramだけでなく，1-gramが非常に有効となる場合も考えられる．
  例えば，読点や区点は前の単語に必ずつながり，次の単語とは必ず区切れる．
  そこで，6種類のn-gramリストに加えて1-gramリストを用いて実験を行ったところ，F値が99.31\%に上昇した．

\item 排反な規則を用いる方法

  村田らにより，排反な規則を用いる手法が高い精度を得られると報告されている
  \cite{Murata2000}
  ．
  6種類のn-gramリストの排反な規則を考慮して実験を行ったところ，F値が99.26\%に上昇した．

\end{itemize}

上記2種類の手法をすべて組み合わせて実験を行ったところ，村田らの手法よりも簡明であるが，99.38\%という非常に高いF値を得られた．



\subsection{処理速度}\label{subsec:処理速度}

n-gramリストの学習と評価システムの処理速度の計測を行った．

\ref{subsec:n-gramリスト取得}節の図\ref{tab:学習結果例}で示した品詞2-gramの学習に関しては，学習プログラムの最適化は全く行わなかったが，計算機にSun Ultra1 133MHzを，プログラム言語にPerlを用いたところ，10000文の学習に要した時間は58秒(1文あたり5.8ms)と非常に高速であった．
また，6種類のn-gramリストすべての学習に要した時間も，216秒(1文あたり21.5ms)と高速であった．

6種類のn-gramリストを学習した結果は約41万規則で，圧縮を全く行わずに図\ref{tab:学習結果例}のようにテキストベースでデータを保持すると約14.4MB，圧縮を行うと約2MBとなった．

また評価システムについても同様にアルゴリズムの最適化を全く行わなかったが，\ref{subsubsec:n-gramの数}節の実験に関して，計算機にSun Ultra1 133MHzを，プログラム言語にPerlを用いたところ，4種類のn-gramリストを用いた処理に要した時間は225秒(1文あたり22.6ms)，6種類のn-gramリストの場合には253秒(1文あたり25.4ms)と非常に高速であった．



\subsection{実験のまとめ}\label{subsec:まとめ}

以上の実験の結果を図\ref{fig:まとめ}のグラフにまとめた．
比較のため，knp2.0b4の精度とknp2.0b6
\cite{knp2.0b6}
の精度も示した．
knp2.0b6の精度が非常に高いのは，京大コーパスがknp2.0b4の出力を人手で修正して作成されたものであり，その修正結果をさらにknpの文節まとめあげ規則に反映したためである．
つまり，knp2.0b6の結果はクローズドテストにほぼ等しい．

\begin{figure}
  \begin{center}
    \begin{epsf}
    \epsfile{file=all-result-jis.eps,scale=0.66}
    \end{epsf}
    \begin{draft}
    \atari(404, 145,1bp)
    \end{draft}
    \caption{すべての実験の結果}
    
    
    
    \label{fig:まとめ}
  \end{center}
\end{figure}

本手法が従来の手法よりも優れていることは，\ref{subsubsec:比較実験}節の比較実験により示された．
また，本手法が非常に簡明であること，車載情報機器への実装を最大の目標としていることを考慮すると，本手法は非常に優れているといえる．


\subsection{考察}\label{subsec:考察}

本手法のように非常に簡明な方法で99.38\%という高い精度を得られる理由と，本手法のロバスト性について，\ref{subsec:実験結果}節で行った実験の結果に基づいて考察する．

\ref{subsubsec:n-gramの数}節の実験で，6種類のn-gramリストを適用する順序で最も高い精度を得られたのは，表\ref{tab:適用順}に示したように，

\begin{center}
  単語表記 3-gram $\rightarrow$ 単語表記＋品詞 2-gram $\rightarrow$ 単語表記 2-gram

  $\rightarrow$ 品詞細分類 2-gram $\rightarrow$ 品詞 3-gram $\rightarrow$ 品詞 2-gram
\end{center}
であった．
これらのn-gramリストをそれぞれ1つだけ用いて文節まとめあげを行った場合の精度は，表\ref{tab:n-gram1つ}に示したとおりである．
\ref{sec:文節まとめあげ}章で述べたように，本手法では文節に区切るか区切らないか決定できない場合のデフォルト処理を「文節に区切る」としているが，「文節に区切らない」とすると，それぞれの精度は表\ref{tab:n-gram1つ}のようになる．

本手法の評価基準であるF値は，式\ref{eq:Eval}に示すように文節区切りを基準としている．
そのため，デフォルト処理を文節に区切らないことにすると，得られる適合率は，n-gramリストにより「文節に区切る」と確定した個所が正しい区切りかどうか，という正確な値となる．

この適合率が，表\ref{tab:n-gram1つ}の右側の中で最も注目すべき値である．
この表から，先に適用されるn-gramリストほど適合率が高いことがわかる．
つまり本手法の文節まとめあげ処理は次のように考えることができる．
1つの形態素の隙間の文節区切りを確定するために，適合率の最も高いn-gramリストを最初に参照し，その中で見つけられれば最も高い適合率で文節区切りを確定できる．
しかし，適合率が高いと再現率は低くなるため，規則を適用できる個所は少なくなる．
そこで，そのn-gramリスト中で規則を見つけられなかった個所は，次に適合率の高いn-gramリストにより区切りを決定する．
同様にして適合率の高い順にn-gramリストを調べることで，最終的に高い精度での文節まとめあげが可能になる(図\ref{fig:本手法の概念})．

\begin{figure}
  \begin{center}
    \begin{tabular}{ccl}
      \fbox{1番目に高い適合率のn-gramリスト} & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      \fbox{2番目に高い適合率のn-gramリスト} & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      $\cdots$                               & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      \fbox{最も低い適合率のn-gramリスト}    & → 適用 & → 確定\\
      ↓\\
      非適用\\
      ↓\\
      確定\\
      (文節に区切る)\\
    \end{tabular}
    \caption{本手法の処理の概念図}
    
    
    
    \label{fig:本手法の概念}
  \end{center}
\end{figure}

低い適合率のn-gramリストを最初に適用して確定を行えば，その低い適合率が最終的な精度に大きく影響することは容易に想像できる．
そのため，高い適合率のn-gramリストから順に適用するということは理想的な処理であるといえる．
このことは，村田らのが100\%の確率である排反な規則を最優先に考慮するという考えを拡張してより柔軟にした，と考えることもできる．

ただし，先に適用されるn-gramリスト中に51\%の確率の規則が存在する場合には，たとえ後に適用されるn-gramリスト中に100\%の確率の規則が存在しても，先のn-gramリストにより文節区切りが確定される．
本手法はいかに簡明に文節まとめあげを行うか，ということを目標としていたため，この点についての考慮は行わなかった．
しかし，さらに精度を向上させるためには，このような点も考慮して，決定リストの要素を並べる順序をどのようにするのが最適であるか，より詳しく調べる必要があると思われる．

次に，本手法のロバスト性について考察する．
本手法では，入力される形態素解析済みのデータは100\%正しいものとして扱っているが，実際には形態素解析ツールの精度は100\%ではない．
そこで，形態素解析ツールの出力に誤りがある場合に，本手法の文節まとめあげの精度がどのように変化するか調べた．

形態素解析ツールの出力の誤りには主に，付与する品詞の誤りや形態素の区切り誤りがある．
形態素の区切りの誤りには，一つの形態素を複数に区切る誤りや，複数の形態素を一つのまとめる誤りなどがあるため非常に複雑であり，ここでは品詞の誤りがある場合についてだけ考える．
ある形態素に品詞の誤りがある場合，3-gramを用いる時はその前後3個所の文節区切りに影響を及ぼし，2-gramを用いる時はその前後2個所の文節区切りに影響を及ぼす．
そのため，品詞の誤りが1つ生じた場合に必ず文節区切りを誤ると仮定すると，形態素解析から文節まとめあげに至る間に誤りが増加する割合は，表\ref{tab:n-gram1つ}の被覆率と表\ref{tab:適用順}の適用順から，
\begin{eqnarray*}
  誤りの増加率 & = & 3 \times 21.73\% + 2 \times ( 100\% - 21.73\% ) \times 61.51\% + \cdots\\
  & = & 2.49
\end{eqnarray*}
と求められる．
つまり，形態素解析が99.0\%(誤りが1\%)の精度であるとすると，本手法の精度は99.38\%-2.49\%=96.89\%ということになる．

従来の研究では，このような値が示されていないために単純にロバスト性を比較することはできない．
しかし，形態素解析を誤ると必ず文節まとめあげを誤ると仮定していることや，他の手法が3-gram以上の情報も用いているためより多くの誤りを引き起こす可能性があることを考えると，本手法は従来の手法よりロバストであると考えられる．



\section{おわりに}

本研究で提案した文節まとめあげの手法は，車載情報機器の求める条件を満たすよう考案したものであり，複数の決定リストを順次適用して文節の区切りを行うだけ非常に簡明かつ高速である．
それにもかかわらず，従来の手法と比較してより高い精度を得られることが示された．
また，本手法は非常に簡明であるため，他の手法の長所のみを導入することが容易である．
そのことを1-gramや排反な規則を組み合わせることにより示した．

今後は，本手法を係り受け解析の技術と融合させ，より高精度な係り受け解析の技術に応用し，音声合成の品質の向上に貢献しようと考えている．



\bibliographystyle{jnlpbbl}
\bibliography{jpaper}

\begin{biography}
\biotitle{略歴}
\bioauthor{白木 伸征}{
  1997年京都大学工学部電気系学科卒業．
  1999年同大学院修士課程修了．
  同年，株式会社豊田中央研究所に入社，現在に至る．
  自然言語処理，ヒューマンインタフェースの研究に従事．
}
\bioauthor{梅村 祥之（正会員）}{
  1979年岐阜大学工学部電子工学科卒業．
  1981年名古屋大学大学院工学研究科修士課程修了．
  同年，東京芝浦電気（株）入社．
  1988年（株）豊田中央研究所入社．
  自然言語処理，音響・音声処理，画像処理の研究に従事．
}
\bioauthor{原田 義久}{
  1973年名古屋工業大学計測工学科卒業，
  1975年東京工業大学制御工学専攻修士課程修了，
  工学博士（京都大学），
  同年（株）豊田中央研究所入社，
  2000年名古屋商科大学教授，IEEE ICCD'84優秀論文賞，
  IJCNN Best Presentation Award受賞．
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}
