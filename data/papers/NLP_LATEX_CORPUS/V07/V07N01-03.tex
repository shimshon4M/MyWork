




\documentstyle[epsf,jnlpbbl]{jnlp_j}

\setcounter{page}{31}
\setcounter{巻数}{7}
\setcounter{号数}{1}
\setcounter{年}{2000}
\setcounter{月}{1}
\受付{1999}{6}{14}
\採録{1999}{10}{18}

\setcounter{secnumdepth}{2}

\title{機械学習手法を用いた名詞句の指示性の推定}
\author{村田 真樹\affiref{CRL} \and 内元 清貴\affiref{CRL} \and 馬 青\affiref{CRL} \and 井佐原 均\affiref{CRL}}

\headauthor{村田 真樹・内元 清貴・馬 青・井佐原 均}
\headtitle{機械学習手法を用いた名詞句の指示性の推定}

\affilabel{CRL}{郵政省 通信総合研究所}
{Communications Research Laboratory, Ministry of Posts and Telecommunications}

\jabstract{
言語処理の研究には名詞句の指示性の推定という問題がある．
名詞句の指示性とは，名詞句の対象への指示の仕方のことで，
指示性としては総称名詞句，定名詞句，不定名詞句の三種類が主に設けられている．
この指示性は，日英機械翻訳の冠詞生成や同一名詞句の照応解析に役に立つ．
名詞句の指示性の先行研究では，
表層の手がかり語を利用した規則を利用して解析し，
複数の規則が競合した場合は規則により各指示性に得点を付与し
合計点の最も大きい指示性を解としていた．
この規則に記述している得点は人手で付与しており，
人手の介入が大きい方法となっていた．
本稿では，この人手で付与していた得点部分を
機械学習の手法で自動調節することで，
人手のコストを削減することに成功したことについて記述している．
}

\jkeywords{名詞句，指示性，最大エントロピー法，パラメータ調整}

\etitle{Machine learning approach to estimating\\ a referential property of a noun phrase}
\eauthor{Masaki Murata\affiref{CRL} \and Kiyotaka Uchimoto\affiref{CRL} \and Qing Ma\affiref{CRL} \and Hitoshi Isahara\affiref{CRL}} 

\eabstract{
The referential properties of noun phrases are useful for 
article generation in Japanese-English machine translation and 
in anaphora resolution in Japanese same noun phrases 
and are generally classified into 
generic noun phrases, definite noun phrases and indefinite noun phrases. 
In the previous work, 
an estimation of referential properties was done by 
developing rules that used clue words. 
If two or more rules were in conflict with each other, 
the category having the maximum total score given by the rules 
was selected as the desired category. 
The score given by each rule was established by hand, 
so the manpower cost was high. 
This paper describes a machine learning method 
that reduces the amount of manpower needed to adjust these scores. 
}

\ekeywords{Noun phrase, Referential property, Maximum entropy method, Parameter tuning}

\begin{document}
\maketitle


\section{はじめに}\label{intro}

言語処理の研究に名詞句の指示性の推定という問題がある\cite{murata_ref_nlp}．
名詞句の指示性とは，名詞句の対象への指示の仕方のことであり，
主に以下の三つに分類される．
(指示性の詳細な説明は次節で行なう．)
\begin{itemize}
\item 
  不定名詞句 -- その名詞句の意味する類の不特定の成員を意味する．

  (例文) \underline{犬}が三匹います．
\item 
  定名詞句 -- 文脈中唯一のものを意味する．

  (例文) \underline{その犬}は役に立ちます．
\item 
  総称名詞句 -- その名詞句の類すべてを意味する．

  (例文) \underline{犬}は役に立つ動物です．

  (この例文の「犬」は犬一般を意味しており，
  総称名詞句に分類される．)
\end{itemize}


この指示性というものを，
日本語文章中にある各名詞句について推定する
ことは，(i)日英機械翻訳における冠詞の生成の研究や，
(ii)名詞句の指示先などを推定する照応解析の研究に役に立つ．

\begin{itemize}
\item[(i)] 冠詞生成の研究

冠詞生成の研究では，
不定名詞句と推定できれば
単数名詞句なら不定冠詞をつけ，複数名詞句なら冠詞はつけないと
わかるし，定名詞句と推定できれば定冠詞をつければよいと
わかるし，総称名詞句の場合ならばtheをつける場合もaをつける場合も
複数形にする場合もあり複雑であるが
総称名詞句用の冠詞生成の方法に基づいて生成すればよい
とわかる\footnote{名詞句の指示性を冠詞の生成に
実際に用いている研究としては，Bondのもの\cite{Bond_94}がある．}．
例えば，
\begin{equation}
\mbox{\underline{本}\.と\.い\.う\.の\.は人間の成長に欠かせません．}
  \label{eqn:book_hito}
\end{equation}
の「本」は総称名詞句であるので
英語では``a book''にも``books''にも
``the book''にも訳すことができるとわかる．
また，
\begin{equation}
\mbox{\.昨\.日\.僕\.が\.貸\.し\.た\underline{本}は読みましたか．}
  \label{eqn:book_boku}
\end{equation}
の「本」は定名詞句であるので，英語では ``the book''と訳す
ことができるとわかる．

\item[(ii)] 照応解析の研究

名詞句の指示先などを推定する照応解析の研究では，
定名詞句でなければ前方の名詞句を指示することができない
などがわかる\cite{murata_noun_nlp}．
例えば，
\begin{equation}
  \begin{minipage}[h]{6.5cm}
\vspace*{0.2cm}
\underline{本}をお土産に買いました．

\underline{本}\.と\.い\.う\.の\.は人間の成長に欠かせません．
\vspace*{0.2cm}
  \end{minipage}
  \label{eqn:book_miyage}
\end{equation}
の例文では，二文目の「本」は総称名詞句であるので
一文目の「本」を指示することはないと解析することができる．
\end{itemize}

以上のように総称や定・不定などの名詞句の指示性というものは，
冠詞の生成や照応解析で利用されるものであり，
これを推定することは言語処理研究の一つの重要な問題と
なっている．

名詞句の指示性の推定の先行研究\cite{murata_ref_nlp}では，
表層表現を用いた規則を人手で作成して
指示性の推定を行なっていた．
例えば，前述の例文(\ref{eqn:book_hito})の「本」だと，
「というのは」という表現から総称名詞句であると，
また例文(\ref{eqn:book_boku})の「本」だと，
修飾節「昨日僕が貸した」が限定していることから
定名詞句であると解析していた．
また，規則は86個作成しており，
複数の規則が競合し
どの規則を信頼して解けばよいかが曖昧な場合については，
規則に得点を与えることで競合を解消していた．

本稿では，先行研究で行なった名詞句の指示性の推定に
おける人手の介入が若干でも減少するように，
規則の競合の際に人手でふっていた得点の部分において
機械学習の手法を用いることで，
人手で規則に得点をふるという調整を不要にすることを
目的としている．
本稿で用いる機械学習手法としては，
データスパースネスに強い
最大エントロピー法を採用した．

\section{名詞句の指示性の分類}\label{sec:riron}

名詞句の指示性とは名詞句の対象への指示の仕方である．
まず名詞句を，その名詞句の類の成員すべてか
類自体を指示対象とする
{\bf 総称名詞句}と，
類の成員の一部を指示対象とする
{\bf 非総称名詞句}に分ける．
次に，非総称名詞句を指示対象が確定しているか否かで，
{\bf 定名詞句}と{\bf 不定名詞句}に分ける
(図\ref{fig:sijisei_bunrui})\footnote{ここでの
名詞句の指示性の分類は先行研究\cite{murata_ref_nlp}での
分類に基づく．}．

\begin{figure}[t]
\small
\begin{center}
\fbox{
  \begin{minipage}[c]{220pt}
\begin{center}
{
\tiny

\[
\mbox{\normalsize 名詞句}
\left\{
\begin{array}[h]{cc}
\mbox{\normalsize 総称名詞句} & \\
 & \\
\mbox{\normalsize 非総称名詞句} &
\left\{
\begin{array}[h]{c}
\mbox{\normalsize 定名詞句}\\
 \\
\mbox{\normalsize 不定名詞句}
\end{array}
\right.
\end{array}
\right.
\]
}
\end{center}

  \caption{名詞句の指示性の分類}
  \label{fig:sijisei_bunrui}
  \end{minipage}
}\end{center}
\end{figure}


\paragraph{総称名詞句}

総称名詞句は，その名詞句が意味する類に属する任意の成員
（単数でも，複数でも，不可算のものでもよい）のすべて，
もしくはその名詞句が意味する類それ自身を指示する．
例えば，次の文(\ref{eqn:doguse})の「犬」は総称名詞句である．
\begin{equation}
\underline{犬}は役に立つ動物です．
  \label{eqn:doguse}
\end{equation}
ここでの「犬」は
「犬」という類に属する成員のすべてを指示対象としている．

\paragraph{定名詞句}

定名詞句は，その名詞句が意味する類に属する文脈上唯一の成員（単数でも複数でも不可算のものでもよい）を指示する．
例えば，次の文(\ref{eqn:thedoguse})の「その犬」は定名詞句である．
\begin{equation}
\underline{その犬}は役に立ちます．
  \label{eqn:thedoguse}
\end{equation}
ここでの「その犬」は，
「犬」という類に属する文脈上唯一の成員を指示対象としている．
このことは，指示詞「その」によって表わされており，
聞き手は「その犬」なるものを確定できる．

\paragraph{不定名詞句}

不定名詞句は，その名詞句が意味する類に属するある不特定の成員
（単数でも複数でも不可算のものでもよい）を指示する．
不特定の成員を指示するというのは，現時点での聞き手の情報ではその名詞句が
成員のどれを指し示すのか確定していないという意味である．
また，現時点での聞き手の情報では，
その名詞句が成員のどれを
指し示しているとしても，その文の解釈として間違っていないということでもある．
不定名詞句は総称名詞句とは異なり，その名詞句の意味する類の成員のすべてを
指示するのではなくて，その名詞句の意味する類の成員の一部を指示する．
次の文の「犬」は不定名詞句である．
\begin{equation}
\underline{犬}が三匹います．
  \label{eqn:dog3}
\end{equation}
ここでの「犬」は
犬という類に属する任意の三匹の成員を指示対象として持ちえる．
これは
どんな犬でも三匹いればこの文が使えるということである．


\section{名詞句の指示性の推定方法}\label{sec:decide}

\subsection{先行研究での推定方法}\label{sec:decide_pre}

先行研究\cite{murata_noun_nlp}では，
「可能性」と「得点」という二つの評価値を用い，
人手で作成した規則により，
各指示性に「可能性」と「得点」を与え
この評価値により指示性を推定していた．
各規則によって与えられる「可能性」と「得点」は，
「可能性」については指示性ごとに AND をとり，
「得点」については指示性ごとに足し算を行なう．
その結果，「可能性」が存在し
「得点」の合計が最も大きい指示性を
解であると推定していた．

\begin{figure}[t]
\small
  \begin{center}
\fbox{
  \begin{minipage}[c]{220pt}
\baselineskip=12pt
\hspace*{1.0cm}\protect\verb+(規則の適用条件)+\\
\hspace*{2.0cm}\protect\verb++\{\verb+不定　　　(可能性 得点)+\\
\hspace*{2.18cm}\protect\verb+定　　　　(可能性 得点)+\\
\hspace*{2.18cm}\protect\verb+総称　　　(可能性 得点)+\}

  \caption{名詞句の指示性を推定する規則}
  \label{fig:rule_kouzou_sijisei}
  \end{minipage}
}
  \end{center}
\end{figure}

規則は
図\ref{fig:rule_kouzou_sijisei}の構造をしており，
図の「規則の適用条件」には，
その規則が適用されるかどうかの条件として，
文中の手がかりとなる表現を記述する．
各分類には「可能性」と「得点」を一つずつ与えている．
「可能性」は1か0のみであり，
「得点」は0から10の間の整数である．

「可能性」が1の分類がただ一つ求まった場合は，その分類を推定の結果とする．
「可能性」が1の分類が複数ある場合は，
その中で「得点」の合計が最も大きい分類を推定の結果としていた．
この推定方法では，「得点」だけでなく
「可能性」という評価値も用いている．
これは，人手での調整を軽減するために，
確実に決まりそうなところは「可能性」によって
確実に決め「得点」の調整を不要にするためであった．


規則は86個作成していた．
全規則については文献\cite{murata_B}を参照のこと．
主要なものをいくつか以下に示す．

\begin{enumerate}
\item 指示詞(「この」や「その」など)によって修飾される時，\\
\{
\mbox{不定名詞句}  (0 0) \,
\mbox{定名詞句}   (1 2)  \,
\mbox{総称名詞句}  (0 0)\}
\footnote{
各分類の「可能性」と「得点」を表わす．図\ref{fig:rule_kouzou_sijisei}参照．
}\\
(例文)\underline{\.こ\.の本}はおもしろい. \\
(訳文) \underline{This book} is interesting.
\item 名詞句につく助詞が「は」で
      述語が過去形の時，\\
\mbox{\{
\mbox{不定名詞句} (1 0) \,
\mbox{定名詞句}   (1 3) \,
\mbox{総称名詞句} (1 1)\}}\\
(例文)\underline{犬}\.は向こうに\.行\.き\.ま\.し\.た．\\
(訳文) \underline{The dog} went away.
\item 名詞句につく助詞が「は」で
      述語が現在形の時，\\
\mbox{\{
\mbox{不定名詞句} (1 0) \,
\mbox{定名詞句}   (1 2) \,
\mbox{総称名詞句} (1 3)\}}\\
(例文)\underline{犬}\.は役に立つ動物\.で\.す．\\
(訳文) \underline{Dogs}
\footnote{
主語が総称名詞句になる場合であるので
``a dog''でも``the dog''でもよい．
}
 are useful animals.
\end{enumerate}

他にも，
(i)「地球」「宇宙」のような名詞句自身から定名詞句と推定する規則
\footnote{
\label{foot:tikyuu}
これは本来的には語の意味として取り扱うのが適切だろうが，
    これまで取り扱ってきた場合の特殊な場合と位置付けて
    規則の形で処理することにしている．
}，
(ii)名詞句に数詞がかかることから総称名詞句以外と推定する規則，
(iii)同一名詞の既出により定名詞句と推定する規則，
(iv)「いつも」「昔は」「〜では」のような副詞が動詞にかかることから
総称名詞句と推定する規則，
(v)「〜が好き」「〜を楽しむ」のような動詞から
総称名詞句と推定する規則，
(vi)「用」「向き」のような接尾辞から
総称名詞句と推定する規則などがある．
手がかりとなる語がない時は不定名詞句と推定するようにしている

例として，次の文の中に現れる名詞句「我々が昨日摘みとった果物」に注目し，
これにどのような規則が適用され得点がどのようになるか，
具体的に説明する．

\begin{description}
\item \underline{我々が昨日摘みとった果物}は味がいいです．
\end{description}
\underline{The fruit that we picked yesterday} tastes delicious.\\

以下のように七つの規則が適用され，
この「果物」は定名詞句と推定された．

\begin{itemize}
\item[(a)] 名詞句につく助詞が「は」で述語が現在形の時，\\(果物\.は味が\.い\.い\.で\.す．)
\footnote{規則が適用される手がかりとなる表現．}
\\
\mbox{\{
\mbox{不定名詞句}  (1 0) \,
\mbox{定名詞句}  (1 2)   \,
\mbox{総称名詞句}  (1 3)\}}

\item[(b)] 述部が過去形の節が係る時，\\(摘み\.と\.っ\.た)\\
\mbox{\{
\mbox{不定名詞句}  (1  0) \,
\mbox{定名詞句}    (1  1) \, 
\mbox{総称名詞句}  (1  0)\}}

\item[(c)] 「は」か「が」がついた定名詞句を含む節が係る時，\\(\.我\.々\.が)\\
\mbox{\{
\mbox{不定名詞句}  (1  0) \,
\mbox{定名詞句}  (1  1) \,
\mbox{総称名詞句}  (1  0)\}}

\item[(d)] 助詞がついた定名詞句を含む節が係る時，\\(\.我\.々が)\\
\mbox{\{
\mbox{不定名詞句}  (1  0) \,
\mbox{定名詞句}  (1  1) \,
\mbox{総称名詞句}  (1  0)\}}

\item[(e)] 代名詞を含む節が係る時，\\(\.我\.々が)\\
\mbox{\{
\mbox{不定名詞句}  (1  0) \,
\mbox{定名詞句}    (1  1) \,
\mbox{総称名詞句}  (1  0)\}}

\item[(f)] 名詞句につく助詞が「は」で述語が形容詞の時，\\(果物\.は味が\.い\.い\.で\.す．)\\
\mbox{\{
\mbox{不定名詞句}  (1  0) \,
\mbox{定名詞句}    (1  3) \,
\mbox{総称名詞句}  (1  4)\}}

\item[(g)] 主要部の名詞が普通名詞の時，\\(果物)\\
\mbox{\{
\mbox{不定名詞句}  (1  1) \,
\mbox{定名詞句}    (1  0) \,
\mbox{総称名詞句}  (1  0)\}}

\end{itemize}

これらすべての規則の適用の結果として
「果物」の最終の「可能性」と「得点」は，\\
\mbox{\{
\mbox{不定名詞句}  (1  1) \,
\mbox{定名詞句}    (1  9) \,
\mbox{総称名詞句}  (1  7)\}}\\
となり，定名詞句と推定される．

このような解析を，
対象とする文章の各名詞句について
最初のものから順番に決定的に行なっていく．
既に推定された指示性は後続の名詞句の解析において
手がかりとして用いられる場合がある(例：上記の規則(c),(d))．

先行研究での推定方法は
おおよそ以上のとおりである．
この方法では，
「可能性」と「得点」という二つの評価値を
うまく解析できるように人手で付与する必要があり，
人手の介入が大きいものとなっている．
規則の条件部分にある，解析に効果のある
手がかり表現については人手で収集するのも
有効かもしれないが，
「可能性」と「得点」の二つの評価値については
なんらかの機械学習手法で解決できるのではないかと
考えた．
そこで，本稿では次節で述べるような手法を利用することで，
「可能性」と「得点」の二つの評価値を
人手でふる必要性をないものとした．

\subsection{本稿での推定方法}\label{sec:decide_now}

本稿での指示性の推定は教師あり機械学習手法に基づいて行なう．
機械学習手法としては，
正解の名詞句の指示性を付与した大規模なコーパスを
作成するのはコストが大きく困難であるので，
データスパースネスに強い最大エントロピー法を利用することにした．
最大エントロピー法とは，分類先の推定において，
素性(解析に用いられる情報の
細かい単位のこと)を定義しておくと，学習データから
素性の各出現パターンに対して各分類になる確率を
求めるもので，
この確率を求める際に，
エントロピーを最大にする操作を行なうため，
この方法は最大エントロピー法と呼ばれている．
このエントロピーを最大にする操作は，
確率モデルを一様にする効果を示し，
このことが最大エントロピー法が
データスパースネスに強い理由とされている．
最大エントロピー法の詳細な説明は付録\ref{sec:me}
最大エントロピー法(文献\protect\cite{uchimoto:nlp99}より)で
行なっている．
本研究の最大エントロピー法の利用では，
文献\cite{ristad98}のシステムを用いた\footnote{今は
Web上に存在していない．
文献としては\cite{ristad97}を参照のこと．}．
解析は，そのシステムの出力から
総称名詞句，定名詞句，不定名詞句の
三つの確率を計算し，
その確率の大きいものが解であると推定することによって行なう．

最大エントロピー法の利用においては
学習に用いる素性が必要となる．
学習に用いる素性としては，
先行研究で用いていた86個の人手で作成した
規則の条件部を用いた．
このため，学習に用いる素性の個数は86個となる．

例えば，先にあげた\ref{sec:decide_pre}節の三つの規則1〜3だと，
条件部分だけを取り出して以下のような三つの素性が得られる．
\begin{enumerate}
\item 指示詞(「この」や「その」など)によって修飾されるか．
\item 名詞句につく助詞が「は」で述語が過去形か．
\item 名詞句につく助詞が「は」で述語が現在形か．
\end{enumerate}

最大エントロピー法によってどのように指示性が解析されるかを，
前節であげた以下の同じ例文で具体的に説明する．

\begin{description}
\item \underline{我々が昨日摘みとった果物}は味がいいです．
\end{description}
\underline{The fruit that we picked yesterday} tastes delicious.\\

前節と同じように「我々が昨日摘みとった果物」に注目する．
規則としては前節と同じように
以下の七つの規則が適用される．
規則の指示性の各分類につけてある数は，
各規則だけが適用される場合のその分類になる条件確率のことで，
学習コーパスから最大エントロピー法によって
計算される値である\footnote{この条件確率の詳細は
付録\ref{sec:me}を参照のこと．
付録\ref{sec:me}の式(\ref{eq:alpha})の$\alpha_{a,j}$を
各指示性で正規化したものがここの条件確率に相当する．}．
(ここで付与している値は実際に\ref{sec:jikken}節の機械学習2において
得られたものである．)

\begin{itemize}
\item[(a)] 名詞句につく助詞が「は」で述語が現在形の時，\\(果物\.は味が\.い\.い\.で\.す．)
\footnote{規則が適用される手がかりとなる表現．}
\\
\mbox{\{\mbox{不定名詞句}  \, 0.31, \,
\mbox{定名詞句}    \, 0.29,   \,
\mbox{総称名詞句}  \, 0.40\}}

\item[(b)] 述部が過去形の節が係る時，\\(摘み\.と\.っ\.た)\\
\mbox{\{\mbox{不定名詞句}  \, 0.31, \,
\mbox{定名詞句}    \, 0.49, \, 
\mbox{総称名詞句}  \, 0.19\}}

\item[(c)] 「は」か「が」がついた定名詞句を含む節が係る時，\\(\.我\.々\.が)\\
\mbox{\{\mbox{不定名詞句}  \, 0.19, \,
\mbox{定名詞句}    \, 0.61, \,
\mbox{総称名詞句}  \, 0.19\}}

\item[(d)] 助詞がついた定名詞句を含む節が係る時，\\(\.我\.々が)\\
\mbox{\{\mbox{不定名詞句}  \, 0.01, \,
\mbox{定名詞句}    \, 0.80, \,
\mbox{総称名詞句}  \, 0.18\}}

\item[(e)] 代名詞を含む節が係る時，\\(\.我\.々が)\\
\mbox{\{\mbox{不定名詞句}  \, 0.20, \,
\mbox{定名詞句}    \, 0.44, \,
\mbox{総称名詞句}  \, 0.37\}}

\item[(f)] 名詞句につく助詞が「は」で述語が形容詞の時，\\(果物\.は味が\.い\.い\.で\.す．)\\
\mbox{\{\mbox{不定名詞句}  \, 0.13, \,
\mbox{定名詞句}  \,  0.80, \,
\mbox{総称名詞句} \, 0.07\}}

\item[(g)] 主要部の名詞が普通名詞の時，\\(果物)\\
\mbox{\{\mbox{不定名詞句}  \, 0.72, \,
\mbox{定名詞句}  \,  0.15, \,
\mbox{総称名詞句} \,  0.14\}}

\end{itemize}

最大エントロピー法を用いた方法では，
上記の規則についている値を分類ごとに
掛け合わせ，それらを正規化した結果が最も大きい分類を
求める分類先とする(ここでのかけ算と正規化の演算は
最大エントロピー法では付録\ref{sec:me}の式(\ref{eq:p})の
演算を行なっていることに相当する．)．この場合で，
すべての規則にふられた数値を掛け合わせて正規化(各分類の数値を足すと
1になるように)すると，\\
\mbox{\{
\mbox{不定名詞句}  0.001, \,
\mbox{定名詞句}    0.996, \,
\mbox{総称名詞句}  0.002\}}\\
となり，定名詞句の値が最も大きく
定名詞句と正しく推定される．

文章全体での解析の流れは，
先行研究と全く同じで，
対象とする文章の各名詞について
最初のものから順番に
決定的に指示性の推定を行なっていく．

\section{実験と考察}\label{sec:jikken}



実験には，先行研究で用いていたものと
全く同じデータを利用した．
この実験に用いるデータは，名詞句の指示性の分類の付与が
やりやすいように
日英の対訳がある文章に限ったものだった．
実験対象のテキストの各名詞句への
正解の分類の付与は人手で行なっていた．
正解の決定の際には対訳の英語文を見て行なったが，
必ずしも冠詞にとらわれることなく
\ref{sec:riron}節で説明した分類の定義によって正解を決定していた．
指示性の分類のうち
総称名詞句の判定は極めて困難であり，
表~\ref{fig:sousyou}のようなものを
総称名詞句としたが，
付与した正解自体が間違っている可能性がある．
以下，正解とはこの人手による分類のことをいう．

\begin{table}[t]
\small

\caption{総称名詞句とした名詞句の例(下線部の名詞を主要部に持つ名詞句)}\label{fig:sousyou}

{
  \begin{center}

\begin{tabular}{|c@{ }p{7.4cm}|} \hline

(1)&\underline{ラクダ}は\underline{水}を飲まなくても長い間歩くことができます．\\ 

(2)&ワシントンスクールから一クラスの学生たちが，昨日，\underline{見学}にいきました．\\ 

(3)&多くの若い\underline{男}の\underline{人たち}は\underline{陸軍}に兵役します．\\ 

(4)&\underline{紳士}は普通\underline{淑女}のために\underline{ドア}を開けます．\\ 

(5)&有名なシャ−ロックホ−ムズ探偵の物語は大抵ロンドン地域を\underline{背景}にしたものです．\\ 

(6)&彼はクリスマスの\underline{贈り物}に本を買いました．\\ 

(7)&ワールドカップ大会の決勝戦は，\underline{タンゴ}のアルゼンチンと\underline{行進曲}の西ドイツとの勝負だ．\\[0.1cm] \hline
\end{tabular}
    
  \end{center}
}

\end{table}


本研究の推定で用いる素性では，
形態素・構文情報が必要であるが，
指示性の推定の前に形態素・構文解析を行なっている\cite{juman}\cite{csan2_ieice}．
また，形態素・構文解析での誤りは人手で修正している．

本研究の学習セット，テストセットは，
先行研究のものとまったく同じものを使った．
学習セットは，
三つの資料\{英語冠詞用法辞典\cite{kanshi}
から取り出した典型的な用法の例文(140文，解析した名詞句380個)，
物語の「こぶとりじいさん」\cite{kobu}全文(104文，解析した名詞句267個)
，86年7月1日の天声人語(23文，解析した名詞句98個)\}で，
テストセットは，
三つの資料\{
物語の「つるのおんがえし」\cite{kobu}全文(263文，解析した名詞句699個)，
86年7月8，9，15日の天声人語の三回分(75文，解析した名詞句283個)，
冷戦後世界と太平洋アジア
$\langle$国際文化会館会報　Vol.3  No.2  1992年　4月号$\rangle$
(22文，解析した名詞句192個)\}である．
\ref{sec:decide}節で説明した86個の規則は
学習セットを人手で調査して作成したものである．
また，先行研究において86個の規則に人手で「得点」をふる際には，
学習セットでの解析精度を確認しながら「得点」の微調整を行なっている．

\begin{table}[t]
\small

\caption{人手ルールベース(学習セット)}\label{tab:kanshi_d}

\begin{center}


{

\begin{tabular}[c]{|l|r|r|r|r|r|r|r|r|r|r|} \hline
 & \multicolumn{5}{c|}{指示性}   \\ \hline 
\multicolumn{1}{|c|}{評価}  &  不定  &  定 &  総称 &  その他 & 総数 \\\hline
\multicolumn{6}{|c|}{英語冠詞用法辞典(140文, 380名詞句)} \\ \hline 
   正解   &      96  &     184  &      58  &       1  &     339  \\
  不正解  &       4  &      28  &       8  &       1  &      41  \\
\hline 
 正解率&    96.0  &    86.8  &    87.9  &    50.0  &    89.2  \\\hline
\multicolumn{6}{|c|}{こぶとりじいさん(104文, 267名詞句)} \\ \hline 
   正解   &      73  &     140 &       6  &       1  &    222  \\
  不正解  &      14  &      27  &       4  &       0  &      45    \\
\hline
正解率&   83.9  &   84.0  &   60.0  &  100.0  &   83.2  \\\hline
\multicolumn{6}{|c|}{天声人語(23文, 98名詞句)} \\ \hline 
   正解   &      25  &     35 &      16  &       0  &    76  \\
  不正解  &       5  &      14  &       3  &       0  &      22 \\
\hline
正解率&    83.3  &    71.4  &    84.2  &    -----  &    77.6   \\\hline
全体での出現率 &  29.1  &  57.7   &  12.8   &  0.4  &  100.0   \\
全体での正解率 &  89.4  &  84.0   &  84.2   &  66.7   &  85.5  \\\hline
\end{tabular}
}
\end{center}
\end{table}

\begin{table}[t]
\small

  \caption{人手ルールベース(テストセット)}\label{tab:turu_d}

\begin{center}


{

\begin{tabular}[c]{|l|r|r|r|r|r|} \hline
 & \multicolumn{5}{|c|}{指示性}  \\ \hline 
\multicolumn{1}{|c|}{評価}  &  不定  &  定    &  総称 &  その他 &   総数   \\ \hline 
\multicolumn{6}{|c|}{つるのおんがえし(263文, 699名詞句)} \\ \hline 
   正解   &     109  &    363  &      13  &      10  &   495   \\
  不正解  &      38  &     160  &       6  &       0  &     204 \\
\hline
  正解率   &    74.2  &    69.4  &    68.4  &   100.0  &    70.8 \\\hline
\multicolumn{6}{|c|}{天声人語(75文, 283名詞句)} \\ \hline 
   正解   &      75  &    81  &      16  &       0  &   172  \\
  不正解  &      41  &      60  &      10  &       0  &     111  \\
\hline
  正解率   &    64.7  &    57.5  &    61.5  &    ----- &    60.8   \\\hline
\multicolumn{6}{|c|}{冷戦後世界と太平洋アジア(22文, 192名詞句)} \\\hline 
   正解   &      21  &    108  &      11  &       2  &  142  \\
  不正解  &      17  &      31  &       2  &       0  &      50  \\
\hline
  正解率   &    55.3  &    77.7  &    84.6  &   100.0  &    74.0   \\\hline
全体での出現率 &  25.6  &  68.4  &  4.9   &  1.0   &  100.0 \\
全体での正解率 &  68.1   &  68.7 &  69.0 &  100.0  &  68.9  \\\hline
\end{tabular}
}
\end{center}
\end{table}

まず，このコーパスを用いて以下の二つの実験を行なった．
\begin{itemize}
\item 
  人手ルールベースの手法 --- \ref{sec:decide_pre}節で述べた方法に
  より指示性を推定する．(先行研究\cite{murata_ref_nlp}での実験結果を
  再掲しているのと等価)

\item 
  機械学習1 --- \ref{sec:decide_now}節で述べた方法により，
  指示性を推定する．

\end{itemize}
これらの実験結果を表\ref{tab:kanshi_d}〜表\ref{tab:turu_m1}に
示す．
ただし，機械学習1での学習においては，
前述の規則(c),(d)のような既に推定された指示性を用いる場合は
その学習において推定されるものではなく
正解の指示性を用いて学習を行なっている．
一方，表\ref{tab:kanshi_m1},表\ref{tab:turu_m1}のような
精度を求める際の解析においては，
正解の指示性ではなく，
推定された指示性を用いている．

表中の「出現率」は各分類の個数を総数で割ったものである．
「その他」は，
先行研究において指示性が曖昧な場合にふっていたタグに相当するもので，
事例数が少なく本研究では無視してよい．

\begin{table}[t]
\small

\caption{機械学習1(学習セット)}\label{tab:kanshi_m1}

\begin{center}


{

\begin{tabular}[c]{|l|r|r|r|r|r|r|r|r|r|r|} \hline
 & \multicolumn{5}{c|}{指示性}   \\ \hline 
\multicolumn{1}{|c|}{評価}  &  不定  &  定 &  総称 &  その他 & 総数 \\\hline
\multicolumn{6}{|c|}{英語冠詞用法辞典(140文, 380名詞句)} \\ \hline 
   正解   &      95  &     199  &      32  &       0  &     326   \\
  不正解  &       5  &      13  &      34  &       2  &      54   \\\hline
  正解率  &   95.0  &   93.9  &   48.5  &    0.0  &   85.8   \\\hline
\multicolumn{6}{|c|}{こぶとりじいさん(104文, 267名詞句)} \\\hline 
   正解   &      71  &     151  &       1  &       0  &     223   \\
  不正解  &      16  &      18  &       9  &       1  &      44   \\\hline
  正解率  &   81.6  &   89.4  &   10.0  &    0.0  &   83.5   \\\hline
\multicolumn{6}{|c|}{天声人語(23文, 98名詞句)} \\ \hline 
   正解   &      21  &      46  &       5  &       0  &      72   \\
  不正解  &       9  &       3  &      14  &       0  &      26   \\\hline
  正解率  &   70.0  &   93.9  &   26.3  &     ---  &   73.5   \\\hline
全体での出現率 &  29.1  &  57.7   &  12.8   &  0.4  &  100.0   \\
全体での正解率  &   86.2  &   92.1  &   40.0  &    0.0  &   83.4   \\\hline
\end{tabular}
}
\end{center}
\end{table}

\begin{table}[t]
\small

\caption{機械学習1(テストセット)}\label{tab:turu_m1}

\begin{center}


{

\begin{tabular}[c]{|l|r|r|r|r|r|} \hline
 & \multicolumn{5}{|c|}{指示性}  \\ \hline 
\multicolumn{1}{|c|}{評価}  &  不定  &  定    &  総称 &  その他 &   総数   \\ \hline 
\multicolumn{6}{|c|}{つるのおんがえし(263文, 699名詞句)} \\ \hline 
   正解   &     104  &     408  &       0  &       0  &     512   \\
  不正解  &      43  &     115  &      19  &      10  &     187   \\\hline
  正解率  &   70.8  &   78.0  &    0.0  &    0.0  &   73.3   \\\hline
\multicolumn{6}{|c|}{天声人語(75文, 283名詞句)} \\ \hline 
   正解   &      72  &     108  &       2  &       0  &     182   \\
  不正解  &      44  &      33  &      24  &       0  &     101   \\\hline
  正解率  &   62.1  &   76.6  &    7.7  &     ---  &   64.3   \\\hline
\multicolumn{6}{|c|}{冷戦後世界と太平洋アジア(22文, 192名詞句)} \\\hline 
   正解   &      21  &     130  &       1  &       0  &     152   \\
  不正解  &      17  &       9  &      12  &       2  &      40   \\\hline
  正解率  &   55.3  &   93.5  &    7.7  &    0.0  &   79.2   \\\hline
全体での出現率 &  25.6  &  68.4  &  4.9    &  1.0   &  100.0 \\
全体での正解率  &   65.5  &   80.5  &    5.2  &    0.00  &   72.1   \\\hline
\end{tabular}
}
\end{center}
\end{table}

テストセットの指示性全体での精度では，
人手ルールベースで68.9\% (表\ref{tab:turu_d})，
機械学習1で72.1\%(表\ref{tab:turu_m1})であった．
人手ルールベースの方法では
規則に人手で得点をふる必要があったが，
規則に人手で得点をふる必要がない
機械学習の方法でも，
人手ルールベースの方法と同程度以上の精度を
出すことができることがわかった．
しかし，実験結果の表\ref{tab:turu_d}と表\ref{tab:turu_m1}を
見比べるとわかるように，
人手ルールベースの方法では
各指示性ともに70\%弱で極端に精度の悪い分類はないが，
機械学習1の方では
不定名詞句と定名詞句は
70\%前後で問題ないが
総称名詞句での精度は5.2\%と極端に低いものとなっている．
これでは，
総称名詞句の出現率は4.9\%であり
出現率が小さいので，
総称名詞句での精度が悪くとも全体での精度が高くなっているだけで，
あまり良い結果とはいえない．

\begin{table}[t]
\small

\caption{機械学習2(学習セット)}\label{tab:kanshi_m2}

\begin{center}


{

\begin{tabular}[c]{|l|r|r|r|r|r|r|r|r|r|r|} \hline
 & \multicolumn{5}{c|}{指示性}   \\ \hline 
\multicolumn{1}{|c|}{評価}  &  不定  &  定 &  総称 &  その他 & 総数 \\\hline
\multicolumn{6}{|c|}{英語冠詞用法辞典(140文, 380名詞句)} \\ \hline 
   正解   &      97  &     188  &      57  &       0  &     342   \\
  不正解  &       3  &      24  &       9  &       2  &      38   \\\hline
  正解率  &   97.0  &   88.7  &   86.4  &    0.0  &   90.0   \\\hline
\multicolumn{6}{|c|}{こぶとりじいさん(104文, 267名詞句)} \\ \hline 
   正解   &      80  &     137  &       6  &       0  &     223   \\
  不正解  &       7  &      32  &       4  &       1  &      44   \\\hline
  正解率  &   92.0  &   81.1  &   60.0  &    0.0  &   83.5   \\\hline
\multicolumn{6}{|c|}{天声人語(23文, 98名詞句)} \\ \hline 
   正解   &      26  &      40  &      17  &       0  &      83   \\
  不正解  &       4  &       9  &       2  &       0  &      15   \\\hline
  正解率  &   86.7  &   81.6  &   89.5  &     ---  &   84.7   \\\hline
全体での出現率 &  29.1  &  57.7   &  12.8   &  0.4  &  100.0   \\
全体での正解率  &   93.6  &   84.9  &   84.2  &    0.0  &   87.0   \\\hline
\end{tabular}
}
\end{center}
\end{table}

\begin{table}[t]
\small

\caption{機械学習2(テストセット)}\label{tab:turu_m2}

\begin{center}


{

\begin{tabular}[c]{|l|r|r|r|r|r|} \hline
 & \multicolumn{5}{|c|}{指示性}  \\ \hline 
\multicolumn{1}{|c|}{評価}  &  不定  &  定    &  総称 &  その他 &   総数   \\ \hline 
\multicolumn{6}{|c|}{つるのおんがえし(263文, 699名詞句)} \\ \hline 
   正解   &     112  &     360  &      13  &       0  &     485   \\
  不正解  &      35  &     163  &       6  &      10  &     214   \\\hline
  正解率  &   76.2  &   68.8  &   68.4  &    0.0  &   69.4   \\\hline
\multicolumn{6}{|c|}{天声人語(75文, 283名詞句)} \\ \hline 
   正解   &      79  &      88  &      14  &       0  &     181   \\
  不正解  &      37  &      53  &      12  &       0  &     102   \\\hline
  正解率  &   68.1  &   62.4  &   53.9  &     ---  &   64.0   \\\hline
\multicolumn{6}{|c|}{冷戦後世界と太平洋アジア(22文, 192名詞句)} \\\hline 
   正解   &      25  &     110  &      10  &       0  &     145   \\
  不正解  &      13  &      29  &       3  &       2  &      47   \\\hline
  正解率  &   65.8  &   79.1  &   76.9  &    0.0  &   75.5   \\\hline
全体での出現率 &  25.6  &  68.4 &  4.9    &  1.0   &  100.0 \\
全体での正解率  &   71.8  &   69.5  &   63.8  &    0.0  &   69.1   \\\hline
\end{tabular}
}
\end{center}
\end{table}

総称名詞句での精度が下がっているのは，
学習データにおいて総称名詞句の頻度が小さく
頻度が多い定名詞句に偏った学習がなされているためでは
ないかと考えた．
(例えば，表\ref{tab:kanshi_m1}の学習セットでの
機械学習の精度では定名詞句の精度は92\%と高いが，
総称名詞句の精度は40\%と学習セットにおいてもかなり低いものと
なっており，定名詞句に偏った学習がなされていることを
予想させる．)
そこで，次に以下の実験を行なった．
\begin{itemize}
\item 
  機械学習2 --- \ref{sec:decide_now}節で述べた方法により
  指示性を推定する際の最大エントロピー法の学習において，
  不定名詞句と定名詞句と総称名詞句に対し
  その出現率の逆数にみあう値を学習での頻度に掛け合わす．
  本研究は，不定名詞句と定名詞句と総称名詞句に対し
  4, 2, 9の値を掛け合わした．
\end{itemize}
つまり，総称名詞句は定名詞句の2/9ぐらいしか出現していないので，
定名詞句がもとよりも2倍多めに出現していたこと，
総称名詞句がもとよりも9倍多めに出現していたというように
学習データでの頻度を操作する．
この操作を行なうことで，
学習データでの不定名詞句と定名詞句と総称名詞句の頻度は
見かけ上均等になり，定名詞句に偏った解析にはならなくなる
と考えた．
また，この操作は次のようなことを行なっているとも考えることができる．
機械学習1では一般の学習と同じなので，
\begin{equation}
  \label{eq:ml1}
  評価関数 = (全体での正解率) 
\end{equation}
の値を極力大きくするように学習するが，
機械学習2では各指示性とも頻度をそろえるため，
\begin{equation}
  \label{eq:ml2}
  \begin{minipage}[h]{6.5cm}
\begin{tabular}[h]{l@{}l}
評価関数 =  & (不定名詞句での正解率) と \\
         & (定名詞句での正解率) と \\
         & (総称名詞句での正解率) の平均 \\
\end{tabular}
  \end{minipage}
\end{equation}
の値を極力大きくするように学習を行なっていることになると思われる\footnote{
表\ref{tab:turu_m1}と表\ref{tab:turu_m2}のテストセットのでの精度を見比べて
ほしい．
全指示性での正解率では
機械学習1の72.1\%は機械学習2の69.1\%を上回っており，
機械学習1の式(\ref{eq:ml1})を最大にするという傾向にそった結果となっている．
また，式(\ref{eq:ml2})の値では，
機械学習1で50.4\%(=(65.5 + 80.5+ 5.2)/3)，
機械学習2で68.4\%(=(65.5 + 80.5+ 5.2)/3)となり，
機械学習2で式(\ref{eq:ml2})を最大にするという効果のおかげで
機械学習2の値が機械学習1の値を上回ったものと思われる．
ところで，これを学習セットで考察すると思わしくない面がある．
式(\ref{eq:ml2})の方はよいが，
式(\ref{eq:ml1})の方では機械学習2の方が大きいものとなっている．
これは学習セットにおいて既に解析した指示性を
後続の名詞句の指示性の推定に用いる場合が影響しているものと思われる．
前述のとおり既に推定された指示性を用いる場合は，
学習においては正解の指示性を用い，
表\ref{tab:kanshi_m1}，表\ref{tab:kanshi_m2}での解析において精度を
求める際には
正解の指示性ではなく推定された指示性を用いている．
学習セットで式(\ref{eq:ml1})の議論をする場合は
学習で行なった条件での精度を見る必要がある．
このため，学習セットでの解析精度を出すときにも
学習時と同様正解の指示性を用いることにして精度を求めると，
全指示性での正解率は
機械学習1で88.1\%，機械学習2で87.5\%であった．
この数値ならば，機械学習1の方で
式(\ref{eq:ml1})を大きくするように学習するということと
矛盾しない．} \footnote{ここで頻度をそろえることが
式(\ref{eq:ml2})を最大にするように学習していることになると
述べているが，厳密には証明が必要であろう．
(実験的な確認は一つ前の脚注によっている．)
事例の頻度の調整は
付録\ref{sec:me}の式(\ref{eq:constraint})や式(\ref{eq:entropy})で
事例で和をとっている部分に対して影響が出ると
思われるが，厳密に理論をつめていない．
このあたりの証明は理論よりの研究者にゆだねたい．}．

機械学習2の実験結果を表\ref{tab:kanshi_m2}，表\ref{tab:turu_m2}に示す．
ただし，機械学習2と同様，
前述の規則(c),(d)のような既に推定された指示性を用いる場合は，
学習においては正解の指示性を用い，
精度を求める際には
正解の指示性ではなく推定された指示性を用いている．

機械学習2のテストセットの指示性全体での精度では，69.1\%であった．
これは人手ルールベースでの68.9\%とほぼ同じ値である．
次に各指示性での精度を見てみると，
機械学習2ではそれほど均等ではないが
おおよそ70\%前後に集まっていることがわかる．
一番悪い総称名詞句でも63.8\%の精度を出していることから，
機械学習2の方法をとれば，
指示性を均等な精度で解析できることがわかった．

整理すると本研究において以下のことがわかったことになる．
\begin{itemize}
\item 
  機械学習の方法により，規則の競合の解消に用いる得点を
  人手でふる必要性がなくなる場合がある．
\item 
  分類に均等な精度が得られていない場合には，
  学習データでの各分類の頻度を均等にすることで
  ある程度分類に均等な精度にできる場合がある．
\end{itemize}

以上の結果のように機械学習の手法を用いることで，
規則の競合の解消用の得点を人手で調整する必要が
なくなって，人手のコストが軽減できる場合があることが
わかった．
しかし，本研究で行なったことはまだ
規則の競合の解消だけであり，
規則の条件部分，つまり，
どのような表現が手がかりとして有効かの部分の抽出は
人手にゆだねられたままである．
今後はどのような表現が手がかりとして有効かを調査する部分も
自動化する方法を模索する予定であるが，
有効な手がかりの抽出は難しい問題で
この部分だけは人手に頼らざるをえないのでは
ないかとも考えている．

次に機械学習2において最大エントロピー法を用いて
規則にふった値について考察する．
86個の規則のうち主要なものについて以下で考察する．
それぞれ規則とも，条件部，人手で付与した得点，
機械学習2によって付与した値の順で示している．
\begin{enumerate}
\item 
  不定名詞句に関わる規則

  \begin{itemize}
  \item 
    名詞句につく助詞が「が」である時，\\
    \mbox{\{\mbox{不定名詞句} (1 2) \,
      \mbox{定名詞句}   (1 1) \,
      \mbox{総称名詞句} (1 0)\}}\\
    \mbox{\{\mbox{不定名詞句} \, 0.62, \,
      \mbox{定名詞句}   \, 0.21, \,
      \mbox{総称名詞句} \, 0.17\}}

    助詞「が」つくと不定名詞句の傾向があるが，
    機械学習2による値でもその傾向が反映されている．
    また，0.99のような極端に大きい値でないことから，
    その傾向がそれほど強くないということも示している．
    また，「が」がつくと総称名詞句の可能性が低いが
    その傾向も示されている．
    
  \item 
    名詞句の修飾語が連体詞「ある」である時，\\
    \mbox{\{\mbox{不定名詞句} (1 2) \,
      \mbox{定名詞句}   (0 0) \,
      \mbox{総称名詞句} (0 0)\}}\\
    \mbox{\{\mbox{不定名詞句} \, 0.99, \,
      \mbox{定名詞句}   \, 0.0001, \,
      \mbox{総称名詞句} \, 0.0001\}}

    連体詞「ある」がつくときはほぼ不定名詞句だろうと考え，
   人手で付与した「可能性」は不定名詞句以外を0にしていたが，
   機械学習2による値でも不定名詞句以外の値が0.0001と極めて小さく
   上記の傾向がしっかりと得られている．

   連体詞「ある」と同様に，判定詞「だ」がつく場合，
   数詞がつく場合も不定名詞句の値が極端に高く，
   これらの表現により不定名詞句になりやすいことが
   機械学習2によっても正しく求めることができることがわかる．
   
 \item 
   普通名詞である時，\\
   \mbox{\{\mbox{不定名詞句} (1 1) \,
     \mbox{定名詞句}   (1 0) \,
     \mbox{総称名詞句} (1 0)\}}\\
   \mbox{\{\mbox{不定名詞句} \, 0.72, \,
     \mbox{定名詞句}   \, 0.15, \,
     \mbox{総称名詞句} \, 0.14\}}
   
   この規則は他の規則が適用されないとき，
   つまり手がかりとなる表現がないときに
   不定名詞句であると推定するデフォルトの規則である．
   機械学習2により得られた値も不定名詞句が幾分
   大きな値を持つということで，
   適切にデフォルトの規則の役割を果たしていると思われる．

  \end{itemize}

\item 
  定名詞句に関わる規則
  \begin{itemize}
  \item 
    解析する名詞句が代名詞の場合，\\
    \mbox{\{\mbox{不定名詞句} (0 0) \,
      \mbox{定名詞句}   (1 2) \,
      \mbox{総称名詞句} (0 0)\}}\\
    \mbox{\{\mbox{不定名詞句} \, 0.005, \,
      \mbox{定名詞句}   \, 0.99, \,
      \mbox{総称名詞句} \, 0.005\}}

    代名詞の場合はほぼ定名詞句だろうと考え，
    人手で付与した「可能性」は定名詞句以外を0にしていたが，
    機械学習2による値でも定名詞句以外の値が極めて小さく
    上記の傾向がしっかりと得られている．

  \item 「は」か「が」がついた定名詞句を含む節が係る場合，\\
    \mbox{\{\mbox{不定名詞句} (1 1) \,
      \mbox{定名詞句}   (1 2) \,
      \mbox{総称名詞句} (1 1)\}}\\
    \mbox{\{\mbox{不定名詞句}  \, 0.19, \,
      \mbox{定名詞句}    \, 0.61, \,
      \mbox{総称名詞句}  \, 0.19\}}

    単に「は」か「が」がついた定名詞句を含んでいるだけでは
    限定修飾になるとは限らないが，
    それでもそういう表現があると限定修飾になりやすく
    定名詞句になる傾向が強いと考えられるが，
    実際の値もそのような傾向(完全に定名詞句というわけでは
    ないが定名詞句の可能性が高い)に沿ったものとなっている．

  \item
    直前の五つの文のどれかに同じ名詞句が既に現れており，
    その名詞句の指示性が「不定名詞句」の場合，\\
    \mbox{\{\mbox{不定名詞句} (1 1) \,
      \mbox{定名詞句}   (1 3) \,
      \mbox{総称名詞句} (1 0)\}}\\
    \mbox{\{\mbox{不定名詞句}  \, 0.07, \,
      \mbox{定名詞句}    \, 0.88, \,
      \mbox{総称名詞句}  \, 0.05\}}

    同一名詞句が既出の場合は，それを指示することが多く
    指示性は定名詞句になりやすいが，機械学習2の値は
    その傾向に沿ったものとなっている．

  \end{itemize}

\item 
  総称名詞句に関わる規則
  \begin{itemize}
  \item 
    修飾語を持たない名詞句で，うしろにつく助詞が「は」である時，\\
    \mbox{\{\mbox{不定名詞句} (1 0) \,
      \mbox{定名詞句}   (1 1) \,
      \mbox{総称名詞句} (1 1)\}}\\
    \mbox{\{\mbox{不定名詞句}  \, 0.03, \,
      \mbox{定名詞句}    \, 0.26, \,
      \mbox{総称名詞句}  \, 0.71\}}

    助詞「は」は旧情報の定名詞句と総称名詞句に
    つきやすい表現として人手の得点では
    それぞれに1点ずつ与えるものを作成していた．
    機械学習2の値でも，
    定名詞句と総称名詞句の値が大きくその傾向はある．
    しかし，総称名詞句の値の方が大きくなっている．
    定名詞句を推定する他の規則が多くあるため，
    助詞「は」で手がかりが少ないときに
    総称名詞句と判定できるようになっているものと思われる．

  \item 
    名詞句につく助詞が「は」で述語が形容詞の時，\\
    \mbox{\{\mbox{不定名詞句}  (1  0) \,
      \mbox{定名詞句}    (1  3) \,
      \mbox{総称名詞句}  (1  4)\}}\\
    \mbox{\{\mbox{不定名詞句}  \, 0.13, \,
      \mbox{定名詞句}  \,  0.80, \,
      \mbox{総称名詞句} \, 0.07\}}

    人手で作成した規則では総称名詞句になる可能性が高いとしていたが，
    機械学習2での値は定名詞句が大きいものとなっている．
    これは学習データの不足による機械学習2での推定ミスか，
    一つ上の規則などの他の規則との兼ね合いで
    この規則では総称名詞句よりも定名詞句を重視するということになっているのか，
    もともとの人手での得点が良くなかったかのいずれかによると思われる．
    もし，学習データの不足であれば
    データを増やすことで改善が期待できる．

  \item 
    名詞句に続く助詞が「とは」か「というのは」の時，\\
    \mbox{\{\mbox{不定名詞句} (0 0) \,
      \mbox{定名詞句}   (1 0) \,
      \mbox{総称名詞句} (1 2)\}}\\
    \mbox{\{\mbox{不定名詞句}  \, 0.05, \,
      \mbox{定名詞句}    \, 0.05, \,
      \mbox{総称名詞句}  \, 0.90\}}

    助詞「とは」「というのは」が続く場合は，
    なんらかの概念について説明するということで
    総称名詞句になることが多いが，
    その傾向が反映されている．

  \item 
    述語に総称副詞(例：「いつも」「一般に」「伝統的に」
    「昔は」「〜では」)などがかかる文中の語の時\footnote{
この規則の条件部には
多くの総称副詞を``or''の形で人手で列挙している．
つまり，ここであげた総称副詞のどれが出現しても
この規則が適用されるように規則の抽象化がなされている．
機械学習では，
小量の学習データでも学習できるように
いかに抽象化した規則を獲得していくかが問題であるが，
この規則の場合その規則の抽象化を人手で行なっていると
いうことになる．
(例えば，森らのコーパスベースの形態素解析の研究\cite{mori_nlp98}では
複数の形態素をまとめたクラスというものを用いることで
情報の抽象化を実現し精度向上を行なっている．)
今後，指示性の問題で
規則の条件部も機械学習により獲得しようと思えば，
この抽象化を考慮する必要があるということを
この規則が物語っている．}，\\
    \mbox{\{\mbox{不定名詞句} (0 0) \,
      \mbox{定名詞句}   (1 1) \,
      \mbox{総称名詞句} (1 2)\}}\\
    \mbox{\{\mbox{不定名詞句}  \, 0.02, \,
      \mbox{定名詞句}    \, 0.09, \,
      \mbox{総称名詞句}  \, 0.89\}}

    この場合，総称副詞により総称名詞句になりやすいが
    その傾向が表れている．
    

  \end{itemize}

\end{enumerate}

以上のように機械学習2により得られた値は，
人手でふった数値とほぼ同じ傾向のものであり，
かつ，言葉に対する直観的な理由づけに沿ったものとなっている．


\section{おわりに}\label{sec:end}
本研究では，名詞句の指示性の推定における
規則の競合解消のため，人手で付与していた得点づけを，
機械学習で自動化することに成功した．
このことにより，
規則の競合解消のために人手のコストを払う必要がないこと
になった．

また，機械学習においては，
学習データでの頻度を分野ごとに均等にすることで，
解析結果の精度も分野ごとに均等にできる場合があることがわかった．

また，機械学習によって得られた各規則に付与する値を
考察し，これらの値が言語学的な理由づけとも矛盾しないことを
確認した．

しかし，本研究で行なったことはまだ
規則の競合の解消を自動化しただけであり，
規則の条件部分の抽出，つまり，
どのような表現が手がかりとして有効かの特定の部分は 
人手にゆだねられたままである．
現在の指示性の推定精度は70\%程度とそれほど高くなく
精度向上を図る必要があるが，
この精度向上には
手がかりとなる表現を増やしていくことが不可欠である．
そういう意味でも
どのような表現が手がかりとして有効かを抽出する部分も
自動化する必要性は大きい．
今後，有効な表現を自動的に抽出する
方法を模索する予定ではあるが，
有効な手がかりの抽出は難しい問題で
この部分だけは人手に頼らざるをえないのでは
ないかとも考えている．

\appendix
\section{最大エントロピー法(文献\protect\cite{uchimoto:nlp99}より)}\label{sec:me}

本付録では読者の便を考え最大エントロピー法について説明している．
本付録の最大エントロピー法の説明は
文献\cite{uchimoto:nlp99}での説明を一部改変のうえ
そのまま引用している．

一般に確率モデルでは，文脈(観測される情報のこと)とそのときに得られる出力値
との関係は既知のデータから推定される確率分布によって表される．
いろいろな状況に対してできるだけ正確に出力値を予測するためには
文脈を細かくする必要があるが，細かくしすぎると既知のデータにおいて
それぞれの文脈に対応する事例の数が少なくなりデータスパースネスの問題が生じる．
最大エントロピー法では，文脈は素性と呼ばれる個々の要素によって表され，
確率分布は素性を引数とした関数として表される．
そして，各々の素性はトレーニングデータにおける
確率分布のエントロピーが最大になるように重み付けされる．
このエントロピーを最大にするという操作によって，
既知データに観測されなかったような素性あるいは
まれにしか観測されなかった素性については，
それぞれの出力値に対して確率値が等確率になるように
あるいは近付くように重み付けされる．
このため最大エントロピー法はデータスパースネスに強いとされている．
このモデルは例えば言語現象などのように既知データにすべての現象が現れ得ない
ような現象を扱うのに適したモデルであると言える．

以上のような性質を持つ最大エントロピー法では，
確率分布の式は以下のように求められる．
文脈$b (\in$$B)$で出力値$a (\in$$A)$となる事象$(a,b)$の確率分布$p(a,b)$を
最大エントロピー法により推定することを考える．
文脈$b$は$k$個の素性$f_j (1\leq j\leq k)$の集合で表す．
そして，文脈$b$において，素性$f_j$が観測され
かつ出力値が$a$となるときに1を返す以下のような関数を定義する．
{\small\it
\begin{eqnarray}
  \label{eq:f}
  g_{j}(a,b) & = & 
  \left\{
  \begin{array}[c]{l}
    1\ (exist(b,f_{j})=1 \ \& \ 出力値=a)\\
    0\ (それ以外)
  \end{array}
  \right.
\end{eqnarray}
}
これを素性関数と呼ぶ．
ここで，$exist(b,f_j)$は，文脈$b$において素性$f_j$が観測されるか否かによって
1あるいは0の値を返す関数とする．

次に，それぞれの素性が既知のデータ中に現れた割合は
未知のデータも含む全データ中においても変わらないとする制約を加える．
つまり，推定するべき確率分布$p(a|b)$による素性$f_j$の期待値と，
既知データにおける確率分布$\tilde{p}(a,b)$による
素性$f_j$の期待値が等しいと仮定する．これは以下の制約式で表せる．
{\small\it
\begin{eqnarray}
  \label{eq:constraint}
  \sum_{a\in A,b\in B}\tilde{p}(b)p(a|b)g_{j}(a,b) 
  \ = \sum_{a\in A,b\in B}\tilde{p}(a,b)g_{j}(a,b)\\
  \ for\ \forall f_{j}\ (1\leq j \leq k) \nonumber
\end{eqnarray}
}
ここで，$\tilde{p}(b)$，$\tilde{p}(a,b)$は，
$freq(b)$，$freq(a,b)$をそれぞれ既知データにおける
事象$b$，$(a,b)$の出現頻度として以下のように推定する．
{\small\it
\begin{eqnarray}
  \tilde{p}(b) & = & 
  \frac{freq(b)}{\displaystyle\sum_{b\in B} freq(b)}\\
  \tilde{p}(a,b) & = & 
  \frac{freq(a,b)}{\displaystyle\sum_{a\in A,b\in B} freq(a,b)}
\end{eqnarray}
}

次に，式(\ref{eq:constraint})の制約を満たす確率分布$p(a,b)$のうち，
エントロピー
{\small\it
\begin{eqnarray}
  \label{eq:entropy}
  H(p) & = & -\sum_{a\in A,b\in B}\tilde{p}(b)p(a|b)\ log\left(p(a,b)\right)
\end{eqnarray}
}
を最大にする確率分布を推定するべき確率分布とする．
これは，最も一様な分布となる．
このような確率分布は唯一存在し，以下の確率分布$p^{*}$として記述される．
{\small\it
\begin{eqnarray}
  \label{eq:p}
  p^{*}(a|b) & = & \frac{\prod_{j=1}^{k}\alpha_{a,j}^{g_{j}(a,b)}}
  {\sum_{a\in A} \prod_{j=1}^{k}\alpha_{a,j}^{g_{j}(a,b)}}\\
  & & (0\leq \alpha_{a,j}\leq \infty)\nonumber
\end{eqnarray}
}
ただし，
{\small\it
\begin{eqnarray}
  \label{eq:alpha}
  \alpha_{a,j} & = & e^{\lambda_{a,j}}
\end{eqnarray}
}
であり，$\lambda_{a,j}$は素性関数$g_{j}(a,b)$のパラメータである．
このパラメータは文脈$b$のもとで出力値$a$となることを予測するのに
素性$f_{j}$がどれだけ重要な役割を果たすかを表している．
訓練集合が与えられたとき，パラメータの推定には
Improved Iterative Scaling(IIS)アルゴリズム\cite{pietra95}などが用いられる．
学習コーパスから実際に式(\ref{eq:p})の確率分布を求めるために，
われわれは Ristad のツール\cite{ristad98}を使っている．


\bibliographystyle{jnlpbbl}
\bibliography{jpaper}

\begin{biography}
\biotitle{略歴}
\bioauthor{村田真樹}{
1993年京都大学工学部卒業．
1995年同大学院修士課程修了．
1997年同大学院博士課程修了，博士（工学）．
同年，京都大学にて日本学術振興会リサーチ・アソシエイト．
1998年郵政省通信総合研究所入所．研究官．
自然言語処理，機械翻訳の研究に従事．
言語処理学会，情報処理学会，ACL，各会員．}
\bioauthor{内元清貴}{
1994年京都大学工学部卒業．
1996年同大学院修士課程修了．
同年郵政省通信総合研究所入所，郵政技官．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，ACL，各会員．}
\bioauthor{馬 青}{
1983年北京航空航天大学自動制御学部卒業．
1987年筑波大学大学院理工学研究科修士課程修了．
1990年同大学院工学研究科博士課程修了．工学博士．
1990 $\sim$ 93年株式会社小野測器勤務．
1993年郵政省通信総合研究所入所，主任研究官． 
人工神経回路網モデル，知識表現，自然言語処理の研究に従事． 
日本神経回路学会，言語処理学会，電子情報通信学会，各会員．}
\bioauthor{井佐原均}{
1978年京都大学工学部電気工学第二学科卒業．
1980年同大学院修士課程修了．博士（工学）．
同年通商産業省電子技術総合研究所入所．
1995年郵政省通信総合研究所
関西支所知的機能研究室室長．自然言語処理，機械翻訳の研究に従事．
言語処理学会，情報処理学会，人工知能学会，日本認知科学会，ACL，各会員．}

\bioreceived{受付}
\bioaccepted{採録}

\end{biography}

\end{document}

        
