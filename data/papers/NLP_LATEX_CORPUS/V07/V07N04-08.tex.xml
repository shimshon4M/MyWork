<?xml version="1.0" ?>
<root>
  <title>コーパスからの語順の学習</title>
  <author>内元清貴村田真樹馬青関根聡井佐原均</author>
  <jabstract>本論文では，日本語の語順の傾向をコーパスから学習する手法を提案する．ここで語順とは係り相互間の語順，つまり同じ文節に係っていく文節の順序関係を意味するものとする．我々が提案する手法では，文節内外に含まれるさまざまな情報から語順の傾向を自動学習するモデルを用いる．このモデルによって，それぞれの情報が語順の決定にどの程度寄与するか，また，どのような情報の組み合わせのときにどのような傾向の語順になるかを推測することができる．個々の情報が語順の決定に寄与する度合は最大エントロピー(ME)法によって効率良く学習される．学習されたモデルの性能は，そのモデルを用いて語順を決めるテストを行ない，元の文における語順とどの程度一致するかを調べることによって定量的に評価することができる．正しい語順の情報はテキスト上に保存されているため，学習コーパスは必ずしもタグ付きである必要はなく，生コーパスを既存の解析システムで解析した結果を用いてもよい．本論文ではこのことを実験によって示す．</jabstract>
  <jkeywords>語順，コーパス，学習，最大エントロピーモデル，生成</jkeywords>
  <section title="はじめに">日本語は語順が自由であると言われている．しかし，これまでの言語学的な調査によると実際には，時間を表す副詞の方が主語より前に来やすい，長い修飾句を持つ文節は前に来やすいといった何らかの傾向がある．もしこの傾向をうまく整理することができれば，それは文を解析あるいは生成する際に有効な情報となる．本論文では語順とは，係り相互間の語順，つまり同じ文節に係っていく文節の順序関係を意味するものとする．語順を決定する要因にはさまざまなものがある．それらの要因は語順を支配する基本的条件として文献にまとめられており，それを我々の定義する語順について解釈しなおすと次のようになる．成分的条件深く係っていく文節は浅く係っていく文節より前に来やすい．深く係っていく文節とは係り文節と受け文節の距離が長い文節のことを言う．例えば，係り文節と受け文節の呼応を見ると，基本的語順は，感動詞などを含む文節，時間を表す副詞を含む文節，主語を含む文節，目的語を含む文節の順になり，このとき，時間を表す副詞を含む文節は主語を含む文節より深く係っていく文節であると言う．このように係り文節と受け文節の距離を表す概念を係りの深さという．広く係っていく文節は狭く係っていく文節より前に来やすい．広く係っていく文節とは受け文節を厳しく限定しない文節のことである．例えば，「東京へ」のような文節は「行く」のように何らかの移動を表す動詞が受け文節に来ることが多いが，「私が」のような文節は受け文節をそれほど限定しない．このとき，「私が」は「東京へ」より広く係っていく文節であると言う．このように係り文節がどの程度受け文節を限定するかという概念を係りの広さと言う．構文的条件長い文節は短い文節より前に来やすい．長い文節とは修飾句の長い文節のことを言う．文脈指示語を含む文節は前に来やすい．承前反復語を含む文節は前に来やすい．承前反復語とは前文の語を承けて使われている語のことを言う．例えば，「あるところにおじいさんとおばあさんがおりました．おじいさんは山へ柴刈におばあさんは川へ洗濯に行きました．」という文では，2文目の「おじいさん」や「おばあさん」が承前反復語である．提題助詞「は」を伴う文節は前に来やすい．以上のような要素と語順の関係を整理する試みの一つとして，特に係りの広さに着目し，辞書の情報を用いて語順を推定するモデルが提案された．しかし，動詞の格要素の語順に限定しており必須格しか扱えない，文脈情報が扱えないなどの問題点が指摘されている．語順を推定するモデルとしては他にN-gramモデルを用いたものがあるが，これは一文内の形態素の並びを推定するモデルであり，我々とは問題設定が異なる．また，上に箇条書きとしてあげたような要素は特に考慮していない．英語については，語順を名詞の修飾語の順序関係に限定し統計的に推定するモデルが提案されたが，語順を決定する要因として多くの要素を同時に考慮することはできないため，日本語の語順に対して適用するのは難しい．本論文では，上に箇条書きとしてあげたような要素と語順の傾向との関係をコーパスから学習する手法を提案する．この手法では，語順の決定にはどの要素がどの程度寄与するかだけでなく，どのような要素の組み合わせのときにどのような傾向の語順になるかということもコーパスから自動学習することができる．個々の要素の寄与の度合は最大エントロピー(ME)モデルを用いて効率良く学習する．学習されたモデルの性能は，そのモデルを用いて語順を決めるテストを行ない，元の文における語順とどの程度一致するかを調べることによって定量的に評価することができる．正しい語順の情報はテキスト上に保存されているため，学習コーパスは必ずしもタグ付きである必要はなく，生コーパスを既存の解析システムで解析した結果を用いてもよい．後節の実験で示すように，既存の解析システムの精度が90%程度であったとしても学習コーパスとして十分に役割を果たすのである．</section>
  <section title="語順の学習と生成"/>
  <subsection title="学習モデル">この節ではどの語順が妥当であるかを確率として計算するためのモデルについて述べる．モデルとしては，MEに基づく確率モデルを採用する．まず，MEの基本について説明し，その後，MEに基づく確率モデルについて述べる．</subsection>
  <subsubsection title="ME(最大エントロピー)モデル">一般に確率モデルでは，文脈(観測される情報のこと)とそのときに得られる出力値との関係は既知のデータから推定される確率分布によって表される．いろいろな状況に対してできるだけ正確に出力値を予測するためには文脈を細かく定義する必要があるが，細かくしすぎると既知のデータにおいてそれぞれの文脈に対応する事例の数が少なくなりデータスパースネスの問題が生じる．MEモデルでは，文脈は素性と呼ばれる個々の要素によって表され，確率分布は素性を引数とした関数として表される．そして，各々の素性はトレーニングデータにおける確率分布のエントロピーが最大になるように重み付けされる．このエントロピーを最大にするという操作によって，既知データに観測されなかったような素性あるいはまれにしか観測されなかった素性については，それぞれの出力値に対して確率値が等確率になるようにあるいは近付くように重み付けされる．このように未知のデータに対して考慮した重み付けがなされるため，MEモデルは比較的データスパースネスに強いとされている．このモデルは例えば言語現象などのように既知データにすべての現象が現れ得ないような現象を扱うのに適したモデルであると言える．以上のような性質を持つMEモデルでは，確率分布の式は以下のように求められる．文脈の集合をB，出力値の集合をAとするとき，文脈b(B)で出力値a(A)となる事象(a,b)の確率分布p(a,b)をMEにより推定することを考える．文脈bはk個の素性f_j(1jk)の集合で表す．そして，文脈bにおいて，素性f_jが観測されかつ出力値がaとなるときに1を返す以下のような関数を定義する．g_j(a,b)&amp;=&amp;.eqnarrayこれを素性関数と呼ぶ．ここで，exist(b,f_j)は，文脈bにおいて素性f_jが観測されるか否かによって1あるいは0の値を返す関数とする．次に，それぞれの素性が既知のデータ中に現れた割合は未知のデータも含む全データ中においても変わらないとする制約を加える．つまり，推定するべき確率分布p(a,b)による素性f_jの期待値と，既知データにおける経験確率分布p(a,b)による素性f_jの期待値が等しいと仮定する．これは以下の制約式で表せる．_aA,bBp(a,b)g_j(a,b)&amp;=&amp;_aA,bBp(a,b)g_j(a,b)forf_j(1jk)eqnarrayこの式で，p(a,b)=p(b)p(a|b)p(b)p(a|b)という近似を行ない以下の式を得る．_aA,bBp(b)p(a|b)g_j(a,b)&amp;=&amp;_aA,bBp(a,b)g_j(a,b)forf_j(1jk)eqnarrayここで，p(b)，p(a,b)は，freq(b)，freq(a,b)をそれぞれ既知データにおける事象bの出現頻度，出力値aと事象bの共起頻度として以下のように推定する．p(b)&amp;=&amp;freq(b)_bBfreq(b)p(a,b)&amp;=&amp;freq(a,b)_aA,bBfreq(a,b)eqnarray次に，式()の制約を満たす確率分布p(a,b)のうち，エントロピーH(p)&amp;=&amp;-_aA,bBp(b)p(a|b)log(p(a,b))eqnarrayを最大にする確率分布を推定するべき確率分布とする．これは，式()の制約を満たす確率分布のうちで最も一様な分布となる．このような確率分布は唯一存在し，以下の確率分布p^*として記述される．p^*(a|b)&amp;=&amp;_j=1^k_a,j^g_j(a,b)_aA_j=1^k_a,j^g_j(a,b)(0_a,j)eqnarrayただし，_a,j&amp;=&amp;e^_a,jeqnarrayであり，_a,jは素性関数g_j(a,b)の重みである．この重みは文脈bのもとで出力値aとなることを予測するのに素性f_jがどれだけ重要な役割を果たすかを表している．訓練集合が与えられたとき，_a,jの推定にはImprovedIterativeScaling(IIS)アルゴリズムなどが用いられる．式()の導出については文献を参照されたい．</subsubsection>
  <subsubsection title="語順モデル">本節では語順を学習するためのMEモデルについて述べる．ここで語順は，ある一つの文節に対しそれに係る文節(係り文節)が複数あるとき，その係り文節の順序を語順と定義する．係り文節の数はさまざまであるが，係り文節の数によらず二つずつ取り上げてその順序を学習するモデルを提案する．これを語順モデルと呼ぶ．このモデルは前節のMEモデルにおける式()を用いて以下のように求められる．ある文脈bにおいて文節Bに係る文節が二つあるときそれぞれを文節B_1と文節B_2とすると，B_1の次にB_2という順序が適切である確率p^*(1|b)は，出力値aを二つの文節の順序が適切であるか否かの1,0の二値とし，k個の素性f_j(1jk)を考えるとき次の式で表される．p^*(1|b)&amp;=&amp;_j=1^k_1,j^g_j(1,b)_j=1^k_1,j^g_j(1,b)+_j=1^k_0,j^g_j(0,b)eqnarrayこの式の_1,j，_0,jの値を学習するためのデータとしては，形態素解析，構文解析済みのコーパスを用いる．一般に係り文節が二つ以上あるときは次のようにする．ある文脈bにおいて文節Bに係る文節が文節B_1，文節B_2，，文節B_n(n2)のn個あるとき，その順序が適切である確率をP(1|b)とすると，この確率は係り文節を二つずつ取り上げたときそれぞれの順序が適切である確率，つまり，P(W_i,i+j=1|1in-1,1jn-i|b)で表される．ここで，W_i,i+j=1は文節iと文節(i+j)の順序がこの順で適切であることを表す．このとき，W_i,i+jはそれぞれ独立であると仮定すると，P(1|b)は次の式で表される．P(1|b)&amp;=&amp;P(W_i,i+j=1|1in-1,1jn-i|b)&amp;&amp;_i=1^n-1_j=1^n-iP(W_i,i+j=1|b_i,i+j)&amp;=&amp;_i=1^n-1_j=1^n-ip^*(1|b_i,i+j)eqnarrayここで，b_i,i+jは文節Bとそれに係る文節B_i，文節B_i+jに着目したときの文脈を表す．例えば，コーパスに「昨日／太郎は／テニスを／した．」(／は文節の区切りを表す．)という文があった場合を考える．動詞「した」に係る文節は「昨日」，「太郎は」，「テニスを」の三つである．語順モデルでは，このうち二文節ずつ，つまり「昨日」と「太郎は」，「昨日」と「テニスを」，「太郎は」と「テニスを」の三つのペアを取り上げ，それぞれこの語順が適切であると仮定して学習する．素性としては文節の持つ属性などを考える．例えば，「昨日／太郎は／した．」という関係からは「時相名詞」の方が「固有名詞」より前に来るという情報，「太郎は／テニスを／した．」という関係からは「は」格の方が「を」格より前に来るという情報などを用いる．</subsubsection>
  <subsection title="語順の生成">本節では学習した語順モデルを用いて語順を生成するアルゴリズムについて説明する．語順の生成とは，ある文節に対し複数の係り文節があるものについて，その係り文節の順序を決めることを言う．入力は係り受け関係にある文節および素性の有無を判定するのに必要な情報であり，出力は係り文節の並びである．ただし，各文節を構成する語の語彙選択はすでになされており，文節間の係り受け関係は決まっていると仮定する．素性の有無を判定するのに必要な情報とは，形態素情報，文節区切り情報，統語情報，文脈情報などである．実際に実験で用いた情報については~章で述べる．語順の生成は次の手順で行なう．手順係り文節について可能性のある並びをすべて考える．それぞれの並びについて，その係り文節の順序が適切である確率を語順モデルを用いて求める．全体の確率が最大となる並びを解とする．全体の確率としては式()を用いる．例えば，再び「昨日／太郎は／テニスを／した．」という文を考えよう．動詞「した」に係る文節は「昨日」，「太郎は」，「テニスを」の三つである．この三つの係り文節の順序を以下の手順で決定する．二文節ずつ，つまり「昨日」と「太郎は」，「昨日」と「テニスを」，「太郎は」と「テニスを」の三つのペアを取り上げ，語順モデルの式()を用いてそれぞれこの語順が適切である確率P_昨日,太郎は，P_昨日,テニスを，P_太郎は,テニスをを求める．例えば，ある文脈においてそれぞれ0.6，0.8，0.7であったと仮定する．六つの語順の可能性すべてについて全体の確率を計算し(表~)はそれぞれ独立であると仮定したため，式()は近似式となっている．したがって，式()により計算される確率の総和は必ずしも1にはならない．さらに，ここで例としてあげた確率P_昨日,太郎は=0.6，P_昨日,テニスを=0.8，P_太郎は,テニスを=0.7は適当に与えたものであるため，表~の六つの語順の可能性すべてについて全体の確率を計算し，その総和をとっても1にはならない．，最も確率の高いもの「昨日／太郎は／テニスを／した．」が最も適切な語順であるとする．[htbp]table*</subsection>
  <subsection title="性能評価">本節では語順モデルの性能つまりコーパスにおける語順をどの程度学習できたかを評価する方法について述べる．性能の評価は，コーパスから係り受け関係にある文節で複数の係り文節を持つものを取り出し，これを入力として節で述べた方法で語順を生成し，どの程度元の文における語順と一致するかを調べることによって行なう．この一致する割合を一致率と呼ぶことにする．このように元の文とどの程度一致するかを評価の尺度として用いることによって，客観的な評価が可能となる．また，一致率によって評価しておけば，学習したモデルがどの程度学習コーパスにおける語順に近いものを生成できるかを知った上でそのモデルを使うことができる．一致率の尺度としては以下の二種類のものを用いる．</subsection>
  <section title="実験と考察">この章では，語順生成の実験をいろいろな角度から分析する．実験には，京大コーパス(Version2)を用いた．学習には1月1日から8日までと1月10日から6月9日までの17,562文を，試験には1月9日と6月10日から6月30日までの2,394文を用いた．</section>
  <subsection title="実験データにおける語順の定義">ある一つの文節に対しそれに係る文節(係り文節)が複数あるとき，その係り文節の順序を語順と定義した．我々が用いた実験データでは，各文節は係り先(受け文節)の情報を一つだけ持つ．そして，ある文節B_mとその受け文節B_dとの間にB_dと並列の関係にある文節B_pがある場合，B_pにはその受け文節がB_dであるという情報とともに並列を表すラベル(P)が付与されている．これは，文節B_mがB_pとB_dの両方に係り得ることを間接的に示している．このような場合は文節B_mがB_pとB_dの両方に係るとする．以上の条件の下では，ある文節Bの係り文節は以下の手順で同定できる．Bを受け文節とする文節はBの係り文節とする．Bにラベルが付与されているとき，Bよりも文頭に近い位置にありBと同じ受け文節を持つ文節はBの係り文節とする．Bの係り文節の係り文節うちラベルが付与された文節はBの係り文節とする．手順(3)を再帰的に繰り返す．以上の手順で，並列の関係にある文節はすべて同じ文節に係るものとして同定される．例えば，表~の左欄のようなデータからはそれぞれの文節に対し，同表の右欄のような係り文節が得られる．ここで例えば，「出て，」と「優勝した」が並列の関係にあることから，「優勝した．」の係り文節である「花子は」は「出て，」にも係る文節として同定されている．また，「太郎と」と「花子は」が並列の関係にあることから，「太郎と」は「花子は」と同じ受け文節に係る文節として同定されている．[htbp]table*</subsection>
  <subsection title="実験結果">まず，語順の学習および生成の実験に用いた素性を表~，表~に示す．表~にあげた素性は素性名と素性値から成り，文節が持ち得る属性の情報，統語情報，文脈情報を表している．これらを基本素性と呼ぶ．一方，表~にあげた素性は基本素性の組み合わせである．これらの素性は文献の「語順を支配する基本条件」をできるだけ反映するように選んだ．素性の総数はおよそ19万個である．そのうち学習には学習コーパスに3回以上観測されたもの51,590個を用いた．表~，表~の素性名で使われている用語の意味は以下の通りである．表~でタイプ1からタイプ6までは文節内の属性を表し，タイプ7からタイプ10までは統語的な情報を表す．タイプ11とタイプ12は文脈的な情報を表す．次に我々の解析結果を表~に示す．第1行は京大コーパス1月9日と6月10日から6月30日までの2,394文のうち係り文節を二つ以上持つ文節5,278文節に対して，その係り受け関係にある文節およびそれらの文節に関してコーパスから得られる形態素情報，文節区切り情報，統語情報，文脈情報を入力とし，語順を生成させたときの結果である．ただし，統語情報としては係り受けが並列あるいは同格の関係にあるかどうかおよび文末であるかどうかの情報のみを与える．また，文脈情報としては生成の対象となっている文節を含む文の前の文を与える．ベースライン1としてはランダムに選んだ場合の一致率をあげた．ベースライン2としては，語順モデルの式()の代わりに次の式を用いたときの一致率をあげた．p^*(1|b)&amp;=&amp;freq(w_12)freq(w_12)+freq(w_21)eqnarrayここで，freq(w_12)，freq(w_21)は，係り文節B_1とB_2の語形の見出し語をw_1，w_2，受け文節Bの主辞見出しをwとするとき，これらが毎日新聞91年から97年のテキストにおいてそれぞれ「w_1／w_2／w」，「w_2／w_1／w」の順に現れた頻度を表す)，freq(w_21)としてそれぞれ，「w_1／w_2」，「w_2／w_1」の順に現れた頻度を用いた．さらにfreq(w_12)，freq(w_21)がいずれも0のときは0から1までの乱数値を与えた．．式()を用いると例えば，「太郎は／テニスを／した．」の場合，「は／を／した」の順に現れる頻度と「を／は／した」の順に現れる頻度を調べ，頻度が大きい並びを解とすることになる．</subsection>
  <subsection title="素性と一致率">この節では，我々が実験で用いた素性が一致率の向上にどの程度貢献しているかを示す．~節にあげた表~，表~の右欄には，それぞれの素性を削除したときの一致率と削除したことによる一致率の増減を示してある．基本素性を削るときは，それを含む組み合わせの素性も一緒に削った．最も一致率の増加に貢献していると考えられるのは，語形の情報である．語形は主に格や活用形を表す部分であり，この部分の情報によって最も語順が影響を受けているという結果は人間の直観とも合っている．我々が実験に用いた素性は，言語学的な研究において「語順を支配する基本条件」とされているものをできるだけ反映したものである．その条件がどの程度一致率に影響しているかを示すために，表~，表~に素性のまとまりごとにその素性を削除したときの一致率を示した．しかし，「は」「を」などの助詞をひとまとまりとして削除しているなど，削除する単位が言語学的に興味のある情報よりも粗い可能性がある．そのような場合には，興味のある要素に対応する素性のみ，例えば助詞の「は」のみについて，その素性を削除したときとしなかったときの一致率を比べることにより，その重要性を定量的に検証することが可能である．さらに新たな言語学的成果に対してもそれに対応するような素性を追加して一致率に有意な増加がみられるかどうかを調べることにより，同様に検証することができると考えられる．</subsection>
  <subsection title="学習コーパスと一致率">この節では，学習コーパスと一致率の関係について考察する．まず，図~，図~に学習コーパスの量と一致率の関係をあげる．これらの図には学習コーパスとテストコーパスのそれぞれを解析した場合のコーパスの量と一致率の関係を載せている．学習コーパスに対する実験としては基本的に京大コーパス1月1日の1,172文を用いた．学習コーパスが250文，500文のときは1月1日の1,172文のうち上から250文，500文を用いた．学習コーパスが250文という少ない量でもテストコーパスに対して二文節単位で82.54%，完全一致で68.40%の一致率となっている．これはベースラインよりもかなり高い一致率である．この結果は，学習コーパスの量が少なくても新聞記事に対してはある程度語順の傾向を学習できることを示している．学習コーパスが17,562文のとき，一致率は完全一致で75.41%である．テストコーパスと一致しなかった残りの約25%のうちいくつかは学習がうまくできなかったものであり，残りは語順が比較的自由なもので必ずしもコーパスと一致しなくてもよいものであると考えられる．前者に対しては誤りを分析して，語順の傾向を効率良く学習する素性をもっと補う必要がある．そこで，テストコーパスに対する結果を調査した．係り文節の語順がテストコーパスと一致しなかった1,298文節から，ランダムに100文節を選び分析した．そのうち，システムが生成した語順でも不自然ではないものが48個，不自然なものが52個であった．この不自然なものがテストコーパスの語順と一致するようになるには，大量の学習コーパス，および表~，表~にあげたものとは性質の異なる素性が必要である．学習コーパスが不十分であると思われるものの中には，「法治国家が／聞いて／あきれる」，「創案したのが／そもそもの／始まり」，「味に／精魂／込める」などイディオム的な表現を含むものが多かった．コーパスの量が増えればこのような表現に対しては適切な語順が学習される可能性が高い．新たな素性を考慮するべきであると思われるものの中には，並列関係を含むものが目立った．これについては今後の言語学的な知見なども考慮しながら有効そうな素性を追加したい．今回素性として用いた意味素性および文脈指示語や承前反復語は，意味解析，文脈解析をした結果を基にしている訳ではない．これらをより有効に利用できるようにするためには，意味タグや文脈タグなどが付与されたコーパスおよび意味解析システムや文脈解析システムを統合して用いていく必要がある．</subsection>
  <subsection title="生コーパスからの学習">正しい語順の情報はテキスト上に保存されているため，学習コーパスは必ずしもタグ付きである必要はなく，生コーパスに対し既存のシステムを用いて解析した結果を学習に用いることもできる．本節では，タグ付きコーパスと生コーパスを用いて，あるいは生コーパスのみを用いて学習したときにどの程度の一致率が得られるかについて実験結果を示し考察する．生コーパスとしては毎日新聞1994年版の最初の200,000文と，京大コーパスの1月1日から8日までと1月10日から6月9日までの17,562文，合計217,562文を用いた．このうち京大コーパスの17,562文はタグの付与されていない原文を用いた．生コーパスに対しては，そこから素性の情報を得るために形態素解析，構文解析を行なう．形態素解析にはJUMAN，構文解析にはKNPを用いた．JUMANは形態素区切りおよび品詞の付与の精度が98%程度，KNPは係り受け単位の精度が90%程度である．これらはいずれも新聞記事に対する精度である．テストコーパスに対する一致率は，学習コーパスとして生コーパスのみ217,562文を用いた場合，二文節単位で87.64%，完全一致で75.77%であり，学習コーパスとして生コーパス(毎日新聞1994年版の最初の200,000文)とタグ付コーパス(京大コーパスの17,562文)合計217,562文を用いた場合，二文節単位で87.66%，完全一致で75.88%であった．いずれの場合もタグ付コーパスのみ17,562文を用いたときに比べて，0.2%から0.5%程度一致率が増加した．この結果から，タグ付きコーパスが少ない場合は，既存の解析システムの精度が90%程度であれば生コーパスのみでも学習コーパスとして十分に役割を果たすことが分かる．またこの結果は語順の学習はシステムの解析誤りの影響をあまり受けないということを示していると言える．</subsection>
  <section title="まとめ">本論文ではコーパスから語順を学習する方法について述べた．ここで語順は，ある一つの受け文節に対し係り文節が複数あるときその係り文節の順序を表すものと定義した．係り文節の数はさまざまであるが，係り文節の数によらず二つずつ取り上げてその順序を学習するモデルを提案した．学習モデルにはME(最大エントロピー)モデルを用いた．このモデルは，学習コーパスから得られる情報を基に適切な語順を予測するのに有効な素性を学習することによって得られる．我々が素性として利用したのは，文節の持つ属性，統語情報，文脈情報およびそれらの組み合わせである．これらの素性のうちそれぞれを削除した実験を行なうことによって，その中でも格や活用部分の情報が語順の傾向を学習する上で特に有効に働くことが分かった．また，学習コーパスの量を変えて実験を行なうことによって，我々の手法が少ない学習データに対しても効率良く語順を学習できるだけでなく，タグ付コーパスだけでなく生コーパスも学習に利用できることも分かった．学習したモデルを用いて語順を生成させたとき，コーパスと一致する割合は，京大コーパスを使用した実験で75.41%であった．一致しなかった残りの約25%をサンプリング調査したところ，その48%がモデルを用いて生成した語順でも不自然ではないことが分かった．今回の実験には新聞記事のような一般的な語順のテキストを用いた．スタイルが異なれば語順の傾向も異なると考えられるため，今後，小説などのように新聞記事とはスタイルが異なるテキストを用いて実験し，我々の提案したモデルがどの程度語順の傾向の違いを学習できるかを調べたい．また，本論文で扱ったのは日本語の語順であったが，英語についても同様に語順の傾向を学習できると考えられる．今後，英語についても同様のモデルを用いて語順を学習し，モデルの評価をしたい．文生成においては一般に客観的な評価基準がないため評価が難しいが，本論文で示したようにコーパスに基づく評価方法をとることにより，少なくとも語順の生成に関しては客観的な評価が可能になったと言えるだろう．本論文で我々が提案した手法には，以下のような応用が考えられる．校正支援ユーザが作文した文を構文解析して依存構造を得た後，それを入力として語順を生成させユーザに提示する．語順モデルを用いて生成させた語順の方がユーザの作文における語順より自然な語順になっている可能性が高いと考えられる．機械翻訳における対象言語の語順の生成対象言語において，文節間の依存構造が決まり，各文節において語彙選択が終了すれば，我々が提案した語順モデルを用いて一文全体の語順を決めることができる．このとき一文全体の語順としては，一文全体の語順の確率が最大となるものを選ぶ．一文全体の語順の確率は，受け文節ごとにその受け文節に係る文節の順序の確率を式()を用いて求め，その積として求める．構文解析における誤り検出構文解析結果に複数の係り文節を持つ文節がある場合，その係り文節の順序の確率を式()を用いて求め，その値が著しく低い場合に誤りとして検出する．document</section>
</root>
