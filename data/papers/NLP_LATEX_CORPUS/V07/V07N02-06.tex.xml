<?xml version="1.0" ?>
<root>
  <title/>
  <author/>
  <jkeywords/>
  <section title="Introduction">Thetaskofinformationretrievalsystemistoextractrelevantdocumentsfromalargecollectionofdocumentsinresponsetouserqueries.Mostmoderninformationretrievalsystemsdonotoutputasetofdocumentsforaquery.Instead,theyoutputalistofdocumentsrankedindescendingorderofrelevancetothequery.Inconsequence,thetaskofmoderninformationretrievalsystemcanbere-statedastopushtherelevantdocumentstothetopoftheretrieveddocumentsrank.Althoughinformationcanbepresentedindiverseformsuchastabularnumericaldata,graphicaldisplays,photographicimages,humanspeech,andsoon,theterminformationretrievalasusedinthispapershallreferspecificallytotheretrievaloftextualinformation.Thefundamentalproblemsininformationretrievalisthattherearemanywaystoexpressthesameconceptinnaturallanguage.Userindifferentcontexts,orwithdifferentinformationneedsorknowledgeoftendescribethesameinformationusingdifferentterms.Inconsequence,relevantdocumentwhichdonotcontaintheexacttermsasthequerywillbeputinlowrank.Inthispaper,weaddressthewordmismatchproblemthroughautomaticqueryexpansion.Thequeryisexpandedbyusingtermswhichhaverelatedmeaningtothoseinthequery.Theexpansiontermscanbetakenfromthesauri.Roughly,therearetwotypesofthesauri,i.e.,hand-craftedthesauriandcorpus-basedautomaticallyconstructedthesauri.Hand-craftedthesauridescribethesynonymousrelationshipbetweenwords,thoughmanythesauriusefinergrainedrelationsuchasbroaderterms,narrowerterms,andsoon.Someofthehand-craftedthesauriareforspecificdomainswhileothersareforgeneralpurpose.Therelationinhand-craftedthesauricanbeusedforqueryexpansion.Queryexpansionusingspecificdomainthesaurihasbeenreportedyieldingaverygoodresults.Currently,thenumberofexistingdomainspecificthesauricanbecountedbyfinger,whilethenumberofdomainintheworldisverylarge.Unfortunatelybuildingsuchthesaurimanuallyrequiresalotofhumanlaborfromlinguistsordomainexpertsandspendingverymuchtime.Incontrast,theuseofgeneral-purposethesauriforqueryexpansionhasbeenreportedfailtoimprovetheinformationretrievalperformancebyseveralresearchers.Automaticthesaurusconstructionisanextensivestudiedareaincomputationallinguistics.Theoriginalmotivationbehindtheautomaticthesaurusconstructionistofindaneconomicalternativetohand-craftedthesaurus.Broadly,therearetwomethodstoconstructthesaurusautomatically.Thefirstoneisbasedonthesimilaritiesbetweenwordsonthebasisofco-occurrencedataineachdocument,andtheotheroneisbasedontheco-occurrenceofsomesyntacticrelationssuchaspredicate-argumentinthewholedocuments.Manyresearcherfoundsomeslightimprovementusingtheco-occurrence-basedthesaurus,andsomemixedresultsusingthesyntactic-relation-basedthesaurus.Previously,weconductedananalysisofthedifferenttypesofthesauridescribedabove,andfoundthateachtypeofthesaurushasdifferentadvantagesanddisadvantageswhichcanbesummarizedasfollows:Hand-craftedthesauruscancapturegeneraltermrelation.cannotcapturedomain-specificrelation.Co-occurrence-basedthesauruscancapturedomain-specificrelation.cannotcapturetherelationbetweentermswhichdonotco-occurinthesamedocumentorwindow.Syntactic-relation-basedthesauruscancapturedomain-specificrelation.cancapturetherelationbetweentermseventhoughtheydonotco-occurinthesamedocument.wordswithsimilarheadsormodifiersarenotalwaysgoodcandidatesforexpansionInthispaperweexploreandanalyzeamethodtocombinethethreetypesofthesauri(hand-crafted,co-occurrence-based,andsyntactic-relation-basedthesaurus)forthepurposeofqueryexpansion.Inthenextsectionwedesribethedetailmethodofcombiningthesauri,andinSection3wegivesomeexperimentalresultsusingalargeTREC-7collectionandseveralsmallinformationretrievaltestcollections.WediscusswhyourmethodworkinSection4andalsoperformfailureanalysisinSection5.Wetriedtocombineourmethodwithpseudo-relevance-feedbackalongwithexperimentalresultsinSection6.Finally,inSection7wegiveconclusionsandfuturework.</section>
  <section title="Method">Inthissection,wefirstdescribeourmethodtoconstructeachtypeofthesaurusutilizedinthisresearch,andthendescribeourattemptominimizethemisleadingexpansiontermsbyusingtermweightingmethodbasedonthesethesauri.</section>
  <subsection title="WordNet">WordNetisamachine-readablehand-craftedthesaurus.WordformsinWordNetarerepresentedintheirfamiliarorthograpyandwordmeaningsarerepresentedbysynonymsets(synset).Asynonymsetrepresentsaconceptandcomprisesallthosetermswhichcanbeusedtoexpresstheconcept.Inotherwordasynsetisalistofsynonymouswordformsthatareinterchangeableinsomecontext.Thesimilaritybetweenwordsw_1andw_2canbedefinedastheshortestpathfromeachsenseofw_1toeachsenseofw_2,asbelow~:sim_path(w_1,w_2)=max[-(N_p2D)]displaymathwhereN_pisthenumberofnodesinpathpfromw_1tow_2andDisthemaximumdepthofthetaxonomy.Similarityalsocanbemeasuredusingtheinformationcontentoftheconceptsthatsubsumewordsinthetaxonomy,asbelow~:[sim_IC(w_1,w_2)=_cS(c_1,c_2)[-p(c)]]whereS(c_1,c_2)isthesetofconceptsthatsubsumebothc_1andc_2.Conceptprobabilitiesarecomputedsimplyastherelativefrequencyderivedfromthedocumentcollection,[p(c)=freq(c)N]whereNisthetotalnumberofnounsobserved,excludingthosenotsubsumedbyanyWordNetclass.Wesumupthepath-basedsimilarityandinformation-content-basedsimilaritytoserveasthefinalsimilarity.</subsection>
  <subsection title="Co-occurrence-based thesaurus">Co-occurrence-basedthesaurusutilizethenumberofoccurrenceorco-occurrenceofwordswithinadocumentorwithinawindowasasourceofinformationtobuildthesaurus.WeusetextualwindowsbasedonTextTilingalgorithmtocalculatethemutualinformationbetweenapairofwords.TextTilingisaparagraph-levelmodelofdiscoursestructurebasedonthenotionofsubtopicshiftandanalgorithmforsubdividingexpositorytextintomulti-paragraphpassagesorsubtopicsegments.Thisalgorithmmakesuseofpatternsoflexicalco-occurrenceanddistribution.Thealgorithmhasthreeparts:tokenizationintotermsandsentence-sizedunits,determinationofascoreforeachsentence-sizedunit,anddetectionofthesubtopicboundaries,whichareassumedtooccuratthelargestvalleysinthegraphthatresultsfromplottingsentence-unitagainstscores.WethenemployaninformationtheoreticdefinitionofmutualinformationwhichcomparestheprobabilityofobservingtwowordstogethertothatofobservingeachwordindependentlyinthepassagesdefinedbyTextTiling.Wordshavinghighmutualinformationoveracorpusareassumedsemanticallyrelated.</subsection>
  <subsection title="Syntactic-relation-based Thesaurus">Thebasicpremiseofthismethodtobuildthesaurusisthatwordsfoundinthesamegrammaticalcontexttendtosharesemanticsimilarity.Syntacticanalysisallowsustoknowwhatwordsmodifyotherwords,andtodevelopcontextsfromthisinformation.Tobuildsuchthesaurus,firstly,allthedocumentsareparsedusingtheApplePieParser.Thisparserisabottom-upprobabilisticchartparserwhichfindstheparsetreewiththebestscorebywayofthebest-firstsearchalgorithm.Itsgrammarisasemi-contextsensitivegrammarwithtwonon-terminalsandwasautomaticallyextractedfromPennTreeBanksyntacticallytaggedcorpusdevelopedattheUniversityofPennsylvania.TheparsergeneratesasyntactictreeinthemannerofaPennTreeBankbracketing.Theaccuracyofthisparserisreportedasparsevalrecall77.45%andparsevalprecision75.58%.Usingtheaboveparser,weextractedsubject-verb,verb-object,adjective-noun,andnoun-nounrelations,sothateachnounhasasetofverbs,adjectives,andnounsthatitco-occurswith,andforeachsuchrelationship,amutualinformationvalueiscalculated.I_sub(v_i,n_j)=f_sub(n_j,v_i)/N_sub(f_sub(n_j)/N_sub)(f(v_i)/N_sub)wheref_sub(v_i,n_j)isthefrequencyofnounn_joccurringasthesubjectofverbv_i,f_sub(n_j)isthefrequencyofthenounn_joccurringassubjectofanyverb,f(v_i)isthefrequencyoftheverbv_i,andN_subisthenumberofsubject-verbrelations.I_obj(v_i,n_j)=f_obj(n_j,v_i)/N_obj(f_obj(n_j)/N_obj)(f(v_i)/N_obj)wheref_obj(v_i,n_j)isthefrequencyofnounn_joccurringastheobjectofverbv_i,f_obj(n_j)isthefrequencyofthenounn_joccurringasobjectofanyverb,f(v_i)isthefrequencyoftheverbv_i,andN_objisthenumberofverb-objectrelations.I_adj(a_i,n_j)=f_adj(n_j,a_i)/N_adj(f_adj(n_j)/N_adj)(f(a_i)/N_adj)wheref(a_i,n_j)isthefrequencyofnounn_joccurringastheargumentofadjectivea_i,f_adj(n_j)isthefrequencyofthenounn_joccurringastheargumentofanyadjective,f(a_i)isthefrequencyoftheadjectivea_i,andN_adjisthenumberofadjective-nounrelations.I_noun(n_i,n_j)=f_noun(n_j,n_i)/N_noun(f_noun(n_j)/N_noun)(f(n_i)/N_noun)wheref(n_i,n_j)isthefrequencyofnounn_joccurringastheargumentofnounn_i,f_noun(n_j)isthefrequencyofthenounn_joccurringastheargumentofanynoun,f(n_i)isthefrequencyofthenounn_i,andN_nounisthenumberofnoun-nounrelations.Thesimilaritybetweentwowordsw_1andw_2canbecomputedasfollows:[sim(w_1,w_2)=_(r,w)T(w_1)T(w_2)(I_r(w_1,w)+I_r(w_2,w))_(r,w)T(w_1)I_r(w_1,w)+_(r,w)T(w_2)I_r(w_2,w)]whereristhesyntacticrelationtype,andwisaverb,ifristhesubject-verborobject-verbrelation.anadjective,ifristheadjective-nounrelation.anoun,ifristhenoun-nounrelation.andT(w)isthesetofpairs(r,w')suchthatI_r(w,w')ispositive.</subsection>
  <subsection title="Combination and Term Expansion Method">Aqueryqisrepresentedbythevector=(w_1,w_2,...,w_n),whereeachw_iistheweightofeachsearchtermt_icontainedinqueryq.WeusedSMARTversion11.0toobtaintheinitialqueryweightusingtheformulaltcasbelows:[((tf_ik)+1.0)*(N/n_k)_j=1^n[((tf_ij+1.0)*(N/n_j)]^2]wheretf_ikistheoccurrrencefrequencyoftermt_kinqueryq_i,Nisthetotalnumberofdocumentsinthecollection,andn_kisthenumberofdocumentstowhichtermt_kisassigned.Usingtheaboveweightingmethod,theweightofinitialquerytermsliesbetween0and1.Ontheotherhand,thesimilarityineachtypeofthesaurusdoesnothaveafixedrange.Hence,weapplythefollowingnormalizationstrategytoeachtypeofthesaurustobringthesimilarityvalueintotherange[0,1].[sim_new=sim_old-sim_minsim_max-sim_min]Althoughtherearemanycombinationmethodsthatcanbetried,wejustdefinethesimilarityvaluebetweentwotermsinthecombinedthesauriastheaverageoftheirsimilarityvalueoveralltypesofthesaurusbecausewedonotwanttointroduceadditionalparametersherewhichdependonqueriesnature.Thesimilaritybetweenaqueryqandatermt_jcanbedefinedasbelows:[simqt(q,t_j)=_t_iqw_i*sim(t_i,t_j)]wherethevalueofsim(t_i,t_j)istakenfromthecombinedthesauriasdescribedabove.Withrespecttothequeryq,allthetermsinthecollectioncannowberankedaccordingtotheirsimqt.Expansiontermsaretermst_jwithhighsimqt(q,t_j).Theweight(q,t_j)ofanexpansiontermt_jisdefinedasafunctionofsimqt(q,t_j):[weight(q,t_j)=simqt(q,t_j)_t_iqw_i]where0weight(q,t_j)1.Theweightofanexpansiontermdependsbothonalltermsappearinginaqueryandonthesimilaritybetweentheterms,andrangesfrom0to1.Thisweightcanbeinterpretedmathematicallyastheweightedmeanofthesimilaritiesbetweenthetermt_jandallthequeryterms.Theweightoftheoriginalquerytermsaretheweightingfactorsofthosesimilarities.Thereforethequeryqisexpandedbyaddingthefollowingquery:[q_e=(a_1,a_2,...,a_r)]wherea_jisequaltoweight(q,t_j)ift_jbelongstothetoprrankedterms.Otherwisea_jisequalto0.Theresultingexpandedqueryis:[q_expanded=qq_e]wheretheisdefinedastheconcatenationoperator.Themethodabovecanaccommodatepolysemy,becauseanexpansiontermwhichistakenfromadifferentsensetotheoriginalquerytermisgivenaverylowweight.</subsection>
  <section title="Experimental Results"/>
  <subsection title="Test Collection">AsamaintestcollectionweuseTREC-7collection.TREC(TextREtrievalConference)isanDARPA(DefenseAdvancedResearchProjectAgency)andNIST(NationalInstituteofStandardsandTechnology)co-sponsoredeffortthatbringstogetherinformationretrievalresearchersfromaroundtheworldtodiscussandcomparetheperformanceoftheirsystems,andtodevelopalargetestcollectionforinformationretrievalsystem.Theseventhinthisseriesofannualconferences,TREC-7,attracted56differentparticipantsfromacademicinstitutions,governmentorganizations,andcommercialorganizations.Withsuchalargeparticipationofvariousinformationretrievalresearchers,alargeandvariedcollectionsoffull-textdocuments,alargenumberofuserqueries,andasuperiorsetofindependentrelevancejudgements,TRECcollectionshaverightfullybecomethestandardtestcollectionsforcurrentinformationretrievalresearch.ThecommoninformationretrievaltaskofrankingdocumentsforanewqueryiscalledtheadhoctaskintheTRECframework.TheTRECdatacomesonCD-ROMs,calledtheTRECdisks.Thedisksarenumbered,andacombinationofseveraldiskcanbeusedtoformatextcollectionforexperimentation.TheTREC-7testcollectionconsistsof50topics(queries)and528,155documentsfromseveralsources:theFinancialTimes(FT),FederalRegister(FR94),ForeignBroadcastInformationService(FBIS)andtheLATimes.Eachtopicconsistsofthreesections,theTitle,DescriptionandNarrative.Table~showsstatisticsoftheTREC-7documentcollection,Table~showsstatisticsofthetopics,andFigure~showsanexampleofatopic,andFigure~showsitsexpansiontermsproducedbyourmethod.[htbp]figure*[htbp]figure*Itiswellknownthatmanyinformationretrievaltechniquesaresensitivetofactorssuchasquerylength,documentlength,andsoforth.Forexample,onetechniquewhichworksverywellforlongqueriesmaynotworkwellforshortqueries.Toensurethatourtechniquesandconclusionsaregeneral,weusedifferent-lengthqueryinTREC-7collection.BesidethelargeandthenewerTREC-7testcollectiondescribedbefore,wealsousesomeprevioussmalltestcollections,becausealthoughmostrealworldcollectionsarelarge,somecanbequitesmall.ThesesmallcollectionshavebeenwidelyusedintheexperimentsbymanyinformationretrievalresearchersbeforeTREC.Theseoldtestcollectionshavealwaysbeenbuilttoservesomepurpose.Forexample,theCranfieldcollectionwasoriginallybuilttotestdifferenttypesofmanualindexing,theMEDLINEcollectionwasbuiltinanearlyattempttocomparetheoperationalBooleanMEDLARSsystemwiththeexperimentalrankingusedinSMART,andtheCACMandCISIcollectionswerebuilttoinvestigatetheuseofanextendedvectorspacemodelthatincludedbibliographicdata.Mostoftheoldtestcollectionsareverydomainspecificandcontainonlytheabstract.InTable~and~wedescribethestatisticsandthedomainoftheoldcollection,respectively.</subsection>
  <subsection title="Evaluation method">Recallandprecisionaretwowidelyusedmetricstomeasuretheretrievaleffectivenessofaninformationretrievalsystem.Recallisthefractionoftherelevantdocumentswhichhasbeenretrieved,i.e.[recall=number~of~relevant~documents~retrievednumber~of~relevant~documents~in~collection.]isthefractionoftheretrieveddocument,i.e.[precision=number~of~relevant~documents~retrievedtotal~number~of~documents~retrieved.]However,precisionandrecallareset-basedmeasures.Thatis,theyevaluatethequalityofanunorderedsetofretrieveddocuments.Toevaluaterankedlists,precisioncanbeplottedagainstrecallaftereachretrieveddocument.Tofacilitatecomparingperformanceoverasetoftopics,eachwithadifferentnumberofrelevantdocuments,individualtopicprecisionvaluesareinterpolatedtoasetofstandardrecalllevels(0to1inincrementsof0.1).Theparticularruleusedtointerpolateprecisionatstandardrecallleveliistousethemaximumprecisionobtainedforthetopicforanyactualrecalllevelgreaterthanorequaltoi.Notethatwhileprecisionisnotdefinedatarecall0.0,thisinterpolationruledoesdefineaninterpolatedvalueforrecalllevel0.0.Forexampleassumeadocumentcollectionhas20documents,fourofwhicharerelevanttotopictinwhichtheyareretrievedatranks1,2,4,15.Theexactrecallpointsare0.25,0.5,0.75,and1.0.Usingtheinterpolationrule,theinterpolatedprecisionforallstandardrecalllevels0.0,0.1,0.2,0.3,0.4,and0.5is1,theinterpolatedprecisionforrecalllevels0.6and0.7is0.75,andtheinterpolatedprecisionforrecalllevels0.8,0.9,and1.0is0.27.</subsection>
  <subsection title="Results">Table~showstheaverageof11-pointinterpolatedprecisionusingvarioussectionoftopicsinTREC-7collection,andTable~showstheaverageof11-pointinterpolatedprecisioninseveralsmallcollections.Wecanseethatourmethodgiveaconsistentandsignificantimprovementcomparedwiththebaselineandusingonlyonetypeofthesaurus.[hbpt]table*</subsection>
  <section title="Discussion">Theimportantpointsofourmethodare:thecoverageofWordNetisbroadenedweightingmethod.Thethreetypesofthesauriweusedhavedifferentcharacteristics.AutomaticallyconstructedthesauriaddnotonlynewtermsbutalsonewrelationshipsnotfoundinWordNet.Iftwotermsoftenco-occurtogetherinadocumentthenthosetwotermsarelikelybearsomerelationship.Whynotonlyusetheautomaticallyconstructedthesauri?Theanswertothisisthatsomerelationshipsmaybemissingintheautomaticallyconstructedthesauri.Forexample,considerthewordstumorandtumour.Thesewordscertainlysharethesamecontext,butwouldneverappearinthesamedocument,atleastnotwithafrequencyrecognizedbyaco-occurrence-basedmethod.Ingeneral,differentwordsusedtodescribesimilarconceptsmayneverbeusedinthesamedocument,andarethusmissedbytheco-occurrencemethods.HowevertheirrelationshipmaybefoundintheWordNetthesaurus.Thesecondpointisourweightingmethod.Asalreadymentionedbefore,mostattemptsatautomaticallyexpandingqueriesbymeansofWordNethavefailedtoimproveretrievaleffectiveness.Theoppositehasoftenbeentrue:expandedquerieswerelesseffectivethantheoriginalqueries.Besidethe``incomplete''natureofWordNet,webelievethatafurtherproblem,theweightingofexpansionterms,hasnotbeensolved.AllweightingmethodsdescribedinthepastresearchesofqueryexpansionusingWordNethavebeenbasedon``trialanderror''orad-hocmethods.Thatis,theyhavenounderlyingjustification.Theadvantagesofourweightingmethodare:theweightofeachexpansiontermconsidersthesimilarityofthattermwithalltermsintheoriginalquery,ratherthantojustoneorsomequeryterms.theweightoftheexpansiontermaccommodatesthepolysemouswordproblem.Thismethodcanaccommodatethepolysemouswordproblem,becauseanexpansiontermtakenfromadifferentsensetotheoriginalquerytermsenseisgivenverylowweight.Thereasonforthisisthat,theweightingmethoddependsonallquerytermsandallofthethesauri.Forexample,thewordbankhasmanysensesinWordNet.Twosuchsensesarethefinancialinstitutionandtheriveredgesenses.Inadocumentcollectionrelatingtofinancialbanks,theriversenseofbankwillgenerallynotbefoundintheco-occurrence-basedthesaurusbecauseofalackofarticlestalkingaboutrivers.Eventhough(withsmallpossibility)theremaybesomedocumentsinthecollectiontalkingaboutrivers,ifthequerycontainedthefinancesenseofbankthentheothertermsinthequerywouldalsoconcernedwithfinanceandnotrivers.Thusriverswouldonlyhavearelationshipwiththebanktermandtherewouldbenorelationshipswithothertermsintheoriginalquery,resultinginalowweight.Sinceourweightingmethoddependsonbothqueryinitsentiretyandsimilarityinthethreethesauri,thewrongsenseexpansiontermsaregivenverylowweight.</section>
  <section title="Failure Analysis">Althoughourmethodasawholegivesaverysignificantimprovement,itstillfurthercanbeimproved.Ofthe50queriesofTREC-7collection,ourmethodimprovestheperformanceof43queriesanddegradetheperformanceof7queriescomparedwiththebaseline.Weinvestigatedmanuallywhyourmethoddegradetheperformanceofseveralqueries.</section>
  <subsection title="Negation statements in the query">Wefoundthatmostofthequerieshurtedbyourmethodcontainsthenegationstatements.Throughourmethod,allthetermsinthenegationstatementsarealsoconsideredforqueryexpansionwhichisdegradingtheretrievalperformanceforthatquery.Figureshowstwoexamplesofquerywhichcontainnegationstatements.[htbp]figure*Tableshowstheresultsofeliminatingthenegationstatementsfromthequeriesmanuallyforeachquerycontainingnegationstatements.Asthattableshown,eliminatingthenegationstatementsimprovestheretrievaleffectiveness.Itistobeinvestigatedfurtherhowwecouldidentifythenegationstatementsautomatically.</subsection>
  <subsection title="Multiple aspects of query">Anexaminationofthetop-rankednon-relevantdocumentsforvariousqueriesshowsthatacommonlyoccurringcauseofnon-relevanceamongsuchdocumentsisinadequatequerycoverage,i.e.,thequeryconsistsofmultipleaspects,onlysomeofwhicharecoveredinthesedocuments.Forexample,aqueryoftheTRECcollectionasks:IdentifydocumentsdiscussingtheuseofestrogenbypostmenopausalwomeninBritain.Severaltop-rankednon-relevantdocumentscontaininformationabouttheuseofhormonebypostmenopausalwomenbutnotinBritain.IfwelookattheexpansiontermsproducedbyourmethodasshowninFigurewecouldseethatmanyexpansiontermshaverelationshipwithallquerytermsexceptBritain.ThisisbecauseallquerytermsbutBritainhaverelationshipbetweeneachotherandthesetermshaveahighoriginaltermweight.Onthecontrary,BritaindoesnothaverelationshipwithotherquerytermsandBritainhavealoworiginaltermweightinalmostalldocumentsincollection.Consequently,thetermrelatedtoBritainaregivenalowweightbyourmethod.[htbp]figure*Toinvestigatetherelatednessorindependenceofquerywords,weexaminetheirco-occurrencepatternsin1000documentsinitiallyretrievedforaquery.Iftwowordshavethesameaspect,thentheyoftenoccurtogetherinmanyofthesedocuments.Ifoneofthewordsappearsinadocument,thechanceoftheotheroccurringwithinthesamedocumentislikelytoberelativelyhigh.Ontheotherhand,iftwowordsbearindependentconcepts,theoccurrencesofthewordsarenotstronglyrelated.Basedonthisobservation,were-rankthetop-1000retrieveddocuments,byre-computingthesimilaritybetweenaqueryq=t_1,t_2,..,t_m(termsareorderedbydecreasingoftheirinversedocumentfrequency)anddocumentDasbelows:[Sim_new(D)=idf(t_1)+_i=2^midf(t_i)~~min_j=1^i-1(1-P(t_i|t_j)),]whereidfistheinverseofdocumentfrequencyinthetop-1000initiallyretrieveddocuments,misthenumberoftermsinquerythatappearindocumentD,andP(t_i|t_j)isestimatedbasedonwordoccurrencesindocumentcollectionandisgivenby:[#~documents~containing~words~t_i~and~t_j#~documents~containing~word~t_j.]Forexample,inthequerystatedabove,thetermsestrogen,postmenopausal,andwomenarestronglyrelatedtoeachother.Ifthetermpostmenopausaloccursinadocument,theprobabilityofwordwomenoccurringinthesamedocumentishigh.Accordingly,thecontributionofwordwomentoSim_newisreducedinthiscase.Ontheotherhand,termspostmenopausalandBritaincorrespondtotwoindependentaspectsofthequeryandtheoccurrencesofthesetwotermsarerelativelyuncorrelated.Therefore,ifadocumentcontainsthesetwoterms,thecontributionofBritainishigheranditcountsasanimportantnewmatchingtermsinceitsoccurrenceisnotwellpredictedbyothermatchingterm(postmenopausal).Thistechniquecanimprovetheaverageof11-pointinterpolatedprecisionofTREC-7collectionforabout3.3%asshowninTable.WealsoinvestigatedanothermethodtoovercomethisprobleminwhichwebuiltaBooleanexpressionforallquerymanually.Termsinthesameaspectofqueryareplacedinorrelation,andtermsindifferentaspectareplacedinandrelation.Documentsthatsatisfytheconstraintcontainatleastonewordfromeachaspectofthequery.Forexample,forthequerystatedbefore(IdentifydocumentsdiscussingtheuseofestrogenbypostmenopausalwomeninBritain),weconstructbooleanexpressionasfollows:estrogenand(postmenopausalorwoman)andbritain.verbatimUsingthismethod,weagainre-rankthetop1000documentsinitiallyretrieved.Documentsthatmatchmorewordsindifferentaspectofqueryarerankedaheadofdocumentsthatmatchlesswords.Tiesareresolvedbyreferringtotheoriginaldocumentweight.Usingthismethodwecanimprovetheaverageof11-pointinterpolatedprecisionofTREC-7collectionforabout11.3%,asshowninTable.Thiscorrelationandbooleanrerankingmethodsdegradesomequeriesperformance,becauseinthosequeriesthesemethodsoverweightseveralqueryterms.Itistobefurtherinvestigatedhowwecoulddesigntheappropriatemethodtoovercomethisproblem.</subsection>
  <section title="Combining with relevance feedback">Inthissection,wedescribethecombinationofourmethodwithpseudo-relevancefeedback.Pseudo-relevancefeedbackisafeedbackaproachwithoutrequiringrelevanceinformation.Instead,aninitialretrievalisperformed,andthetop-nrankeddocumentsareallassumedtoberelevantforobtainingexpansionterms(q_feedback)asbelows:[q_feedback=1|D_r|_d_iD_rd_i]Inthiscase,D_risasetofdocumentsrankedonthetopintheinitialretrievalandd_iisthevectorrepresentationofdocumentd_i.Intheframeworkoftheinferencenetwork,theinformationneedoftheuserisrepresentedbymultiplequeries.Multiplequeriesmeansthataninformationneedisrepresentedbysomedifferentqueryrepresentation.Experimentsshowthatmultiplequeryrepresentationscanproducebetterresultsthanusingonerepresentationalone.However,howtoobtainthesequeriesisnotdiscussedinthismodel.Hencewetrytofindmultiplequeryrepresentationsfortheinformationstructurederivedfromfeedbackinformation.Inthisway,thefollowingthreerepresentationscanbeobtained:representationderiveddirectlyfromtheoriginalquery:q_original,representationobtainedbyourmethod:q_thesauri,representationderivedfromtheretrieveddocumentsofthepreviousrun:q_feedback.Alinearcombinationofthethreequeryrepresentationsisusedtoretrievedocuments.However,wedonotintroduceadditionalparameterswhicharequitedifficulttodetermine.Alsowebelievethattheparametervaluesdeterminedforsomequeriesmaynotbesuitableforsomeotherqueriesbecausetheyarequerydependent.Hencethesimplecombinationweuseis:[q_original+q_thesauri+q_feedback.]Whenusingtherelevance-feedbackmethod,weusedthetop30rankeddocumentsofthepreviousrunoftheoriginalquerytoobtainq_feedback.Inordertoevaluatetheretrievaleffectivenessofthenewmethod,wecarriedoutsomeexperimentsusingTREC-7collectiontocomparetheretrievaleffectivenessofthefollowingmethodsusingdifferentcombinationofthequeryrepresentations.Figureshows11-pointinterpolatedprecisionusingourmethodalone,pseudo-feedbackalone,andthecombinationofourmethodandpseudo-feedback.Ourmethodalonehasbetterperformancethanthepseudo-feedbackmethod,andthecombinationofourmethodandpseudo-feedbackslightlybetterthanourmethodalone.Recently,XuandCroft(1996)suggestedamethodcalledlocalcontextanalysis,whichalsoutilizetheco-occurrence-basedthesaurusandrelevancefeedbackmethod.Insteadofgatheringco-occurrencedatafromthewholecorpus,hegatheritfromthetop-nrankeddocument.Wecarryoutexperimentsinthatwebuildthecombined-thesauribasedonthetop-nrankeddocument,ratherthanthewholecorpus.AscanbeseeninFigure~,queryexpansionusingthecombinedthesauribuiltfromthetop-nrankeddocumenthavealowerperformancethanqueryexpansionusingthecombinedthesauribuiltfromthewholecorpus.</section>
  <section title="Conclusions and Future Work">Wehaveproposedtheuseofmultipletypesofthesauriforqueryexpansionininformationretrieval,givesomefailureanalysis,andcombiningourmethodwithpseudo-relevancefeedbackmethod.Thebasicideaunderlyingourmethodisthateachtypeofthesaurushasdifferentcharacteristicsandcombiningthemprovidesavaluableresourcetoexpandthequery.Misleadingexpansiontermscanbeavoidedbydesigningaweightingtermmethodinwhichtheweightofexpansiontermsnotonlydependsonallqueryterms,butalsodependsontheirsimilarityvaluesinalltypeofthesaurus.Futureresearchwillincludetheuseofparserwithbetterperformance,designingageneralalgorithmforautomaticallyhandlingthenegationstatements,andalsodesigninganeffectivealgorithmforhandlingthemultipleaspectcontaininthequery.</section>
  <section title="Acknowledgments">Theauthorswouldliketothanktheanonymousrefereesforusefulcommentsontheearlierversionofthispaper.WealsothankChrisBuckley(SabIRResearch)forsupportwithSMART,SatoshiSekine(NewYorkUniversity)fortheApplePieParser,AkitoshiOkumura(NECC&amp;CMediaLab.)forprovidingthecomputerenvironmentsinverypreliminaryexperiments.ThisresearchispartiallysupportedbyJSPSprojectnumberJSPS-RFTF96P00502.document</section>
</root>
