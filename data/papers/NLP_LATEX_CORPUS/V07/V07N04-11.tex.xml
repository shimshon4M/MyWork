<?xml version="1.0" ?>
<root>
  <title>複数決定リストの順次適用による文節まとめあげ</title>
  <author>白木伸征梅村祥之原田義久</author>
  <jabstract>近年の高度情報化の流れにより，自動車にも種々の情報機器が搭載されるようになり，その中で音声認識・合成の必要性が高まっている．本研究は音声合成を行うための日本語解析の中で基本となる，文節まとめあげに関する研究報告である．従来の文節まとめあげは，人手規則による手法と機械学習による手法の二つに大きく分けられる．前者は，長年の努力により非常に高い精度を得られているが，入力データ形式が固定であるために柔軟性に欠け，人手で規則を作成・保守管理するため多大な労力を要し，車載情報機器へ実装するには問題が大きい．また後者は，それらの問題に柔軟に対処できるが，精度を向上させるためにアルゴリズムが複雑化しており，その結果開発期間が延長するなどの問題が生じ，車載情報機器には不向きである．そこで本研究は，決定リストを用いる手法を発展させ，複数の決定リストを順に適用するだけという非常に簡明な文節まとめあげの手法を提案する．決定リストの手法は非常に単純であるが，それだけでは高い精度が得られない．そこで，決定リストを一つではなく複数作成し，それぞれのリストを最適な順序に並べて利用することにより精度向上を図った．この結果，京大コーパスの最初の10000文を学習コーパス，残りの約10000文をテストコーパスとして実験を行ったところ，非常に簡明な手法ながら，99.38%という高い精度を得られた．</jabstract>
  <jkeywords>文節まとめあげ,決定リスト</jkeywords>
  <section title="はじめに">近年の高度情報化の流れにより，種々の情報機器が自動車にも搭載されるようになり，さまざまな情報通信サービスが広がりつつある．このような車載情報機器は，自動車に搭載するためにCPUの速度やRAM，ROMなどのメモリ容量の制約が非常に厳しく，また，開発期間がより短いことや保守管理の労力の低減も同時に求められている．自動車内で提供される情報通信サービスには，交通情報，観光情報，電子メール，一般情報(例えばニュース)などが含まれるが，このような情報はディスプレイ上に文字で表示するよりも，音声により提供する方が望ましいとされている．文字情報を音声に変換する技術の研究開発は進んでいるが，その合成音声の韻律は不自然という問題がある．その原因として大きな割合を占めるものはポーズ位置の誤りであり，これを改善することにより韻律の改善が可能となる．ポーズ位置を制御する手法として，係り受け解析を利用する方法が研究されている．これらの手法の中で，海木らや清水らの手法は係り受けの距離が2以上の文節の後にポーズを挿入するという方法であり，その有効性がすでに示されている．そしてこの手法を実現するためには，高精度な係り受け解析が必要となる．文節まとめあげは図のように，形態素解析された日本語文を文節にまとめあげる処理のことをいう．この処理は，日本語文の係り受け解析に重要となるものであるため，文節まとめあげの精度が高いことが望まれる．本研究はこのように，係り受け解析にとって重要な位置を占めている文節まとめあげに関する研究報告である．従来の文節まとめあげは，人手によりまとめあげ規則を書き下す方法と，機械学習によって得た統計情報を利用する方法の二通りに大きく分けられる．人手により作成した規則を用いる方法としてはknpがあり，高い精度を得られているが，人手により規則を保守管理することは容易ではなく，車載情報機器には不向きであるといえる．機械学習を用いる方法としては村田らによる方法があるが，まとめあげのための情報を152通りも利用しているなど非常に複雑なアルゴリズムになっている．このため新たに車載情報機器に実装するためには長い開発期間を要し，また規則の学習にも長い時間を要するため保守管理にも時間がかかり，さらにデータ量が膨大になるなどの問題も生じるため，車載情報機器には不向きであるといえる．本研究ではこれらの問題を解決し，従来手法と比べて遜色ない精度を持ち，保守管理が容易でかつ車載情報機器の求める厳しい条件に適した，複数決定リストの順次適用による文節まとめあげという新しい手法を考案した．そしてこの手法を用いて文節まとめあげを行ったところ，最高で99.38%という非常に高い精度が得られたことを報告する．</section>
  <section title="従来の研究">文節まとめあげに関する従来の研究は，人手により文節まとめあげの規則を書き下す方法と，大規模コーパスから機械学習により得た統計情報を利用する方法の2種類に大きく分けられる．これらの手法について以下で説明する．</section>
  <subsection title="人手規則による文節まとめあげ">人手により作成した文節まとめあげの規則を利用する最もよく知られているツールに，knpがある．knpは文節に関する規則を人手で網羅することにより，99%以上という非常に高精度な文節まとめあげを実現している．knpの文節まとめあげの規則は906行のファイルに148種類の規則が記述されている．knpへの入力は形態素解析ツールjumanの出力に限定されており，文節まとめあげの規則もその形式に基づいて作成されている．そのため，juman以外の形態素解析ツールの出力形式で利用するためには，規則をすべて書き直す必要がある．人手規則による文節まとめあげは，このように多数の規則を人手で修正・追加を繰り返さなければならず，大きな労力が必要という問題がある．しかしながら，車載情報機器の形態素解析部の出力形式はそれぞれ機種によって異なり，knpを車載情報機器に実装するためには規則をすべて書き直さなければならず，規則の保守管理も容易ではないため，問題が大きい．</subsection>
  <subsection title="機械学習による文節まとめあげ">人手規則による文節まとめあげの持つ問題に対処でき，最近最も盛んに研究されているのが，大規模コーパスから機械学習により得た統計情報を利用して文節まとめあげを行う手法である．機械学習による手法は，大規模コーパスから文節区切りの規則を学習し，それにより文節まとめあげを行う．そのため人手により規則を保守管理する必要がなく，また形態素解析ツールの出力形式に依存しないという利点がある．ただし機械学習の手法でも，学習用のコーパスを準備するという労力は必要である．しかし，京大コーパスなどの大規模コーパスの構文情報を，形態素解析ツールの各出力形式に変換するのは，文節区切りの情報だけに限定するため容易である．また人手により規則を作成する場合，プログラミングの専門的な知識が必要であるうえ，規則を改良するためには多くの試行錯誤が必要となる．それに対し，コーパスの作成を行う場合は，コーパスの原文を形態素解析した結果がほぼ100%に近い精度であり，それを文節に区切るだけでコーパスが得られるので特別に専門的知識は必要ない．また，単にコーパスの量を増やすだけで精度を向上させることができる．これらのことから，機械学習の手法は必要な労力が少ないといえる．機械学習を用いる文節まとめあげには様々な種類があるが，これまでに最も精度の高い結果を得ているのが，村田らによる研究である．村田らは，決定リストを用いた文節まとめあげの手法に排反な規則を組み合わせた手法を提案している．決定リストは，規則をある優先順位を決めて1次元に並べたリストのことである．そしてそのリストを順に探索して一番最初に適用された規則のみを用いて解析を行う手法である．決定リストの要素としてよく用いられるのは，大規模コーパスから学習した結果であり，それを並べる優先順位としては確率が主に用いられる．例えば，図のような決定リストにより，「うまく,日本語,文,を,解析,する,．」という形態素解析済みの文を処理する方法について考える．「うまく(形容詞)」と「日本語(名詞)」という情報から，「うまく」＋「日本語」という規則が最初に適用されるため，この部分は「文節に区切る」と決定される．リストの下位に「形容詞」＋「名詞」は「文節に区切らない」という規則があるが，決定リストはリストの上位の要素から適用するため，この規則は無視される．村田らの手法は，文節に区切るあるいは区切らない確率が100%である規則を排反な規則と呼び，決定リストの手法に排反な規則を組み合わせて文節まとめあげを行う．確率が100%でない規則を適用するのは，あらかじめ誤る可能性のあるものを利用するということになるため，高い精度を望むことができない．そのため排反な規則を重要視しなければならない，と主張している．図のような前後4つの形態素の4種類の情報を152種類組み合わせて，それにより決定リストを作成する．決定リストの要素を並べる順序は，まず確率でソートして，同じ確率のものは頻度順にソートする．例えば，ある形態素の隙間の文節区切りを決定する時に図のような規則のパターンが一致して適用可能である場合，決定リストの手法であれば，最初の規則Aが適用されるため「文節に区切らない」と決定される．しかし規則B，C，Dを見ると，各規則ごとの頻度は規則Aと比べると小さいが，それぞれの頻度を足しあわせると規則Aの頻度よりも大きい．そのため，規則B，C，Dに従って「文節に区切る」と決定する方が望ましいと考えられる．このように，排反な規則，つまり確率が100%となる規則の頻度を足しあわせ，その頻度により文節区切りの決定を行う．この手法による文節まとめあげは，最高で99.17%という高い精度を得ている．しかしこの手法は，図のような情報の組み合わせが152種類もある．京大コーパス中のデータは，1文平均約23の形態素の隙間があるため，1つの形態素の隙間に対して152種類の組み合せを考慮すると，1文あたり15223=約3500回もの処理をしなければならない．このようにアルゴリズムが複雑なため，新たに車載情報機器に実装するためには長い開発期間を要し，また規則の学習に長い時間を要するため保守管理にも時間がかかり，さらにデータ量が膨大になるなど様々な問題がある．そのため，車載情報機器には不向きであるといえる．章では，これらの問題を解決するために考案した新しい手法について述べる．</subsection>
  <section title="本研究の文節まとめあげの手法"/>
  <subsection title="複数決定リストの順次適用による文節まとめあげ">本研究では，従来手法の問題点を解決するために次の点に着目した．学習が容易で用いる情報の数が少ないこと学習結果を利用して文節をまとめる方法が従来手法より簡明であること精度が従来手法と同程度かそれ以上となることこれらを実現するために，複数決定リストの順次適用による文節まとめあげという新しい手法を考案した．機械学習を用いる従来手法では，大規模コーパスから得られた様々なn-gram(主に2-gramから4-gram)が利用されている．本手法では，1つの形態素の隙間に対して6種類のn-gramのそれぞれの決定リストだけを考慮するという非常に簡明な方法を用いる．具体的には，品詞，単語表記，品詞細分類，単語表記＋品詞の4種類の形態素2-gramと，品詞，単語表記の2種類の形態素3-gramを要素とする決定リストを利用する(図)．以下では，これらのn-gramを要素とする決定リストを，n-gramリストと呼ぶ．文節まとめあげの処理は，村田らと同様に形態素解析済みのテキストに対して行い，形態素の隙間ごとにその前後の形態素の情報からn-gramリストを調べて文節を区切るか区切らないかを決定する処理とした．例えば，2-gramの場合にはY，Zという連続する2つの単語のYとZの間，3-gramの場合にはX，Y，Zという連続する3つの単語のYとZの間に注目し，その間の文節区切りを次のように決定する．X，Y，Zの形態素を得る．図の6種類のn-gramリストを順番に調べる．n-gramリスト中に規則が見つかり，文節に区切る数が区切らない数よりも多い場合には区切りを入れ，少ない場合には区切らないこととする．この段階でYとZの文節区切りを確定し，処理を終了する．n-gramリスト中に規則が見つからない場合，または文節に区切る数と区切らない数が等しい場合には，次のn-gramリストを調べる．6種類すべてのn-gramリストを調べた結果，文節に区切るか区切らないか確定しない場合，デフォルト処理として文節に区切るものとする．本手法の最大の特徴は，このように6種類のn-gramリストを順番に調べるだけで文節まとめあげを行う，という非常に簡明な点である．村田らの手法では節で示したように，1つの形態素の隙間に対して約3500回もの処理をしなければならない．しかし，本手法では最大で623=138回の処理でよいため，村田らの手法と比べて約125の処理量で文節まとめあげを行うことができる．</subsection>
  <subsection title="n-gramリストの取得方法">各n-gramリストの要素は，大規模コーパスから機械学習によって得る．本研究では，学習コーパスとして京大コーパスを利用した．京大コーパスにはあらかじめ詳細な形態素の情報と文節区切りの情報が付与されているので，形態素の隙間ごとに文節に区切る数と区切らない数を数えて，それを確率の高い順に並べて保持する．ただし，確率には文節に区切る確率か文節に区切らない確率の2種類があるが，高い方の確率を基準としてリストに並べた．つまり，リストの最下位は確率50%となる．以上のようにして得られた品詞2-gramの学習結果の決定リストの例を図に示す．</subsection>
  <section title="実験と考察"/>
  <subsection title="実験方法">本手法の性能を評価するため，評価システムを作成して以下の実験を行った．6種類のn-gramリストを適用する数や順序を変化させる実験学習コーパスの量を変化させる実験学習結果の一部分だけ利用する実験比較実験n-gramや条件の追加実験1.,3.,4.,5.の実験の学習コーパスには，京大コーパスの最初の10000文を利用し，2.の実験には，京大コーパスを最初から1000文ずつ10000文まで変化させて利用した．また，すべての実験のテストコーパスは京大コーパスの10001文目からの残り9956文を利用した．学習コーパス，テストコーパスの内容は表の通りである．</subsection>
  <subsection title="評価基準">本研究の文節まとめあげの評価基準には，村田らが用いたF値を採用した．F値はF-measureを意味し，適合率と再現率の調和平均から得られる．適合率と再現率は，評価システムの出力とテストコーパスの内容を比較して，次のように計算する．eqnarrayここで，resultを評価システムが文節に区切った数，correctをテストコーパスで文節に区切られている数(正解の区切り)，rightを両者の文節区切りが一致している数とする．これらの調和平均を以下のように計算すると，F値が得られる．F=(1適合率+1再現率2)^-1100(%)displaymath例えば，次のようなテストコーパスの文節区切りと評価システムの出力がある時のF値の計算例を示す．文中「｜」により文節の区切りを表すものとする．</subsection>
  <subsection title="実験結果"/>
  <subsubsection title="n-gramリストを用いる数や適用する順序を変化させる実験">6種類のn-gramリストを用いる時に，n-gramリストを用いる数や適用する順序により精度が変化すると考えられる．そこで，6種類のn-gramリストを用いる数や順序を変化させて実験したところ，図のような結果を得た．ただし図中，n-gramリストを用いた数が1,2,3,4は4種類の2-gramリストだけを用いた結果で，数が5,6はさらに2種類の3-gramリストを加えた結果である．n-gramリストを用いた数ごとのF値は，その数における最も精度の高かった順序の結果のみを示した．また，それぞれn-gramリストを1つだけ用いた結果を表に，最も精度の高かった時のn-gramリストの適用順を表に示した．表中のデフォルト処理とは，n-gramリスト中で規則を見つけられなかった場合に適用する処理のことを表す．本手法ではデフォルト処理として「区切る」を用いるが，比較のため「区切らない」場合の精度も示した．また，表中の被覆率は，規則を適用できた割合を示す．この結果から，使用するn-gramリストの数が多いほど精度が上がるが，3つ以上のn-gramリストを用いるとほぼ精度が飽和することがわかった．</subsubsection>
  <subsubsection title="学習コーパスの量を変化させる実験">学習コーパスの量を変化させた時に，精度がどのように変化するか調べた．学習コーパスは京大コーパスの最初から1000文ずつ増やし10000文まで変化させ，テストコーパスは京大コーパスの10001文目からの9956文で固定して実験を行った．その結果を図に示した．図中，4種類は2-gramリストのみ，6種類はすべてのn-gramリストを利用した時の結果である．この結果から，学習量が増すにつれて精度が向上することがわかった．しかし，10000文学習した段階でほぼ飽和していると考えられる．</subsubsection>
  <subsubsection title="学習結果の一部分だけ利用する実験">学習をした結果は確率順に並べられており，リストの上位は確率が高いので確信度が高いといえ，逆にリストの下位は確率が50%に近いので確信度が低いといえる．そこで，確率の高いものだけを利用すると精度がどのように変化するか調べた．この実験で調べる内容は，車載情報機器はメモリ容量の要求が厳しいため，学習結果のデータ量はできるだけ少ないことが求められるが，データ量を減らす時にどれだけの精度が得られるか，ということである．学習結果を利用する割合を，10000文を学習した各n-gramリストの上位から10%，20%と10%ずつ増やし100%まで変化させて実験を行ったところ，図の結果を得た．図中，4種類は2-gramリストのみ，6種類はすべてのn-gramリストを利用した時の結果であるこの結果，およそ60%のデータを利用すれば100%利用した時とほぼ同等の精度を得られることがわかった．以上の実験から，車載情報機器が要求する速度・データ容量などに柔軟に対応できることを示すことができた．</subsubsection>
  <subsubsection title="比較実験">本手法は，複数の決定リストを順次適用するというものであるが，これらの複数の決定リストを大きな一つの決定リストにまとめて考えると，n-gramの種類(素性)によりソートしてから確率でソートしたリストと考えることもできる．このソートの順序は村田らの提案する手法とは逆で，村田らの手法では確率，頻度，素性という順序でソートしたリストを用いている．そこで，本手法，村田らの手法，決定リストの手法の3手法を比較するために，本手法の決定リストを大きな1つの決定リストにまとめ，それを用いて比較実験を行った．決定リストの手法では，確率，頻度，素性という順序でソートして用い，村田らの手法では，この決定リスト中の同じ確率となる規則の各頻度を足しあわせた結果により文節の区切りを判定した．これらの実験結果を表に示した．この結果から，同じ評価基準で実験を行った場合には，本手法が最も優れていることが示された．</subsubsection>
  <subsubsection title="n-gramや条件の追加実験">本手法の最大の特徴は，非常に簡明な方法で充分な精度を得られることである．非常に簡明であるので，従来手法の長所だけを組み合わせることも容易である．そのことを示すため，京大コーパスの最初の10000文を学習コーパス，残りの9956文をテストコーパスとして以下のような2種類の追加実験を行った．1-gramを利用する方法2-gramや3-gramだけでなく，1-gramが非常に有効となる場合も考えられる．例えば，読点や区点は前の単語に必ずつながり，次の単語とは必ず区切れる．そこで，6種類のn-gramリストに加えて1-gramリストを用いて実験を行ったところ，F値が99.31%に上昇した．排反な規則を用いる方法村田らにより，排反な規則を用いる手法が高い精度を得られると報告されている．6種類のn-gramリストの排反な規則を考慮して実験を行ったところ，F値が99.26%に上昇した．上記2種類の手法をすべて組み合わせて実験を行ったところ，村田らの手法よりも簡明であるが，99.38%という非常に高いF値を得られた．</subsubsection>
  <subsection title="処理速度">n-gramリストの学習と評価システムの処理速度の計測を行った．節の図で示した品詞2-gramの学習に関しては，学習プログラムの最適化は全く行わなかったが，計算機にSunUltra1133MHzを，プログラム言語にPerlを用いたところ，10000文の学習に要した時間は58秒(1文あたり5.8ms)と非常に高速であった．また，6種類のn-gramリストすべての学習に要した時間も，216秒(1文あたり21.5ms)と高速であった．6種類のn-gramリストを学習した結果は約41万規則で，圧縮を全く行わずに図のようにテキストベースでデータを保持すると約14.4MB，圧縮を行うと約2MBとなった．また評価システムについても同様にアルゴリズムの最適化を全く行わなかったが，節の実験に関して，計算機にSunUltra1133MHzを，プログラム言語にPerlを用いたところ，4種類のn-gramリストを用いた処理に要した時間は225秒(1文あたり22.6ms)，6種類のn-gramリストの場合には253秒(1文あたり25.4ms)と非常に高速であった．</subsection>
  <subsection title="実験のまとめ">以上の実験の結果を図のグラフにまとめた．比較のため，knp2.0b4の精度とknp2.0b6の精度も示した．knp2.0b6の精度が非常に高いのは，京大コーパスがknp2.0b4の出力を人手で修正して作成されたものであり，その修正結果をさらにknpの文節まとめあげ規則に反映したためである．つまり，knp2.0b6の結果はクローズドテストにほぼ等しい．本手法が従来の手法よりも優れていることは，節の比較実験により示された．また，本手法が非常に簡明であること，車載情報機器への実装を最大の目標としていることを考慮すると，本手法は非常に優れているといえる．</subsection>
  <subsection title="考察">本手法のように非常に簡明な方法で99.38%という高い精度を得られる理由と，本手法のロバスト性について，節で行った実験の結果に基づいて考察する．節の実験で，6種類のn-gramリストを適用する順序で最も高い精度を得られたのは，表に示したように，であった．これらのn-gramリストをそれぞれ1つだけ用いて文節まとめあげを行った場合の精度は，表に示したとおりである．章で述べたように，本手法では文節に区切るか区切らないか決定できない場合のデフォルト処理を「文節に区切る」としているが，「文節に区切らない」とすると，それぞれの精度は表のようになる．本手法の評価基準であるF値は，式に示すように文節区切りを基準としている．そのため，デフォルト処理を文節に区切らないことにすると，得られる適合率は，n-gramリストにより「文節に区切る」と確定した個所が正しい区切りかどうか，という正確な値となる．この適合率が，表の右側の中で最も注目すべき値である．この表から，先に適用されるn-gramリストほど適合率が高いことがわかる．つまり本手法の文節まとめあげ処理は次のように考えることができる．1つの形態素の隙間の文節区切りを確定するために，適合率の最も高いn-gramリストを最初に参照し，その中で見つけられれば最も高い適合率で文節区切りを確定できる．しかし，適合率が高いと再現率は低くなるため，規則を適用できる個所は少なくなる．そこで，そのn-gramリスト中で規則を見つけられなかった個所は，次に適合率の高いn-gramリストにより区切りを決定する．同様にして適合率の高い順にn-gramリストを調べることで，最終的に高い精度での文節まとめあげが可能になる(図)．低い適合率のn-gramリストを最初に適用して確定を行えば，その低い適合率が最終的な精度に大きく影響することは容易に想像できる．そのため，高い適合率のn-gramリストから順に適用するということは理想的な処理であるといえる．このことは，村田らのが100%の確率である排反な規則を最優先に考慮するという考えを拡張してより柔軟にした，と考えることもできる．ただし，先に適用されるn-gramリスト中に51%の確率の規則が存在する場合には，たとえ後に適用されるn-gramリスト中に100%の確率の規則が存在しても，先のn-gramリストにより文節区切りが確定される．本手法はいかに簡明に文節まとめあげを行うか，ということを目標としていたため，この点についての考慮は行わなかった．しかし，さらに精度を向上させるためには，このような点も考慮して，決定リストの要素を並べる順序をどのようにするのが最適であるか，より詳しく調べる必要があると思われる．次に，本手法のロバスト性について考察する．本手法では，入力される形態素解析済みのデータは100%正しいものとして扱っているが，実際には形態素解析ツールの精度は100%ではない．そこで，形態素解析ツールの出力に誤りがある場合に，本手法の文節まとめあげの精度がどのように変化するか調べた．形態素解析ツールの出力の誤りには主に，付与する品詞の誤りや形態素の区切り誤りがある．形態素の区切りの誤りには，一つの形態素を複数に区切る誤りや，複数の形態素を一つのまとめる誤りなどがあるため非常に複雑であり，ここでは品詞の誤りがある場合についてだけ考える．ある形態素に品詞の誤りがある場合，3-gramを用いる時はその前後3個所の文節区切りに影響を及ぼし，2-gramを用いる時はその前後2個所の文節区切りに影響を及ぼす．そのため，品詞の誤りが1つ生じた場合に必ず文節区切りを誤ると仮定すると，形態素解析から文節まとめあげに至る間に誤りが増加する割合は，表の被覆率と表の適用順から，誤りの増加率&amp;=&amp;321.73%+2(100%-21.73%)61.51%+&amp;=&amp;2.49eqnarray*と求められる．つまり，形態素解析が99.0%(誤りが1%)の精度であるとすると，本手法の精度は99.38%-2.49%=96.89%ということになる．従来の研究では，このような値が示されていないために単純にロバスト性を比較することはできない．しかし，形態素解析を誤ると必ず文節まとめあげを誤ると仮定していることや，他の手法が3-gram以上の情報も用いているためより多くの誤りを引き起こす可能性があることを考えると，本手法は従来の手法よりロバストであると考えられる．</subsection>
  <section title="おわりに">本研究で提案した文節まとめあげの手法は，車載情報機器の求める条件を満たすよう考案したものであり，複数の決定リストを順次適用して文節の区切りを行うだけ非常に簡明かつ高速である．それにもかかわらず，従来の手法と比較してより高い精度を得られることが示された．また，本手法は非常に簡明であるため，他の手法の長所のみを導入することが容易である．そのことを1-gramや排反な規則を組み合わせることにより示した．今後は，本手法を係り受け解析の技術と融合させ，より高精度な係り受け解析の技術に応用し，音声合成の品質の向上に貢献しようと考えている．document</section>
</root>
