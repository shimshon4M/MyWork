<?xml version="1.0" ?>
<root>
  <title>最大エントロピーモデルと書き換え規則に基づく固有表現抽出</title>
  <author>内元清貴馬青村田真樹小作浩美内山将夫井佐原均</author>
  <jabstract>本論文では，ME(最大エントロピー)モデルと書き換え規則を用いて固有表現を抽出する手法について述べる．固有表現の定義はIREX固有表現抽出タスク(IREX-NE)の定義に基づくものとする．その定義によると，固有表現には一つあるいは複数の形態素からなるもの，形態素単位より短い部分文字列を含むものの2種類がある．複数の形態素からなる固有表現は，固有表現の始まり，中間，終りなどを表すラベルを40個用意し，各々の形態素に対し付与すべきラベルを推定することによって抽出する．ラベルの推定にはMEモデルを用いる．このMEモデルでは学習コーパスで観測される素性と各々の形態素に付与すべきラベルとの関係を学習する．ここで素性とはラベル付与の手がかりとなる情報のことであり，我々の場合，着目している形態素を含む前後2形態素ずつ合計5形態素に関する見出し語，品詞の情報のことである．一方，形態素単位より短い部分文字列を含む固有表現は，MEモデルを用いてラベルを決めた後に書き換え規則を適用することによって抽出する．書き換え規則は学習コーパスに対するシステムの解析結果とコーパスの正解データとの差異を調べることによって自動獲得することができる．本論文ではIREX-NE本試験に用いられたデータに対し我々の手法を適用した結果を示し，さらにいくつかの比較実験から書き換え規則と精度，素性と精度，学習コーパスの量と精度の関係を明らかにする．</jabstract>
  <jkeywords>固有表現，最大エントロピー(ME)モデル，書き換え規則</jkeywords>
  <section title="はじめに">固有表現(NE=NamedEntity)抽出は情報抽出における基礎技術として認識されているだけでなく，形態素，構文解析の精度向上にもつながる重要な技術である．米国では1980年代からMUC(MessageUnderstandingConference)のようなコンテストが行なわれ，その技術の向上が図られてきた．日本においても1998年からコンテスト形式のプロジェクト「IREX(InformationRetrievalandExtractionExercise)」が始められ，そのタスクの一つとして固有表現抽出が盛り込まれた．このタスクで固有表現として抽出するのは，「郵政省」のように組織の名称を表すもの，「小渕恵三」のように人名を表すもの，「神戸」のように地名を表すもの，「カローラ」のように固有物の名称を表すものおよび，「9月28日」，「午後3時」，「100万円」，「10%」のように日付，時間，金銭，割合を表す表現である．このように，固有名詞的表現だけでなく，時間表現，数値表現も抽出の対象としているため，本論文ではそれらをすべてまとめて固有表現と呼ぶ．このような固有表現は多種多様で，次々と新たに生み出されるためそのすべてを辞書に登録しておくことは不可能である．また，同じ表現でも，あるときは地名としてまたあるときは人名として使われるというようにタイプに曖昧性がある．そのため，テキストが与えられたときその中でどの部分がどのタイプの固有表現であるかを同定するのは容易ではない．固有表現を抽出する方法には大きく分けると，人手で作成した規則に基づく方法と学習に基づく方法がある．固有表現の定義は抽出したものを何に応用するかによって異なってくるものであるため，前者の方法では定義が変わるたびに規則を人手で作成し直す必要がありコストがかかる．後者の方法は学習コーパスを作る必要があるが，データスパースネスに強い学習モデルを使えばそれほど大量のコーパスがなくても高い精度が得られる．そこで我々は後者の方法をとることにした．この学習に基づく方法は英語での固有表現抽出の研究でも用いられている．例えば，HMM，決定木モデル，ME(最大エントロピー)モデル，共起情報，誤り駆動の書き換え規則などに基づくシステムがある．学習に基づく方法としてMUCのコンテストで最も精度が高かったのはHMMに基づくNymbleという名のシステムである．このシステムは基本的に以下のような手法をとっている．まず学習では，MUCのNEタスクで定義された「PERSON」や「ORGANIZATION」などの固有表現およびそれ以外を表す「NOT-A-NAME」をそれぞれ状態として持つ状態遷移図を用意し，ある状態で，ある単語が入力されたときにどの状態に移るかを状態遷移確率として求める．そして，解析する際には，ビタビアルゴリズムを用いて，入力された単語列が辿り得る状態のパスうち，最適なパスを探索し，順次，辿った状態を出力することで固有表現を抽出する．他の学習手法を用いたシステムも確率の計算方法は違うが同様の手法をとっていることが多い．Borthwickらは，この学習に基づくシステムおよび人手で作成した規則に基づくシステムの中から，それぞれMUCで比較的精度の高かったシステムを選びそれらを学習に基づく方法によって統合することによってより高い精度を得ている．あるデータに対しては人間のパフォーマンスを越えるような結果も得られている．学習に基づく方法は固有表現抽出の研究以外に形態素解析や構文解析においてもよく用いられている．学習モデルとしてはMEモデルを用いたものが優れた精度を得ていることが多く，データスパースネスに強いため，我々は固有表現抽出においてもこのMEモデルを用いることにした．さらに後処理として，誤り駆動により獲得した書き換え規則を用いる．この書き換え規則を用いる手法は形態素解析でも用いられている．固有表現の定義はIREX固有表現抽出タスク(IREX-NE)の定義に基づくものとする．その定義によると，固有表現には「日本」や「国立／公文書／館」(／は形態素の区切りを表す)のように一つあるいは複数の形態素からなるもの，あるいは「在米」の「米」，「兵庫／県内」の「兵庫県」のように形態素単位より短い部分文字列を含むものの2種類がある．前者の固有表現は，固有表現の始まり，中間，終りなどを表すラベルを40個用意し，各々の形態素に対し付与すべきラベルを推定することによって抽出する．ラベルの推定にはMEモデルを用いる．このMEモデルでは学習コーパスで観測される素性と各々の形態素に付与すべきラベルとの関係を学習する．ここで素性とはラベル付与の手がかりとなる情報のことであり，我々の場合，着目している形態素を含む前後2形態素ずつ合計5形態素に関する見出し語，品詞の情報のことである．ラベルを推定する際には，入力文を形態素解析し，MEモデルを用いてそれぞれの形態素ごとにそこで観測される素性から各ラベルの尤もらしさを確率として計算し，一文全体における確率の積の値が高くなり，かつラベルとラベルの間の連接規則を満たすように各々の形態素に付与するラベルを決める．一文における最適解の探索にはビタビアルゴリズムを用いる．一方，後者の固有表現のように形態素単位より短い部分文字列を含む固有表現は上記の方法では抽出できないので，MEモデルを用いてラベルを決めた後に書き換え規則を適用することによって抽出する．書き換え規則は学習コーパスに対するシステムの解析結果とコーパスの正解データとの差異を調べることによって自動獲得することができる．一つあるいは複数の形態素からなる固有表現についても同様に書き換え規則を適用することは可能であるが，本論文ではMEモデルについてはラベル付けの精度に重点を置き，書き換え規則についてはできるだけ簡便な獲得方法を用いて効果をあげることに重点を置く．本論文ではIREX-NE本試験に用いられたデータに対し我々の手法を適用した結果を示し，さらにいくつかの比較実験からMEモデルにおける素性と精度の関係，学習コーパスの量と精度の関係，さらに簡便な方法を用いて自動獲得した書き換え規則がどの程度精度に貢献するかを明らかにする．</section>
  <section title="固有表現抽出アルゴリズム"/>
  <subsection title="アルゴリズムの概要">固有表現はIREX-NEの定義にしたがい，表~の8種類とする．この節ではこの表にあげたSGMLタグを付与する方法について述べる．[htbp]table*本手法では以下の手順で固有表現を抽出する．テキストを形態素解析する．実験では形態素解析にJUMANを用いた．例えば，``在米女性を中心に「人権を考える会」ができ，…''という部分は表~の第1行のように形態素ごとに区切られ，それぞれの形態素ごとに第2行，第3行のような品詞の情報が得られる．[htbp]table*各形態素にラベルを付与する．ラベルとしては，以下の合計40個を用意した．IREX-NEで定義されている固有表現のタグに「OPTIONAL」を加えた9種類を，固有表現の始まり，中間，終り，単独に分けた94=36個．例えば人名のタグの場合，それぞれ「PERSON:BEGIN」「PERSON:MIDDLE」「PERSON:END」「PERSON:SINGLE」を用いる．このように分けたのは，複数の形態素が一つの固有表現を構成することがあることを考慮するためである．「OPTIONAL」のタグはタグ付けが判定者にも困難な場合のために設けたものである．これもIREX-NEにおける定義にしたがっている．固有表現の判定は人間にも難しいことが多い．例えば，「東京高裁」はLOCATIONかORGANIZATIONか，「日経平均株価」と言ったときの「日経」はORGANIZATIONとするべきかなどがそうである．このような場合，それぞれ「東京高裁」，「日経」にこのタグを付与し，固有表現としては抽出しない．この「OPTIONAL」をラベルとして考慮したのはその性質を学習することによって，例えばLOCATIONかORGANIZATIONの判定が困難なものをいずれかのタグに分類してしまうのを避けることができると考えたためである．固有表現の前後の1形態素および固有表現に挟まれた1形態素を他の形態素と区別するための3個(「PRE」「POST」「MID」)．例えば，``昨日大阪と神戸で…''という部分では「大阪」と「神戸」がそれぞれ地名を表す固有表現であり，その前後の形態素は次のようにラベル付けされる．``昨日(PRE)／大阪(LOCATION:SINGLE)／と(MID)／神戸(LOCATION:SINGLE)／で(POST)…''(括弧内はそれぞれ前の形態素に付与されたラベルの候補)flushleftこの三つのラベル「PRE」「POST」「MID」を用いたのは，固有表現の前後の形態素(接辞など)は固有表現を抽出する際に手がかりとなることが多いため，次にあげる「OTHER」と区別する方が良いと考えたからである．以上のどのラベルもつかない「OTHER」．今，一文がn個の形態素からなるとする．手順(1)で得られた形態素解析結果を用いて，個々の形態素m_i(1in)にそれぞれ上記のラベルのいずれかを付与する．形態素m_iに付与するラベルはコーパスから学習したMEモデルから各ラベルを付与したときの尤もらしさを確率として計算しそれを基に決める．詳しくは，モデルについては節で，最適解の探索アルゴリズムについては節で述べる．書き換え規則による後処理JUMANの解析結果における形態素の境界とIREXで定義されている固有表現の境界は必ずしも一致しない．このような一致しない場合に対応するために書き換え規則を自動獲得し，獲得した規則を用いて後処理を行う．例えば，表~の「在米」に対しては以下のような書き換え規則が適用される．*1em*1em書き換え規則の自動獲得手法については節で述べる．ラベルを固有表現のタグに変換すべてのラベルが決まったら，それぞれのラベルに対し手順(2)で定義したラベルの定義にしたがって，ラベルからIREX-NEで定義されたタグへと変換する．抽出したい固有表現は表~の8種類なので，最後に解析結果から「OPTIONAL」のタグを取り除く．例えば，表~でスコアが最大であるラベル候補1の場合，手順(3)の操作によって``在米(OTHER)''の部分が``在(PRE)米(LOCATION:SINGLE)''(括弧内はそれぞれ前の形態素に付与されたラベルの候補)に書き換えられる．そして，ラベルをタグに変換することによって次のような出力を得る．</subsection>
  <subsection title="固有表現抽出に用いる確率モデル">この節では形態素に付与するラベルの尤もらしさを確率として計算するためのモデルについて述べる．モデルとしては，ME(最大エントロピー法)に基づく確率モデルを採用する．まず，MEの基本について説明し，その後，MEに基づく固有表現ラベル付与確率モデルおよびそのモデルをコーパスから統計的に学習する方法について述べる．</subsection>
  <subsubsection title="ME(最大エントロピー)モデル">一般に確率モデルでは，文脈(観測される情報のこと)とそのときに得られる出力値との関係は既知のデータから推定される確率分布によって表される．いろいろな状況に対してできるだけ正確に出力値を予測するためには文脈を細かく定義する必要があるが，細かくしすぎると既知のデータにおいてそれぞれの文脈に対応する事例の数が少なくなりデータスパースネスの問題が生じる．MEモデルでは，文脈は素性と呼ばれる個々の要素によって表され，確率分布は素性を引数とした関数として表される．そして，各々の素性はトレーニングデータにおける確率分布のエントロピーが最大になるように重み付けされる．このエントロピーを最大にするという操作によって，既知データに観測されなかったような素性あるいはまれにしか観測されなかった素性については，それぞれの出力値に対して確率値が等確率になるようにあるいは近付くように重み付けされる．このように未知のデータに対して考慮した重み付けがなされるため，MEモデルは比較的データスパースネスに強いとされている．このモデルは例えば言語現象などのように既知データにすべての現象が現れ得ないような現象を扱うのに適したモデルであると言える．以上のような性質を持つMEモデルでは，確率分布の式は以下のように求められる．文脈の集合をB，出力値の集合をAとするとき，文脈b(B)で出力値a(A)となる事象(a,b)の確率分布p(a,b)をMEにより推定することを考える．文脈bはk個の素性f_j(1jk)の集合で表す．そして，文脈bにおいて，素性f_jが観測されかつ出力値がaとなるときに1を返す以下のような関数を定義する．g_j(a,b)&amp;=&amp;.eqnarrayこれを素性関数と呼ぶ．ここで，exist(b,f_j)は，文脈bにおいて素性f_jが観測されるか否かによって1あるいは0の値を返す関数とする．次に，それぞれの素性が既知のデータ中に現れた割合は未知のデータも含む全データ中においても変わらないとする制約を加える．つまり，推定するべき確率分布p(a,b)による素性f_jの期待値と，既知データにおける経験確率分布p(a,b)による素性f_jの期待値が等しいと仮定する．これは以下の制約式で表せる．_aA,bBp(a,b)g_j(a,b)=_aA,bBp(a,b)g_j(a,b)forf_j(1jk)eqnarrayこの式で，p(a,b)=p(b)p(a|b)p(b)p(a|b)という近似を行ない以下の式を得る．_aA,bBp(b)p(a|b)g_j(a,b)=_aA,bBp(a,b)g_j(a,b)forf_j(1jk)eqnarrayここで，p(b)，p(a,b)は，freq(b)，freq(a,b)をそれぞれ既知データにおける事象bの出現頻度，出力値aと事象bの共起頻度として以下のように推定する．p(b)&amp;=&amp;freq(b)_bBfreq(b)p(a,b)&amp;=&amp;freq(a,b)_aA,bBfreq(a,b)eqnarray次に，式()の制約を満たす確率分布p(a,b)のうち，エントロピーH(p)&amp;=&amp;-_aA,bBp(b)p(a|b)log(p(a,b))eqnarrayを最大にする確率分布を推定するべき確率分布とする．これは，式()の制約を満たす確率分布のうちで最も一様な分布となる．このような確率分布は唯一存在し，以下の確率分布p^*として記述される．p^*(a|b)&amp;=&amp;_j=1^k_a,j^g_j(a,b)_aA_j=1^k_a,j^g_j(a,b)&amp;&amp;(0_a,j)eqnarrayただし，_a,j&amp;=&amp;e^_a,jeqnarrayであり，_a,jは素性関数g_j(a,b)の重みである．この重みは文脈bのもとで出力値aとなることを予測するのに素性f_jがどれだけ重要な役割を果たすかを表している．訓練集合が与えられたとき，_a,jの推定にはImprovedIterativeScaling(IIS)アルゴリズムなどが用いられる．式()の導出については文献を参照されたい．</subsubsection>
  <subsubsection title="固有表現ラベル付与確率モデル">節に，個々の形態素に付与すべき固有表現のラベルを定義した．以降では，形態素にそれぞれのラベルを付与したときの尤もらしさを表す確率をラベルの付与確率と呼ぶ．一文がn個の形態素からなるとき，形態素m_i(1in)にラベルl_j(0j39)を付与するときの付与確率は，前節で述べたMEモデルの式（）を用いてp^*(l_j|F_i)で求められる．ここでFは「見出し語：人権,品詞(大分類)：名詞,品詞(細分類)：普通名詞」などの素性の集合であり，個々のm_iごとに異なるためF_iと表した．一文全体の付与確率は個々の確率の積で表す．</subsubsection>
  <subsubsection title="素性">基本的に学習コーパスから得られる形態素情報を素性として用いる．実験では，着目している形態素を含む前後2形態素ずつ合計5形態素に関する見出し語，品詞(大分類，細分類)とした．品詞分類はそれぞれ大分類15個，細分類48個である．これはJUMANのものにしたがった．学習コーパスに1，2回しか現れないような素性はノイズとなる可能性があるのでそれを避けるために頻度による素性選択を行なう．見出し語としては学習コーパス中に5回以上現れたものを用い，さらに式()の素性関数としては学習コーパスに3回以上観測されたものを用いる．見出し語を5回以上現れたものとしたのはこれ以上少なくすると素性の数が増え現在のマシンパワーでは学習できなかったためである．素性としては他にもいろいろ考えられるが，今回の実験では学習コーパスから得られる情報でかつ着目している形態素の周辺の情報のみを用いた場合にどの程度の精度が得られるかを調べることに重きを置いた．さらに学習コーパス以外から得られる情報の有効性も調べるために追加実験として，固有名詞に関する辞書情報を利用しその辞書に登録されているかどうかを素性として利用した場合の実験も行なった．これについては節で実験結果をあげて考察する．</subsubsection>
  <subsection title="ビタビアルゴリズム">本節ではラベル付与に用いるビタビアルゴリズムについて説明する．このアルゴリズムは，スコアが一文全体で最適値となるようにラベルを付与するものである．形態素m_iに対し，節で述べたラベルl_jの付与確率p^*(l_j|F_i)の一文全体における掛け算_i=1^np^*(l_j|F_i)が最大になるように各ラベルを決める．ただし，表~の連接規則を満たすようにする．この表で，＄(文末)，＃(文頭)は便宜上設けたもので実際に付与するラベルとは異なる．表~の連接規則は人手で作成した．[htbp]table*手順は以下の通りである．文頭の形態素m_1に対し各ラベルl_j(1)の付与確率p^*(l_j(1)|F_1)(0j(1)39)を計算し，それぞれ各ラベルごとのスコアS_1(l_j(1))とする．つまり，S_1(l_1)=p^*(l_1|F_1),S_1(l_2)=p^*(l_2|F_1),,S_1(l_39)=p^*(l_39|F_1)とする．次の形態素m_2に対し各ラベルの付与確率p^*(l_j(2)|F_2)(0j(2)39)を計算し，それぞれ各ラベルごとのスコアをS_2(l_j(2))&amp;=&amp;max_l_j(1)p^*(l_j(2)|F_2)S_1(l_j(1))eqnarray*とする．ただし，l_j(1)とl_j(2)が連接規則を満たすものに限る．さらに次の形態素m_3に対しても同様に各ラベルの付与確率p^*(l_j(3)|F_3)(0j(3)39)を計算し，それぞれ各ラベルごとのスコアをS_3(l_j(3))&amp;=&amp;max_l_j(2)p^*(l_j(3)|F_3)S_2(l_j(2))eqnarray*とする．ただし，l_j(2)とl_j(3)が連接規則を満たすものに限る．同様のことを文末まで繰り返し，S_n(l_j(n))&amp;=&amp;max_l_j(n-1)p^*(l_j(n)|F_n)S_n-1(l_j(n-1))eqnarray*のうち最大のものを選ぶと，最適解であるラベルの並びl_j(1),l_j(2),,l_j(n)が得られる．</subsection>
  <subsection title="自動獲得した書き換え規則による後処理">MEモデルを用いたラベル付けの処理が終った後で，形態素解析により得られる形態素が固有表現より長い場合に対処するため，予め用意しておいた書き換え規則を適用する．書き換え規則はBrillが品詞タグ付けに用いたのと同様の手法である誤り駆動で獲得する．Brillの規則獲得方法との違いはBrillがテンプレートを用いているのに対して我々は用いていない点である．我々の場合，書き換え規則は学習コーパスに対するシステムの解析結果とコーパスの正解データとの差異を調べることによって自動獲得することができる．差異の中から，コーパスでは同じ文字列に対応しているにもかかわらず形態素の数が異なる部分をすべて抽出し書き換え規則として利用する．ただし，前件部は同じであるが後件部が異なるような規則が複数獲得された場合は，最も頻度の高い規則のみを用いる．最も頻度の高い規則が複数種類ある場合，それらの規則はすべて捨てる．さらに，ここで獲得した規則を学習コーパスに対するシステムの解析結果に適用し，誤りとなる数が正解となる数以上であるものはすべて捨てる．例えば，以下のようなものが書き換え規則として獲得される．</subsection>
  <section title="実験と考察"/>
  <subsection title="実験データ">モデルの学習に用いたデータは，CRL(郵政省通信総合研究所)固有表現データ，IREX-NE予備試験トレーニングデータ，IREX-NE予備試験データ，IREX-NE本試験逮捕トレーニングデータの合計約12,000文である．試験に用いたデータはIREX-NE本試験データである．これらはすべて毎日新聞のデータに対して固有表現のタグが付与されたものである．以下で簡単にデータの説明をする．</subsection>
  <subsubsection title="学習データ">学習コーパスの書式はSGML形式で，各固有表現には表~のタグが付与されている．これらのタグ付コーパスからテキスト部分を取り出して形態素解析し，表~にあげる変換規則を用いて各形態素にラベルが付与されたものに変換した後，学習に用いた．IREX-NEの定義は少しずつ更新されている．しかし，それらの定義の違いによるノイズの数は人間が学習データを作成するときに生じるノイズの数とさほど違いはないと考え，すべて学習に用いた．</subsubsection>
  <subsubsection title="本試験データ">1999年4月14日から5月13日の毎日新聞のデータから選ばれた91記事で，ドメインを限らないもの71記事，約400文(以下，「一般ドメイン」と呼ぶ)と「逮捕」にドメインを限ったもの20記事，約100文(以下，「限定ドメイン」と呼ぶ)の2種類のデータからなる．それぞれのドメインのデータにおける固有表現の数は表~の通りである．[htbp]table*</subsubsection>
  <subsection title="実験結果">実験に用いた素性は形態素解析結果から得られる情報であり，着目している形態素を含む前後2形態素ずつ合計5形態素に関する見出し語，品詞(大分類，細分類)である．見出し語としては学習コーパス中に5回以上現れた12,368個を用いた．品詞分類はJUMANのものにしたがった．それぞれ大分類15個，細分類48個である．このうち，式()の素性関数としては学習コーパスに3回以上観測されたもの27,370個を用いた．モデルの重み(式()の_a,j)の学習にはRistadのツールを利用した．次に我々の解析結果を表~に示す．この表で第1列と第2列は書き換え規則を利用したときの限定ドメインの試験(ARREST)に対する結果とドメインを限定しない試験(GENERAL)に対する結果である．第3列と第4列は書き換え規則を利用しなかったときのそれぞれのドメインに対する結果である．どちらのドメインに対しても特別なチューニングはしなかった．精度はどちらのドメインに対しても書き換え規則を用いたときの方が良く，F-measure&amp;=&amp;2再現率適合率再現率+適合率eqnarray*は限定ドメインに対して83.91，一般ドメインに対して79.42であった．IREX-NEの試験では「OPTIONAL」のタグが振られたものについては，その範囲内にシステムがどのような結果を出そうとも，評価には反映されない．ただし，範囲外にずれて重なっている場合には不正解とされる．本論文においてもこの評価方法にしたがった．[htbp]table*</subsection>
  <subsection title="書き換え規則と精度">書き換え規則の適用対象となる固有表現は形態素単位より短い部分文字列を含むもので，本試験データでは限定ドメインに18個，一般ドメインに79個あった．いずれも本試験データ全体の約5%に相当する．学習コーパスから得られた書き換え規則の数は362個であり，そのうち限定ドメインの試験には9個の規則が延べ11回適用され誤りが1個(再現率56%(10/18)，適合率91%(10/11))，一般ドメインの試験には12個の規則が延べ42回適用され誤りが10個(再現率41%(32/79)，適合率76%(32/42))であった．誤りは以下のようなものであった．本来抽出するべき固有表現の部分文字列を誤って抽出してしまう場合(1個)．「在日米軍横田基地」から「日」だけがLOCATIONとして抽出されていた．これは，IREX-NEの定義によると「在日米軍横田基地」がLOCATIONとして抽出されるべきであるが，MEモデルを用いたラベル付けによってうまく抽出できなかった結果，書き換え規則が適用され誤って抽出されてしまった例である．このような誤りをなくすためには，MEモデルを用いたラベル付けの精度を向上する必要がある．学習コーパスでは固有表現となっていたが，正解データでは固有表現となっていない場合(10個)．学習コーパスでは「邦人」の「邦」がLOCATION，「外相会談」の「外」がORGANIZATIONとなっていたが，本試験の正解データでは固有表現とみなされていなかった．このような誤りをなくすためには学習コーパスの整備が必要である．書き換え規則を用いることにより，F-measureで2ポイント(限定ドメイン)および1.5ポイント(一般ドメイン)程度の精度向上がみられた．ここで用いた書き換え規則は形態素の境界とIREXで定義されている固有表現の境界が一致しない場合にのみ対応するために獲得したものである．一致する場合についても同様の書き換え規則を適用することは可能であるが，そうした場合の追加実験ではF-measureで72.23(限定ドメイン)および73.12(一般ドメイン)と書き換え規則を用いない場合に比べてそれぞれ10ポイントおよび5ポイント程度精度が悪くなった．これは我々の用いた簡便な獲得手法では，MEモデルにより付与したラベルを精度良く書き換えられるほどの規則を獲得できないことを示している．しかし，得られた精度向上および規則獲得の簡便さを考慮すると，MEモデルで抽出できない部分を補う方法としては有効な方法であると言える．本手法では形態素解析が終った後に固有表現のラベルを推定するが，形態素解析の段階で形態素の文法的属性(品詞など)と固有表現のラベルを同時に推定するような方法をとることも考えられる．この場合でも書き換え規則は形態素解析の後処理として利用されている久光らの研究と同様にして使えると考えられる．</subsection>
  <subsection title="素性と精度">実験に用いた素性の有効性を調べるために，それぞれの素性を削除したときの比較実験を行なった．比較実験ではすべて書き換え規則を用いた．結果を表~にあげる．[thbp]table*表中のFというのはF-measureのことで，精度の差というのは，着目している形態素とその前後2形態素ずつについて，見出し語，品詞大分類，品詞細分類のすべての情報を素性として用いたときの精度と比べたときの差を意味する．どの素性を削除した場合にも精度が悪くなっており，どの素性も精度の向上に貢献していることが分かる．特に見出し語は精度向上に著しく貢献している．表~の下から三行は，前後の形態素情報の利用範囲を変更したときの結果であり，着目している形態素の情報のみ(表では「(0)のみ」と示す．)，着目している形態素とその前後の形態素の情報のみ(表では「(-1)(0)(1)」と示す．)，着目している形態素とその前後2形態素の情報(表では「(-2)から(2)」と示す．表~に示した結果と同じ．)，着目している形態素とその前後3形態素の情報(表では「(-3)から(3)」と示す．)をそれぞれ素性として用いたときの精度を表す．用いる情報が前後2形態素ずつより多くても少なくても精度が悪くなった．用いる情報を多くしたにもかかわらず精度が悪くなるのは，データスパースネスの問題が深刻になってくるためであると考えられる．</subsection>
  <subsection title="学習コーパスと精度">この節では，学習コーパスと解析精度の関係について考察する．まず，図~，図~に学習コーパスとテストコーパスのそれぞれを解析した場合の学習コーパスの量と解析精度の関係をあげる．図の横軸は学習コーパスの文数，縦軸はF-measureを表す．学習コーパスの解析には限定ドメインとしてIREX-NE本試験逮捕トレーニングデータ，一般ドメインとしてIREX-NE予備試験データを用いた．図では限定ドメイン，一般ドメインに対するグラフにはそれぞれ「arrest」，「general」，書き換え規則を用いた場合と用いなかった場合にはそれぞれ「with_rules」，「without_rules」という表記を用いている．テストコーパスに対する学習曲線(図~)を見ると，特に一般ドメインに対してはまだ精度は飽和していないようである．学習コーパスに対する学習曲線(図~)もわずかではあるが増加する傾向にある．したがって，少なくとも一般ドメインに対しては学習コーパスの量が増えればもう少し精度の向上が期待できそうである．[htbp]figure*</subsection>
  <subsection title="関連研究との比較">1999年5月13日から17日にかけて，IREX-NEの本試験が行なわれた．試験は13日に実行委員長より問題が配布され，17日までに各々のシステムのタグ付け結果を電子メイルで送り返すという形式で行なわれた．IREX-NE本試験に参加したシステムは15システムであった．それらをパターン駆動型，学習型，それらの組み合わせの3種類に分類すると，我々のシステムは学習型に分類される．本節では主に他の学習型システムとの違いを説明し，そのうち重要であると思われる部分については追加実験を行なうことによりその違いがどの程度精度に影響を与えるかを調べる．学習型のシステムのアプローチは我々のものも含めて四つあり，どれも基本的に関根らのとったアプローチに類似している．関根らのシステムを改良したものにはBorthwickのシステム，野畑のシステム，新納のシステムがあり，それらと我々のシステムの違いを表にすると表~のようになる．違いは主に学習モデル，形態素に付与するラベル(NEラベル)の定義，素性，後処理にある．[thbp]table*以下では主に表~の違いに着目して考察する．</subsection>
  <subsubsection title="形態素に付与するラベル(NEラベル)の定義について">我々の定義したNEラベルは関根らのシステムに比べると7種類多い．これは，関根らのシステムよりさらにOPTIONAL(始まり，中間，終り，単独の4種類)およびPRE，POST，MIDのラベルを考慮したためである．OPTIONALはタグ付けが判定者にも困難な場合のために設けられたものであり，その性質を学習することによって，例えばLOCATIONかORGANIZATIONの判定が困難なものをいずれかのタグに分類してしまうのを避けることができると考えられる．PRE,POST,MIDのラベルは固有表現の前後および固有表現の間の形態素に付与するように設けたものである．これは見方を変えると関根らがOTHER(あるいはNONE)としていたラベルを固有表現以外の部分の始まり(POSTに対応)，中間(OTHERに対応)，終り(PREに対応)，単独(MIDに対応)に細分類したものであるとも言える．OPTIONALに関する4種類およびPRE，POST，MIDのラベルがどの程度精度に影響しているかを調べるために，それぞれのラベルをOTHERにマージして追加実験を行なった．その結果を表~〜表~にあげる．表の括弧内の数値は表~にあげた精度からの増減を表す．これらの実験ではMEモデルによるラベル付けの精度の違いを調べることを目的としているためいずれも書き換え規則は用いていない．[htbp]table*表から分かるようにOPTIONALに関するラベルは期待していたほど精度に影響を与えていなかった．PRE，POST，MIDのラベルは一般ドメイン(GENERAL)に対しては精度の向上に貢献しているのに対し，限定ドメイン(ARREST)に対してはその利用がかえって精度を低下させることになっている．固有表現ごとに精度の増減を調べてみると，PRE，POST，MIDのラベルをOTHERにマージすることによって限定ドメインに対してはPERSONとLOCATIONの精度が良くなっており，他の固有表現に対しては悪くなっていることが分かる．限定ドメインの内訳(表~)を見るとPERSONとLOCATIONの個数が多く，これらの固有表現に対する抽出精度が良くなったため全体の精度も良くなったと考えられる．PERSONとLOCATIONに対する精度が良くなったのはPREやPOSTなどが数の多いPERSONやLOCATIONの性質に引っ張られてPERSONやLOCATIONの前後に位置しやすいラベルとして学習されたためである可能性が高い．PERSONやLOCATIONについてはPREやPOSTなどをさらに細分類してPERSON:PREやPERSON:POSTのようなラベルを考えると良いかも知れない．このような細分類は，PERSONやLOCATION，特にPERSONは固有表現直後の形態素が「さん」や「氏」など特別な語であることが多く，他の固有表現についてそのような傾向は見られないことからも妥当な方法であると考えられる．しかし，抽出精度をもとに細分類を続けると本試験のデータに対しては精度が良くなるかもしれないが，他のデータに対しても良くなるとは言えなくなる．したがって，これ以上細分類して本試験のデータに対する精度を調べることはあまり意味がないと思われる．Borthwickのシステムとの精度の差(表~)は主にこのラベルの定義の違いと素性の違いから生じていると考えられる．素性の違いについては後で述べる．一方，野畑はARTIFACT，LOCATION，ORGANIZATIONを細分類してF-measureで2ポイント程度精度が向上したと報告している．我々のシステムにおいてもどの程度精度に影響するかを調べたいところであるが，学習コーパスに付与されたラベルを人手で細分類する必要があるため同じ学習コーパスを作成するのは困難であると判断し，野畑の細分類に基づいて追加実験をするのは見合わせた．新納は形態素ごとではなく文字ごとにNEラベルを付与する方法を提案した．この方法は形態素の区切りと固有表現の区切りが一致しない場合でも一つのモデルで固有表現を抽出できるという点で優れているが，精度は我々に比べてF-measureで20ポイント以上低い．この理由は，後に述べる素性に関連することであるが，新納の方法が文字3-gramという少ない情報のみを用いてNEラベルを推定しているためであると考えられる．3文字ということは多くても3形態素の情報しか用いていないということである．我々の実験では，節でも述べたように着目する形態素およびその前後2形態素ずつの情報を用いた場合が最も精度が良いことから，新納の方法で我々のシステムと同程度の精度を得るためには少なくとも文字5-gram以上の情報を用いる必要があるだろう．しかし，文字5-gramを得るには膨大な学習コーパスが必要であり，我々が実験に用いた学習コーパスだけでは我々のシステムと同程度の精度は得られないと予想される．</subsubsection>
  <subsubsection title="素性について">Borthwickや野畑は我々が用いた素性に加えて字種情報，統語的情報や辞書情報などを用いて精度を向上させている．このうち字種情報については我々の素性においても形態素の品詞情報としてある程度考慮されている．統語的情報については野畑のシステムで用いられている方法では人手の介入が必要であり，同じ条件での実験は困難である．辞書情報については我々の素性に加えて追加実験を行ない，精度に与える影響を調べた．辞書情報としてはBorthwickや野畑と同様に文献で公開されているものを用いた．これは組織名，地名に関する辞書で登録数は約1,000である．それに加えて，学習コーパスに3回以上出現した固有表現約1,400個(ORGANIZATION:272個,PERSON:336個,LOCATION:339個,ARTIFACT:45個,DATE:233個,TIME:31個,MONEY:21個,PERCENT:45個,OPTIONAL:56個)を取り出しそれぞれの固有表現ごとに9種類の辞書を作成した．予めこれらの辞書に登録されている固有表現をJUMANを用いて形態素解析し，各形態素に我々の定義したNEラベルを付与しておく．素性としては，形態素の見出し語がこれらの辞書中でどのようなNEラベルが付与されているかという情報を用いた．つまり，我々が定義した40個のラベルの各々について付与されているかいないかのそれぞれを素性として用いる．辞書中の形態素の見出し語の異なり数は合計約10,000個である．この素性を，着目している形態素のみについて利用した場合，着目している形態素を含む前後1形態素ずつ合計3形態素について利用した場合，着目している形態素を含む前後2形態素ずつ合計5形態素について利用した場合それぞれについて追加実験を行なった．それぞれの実験結果を表~〜表~にあげる．結果は着目している形態素のみについて利用した場合が最も精度が良く，考慮する前後の形態素の数が増えるにつれて精度は悪くなった．これは辞書の登録数が問題になっている可能性が高い．辞書に登録されている固有名詞は高々2,400個程度であり，そのうち1形態素，2形態素，3形態素，4形態素以上からなるものはそれぞれ745個，448個，125個，60個である．例えば二つ前の形態素の見出し語が辞書にあるかないかという情報(我々が辞書情報の素性として利用したもの)が有効なのは辞書に登録されている固有名詞の約8%，185(=125+60)個についてのみであるということになる．今回，学習コーパス以外から得た辞書情報としては一般に公開されている1,000語程度の辞書を用いたが，一般に利用可能な大規模な固有名詞辞書があれば，辞書の登録数と精度の関係も調べてみたい．[htbp]table*次に，素性として一つ前の形態素に付与したラベルの情報を考慮したときの精度を調べた．一般に学習による形態素解析では一つあるいは二つ前の形態素に付与したラベルの情報を用いて次のラベルを決定することが多い．我々の手法においてこれと同様の情報がどの程度精度に影響を与えるかを調べることが目的である．実験結果を表~にあげる．表から分かるようにどちらのドメインについても精度を下げる結果となった．特に再現率の低下が著しい．これは学習コーパスではOTHERの隣はOTHERであることが多く，この連接関係が他のラベルとの連接に比べて学習されやすいためOTHERが連続する場合が最適解となることが多くなるためであると考えられる．[htbp]table*</subsubsection>
  <subsubsection title="後処理について">Borthwickは我々と同様に形態素解析により得られる形態素が固有表現より長い場合に対処するために書き換え規則を用いて後処理をしている．この後処理により，どちらのシステムもF-measureで2ポイント程度精度が向上している．違いはBorthwickが日本語を母語とする人が人手で作成した規則を用いているのに対し，我々は学習コーパスから誤り駆動で自動獲得した規則を用いている点にある．異なるドメインのテキストが与えられたとき，できるだけコストを少なく学習し直すためには規則を自動獲得できる方が望ましい．誤り駆動型学習を用いて固有表現を抽出するシステムには颯々野らのシステムがある．このシステムは後処理として書き換え規則を適用することにより，形態素単位より短い文字列を含む固有表現だけでなく一つあるいは複数の形態素からなる固有表現も同様の手法を用いて抽出できる．彼らがベースラインとして用いているシステムの精度がF-measureで40程度であるため，我々のシステムをベースラインとして用いることによってより良い精度が得られる可能性が高いと考えられる．</subsubsection>
  <subsubsection title="IREX-NE本試験に参加したシステムの結果との比較">IREX-NE本試験での結果を表~にあげる．最も良い精度を出したシステムは人手により作成された規則に基づいている．我々のシステムは本試験ではシステム番号1223であり，精度はF-measureで限定ドメインに対して74.90，一般ドメインに対して72.18であった．このように精度が悪かったのは「MIDDLE」に関するラベルの連接規則に洩れがあったためである．「MIDDLE」に関するラベル同士が連接可能であるという規則が欠如していたため，``比例(ARTIFACT:BEGIN)／代表(ARTIFACT:MIDDLE)／並立(ARTIFACT:MIDDLE)／制(ARTIFACT:END)''のように4形態素以上からなる固有表現は抽出できなくなっていた．本論文ではその洩れを埋めたときの精度を示した．その精度は最高でF-measureで85.75(限定ドメイン)，80.17(一般ドメイン)であった．これはIREX-NE本試験で我々が用いた素性に加えて，節で述べた人名や組織名などの固有名詞辞書も利用したときの精度であり，悪くない精度であると考えている．我々の手法は学習コーパスがあれば人手のコストもかからないため，さまざまなドメインに対しても低コストでそれなりの精度が得られるものであると言える．</subsubsection>
  <section title="まとめ">本論文ではMEモデルと書き換え規則を用いて固有表現を抽出する手法について述べた．IREX-NEの定義に基づくと固有表現には一つあるいは複数の形態素からなるものと形態素単位より短い部分文字列を含むものの2種類がある．前者の固有表現は，固有表現の始まり，中間，終りなどを表すラベルを40個用意し，それらのラベルを推定することによって抽出する．ラベルの推定にはコーパスから学習したMEモデルを用いる．後者の固有表現は書き換え規則を用いて抽出する．書き換え規則は学習コーパスに対するシステムの解析結果とコーパスの正解データとの差異を調べることによって自動獲得することができる．書き換え規則，素性，学習コーパスの量についての条件を変えた比較実験により，形態素解析により得られる形態素が固有表現より長い場合に書き換え規則が有効であること，我々が考慮した素性，つまり，着目している形態素を含む前後2形態素ずつ合計5形態素に関する見出し語，品詞の情報がIREX-NE本試験に用いられたテキストに対して有効であることを示すことができた．これらは学習コーパスのみから得られる情報であったが，それに加えて一般に公開されている人名や組織名などの固有名詞辞書も利用することにより，IREX-NE本試験のデータに対する実験で，F-measureで85.75(限定ドメイン)，80.17(一般ドメイン)の精度を得ることができた．本手法の精度をさらに向上させるために必要であると考えているのは，以下の三点である．素性の発見今回は利用しなかったような情報，例えば，係り受けの情報や照応関係などを素性として新たに考慮することによって，ラベル推定の精度が向上することが期待される．また，解析と同時に解析の過程で得られた情報を利用することも考えられる．これは今後の重要な課題である．コーパス，辞書の充実今回の実験では書き換え規則を利用したことによる誤り例を考察することで，学習コーパスの誤りが精度に影響することが分かった．また，辞書情報を考慮することで精度が向上することも分かった．コーパス修正や辞書作成にかかるコストを考えると，コーパスの誤りを自動あるいは半自動で修正する方法，辞書情報を自動あるいは半自動で獲得する方法を考案する必要がありそうである．特定ドメインへのチューニングドメインを限定すると，そのドメインに固有の固有表現パターンに，より特化した学習が可能であると考えられる．今回は限定ドメインに対して特にチューニングするようなことはしなかったが，限定ドメインに対しどこまでチューニングすることが可能かを調べたい．謝辞flushleft本研究を進めるにあたって有意義なコメントを下さったニューヨーク大学の関根聡助教授に心から感謝の意を表する．また，データの利用を許可して下さった毎日新聞社に感謝する．document</section>
</root>
