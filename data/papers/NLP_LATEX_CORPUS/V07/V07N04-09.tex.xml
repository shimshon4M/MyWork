<?xml version="1.0" ?>
<root>
  <title>複数決定木を用いた入力誤りに頑健な省略補完手法</title>
  <author>山本和英隅田英一郎</author>
  <jabstract>日本語は主語などの要素がしばしば省略されるため，これらの補完は対話処理において重要である．さらに音声対話処理においては，実際に対話を処理する際に入力となるのは音声であり，一部誤りを含んだ音声認識結果が処理対象となるため，言語処理部においても不正確な入力に対する頑健性が要求される．このため，入力の一部に誤りのある状況下における格要素補完問題を考え，以前に提案した決定木を使用した補完手法を改良したモデルを提案する．このモデルは，複数の決定木を使用することで複数解候補を出力し，その中から学習時の終端節点事例数によって解の選好を行なうことで入力誤りに対する頑健性を強化した．音声認識の実誤りと人工的な誤りの2種類で評価実験を行なった結果，提案手法が誤りを含む入力に対し頑健であることを確認した．また人工的な問題に対するシミュレーションの結果，本提案手法は問題非依存であり，入力誤りの多さに応じた決定木の組み合わせでモデルを構成することで有効に機能することが明らかとなった．</jabstract>
  <jkeywords>省略補完，頑健性，音声言語処理，対話処理，決定木</jkeywords>
  <section title="">*謝辞本研究で，シソーラスに使用した「角川類語新辞典」を機械可読辞書の形で提供いただき，その使用許可をいただいた(株)角川書店に深謝する．document</section>
  <section title="はじめに">人と人，または人と計算機が音声を介してコミュニケーションを行なう際に必要となる音声対話処理における頑健性を議論する．例えば，音声を入力としてこれを翻訳し音声出力する音声翻訳などが本論文の想定する対象である．音声対話処理においては，不明瞭な発声や雑音，音声認識処理部の誤りに起因する誤りによって，言語処理部に対して誤りのない正確な入力が得られない場合があり，この結果従来の自然言語処理では問題とならなかった入力の不正確性が生じる．これに対し，従来行なわれてきた言語処理研究の主眼は，*如何にして入力の不正確性を除去するか*という一点に集中していた．すなわち，言語処理として如何に音声認識の誤りを発見し，また訂正するか，という捉え方をしてきた．あるいはそもそも入力の不正確性は音声認識器に起因する問題であるので，理想の音声認識器を考えることで入力の不正確性に伴う問題を回避してきた．これに対し本研究では，現実的な環境を考えた場合に，音声認識誤りのない状況を仮定して言語処理を行なうことは今後しばらく賢明でないという立場を取る．あるいは音声認識の誤り訂正技術の進歩によっても，音声言語処理において誤入力のない状況を想定することは現実的な仮定でないと考える．よって，音声認識後の各処理部がこれら不正確な入力に対して性能を劣化させないという頑健性の考慮，すなわち，*如何にして不正確な入力に対して言語処理を行なうか*が，音声言語処理においては重要である．ところで，対話においては相手と互いにコミュニケーションを取りながら進行していく．このため発話によって伝達される情報は自己完結的でなく，その結果発話の様々な要素の省略がより頻繁に起こりやすい．特に，本論文の対象である日本語対話では，その言語的性質から多くの場合に文の主語が省略される．日本語における主語の省略は，主語が必須格である英語やドイツ語などへの翻訳の際には大きな問題となり，主語の補完処理は必須の処理となる．以上のように，音声対話処理における入力誤りへの頑健性を考慮した主語補完処理は音声対話処理の実現のための重要な処理の一つである．これは田中の分類による言語表現の多様性分類に従えば，音響レベルにおけるエラーを考慮しながら統語レベルの情報不足(省略)の問題解決をしなければならないことを意味している．実際の音声言語システムにおいてはこのように異なるレベルの多様性を同時に考慮する必要があるにもかかわらず，このような研究は従来行なわれていない．主語の補完手法に関しては，次節で述べるようにこれまで様々な手法が提案されてきた．ところが従来の主語補完手法は，誤りのない文に対して形態素解析，構文解析が成功した後に処理されることを仮定していた．このため誤りを含む可能性のある文に対する処理は考慮外であった．これに対し本論文では，入力の一部に誤りがある状況において，性能劣化を如何に最小限に抑えるかについて議論する．誤り部分が入力のどこなのかは明らかでなく，入力に誤りがないかもしれない．ただし，本研究では述語に誤りはなく，また省略の検出は正しく行なわれることを仮定する．また，属性として使用している言語外情報も，音声認識結果とは無関係の情報であるので，これも誤りはないと仮定する．本論文ではまず，本問題に関係する文献の紹介を行なった後，既提案の決定木学習に基づく主語補完手法を概観し，この頑健性について考察する．次に，より頑健性を持ったモデルを提案し，実験結果からこの有効性を議論する．最後に，人工的な問題によるシミュレーションを行ない，モデルの問題依存性と属性組み合わせに関して議論する．</section>
  <section title="関連研究">前述したように，音声認識誤りを含む要素列を入力とした主語補完手法は，これまで知られていない．最近では，河原らが音声言語処理における頑健性について，丸山が話し言葉の諸相について，それぞれ議論を行なっているが，本論文で取り扱う音響レベル，すなわち不正確な音声認識結果に対する自然言語処理の頑健性に関しては議論されていない．本研究では，音声認識誤りを修復，訂正するのではなく，入力のどこかに誤りがあるという状況下でどのように言語処理を行なうかという議論を行なう．同様の状況を想定して言語処理を進めている研究として，脇田らの研究が知られている．脇田らは，本研究と同様，誤りを含む入力に対して機械翻訳させるという問題に対し，音声認識誤りを訂正するのではなく，翻訳結果の意味的な尤度を計算することで音声認識の誤り部分を特定し，その部分を翻訳結果からはずすことで翻訳する手法を提案している．照応処理の頑健性に関してはAoneandBenettが議論している．ここでは語彙，文法あるいは意味知識の網羅が現実では不可能なことに対処する頑健性の必要性を議論している．ただし，この論文で議論されている頑健性はすべて，利用する情報が不足している場合における頑健性であり，音声言語処理にとって重要な入力の不正確性に関しては考慮されていない．日本語の主語補完に関しては従来から様々な研究がなされてきているが，その多くは書き言葉を対象にしたものであり，話し言葉もしくは対話を対象にしたものは比較的少ない．書き言葉を対象にしたものでは，Nakaiwaetal.の用言意味属性と語用論的，意味論的制約を用いて外界省略の解消を行なったものがある．また村田らは物語を対象に，補完に関係する表層的な言語現象をヒューリスティックスで得点を付与し，それらの合計によって最尤の省略内容を補完している．また，江原らの研究はニュース原稿を対象にしている．ここでは，複文を単文に分割した際に生じる省略主語を補完するという人工的に問題に対して，経験的に8項目の特徴パラメータを設定して，確率モデルによる手法を提案している．Dohsakaは，日本語において発話から語用論的制約を抽出し，制約充足プロセスに基づいて文脈の下で解釈することによる文脈省略の補完手法を提案している．</section>
  <section title="主語補完手法">本節では，日本語の格要素省略を補完する問題に対して我々が文献において提案した手法の概要を紹介する．本論文では，このモデルをSDT(SingleDecisionTree)モデルと呼び，入力の不確かさに対する頑健性という観点から，SDTモデルがどの程度の頑健性を持つのかについて定性的な議論を行なう．さらに，入力の誤りに対して頑健な主語補完モデルを作成するためにはどうすればよいかについて検討する．</section>
  <subsection title="決定木を用いた補完手法">SDTモデルでは，決定木(DecisionTree)による知識表現手法を用いて主語補完知識の構築を行なう．決定木の学習では，(誤りのない)入力と正解となる主語情報を持った事例から，事前に用意した属性の有無によって質問を行ない，エントロピー基準によって事例の分類を行なっていく．論文においては，一般的な決定木学習手法の一つであるC4.5のアルゴリズムによって二分木を作成した．本論文の設定する問題では，補完すべき主語を6種類に分類した．すなわち，一人称単数&lt;1sg&gt;，一人称複数&lt;1pl&gt;，二人称単数&lt;2sg&gt;，二人称複数&lt;2pl&gt;，照応的省略&lt;a&gt;，一般&lt;g&gt;である．決定木は，与えられた入力に対して当該省略がこのどのクラスに属するかを決定する．表に，本問題に対して作成された決定木の例を示す．この決定木では，木の根にあたる節点[1-1]で:sem-code:here43すなわち対象とする述語の意味属性(角川類語新辞典における分類番号上位2けた)が43かどうかによって学習事例が分岐し，これを満たす場合は[2-1]へ，満たさない場合は[2-2]へ進む．節点[6-2]は終端節点であり，解が&lt;1pl&gt;すなわち一人称複数であり，学習事例は5であったことを示す．表の各属性に見られるように，各属性は(属性の種類,照合位置,属性値)の三つ組によって表現される．以下の節では，属性の種類，照合位置について簡単に述べる．</subsection>
  <subsection title="属性集合">本論文では論文と同様に，以下の3種類の属性を用いた．以上をまとめたものを表に示す．全属性を用いて決定木を作成した場合，属性数は367となる．</subsection>
  <subsection title="属性の照合方法">決定木学習時に行なう属性照合は，形態素列とのマッチングによって属性の照合を行なう．すなわち，補完対象の用言を中心にして，表に示す5種類のうちどの位置に出現するかという情報をすべての属性に予め与えておく．例えば，用言に関する属性は:here，格助詞に対しては:before，接頭辞に対しては:latestの位置情報を与える．意味属性に関しては，ある位置にある意味属性を持つ語が含まれているかどうかによって照合を行なう．</subsection>
  <subsection title="SDTモデルの頑健性">以上のSDTモデルの頑健性を考えた場合，以下の点において頑健性があると予想される．すなわち，入力に対して，本来の入力にはない形態素列が誤って挿入された場合における頑健性である．例えば，間投詞や言い淀みなど，音声言語に頻出する冗長語が入力の途中に挿入された場合に，SDTモデルにおいては全く悪影響を与えない．あるいは，音声認識の誤りにより内容語や機能語が挿入された場合であっても，それが偶然に決定木で照合される語句である場合以外は，補完結果が変化することはない．以上の頑健性は，属性照合の際に，ある照合範囲における特定の語句の有無のみを考慮しているために生じる．これにより，照合範囲に対象と無関係の語句が挿入された場合にも影響はなく，また照合対象である語句が照合範囲に偶然挿入される可能性は，一般には低い．ただし，以上は挿入誤りに対するある程度の頑健性のみであり，欠落誤り，置換誤りに対しては影響が出る可能性が高い．なぜなら，前述の照合方法は照合に不要な要素をいくら含んでも影響は少ないが，照合に必要な要素が欠落した場合には対応できないからである．</subsection>
  <subsection title="複数決定木モデル">本論文では入力の不正確性に対する頑健性を持った主語補完モデルを提案する．このモデルは，我々が文献で提案した格要素省略補完モデルSDTを拡張したものであり，複数決定木モデルまたはMDT(MultipleDecisionTree)モデルと呼ぶ．概要を図に示す．MDTモデルは，複数の決定木を使用することによって頑健性を持たせたモデルである．このモデルでは，決定木学習の際に使用する属性集合を変化させることによって決定木を作成し，複数の解答候補を得る．図に示すように，従来SDTでは単一の解D_0のみが得られるため，この解の信頼性が低い場合にも代替解を得ることができなかった．これに対し，本論文で提案するMDTモデルでは，複数の解，例えば(D_1,D_2,,D_n)の解を得ることでき，この中から最も信頼性の高い解を選択することによって，MDTモデル全体としての頑健性が増す．ここで，各決定木の学習は，全く同一の学習事例集合に対して行なう．以下，どのように使用属性を変化させるかについては節で，複数の解候補の中からどのようにして最終解を選択するかについては，節で述べる．</subsection>
  <subsection title="頑健性を強化するための方策">前節に示した省略補完モデルに対し，入力の不正確性に対して頑健なモデルにするにはどうすればいいかを考える．既存のモデルがある場合，このモデルに頑健性を持たせる手段として，本論文では複数の解答候補を用意し，そのうちの一つを何らかの方法によって最終的に選択する，という方策を取る．複数の解答候補を生成するには，解答に至るための情報源を別個にすればよい．すなわち，同一のモデルを使用してそのモデルの入力となる情報源を変化させることによって，各モデルに独自の判断をさせることが可能になる．これはちょうど，ある事象に対して，同一の道具で観察する視点を変化させることに相当する．ここで，以上の方策を取るためには以下の二つの問題を解決しなければならない．すなわち，*どのように別個の情報源を用意するか複数の解答候補からどのように最終解を選択するか*である．以上の問題点については，次節以降で述べる．</subsection>
  <subsection title="属性集合の組合せ">複数決定木モデルにおいては，各決定木の作成時に使用する属性を変化させる必要がある．我々は文献における実験で，属性の種類が減少して同一種類の属性のみで決定木を作成した場合，補完精度の劣化が大きいことを確認した．すなわち主語補完のためには，様々な属性を総合的に考慮して補完する必要がある．このため表で使用した3種類の属性をそのまま使用して各種類ごとに決定木を作成しても，(入力の不正確性とは関係なく)補完精度の劣化が大きいことが容易に予想される．そこで本論文では，これら属性集合を組み合わせることによって各決定木の属性集合を構成することにした．本論文の使用する属性は前述したように3種類であるので，図に示すようにこれらの組合せによって3種類の属性集合を作成した．これにより，使用属性数の減少による各決定木の補完精度の劣化を抑えることができ，同時に複数解候補を作成することが可能になる．</subsection>
  <subsection title="補完候補の選好基準">前節に示すように複数の属性を用意して複数の解答候補が得られたとき，このうちどれを最終的な解答とするかが第二の問題である．本節では，この問題について検討する．複数の解から一つの解を選択する際には多数決基準などが一般的であるが，本問題のように属性の組合せによって決定木を作成している場合に，多数決基準を使用するのは適当ではない．なぜなら，仮に図のような状況で言語外情報が誤りを含んでいると仮定すると，3種類の決定木すべてが誤った解を出力する可能性があるからである．このように一属性が複数の解に影響するような組み合わせ方を行なった場合，解の多数決を取ることは適当ではないと考えた．そこで本論文では，各解答に対して信頼性を計算し，それの比較によって行なう選好基準を提案する．この際，解の信頼性に相当する値として，以下に述べる理由により，決定木学習時に解と同一の終端節点に辿り着いた事例数を用い，これが最多である解を選択する．いま，決定木のある属性において属性照合を誤ったと仮定する．この場合，本来到達すべき終端節点には到達せずに別の節点に到達する．この際，どの節点に到達したかは，これ以上の情報がない場合，一般にすべての節点が同一の確率である．ここで，誤って到達した節点の学習時の事例数を予想すると，全節点への到達可能性が同等なのだから，終端節点の学習事例数に関して最も頻出する事例数が最も可能性が高い．例えば，学習事例数iの終端節点が最も多い場合には，誤って到達した節点の学習時事例数はiの可能性が最も高いと予想するのが自然である．それでは実際にどのような事例数の終端節点が多いのかを調査したのが図である．図では，次節で述べる3種類の決定木それぞれについて，終端節点の事例数別に統計をとったものである．この図から明らかなように，どの決定木においても，学習時の事例数が1の節点が最も多く，その後漸減の傾向にある．すなわちこれらの決定木に関しては，学習時の事例数が少ない節点ほど誤って辿り着く確率が高い．次に，図に示すように，同一の学習事例集合に対して属性集合を(S_1,S_2,,S_n)のn種類に変化させ，複数の決定木を作成することを考える．図において，属性集合S_1による補完結果候補D_1よりも，属性集合S_2による補完結果候補D_2のほうが解の信頼性が高いと考えるのは自然である．なぜならば，これまでの議論により，属性照合を誤って解候補D_2に到達する可能性よりも属性照合を誤って解候補D_1に到達する可能性のほうが高いからである．入力に誤りがあるために本来の属性の照合ができなかった場合には，学習事例数のより少ない節点に到達する確率がより高いため，例のように学習事例数の多い節点に到達した場合には，確率的に解の信頼性が高いと見做すことができる．以上の理由により，我々は決定木学習時の終端節点の事例数によって解の選好を行なう．これにより，各決定木が出力した解答候補のうち，決定木が出力した終端節点の学習時事例数が最大の解答をMDTにおける解答とする．例えば図では属性集合S_2における解答の学習時終端節点事例数が最も多いので，D_2をMDTとしての解答とする．</subsection>
  <subsection title="提案手法の頑健性">本手法の挙動を定性的に考察する．本論文の提案する手法によって入力に若干の誤りがあり，誤り箇所を特定できない場合に対して本手法は有効に機能することが予想できる．ただし選好基準から明らかなように，本手法は学習時において事例が集中した「大きな」節点に対してのみ有効に機能する．あるいはある節点に極端に事例が集中するような場合に，本論文の選好がより有効に機能する．この一方，学習時に事例数が1であった節点は，属性に誤りがあった場合に本手法では本来の正しい解を出力することが期待できない．すなわち，本手法はすべての事例に対して頑健になるわけではないが，事例が集中した節点を対象にしていることから多くの事例に対して頑健になることが予想できる．以上の議論の定量的な検証は節において行なう．</subsection>
  <section title="主語補完実験">本論文で提案したモデルの有効性を議論するため，主語補完実験を行なった．実験は，実際の音声認識結果を入力とした実誤りに対する精度と，人工的に誤りを作成した人工誤りに対する主語補完精度を評価した．本論文では6種類のクラスによる補完精度の違いを議論するのが目的ではないため，以下の実験結果ではクラス別の補完精度を示さず，全評価事例に対する平均を示す．実験では，性能評価尺度としてF値(F-measure)を用いた．F値は，再現率(recall)と適合率(precision)の調和平均であり，Rを再現率，Pを適合率としたとき，以下の式で定義する．ここで，パラメータは適合率の再現率に対する相対的な重要性である．本論文では前述の理由によりこのパラメータを=1として，再現率と適合率の重要性を同等に扱う．</section>
  <subsection title="音声認識結果に対する頑健性">本稿で提案したモデルの有効性を確認するため，実際の音声認識結果を入力とした実誤りに対する補完精度を測定した．また比較のため，音声認識誤りのない正解入力に対する補完精度も測定した．訓練事例数は1401事例，実験事例数は訓練に含まれない303事例である．対象ドメインはホテルの予約もしくは解約時の二者会話であり，ATR旅行会話コーパスを使用した．音声認識装置は日英音声翻訳システムATR-MATRIXにおける音声認識用音響・言語モデルを使用した．実験では，認識装置の音響尤度と言語尤度の相対的重みを変化させることによって3種類の異なる誤り傾向をもつ音声認識結果を用いて行なった．各パラメータの音声認識精度を表に示す．なお，表に示した3種類のパラメータのうち，パラメータP2は使用した音声認識器において最高性能を示すパラメータであり，P1とP3は局所的に最大の音声認識性能を示すパラメータである．実験は，音声認識誤りのない正解入力と，その同一の文集合の音声認識結果の2種類について行なった．実験文数は448文である．表に，実誤りに対する性能を示す．実験の結果，用意したパラメータのいずれにおいてもMDTが最高性能を示した．また，誤りのない入力に対しても，MDTは最も高い主語補完性能を示した．実験は，単独の決定木を使用して補完を行なうSDTモデルによる実験と，本稿の提案するMDTモデルの両者について行なった．SDTモデルにおける属性集合は，図における集合A，集合F，集合Cの三種類に対して行なった．以下では，これをそれぞれ，SDT/A，SDT/F，SDT/Cと表記する．また，MDTモデルは，上記の属性集合A，C，Fの三つからSDTを構成した．</subsection>
  <subsection title="人工誤りに対する実験">次に，モデルの頑健性と誤りの傾向との関連を議論するために，以下のような人工誤りに対してモデルがどのような特性を示すのかを実験した．実験は，以下の4種類の誤りについて行なった．挿入誤り欠落誤り置換誤り(挿入，欠落，置換の)混合誤り</subsection>
  <subsubsection title="挿入誤り">挿入誤りは以下のように作成した．まず，誤りのない形態素列に対して，誤りを挿入する位置を無作為に一ヶ所決定する．この位置に対し，決定木学習を行なった訓練会話の形態素集合から任意の一語を無作為に選択し，この語を挿入する．挿入される語は，訓練会話の各形態素の出現割合と同一の期待値で決定されるため，格助詞などの高頻出語が挿入される可能性が高くなる．以上が一語を挿入する過程であり，N語を挿入する場合には以上の過程をN回繰り返す．挿入誤りの個数と性能との関係を図に示す．図より，MDTモデルは挿入誤りに対してほとんど性能劣化のないことが明らかになった．また三種のSDTモデルに関しても，若干の精度低下はあるものの誤り語数増加に伴う程度低下割合はゆるやかである．SDTモデルが挿入誤りに対してあまり性能が落ちないのは，節で議論した要素照合手法が頑健性を持っていたことを示し，挿入誤りに関してはSDTモデルにもある程度の頑健性を持っていることが確認された．また，MDTモデルにほとんど性能劣化がないのは，上記SDTが持つ頑健性に加え，意思決定を複数行なった後に選択する本手法が有効に機能しているためと考えられる．</subsubsection>
  <subsubsection title="欠落誤り">欠落誤りは以下のように作成した．誤りのない形態素を入力として，欠落させる形態素を無作為に選択する．ただし，省略された主語に対する動詞もしくはサ変名詞は選択の対象からはずす．なぜなら，もし当該動詞もしくはサ変名詞が欠落された形態素が音声認識結果となった場合には，省略の検出が不可能となり，補完の対象とはならないからである．このため，省略の検出を処理の対象外とする本論文の立場では，このような欠落誤りを考慮対象から除外することは妥当である．欠落誤りの個数と性能との関係を図に示す．欠落誤りは補完に必要な情報の一部が欠ける誤りであるため，手がかりが欠如し，挿入誤りよりも性能の劣化をもたらす．図からわかるように，MDTモデルは三種類のSDTのうち最も高精度であるSDT/Cよりも常に高精度である．なお，図においてはSDT/Cモデルがほとんど性能劣化がないが，これは欠落誤りの対象に述語が含まれていないためである．SDT/Cモデルではこの情報を主要な情報として主語を決定しているため，述語以外の形態素の欠落に対してはあまり性能劣化を起こさない．これに対し，SDT/Cモデルの精度が相対的に優れているという情報をMDTは何ら持たないにもかかわらずMDTがSDT/Cの出力する解を比較的多く採用している点から，本論文で提案した選好の有効性を確認することができる．</subsubsection>
  <subsubsection title="置換誤り">置換誤りは以下のように作成した．誤りのない形態素を入力として，欠落させる形態素を無作為に選択する．ただし，省略された主語に対する動詞もしくはサ変名詞は欠落誤りと同様の理由で，欠落の対象からはずす．この後，この欠落の位置に，挿入誤りと同様，決定木学習を行なった訓練会話の形態素集合から任意の一語を無作為に選択し，この語を挿入する．以上が一語を挿入する過程であり，N語を挿入する場合には以上の過程をN回繰り返す．置換誤りの個数と性能との関係を図に示す．置換誤りに対する性能は，欠落誤りと類似の傾向を示した．これは，本実験での置換作成過程が(欠落＋挿入)であり，前述のように挿入誤りに対しては各モデルともかなり頑健であるためであると考えられる．</subsubsection>
  <subsubsection title="混合誤り">混合誤りは以下のように作成した．正解入力に対して，まず誤りの種類を決定する．誤りは，挿入，欠落，置換の三種類が同じ確率で出現するように，無作為に決定する．誤り種類が決定した後は，前述した挿入，欠落，置換誤りの処理を行なう．複数形態素の誤りの場合は，以上の処理を複数回繰り返し，その都度誤り種類を無作為に選択する．混合誤りの個数と性能との関係を図に示す．図から，混合誤りに対してもMDTモデルの優位性を見ることができる．</subsubsection>
  <subsection title="考察">まず，入力誤りに対する頑健性を議論する．図〜図より，本論文で提案するMDTモデルが比較手法(SDT)よりも頑健であることがわかる．特に，MDTモデルは挿入誤りに対して非常に頑健であり，10個に満たない形態素の挿入に対してはほとんど補完性能の劣化がないことが確認された．また表より，実際の音声認識の結果，誤りを含んだ入力に対しても，SDTに比較して優位であることを確認した．MDTの精度は常にどのようなSDTよりも高精度であることから，MDTで採用した選好基準は，ある一定の条件下で最尤のSDTの出力を解とする性質を持っている可能性がある．もしこの仮説が正しければ，より高精度のSDTモデルを用意することでMDTとしての精度も向上することが期待できる．本研究では3種類の属性集合を用意したが，これは3種類である必要はなく，むしろ高性能であると予想されるSDTをできるだけ多く用意することで，MDT全体としてより頑健性が増すことが期待できる．どのようなSDTをどの程度用意すればよいのかについては，次節のシミュレーションで議論する．次に，入力の誤り傾向との関係を議論する．表に，音声認識実験で誤った語の品詞別挿入誤りと欠落誤り数をパラメータ別に示した．この表と表の比較から，内容語によるSDT/Cは普通名詞や本動詞の欠落の最も少なかったパラメータP2が，機能語によるSDT/Fは格助詞の欠落が最も少なかったパラメータP1が最も高い精度を示したと説明できる．表から，3種類のSDTの中で最も良好なSDT/AはP2よりもP1のほうが補完精度が高いが，MDTの補完精度はP2がP1を上回っている．これは，MDTが必ずしもSDT/Aの解を選好しているわけではないことを示している．たとえ音声認識精度が十分でなくても，ある特定の音声認識の誤りにあまり影響されないSDTを用意することができれば，それによって正解に至る解答候補を得ることができ，かつ正しく選好できる可能性が高い．</subsection>
  <section title="シミュレーション">前節の評価実験で，誤りを含む入力に対して節の属性集合からなるMDTモデルが主語補完問題に対し有効に機能することを確認した．しかし，以上の結果はいかなる問題に対してもMDTモデルが有効なのか，あるいは本論文における属性集合の組み合わせ方が偶然有効に機能したのかは明確でない．そこで，MDTモデルの問題依存性，並びに属性集合の組み合わせ方がモデルの精度にどのような影響を与えるのか，の2点を検証，議論するため，人工的な問題を設定してMDTモデルのシミュレーションを行なった．本節ではこの内容及び結果について述べる．</section>
  <subsection title="問題設定とMDTの設定">問題は以下のように設定した．まず，問題の全属性数は10，分類すべきクラス数は10とした．属性値は二値としたため作成される決定木は二分木であり，枝刈りは行なわない．学習事例は，以下の2種類の方法で順に作成した．以上のような方法で，本シミュレーションではS_Dが1084事例，S_Sが1000事例の合計(S)2084事例を作成した．各決定木は，事例集合Sを用いて作成する．次に，使用したMDTについて述べる．MDTは以下のようにSDTを組み合わせて構成した．すなわち，使用属性数がi以上の全属性組み合わせについてSDTをすべて作成し，これを組み合わることで構成した．以下ではこれをMDT(i)と記述する．例えば，MDT(9)は9属性の全組み合わせ(10種類)と10属性の全組み合わせ(1種類)に対してそれぞれ作成した11個のSDTを組み合わせたモデルである．同様にMDT(8)は56個，MDT(7)は176個のSDTからなり，最多のMDT(1)は1023個のSDTから構成される．実験は以下のように行なった．学習時に使用した事例集合Sに対し，各事例について1ヶ所(後述の節では2または3ヶ所，節では0ヶ所)の属性を無作為に選び，その属性値に誤りを起こさせたものを入力とした．すなわち，今回作成する二分木は属性が2値であるため，無作為に選ばれた属性の属性値を反転させたものを入力とした．実験は，10属性以下で構成される全組み合わせのSDT(1023個)に対して精度を測定し，これをもとに10種類のMDT(i)(i=1〜10)の精度を計算した．また比較対象として，多数決基準，すなわちi属性以上のすべてのSDTが返す解のうち最多のものを解とする選考基準での精度も測定した．</subsection>
  <subsection title="シミュレーション結果">ある乱数におけるシミュレーションの結果を図に示す．異なる乱数でシミュレーションを行なった場合も全く同様の傾向が見られた．図で，実線はMDT，点線は多数決基準の精度を示し，SDT単独の精度は点で表した．任意の1属性に誤りがある入力に対し，使用可能な全10属性からなるSDTは10.4%，9属性以上のSDTによる多数決基準は16.0%の正解率であるのに対し，MDT(9)は57.6%の正解率を得ることができ，MDTの優位性を確認した．またMDT(9)は9属性以上で可能な全組み合わせに対して作成したSDTを用いていることより，どうやって不要な属性を減らすか，あるいはどのような組み合わせが適当かを考慮する必要がないため，MDTモデルはこの点において，SDTモデルで使用属性を吟味して精度向上を目指すアプローチよりも優位である．ただし，図が示す通り，MDTモデルは少数属性のSDTを追加していくに従い精度が低下する．逆に多数決基準は精度が向上し7属性以下の決定木を使用した場合には両者の精度が逆転した．このことから，MDTはどのような属性数の決定木を加えても精度向上するわけではないことがわかる．最高の精度は5属性以上による多数決基準によって得られた(58.7%)が，現実的には少数属性の決定木を大量に作成して多数決を取ることは計算量の面で有利ではないため，1誤りの場合はMDT(9)が最も実用的なモデルであると言える．図において各SDTがどのような精度であるかを観察すると，属性数が減少するに伴い，平均的に徐々に精度は向上している．一方，MDT(i)が選択するSDTを観察すると，SDTの中で最少属性のもののうちから選択されている場合が圧倒的に多い．例えば，MDT(6)は6属性のSDTのうちの一つの解を選択している場合が圧倒的に多い．一般的に，終端節点の学習事例数は，多数属性で作成した決定木のそれよりも少数属性のほうが平均的に多いためこのように少数属性のSDTが選択されやすくなるのであろうが，相対的に精度の高い少数属性のSDTを選択してもMDTの精度が低下する理由は不明である．これは今後の課題としたい．</subsection>
  <subsection title="事例集合との関係">節で議論したように，MDTモデルは事例が集中した節点を得るのに用いた属性に誤りがある場合に有効に機能すると予想される．ここではこれを検証する．本シミュレーションでは，終端節点に集中する事例S_Dとそれ以外の事例S_Sの2種類の方法で事例集合Sを作成した．事例集合Sに誤りを含めた場合に，図に示すようにMDT(9)は全体で57.6%の精度が得られたが，これを事例集合別に分類して集計すると，S_Dは96.5%，S_Sは15.5%の精度であり，極端に精度が異なる．この結果は，頻出する現象に対しては入力に誤りがあってもかなり高い精度で正解を得ることができるのに対し，稀に出現する現象は正解を得ることが期待できないことを示し，節で行なった議論が正しいことを確認した．以上の結果から本手法が有効に機能する状況が推測できる．すなわち，決定木において一部の終端節点に事例が集中するような構造を持つ場合ほど，MDTは誤りを含む入力に対して頑健であることが予想される．</subsection>
  <subsection title="誤り数との関係">図においてMDT(9)の精度が最も高いのは，各事例に対して1個の属性値に誤りを起こしているためである可能性がある．ではもし誤りが1ではなく，2もしくは3である場合，MDTはどのような傾向を示すであろうか．これを示したのが図(2誤りの場合)および図(3誤りの場合)である．このシミュレーションにおいては，誤り数以外の条件は全く同じであり，誤りを含める対象の事例集合Sも，図と全く同一のものを使用した．図が示すように，各属性に無作為に2誤りを与えた場合はMDT(8)が，3誤りの場合はMDT(7)が最も高い精度を示していることがわかる．すなわち，誤りの数と用意するSDTとの間には相関関係がありそうである．すなわち，図，図，図から類推すると，属性数がNで誤りが高々iならば属性数が(N-i)以上のすべてのSDTでMDTを構成するのが最善であろう．</subsection>
  <subsection title="正解入力での特性">最後に，誤りがない場合にMDTがどのような挙動を示すのかを検証する．図に，事例集合Sに誤りを与えずに各モデルに入力した場合，すなわち学習事例と入力が全く同一の場合のテスト(closedtest)を行なった結果を示す．この図から明らかなように，一般に属性数の減少に伴い精度は低下していくが，本提案モデルの精度の低下が最も激しい．ただし，正解入力は誤り0の入力であるので，これを前節で議論した誤り数と使用属性数の関係にあてはめると，全属性数で決定木を作成するのが最も適切であろうという予想が得られ，シミュレーション結果と一致する．本シミュレーションでは矛盾のないように属性を作成しているので，このような状況においては全属性による決定木が一つあれば十分で，入力に誤りのない場合は複数決定木モデルを使用する必要がない．ただし，主語補完問題のようにこのような状況が成立しない場合には，実験結果が示すように誤りが0であっても複数決定木モデルが有効に機能する可能性がある．これがどのような場合に有効なのかはシミュレーションでも究明することができなかった．今後の課題としたい．</subsection>
  <section title="結論と今後の課題">音声言語処理では，従来の自然言語処理ではほとんど問題にならなかった入力の不正確性が生じる．これに対し，入力の誤り訂正技術への努力だけでは不十分であり，入力に誤りが含まれていることを前提とした問題解決モデルの構築が，これからの音声言語処理において重要である．本論文では，対話に頻出する主語省略の補完問題を取り上げ，複数の決定木を用いたモデル(MDTモデル)による問題解決手法を提案した．また同時に，複数の補完候補からの選好基準として，学習時の終端節点事例数を使用することを提案した．実験では，音声認識結果に対して正解テキスト入力と比べて数%程度の性能低下で抑えられ，特に挿入誤りに対して頑健であることを示した．また，問題依存性および属性組み合わせに関する議論を行なうため人工的な問題を設定したシミュレーションを行なった．この結果，本モデルは問題非依存のモデルであり，主語補完にのみ有効に機能するわけではないことを示した．本論文で行なった主語補完実験とシミュレーションにより，MDTモデルの特性が明らかになった．これをまとめると，MDTモデルは以下の状況が満たされた場合においてより有効に機能する．決定木内に学習事例が集中する節点が多く存在する問題(節)(全属性数−誤り数)以上の属性から構成される決定木の全組み合わせをモデルの構成要素とした場合(節)入力に若干の誤りのある場合(節)複数決定木モデルは，特に入力列の挿入誤りに対して頑健であると結論づけることができるが，欠落，置換誤りに関しては相対的に脆弱である．これらの誤りによる性能劣化は情報の欠落が原因であるのでやむを得ない面もあるが，今後の課題として情報欠落に伴う精度劣化を最小限に抑えることを目指す．また，主語補完実験においては無誤りでもMDTのほうが高性能であったが，これがどのような状況であったためかは明確でなく，実験においても結論を出すに至らなかった．今後はこの点に関しても検証してみたい．</section>
</root>
