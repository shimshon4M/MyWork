\documentstyle[jnlpbbl,epsf]{jnlp_j}


\setcounter{page}{261}
\setcounter{巻数}{7}
\setcounter{号数}{4}
\setcounter{年}{2000}
\setcounter{月}{10}
\受付{00}{5}{1}
\採録{00}{6}{30}

\setcounter{secnumdepth}{2}

\title{自動要約のための文重要度の比較}
\author{内山 将夫\affiref{U} \and 井佐原 均\affiref{U}}

\headauthor{内山,井佐原}
\headtitle{重要文抽出のための文重要度の比較}

\affilabel{U}{郵政省通信総合研究所}{Communications Research Laboratory, Ministry of Posts and Telecommunications}


\jabstract{本稿では，重要文抽出によるテキスト自動要約のための各
  種重要度を比較した．特に，タイトルとの類似度の高い文から抽出
  するという要約方法を想定し，各種の類似度を比較した．類似度と
  しては，共起関係を利用する方法と利用しない方法とを試みた．そ
  の結果，共起関係を利用する方法の方が高精度な要約が作成できた．
  また，要約の手法としては，他に，本文の先頭数文を抽出する方法
  と，単語の重要度の総和を文の重要度とする方法も試みたが，これ
  らの方法よりも，タイトルとの類似度に基づく方法の方が高精度で
  あった．これらの結果は，共起関係を利用した類似度が自動要約に
  有効であることを示している．}

\jkeywords{テキスト自動要約，重要度，類似度，共起関係}

\etitle{Empirical Comparison of Sentence Importance\\ 
  Measures for Automatic Text Summarization} 
\eauthor{Masao Utiyama\affiref{U} \and Hitoshi Isahara\affiref{U}}

\eabstract{The effectiveness of various statistical measures of
  sentence importance was compared for automatic text
  summarization done by extracting important sentences. We
  focused on comparing various measures of sentence similarity
  on the assumption that important sentences in an article are
  similar to the title. Two types of similarity measures were
  compared: one uses word co-occurrence statistics and the
  other does not. The former proved superior to the latter. 
  Other automatic text summarization methods, such as
  extracting the leading part of an article, or extracting
  sentences with important words, proved inferior to the
  similarity-based method. These results show that similarity
  measurement using word co-occurrence statistics is effective
  for automatic text summarization.}

\ekeywords{automatic text summarization, importance, similarity, co-occurrence statistics}


\begin{document}

\maketitle


\section{はじめに}
\label{sec:intro}

テキスト自動要約は，自然言語処理の重要な研究分野である．自動要
約の方法には様々なものがあるが，現在の主流は，テキスト中から重
要文を抽出して，それらを連結することにより要約を生成する方法で
ある\cite{oku99}．

重要文を選ぶための文の重要度は，一般に，
\begin{itemize}
\item 位置情報 (例：先頭部分の文は重要)
\item 単語の重要度 (例：重要単語を含む文は重要)
\item 文間の類似関係 (例：タイトルと類似している文は重要)
\item 文間の修辞関係 (例：結論を述べている文は重要)
\item 手がかり表現 (例：「要するに〜」などで始まる文は重要)
\end{itemize}
などのテキスト中の各種特徴に基づいて決める\cite{oku99}．

これらの特徴の組合せは，人手で決める
\cite{edmundson69:_new_method_autom_extrac}ことも，機械学習によ
り決める\cite{kupiec95:_train_docum_summar}こともできるが，いず
れの方法で決めるとしても，それぞれの特徴を精度良く自動的に求め
ることが重要である．

そのため，我々は，これらの特徴を個別に調査し，それぞれの自動要
約への寄与を調べることを試みた．特に，本稿では，文間の類似度の
各種尺度を，新聞記事要約を対象として比較した．類似度の良さは，
要約の良さにより比較した．すなわち，精度の高い要約ができるよう
な類似度ほど，高精度の類似度であると解釈した．ここで，文間の類
似度を求める方法としては，単語間の共起関係を利用する方法と利用
しない方法とを試みた．その結果は，共起関係を利用する方法の方が
高精度であった．

なお，各種の類似度を比較するための要約方法としては，タイトルと
の類似度が高い文から重要文として抽出するという方法を利用した．
この要約方法を利用して類似度を比較した理由は，タイトルは本文中
で最も重要であるので，それとの類似度が文の重要度として利用でき
ると考えたからである．なお，タイトルが重要であるという考えに基
づく要約には，\cite[など]
{yoshimi98:_evaluat_impor_senten_connec_title,okunishi98}がある．

また，要約の手法としては，他に，本文の先頭数文を抽出する方法
\cite{brandow95:_autom_conden_elect_public}と，単語の重要度の総
和を文の重要度とする方法
\cite{zechner96:_fast_gener_abstr_gener_domain}も試みたが，これ
らの方法よりも，タイトルとの類似度に基づく方法の方が高精度であっ
た．

これらのことから，共起関係を利用した方法によりタイトルとの類似
度を求め，その類似度が高い方から重要文として抽出する方法が，自
動要約に有効であることが分かった．

以下では，まず，\ref{sec:measures}章で，各種の文の重要度の定義
を述べ，次に，\ref{sec:expriments}章で，各種重要度を比較した実
験について述べる．\ref{sec:conclusion}章は結論である．

\section{文の重要度の定義}
\label{sec:measures}

重要文を抽出するためには，文に重要度を付与する必要がある．その
ための各種の重要度を以下に定義する．なお，以下では，重要度が数
値的に高い文ほど重要な文であるとする．

\subsection{先頭の数文を抽出する手法}
\label{sec:lead}

文章(特に新聞記事)の先頭の数文(冒頭部)は重要と考えられる
\cite{brandow95:_autom_conden_elect_public}．その先頭の数文を抽
出するためには，文$S$の文章中での位置を$p(>=1)$とすると，$S$の
重要度$lead(S)$を，たとえば，
\begin{equation}
  \label{eq:lead}
  lead(S) = \frac{1}{p}
\end{equation}
と定義すれば良い．なお，$lead(S)$としては，その他には，$lead(S)
= -p $などを採用することもできる．

\subsection{単語重要度の和による文重要度}
\label{sec:sum}

重要単語を多く含む文は重要と考えられるので，単語の重要度の和を
文の重要度とすれば良いと考えられる
\cite{zechner96:_fast_gener_abstr_gener_domain}．文の重要度を単
語重要度の和として求めるためには，文$S$を構成する単語集合を
$W(S)$とすると，単語$w$の重要度を$f(w)$とし，$w$の$S$中での頻度
を$n(w,S)$とするとき，文$S$の重要度$sum(S,f)$を，
\begin{equation}
  \label{eq:sum}
  sum(S,f) = \sum_{w \in W(S)} n(w,S) \times f(w)
\end{equation}
と定義すれば良い．

単語$w$の重要度$f(w)$としては，以下のものを定義する．
\begin{eqnarray}
  \label{eq:wimps1}
  one(w) & = & 1\\
  \label{eq:wimps2}
  tf(w) & = & \mbox{要約対象文書中での$w$の頻度}\\
  \label{eq:wimps3}
  idf(w) & = & \log \frac{\mbox{全文書数}}{\mbox{$w$を含む文書数}}\\
  \label{eq:wimps4}
  tfidf(w) & = & tf(w) \times idf(w)
\end{eqnarray}
なお，(\ref{eq:sum})式における$f(w)$を$tfidf(w)$としたときの重
要度が，\cite{zechner96:_fast_gener_abstr_gener_domain}で採用さ
れた文の重要度に相当する．

\subsection{タイトルとの類似度による文重要度}
\label{sec:sim}

タイトルは本文中で最も重要と考えられる
\cite{yoshimi98:_evaluat_impor_senten_connec_title}ので，それと
類似度が高い文は重要と考えられる．そのタイトルとの類似度を文の
重要度とするために，文$S$とタイトル$T$の類似度を以下に定義する．
まず，共起頻度を利用しない方法(以下の$common$, $ip$, $cos$)を定
義する．これらは，類似度の定義として良く知られたものである．

\subsubsection*{共通単語の重みの和}

\begin{equation}
  \label{eq:common}
  common(S,T,f)  =  \sum_{w \in W(S) \cap W(T)} n(w,S) f(w)
\end{equation}

\subsubsection*{内積}

\begin{equation}
  \label{eq:ip}
  ip(S,T,f)  =  \sum_{w \in W(S) \cap W(T)} n(w,S) f(w) \times n(w,T) f(w)
\end{equation}

\subsubsection*{コサイン}

\begin{equation}
  \label{eq:cos}
  cos(S,T,f) = \frac{ip(S,T,f)}{\sqrt{ip(S,S,f)}\sqrt{ip(T,T,f)}}
\end{equation}

ここで，$f$は，(\ref{eq:wimps1})式から(\ref{eq:wimps4})式で定義
された関数のいずれかである．

次に共起頻度を利用する方法(以下の$coProb$, $coIDF$)を定義する．
共起頻度は条件付き確率として式中に現れる．なお，以下で述べる，
比較的簡単な式である$coProb$と，IDF(Inverse Document Frequency)
の拡張としての$coIDF$とは，類似度の尺度として，本稿で新たに提案
するものである．

\subsubsection*{共通単語の条件付き確率の和}

\begin{equation}
  \label{eq:coProb}
  coProb(S,T) = \sum_{w \in W(S)} n(w,S) \Pr(w|T)
\end{equation}

\subsubsection*{IDFの拡張}

\begin{equation}
  \label{eq:coIDF}
  coIDF(S,T) = \sum_{w \in W(S)} n(w,S) \times \Pr(w|T) \log \frac{\Pr(w|T)}{\Pr(w)}
\end{equation}

ここで，
\begin{eqnarray}
  \label{eq:pr1}
  \Pr(w) & = & \frac{\mbox{$w$を含む文書数}}{\mbox{全文書数}}\\
  \label{eq:pr2}
  \Pr(w|T) & = & \max_{v \in W(T)} \Pr(w|v)\\
  \label{eq:pr3}
  \Pr(w|v) & = & \frac{\mbox{$w$と$v$を含む文書数}}{\mbox{$v$を含む文書数}}
\end{eqnarray}
である．

これらの確率の定義によると，$\Pr(x|x) = 1$である．そのため，
(\ref{eq:coIDF})式は，
\begin{eqnarray}
  coIDF(S,T) & = & \sum_{w \in W(S) \cap W(T)} n(w,S) \times idf(w) \nonumber \\
  & + & \sum_{w \in W(S) - W(S) \cap W(T)} n(w,S) \times \Pr(w|T) \log \frac{\Pr(w|T)}{\Pr(w)} \nonumber
\end{eqnarray}
と変形できる．つまり，$coIDF(S,T)$は，共通単語$w$については，
$idf(w)=1\times \log \frac{1}{\Pr(w)}$の和を求め，それ以外につ
いては，共起確率を考慮した値$\Pr(w|T) \log
\frac{\Pr(w|T)}{\Pr(w)}$の和を求めていると言える．これから分か
るように，$\Pr(w|T) \log \frac{\Pr(w|T)}{\Pr(w)}$は，$idf(w)$の
拡張と言える．

また，(\ref{eq:coProb})式は，
\begin{eqnarray}
  coProb(S,T) & = & \sum_{w \in W(S) \cap W(T)} n(w,S) \times one(w) \nonumber \\
  & + & \sum_{w \in W(S) - W(S) \cap W(T)} n(w,S) \times \Pr(w|T)\nonumber
\end{eqnarray}
であるので，共通単語数を確率的に求めたものとも言える．

\section{実験}
\label{sec:expriments}

本章では，各種重要度により重要文を抽出し，その抽出精度を求めた．

\subsection{実験材料}
\label{sec:material}

\subsubsection*{コーパス等}

IDF等を求めるときのコーパスとしては，「CD-毎日新聞」の91-98年版
(8年間分)の約86万記事を茶筅version2.02\cite{matsumoto99}により
形態素解析した結果を用いた．なお，IDF等の計算においては，1記事
を1文書とした．

また，各種の重要度を求めるときに，各文の単語を必要とするが，こ
のときの単語としては，10記事以上に出現した単語で，かつ，茶筅の
品詞体系における，「名詞」「未知語」「記号-アルファベット」に該
当するもののみを選んだ．ただし，名詞のうちで，その下位分類が
「数」「代名詞」「非自立」「特殊」「接尾」「接続詞的」「動詞非
自立的」に該当するものは除いた．

\subsubsection*{正解データ}

「CD-毎日新聞」94年版から抽出した56記事についての，被験者による
重要文抽出結果を正解データとした\footnote{正解データは筑波大学
  山本幹雄助教授に提供していただいた．}．これらの記事は以下の分
布である．
\begin{itemize}
\item 14記事からなるセットが4セットで合計56記事
\item 各セットの14記事は、記事の長さを100文字単位で区切って，各
  文字数の範囲から1記事を無作為に選択．つまり，
  \begin{quote}
    \begin{tabular}{ll}
      0〜99文字　     & 1記事\\
      100〜199文字　  & 1記事\\
      200〜299文字　  & 1記事\\
      ...\\
      1300〜1399文字　& 1記事\\
    \end{tabular}
  \end{quote}
\end{itemize}
各セットは，3または5人の被験者により要約された(set1,3が5人，
set2,4が3人)．

被験者は，各記事から重要文を，抽出結果の分量が，元の記事の約
30\%になるように抽出した\footnote{被験者は，実際には，重要文か
  ら，更に，重要文節も抽出したが，その情報は今回の実験では使用
  しなかった．また，抽出された重要文についても，特に重要な文と，
  その他の重要文という2通りが被験者により区別されているが，今回
  の実験では，この区別は無視して，抽出された文は，区別なく全て
  重要文とした．}．その抽出結果についての諸元を表\ref{tab:stat}
に示す．これらの結果は，各記事を，抽出された文の数によりクラス
分けした場合の統計である．なお，ある文が抽出されたとは，その文
が，過半数の被験者(5人の場合は3人，3人の場合は2人)により抽出さ
れたことであると定義する．また，全記事とは，56記事全てについて
の結果である．

\begin{table}[htbp]
  \caption{被験者による重要文抽出結果の諸元}
  \begin{center}
    \begin{tabular}{|c|cccc|} \hline
      抽出文数 & 記事数 & 平均抽出数 & 平均記事長& 抽出率\\ \hline
      1        & 10     &    1.0     &     2.7   &  0.37\\
      2        & 10     &    2.0     &     5.9   &  0.34\\
      3〜4     & 13     &    3.6     &    12.6   &  0.28\\
      5〜6     & 11     &    5.2     &    16.9   &  0.31\\
      7〜11    & 12     &    8.6     &    27.6   &  0.31\\ \hline
      全記事   & 56     &    4.2     &    13.8   &  0.31\\ \hline
    \end{tabular}
    \label{tab:stat}
  \end{center}
\end{table}

表\ref{tab:stat}で，「抽出文数」により分かれる記事のクラスにお
いて，「記事数」とは，そのクラスに属する記事の数である．「平均
抽出数」とは，そのクラスの各記事から抽出された文数の平均値であ
る．「平均記事長」とは，そのクラスの各記事に含まれる文数の平均
値である．「抽出率」とは，平均抽出数を平均記事長で割った値であ
る．

\paragraph{被験者の重要文抽出精度}

5人の被験者(a,b,c,d,e)について，それぞれが選んだ文と正解データ
(過半数の被験者が選んだ文)との再現率と適合率を表\ref{tab:sbj}に
示す．ただし，被験者$x$が選んだ文の集合を$S(x)$とし，過半数の被
験者に選ばれた文の集合を$M$とするとき，
\begin{eqnarray}
  \label{eq:recall}
  再現率(x) & = & \frac{|S(x) \cap M|}{|M|}\\
  \label{eq:precision}
  適合率(x) & = & \frac{|S(x) \cap M|}{|S(x)|}
\end{eqnarray}
である．

\begin{table}[htbp]
  \caption{被験者の重要文抽出精度}
  \begin{center}
    \begin{tabular}{|c|ccccc|ccccc|}\hline
         &     & &再現率&    &    &    &    &適合率&  &\\ \cline{2-11}
抽出文数 & a  &b   &c   &d   &e   &a   &b   &c   &d   &e\\\hline
1        &0.86&0.80&1.00&1.00&1.00&0.75&0.67&0.88&0.80&0.78\\
2        &0.88&0.75&0.88&0.92&0.94&0.88&0.67&0.82&0.85&0.94\\
3〜4     &0.75&0.71&0.81&0.82&0.98&0.64&0.61&0.69&0.68&0.83\\
5〜6     &0.83&0.63&0.86&0.79&0.97&0.79&0.56&0.78&0.71&0.90\\
7〜11    &0.78&0.76&0.82&0.80&0.86&0.78&0.74&0.83&0.76&0.87\\\hline
全記事   &0.80&0.71&0.84&0.82&0.92&0.75&0.65&0.79&0.73&0.87\\\hline
    \end{tabular}
    \label{tab:sbj}
  \end{center}
\end{table}

表\ref{tab:sbj}の再現率や適合率が高いのは，正解データをこれらの
被験者から作成したので，ある程度は，当然であるが，それでも，後
掲の表\ref{tab:comp}に示す，自動抽出の結果に比べるとずいぶんと
高い．統計的には，全記事を対象として，再現率と適合率とを考えた
とき，もっとも数値の低い被験者bの適合率0.65を除いては，自動抽出
で最高精度である$coIDF$の結果と比べても，比率の差の検定による片
側検定で，全てが有意水準5\%で有意に再現率や適合率が高い．

\subsection{実験方法と実験結果}
\label{sec:results}

正解データの与えられた56記事を要約の対象とし，茶筅により形態素
解析し，その結果について，各種重要度を適用して重要文を抽出した．
各記事から抽出する文数は，正解データにおける抽出文数と同じにし
た．これは，(\ref{eq:recall})式と(\ref{eq:precision})式において，
$|M|=|S(x)|$であることを意味する．したがって，再現率と適合率と
が等しくなる．そのため，本節では，それらを単に精度と呼ぶことに
する．

表\ref{tab:comp}は，\ref{sec:measures}章で定義した各種重要度に
ついて，抽出文数によりクラス分けされた記事について，抽出精度を
求めたものである．たとえば，まず，$lead(S)$は，抽出文数1の記事
に対しては，精度1.00，つまり，1文だけを抜き出すなら，先頭文を抜
き出すと必ず正解であることを示す．次に，たとえば，$sum(S,one)$
は，(\ref{eq:sum})式の関数$f$として，(\ref{eq:wimps1})式の関数
$one$を用いたことを示し，$common(S,T,one)$は，タイトル$T$との類
似度を，関数$one$により，(\ref{eq:common})式を用いて求めたこと
を示す．

\begin{table}[htbp]
  \caption{各種重要度による重要文抽出精度(=適合率,再現率)の比較}
  \begin{center}
    \begin{tabular}{|l|llllll|}\hline
      &  &  & \multicolumn{2}{c}{抽出文数と精度}&  & \\\cline{2-7}
      重要度 & 1 & 2 & 3〜4 & 5〜6 & 7〜11 & 全記事\\ \hline
      $lead(S)$ & 1.00 & 0.65 & 0.68 & 0.49 & 0.42 & 0.53\\ \hline
      $sum(S,one)$ & 0.50$^{--}$ & 0.75 & 0.43$^-$ & 0.40 & 0.53 & 0.50\\
      $sum(S,tf)$ & 0.70 & 0.70 & 0.55 & 0.46 & 0.50 & 0.53\\
      $sum(S,idf)$ & 0.50$^{--}$ & 0.70 & 0.45$^-$ & 0.42 & 0.50 & 0.49\\
      $sum(S,tfidf)$ & 0.70 & 0.65 & 0.49 & 0.40 & 0.55 & 0.52\\ \hline
      $common(S,T,one)$ & 0.80 & 0.75 & 0.49 & 0.49 & 0.55 & 0.55\\
      $common(S,T,tf)$ & 0.80 & 0.75 & 0.49 & 0.46 & 0.53 & 0.54\\
      $common(S,T,idf)$ & 0.80 & 0.70 & 0.47$^-$ & 0.49 & 0.56$^{+}$ & 0.55\\
      $common(S,T,tfidf)$ & 0.90 & 0.70 & 0.49 & 0.47 & 0.52 & 0.54\\\hline
      $ip(S,T,one)$ & 0.80 & 0.75 & 0.47$^-$ & 0.49 & 0.55 & 0.55\\
      $ip(S,T,tf)$ & 0.90 & 0.75 & 0.49 & 0.44 & 0.51 & 0.53\\
      $ip(S,T,idf)$ & 0.80 & 0.70 & 0.49 & 0.47 & 0.53 & 0.54\\
      $ip(S,T,tfidf)$ & 0.90 & 0.70 & 0.47$^-$ & 0.44 & 0.48 & 0.50\\\hline
      $cos(S,T,one)$ & 0.80 & 0.65 & 0.49 & 0.49 & 0.51 & 0.53\\
      $cos(S,T,tf)$ & 0.80 & 0.65 & 0.47$^-$ & 0.46 & 0.50 & 0.51\\
      $cos(S,T,idf)$ & 0.80 & 0.65 & 0.47$^-$ & 0.46 & 0.52 & 0.52\\
      $cos(S,T,tfidf)$ & 0.80 & 0.70 & 0.45$^-$ & 0.44 & 0.49 & 0.50\\ \hline
      $coProb(S,T)$ & 0.80 & 0.75 & 0.53 & 0.47 & 0.62$^{++}$ & 0.59\\
      $coIDF(S,T)$ & 0.80 & 0.75 & 0.53 & 0.54 & 0.61$^{++}$ & 0.60\\ \hline
\end{tabular}
\label{tab:comp}
\end{center}
\end{table}

表\ref{tab:comp}では，$lead(S)$をベースラインとして，各種重要度
を評価した．このとき，もし，ある重要度が$lead(S)$と比率の差の検
定による両側検定により有意に精度が異なるときには，有意水準5\%の
ときには，`$+/-$'，有意水準1\%のときには，`$++/--$'を付けてそれ
を示した．ここで，正の符号は，その重要度が$lead(S)$よりも精度が
高いことを示し，負の符号は，その逆を示している．

表\ref{tab:comp}から，抽出文数1, 2, 3〜4, 5〜6(平均記事長は，そ
れぞれ，2.7, 5.9, 12.6, 16.9文)については，$lead(S)$の精度が他
よりも良いか同等であることが分かる．これは，先頭部に重要なこと
が書かれているという新聞記事の性質を反映している．しかし，抽出
文数7〜11(平均記事長=27.6)になると，先頭部のみでは，カバーでき
る重要文が少なくなるため，$lead(S)$は他と比べて有効な方法ではな
くなる．

全記事での精度に基づいた結果から，まず，単語重要度の組合せ方の
精度を比較すると，
\begin{equation}
  \label{eq:comp1}
  coIDF,coProb (0.595) >= common (0.545) >= ip (0.53) >= cos (0.515) >= sum (0.51)
\end{equation}
である．この順位は，たとえば，$common$ については，
$common(S,T,one)$, $common(S,T,tf)$, $common(S,T,idf)$,
$common(S,T,tfidf)$ の全記事についての精度の平均を求めると，
$(0.55+0.54+0.55+0.54)/4=0.545$であり，$coIDF$と$coProb$では，
$(0.59+0.60)/2=0.595$であることなどから順位付けた．なお，括弧内
の数字は，求めた平均値である．

この結果から，$coIDF$と$coProb$が他よりも重要文選択に適した重要
度であることが分かるが，この結果は統計的には有意ではない．統計
的に有意であることを示すには，より規模の大きい実験が必要である．
ただし，$coIDF$と$coProb$は，表\ref{tab:comp}でも，抽出文数7〜
11の場合には，$lead(S)$と比べて，有意水準1\%で高精度に重要文を
抽出できるので，長い記事については，$lead(S)$を使うよりも，これ
らの共起情報を利用した重要度を使った方が良いと言える．また，短
い記事についても，共起情報を利用した重要度は，$lead(S)$と比べて，
統計的には同等であるので，共起情報を利用した重要度は，自動要約
に適していると言える．



\section{おわりに}
\label{sec:conclusion}

重要文抽出によるテキスト自動要約のために，各種の重要度を比較し
た．本稿では，特に，文間の類似度の各種尺度を，新聞記事要約を対
象として比較した．このとき，文の重要度は，タイトルとの類似度に
より定義した．

文間の類似度を求める方法としては，単語間の共起関係を利用する方
法と利用しない方法とを試みた．実験の結果，共起関係を利用した類
似度の方が，高精度な要約ができた．この結果から，共起関係を利用
した類似度が自動要約に有効であると言える．

我々は，今後，本稿での知見に基づいて，各種情報を統合した自動要
約システムを作ることを考えている．また，本稿で提案した，IDFの拡
張としての類似度を，自動要約だけでなく，情報検索にも応用して，
その有効性を確かめたいと考えている．

\bibliographystyle{jnlpbbl}
\bibliography{sum}

\begin{biography}
\biotitle{略歴}
\bioauthor{内山 将夫}{
筑波大学第三学群情報学類卒業(1992).
筑波大学大学院工学研究科博士課程修了(1997).博士(工学).
信州大学工学部電気電子工学科助手(1997)．
郵政省通信総合研究所非常勤職員(1999).
言語処理学会，情報処理学会，ACL，人工知能学会，日本音響学会，各会員．
}
\bioauthor{井佐原 均}{
1978年京都大学工学部電気工学第二学科卒業．
1980年同大学院修士課程修了．博士（工学）．
同年通商産業省電子技術総合研究所入所．
1995年郵政省通信総合研究所
関西支所知的機能研究室室長．自然言語処理，機械翻訳の研究に従事．
言語処理学会，情報処理学会，人工知能学会，日本認知科学会，ACL，各会員．}
\bioreceived{受付}
\bioaccepted{採録}
\end{biography}

\end{document}
