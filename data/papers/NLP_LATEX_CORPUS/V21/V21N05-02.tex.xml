<?xml version="1.0" ?>
<root>
  <jtitle>共変量シフト下の学習による語義曖昧性解消の教師なし領域適応</jtitle>
  <jauthor>新納浩幸佐々木稔</jauthor>
  <jabstract>本論文では語義曖昧性解消(WordSenseDisambiguation，WSD)の教師なし領域適応の問題に対して，共変量シフト下の学習を試みる．共変量シフト下の学習では確率密度比w(x</jabstract>
  <jkeywords>語義曖昧性解消，領域適応，共変量シフト，uLSIF，負の転移</jkeywords>
  <subsection title="P_S( x">)の補正による確率密度比の算出WSDのタスクではNB法あるいはuLSIFで算出される確率密度比は小さい値を取る傾向があり，実際の学習で用いる際には，少し上方に修正した値を取る方が最終の識別結果が改善されることが多い．これは以下の2点から生じていると考えられる．Tにxが入っているかは確率的であるが，Sには必ずxが入っている．P_S(x)を推定するためにxSを用いるため，訓練データであるxに過学習した結果P_S(x)はP_T(x)に比べて高く見積もられてしまう．このため，求まった確率密度比を上方に修正する手法が存在する．論文では確率密度比w(x)をp乗(0&lt;p&lt;1)することを提案している．また論文では以下で示される相対確率密度比w'(x)を確率密度比として利用することを提案している．[w'(x)=P_T(x)P_S(x)+(1-)P_T(x)]ここで0&lt;&lt;1である．確率密度比w(x)が1以下である場合，w(x)をp乗すると上方に修正できることは，それらの比の対数を取れば，)&lt;0であることから明らかである．[w(x)^pw(x)=(p-1)w(x)&gt;0]また相対確率密度比w'(x)は以下の変形からw(x)を上方に修正していると見なせる．w'(x)&amp;=P_T(x)P_S(x)+(1-)P_T(x)&amp;=1+(1-)w(x)w(x)&amp;&gt;1+(1-)w(x)&amp;=w(x)align*確率密度比が1以上である場合，これらの手法は確率密度比を下方に修正するので，正確には確率密度比を1に近づける手法である．しかし，ほとんどの訓練データの確率密度比は1以下であるために，ここではこれらの手法を上方修正する手法と呼び，提案手法と対比させる．本論文では確率密度比を上方に修正するために，ソース領域のデータとターゲット領域のデータを合わせたデータを新たにソース領域のデータとみなし，NB法を用いてP_S(x)を補正することを提案する．これはSのスパース性を緩和させることを狙ったものである．確率密度比が真の値よりも低く見積もられる原因の1つは，P_S(x)が真の値よりも高く見積もられるからだと考える．さらにその原因がSのスパース性なので，スパース性を緩和するためにSにデータを追加するというアイデアである．ただし追加するデータはSと類似の領域のデータであることが望ましい．WSDの領域適応の場合，SとTは完全に異なることはなく，比較的似ているために，追加するデータとしてTのデータが利用できると考えた．提案手法の新たなソース領域をS+Tで表せば，P_S(x)&gt;P_S+T(x)が成立していると考えるのは自然であり，この不等式が成立していれば，提案手法により確率密度比は上方に修正される．ただし，ここで提案手法は必ずしもNB法の確率密度比を上方に修正できるとは限らないことに注意する．また提案手法はNB法の確率密度比が1以下かどうかには無関係であることにも注意する．NB法の確率密度比が1以上であっても，上方に修正する可能性がある．またP_S+T(x)は以下の式を利用して求められる．P_S+T(f)&amp;=n(S+T,f)+1N(S+T)+2&amp;=n(S,f)+n(T,f)+1N(S)+N(T)+2align*</subsection>
  <section title="はじめに">本論文では，語義曖昧性解消(WordSenseDisambiguation,WSD)の領域適応に対して，共変量シフト下の学習を試みる．共変量シフト下の学習では確率密度比を重みとした重み付き学習を行うが，WSDのタスクでは算出される確率密度比が小さくなる傾向がある．ここではソース領域のコーパスとターゲット領域のコーパスとを合わせたコーパスをソース領域のコーパスと見なすことで，この問題に対処する．なお本手法はターゲット領域のデータにラベル付けしないため，教師なし領域適応手法に分類される．WSDは文中の多義語の語義を識別するタスクである．通常，あるコーパスSから対象単語の用例を取り出し，その用例中の対象単語の語義を付与した訓練データを作成し，そこからSVM等の分類器を学習することでWSDを解決する．ここで学習した分類器を適用する用例がコーパスSとは異なるコーパスT内のものである場合，学習した分類器の精度が悪い場合がある．これが領域適応の問題であり，自然言語処理ではWSD以外にも様々なタスクで問題となるため，近年，活発に研究されている．今，対象単語wの用例をx，wの語義の集合をCとする．x内のwの語義がcCである確率をP(c|x)とおくと，WSDは_cCP(c|x)を求めることで解決できる．領域適応では，コーパスS（ソース領域）から得られた訓練データを用いて，P(c|x)を推定するので，得られるのはS上の条件付き分布P_S(c|x)であるが，識別の対象はコーパスT（ターゲット領域）内のデータであるため必要とされるのはT上の条件付き分布P_T(c|x)である．このため領域適応の問題はP_S(c|x)P_T(c|x)から生じているように見えるが，用例xがどのような領域で現れたとしても，その用例x内の対象単語wの語義が変化するとは考えづらい．このためP_S(c|x)=P_T(c|x)と考えられる．P_S(c|x)=P_T(c|x)が成立しているなら，P_T(c|x)の代わりにP_S(c|x)を用いて識別すればよいと思われるが，この場合，識別の精度が悪いことが多い．これはP_S(x)P_T(x)から生じている．P_S(c|x)=P_T(c|x)かつP_S(x)P_T(x)という仮定は共変量シフトと呼ばれる．自然言語処理の多くの領域適応のタスクは共変量シフトが成立していると考えられる．ソース領域のコーパスSから得られる訓練データをD=(x_i,c_i)_i=1^Nとおく．一般に共変量シフト下の学習では確率密度比w(x)=P_T(x)/P_S(x)を重みとした以下の重み付き対数尤度を最大にするパラメータを求めることで，P_T(c|x)を構築する．[_i=1^Nw(x_i)P_T(c_i|x_i;)]共変量シフト下の学習の要は確率密度比w(x)の算出であるが，その方法は大きく2つに分類できる．1つはP_T(x)とP_S(x)をそれぞれ求め，その比を求めることでw(x)を求める方法である．もう1つはw(x)を直接モデル化する方法である．ただしどちらの方法をとっても，WSDの領域適応に対しては，求められる値が低くなる傾向がある．この問題に対しては，確率密度比をp乗(0&lt;p&lt;1)したり，相対確率密度比を使うなど，求めた確率密度比を上方に修正する手法が存在する．本論文ではP_T(x)とP_S(x)をそれぞれ求める手法を用いる際に，ターゲット領域のコーパスとソース領域のコーパスを合わせたコーパスを，新たにソース領域のコーパスSと見なして確率密度比を求めることを提案する．提案手法は必ずしも確率密度比を上方に修正する訳ではないが，多くの場合，この処理によりP_S(x)の値が減少し，結果的にw(x)の値が増加する．なお，本論文で利用する手法は，ターゲット領域のラベル付きデータを利用しないために，教師なし領域適応手法に属する．当然，ターゲット領域のラベル付きデータを利用する教師付き領域適応手法を用いる方が，WSDの識別精度は高くなる．しかし本論文では教師なし領域適応手法を扱う．理由は3つある．1つ目は，教師なし領域適応手法はラベル付けするコストがないという大きな長所があるからである．2つ目は，共変量シフト下の学習はターゲット領域のラベル付きデータを利用しない設定になっているからである．3つ目は，WSDの領域適応の場合，対象単語毎に領域間距離が異なり，コーパスの領域が異なっていても，領域適応の問題が生じていないケースも多いからである．領域適応の問題が生じている，いないの問題を考察していくには，ターゲット領域のラベル付きデータを利用しない教師なし領域適応手法の方が適している．実験では現代日本語書き言葉均衡コーパス(BalancedCorpusofContemporaryWrittenJapanese,BCCWJ)における3つの領域OC（Yahoo!知恵袋），PB（書籍）及びPN（新聞）を利用する．SemEval-2の日本語WSDタスクではこれらのコーパスの一部に語義タグを付けたデータを公開しており，そのデータを利用する．すべての領域である程度の頻度が存在する多義語16単語を対象にして，WSDの領域適応の実験を行う．領域適応としてはOC→PB，PB→PN，PN→OC，OC→PN，PN→PB，PB→OCの計6通りが存在する．結果166=96通りのWSDの領域適応の問題に対して実験を行った．その結果，提案手法による重み付けの効果を確認できた．また，従来手法はベースラインよりも低い値となったが，これは多くのWSDの教師なし領域適応では負の転移が生じていない，言い換えれば実際には領域適応の問題になっていないことから生じていると考えられる．考察では負の転移と重み付けとの関連，また負の転移と関連の深いMisleadingデータの存在と重み付けとの関連を中心に議論した．</section>
  <section title="関連研究">自然言語処理における領域適応は，帰納学習手法を利用する全てのタスクで生じる問題であるために，その研究は多岐にわたる．利用手法をおおまかに分類すると，ターゲット領域のラベル付きデータを利用するかしないかで分類できる．利用する場合を教師付き領域適応手法，利用しない場合を教師なし領域適応手法と呼ぶ．提案手法は教師なし領域適応手法の範疇に入るので，ここでは教師なし領域適応手法を中心に関連研究を述べる．領域適応の問題は，一般の教師付き学習手法における訓練事例のスパース性の問題だと捉えることもできる．そのためターゲット領域のデータにラベルを付与しないという条件では，半教師付き学習が教師なし領域適応手法として使えることは明らかである．ただし半教師付き学習では大量のラベルなしデータを必要とする．半教師付き学習をWSDに利用する場合，対象単語毎に用例を集める必要があり，しかもターゲット領域のコーパスは新規であることが多いため，対象単語毎の用例を大量に集めることは困難である．このためWSDの領域適応の場合，半教師付き学習を利用しようとすれば，Transductive学習に近い形となるが，ソース領域とターゲット領域が異なる領域適応の形にTransductive学習が利用できるかどうかは明らかではない．WSDの領域適応をタスクとした教師なし領域適応の研究としては，論文の研究がある．そこでの基本的なアイデアはWSDで使うシソーラスをターゲット領域のコーパスから構築することであるが，WSDで使うシソーラスが分野依存になっているかどうかは明らかではない．またChanはターゲット領域上の語義分布をEMアルゴリズムで推定している．これも教師なし領域適応手法であるが，本論文で扱う領域適応では語義分布の違いは顕著ではなく，効果が期待できない．本論文は，WSDの領域適応では共変量シフトの仮定が成立していると考え，共変量シフト下の学習を利用する．共変量シフト下の学習を領域適応に応用した研究としてはJiangの研究と齋木の研究がある．Jiangは確率密度比を手動で調整し，モデルにはロジステック回帰を用いている．また齋木はP_S(x)とP_T(x)をunigramでモデル化することで確率密度比を推定し，モデルには最大エントロピー法を用いている．ただしどちらの研究もタスクはWSDではない．しかもターゲット領域のラベル付きデータを利用しているために，教師なし領域適応手法でもない．また新納はWSDの領域適応に共変量シフト下の学習を用いているが，そこではDaum'eが提案した素性空間拡張法(FeatureAugmentation)を組み合わせて利用しているために，これも教師なし領域適応手法ではない．一方，共変量シフト下の学習は，事例への重み付き学習の一種である．Jiangは識別精度を悪化させるようなデータをMisleadingデータとして訓練データから取り除いて学習することを試みた．これはMisleadingデータの重みを0にした学習と見なせるため，この手法も重み付き学習手法と見なせる．吉田はソース領域内の訓練データxがターゲット領域から見て外れ値と見なせた場合，xをMisleadingと判定し，それらを訓練データから取り除いて学習している．これはWSDの教師なし領域適応手法であるが，Misleadingデータの検出は困難であり，精度の改善には至っていない．またWSDの領域適応をタスクとした古宮の手法も重み付き学習と見なせる．そこでは複数のソース領域のコーパスを用意し，そこから訓練事例をランダムに選択し，選択された訓練データセットの中で，ターゲット領域のテストデータを識別するのに最も適した訓練データセットを選ぶ．これは全ソース領域のコーパスの訓練データから選択された訓練データの重みを1，それ以外を重み0としていることを意味する．ただし複数のソース領域のコーパスから対象単語のラベル付き訓練データを集めるのは実際は困難である．また古宮は上記の研究以外にもWSDの領域適応の研究を行っているが，これらは教師付き学習手法となっている．</section>
  <section title="期待損失最小化に基づく共変量シフト下の学習">対象単語wの語義の集合をC，またwの用例x内のwの語義をcと識別したときの損失関数をl(x,c,d)で表す．dはwの語義を識別する分類器である．P_T(x,c)をターゲット領域上の分布とすれば，本タスクにおける期待損失L_0は以下で表せる．[L_0=_x,cl(x,c,d)P_T(x,c)]またP_S(x,c)をソース領域上の分布とすると以下が成立する．[L_0=_x,cl(x,c,d)P_T(x,c)P_S(x,c)P_S(x,c)]ここで共変量シフトの仮定から[P_T(x,c)P_S(x,c)=P_T(x)P_T(c|x)P_S(x)P_S(c|x)=P_T(x)P_S(x)]となり，w(x)=P_T(x)/P_S(x)とおくと以下が成立する．[L_0=_x,cw(x)l(x,c,d)P_S(x,c)]訓練データをD=(x_i,c_i)_i=1^Nとし，P_S(x,c)を経験分布で近似すれば，[L_01N_i=1^Nw(x_i)l(x_i,c_i,d)]となるので，期待損失最小化の観点から考えると，共変量シフトの問題は以下の式L_1を最小にするdを求めればよいことがわかる．分類器dとして以下の事後確率最大化推定に基づく識別を考える．[d(x)=_cP_T(c|x)]また損失関数として対数損失-P_T(c|x)を用いれば，は以下となる．[L_1=-_i=1^Nw(x_i)P_T(c_i|x_i)]つまり，分類問題の解決にP_T(c|x,)のモデルを導入するアプローチを取る場合，共変量シフト下での学習では，確率密度比を重みとした以下に示す重み付き対数尤度L()を最大化するパラメータを求める形となる．ここではモデルとして以下の式で示される最大エントロピー法を用いる．x=(x_1,x_2,,x_M)が入力，cがクラスである．関数f_j(x,c)は素性関数であり，実質xの真のクラスがcのときにx_jを返し，そうでないとき0を返す関数に設定される．Z(x,)は正規化項であり，以下で表せる．そして=(_1,_2,,_M)が素性に対応する重みパラメータとなる．</section>
  <section title="確率密度比の算出">確率密度比w(x)=P_T(x)/P_S(x)の算出法は大きく2つに分類できる．1つはP_S(x)とP_T(x)を各々推定し，その比を取る手法であり，もう1つはw(x)を直接モデル化する手法である．ここでは前者の方法として論文において提案された手法を利用する．簡単化のために本論文ではこの手法をNB法と名付ける．また後者の方法としては論文において提案された拘束無し最小二乗重要度適合法(unconstrainedLeast-SquaresImportanceFitting,uLSIF)を利用する．</section>
  <subsection title="NB 法">対象単語wの用例xの素性リストをf_1,f_2,,f_nとする．求めるのは領域RS,T上のxの分布P_R(x)である．ここでNaiveBayesで使われるモデルを用いる．NaiveBayesのモデルでは以下を仮定する．[P_R(x)=_i=1^nP_R(f_i)]領域Rのコーパス内のwの全ての用例について素性リストを作成しておく．ここで用例の数をN(R)とおく．またN(R)個の用例の中で，素性fが現れた用例数をn(R,f)とおく．MAP推定でスムージングを行い，P_R(f)を以下で定義する．[P_R(f)=n(R,f)+1N(R)+2]以上より，ソース領域Sの用例xに対して，確率密度比w(x)=P_T(x)/P_S(x)が計算できる．[w(x)=P_T(x)P_S(x)=_i=1^n(n(T,f_i)+1N(T)+2N(S)+2n(S,f_i)+1)]</subsection>
  <subsection title="uLSIF">ソース領域内のデータをx_i^s_i=1^N_s，ターゲット領域内のデータをx_i^t_i=1^N_tとするuLSIFでは確率密度比w(x)を以下の式でモデル化する．w(x)&amp;=_l=1^b_l_l(x)&amp;=(x)align*ただしここで，=(_1,_2,,_b)，(x)=(_1(x),_2(x),,_b(x))である．また_lは正の実数であり，_l(x)は基底関数と呼ばれるソース領域のデータxから正の実数値への関数である．uLSIFでは，概略，自然数bと基底関数(x)を定めた後に，パラメータを推定する手順をとる．説明の都合上，bと(x)が定まった後のの推定を先に説明する．w(x)のモデルをw(x)とおくと，パラメータ_lを推定するには，w(x)とw(x)の平均2乗誤差J_0()を最小にするようなを求めれば良い．w(x)=P_T(x)/P_S(x)に注意すると，J_0()は以下のように変形できる．J_0()&amp;=12(w(x)-w(x))^2P_S(x)dx&amp;=12w(x)^2P_S(x)dx	-w(x)w(x)P_S(x)dx	+12w(x)^2P_S(x)dx&amp;=12w(x)^2P_S(x)dx	-w(x)P_T(x)dx+12w(x)^2P_S(x)dxalign*3項目の式は定数なので，J_0()を最小にするには，以下のJ()を最小にすればよい．[J()=12w(x)^2P_S(x)dx-w(x)P_T(x)dx]J()を経験分布で近似したJ()は以下となる．ここでHはbbの行列であり，そのl行l'列の要素H_l,l'は以下である．[H_l,l'=1N_s_i=1^N_s_l(x_i^s)_l'(x_i^s)]またhはb次元のベクトルであり，そのl次元目の要素h_lは以下である．[h_l=1N_t_j=1^N_t_l(x_j^t)]J()の最小値を求める際に正則化を行う．このとき付加する正則化項をL2ノルムに設定し，&gt;0の条件を外して，以下の最小化問題を解く．ここでパラメータが導入されることに注意する．は基底関数を設定する際に決められる．[_[12^TH-h^T+2^T]]この最小化問題は制約のない凸2次計画問題であるために，唯一の大域解が得られる．その解は以下である．最後に&gt;0の条件に合わせるように，以下の調整を行う．パラメータbと基底関数の設定であるが，まず，bについては以下で設定する．[b=(100,N_t)]次にターゲット領域のデータから重複を許さずにb個の点をランダムに取り出す．それらの点をx_j^t_j=1^bとおく．そして基底関数_l(x)を以下のガウシアンカーネルで定義する．[_l(x)=K(x,x_l^t)=(-||x-x_l^t||^2^2)]以上より，確率密度比を求めるために残されているパラメータは正則化項の係数とガウシアンカーネルの幅の2つである．これらのパラメータはグリッドサーチの交差検定で求める．まずソース領域のデータとターゲット領域のデータをそれぞれ交わりのないR個の部分集合に分割する．それらの部分集合の中でr番目の部分集合を除き，残りを結合した集合を作る．それらを新たなソース領域のデータとターゲット領域のデータと見なす．そしてとをある値に設定し，とよりを求め，よりJ()^(r)の値を求める．rを1からRまで変化させることで，R個のJ()^(r)の値が求まり，それらを平均した値をとに対するJ()の値とする．次にとを変化させ，上記手順で得られるJ()の値が最小となるとを求め，これをとの推定値とする．</subsection>
  <section title="実験">BCCWJのPB（書籍），OC（Yahoo!知恵袋）及びPN（新聞）を異なった領域として実験を行う．SemEval-2の日本語WSDタスクではこれら領域のコーパスの一部に語義タグを付けたデータを公開しており，そのデータを利用する．この3つの領域からある程度頻度のある多義語16単語をWSDの対象単語とする．これら単語と辞書上での語義数及び各コーパスでの頻度と語義数をに示す．領域適応の方向としてはOC→PB，PB→PN，PN→OC，OC→PN，PN→PB，PB→OCの計6通りの方向が存在する．本稿で利用した素性は以下の8種類である．(e0)wの表記，(e1)wの品詞，(e2)w_-1の表記，(e3)w_-1の品詞，(e4)w_1の表記，(e5)w_1の品詞，(e6)wの前後3単語までの自立語の表記，(e7)e6の分類語彙表の番号の4桁と5桁．なお対象単語の直前の単語をw_-1，直後の単語をw_1としている．対象単語wについてソース領域Sからターゲット領域Tへの領域適応の実験について説明する．ソース領域Sの訓練データのみを用いて，手法Aにより分類器を学習しwに対する正解率を求める．16種類の各対象単語(w_1,w_2,,w_16)に対する正解率の平均，つまりマクロ平均をソース領域Sからターゲット領域Tに対する手法Aの正解率とする．結果，手法Aについて6種類の各領域適応に対しての正解率が得られる．それらの平均を手法Aの平均正解率とする．上記の手法Aとしては，以下の8種類を試す．(1)重みを考慮しない（重みを1で固定する）手法(Base)，(2)NB法による重みをつけた手法(NB)，(3)NB法の重みをp乗した値を重みにする手法(P-NB)，(4)NB法の重みを相対確率密度比により上方修正した値を重みにする手法(A-NB)，(5)uLSIFによる重みをつけた手法(uLISF)，(6)uLSIFの重みをp乗した値を重みにする手法(P-uLSIF)，(7)uLSIFの重みを相対確率密度比により上方修正した値を重みにする手法(A-uLSIF)，(8)提案手法，またすべての手法において学習アルゴリズムとしては最大エントロピー法を用いた．またその実行にはツールのClassiasを用いた．SからTへの領域適応における各手法の正解率をに示す．ただしP-NB，A-NB，P-uLSIF，A-uLSIFについてはpとのパラメータが存在する．これらの値については，その値を0.01から0.09まで0.01刻み，及び0.1から0.9まで0.1刻みで変化させ，平均正解率が最もよい値を示した値を採用した．結果，P-NBについてはp=0.2，A-NBについては=0.01，P-uLSIFについてはp=0.04，A-uLSIFについては=0.01の値を採用した．が示すように，領域適応のタイプ毎に最適な手法は異なるが，平均正解率としては提案手法が最も高い値を示した．またP-NBとA-NBの平均正解率はNBの平均正解率よりも高く，P-uLSIFとA-uLSIFの平均正解率はuLSIFの平均正解率よりも高い．つまり確率密度比を上方に修正する手法が有効であったことがわかる．また有意差を検定するために以下の実験を行った．まず対象単語毎にOCのデータからランダムに9割のデータ取り出し，それらのデータセットをOC-1とする．これを20回行い，OC-1，OC-2，，OC-20を作成する．同様にPBのデータからPB-1，PB-2，，PB-20を作成する．また同様にPNのデータからPN-1，PN-2，，PN-20を作成する．そしてデータセットの組(OC-i,PB-i,PN-i)を用いて，前述した実験と同様の実験を行い，20個の平均正解率を算出しt-検定（両側検定の有意水準5%）を行った．結果をに示す．における評価値は以下の式により計算されたものである．[X_1-X_2(1n_2+1n_2)n_1S_1^2+n_2S_2^2n_1+n_2-2]ここでX_1とS_1^2が提案手法の20個の平均正解率の平均と分散であり，X_2とS_2^2が比較対象の手法の20個の平均正解率の平均と分散である．n_1とn_2は共にサンプル数20である．この評価値が自由度38のt分布の0.975の分位点2.0244よりも大きい場合に，提案手法が対応する手法に対して有意であると判定される．が示すようにP-NB以外の全ての手法に対して，提案手法が有意に優れていた．</section>
  <section title="考察"/>
  <subsection title="確率密度比を上方修正しないケース">「p乗する」あるいは「相対確率密度比を取る」という手法は，元の確率密度比が1以下である全てのデータに対してその値を上方に修正するが，提案手法は一部のデータに対してはNB法の確率密度比が1以下であっても，それらを上方に修正できない．提案手法により確率密度比の値が大きくならず，逆に小さくなったデータの個数をに示す．ほとんどのデータに対して，その確率密度比を上方に修正しているが，修正できていないデータが極端に多いケースも存在する．例えば，PB→PNに関しては「言う」「自分」「見る」「やる」「ゆく」，OC→PNに関しては「書く」「見る」「やる」「ゆく」である．これらに関してのみBaseとNBと提案手法の正解率の比較をに示す．からわかるように，上方修正ができないデータが多くなると，提案手法はNB法よりも正解率が下がっている．ただし，下方に修正した場合には必ず正解率が下がるとも言えないことに注意したい．例えば，確率密度比の値を下げないようにするには提案手法を修正し，「NB法の値を上方に修正できなければ，NB法の値をそのまま使う」という形にすれば良い．この修正案の手法も試した結果をに示す．修正案の手法の平均正解率は，提案手法よりも若干悪かった．上記の実験はNB法による確率密度比が1以下かどうかは考慮していない．「p乗する」や「相対確率密度比を取る」手法では，確率密度比が1以上の場合に，その値を逆に小さくしている．確率密度比が1以上の場合に，上方修正する方がよいのか下方修正する方がよいのかは未解決である．参考として上記の修正案の手法を更に修正し，「NB法の値が1以上の場合，あるいはNB法の値を上方に修正できな場合にはNB法の値をそのまま使う」という形の実験も行った．結果，平均正解率は72.14と若干改善はされたが，提案手法よりも若干悪いことに変化はなかった．データの確率密度比（重み）はその値の大きさが重要ではなく，他データとの重みとの関係が本質的である．例えば全てのデータの重みを10倍して，値自体を増やしても，推定できるパラメータが変化しないのは，重み付き対数尤度（）の最大化する部分が変化しないことから明らかである．データの重みはタスクの背景知識から，その重要度を設定していくか，そのデータを数値化した後に確率密度比という観点から設定していくしか方法はないと考える．提案手法は後者であり，コーパスのスパース性への対処からNB法を改良した手法と考えている．上方修正することに，どのような意味があるかを調べることは今後の課題である．</subsection>
  <subsection title="提案手法の重みの上方修正">提案手法は，確率密度比を上方修正する手法と組み合わせて利用することで更なる精度改善も可能である．提案手法の確率密度比をp乗した場合の平均正解率の変化をに示す．p=0.6のとき最大値72.54%をとった．また提案手法の確率密度比に対してパラメータの相対確率密度比をとった場合の平均正解率の変化をに示す．=0.6のとき最大値72.30%をとった．ともに確率密度比を上方修正することで平均正解率は改善されている．本論文の以降の記述において，提案手法の重みをp乗した値を重みにする手法を「P-提案手法」，提案手法の重みを相対確率密度比により上方修正した値を重みにする手法を「A-提案手法」と名付ける．ここでp=0.6，=0.6である．また前節で行った有意差の検定を「P-提案手法」と「A-提案手法」に対しても行った．結果，「P-提案手法」はP-NBや提案手法を含む全ての手法に対して有意に優れていた．ただし「A-提案手法」はP-NBや提案手法とに有意な差はなかった．</subsection>
  <subsection title="Misleading データからの評価">本論文で提案した確率密度比（重み）はNB法やuLSIFによる確率密度比よりも，有効に機能していた．ただし真の確率密度比の値は未知であるために，真の値に近いかどうかという観点での評価は不可能である．また重みの設定だけで，どの程度まで平均正解率が向上できるのかも未知である．一方，Misleadingデータを削除してから学習を行うことでかなりの精度向上が可能であることが論文により示されている．Misleadingデータを削除してから学習することは，Misleadingデータの重みを0，それ以外のデータの重みを1とした重み付き学習と見なせる．この重み付けが真の確率密度比と類似しているかどうかは不明だが，Misleadingデータに対してはできるだけ小さな重みを与える手法が優れているとみなせる．そこでここでは各手法においてMisleadingデータに付与された重みを調べることで手法を評価する．まず論文で行ったように，しらみつぶしにMisleadingを見つけ出す．領域Sから領域Tの領域適応において，対象単語wのS上のラベル付きデータDが存在する．まずDで学習した識別器のTに対する正解率p_0を測る．次にDから1つデータxを取り除き，D-xから学習した識別器のTに対する正解率p_1を測る．p_1&gt;p_0となった場合，データxをMisleadingデータと見なす．これをD内のすべてのデータに対して行い，SからTの領域適応における対象単語wのMisleadingデータを見つける．この処理によって見つけ出されたMisleadingデータの個数を示す．括弧内の数値は全データ数である．またMisleadingによる重みを用いた学習の識別結果をに示す．表中のMisleadがそれにあたる．本論文の実験で得られている平均正解率よりもかなり高い．つまり重みの設定のみでもBaseの平均正解率71.71%を少なくとも75.42%まで改善可能である．次に各手法がMisleadingデータに付与した重みにより手法を評価する．領域Sから領域Tの領域適応において，対象単語wのS上のラベル付きデータをD=x_i_i=1^N_wとする．まずD内のデータの重みの平均値m_wを調べる．[m_w=1N_w_i=1^N_ww(x_i)]次にD内のMisleadingデータをx'_j_j=1^M_wとする．各x'_jの重みw(x'_j)がm_wと比較して小さな値であればよいので，対象単語wに関するMisleadingデータを用いた評価値d_wを以下で測る．[d_w=1M_w_j=1^M_ww(x'_j)m_w]d_wは対象単語wの訓練データの重みの平均値m_wに対して，Misleadingデータx'_jの重みw(x'_j)の比を取り，その比の平均を取ったものである．このためd_wの値が小さいほど，適切に重み付けできていると考えられる．そしてd_wの各単語に関して平均を取った値を，その手法におけるSからTのMisleadingデータを用いた評価値（小さいほど良い）とする．これをまとめたものがである．が示すように，Misleadingデータを用いた評価では，NB法，uLSIF及び提案手法の3つの中でuLSIFが最も優れている．ただし提案手法はNB法よりも優れていた．更に全ての手法において「p乗する」，あるいは「相対確率密度比を取る」ことで評価値は改善されており，重みを上方修正する効果があることがわかる．また「p乗する」と「相対確率密度比を取る」を比較すると，「p乗する」方が効果があることもわかる．</subsection>
  <subsection title="負の転移の有無">NB法やuLSIFはBaseよりも平均正解率が低い．これは確率密度比からの重み付き学習が効果がなかったことを示している．この原因として，WSDの領域適応では，領域の変化はあるが，実際には領域適応の問題が生じていない，つまり負の転移が生じていない対象単語がかなり存在するからだと考える．負の転移が生じていなければ，訓練データを全て利用して学習する方が有利であることは明らかであり，重みをつけると逆効果になると考えられる．この点を確認するために，負の転移が生じているものと生じていないものに分けて，各手法の平均正解率を測ってみる．まず負の転移が生じている単語の判定であるが，これはで示したMisleadingデータの個数から行う．ここではMisleadingデータが全データの1割以下の場合，負の転移が生じないと判定した．結果をに示す．チェックが付いているものが「負の転移が生じない」と判定したものである．でチェックがついていない対象単語に限定して，各手法の平均正解率を測った結果がである．また逆にでチェックがついている対象単語に限定して，各手法の平均正解率を測った結果がである．とからわかるように，NB法やuLSIFは負の転移が生じる，生じないに関わらず，Baseよりも平均正解率が低く，本実験においては有効ではなかった．一方，提案手法は負の転移が生じる場合でも，生じない場合でもBaseよりも平均正解率が高く，どちらの場合でも有効であることがわかる．また負の転移が生じる場合，提案手法の平均正解率はNB法の平均正解率の1.09倍であり，uLSIFの平均正解率1.05倍である．一方，負の転移が生じない場合，提案手法の平均正解率はNB法の平均正解率の1.02倍であり，uLSIFの平均正解率1.03倍である．つまり負の転移が生じるケースで提案手法と既存手法（NB法，uLSIF）との差が大きくなる．更に確率密度比を上方修正する効果をみてみる．負の転移が生じる場合，NB法は平均正解率60.69%がp乗することで65.19%，相対確率密度比を取ることで65.35%まで向上しているので，平均的には7.5%平均正解率が向上している．同様に計算してuLSIFの平均正解率は3.6%，提案手法の平均正解率は0.5%向上している．負の転移が生じない場合，NB法は1.4%，uLSIFは2.8%平均正解率が向上している．また提案手法では平均正解率はほとんど変化しない．つまり確率密度比を上方修正する効果は負の転移が生じるケースで顕著になっている．今後の課題としてはMisleadingデータの検出方法を考案することである．Misleadingデータを検出し，そのデータに重みを0にすることはかなりの精度向上が期待できる．またMisleadingデータの割合から負の転移の有無を判定し，負の転移が生じる問題にだけ，重み付け学習手法を適用するアプローチも効果があると考えられる．</subsection>
  <subsection title="トピックモデルの利用">論文は本論文と同じタスクに対して一部同じデータを用いた実験結果を示している．ここではそこでの実験結果の値と本論文の実験結果の値を比較し，手法間の違いを考察する．論文の核となるアイデアは，ターゲット領域Tのトピックモデルを作成し，ターゲット領域に特有のシソーラスを構築することである．このシソーラスの情報を素性として組み込むことで，識別精度を上げることを狙っている．実験はOC→PBとの2方向である．また対象単語は本論文の16単語の他「来る」が含まれている．OC→PBとPB→OCの領域適応における，本論文の対象単語16単語についての識別精度の比較をとに示す．なお表中のSVM-TM-kNNは論文の手法を意味する．対象単語に応じて最も高い正解率の手法は異なるが，平均的にはSVM-TM-kNNが最も高い正解率を示している．ただしSVM-TM-kNNはトピックモデルを構築するために，ターゲット領域のコーパスを利用していることに注意したい．本論文の提案手法はターゲット領域の対象単語の用例を用いているが，コーパスは利用していない．つまり利用しているリソースが異なるために，単純にSVM-TM-kNNが提案手法よりも優れているとは結論できない．またSVM-TM-kNNにおけるトピックモデルは素性構築の際に利用されているだけであり，提案手法と競合するものではない．つまりSVM-TM-kNNの手法を利用して，WSDでの素性を構築し，それに対して本論文の提案手法を適用することも可能である．今後はこの方向での改良も試みたい．</subsection>
  <section title="おわりに">本論文では，WSDの領域適応に対して，共変量シフト下の学習を試みた．共変量シフト下の学習では確率密度比を重みとした重み付き学習を行うが，WSDのタスクでは算出される確率密度比が小さくなる傾向があるため，ソース領域のコーパスとターゲット領域のコーパスとを合わせたコーパスをソース領域のコーパスと見なしてNB法を用いる手法を提案した．BCCWJの3つの領域OC（Yahoo!知恵袋），PB（書籍）及びPN（新聞）に共通して出現する多義語16単語を対象にして，WSDの領域適応の実験を行った．NB法，uLSIF及び提案手法を比較すると，提案手法が最も高い平均正解率を出した．また「p乗する」や「相対確率密度比を取る」といった確率密度比を上方修正する手法も試し，提案手法のように確率密度比を上方修正する効果を確認した．またMisleadingデータをしらみつぶし的に取り出し，Misleadingデータを用いた手法の評価も行った．Misleadingデータを利用した評価ではuLSIFが優れていたが，提案手法はNB法の改良になっていることを確認できた．WSDの領域適応の場合，Misleadingデータの検出あるいは負の転移の有無を判定することが，精度改善に大きく寄与できる．今後はこの点の研究を進めたい．またトピックモデルの利用も検討したい．document</section>
</root>
