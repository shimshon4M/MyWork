<?xml version="1.0" ?>
<root>
  <section title="Introduction">Knowledgeacquisitionfromalargecorpushasbeenactivelystudiedinrecentyears.Fundamentalanalysistechniqueshavebeenappliedtoacorpusandknowledgeisacquiredfromtheanalysis.Inparticular,dependencyparsinghasbeenusedfortaskslikecaseframecompilation,relationextraction,andparaphraseacquisition.Forthesetasks,theaccuracyofdependencyparsingisvital.Althoughtheaccuracyofstate-of-the-artdependencyparsersforsomelanguageslikeEnglishandJapaneseisover90%,itisstillnothighenoughtoacquireaccurateknowledge.Furthermore,ifonetriestoapplythismethodofknowledgeacquisitiontodifficult-to-analyzelanguageslikeChineseandArabic,thequalityoftheresultingknowledgeworsens.Duringthedependencyparsingprocess,evenifaparser'saverageperformanceishigh,certaintypesofdependencyrelationsarejudgedwithhighaccuracybutothertypeswithverylowaccuracy.Inaddition,sometypesofdependencystructuresarerelativelydifficultforanyparsertocorrectlyanalyze.Asaresult,aparserwilltendtoproduceautomaticparsesofvaryinglevelsofquality,dependingonthepropertiesofdependency.Usingfullstructuresofautomaticparsesforsubsequenttasks,suchastheextractionofpredicate-argumentstructures,willinevitablyleadtonoisyresults.Inpractice,however,severaltasksdonotrequirefullparsestructuresbutonlypartialones.Toavoidthepropagationoferrorsfromautomaticanalyses,itispreferabletouseonlyhighqualitydependenciesforknowledgeacquisitionratherthanautomaticparses.Inthisstudy,wepresentasupervisedlanguage-independentapproachforselectinghighqualitydependenciesfromautomaticparses.Thismethodconsiderslinguisticfeaturesthatarerelatedtothelevelofdifficultyinherentindependencyparsing.Weuseasinglesetofdependencylabeleddata,suchasTreebank,partofwhichisusedtotrainadependencyparser.Weconductexperimentsonsevenlanguages,fiveofwhichareIndo--Europeanlanguagesandtwonon-Indo--Europeanlanguages(ChineseandJapanese).Theexperimentalresultsshowthatforallthelanguages,ourproposedmethodcanselecthighqualitydependenciesthanbaselinemethods.Thisstudyisorganizedasfollows.Sectionreviewssomeresearchrelevanttoourapproach.Sectiondescribesthehighqualitydependencyselectionprocess.Sectionpresentsadetaileddescriptionofourresearch,conductedusingthreelanguages,alongwiththeresults.Sectiondescribesseveraladditionalexperimentsconductedusingotherlanguages.Sectionpresentsadiscussionofourresults.Finally,Sectionpresentsaconclusionofourapproachandproposesfuturework.</section>
  <section title="Related Work">Therehavebeenseveralapproachesdevotedtoautomaticselectionofhighqualityparsesordependencies.Accordingtoselectionalgorithms,theycanbecategorizedassupervisedandunsupervisedmethods.Supervisedmethodsprimarilyfocusontheconstructionofamachinelearningclassifierandpredictthereliabilityofparsesordependenciesonthebasisofvarioussyntacticandsemanticfeatures.createdWOODWARD,whichisaWeb-basedsemanticfilteringsystem.Theyfirstmappedtheparsestoalogic-basedrepresentationcalledrelationalconjunction(RC).Thereafter,fourdifferentmethodswereemployedtoanalyzewhetheraconjunctintheRCrepresentationwaslikelytobereasonable.builtabinaryclassifierthatdeterminesthereliabilityofeachparse.Thelinguisticfeaturestheyusedfortheclassification,suchassentencelength,thenumberofunknownwords,andthenumberofcommas,arebasedontheideathatthereliabilityofparsesisdeterminedbythedegreeofsentencedifficulty.Theworkmostrelatedtooursisthatof.Theyproposedaframeworkthatselectshighqualityparsesinthefirststageandthenhighqualitydependenciesfromthoseparses.Incomparisonwiththeirwork,weconsiderthatevensomelowqualitysentencescancontainhighqualitydependencies.Inaddition,wetakeintoaccountothercharacteristicsthatcandirectlyaffecthighqualitydependencyselection,suchascontextinformationandtreefeatures.Amongsupervisedmethods,ensembleapproacheswerealsoproposed.Forexample,ReichartandRappoport(2007)Reichart:2007judgedparsequalityusingaSampleEnsembleParseAssessment(SEPA)algorithm.Theytrainedseveraldifferentparsersbyusingsamplesfromthetrainingdata.Thereafter,thelevelofagreementamongthoseparserswasusedtopredictthequalityoftheparse.AnothersimilarapproachproposedbySagaeandTsujii(2007)Sagae:2007alsoselectedhighqualityparsesbycomputingthelevelofagreementamongdifferentparseroutputs.However,differentfromtheresearchpreviouslymentioned,whichusedseveralconstituencyparserstrainedwithdifferenttrainingdatasets,theyusedasingledatasettotraindifferentdependencyparsingalgorithms.Differentfromtheabovementionedmethods,ourmethodjudgesthereliabilityofeachdependencyproducedbyaparser.Unsupervisedalgorithmsfordetectingreliabledependencyparseshavebeenproposed.Observingthescoreofeachedgeisabasicmethodforjudgingthereliabilityofeachdependency.Yoav2012GoldbergandElhadad(2012)proposedamethodofassigningeachedgeariskscoreastheinverseoftheconfidencescoredefinedbyariskfunction.However,selectingdependenciespurelyonthebasisofsuchscoresisnotsufficientforjudginghighqualitydependencies.Wereachedthissameconclusioninourcomparativeevaluationsofdependencyselectionapproachesondifferentlanguages.ReichartandRappoport(2009)Reichart:2009proposedanunsupervisedmethodforhighqualityparseselection,basedontheideathatsyntacticstructuresfrequentlyproducedbyaparseraremorelikelytobeaccuratethanthoseproducedlessfrequently.TheydevelopedPOS-basedUnsupervisedParseAssessmentAlgorithm(PUPA)tocalculatethestatisticssummarizingthePOStagsequencesofparsesproducedbyanunsupervisedconstituencyparser.proposedULISSE(UnsupervisedLInguiSticallydrivenSelectionofdEpendencyparses),whichisalsoanunsupervisedsystem.DifferentfromPUPA,thismethodaddressedthereliableparseselectiontaskusinganunsupervisedmethodinasupervisedparsingscenario.Ratherthanusingconstituency-relatedfeatures,suchasorderedPOStagsequences,theyuseddependency-motivatedfeatures,suchasparsetreedepthanddependencylinklength.Althoughunsupervisedmethodsmaysolvethedomainadaptionissueanddonotusecostlyannotateddata,theaccuracyofselectedparses,whichislessthan95%,stillneedstobeimprovedforknowledgeacquisitiontasks.</section>
  <section title="High Quality Dependency Selection">Inthissection,wepresentaframeworkforhighlyreliabledependencyselectionfromautomaticparses.Figure1showstheoverviewofourapproach.Weuseapartofatreebankdatasettotrainaparserandanotherparttotrainabinaryclassifierthatjudgesthereliabilityofadependency.Weusesupportvectormachines(SVMs)forthisclassification.</section>
  <subsection title="Training Data for Dependency Selection">Supervisedmethodsalwaysrequiremanuallyannotatedtrainingdatathatareusuallyveryexpensivetoobtain.Owingtolimitedexistingresources,wetrainaclassifierforselectinghighlyreliabledependenciesfromparsingoutputsusingtrainingdatafromthesametreebankthatisusedinthefirststagedependencyparsing.Inparticular,thestandardtrainingsectionofthetreebankisusedtotrainadependencyparserandthenthedevelopmentsectionisusedtoapplydependencyparsingusingthepreviouslytrainedparser.Fromtheoutputparsesofthedevelopmentsection,weacquiredtrainingdatafordependencyselectionbycollectingeachdependency.Wethenjudgethesuccessofeachdependencyaccordingtothegoldstandarddata.Allcorrectdependencieswereusedaspositivetrainingexamplesfordependencyselectionandviceversa.</subsection>
  <subsection title="Dependency Selection">Wejudgethedependencyineachparseandretainonlyhighqualityoutputforknowledgeacquisition.Therearemanyfactorsthataffecttheparsingperformance,suchasdistancebetweendependenciesandcomplexityoftreestructures.Bytakingthesefactorsintoconsideration,wecreatesetsoffeaturesforselectinghighqualitydependencies.Tables1,2,and3presentthedetailsofthesefeatures.</subsection>
  <subsubsection title="Basic Features">Ifthereisacomma,colonorsemi-colonbetweentwowords,theyaremuchlesslikelytohaveadependencyrelationthanthosepairsthatdonotcontainanypunctuation.Itismuchmoredifficultforparserstocorrectlyanalyzedependenciesthatcontainpunctuationthanthosewithoutpunctuation.Weusethemostcommonpunctuationsasfeaturesfordependencyselection.Adependencyrelationbetweenwordsismuchmorelikelywhenargumentsarenearby.Therefore,distancebetweenwordsisalsoanimportantfactorthatreflectsthedifficultyofjudgingdependencyrelations.Yuetal.(2008)usedtheabovementionedfeaturesbutdidnotuseWord_head,Word_mod,orthecontextfeatures,whicharedescribedinthenextsection.</subsubsection>
  <subsubsection title="Context Features ">Inadditiontothesebasicfeatures,weconsidercontextfeaturesthatarethoughttoaffectparsingperformance.Table2liststhesecontextfeatures.Forexample,thetwosentences``theyeatsaladwithafork''and``theyeatsaladwithsauce''containthePP-attachmentambiguityproblem,whichisoneofthemostdifficultproblemsencounteredinparsing.Thetwoprepositionalphrases``withafork''and``withsauce''dependontheverb``eat''andthenoun``sauce,''respectively.However,adependencyparsercanhardlyresolvethesetwocases.Therefore,wetendtojudgethistypeofstructureasunreliable.Consideranothersimilarsentence``theyeatitwithafork.''Becausetheprepositionalphrase``withafork''cannotdependonthepronoun``it''butonlyontheverb``eat,''thiscasecanbeclearlyjudgedasahighlyreliabledependency.Insomemorecomplexcases,itisalsonecessarytoobservealargerspanofcontext.Tolearnsuchlinguisticcharacteristicsautomatically,besidesPOStagsandtheheadandmodifierinadependency,wealsousetheprecedingandfollowingoneandtwowords,respectively,alongwiththePOStagsoftheabovementionedlinguisticcharacteristics.Anotherimportantfactisthatverbphrasesinthedependencytreestructureofaparsearenormallytherootnodeoftheentiredependencytreeortheparentnodeofasubtree.Whenawordpaircontainsaverbphrasebetweenthem,thetwowordsarealwaysondifferentsidesoftheparentnode.Thus,thesekindsofwordpairsnormallyhavenodependencylinkbetweenthem.Forexample,inSVO(subject-verb-object)languagessuchasEnglishandChinese,thesubjectappearsfirst,theverbsecond,andthentheobjectthird.Themostcommonexampleofthisiswhenthesubjectsandobjectslocatedonbothsidesoftheverbarethemodifiersoftheverb.Therefore,argumentpairsthathaveaverbbetweenthemrarelyhaveadependencyrelation.Observingwhetherthereareverbphrasesbetweenhead-modifierpairscanhelpjudgedependencyreliability.</subsubsection>
  <subsubsection title="Tree Features ">Theinputforourhighqualitydependencyselectionmethodisadependencytree.Itisnaturaltousetreefeaturestoidentifydependencyquality.Onthebasisofahead-modifierdependency,weobservemodifiersofamodifier,i.e.,childrennodes,ahead'sparentnode---whicharecalledgrandparentnodes---andchildrennodesofthegrandparentnode,whichwecallunclenodes.</subsubsection>
  <subsubsection title="Edge Score ">Somedependencyparsersoutputthescoreofeachdependency(i.e.,edgeconfidencevalue)duringtheparsingprocess.Ahighscoreindicatesahighpossibilitythatthedependencyiscorrect.However,utilizingthisscoreastheonlyfeatureisnotsufficientforacquiringhighqualitydependencies,especiallyinlowqualityparses.Weconsidertherealvalueofthescoreasanadditionalfeature.</subsubsection>
  <section title="Main Experiments"/>
  <subsection title="Experimental Settings">Wefirstconductedourexperimentonthreelanguages,includingEnglish,Japanese,andChinese,usingthedatafromtheCoNLL-2009sharedtask.Foreachlanguage,weemployedtheMSTparserstrctlrn/MSTParser/MSTParser.html(version0.5.0)asabasedependencyparserandusethetrainingdatatotrainadependencyparsingmodel.KD-Fix(0.05*20)confidencescoreisoneoftheedgescorecalculationmethodsintheMSTparser,whichwasreportedasthebestmethodfortheMSTparsertopredictedgescores.WeusedtheKD-Fixvalueastheedgescoreinallexperiments.Weappliedthedevelopmentdatatothedependencyparsingmodeltoacquirethetrainingdatafordependencyselection.WeusedautomaticPOStagsforthedependencyselectionapproach(automaticsegmentationforJapaneseandChinese).TheMXPOSTtaggerwasusedforEnglishautomaticPOStagging,andforChinese,weemployedMMAtoapplybothsegmentationandPOStagging.WeusedJUMANforJapanesemorphologicalanalysis.Fromthedependencyparseroutput,wecollectedtrainingdataforhighqualitydependencyselection.Allcorrectdependencies,accordingtothegoldstandarddata,weredefinedaspositiveexamplesandviceversa.WeutilizedSVMstocompletethisbinaryclassificationtask,specifically,weemployedSVM-Lightwithalinearkernel.Theoption-jratiowasusedtosolvethepositiveandnegativeimbalanceinthetrainingdatafortheclassifier,whereratiowascalculatedbydividingthenumberofnegativesamplesbythenumberofpositivesamples.InordertocomparetheseresultswiththeworkdonebyYuetal.(2008),wesetthebasicfeatureasabaseline.Theevaluationdataforeachlanguagewasthenusedtoevaluatetheeffectivenessofdependencyselection.</subsection>
  <subsection title="Evaluation Metrics">OnthebasisoftheoutputoftheSVMs,weselecteddependencieswithoutputscoresgreaterthanaspecificthreshold,withahigheroutputscoreindicatingamorereliabledependency.Asaresult,ahighthresholdmeantalowrecall.Thereafter,weevaluatedtheselecteddependenciesbycalculatingthepercentageofcorrecthead-modifierdependencies(excludingpunctuations)accordingtothegoldstandarddata.Precisionandrecallwerecalculatedasfollows.precision=#ofcorrectlyretrieveddependencies#ofdependenciesretrievedrecall=#ofcorrectlyretrieveddependencies#ofcorrectdependenciesingoldstandarddatagather*InautomaticallytaggedandparsedChineseandJapanesedata,thereweresegmentationsthatwereincorrectlyproduced.Thesecasesweretreatedasincorrectinstances.Notethatthemaximumrecallforeachlanguagewasequaltotheprecisionofthebaseparser.</subsection>
  <subsection title="Experimental Results"/>
  <subsubsection title="Effectiveness of Dependency Selection ">Figure2showstheprecision-recallcurvesoftheselecteddependenciesusingSVMs.Differentcriteriawereusedforalllanguages.Thecurveslabeled``basicfeat.''indicatesthatbasicfeatureswereusedforthedependencyselection.``Score''isthemethodthatselectsdependencieswiththeedgescores(MSTparser'sKD-Fix)higherthanthethreshold.NotethatthismethoddoesnotuseSVMs.``Propfeat.''indicatesthatproposedfeatureswereused,inwhichtherealvaluesoftheedgescoreswereusedasafeatureintheclassifier.Wecanseefromtheresultsthatourproposedfeaturesoutperformedtheotherfeaturesetsinmostcases,especiallyforChineseandJapanese.Toinvestigatethefeaturethatismosteffectiveonthedependencyselection,weplotteddifferentprecision-recallcurvesusingdifferentfeaturecombinations(Figure3).Notethat``all''isequaltoourproposedmethodinFigure2,whichusesallfeatures.Wecanseethatallfeaturesworkdifferentlyfordifferentlanguages.Forexample,edgescorescaneffectivelyhelpselecthighqualitydependencyforEnglishbutcontextandtree-basedfeaturesperformbetteronJapanese.Thoselanguageshavedifferentbaseparser'sperformanceanddifferentdependencystyles(e.g.,head-finalforJapanese).WespeculatethatfeaturessuchasdistancebetweenargumentsandcommahaveasignificantinfluenceonJapanesedependencyselection.</subsubsection>
  <subsubsection title="Statistics of Selected Dependencies ">Inthissection,weinvestigatethedistributionofdependenciesinordertodeterminetheprimarytypesselected.ThisinvestigationletsusobservewhetherselecteddependenciesarebiasedtowardscertaintypesofPOS(e.g.,meaninglesspatterns,suchas``DTNN'').Eachdependencytypewasrepresentedbycoarse-grainedPOSpairs(thefirsttwocharactersofthePOSnames).Figures4and5summarizethestatisticsforselecteddependencyPOSpairsusingdifferentmethodsfordifferentlanguages.Ineachfigure,theleftandmiddlegraphsrepresentthedependenciesselectedunderdifferentthresholds(i.e.,50%and20%recall,respectively),andtherightmostgraphsareplottedwithoutthedependencyselection.Foralllanguages,underbothselectionmethods(i.e.,proposedmethodandtheselectionmethodbyedgescore),dependencieswithnounsweredominantacrossalltypes.Forlarge-scaleknowledgeacquisition,however,dependencieswithverbsaremostimportantbecauseverbphrasesalwayscontainmostoftheinformationaboutaspecificevent.Therefore,verbphraseextractioniskeyinrecognizingpredicate-argumentstructuresinknowledgeacquisition.Thepattern``NNVB''alsowasprominent,whichindicatesthatpredicate-argumentdependencieswerestillselectedquitefrequentlyamongthehighqualitydependencies.Selectingdependenciesusingdifferentfeatureswillinevitablyleadtothelossofsomeinformativepatternsalongwiththosethatareconsiderednoisy.Fromtheresults,bothselectionmethodshavesimilartendenciesinselectingvarioustypesofdependencies.Thekeypointhereisthatourproposedmethod,whichuseddifferenttypesoffeatures,stillproducedahighproportionofinformativedependencies.</subsubsection>
  <section title="Additional Experiments"/>
  <subsection title="Experiments on Other Languages">WeappliedadditionalmultilingualexperimentsonCatalan,Czech,Spanish,andGermanusingtheCoNLL-2009sharedtaskdata.TheMSTparseragainwasusedfordependencyparsing.Notethattheselanguagespossessthenon-projectiveproperty,whichindicatescrossingedgesinadependencytree.Theyallowformoreconstructionsthantheprojectiveconstraint.Asaresult,thenon-projectiveoptioninMSTparserwastriggered.Figure6showstheprecision-recallcurvesofdependencyselectionforthesefourlanguages.Wedirectlyusedthe6thcolumnintheCoNLL-2009sharedtaskdataasautomaticPOStags.Foreachlanguage,weexhibitedtheprecisionatvariousrecallvaluesinordertohighlightthequalityofselecteddependenciesunderdifferentselectionthresholds.Table4showstheprecisionofdependenciesselectedbyourmethodunder20%and50%recallforalllanguages.Fromtheresults,wecanseethatthedependencyselectionmethodthatusedourproposedfeaturesoutperformedthemethodthatusedthebasicfeaturesforalllanguages.ForJapanese,Chinese,andCatalan,usingtheproposedfeatureshadagreatereffectonhighqualitydependencyselectionthanotherlanguages,comparedtothemethodonlyusingtheedgescores.</subsection>
  <subsection title="Experiment on Different Domain">Oneofthebiggestproblemsthatmostdata-drivenparsersfaceisthedomainadaptationprobleminthattheiraccuracydecreasessignificantlyowingtothelackofdomain-specificknowledge.Weappliedthedependencyparsingmodeltrainedonsection2tosection21ofthePennTreebank(PTB)totheBrowncorpus,andobtainedanunlabeledattachmentscoreof0.832,whichissignificantlylowerthanthein-domainscoreby7.4%.WeappliedthesamedependencyselectionmodeltrainedonthePTBtrainingsectionstothepBrowncorpus.Figure7showstheprecision-recallcurvesfordependencyselectiononthePTBtestsection(section23)andtheBrowncorpususingdifferentselectingmethods.Similarlytopreviousfigures,``brownbasic''indicatesselectionusingbasicfeatures.``Brownscore''indicatesonlyedgescoreswereusedforclassification.``Brownprop.''and``ptbprop.''representproposedfeatureswereusedfordependencyselectiononbrowncorpusandPTB,respectively.Fromtheresults,wecanseethatourproposedmethodoutperformstheonethatusedbasicfeatures,andalsohasanadvantageoverthemethodthatusededgescoreswithlowrecall.Forexamples,whentherecallwas20%,highqualitydependencieswithaprecisiongreaterthan98%couldbeacquired.Thisshowsthatourmethodworkswellondatafromdifferentdomainsandthatthereisawaytoacquireknowledgefromalargerawcorpusindifferentdomains(e.g.,theWeb).</subsection>
  <subsection title="Experiment using Different Proportions of Training Data">Todeterminetheamountoftrainingdatarequiredtoachieveareasonabledependencyselectionperformance,weuseddifferentproportionsofthePTBdevelopmentsectiontotraindifferentclassifiers.Thereafter,weusedthesametestsettoevaluateeachclassifierusingthesamemetricdescribedinSection4.Notethatthemethodthatusesonlytheedgescoresdoesnotchangewithdifferentdataproportions(i.e.,oneshouldgetsimilarclassificationperformanceusingtheedgescoreasafeatureregardlessofthesizeofthetrainingdataset).Thus,weonlyusedfeaturesincluding``basic'',``context'',and``tree''inthisexperiment.Figure8showstheprecision-recallcurvesofdependencyselectionobtainedusingdifferentsizedtrainingdatasets.Theperformancedecreasesslightlywhenthetrainingdatasetdecreasesinsize.However,aprecisiongreaterthan98%isstillachievablewhentherecallis20%,evenwhenusingonly25%ofthetrainingdata.Fromtheresults,wecanseethattrainingdatasetsofvarioussizescanbeusedtotraineffectiveclassifiers.</subsection>
  <subsection title="Experiment using a Different Parser">AsMSTparserisagraph-baseddependencyparser,wewantedtofurthertestourproposedframeworkondifferenttypesofsyntacticparsers.Therefore,wechoosetheStanfordparser,aprobabilisticcontext-freegrammar(PCFG)parser.AlthoughtheoutputoftheStanfordparsercanbeconvertedintodependencystyle,itisunabletooutputanedgescore.Asaresult,weusedfeaturesincluding``basic'',``context''and``tree''inthisexperiment.WeconductedtheexperimentonEnglishandChinese.WedirectlyusedEnglishrawtextandChinesesegmentedtextbyMMAasinput,andemployedtheStanfordparserforPOStaggingandparsing.Figure~9showstheprecision-recallcurvesforEnglishandChinese.Englishcanachievehighprecisionaround98.5%whentherecallis25%.EventhoughthebaseparserforChineseachievedonly67.5%,wecanstillextractdependencieswithover92%precision.</subsection>
  <subsection title="Using Dependency Selection in Other Tasks">Weappliedourproposeddependencyselectionapproachtopredicate-argumentstructureextractionanddistributionalsimilaritycalculation.First,weappliedthedependencyselectiontoautomaticparsesandusedonlyhighqualityedgestoextractpredicate-argumentstructures.Withacentralfocusonverbsineachdependencytree,weusedonlyverb-dependentargumentsandrepresentedeachargumentbyitssyntacticsurfacecase(i.e.,subject,object,prepositionalphrase,etc.)withsetsofheuristicconversionrules.Distributionalsimilarityisamethodthatdetermineswordsimilarityonthebasisofametricderivedfromthedistributionoftheverbanditsargumentsinalargetextcorpus.ForEnglish,weusedalarge-scaleWebcorpusthatcontained200millionsentences.WeemployedtheWordsim353datasetforevaluation,whichcontainshuman-assignedsimilaritiesbetweeneachwordpair.ForChinese,fivemillionsentencesfromtheChineseGigawordwereusedfordistributionalsimilaritycalculation.Wealsousedamanuallyconstructedgold-standarddatasetcontainingmorethan500wordpairsforChinesewordsimilarityevaluation.Foreachwordpairintheevaluationset,weevaluatedthewordsimilarityusingthedistributionalthesauricalculatedusingtheacquiredpredicate-argumentpairs.Weusedspearman'scorrelationcoefficient,calculatedbycomparingtheranksbetweenthetwosetsofsimilarities(i.e.,goldsimilarities,andautomaticallycalculatedsimilarities),toevaluatethequalityofthethesauri.Datasizeisanimportantfactorthatcanaffectdistributionalsimilaritycalculations.Therefore,tocomparethethesauricalculatedfrompredicate-argumentpairsofvarioussizes,werandomlysampleddifferentsizedsetsofpredicate-argumentpairs.Figure10showstheSpearmancoefficientvaluesforthedistributionalsimilaritycalculationsunderthethreecriteriamentionedabove.Aswecansee,performanceofdistributionalsimilaritycalculationscanbeimprovedbyselectinghighqualitydependencies,forbothChineseandEnglish.Usingthedependencyselectionprocess,thenegativeeffectsthatthenoisydatacanhaveonsemanticrepresentationofwordsimilaritycanbeeffectivelyreduced.Theresultshowsthatthequalityofdependenciesanddatasizearebothimportantfactorsfordistributionalsimilaritycalculation.</subsection>
  <section title="Discussion">Weachieveddependencyprecisionsof99.6%,97.8%,and98.8%forEnglish,Chinese,andJapanese,respectively,usingautomaticallytaggeddatawitharecallof20%.AllfourEuropeanlanguageshavearound99.5%precisionunderthisrecall.OurproposedfeaturesshowasignificantadvantageovertheoriginalfeaturesetproposedinthepreviousstudyofYuetal.(2008).Bytakingintoaccountcontextandtreeinformation,wecaneffectivelyhelpthesystemlearnautomaticdependencyparsereliabilitynotonlyfromthesamedomainbutalsofromotherdomains.Asshownintheexperiments,theresultsarequitepromisingfordifferenttypesofsyntacticparsers,aswell.Thestatisticscalculatedforselecteddependenciesshowedthatevenwhenweadoptedalowrecallvaluetoobtainahighprecisiontheycontainedmanydependenciesrelatedtonounsandverbs.Thelowrecall(e.g.,20%)canbecompensatedforbyusingverylargerawcorpora,whicharerelativelyeasytoacquire.Theapplicabilitytodifferentdomainsalsoallowsustoacquireknowledgefromlargerawcorporaofvariousdomains.Moreover,ourproposedapproachcanbenefitsubsequentNLPtasks,suchasdistributionalsimilaritycalculation.Eachfeaturetypehadadifferentinfluenceondifferentlanguages.Forexample,EnglishandChineseperformedsimilarlywhenusingedgescoresvs.proposedfeatures.However,Japaneseshowedbetterperformanceusingourproposedfeatures.WespeculatethatfeaturessuchasthedistancebetweenargumentsandcommashadasignificantinfluenceonJapanesedependencyselection.Eventhoughselectionusingedgescorescanhelpacquirehighqualitydependencies,whichsometimeshavesimilarperformancetoourproposedfeatures,itisveryimportanttonotethatedgescoresarenotalwaysavailablefordifferenttypesofparsers(e.g.,Stanfordparser).Furthermore,producingedgescores(e.g.,KD-FixofMSTparser)demandsalargeramountofcomputermemory,whichnormallymakesitimpracticaltoapplyparallelanalysestolarge-scalecorporainpractice.</section>
  <section title="Conclusion and Future Work">Inthisstudy,weproposedaclassificationapproachforhighqualitydependencyselection.Wecreatedasetoffeaturesthatconsidercontextandtreeinformationinselectinghighlyreliabledependenciesfromparsedsentences.Thisapproachcanextracthighqualitydependenciesevenfromlowqualityparses.Theexperimentsshowedthatourmethodworksforin-domainparsesaswellasout-of-domainparses.WecanextracthighqualitydependenciesfromalargecorpussuchastheWeb,andcansubsequentlyassistknowledgeacquisitiontasks,suchassubcategorizationframeacquisitionandcaseframecompilation,whichdependhighlyontheparsequality.Sinceautomaticparsescanbeusedtoimprovethebaseparseritself,weplantouseabootstrappingstrategytoimprovedependencyparsersbasedonhighqualityknowledgeacquiredfromlargecorpora.document</section>
</root>
