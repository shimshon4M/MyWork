<?xml version="1.0" ?>
<root>
  <subsection title="Parameter ">Weinvestigatedtheinfluenceofthethreshold(Figure,,and).Figuresandillustratethenumberofword-alignedtransliterationpairsandtheircoveragefordifferentvaluesof.Thesefiguresindicatethatasufficientnumberoftransliterationpairscanbeextractedwhenissufficientlysmall,andconsequentlythefeaturesarefiredinmanyexamples.FigurerepresentstherelationbetweenandF_1-score.ComparingFigurewithFiguresand,wecanconfirmthattheincreaseinthenumberoftransliterationpairsandthecoverageresultsinhigherF_1-score.WhiletheF_1-scoredropswhenthevalueofistoolarge(e.g.,-20),theF_1-scoreisotherwisealmostconstant.Thisdemonstratesthataccuracyofourmethodisnotsensitivetothevalueofanditisgenerallyeasytosetneartheoptimalvalue.Moreimportantly,theF_1-scoreisconsistentlyhigherthanBasicirrespectiveofthevalueof.Wecanconcludethatthechangeintheparametervaluehaslittleinfluenceontheaccuracyoftheproposedmethod.</subsection>
  <section title="Introduction"/>
  <subsection title="Japanese katakana words and noun compound splitting">BorrowingisamajorsourceofwordformationinJapanese,andnumerousforeignwords(propernamesandneologisms)arecontinuouslybeingimportedfromotherlanguages.MostborrowedwordsinmodernJapanesearetransliterationsfromEnglish,andtheyarereferredtoaskatakanawordsbecausetransliteratedforeignwordsareprimarilyspelledusingkatakanacharactersintheJapanesewritingsystem.CompoundingisanothersourceofwordformationcommoninJapanese.Inparticular,nouncompoundsarefrequentlyproducedbymergingtwoormorenouns.Thesetwotypesofwordformationyieldasignificantamountofkatakananouncompounds,makingJapaneseahighlyproductivelanguage.InJapaneseaswellassomeEuropeanandAsianlanguages(e.g.,German,Dutch,and),theconstituentwordsofcompoundsarenotseparatedbywhitespaces,unlikethoseofEnglish.Insuchlanguages,itisbeneficialforvariousNLPapplicationstobeabletosplitsuchcompounds.Forexample,compoundsplittingenablesSMTsystemstotranslateacompoundonaword-by-wordbasis,evenifthecompounditselfisnotfoundinthetranslationtable.InthecontextofIR,decompoundinghasananalogouseffecttostemming,anditsignificantlyimprovesretrievalresults.Inabbreviationrecognition,thedefinitionofanabbreviationisoftenintheformofanouncompound,andmostabbreviationrecognitionalgorithmsassumethatthedefinitionisproperlysegmented;seee.g.,.ThishasledNLPresearcherstoexploremethodsforsplittingcompounds,especiallynouncompounds,invariouslanguages.Whilemanymethodshavebeenpresented,theybasicallyrequireexpensivelinguisticresourcestoachievesufficientlyhighaccuracy.Forexample,employedaworddictionary.Otherstudieshavesuggestedusingbilingualresourcessuchasparallelcorpora.TheideabehindthesemethodsisthatcompoundsarebasicallysplitintoconstituentwordswhentheyaretranslatedintoEnglish,andhencesplittingrulescanbelearnedbydiscoveringwordalignmentsinbilingualresources.Thelargestreasonforthedifficultyofcompoundsplittingistheexistencewordsnotfoundintheabovementionedlinguisticresources.InthecaseofJapanese,itisknownthatkatakanawordsconstitutealargesourceofout-of-vocabularywords.Asalready-mentioned,katakanawordsarehighlyproductive,andthuswecannolongerexpectexistinglinguisticresourcestohavesufficientcoverage.Accordingto,almost20%ofkatakanawordsareoutofvocabularyinnewsarticles.Thesekatakanawordsareoftennouncompounds,andposeconsiderabledifficultyforJapanesetextprocessing.Examplesofkatakananouncompoundsthataredifficulttosplitincludethefollowig:“モンスターペアレント(monsterparent)”-0.5zw.Althoughitmightseemeasytosplititinto“モンスター(monster)”and“ペアレント(parent),”itishardforexistentwordsegmentersbecausethekatakanaword“ペアレント(parent)”isnotregisteredindictionaries.Infact,wefoundthatMeCabver.~0.98usingNAIST-jdicver.~0.6.0failstosplitit.</subsection>
  <subsection title="Paraphrases as implicit word boundaries">Toalleviatetheerrorscausedbyout-of-vocabularywords,weexploredtheuseofunlabeledtextualdataforsplittingkatakananouncompounds.Sincethebodyoftheavailableunlabeledtextgenerallycontainsconsiderablymoredatathanworddictionariesandotherexpensivelinguisticresources,wethinkitiscrucialtoestablishamethodologythattakesfulladvantageofsucheasilyavailabletextualdata.Whileseveralapproacheshavealreadybeenproposed,theirlevelsofaccuracyarestillunsatisfactory(seeSection).Fromabroadperspective,ourapproachcanbeseenasusingparaphrasesofnouncompounds.AswewillseeinSectionsand,katakananouncompoundscanbeparaphrasedintovariousformsthatstronglyindicatewordboundarieswithintheoriginalnouncompound.Thispaperempiricallydemonstratesthatsplittingaccuracycanbesignificantlyimprovedbyextractingsuchparaphrasesfromunlabeledtext,theWebinourcase,andthenusingthatinformationtoconstructsplittingmodels.Specifically,twotypesofparaphrasesareinvestigatedinthispaper.Sectionexploresmonolingualparaphrasesthatcanbegeneratedbyinsertingcertainlinguisticmarkersbetweenconstituentwordsofkatakananouncompounds.Section,inturn,exploresbilingualparaphrases(specifically,back-transliteration).Sincekatakanawordsarebasicallytransliterationsfromback-transliteratingkatakananouncompoundsisalsousefulforsplitting.Toavoidterminologicalconfusion,monolingualparaphraseswillsimplybereferredtoasparaphrasesandbilingualparaphrasesasback-transliterationsintherestofthisarticle.Weperformedexperimentstoevaluateourmethodempirically.Theresultsdemonstratedthatbothparaphrasingandback-transliterationsubstantiallyimprovedperformanceintermsofF_1-score,andthebestperformancewasachievedwhentheywerecombined.Wealsoconfirmedthatourmethodconsiderablyoutperformspreviouslyproposedsplittingmethods.Alltheseresultsstronglysuggesttheeffectivenessofparaphrasingandback-transliterationforidentifyingwordboundarieswithinkatakananouncompounds.Thispaperisorganizedasfollows.Sectionprovidesanoverviewofpreviousstudiesonnouncompoundsplittingandrelatedareas.Sectionpresentsoursupervisedmethodofsplittingkatakananouncompounds.Sectionandexplainhowtomakeuseofparaphrasingandback-transliterationasfeatures.Sectionprovidesexperimentalresultsanddiscussesthem.WepresentourconclusioninSection.</subsection>
  <section title="Related Work"/>
  <subsection title="Compound splitting">Acommonapproachtosplittingcompoundswithoutexpensivelinguisticresourcesisanunsupervisedmethodbasedonwordandstringfrequenciesestimatedfromunlabeledtext.Nakazawaetal.Nakazawa05alsoinvestigatedmethodsofsplittingkatakananouncompounds.Althoughthefrequency-basedmethodgenerallyachieveshighrecall,itslevelofprecisionisnotsatisfactory.Ourexperimentsempiricallycomparedourmethodwithfrequency-basedmethods,andtheresultsdemonstratedtheadvantagesofourmethod.Ourapproachcanbeseenasaugmentingdiscriminativemodelsofcompoundsplittingwithlargeexternallinguisticresources,i.e.,textualdataontheWeb.Inasimilarspirit,Alfonsecaetal.@AlfonsecaCICLing08proposedusingquerylogsforcompoundsplitting.However,theirexperimentalresultsdidnotclearlydemonstratetheirmethod'seffectiveness.Withoutthequerylogs,accuracywasreportedtodroponlyslightlyfrom90.55%to90.45%.Incontrast,ourexperimentalresultsshowedstatisticallysignificantimprovementsasaresultofusingadditionalresources.Moreover,unlikequerylogs,thetextualdatausedinourmethodiseasilyavailable.HolzandBiemannHolz08proposedamethodforsplittingandparaphrasingGermancompounds.Whiletheirstudyisrelatedtoours,theiralgorithmisapipelinemodel,andtheresultsofparaphrasingarenotemployedduringsplitting.</subsection>
  <subsection title="Other research topics">Ourstudyiscloselyrelatedtowordsegmentation,whichisanimportantresearchtopicinAsianlanguagesincludingJapanese.Althoughwecanuseexistingwordsegmentationsystemstosplitkatakananouncompounds,itisdifficulttoachievethedesiredlevelofaccuracy,aswillbeempiricallydemonstratedinSection.Onereasonforthisisthatkatakananouncompoundsoftenincludeout-of-vocabularywords,whicharedifficultforexistingsegmentationsystemstodealwith.Seefordiscussionofthispoint.Fromawordsegmentationperspective,ourtaskcanbeseenasacasestudyfocusingonacertainlinguisticphenomenonofparticulardifficulty.Moreimportantly,weareunawareofanyattemptstouseparaphraingortransliterationforwordsegmentationinthesamemanner.Ourmethodofusingback-transliterationforsplittingkatakananouncompounds(Section)iscloselyrelatedtomethodsforminingtransliterationfromWebtext.Thegreatestfactordifferentiatingthesestudiesfromoursisthattheirprimarygoalwastobuildamachinetransliterationsystemortobuildabilingualdictionary;noneofthemexploredsplittingcompounds.</subsection>
  <section title="A Supervised Approach">Thetaskweexamineinthispaperissplittingakatakananouncompoundxintoitsconstituentwords,=(y_1,y_2y_||).Notethattheoutputcanbeasingleword,i.e.,||=1.Sinceitispossiblefortheinputtobeanout-of-vocabularyword,itisnotatalltrivialtoidentifythesinglewordassuch.Anaivemethodwoulderroneouslysplitanout-of-vocabularywordintomultipleconstituentwords.SincekatakanawordsaremostlytransliterationsfromEnglish,aswediscussedinSection,weassumethattheinputxinthefollowingdiscussionisatransliterationfromEnglish.Althoughitisdifficulttoverifythisassumption,analyzedqueriessubmittedtoaWebsearchengineandfoundthat87%ofthequeriesspelledbykatakanaweretransliterationsfromEnglish.Fromthisdata,wecanexpectthatourassumptionholdstosomeextentinrealtextualdata.Weformalizeourtaskasastructurepredictionproblemthat,givenakatakananouncompoundx,predictsthemostprobablesplitting^*.[^*=_Y(x)(),]whereY(x)representsthesetofallsplittingoptionsofx,()isafeaturevectorrepresentationof,andisaweightvectortobeestimatedfromlabeleddata.Tablesummarizesourfeatureset.Features1and2areword1-gramand2-gramfeatures,respectively.Feature3representsthelengthoftheconstituentword.Len(y)returnsthenumberofcharactersofy(1,2,3,4,or5).Feature4indicateswhethertheconstituentwordisregisteredinanexternaldictionary.(y)returnstrueifthewordyisinthedictionary.Inadditiontothesebasicfeatures,wealsoemployparaphrasingandback-transliterationofkatakananouncompoundsasfeatures,whicharedetailedinSectionsand,respectively.Weoptimizetheweightvectorusinganarbitrarytrainingalgorithm.Here,weadopttheaveragedperceptronalgorithmforthesakeoftimeefficiency.TheperceptronoffersefficientonlinetrainingandperformscomparativelywellwithbatchalgorithmssuchasSVMs.Sinceweuseonlyfactoredfeatures(seeTable,Sectionsand),dynamicprogrammingcanbeusedtolocate^*.</section>
  <section title="Paraphrase Features">Inthissection,wearguethatparaphrasingofkatakananouncompoundsprovidesusefulinformationonthewordboundaries.Consequently,weproposeusingparaphrasefrequenciesasfeaturesfortrainingthediscriminativemodel(template5inTable).</section>
  <subsection title="Paraphrasing of noun compounds">Akatakananouncompoundcanbeparaphrasedintovariousforms,someofwhichprovideinformationonthewordboundarieswithintheoriginalcompound.アンチョビパスタanchovypastaex:anchovyアンチョビ・パスタanchovypasta[3pt]アンチョビのwithanchovyパスタpastalingexampleexamplesareparaphrasesofeachother.(a)isintheformofanouncompoundwhoseinternalwordboundaryisambiguous.In(b),ontheotherhand,acentereddot“・”isinsertedbetweentheconstituentwords.IntheJapanesewritingsystem,thecentereddotissometimes,thoughnotalways,usedtoseparatelongkatakanacompoundsforthesakeofreadability.(c)isthenounphrasegeneratedfrom(a)byinsertingthepossessivemarker“の”-0.5zw,whichcanbetranslatedaswithinthiscontext,betweentheconstituentwords.Ifweobserveparaphrasesof(a)suchas(b)and(c),wecanguessthatawordboundaryexistsbetween“アンチョビ(anchovy)”and“パスタ(pasta)”-0.5zw.</subsection>
  <subsection title="Paraphrasing rules">TheprecedingdiscussionledustouseparaphrasefrequenciesestimatedfromWebtextforsplittingkatakananouncompounds.Forthispurpose,weestablishedthesevenparaphrasingrulesillustratedinTable.TherulestaketheformofX_1X_2_1MX_2,whereX_1andX_2representnouns,andMisacertainlinguisticmarker(e.g.,thepossessivemarker“の”-0.5zw).Theleft-handtermcorrespondstoacompoundtobeparaphrased,andtheright-handtermrepresentsitsparaphrase.Forinstance,X_1=“アンチョビ(anchovy)”-0.5zw,X_2=“パスタ(pasta)”-0.5zw,andM=“の”-0.5zw.Theparaphrasingrulesweusearebasedontherulesproposedbyforexpandingcomplexterms,primarilynouncompounds,intotheirvariants.</subsection>
  <subsection title="Web-based frequency as a feature">WeintroducedanewfeatureusingtheparaphrasingrulesandWebtext.Forpreprocessing,weusedregularexpressionstocountthefrequenciesofallpotentialparaphrasesofkatakananouncompounds.where(katakana)correspondstoonekatakanacharacterand+isagreedyquantifier.Theseregularexpressionscanbeusedtocountpotentialparaphraseswithoutperformingwordsegmentation,becausethetargetisrestrictedtokatakananouncompounds.Textsthatmatchtheaboveregularexpressionsarealwayssurroundedbynon-katakanacharacters(e.g.,hiraganaandkanji).Becausesuchachangeincharactertypestronglyindicatesthepresenceofwordboundaries,oursimpleapproachcansuccessfullycountthefrequencyofthepotentialparaphrases.Givenacandidatesegmentationattesttime,wegenerateparaphrasesofthenouncompoundbysettingX_1=y_i-1andX_2=y_iandapplyingtheparaphrasingrules.Wethenuse(F+1),whereFisthesumoftheWeb-basedfrequenciesofthegeneratedparaphrases,asthefeatureoftheboundarybetweeny_i-1andy_i.OnemaythinkthissimplisticapproachcansacrificeaccuracybecauseitispossiblethatthefeaturesarefiredevenifX_1andX_2arereplacedbynounsequencesandmorphemes,whicharesmallerunitsthannouns.However,ourempiricalexperimentsdemonstratedthatthissimplemethodworkssufficientlywellinpractice.Therefore,inthispaper,weproposesuchanapproachforthesakeofsimplicity.Thereasonthatweuselogarithmicfrequency,ratherthanrawfrequency,isforscalingofthefeaturevalue.Sincetheotherfeatureshavebinaryvaluees,wefoundininitialexperiments,thattheimportanceofthisfeatureisoveremphasizedifweuserawfrequency.Notethatweuse(F+1)ratherthanFtoavoidthefeaturevaluebeingzerowhenF=1.</subsection>
  <section title="Back-transliteration Features">MostkatakanawordsaretransliterationsfromEnglish,wherewordsareseparatedbywhitespaces.Itis,therefore,reasonabletothinkthatback-transliteratingkatakananouncompoundsintoEnglishwouldprovideinformationonwordboundaries,similartoparaphrasing.Thissectionpresentsamethodforextractingback-transliterationsofkatakanawordsfrommonolingualWebtext,andestablishingwordalignmentsbetweenthesekatakanaandEnglishwords(Table):thepairofkatakanawordsanditsEnglishback-transliterationsarereferredtoasatransliterationpair.Whenthetransliterationpairisannotatedwithwordalignmentinformation,asseeninTable,itisreferredtoasa-alignedtransliterationpair.Usingword-alignedtransliterationpairsextractedfromtheWebtext,wederiveabinaryfeatureindicatingwhetherkatakanawordy_icorrespondstoasingleEnglishword.Additionally,wederiveanotherfeatureindicatingwhetherakatakanaword2-gramy_i-1y_icorrespondstoanEnglishword2-gram(template6and7inTable).</section>
  <subsection title="Parenthetical expressions">InJapanese,transliteratedwordsaresometimesfollowedbytheirEnglishback-transliterationsinparentheses:アメリカで|ジャンクフード(junkfood)と言えば...ex:junkトラックバック|スパム(spam)を撃退するため...lingexampletheunderlineindicatestheJapanesetextthatisfollowedbyitsEnglishback-transliteration.Weextractword-alignedtransliterationpairsfromsuchparentheticalexpressionsbyestablishingcorrespondencesbetweenpre-parenthesesandin-parentheseswords.Toaccomplishthis,wehavetoresolvethreeproblems:</subsection>
  <subsection title="Exploiting phonetic similarity">Althoughseveralstudieshaveexploredminingtransliterationsfromsuchparentheticalexpressions,thethirdproblemhasnotbeengivenmuchattention.Inpreviousstudies,thepre-parenthesestextistypicallyassumedtobecorrectlysegmentedbyuseofexistentwordsegmentationsystems.Thisis,however,notappropriatewhenthepre-parenthesistextisakatakananouncompound,whichisdifficultforexistingsystemstohandle,andhencecauseserrors.Tohandletheseproblems,weproposeusingthephoneticpropertiesofthetransliterations.Forthepurposeofexplanation,weshallfirstfocusonProblemC.SincetransliteratedkatakanawordspreservethepronunciationoftheoriginalEnglishwordstosomeextent,wecandiscoverthecorrespondencebetweensubstringsofthetwolanguagesbasedonphoneticsimilarity:[ジャン]_1[ク]_2[フー]_3[ド]_4ex:junk2[jun]_1[k]_2[foo]_3[d]_4lingexamplethatthesearethepre-parenthesisandparentheticaltextin(a).Thesubstringsaresurroundedbysquarebracketswiththesamenumberwhichcorrespondtoeachother.Givensuchacorrespondence,wecansegmentthepre-parenthesistext(a)accordingtoitsEnglishcounterpart(b),whosewordsareseparatedbywhitespace.Wecanrecognizethatthekatakanastring“ジャンク,”whichistheconcatenationofthefirsttwosubstringsin(a),formsasinglewordbecauseitcorrespondstotheEnglishwordjunk,andsoon.Consequently,(a)canbesegmentedintotwowords,“ジャンク(junk)”and“フード(food).”Thewordalignmentistriviallyestablished.ForProblemAandB,wecanalsousethephoneticsimilaritybetweenpre-parenthesisandin-parenthesistext.Iftheparentheticalexpressiondoesnotprovidethetransliteration,oriftheleftboundaryiserroneouslyidentified,wecanexpectthephoneticsimilaritytobecomesmall.Thus,suchsituationscanbeidentified.</subsection>
  <subsection title="A phonetic similarity model">ToestablishsubstringalignmentbetweenkatakanaandLatinalphabetstrings,weusetheprobabilisticmodelproposedby.Letfandebethekatakanaandalphabetstrings,andAbethesubstringalignmentbetweenthem.Moreprecisely,Aisasetofcorrespondingsubstringpairs(f_i,e_i)suchthatf=f_1f_2f_|A|ande=e_1e_2e_|A|.Theprobabilityofsuchalignmentisdefinedas[p(f,e,A)=_(f_i,e_i)Ap(f_i,e_i)]SinceAisusuallyunobservable,itistreatedasahiddenvariable.Tableillustratesanexampleofthesubstringalignmentbetweenf=“ジャンクフード”ande=``junkfood,''andthelikelihoodofeachsubstringpairestimatedinourexperiment.Themodelparametersareestimatedfromasetoftransliterationpairs(f,e)usingtheEMalgorithm.IntheE-step,weestimatep(A|f,e)basedonthecurrentparameters.Intheparameterestimation,werestrictbothf_iande_itobeatmostthreecharacterslong.ThisnotonlymakestheE-stepcomputationallyefficientbutalsoavoidsover-fittingbypreventingverylongsubstringsfrombeingaligned.IntheM-step,theparameterisre-estimatedusingtheresultoftheE-step.Wecanaccomplishthisbyusinganextensionoftheforward-backwardalgorithm.Seefordetails.Givenanewtransliterationpair(f,e),wecandeterminethesubstringalignmentas[A^*=_Ap(f,e,A).]Infindingthesubstringalignment,awhitespaceontheEnglishsideisusedasaconstraint,sothattheEnglishsubstringe_idoesnotspanawhitespace.</subsection>
  <subsection title="Extracting word-aligned transliteration pairs">Theword-alignedtransliterationpairsareextractedusingthephoneticsimilaritymodelasfollows.thatitispossibleinstep2formorethanoneback-transliterationetobefoundforasinglekatakanastringfbecauseofspellingvariationsanderrors.Insuchacase,weusethepair(f,e)withthehighestscore.</subsection>
  <section title="Experiments and Discussion">Weconductedexperimentstoinvestigatehowtheuseofparaphrasingandback-transliterationimprovestheperformanceofthediscriminativemodel.</section>
  <subsection title="Experimental setting">Totrainthephoneticsimilaritymodel,weusedasetoftransliterationpairsextractedfromtheWikipedia.SincepersonnamesarealmostalwaystransliteratedwhentheyareimportedfromEnglishtoJapanese,wemadeuseoftheWikipediaarticlesintheLivingpeoplecategory.Fromthetitlesofthesearticles,weautomaticallyextractedpersonnameswritteninkatakanaalongwiththeirEnglishcounterpartsobtainableviathemultilinguallinksprovidedbyWikipedia.Thisyielded17,509transliterationpairsfortraining.InperformingtheEMalgorithm,wetried10differentinitialparametersandselectedthemodelthatachievedthehighestlikelihood.ThedatafortrainingandtestingtheperceptronwasbuiltusingtheJapanese-EnglishdictionaryEDICT.jwb/edict_doc.htmlWerandomlyextracted5,286entrieswritteninkatakanafromEDICTandmanuallyannotatedwordboundariesbyestablishingwordcorrespondencestotheirEnglishtransliterations.SinceEnglishtransliterationsarealreadyprovidedbyEDICT,theannotationcanbetriviallyprovidedbyanativespeakerofJapanese.Theresultingdatacontained3,041,2,081,and164exampleswhichrespectivelyconstituteofsingleword,twowordsandmorethantwowords.Theaveragenumberofcharactersandconstituentwordsperexamplewas6.60and1.46,respectively.Usingthisdataset,weperformedtwo-foldcross-validationfortestingtheperceptron.Thenumberofiterationswassetto20forallexperiments.AsWebcorpora,weused1.7~Gsentencesfromblogarticles.Fromthecorpora,weextracted14,966,205(potential)paraphrasesofkatakananouncompoundstogetherwiththeirfrequencies(Table).Wealsoextracted151,195word-alignedtransliterationpairs(Table).Thus,werangedthethresholdin-10,-20,-150andchosethevaluewithethebestperformance(=-80).</subsection>
  <subsection title="Baseline systems">Wecomparedoursystemwiththreefrequency-basedbaselinesystems,twosupervisedbaselines,andthreestate-of-the-artwordsegmenters.Thefirstfrequency-basedbaseline,Unigram,performscompoundsplittingbasedonaword1-gramlanguagemodel:[^*=_Y(x)_ip(y_i),]wherep(y_i)representstheprobabilityofy_i.Thesecondfrequency-basedbaseline,Gmf,outputsthesplittingoptionwiththehighestgeometricmeanfrequencyoftheconstituentwords:[^*=_Y(x)()=_Y(x)_if(y_i)^1/||,]wheref(y_i)representsthefrequencyofy_i.Thethirdfrequency-basedbaseline,Gmf2,isamodificationofGmfproposedbyNakazawaetal.Nakazawa05.ItisbasedonthefollowingscoreinsteadofGMF():[()=()&amp;(||=1)[10pt]()CN^l+&amp;(||2),cases]whereC,N,andarehyperparametersandlistheaveragelengthoftheconstituentwords.Following,thehyperparametersweresetasC=2,500,N=4,and=0.7.Weestimatedp(y)andf(y)fromtheWebcorpora.Thefirstsupervisedbaseline,AP,istheaveragedperceptronmodeltrainedusingonlythebasicfeatureset(templates1--4inTable).Thesecondsupervisedbaseline,AP+Gmf2isacombinationofAPandGmf2,whichperformedthebestamongstthefrequency-basedbaselines.Following,2isintegratedintoAPastwobinaryfeaturesindicatingwhetherGMF2()islargerthananyothercandidate,andwhetherGMF2()islargerthanthenon-splitcandidate.AlthoughAlfonsecaetal.AlfonsecaCICLing08alsoproposedusing(thelogof)thegeometricmeanfrequencyasafeature,thisdegradedtheperformance.Forwordsegmenters,weusedJumanver.~6.0,Mecabver.~0.98,andKyteaver.~0.3.1.Thesebaselineswerechosentoshowhowwellexistingwordsegmentationsystemsperformthistask.Althoughtheliteraturestatesthatitisdifficultforexistingsystemstohandlekatakananouncompounds,noempiricaldataonthisissuehasbeenpresentedsofar.</subsection>
  <subsection title="Comparison with baseline systems">Tablecomparestheperformanceofoursystem(Proposed)withthebaselinesystems.Firstofall,wecanseethatProposedclearlyimprovedtheperformanceofAP,demon-stratingtheeffectivenessofusingparaphrasingandback-transliterations.WefoundthatthehigheraccuracyofProposedincomparisonwiththebaselinesisstatisticallysignificant(p&lt;0.01,McNemar'stest).Oursystemalsooutperformedallfrequency-basedbaselines(,Gmf,andGmf2).Thisisnotsurprising,sincethesimplesupervisedbaseline,AP,alreadyoutperformedthefrequency-basedones.IndeedsimilarexperimentalresultswerealsoreportedbyAlfonsecaAlfonsecaACL08.AninterestingobservationhereisthecomparisonbetweenProposedandAP+Gmf2.ItrevealsthatourapproachimprovedtheperformanceofAPmorethanthefrequency-basedmethod.Theseresultsindicatethatparaphrasingandback-transliterationaremoreinformativecuesthanthesimplefrequencyofconstituentwords.Theperformanceofthethreewordsegmentationbaselines(Juman,Mecab,andKyTea)issignificantlyworseinourtaskthaninthestandardwordsegmentationtask,wherenearly99%precisionandrecallarereported.Thisdemonstratesthatsplittingakatakananouncompoundisnotatrivialtasktoresolve,evenforthestate-of-the-artwordsegmentationsystems.Ontheotherhand,outperformedthethreesystemsinthistask,thatis,ourtechniquecansuccessfullyovercometheweaknessesofexistingwordsegmentationsystems.TableillustratesexampleoutputsofMeCabandProposed.Inthefirstexample,thekatakanaword“ディクショナリー(dictionary)”wasnotregisteredinNAIST-jdic,andMeCabfailedtohandleit.Ontheotherhand,Proposedlearnedthefollowingword-alignedtransliterationpairsandsuccessfullysplitit.thenextexample,MeCabfailedtosplit“メインタイトル(maintitle)”althoughboth“メイン(main)”and“タイトル(title)”appearinNAIST-jdic.ThiserrorisprobablycausedbyOOVwordprocessingalgorithmimplementedinMeCab.Ontheotherhand,Proposedcouldsuccessfullysplit“メインタイトル(maintitle)”becauseitusesfeaturesbasedparaphrasessuchas“メインのタイトル(maintitle).”Inthelastexample,MeCaboversegments“アナトミー(anatomy)”becauseNAIST-jdiccontainsthepropername“トミー(Tommy)”-0.5zw,whileavoidsover-segmentationbyusingaback-transliterationof“アナトミー(anatomy).”ItisinterestingthatKyTeaperformedthebestamongthebaselinewordsegmenters,althoughthisfindingisnotdirectlyrelevanttoourproposal.WethinkthisisbecauseJumanandMeCabheavilyreliesondictionarylook-upforcandidateselection,whereasKyTeadoesnot.</subsection>
  <subsection title="An investigation of out-of-vocabulary words">Inourtestdata,2,681outofthe5,286katakananouncompoundscontainedatleastoneout-of-vocabularywordnotregisteredinNAIST-jdic.Tableillustratestheresultsofthesupervisedsystemsforthose2,681compoundsandtheremaining2,605katakananouncompounds(referredtoasw/OOVandw/oOOVdata,respectively).Whileaccuracyexceeds90%forw/oOOVdata,itissubstantiallydegradedforw/OOVdata.Thisisconsistentwithourclaimthatout-of-vocabularywordsareamajorsourceoferrorsinsplittingnouncompounds.Thethreesupervisedsystemsperformedalmostequallyforw/oOOVdata.ThisisbecauseAPtriviallyperformsverywellonthissubset,andfurtherimprovementisdifficult.Ontheotherhand,wecanseethattherearesubstantialperformancegapsbetweenthesystems'peformancewiththew/OOVdata.ThisresultreflectstheeffectoftheadditionalfeaturesmoredirectlythantheresultsshowninTable.</subsection>
  <subsection title="Effect of the two new features">Toseetheeffectofthenewfeaturesinmoredetail,welookedattheperformancesofoursystemusingdifferentfeaturesets(Table).Thefirstcolumnrepresentsthefeaturesetweused:Basic,Para,Trans,andAllrepresentthebasicfeatures,paraphrasingfeature,back-transliterationfeature,andallfeatures.Theresultsdemonstratethataddingeitherofthenewfeaturesimprovedtheperformance,andthebestresultwasachievedwhentheywereusedtogether.Inallcases,theimprovementoverBasicwasstatisticallysignificant(p&lt;0.01,McNemar'stest).Next,weinvestigatedthecoverageofthefeatures.Ourtestdatacomprised7,709constituentwords,4,935(64.0%)ofwhichwerecoveredbyNAIST-jdic.Thecoveragewassignificantlyimprovedwhileusingtheback-transliterationfeature.Weobservedthat5941words(77.1%)areinNAIST-jdicorword-alignedtransliterationpairsextractedfromtheWebtext.Thisshowsthattheback-transliterationfeaturesuccessfullyreducedthenumberofout-of-vocabularywords.Ontheotherhand,ourtestdataincluded2,423constituentword2-grams,and79.5%(1,926/2,423)and12.8%(331/2,423)ofthemwerecoveredbyparaphrasing-basedandback-transliteration-basedfeatures,respectively.Weinvestigatedtherelationshipbetweenthecoverageofthenewfeaturesandthesizeoftheblogdatafromwhichthenewfeaturesarederived(Figure~).TheX-axisrepresentsthefilesizeoftheblogdata(UTF8encoding)compressedbygzipcommand.Thefigureindicatesthathighercoveragecanbeachievedbyusingalargervolumeofblogdata.However,atthesametime,weseethattheincreaseinthecoveragesaturatesasthesizeoftheblogdataincreases.Theconclusionwedrawfromthisfigureisthatitisdifficulttofurtherimprovecoveragebymerelyincreasingthevolumeofblogdata,anditisthusimportanttoexploreotherapproachessuchasexpandingtheparaphrasingrules.</subsection>
  <subsection title="Error analysis">Ourerroranalysisrevealedthatmanyerrorsarecausedbyover-segmentation,e.g.,splitting“アップロード(upload)”into“アップ(up)”and“ロード(load)”or“トランスフォーマー(transformer)”into“トランス(trans)”and“フォーマー(former).”Since“アップ(up)”and“トランス(trans)”areprefixes,theseresultsareinappropriateforwordsegmentation,althoughtheymaybeappropriateformorphologicalsegmentation.Onecauseofsuchover-segmentationisthatsomestringsareambiguousandcanbeusedasnotonlyprefixesbutalsoaswordsdependingontheircontext.Forexample,while“アップ(up)”caninfactbeusedasaprefix,itcanalsobeusedasanindependentnounasin“給料がアップする(salaryraises)”Similardiscussionappliesto“トランス(trans),”e.g.,“トランス状態(trancestate).”Theproblemcausedbysuchambiguitiesisthatdictionary-basedfeatures(template4inTable)areover-activated.Forexample,intheexamplesdiscussedabove,dictionary-basedfeaturesarewronglyactivatedbecauseboth“アップ(up)”and“トランス(trans)”areregisteredinNAIST-jdicasnouns.Asimilarproblemoccurswithback-transliterationfeatures.Ourmethodofextractingword-alignedtransliterationpairsassumesthatEnglishtextisproperlysegmented.Inpractice,however,whitespacesaresometimesinsertedaroundprefixesandsuffixesand,astheresult,inappropriatepairsareextracted.Tableshowssomeword-alignedtransliterationpairsthatareconsideredtohavecausedover-segmentation.Thetableshowsthattransliterationpairsareappropriatelyextractedfor“アップロード(upload)”and“トランスフォーマー(transformer),”butnotfor“アップローダー(uploader)”and“トランスフォーム(transform).”Back-transliterationfeaturesextractedfromthesetransliterationpairscanbeconsideredtohaveabadinfluenceonaccuracy.Itisonefutureworktodecreasethenumberoferrorsofthistype.Wecanconsideranotherreasonforover-segmentation.Inthetestdata,morethanhalftheexamplesconstituteasingleword,anditispossiblethattheexperimentalsettingisbiasedtowardspromotingover-segmentation.Itishardtoverifythisassumptionbecausetherearenootherdatasetsavailableforourtask.Wehavetofutherinvestigatethismatterinfutureresearch.</subsection>
  <section title="Conclusion">Inthispaper,weproposedamethodforimprovingtheaccuracyofkatakananouncompoundsplittinginJapanesebytheuseofparaphrasingandback-transliteration.ThemethodallowsustotakeadvantageoflargesetsofunlabeleddatatoalleviatetheinfluenceofOOVwords,whichareamajorsourceofsegmentationerrors.Inourexperiments,weempiricallydemonstratedtheeffectivenessoftheproposedmethodbycomparingitwitheightbaselinemethods.Ourfutureworkincludesdevelopingamodelthatintegratesthemethodpresentedinthispaperwithexistingwordsegmentationmethods.Althoughtheycanbecombinedinapipelinedmanner,suchanad-hocapproachisnotalwayssatisfactoryfromatheoreticalperspective.Oneapproachwouldbetoincorporatethenewfeaturesintoexistingwordsegmentationsystems.Anotherinterestingdirectionwouldbetointegratethenewfeaturesintoanunsupervisedframework,whichhasbeenactivelystudiedinrecentyears.Wealsoconsideritimportanttogeneralizetheideapresentedinthispaper.AlthoughthediscussionsinthispaperarefocusedonkatakananouncompoundswithoriginsinEnglish,asimilarapproachislikelytobeeffectiveforothertypesofcompounds.Forexample,ourparaphrasingruleswouldbeusefulforsplitting“トンコツラーメン(porkbonenoodle)”into“トンコツ(porkbone)”and“ラーメン(noodle)”-0.5zw,bothofwhicharespelledwithkatakanacharactersbutnotEnglishtransliterations.Whatismore,theideaofusingparaphrasesasfeaturesforwordsegmentationisnotlimitedtonouncompounds,andweplantoexplorethisresearchdirectioninthefuture.partofthepaperwaspresentedatthe2011ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.document</section>
</root>
