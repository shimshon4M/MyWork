<?xml version="1.0" ?>
<root>
  <section title="Introduction">Probabilisticcontext-freegrammars(PCFGs)areawidelyknownclassofprobabilisticlanguagemodels.Theycanbeseenascontext-freegrammars(CFGs)inwhicheachproductionruleisassociatedwitharealnumber,interpretedasaprobabilityoraparameter.Theprobabilityofasentenceoritsparseiscomputedfromtheseruleprobabilitiesandexploitedinvariouspredictivetasks.However,practicalproblems,suchascostandsubjectivity,ariseifwemanuallyspecifytheruleprobabilities.OnesolutionforthisistotrainPCFGs,i.e.,toautomaticallyestimatetheruleprobabilitiesfromcorpora.Fromsyntacticallyannotatedcorpora,itisstraightforwardtoestimateruleprobabilitiesastherelativefrequenciesofrulesinthecorpora.However,weuseunbracketed(onlymorphologicallyanalyzed)corporaasalessexpensivetrainingresource.Intheliterature,theInside-Outsidealgorithm(hereaftertheI-Oalgorithm)isawell-knownmethodfortrainingPCFGsfromsuchunbracketedcorpora.WecanregardtheI-OalgorithmasanEMalgorithmtailoredforPCFGs,asitisbuiltonatriangularmatrix,thatwasoriginallyusedintheCocke-Younger-Kasami(CYK)parser.TheI-Oalgorithmiscertainlyapolynomial-timealgorithm,butitscubiccomputationtimehindersusfromhandlinglarge-scalecorpora.Furthermore,ithasalimitationinapplicability,inthattheunderlyingCFGmusttakeChomskynormalform(CNF).Toovercometheseshortcomings,weproposeanefficientmethodfortrainingPCFGparametersbyassumingthattheunderlyingCFGisgiven.Intheproposedmethod,weintroducewell-formedsubstringtables(WFSTs),whicharedatastructuresoriginallyusedinefficientparsingalgorithms.Theentireprocessoftheproposedmethodissplitintothefollowingtwosteps:WFSTisagenericnamefordatastructuresthatcontainallpartialparsetreesobtainedduringparsing.UsingWFSTsisastandardtechniqueforpreventingtheparserfromre-analyzingphrasesthathavealreadybeenanalyzed.TheparsersfinallyoutputfullparsesbyassemblingthepartialparsesinaWFST.Table~listsWFSTsusedinwell-knownparsers.usedparseinformationinPCFGtraining,aswedoinourproposal;however,theydidnotexploitWFSTs.Theproposedmethodmakessubstantialimprovementingeneralityandefficiencyatthesametime.Tobemoreconcrete,ithasacoupleofadvantages:Asstatedbefore,theI-Oalgorithmworksonatriangularmatrix,whichistheWFSToftheCYKparser,soitreducestotheproposedalgorithm,wheretheCYKparserandthegEMalgorithmarecascaded(Advantage~1).Ontheotherhand,theproposedalgorithmdoesnotrequiretheassumptionthattheunderlyingCFGtakesCNFwhencombiningtheEarleyparserorthegeneralizedLR(GLR)parserwiththegEMalgorithm.ThepaperwillalsoshowthattheproposedmethodincludesStolcke'sprobabilisticEarleyparserandatrainingmethodfrombracketedcorpora,proposedbyPereira92.Furthermore,Advantage~2comesfromthefactthattheproposedmethodonlyscansacompactdatastructure,i.e.,aWFST.AcombinationwiththeGLRparserwouldfurtherreducethetrainingtime,thankstotheparser'sbottom-upnatureandpre-compilationofCFGsintoLRtables.Advantage~3exhibitsabenefitfromthegeneralityoftheproposedmethod,andinthispaper,wepresentapolynomial-timeEMalgorithmforKitaet~al.'s(1994)rulebigrammodels.Kita94Therestofthepaperisoutlinedasfollows.First,Section~formallyintroducesPCFG,theCYKparser,theI-Oalgorithm,andtheirrelatednotions.Then,Section~describesacombinationoftheCYKparserandthegEMalgorithm,andcomparestheresultwiththeI-OalgorithmtoseeAdvantage~1.ToexamineAdvantage~2,Section~reportsanexperimentalresultwherethetrainingtimeofacombinationoftheGLRparserandthegEMalgorithmismeasuredusingtheATRdialoguecorpus(SLDB).Section~showsAdvantage~3specifically,bypresentingapolynomial-timeEMalgorithmforanextensionofPCFG.Lastly,Section~describesrelatedworkandprovidesanadditionaldiscussiononAdvantage~1.Mostoftheexamplegrammarsandsentences,andtheirparsingresultsareborrowedfrom,possiblywithsomemodifications.</section>
  <section title="Preliminaries">Inthissection,weintroducesomeconceptsandnotationrelatedtothepaper.First,weletA,B,benon-terminalsymbolsinaCFG,anda,b,terminalsymbols.Also,indicatesanon-terminalorterminalsymbol,and,,indicateanemptysequenceorsequencesthatcomprisenon-terminalandterminalsymbols.Anemptysequenceisdenotedby.Thesymbolsinexamplegrammarsarewrittenintypewriterfonts(e.g.,S,NP,).Alistwhosen-thelementisdenotedbyy_nisrepresentedbyy_1,y_2,.ForalistY=,y,,wecansayyY.ThecardinalityofasetX,thenumberofsymbolsinasequence,andthenumberofelementsinalistYaredenotedby|X|,||,and|Y|,respectively.</section>
  <subsection title="Probabilistic context-free grammars">First,wedefineaCFGGbyaquadruple,,R,S,whereisasetofnon-terminalsymbols,isasetofterminalsymbols,Risasetofproductionrules,andSisastartingsymbol(S).AproductionrulerinRtakestheformAandreplacesanon-terminalsymbolAappearinginsomesequence'with.Inthispaper,wealwaysapplyaproductionrulethatreplacestheleftmostnon-terminalsymbol,i.e.,wefocusonlyonleftmostderivations.Wewriterwhenisrewrittenintobyaproductionruler.Whensuchrewritingsareperformedforzeroormoretimes,wewriteandsaythatisderivedfrom.Ifweemphasizethatthereisoneormorerewritings,wewrite.AsequenceofterminalsymbolsthatcanbederivedfromthestartsymbolS(i.e.,S)iscalledasentence.ThesetofsentencesthatcanbederivedusingtheproductionrulesinaCFGGiscalledthelanguageofG,andisdenotedbyL_G.Then,wedenotebyG()aPCFGwhoseunderlyingCFGisG.Here,isa|R|-dimensionalvector,andiscalledtheparametersofthePCFG.Eachelementinisreferredtoby(r),whererR,andweassumethat0(r)1and_:(A)R(A)=1.WithaPCFG,therulesappliedaresupposedtobechosenindependently.Thus,inaderivation_0r_1_1r_2_2	r_3r_K_K,thegenerativeprobabilityP(|)ofasequence=r_1,r_2,,r_KoftheappliedrulesiscomputedbyLetting(r,)bethenumberofoccurrencesofarulerinruleapplications,theprobabilityabovecanbecomputationallysimplifiedasFurthermore,let()beasetofpossibleruleapplicationstogenerateasentence.Then,notingthatisuniquelydeterminedgivenruleapplications,wehavethefollowingrelationconcerningajointprobabilityP(,|):Fromthis,wehavethegenerativeprobabilityP(|)ofasentencebeingderivedfromthestartsymbolSasfollows:Ifparameterisobviousfromthecontext,weabbreviateP(,|)andP(,|)asP(,)andP(,),respectively.Inadditiontotheindependenceofruleapplications,anyPCFGG()inthispaperisassumedtosatisfythefollowingconditions:G()isconsistent,i.e.,_L_GP(|)=1holds.Ghasnorule,i.e.,noproductionrulewhoserighthandsideis.Thereisnocyclicproductionw.r.t.G,i.e.,GhasnononterminalAsuchthatAA.Chi98provedthat,givenanunderlyingCFGsatisfyingthelasttwoconditionsandunbracketedcorporaoffinite-lengthsentences,PCFGG(^)isconsistentwhere^istheparameterstrainedbytheI-Oalgorithm.</subsection>
  <subsection title="Corpora and parse trees">Inasentence=w_1w_2w_nL_G,eachw_jiscalledaword(n&gt;0,j=1n).Then,weintroduceEarley-stylewordpositionsd=0nin.For0dd'n,asubsequenceoraphrasew_d+1w_d'betweenpositionsdandd'isdenotedby_d,d'(notethat=_0,n).Aphrasew_dw_d'maybewrittenbyalistw_d,,w_d'.ForasentenceL_G,aparsetreeofrepresentsaderivationprocessSinatreeform.Sincewefocusonleftmostderivations,aparsetreetofisuniquelydeterminedfromruleapplicationsinS,andthus,wewillrefertotandinterchangeably.Havingassumedthatthereisneitherrulenorcyclicproduction,asubtreet'ofaparsetreetofasentenceisuniquelyidentifiedbyapaird,d'wherethewordsinw_d,d'areleafnodesint'.Fromthisobservation,lettingAbetherootnodeoft',weoftenrefertot'byalabelA(d,d'),calledasubtreelabel.Then,aparsetreetofasentencecanbeseenasaset(t)ofsuchsubtreelabelsofnon-leafnodes.(t)iscalledalabelsetoft.Somemayfindthatapaird,d'ofwordpositionscorrespondstoabracketinbracketedcorpora.Wedefine(t)d,d'A(d,d')(t)andcall(t)thebracketsetoft.Furthermore,supposethataproductionruleA_1_2_Misappliedinatreet,and_1,_2,,_Maretherootnodesofsubtrees_m(d_m-1,d_m)(m=1M),asillustratedinFigure~.Then,weintroduceapartialorder@suchthatA(d_0,d_M)@_m(d_m-1,d_m),andsaythatA(d_0,d_M)isaparentof_m(d_m-1,d_m),orinversely,_m(d_m-1,d_m)isachildofA(d_0,d_M).Withaslightadjustmentinnotation,wejointlywritethepartialorderingsaboveasandcallthisaparent-childrenpairofsubtrees.Wedefine(t)astheentirecollectionofsuchparent-childrenpairsinatreet.Forasequenceofruleapplicationsthatcorrespondstoaparsetreet,wedefine()(t),()(t),and()(t).WeconsiderfourtypesofcorporafortrainingPCFGs:(1)labeledcorpora,(2)fullybracketedcorpora,(3)partiallybracketedcorpora,and(4)unbracketedcorpora.Ourtrainingschemeismaximumlikelihoodestimation,whereacorpusc_1,c_2,,c_NofNsentencesisconsideredastheresultofNindependentsamplings(i.e.,probabilisticderivations)usingtheruleswithprobabilitiesinPCFGG().Letting_and_be,respectively,thesentenceandtheruleapplicationsobtainedinthe-thsampling(=1N),c_=_,(_)whenisalabeledcorpus,c_=_,(_)whenisafullybracketedcorpus,c_=_,_whenisapartiallybracketedcorpus,andc_=_whenisanunbracketedcorpus(_L_G,_(_),and_(_)).</subsection>
  <subsection title="The CYK parser">TheCYKparserisapplicabletotheCFGsinCNF.Wepreparean(n_n_)uppertriangularmatrixT^()forasentence_inanunbracketedcorpus(n_=|_|).UnlikeatypicalformulationoftheCYKparser,therownumbersofthetriangularmatrixaredecrementedbyoneinordertomaintainconsistencywiththeEarley-stylewordpositionsweuse.TheelementT_d,d'atthed-throwandthed'-thcolumninthetriangularmatrixstoresallpartialparsetreesforthephrase_d,d'.Figure~showstheroutineCYK-Parser,whichimplementstheCYKparser.Startingfromthediagonalelementsinthetriangularmatrix,webuilduppartialparsetrees(parent-childrenpairs)innon-diagonalelementstowardsthetop-rightcornerofthematrix(Lines~--).Finally,ifwehaveaparent-childrenpairoftheform``S(0,n_)@;''inthetop-rightcornerT_0,n_,werecognizethattheparsinghasendedinsuccess,andotherwise,theparsinghasfailed(Line~).Afterasuccessfulparsing,wecanextractafullparsetreebyfollowingtheparent-childrenpairsfrom``S(0,n_)@;''storedinthetop-rightcorner.Forexample,followingaJapaneseCFGG1showninFigure~,wehaveatriangularmatrixshowninFigure~forasentence=急いで,走る,一郎,を,見た([Someone]sawIchirowhoisrunninginahurry).Fromtheparent-childrenpairsmarkedby,wecanextractparsetreet1inFigure~,andfromthosemarkedby,parsetreet2isextracted.</subsection>
  <subsection title="The Inside-Outside algorithm">Asmentionedbefore,weaimtotraintheparametersofaPCFGfromagivencorpus=c_1,c_2,,c_N,followingastandardmannerofmaximumlikelihoodestimation.Foralabeledcorpus,therelativefrequency^(r)ofarulerisexactlythemaximumlikelihoodestimateoftheparameter(r).Generally,however,suchlabeledcorporaareexpensive,anditseemsmorelikelythatonlyunbracketedcorporaareavailable.TheI-Oalgorithm,anEMalgorithmtailoredforPCFGs,isusedinsuchacase,sincetherelativefrequencymethodcannotbeappliedtounbracketedcorpora.TheI-Oalgorithmisamaximumlikelihoodestimationmethod,i.e.,itfindstheparameters^thatlocallymaximizethelikelihood_=1^NP(_)oritslogarithm_=1^NP(_)(calledthelog-likelihood),givenanunbracketedcorpus=_1,_2,,_N.IntheliteratureincludingLari90'swork,therulesetRofanunderlyingCFGisnotgiven,whileonlysetofterminalsandsetofnon-terminalsaregiven.Forcomparison,wedescribetheI-OalgorithmtowhichsomerulesetRisgiven.Indeed,theI-Oalgorithmgivenandisequivalenttotheonegiventhefollowingruleset(abbreviatedashereafter):Notethat,inbothcases,therulesetneedstotakeCNF.WhileLari90usedtheI-OalgorithmforlearningsetRofproductionrulesaswell,wefocusonthetrainingofparameters.ThecentralpartoftheI-Oalgorithmisthecomputationoftwotypesofprobabilities:theinsideprobabilitiesP(A_d,d'^())andtheoutsideprobabilitiesP(S_0,d^()A_d',n_^())(=1N,A,0d&lt;d'n_).Theseprobabilitiesarestoredintothearrayvariables_d,d'^()[A]and_d,d'^()[A],respectively.ThesearrayvariablesarepreparedintheelementT_d,d'inthetriangularmatrix.ThegenerativeprobabilityP(S_)ofasentence_isstoredinto_0,n_^()[S].TheroutinesGet-BetaandGet-Alpha,whichareusedforcomputingtheinsideandoutsideprobabilities,respectively,arepresentedinFigure~.Intheseroutines,forsimplicity,weassumethatthearrayvariables_d,d'^()[]and_d,d'^()[]areinitializedaszero,whenevertheroutinesarecalled.Startingfromthediagonalelementsofthetriangularmatrix,Get-Betacomputestheinsideprobabilitiestowardsthetop-rightcorner_0,n_^()[],justliketheCYKparserbuildsuppartialparsetrees.Conversely,Get-Alphastartsfromthetop-rightcorner_0,n_^()[]andcomputestheoutsideprobabilitiestowardsthediagonalelements.Thiswayofcomputingtheinsideandoutsideprobabilitiescanbeseenasdynamicprogramming.Afterhavingcomputedtheinsideandoutsideprobabilities,theconditionalexpectedoccurrences(theexpectedrulecountshereafter)ofABCandAainruleapplications,givenacorpus,arecomputedas:[ABC]&amp;:=	_=1^N		1_0,n_^()[S]		_k=2^n__d=0^n_-k_k'=1^k-1		(ABC)		_d,d+k^()[A]		_d,d+k'^()[B]		_d+k',d+k^()[C]	,[Aa]&amp;:=		_=1^N		1_0,n_^()[S]		_d=0^n_-1(Aa)_d,d+1^()[A].	alignFurthermore,parameters(A)arere-estimatedfromtheexpectedrulecountsabove:IntheI-Oalgorithm,wefirstinitializerandomly,andtheniterativelyupdatebyGet-Beta;Get-Alpha;andEqs.~,,and.Withthisiteration,thelog-likelihood_=1^NP(_)=	_=1^N_0,n_^()[S]increasesmonotonicallyandfinallyconverges.Afterconvergence,theI-Oalgorithmterminatesandoutputstheparametersatthesametimeasthetrainedones.Here,weevaluatethecomplexityoftheI-Oalgorithm.Ingeneral,thenumberofiterationsisunknowninadvancesinceitdependsontheinitialparameters,soweevaluatethecomplexityoftheI-Oalgorithmwiththatofoneiteration.Givenasetofnonterminalsandasetofterminals,theworst-casecomplexityismeasuredconsideringthecasewithR=(,).LetLbethelengthofthelongestsentenceinatrainingcorpus.Then,byexaminingthefororforeachloopsandtherangesofthesummationsinGet-BetaandGet-Alpha(Figure~),theworst-casecomplexityoftheI-OalgorithmisO(|R|L^3N)=O(||^3L^3N).</subsection>
  <subsection title="Additional notes on the Inside-Outside algorithm">ThemostexpensivepartintheI-Oalgorithmisthecomputationoftheinsideandoutsideprobabilities.Thatis,atLine~inGet-Beta,wecomputetheinsideprobabilities,takingintoaccountallthesituationsillustratedinFigure~(1).Fortheoutsideprobabilities,thefirstandsecondtermsontherighthandsideatLines~andinGet-AlphacorrespondtoallthesituationsinFigure~(2)and(3),respectively.OnemayseethattheprocessofprobabilitycomputationintheI-Oalgorithmissimilartotop-downparsers,sinceitconsidersallpossiblesituationswithouttakingintoaccounttheinputsentences_.Ingeneral,ignoringtheconstraintsfromtheinputsentencesslowsdowntheparser,andtherefore,byanalogy,theI-Oalgorithm'stop-downnatureseemstoproduceanextracomputationalcost.Toseethismoreformally,werevisitthederivationoftheI-OalgorithmdescribedinLafferty93.First,letusdefine(r,)astheoccurrencesofarulerinruleapplications,aswedidinSection~.Then,theI-Oalgorithmcanbeobtainedbyfirstconsideringthecomputationoftheexpectedrulecount[r]ofaruler:secondbyrewritingEq.~intotheformusingthepartialderivativew.r.t.parameter(r):andfinallybyrewritingEq.~intoadynamicprogrammingstyle.Specifically,substitutingr=(ABC)intoEq.~,theI-Oalgorithmcomputes(ABC)	_all;P(_,)asfollows(heresubscripts_andsuperscripts^()areomitted):&amp;(ABC)	_		P(,)	&amp;=(ABC)		_				P(,)	&amp;=(ABC)		_d,k,k'		_				P(,)		&amp;=(ABC)		_d,k,k'			P(S_0,dA_d+k,n)			(ABC)	&amp;			P(B_d,d+k')			P(C_d+k',d+k)	&amp;=		_d,k,k'			P(S_0,dA_d+k,n)			P(B_d,d+k')			P(C_d+k',d+k).alignThetransformationinEq.~isdoneindependentlyoftheinputsentenceoritsparsetreet();therefore,theI-Oalgorithmrunsinatop-downmanner.Anotherapproachtocomputingtheexpectedrulecounts[r]isjusttotransformEq.~intoEq.~belowusingEq.~,wheretheparseinformationisexploiteddirectly.Inthisapproach,isobtainedinadvanceusingsomeefficientparser.Now,weseethatEq.~isthesameasFujisakietal.'sFujisaki89methodinournotation.ByusingEq.~,unliketheI-Oalgorithm,wecanavoidprobabilitycomputationsthatarenotrelatedto.Howeveringeneral,|()|isexponentialtothesentencelength||,andthus,itisnotfeasibletocomputeEq.~asitis.Theproposedmethod,whichispresentednext,introducesthenotionofdynamicprogrammingliketheI-Oalgorithm,andcomputesEq.~quickly,usingaWFSTheldinsomeefficientparser.Thus,wecansaythattheproposedalgorithmharmonizestheadvantagesofFujisakietal.'smethodandtheI-Oalgorithm.</subsection>
  <section title="Proposed method">TheoutlineoftheproposedmethodisillustratedinFigure~.Asinputs,theproposedmethodisgivenanunderlyingCFGG=,,R,SofthetargetprobabilisticCFGG()andanunbracketedcorpus.Then,itreturnstrainedparametersastheoutput.Intheproposedmethod,wesplittheentiretrainingprocessintotwosteps:parsingandEMlearning.First,weanalyzeeachsentence_inthecorpusbysomeefficientparser.Then,theparseinformationisstoredintoaWFSToftheparser.Thisparseinformationiscollectivelyequivalenttoaset(_)ofparsetreesof_,butisstoredfragmentarily.Therefore,weneedanextractionstepforthefragmentaryparseinformationafterparsing,andtheextracteddatastructureiscalledasupportgraph.Finally,basedonthesupportgraphs,werunthegEMalgorithmandreturnastrainedparameters.InthecaseofaCFGG1andasentence_=急いで,走る,一郎,を,見たinFigure~,asupportgraphisextractedfromtheparent-childrenpairsmarkedwithandinFigure~.Asillustratedinthisexample,thesupportgraphsscannedbythegEMalgorithmcanbemuchsmallerthantheentiretriangularmatrix,andaccordingly,wecangainasignificantspeed-upovertheI-Oalgorithmwhichinherentlyscanstheentirematrix.</section>
  <subsection title="Support graphs">ItwouldbeeasiertounderstandthegEMalgorithmifwerepresentthepairO_,_asadatastructurecalledasupportgraph_.Indeed,theword``graphical''inthenamecomesfromthisviewpoint.First,Figure~(a)showsthesupportgraphthatcorrespondstotheexampleofO_and_inthelastsubsection.Asupportgraph_isadirectedacyclicgraphthathasastructuresimilartoarecursivetransitionnetwork(RTN),andconsistsofdisconnectedsubgraphs_(),_(),whereO_.Each_()iscalledasupportsubgraphforandlabeledby=A(d,d').Each_()hastwospecialnodes---calledthestartingnodeandtheendingnode---labeledbystartandendinFigure~,respectively.ForeachE_(),thestartingnode,thenodeslabeledbyanelementinE(aruleAorasubtreeA(d,d')),andtheendingnodeareconnectedinthisorder.Notethattwoormorenodescanhavethesamelabel.Thepathfromthestartingnodetotheendingnodeiscalledthelocalpath,whichisalsoreferredtobyE.Inalocalpath,thenodeslabeledbyaruleAarecalledbasicnodesandthoselabeledbyasubtreeA(d,d')arecalledintermediatenodes.Thesenodesaredenotedbyand,respectively,asinFigure~.Supportgraphshavethefollowingfeatures:Wecanconductarecursivetraversaloverasupportgraph_,likethewayoveranRTN.Therearemultiplewaysoftraversalthatsharesomepartialpaths.ForeachE_()inasupportsubgraph_()=,(),@'holdsforevery'=A(d,d')E.Thenumbersofbasicandintermediatenodesinalocalpatharenotpredefined.Arecursivetraversal,thefirstfeature,isperformedasfollows.WefirststartfromthestartingnodeofasupportsubgraphS(0,n_)andvisitthenodesonebyonealongthedirectedges.Whenvisitinganintermediatenode=A(d,d'),wejumptothestartingnodeofthesupportsubgraphlabeledby.Next,whenreachingtheendingnodeofthecurrentsupportsubgraph,wegobacktotheoriginalnode.Afterrepeatingsuchrecursivevisits,thetraversalfinisheswhenwereachtheendingnodeofthesupportsubgraphofS(0,n_).Inabranchatsomenode,wechooseoneofthepossibledestinations.Ifwecollectthesubtreelabelsoftheintermediatenodesvisitedduringatraversal,wehavealabelsetthatmeansoneparsetreeofthesentence_.Similarly,collectingtherulelabelsofthebasicnodesvisited,wherethenodesareorderedasinFigure~,wehaveasequenceofruleapplications(_)intheleftmostderivationof_.Byexhaustivetraversals,wecanfindallpossiblesequencesofruleapplicationsin(_).ThenotionofrecursivetraversalisusedinjustifyingthegEMalgorithm(Appendix~).Here,weshowanexampleofarecursivetraversalinFigure~~(b),wherethepathofthetraversalisdrawnasadottedline.Thesecondfeatureaboveisobtainedbecause,inarecursivetraversal,wemayjumpintothesamesupportsubgraph_()fromtwoormoreintermediatenodeslabeledwith.Thisstructuresharingcompressessupportgraphs,andaccordingly,thegEMalgorithmefficientlycomputesvariousprobabilityvalues.Forexample,wejumpintosubgraph_(V(4,5))fromthenodeslabeledwithV(4,5)andmarkedwithinFigure~(a).ThethirdfeatureisobviousfromtheassumptiononunderlyingCFGsthatwehaveneitherrulenorcyclicproductionAA,andfromthedefinitionsofO_and_.Inotherwords,if@',thenthenodesinthesupportsubgraph_(')of'neverreferto.Basedonthis,thegEMalgorithmworksinageneralizeddynamicprogrammingfashionincomputingtheinsideandoutsideprobabilities(Section~).Finally,thefourthfeatureshowsthegeneralityofsupportgraphs,whichisfullyexploitedbythegEMalgorithm.</subsection>
  <subsection title="Extracting support graphs">WenextexplainhowtoextractasupportgraphfromtheWFSTheldintheparser.Asmentionedbefore,O_isanorderedsetofmembersinV_suchthatthetotalorderinO_satisfiesthepartialorder@intheWFST_.Ingeneral,atotalorderthatsatisfiesagivenpartialordercanbefoundbytopologicalsorting,andthusweconducttopologicalsortingtoobtainO_andpickup_duringsorting.Figure~(above)showsaroutineExtract-CYKforextractingsupportgraphsinthisway.Extract-CYKisrathergeneral,whileitssubroutineshouldbetailoredfortheWFSTsoftheparserinuse.Figure~(below)showsasubroutineVisit-CYKthatrunsoveratriangularmatrixoftheCYKparser.Fortheseroutines,wefirstprepareastack(U),whichclearsthestackU;PushStack(x,U),whichpushesanobjectxintoU;andPopStack(U),whichreturnsthepoppedobjectfromU.Uandaflagarray[]inaglobalarea.Then,wecallVisit-CYKrecursivelytovisitthesubtreesA(d,d')fromthetop-rightcornerofthetriangularmatrix(Line~inExtract-CYK).Afterreturningfromallrecursivecalls,wepushthecurrentsubtreelabelintothestackU(Line~inVisit-CYK).Duringrecursivecalls,werecord_aswell(Lines~andinVisit-CYK).Notethatweputtracesintotheflags[]toavoidrevisits(Lines~,,andinVisit-CYK).Finally,O_isobtainedbypoppingupthesubtreelabelsfromU(Lines~andinExtract-CYK).TheGLRparserdoesnotrequireCNFfortheunderlyingCFG;hence,forpackedsharedforests,weneedtointroduceamoregeneralroutinethanVisit-CYK.However,thebasicstructureshouldbethesameinthatweuseastack,aflagarrayfortracesandrecursivecalls.Finally,theroutinesforextractingsupportgraphsoftenresemblearoutineforoutputtingorcountingfullparsetrees,oftenprovidedintheparsersoftware,andsosuchabuilt-inroutinecanbeabaseforimplementation.</subsection>
  <subsection title="Graphical EM algorithm">Theproposedmethod'smainroutineLearn-PCFGispresentedinFigure~.WehavedescribedtwosubroutinesCYK-ParserandExtract-CYK,andinthissubsection,wepresentGraphical-EM,whichimplementsthegEMalgorithm.SimilartotheI-Oalgorithm,thecentralpartofthegEMalgorithmiscomputingtheinsideandoutsideprobabilities.TheinsideandoutsideprobabilitiesofeachO_are,respectively,storedintothearrayvariables[,]and[,],keptinsupportsubgraph_()=,_()._()hasanarrayvariable[,,E]foreachlocalpathE_().Wealsohaveanarrayvariable[A]thatstorestheexpectedrulecountofeachruleA.Graphical-EMhastwosubroutines:Get-Inside-Probs,whichcomputestheinsideprobabilities,andGet-Expectations,whichsimultaneouslycomputestheoutsideprobabilitiesandtheexpectedrulecounts.Graphical-EMisshowninFigure~.InGraphical-EM,wefirstinitializeallparameters(Line~).Then,weiterateGet-Inside-Probs,Get-Expectationsandre-estimationofparametersinthisorder(Lines~and).Aftertheconvergenceoflog-likelihood(Line~),weconsidertheparametersatthemomentasthetrainedones^.Thelog-likelihoodiscomputedusingthegenerativeprobabilityP(_)of_storedin[,S(0,n_)](Lines~and).Figure~showstwosubroutinesGet-Inside-ProbsandGet-Expectations.Figure~illustrateshowthesesubroutinesworkoveranexamplesupportgraph.Theinsideprobabilities[,]inGet-Inside-ProbsarecomputedfromthelastsupportsubgraphaccordingtoO_.ForeachlocalpathE_(_k)in_k'ssupportsubgraph_(_k)=_k,_(_k)(k=1|O_|),wecomputetheproductofinsideprobabilitiesofthenodesinthelocalpathandstoretheproductinto[,_k,E](Lines~andandFigure~(1)).Incomputingtheproduct,wemultiplytheparameter(A)forabasicnodeAortheinsideprobability[,']foranintermediatenode'(Figure~(2)).,wealwayshavek&lt;k'.AlsonotethatthecomputationofisconductedfromthelastsupportsubgraphaccordingtoO_.Then,itisobviousthat[,']hasalreadybeencomputedwhenitisreferredto.Finally,wecompute[_k]bysumming[,_k,E](Line~andFigure~(3)).Ontheotherhand,inverselywithGet-Inside-Probs,Get-ExpectationsstartsfromthefirstsupportsubgraphaccordingtoO_.Inthisroutine,wefirstinitializethearrayvariablesand.Inparticular,regardingtheoutsideprobabilities[,],wesetonefor_1=S(0,n_),whichisthefirstelementofO_,andsetzerofortheothers(Lines~and).Next,foreachk=1|O_|,weconsideralocalpathEinthesupportsubgraph_(_k)of_k(Line~),andthesubtree'EwhoseoutsideprobabilityistobeupdatedatLine~.Then,theproductofthelocaloutsideprobabilityof'inE(theproductofinsideprobabilitiesofthenodesotherthan')andtheoutsideprobabilityof_k(theparentof')isaccumulatedinto[,'](Figure~(4)).,k&lt;k'alwaysholdsfromthethirdfeatureofsupportgraphs,andso'appearsafter_kintheorderO_.Inversely,inasupportsubgraph_(_k'')wherek''=k|O_|,[,_k]willneverbemodified,andhencethecomputationof[,_k]intherighthandsideofthesubstitutionatLine~hasbeencompleted.However,atLine~,forabasicnodeA,theproductoftheprobability[,_k,E]ofthelocalpathEandtheoutsideprobability[,_k]oftheparent_k,dividedbythegenerativeprobabilityP(_)ofthesentence_,,weinitializesothatP(_|)&gt;0holdsforall=1N.So,afteranyre-estimationsofinthegEMalgorithm,itneverhappensthatP(_|)=0.Since,asroughlyprovedinAppendix~,theexpectedrulecounts[r]inthegEMalgorithmandthoseinFujisakiet~al.'s(1989)method(Eq.~)arealwaysequal,thispropertycanbeprovedinductivelyasfollows.First,supposethatP(_|^(m))&gt;0holdsundertheparametersafterthem-thre-estimation.Then,thereshouldexistsome(_)thatsatisfiesP(|^(m))&gt;0.Furthermore,foranyruler,[r]&gt;0shouldholdunder^(m),fromthefactthat(r,)&gt;0andEq.~.Thisimpliesthattheparameter^(m+1)(r)afterthenextre-estimationisalsopositive,asseenfromLine~inGraphical-EM.Again,forconsideredabove,wehaveP(|^(m+1))&gt;0,andconsequently,P(_|^(m+1))&gt;0.Now,wesummarizethatP(_|^(m))&gt;0P(_|^(m+1))&gt;0,andtherefore,ifweinitializetheparametersas^(0)suchthatP(_|^(0))&gt;0,thenP(_|^(m))&gt;0afterthesubsequentre-estimations(m=1,2,).[Q.E.D.]TomakesurethatP(_|)&gt;0inpracticalcases,itsufficestochooses.t.(r)&gt;0holdsforeveryrR.isaccumulatedinto[A](Figure~(5)).Aftersuchasynchronousaccumulationsinto[A],[A]containstheexpectedrulecountofruleAwhenGet-Expectationsterminates.ThecomputationsinthegEMalgorithmdescribedabovearejustifiedwiththenotionofrecursivetraversaloversupportgraphs(Section~).SuchajustificationwillbemadeinAppendix~.Ingeneral,theEMalgorithmisahill-climbingalgorithmtargetingthelog-likelihoodfunction,andhence,onlyguaranteesalocalmaximumlikelihoodestimate.Asaresult,thequalityofthetrainedparametersdependsheavilyontheinitialparameters.Lari90proposedtoinitializetheparametersusingtrainedhiddenMarkovmodels.OnesimplesolutionforlocaloptimalityistofirstrepeattheEMalgorithmhtimeswithrandominitialparameters,andthentopickuptheparametersinconvergenceatthehighestlog-likelihoodasthebesttrainedparameters.Inthispaper,thismethodiscalledrandomrestarting.</subsection>
  <subsection title="Probabilistic parsing">Havingtrainedtheparameters,wecanfindthemostlikelyderivation^_argmax_all;P(|_)=argmax_all;P(,_)=argmax_(_)P()foreachinputsentence_inthetestcorpus.Wedefinet^_astheparsetreecorrespondingto^_,andresolvethesyntacticambiguityin_byt^_.|(_)|isstillexponentialhere,soweaimtofindt^_onthebasisofsupportgraphs.Figure~showsaroutinePredictforfindingt^_,anditssubroutinesGet-Max-ProbsandConstruct-Tree.doesnotworkcorrectly,sinceitusestheinsideprobabilitiescomputedbyGet-Inside-Probs.Predicttakesasinputthecorpus=_1,_2,,_N,andforeachsentence_,itoutputsaset(t^_)ofsubtreelabelsinthemostlikelyparsetree.InPredict,wefirstrunaparser,aroutineforextractingsupportgraphs,andasubroutineGet-Max-Probs(Line~).Get-Max-Probsdeterminesthemostlikelysubtreesfragmentarilyinadynamicprogrammingfashion.Anothersubroutine,Construct-Tree,isthencalledforbuildingthemostlikely,fullparsetreefromsuchfragmentaryparseinformation(Line~).Here,wedescribefurtherdetails.Get-Max-ProbsworkssimilarlytoGet-Inside-Probs,buthastwodifferences.First,tofindthemostlikelylocalpaths,Get-Max-ProbsusesthemaximizationoperatorinsteadofthesummationatLine~,i.e.,themeaningsoftwoarrayvariables,and,havebeenchanged.TheseconddifferenceisthatGet-Max-Probsusesanadditionalarrayvariable[,_k]forrecordingthemostlikelylocalpathitself(Line~).Construct-Treeconductsarecursivetraversalover[,_k]andaddsthesubtreelabelsA(d,d')inthemostlikelylocalpath[,]into^_(Line~).Thisprocesscorrespondstobuildingthemostlikelyparsetree.Ifweextend[,]tocontaintwoormorecandidatelocalpaths,wewouldhavetop-nmostlikelyparsetrees.</subsection>
  <subsection title="Complexity">Asstatedbefore,sincethenumberofiterationsdependsontheinitialparameters,weevaluatethecomplexityoftheI-Oalgorithmwiththatofoneiteration.ThisisexactlythecomplexityinsidetherepeatloopinGraphical-EM.First,letO_=_1^(),	_2^(),,^()_|O_|foreach=1N.Notethat,intheroutineGet-Inside-ProbscalledfromGraphical-EM,wevisiteachelementin_(_k^())onceforallk=1|O_|.Then,thecomplexityofGet-Inside-ProbsisevaluatedasO(_num_maxsizeN),where:_num&amp;	_=1N		_k=1^|O_||_(_k^())|,	_maxsize&amp;	_E:;=1N,;k=1|O_|,;			E_(_k^())		|E|.	alignSimilarlyweseethatGet-ExpectationsrequiresO(_num_maxsizeN)~time.LetLbethemaximumsentencelengthinatrainingcorpus,andconsiderasetofnonterminalsandasetofterminals.Here,weevaluatetheworst-casecomplexitywiththemaximumgrammar(Eq.~)inCNF.Forsuchagrammar,wehaveforallA,dandd',suchthatA,0d,d'Landd+2d'(thecasewithd'=d+1isignorable).Then,since|O_|=|A(d,d')A,;0d&lt;d'L|=O(||L^2)and|_()|=O(||^2L)hold,_num=O(||^3L^3)fromthedefinitioninEq.~.AlsofromthedefinitioninEq.~,_maxsize=3=O(1).Thecomplexityofparameterre-estimationisO(||)=O(||^3),whichisignorable.Fromthediscussionabove,thecomplexityofthegEMalgorithmisO(||^3L^3N),i.e.,thesameasthatoftheI-Oalgorithm.WithagrammarinCNF,theworst-casecomplexityoftheCYKparser(CYK-Parser)andtheroutineforextractingsupportgraphs(Extract-CYK)isO(||^3L^3N),whichisthesameasthatofoneEMiteration.However,notethattheEMalgorithmusuallyiteratesforafewdozensorhundredsoftimes,sothecomputationtimeoftheseroutinesisoftenignorableintheentiretrainingprocess.Similarly,assumingCNF,thecomplexityofcomputingthegenerativeprobabilityorprobabilisticparsingforasentenceisO(||^3L^3)(N=1).Fortheparsers(e.g.,CYKandGLR)thatuseWFSTswithparent-childrenpairsoftheforminEq.~,wehavethesamesupportgraphsO_,_andthesamecomplexity.WeevaluatethecasewiththeEarleyparserinAppendix~.</subsection>
  <section title="Experiments on training time">ToshowAdvantage~2ofourproposal,thatitcanrunsignificantlyfasterthantheI-OalgorithmwithapracticalCFG,wemeasuredthetrainingtimefortheATRdialoguecorpus(SLDB).TheunderlyingCFGisamodifiedversionofaJapanesegrammarby,whichwasoriginallyhand-craftedforspeechrecognition.Themodifiedgrammarhas860rules,andaccordingtothismodifiedversion,thecorpuswasalsomodified.isaCFGwhoseterminalsymbolsarefine-grainedpartsofspeech,andhas173nonterminalsand441terminals.Theaverage,theminimum,andthemaximumsentencelengthinthecorpusare9.97,2,and49,respectively.SincetherulesetinisnotinCNF,weusedaGLRparserintheproposedmethod.However,sincetheI-OalgorithmonlyworkswithCFGsinCNF,wetransformedintoinCNF,whichhas2,308rules,210nonterminals,and441terminals.Inourexperiments,wecomparethetrainingtimebetweentheproposedmethodandtheI-Oalgorithm,givenasanunderlyingCFG.TheI-OalgorithmistheonedescribedinSection~,andusesrulesetininsteadof(Eq.~).).Wemeasuredthetimeconsumedforare-estimationoftheparameters(calledthere-estimationtime),varyingthesentencelengthL.Forthis,wefirstgatheredthesentencesoflengthsL-1andLintoagroup(L=2,4,26),andfromeachgroup,werandomlypickedup100sentencesas_L.Then,foreach_Lbeingtreatedasatrainingcorpus,wemeasuredthere-estimationtime.Figure~(left)showsthemeasurementresults.They-axisindicatestheaveragere-estimationtimeinsecondsandLinthex-axiscorrespondstothetrainingcorpus_L.Thecurve``Inside-Outside''indicatesthere-estimationtimeintheI-Oalgorithm,and``IOwithpruning''indicatesthere-estimationtimeinapruning-embedded(or,inshort,pruning)versionoftheI-Oalgorithm,whichispresentedbyKita99.Thismodifiedversionismoreefficientthantheoriginal,inthatitskipsredundantzero-probabilitycomputationsincomputingoutsideprobabilities.Finally,``GraphicalEM''indicatesthere-estimationtimeinthegEMalgorithm.Tomakethegraphshapesreadable,wemagnifyandminifythescaleofthey-axisofFigure~(left)asshowninFigure~(center)andFigure~(right),respectively.AsshowninFigure~(left),thegEMalgorithmrunssignificantlyfasterthantheI-Oalgorithmanditspruningversion.Inaddition,Figure~(center)indicatesthatthere-estimationtimeintheI-Oalgorithmdrawsacubiccurvew.r.t.thesentencelengthL,asthetheoryindicates.Thepruningversioncertainlyrunsfasterthantheoriginalbutonlyinquadratictimeatbest,sinceitstillunconditionallyscansallelementsinthetriangularmatrix.Notingthatweneedtorepeatre-estimationsseveralhundredtimesandconductrandomrestarts,itisnotpracticaltoruntheI-Oalgorithmoritspruningversionuntilconvergenceforthetrainingcorpora_LwhereL&gt;20.InContrast,asshowninFig~(right),theproposedmethodrunsalmostinlineartimeinsentencelengthL,whereL=2,4,,26.Thissignificantgapfromtheworst-casecomplexityO(||^3L^3)seemstobebroughtbythegrammaticalconstraintsthatgreatlyreducetheambiguityoftheinputsentences,ormorespecifically,thenumberofsubtreesstoredintheWFSTs.AtsentencelengthL=10,whichisclosetotheaverage9.97intheATRdialoguecorpus,theproposedmethodrunsaboutonethousandtimesfasterthantheI-Oalgorithm(aboutsevenhundredtimesfasterthanthepruningversion).Whenweusetherandomrestartingmethod(Section~)toobtainbetterparametersw.r.t.thelog-likelihood,theentiretrainingtimeisbrokendownasfollows:()&amp;=	()&amp;+()&amp;+(),()&amp;=	()&amp;()&amp;().align*Usingthelength-wisetrainingcorpora_L(L=2,4,,26)describedbefore,wemeasuredthebreakdownsoftrainingtime(theparsingtime,thetimespentonextractingsupportgraphsandthetimespentonthegEMalgorithm),andtheresultsareshowninFigure~.Thex-axisandthey-axisrespectivelyindicatethesentencelengthLandtheconsumptiontimeinseconds.AlsoFigure~(left)showsthecasewithoutrestarts(i.e.,h=1)andFigure~(right)showsthecasewith10restarts(h=10).Wefixedthenumberofre-estimationsuntilconvergenceas100becauseitvariesdependingonthecorpus_L.Theparsingtime(``Parsing''),thetimespentforextractingsupportgraphs(``Supportgraph'')andthetimespentonthegEMalgorithm(``GraphicalEM'')arealmostlinearinsentencelengthL.Figure~(right)alsoindicatesthat,whenintroducingrandomrestarts,theparsingtimeandthetimespentonsupport-graphextractionareignorableintheentiretrainingtime,aswedonothavetorepeatparsingandsupport-graphextractioninrandomrestarts.Sothesetwostepscanbeseenasasmallpreprocessingthatyieldsasignificantspeedupoftraining,andinthisway,weenjoythemeritofseparatingtheentiretrainingprocessintoparsingandEMlearning.</section>
  <section title="EM learning of the extensions of PCFGs">Sofar,therehavebeenseveralproposalsthatincorporatecontext-sensitivityintoPCFGs.However,exceptforCharniakandCarroll'sCharniak94bpseudoprobabilisticcontext-sensitivegrammars,noEMalgorithmshavebeenpresentedforsuchextensionsofPCFGs.Inthissection,toshowAdvantage~3oftheproposedmethodthatitcoverspolynomial-timeEMalgorithmsforvariousextensionsofPCFGs,weselectKitaet~al.'sKita94rulebigrammodelsandpresenttheirpolynomial-timeEMalgorithm.</section>
  <subsection title="The rule bigram models">First,weconcentrateonleftmostderivationsasinthecasewithPCFGs.Then,relaxingtheassumptioninPCFGsthatproductionrulesarechosentotallyindependently,weassumethatrulesarechosendependingontheoneatthelastchoice.Bythisrelaxation,wecanaddsomecontext-sensitivity,whichisnotcoveredbyPCFGs,intotherulebigrammodels.Underthisassumption,thegenerativeprobabilityofruleapplicationsiscomputedasHere,#isthemarkerthatindicatesasentenceboundary,and(rr')isaparameterassociatedwitheachrulerR(r'R#),inwhich_:(A)R(Ar)=1holdsforAandrR#.InKita94,givenanunbracketedcorpus=_1,,_N,aparameter(r_k|r_k-1)isre-estimatedasHere,forruleapplications,(r,r';)indicatesthenumberofoccurrencesofr'justafterrin.Fromthisdefinition,_r'R(r,r';)=(r;)obviouslyholds.However,similartoEqs.~andandinlightoftheoriginaldefinition,theformulaforre-estimationisderivedasfollows(m=1,2,):&amp;^(m+1)(r_k|r_k-1):=&amp;(					_=1^N							_(_)					P(|^(m))(r_k-1,r_k;)			P(_|^(m))			)	/	(			_=1^N							_(_)					P(|^(m))					(r_k-1;)			P(_|^(m))		)	..alignBythere-estimationinEq.~,wecanachieve(local)maximumlikelihoodestimation,butobviouslyEq.~isnotfeasible,as|()|isgenerallyexponentialin||.</subsection>
  <subsection title="Graphical EM algorithm applied to the rule bigram models">Toderiveapolynomial-timeEMalgorithmfortherulebigrammodels,whosere-estimationisequivalenttoEq.~,weexploitthegeneralityoftheproposedmethod.Beforemovingfurther,weintroducesomenotations.Wefirstconsidertheleftmostderivationofasentenceasfollows:InEq.~,ristheruleappliedjustbeforeAisexpanded,andr'isthelastruleappliedinapartialderivationA_d,d'.Consideringrandr'asthecontext,thesubtreethatgoverns_d,d'islabeledasA(d,d'|r,r').Werefertoruler'by(A,d,d';),andruler'',whichisappliedjustafterr,byAr.Intherulebigrammodels,wechooseArwithprobability(A|r).Wealsodefine(A,d,d';)(A,d,d';)(),thesetofthelastappliedrulesinderivingasubtreeA(d,d')whileisbeinggenerated.Now,wepresentanEMalgorithmwheretheCYKparserisadoptedintheproposedmethod.Inthiscase,nochangeisrequiredfortheCYKparser.Furthermore,sincethebasiccontrolflowofthegEMalgorithmcanremainthesame,theonlypartweneedtoworkoutistheroutineforextractingsupportgraphs.Forexample,wehavethefollowinglogicalrelation_fort2inFigure~:&amp;_(VP(1,5	ADV急いで,;V見た))=&amp;;			VPPP;V			急いで;,;		PP(1,4			VPPP;V,;Pを),;		V(4,5			Pを,;			V見た)	.;	align*Here,asubtreelabelA(d,d')isliterallyspecializedintoA(d,d'|r,r')byapairr,r'whereristheruleappliedjustbeforethecorrespondingpartialderivationA_d,d'occurs,andr'isthelastappliedruleinthepartialderivation.Intheproposedmethod,context-sensitivityistypicallyincorporatedbyliteralspecializationofsubtreelabels,asabove.Figure~and,respectively,showthesupport-graphextractionroutineExtract-CYK-RBtailoredfortherulebigrammodels,anditsrecursivesubroutineVisit-CYK-RB.ThesubroutineVisit-CYK-RB(,r,A,d,d')visitsthesubtreeA(d,d')intheparsetreeof_,andadds(A,d,d';_)intoaglobalarrayvariable[A(d,d')]..Thatis,itrecomputes[A(d,d')]forthecallswithdifferentr's.WhatremainsistomodifythegEMalgorithmslightly.Morespecifically,wefirstreplaceA,(A)and[A]withAr,(A|r)and[A|r],respectively.ThenwewraptheforeachloopsatLines~andinGraphical-EMandLine~inGet-Expectationsbythe``foreachrR''loop.Next,weevaluatetheworst-casecomplexityoftheEMalgorithmfortherulebigrammodels.Considering,theworse-casecomplexityisO(||^12L^3N).suchthat0d&lt;d'Landd+2d',andr,r'R,wehavethefollowingsupportsubgraphforA(d,d'|r,r'):[_(A(d,d'|r,r'))=					ABCr,;B(d,d''|ABC,r''),;C(d'',d'|r'',r')			;|		.	,]andA(d,d'|r,r')appearsinO_(=1N).Then,itisobviousthat|_()|=O(||^2L|R|).Inaddition,O_isanorderedsetofthemembersinasubsetofA(d,d'|r,r');|;	A,;0d&lt;d'L,;r,r'R,wehave|O_|=O(||L^2|R|^2).Sobydefinitionwehave_num=O(||^3L^3|R|^3)and_maxsize=O(1).Finally,consideringthecasewithR=,theworst-casecomplexityofthegEMalgorithmisO(||^3L^3||^3N)=O(||^12L^3N).Thiscomputationalorderisquitelarge,butisstillcubicinsentencelengthL.Furthermore,thesignificantgapbetweentheworst-casecomplexityandtheactualcomputationtimeshowninSection~alsoseemsapplicabletotherulebigrammodels.Indeed,reportedthat,withahand-craftedCFGinSection~,theproposedmethodfortherulebigrammodelsonlyrunsabout1.5timesslowerthanthatforPCFGs.</subsection>
  <section title="Related work">Intheliterature,severalprobabilisticparsershavebeenproposed,e.g.,Magermanand'sMagerman91Pearl;itssuccessor,MagermanandWeir'sMagerman92Picky;andStolcke'sStolcke95probabilisticEarleyparser.However,mostprobabilisticparsers(exceptStolcke's)assumeasinputanunderlyinggrammarGtogetherwithparameters,anddonotconsiderhowtotraintheparameters.AsEMtrainingmethodsforPCFGsnotinCNF,Kupiec'sKupiec92methodandStolcke'sprobabilisticEarleyparserhavebeenproposed.Kupiec'smethodfirstconsidersPCFGsasrecursivetransitionnetworks,andtrainsthemonanextendedtrellisdiagram.Kupiec'smethodandtheI-Oalgorithmaresimilarintheirtop-downapproach.WFSTsexploitedintheproposedmethodareessentialandwell-knowninCFG-basedparsingmethods,sotheproposedmethodseemsconceptuallysimplerthanKupiec'smethod,whichusesanextendedtrellisdiagram.ForPCFGswithneitherrulenorcyclicproductionAA,Stolcke's(1995)methodisequivalenttotheproposedmethod,inwhichtheEarleyparserandthegEMalgorithmarecascaded(Appendix~).Therefore,forsuchPCFGs,theproposedmethodisageneralizationofStolcke'smethod.Inaddition,StolckedidnotmentionanytrainingmethodforextensionsofPCFGs.ItisaninterestingfutureworktoextendittoworkforPCFGswithrules,cyclicproductions,orboth.proposedamethodthatsimultaneouslylearnsthestructureandparametersofagrammar,fromapartiallyorfullybracketedcorpus.Theyalsoshowedempiricallythatthequalityofthegrammarstructureandparameterslearnedbytheirmethodissignificantlyimprovedcomparedtothoselearnedfromthecorrespondingunbracketedcorpus.Intheproposedmethod,itispossibletotrainPCFGsfrompartiallyorfullybracketedcorpora,justbyusingaparserthatoutputsparsetreessatisfyingtheconstraintsfromthebrackets.ThissimplicitycomesfromapropertywherebyweonlyneedtheWFSTforEMlearning.ThecomplexityoftrainingPCFGsfromafullybracketedcorpusintheproposedmethodisO(||^3LN),whichisthesameasthatofPereiraandSchabes'smethod.(_)|	=O(|||_|)=O(||L).Sincethenumberofpossibled'''sinEq.~thatareconsistentwith(_)isatmostone,|_(A(d,d'))|=O(||^2)holdsforeach=1N.Therefore,wehave_num=O(||^3L)bydefinition(Eq.~),andalsohave_maxsize=O(1)asdiscussedbefore.Consequently,thecomplexityofre-estimationinthegEMalgorithmisO(||^3LN).Inthispaper,wehaveassumedthatanunderlyingCFGisgiven.However,automatedlearningofthegrammarstructure,orgrammarinduction,isanimportantresearchtopic,sinceitisquitecostlyforahumantowriteprecisegrammars.Forinstance,givenasetofnonterminalsandasetofterminals,LariandYoungproposed,first,toruntheI-Oalgorithmwiththeruleset(,),andsecond,toremovetheruleswhoseprobabilitiesaresufficientlysmall.PereiraandSchabes'sPereira92method,whichhasbeenmentionedbefore,canalsobeunderstoodasamethodforgrammarinductionfrombracketedcorpora.OnetypicalprobleminsuchEM-basedapproachesisthattheyonlyfindalocalmaximumlikelihoodestimate,andhencethequalityofthelearnedgrammarheavilydependsontheinitialparameters.Againstthisproblemoflocality,therehavebeenproposalsintraininghiddenMarkovmodels(HMMs),suchasthesuccessivestatesplitting(SSS)algorithmandastructurallearningmethodbasedonmodelselectioncriteria.Thesemethodsseparatetheentirelearningprocessintotwosteps,trainingparametersandexploringthemodelstructure,andrunsthesetwostepsalternately.WhenoneextendsthesemethodstothestructurallearningofPCFGs,asamodel(grammar)structureisgivenintheparametertrainingstep,theproposedmethodwilleffectivelyacceleratethelearning.ThegEMalgorithmwasoriginallyproposedbyforaprobabilisticlogicprogramminglanguagecalledPRISM.PRISM'ssemanticbasisisthedistributionsemantics,whichisaprobabilisticextensionoftheleastmodelsemanticsinlogicprograms.TheoriginalproposalcascadesOLDT(OrderedLinearresolutionforDefiniteclauseswithTabulation)andthegEMalgorithm.Inthispaper,wereplaceOLDTbyaCFGparserwithafocusontrainingPCFGsandtheirextensions.AlthoughOLDTisagenerictop-downsearchtechniquethatisapplicabletoparsing,theGLRparserrunsfasterforpracticalgrammars,thankstopre-compilationofCFGsintoLRtablesanditsbottom-upsearchstrategy.Inbothcases,sincetheextractedsupportgraphsarethesame,thetimespentonthegEMalgorithmisalsothesame.</section>
  <section title="Conclusion">Inthispaper,weproposedagenericmethodfortrainingtheparametersinPCFGsfromunbracketedcorpora,undertheassumptionthattheunderlyingCFGisgiven.TheproposedmethodimprovestheI-Oalgorithmongeneralityandefficiency(withpracticalunderlyingCFGs)atthesametime.TheproposedmethodseparatestheentiretrainingprocessintoparsingandEMlearning.Thatis,itextractstheparseinformationfromtheWFSTstoredintheparserandexploitstheextractedinformation,whichisoftencompact,inEMtraining.Usingthisdesign,theproposedmethodovercomestheefficiencyoftheI-Oalgorithm,whichsuffersfromitstop-downnature.Anytechniquethatimprovesparsingefficiencywouldacceleratetheproposedmethod.Weimplementedtheproposedmethodandconfirmedthat,givenahand-craftedJapanesegrammar,itrunssignificantly(onethousandtimesattheaveragesentencelength)fasterthantheI-Oalgorithm.Basedonthegeneralityoftheproposedmethod,wealsoderivedapolynomial-timeEMalgorithmforCFGswithcontext-sensitiveprobabilities(i.e.,therulebigrammodels)andshowedthattheproposedmethodcancoverpreviousmethodssuchasPereiraandSchabes's(1992)methodandStolcke's(1995)probabilisticEarleyparsers.Inthefuture,wewouldliketoconductfurtherexperimentswithsomeextensionsofPCFGsandworkforgrammarinductionusingtheproposedmethod.Also,thereisaninterestingopenproblemtoderiveanEMalgorithmfortheprobabilisticGLRmodelrecentlyreformulatedby.revisedversionoftheATRdialoguecorpusandtheJapanesegrammarusedintheexperimentswereprovidedbytheTanaka-TokunagaLaboratoryatTokyoInstituteofTechnology.Wearedeeplygratefulfortheircooperation,andspecialthanksgotoKiyoakiShiraiattheTanaka-TokunagaLaboratoryforofferingdetailedinformationonthecorpusandthegrammar,anauxiliaryprogramforpreprocessing,andsomekeypapersintheliterature.WealsothankNobuhisaUedaforhisinsightfulcommentsfromtheearlystageofthework.TheworkissupportedinpartbytheDiscoveryScienceproject,promotedbyGrant-in-AidforScientificResearchonPriorityAreas~(A).</section>
  <section title="Justification of the graphical EM algorithm">Inthissection,weroughlyshowthatFujisakiet~al.'s(1989)method,theI-OalgorithmandthegEMalgorithmoutputthesametrainedparameters,fromthesameinitialparametersandunderthesameconvergencecriterion.Forthispurpose,weonlyneedtoshowthatthesethreemethodsgivethesameexpectedrulecount[A]foranyrule(A)R.AsseeninSection~,theexpectedrulecountscomputedbyFujisakiet~al.'smethodareequaltothosecomputedbytheI-Oalgorithm,soitissufficienttoshowthattheexpectedrulecountscomputedbythegEMalgorithmareequaltothosecomputedbyFujisakiet~al.'smethod.First,weconsiderrecursivetraversaloverasupportgraph_,whichisdescribedinSection~.Inwhatfollows,thestarting(resp.ending)nodeinthesubgraphofiscalled``'sstarting(resp.ending)node.''Now,weconsiderthetraversalsinwhichwecollecttherulelabelsassociatedwithbasicnodes,andfocusonsomebasicnodevassociatedwithAinasupportgraph_.Also,supposethatvisincludedinasubgraphof,andletEbethelocalpathinwhichvappears.ThissituationisdepictedinFigure~.Then,weconsiderallpossiblerecursivetraversalsinwhichwestartfromS(0,n_)'sstartingnodeandpassthroughv.NoteherethatS(0,n_)isthefirstelementofO_.Wedenoteby(v,_)thesetofsequencesoftherulelabels(ruleapplications)collectedinsuchtraversals(obviously(v,_)(_)).Wefurtherintroducesomenotations.Let_1bethesequenceoftherulelabels(partialruleapplications)collectedinapartialrecursivetraversalfrom'sstartingnodeto'sendingnodethroughthelocalpathEconsideredabove.Alsolet_0beasequenceoftherulelabelscollectedinapartialtraversalfromS(0,n_)'sstartingnodetoanintermediatenodeuwhichisassociatedwith(Figure~),and_2beasequenceoftherulelabelscollectedinapartialtraversalfromutoS(0,n_)'sendingnode.Here,welet(v,_)=_1andobtaintheset(v,_)ofpossiblepairsof_0and_2byvaryinguabove.Then,(v,_)definedabovecanbeseenasaCartesianproductof(v,_)and(v,_).FromthedefinitionsaboveandtheindependenceassumptioninPCFGs,wehave:_'(v,_)P(')&amp;=	__0,_1,_2(v,_)	P(_0,_1,_2)&amp;=	__1(v,_)	__0,_2(v,_)	P(_1)P(_0,_2)&amp;=	(	__1(v,_)	P(_1)	)	(	__0,_2(v,_)	P(_0,_2)	)align*ExaminingrecursivelyhowandarecomputedintheroutineGet-Inside-Probs,weseethat[,,E]=__1(v,_)P(_1).Similarly,examiningrecursivelyhowiscomputedinGet-Expectations,itcanbeseenthat[,]=__0,_2(v,_)P(_0,_2).Asaresult,wehave[,][,,E]=_'(v,_)P(').Wethenseethatthevalueaccumulatedinto[A]atLine~inGet-Expectationsisequalto1P(_)_'(v,_)P(').Disregardingtheorderofcomputations,thegEMsubstantiallyrepeatsthecomputationaboveforeachbasicnodevassociatedwithA,andforeachsupportgraph_(=1N).Theexpectedrulecount[A]isfinallycomputedas:Now,letusconsiderarecursivetraversalfromS(0,n_)'sstartingnode,andletbeasequenceoftherulelabels(ruleapplications)collectedinthetraversal.Then,thenumberofbasicnodesAwevisitinthetraversalisexactly(A,)inournotation.Sointhesummation_v:;A;is;attached;_'(v,_),asequence(_)ofruleapplicationsistakenintoaccountfor(A,)times.ThisimmediatelyimpliesthatEq.~isequivalenttoFujisakiet~al.'sformula(Eq.~).Fromthediscussionsabove,wecanconcludethatFujisakiet~al.'smethod,theI-Oalgorithm,andthegEMalgorithmareequivalenttoeachother.</section>
  <section title="Relation to Stolcke's probabilistic Earley parser">Inthissection,weroughlyrelateStolcke'sprobabilisticEarleyparser~andtheproposedmethodwhentheEarleyparserandthegEMalgorithmarecascaded.First,webrieflydescribetheprobabilisticEarleyparser.</section>
  <subsection title="Probabilistic Earley parser">TheEarleyparseranalyzesaninputsentence_basedonthesetI_ofitems.Eachitemisintheformd'dA.andindicates(i)_0,d'^()=w_1^()w_d'^()hasbeenanalyzed,(ii)thephrasegovernedbyanonterminalAstartsfromthepositiond,(iii)AisexpandedbytheruleA,andanalysishasbeenconducteduntilthepointindicatedbythedotsymbolontherighthandside.Stolcke's(1995)probabilisticEarleyparserisanaturalextensionoftheEarleyparser,whereeachitemd'dA.isassociatedwithitsinsideprobabilityd'dA..Fromnowon,werefertosuchanitemasd'dA.(i.e.,ashorthandofd'dA.).Theinsideprobabilityd'dA.isthesumofprobabilitiesofthederivationpathsfromanitemddA.toanotheritemd'dA.~.Intheparser,theinsideprobabilitiesarecomputedbythreeoperations:InEMlearning,werequiretheoutsideprobabilityd'dA.foranitemd'dA.~.Thisprobabilityisthesumofprobabilitiesofthepathswherewe(i)startfromtheinitialitem00.S,(ii)generate_0,d^(),(iii)passthrough_dA.forsome,(iv)generate_d',n_^()startingfrom_d'A.,and(v)finishwithn_0S.~.Theoutsideprobabilitiesareobtainedby:Weinitializetheoutsideprobabilityasonefortheitemn_0S.,andaszerofortheotheritems.Afterhavingcomputedallinsideandoutsideprobabilities,wecomputetheexpectedrulecountsbyEq.~andre-estimatetheparametersusingEq.~,aswiththeI-Oalgorithm.</subsection>
  <subsection title="Support graphs for the probabilistic Earley parser">ToimplementtheprobabilisticEarleyparser,wereplaceExtract-CYKbyExtract-Earley(Figure~)inthemainroutine(Figure~).WealsoshowthesubroutineVisit-EarleycalledfromExtract-EarleyinFigure~.Inthiscase,weneednotmodifytheroutinesforthegEMalgorithm.Basedontheroutineforoutputtingthefullparsetrees,Extract-Earleygeneratessupportgraphs_=O_,_(=1N).Each_takesthefollowingform:_(ddB.)&amp;=B,	_(d'dAw_d'^().)&amp;=			(d'-1)dA.w_d'^(),	_(d'dAB.)&amp;=															(d''dA.B),;						(d'd''B.)							&amp;|;					dd''&lt;d',					(d'd''B.)I_				.	alignInthegEMalgorithm,computingtheinsideprobabilitiesforasupportsubgraphinEq.~correspondstothePredictionoperationintheprobabilisticEarleyparser.Similarly,computingtheinsideprobabilityforEq.~correspondstotheScanningoperation,andcomputingtheinside(resp.outside)probabilityforEq.~correspondstotheCompletion(resp.ReverseCompletion)operation.Last,computingtheexpectedrulecountsforEq.~correspondstoEq.~.Now,weevaluatethecomplexityofthegEMalgorithmforthesupportgraphsabove.Regardingtimeconsumption,thecomputationrelatedtothesupportsubgraphsinEq.~occupiesthelargestpart.GivenanunderlyingCFGinCNF,thetotalnumberofnodesinsuchsupportsubgraphsisobtainedasO(|R|L^3)byconsideringallpossiblerulesandwordpositions(d,d',andd''),whereRistherulesetandListhemaximumsentencelength.WhenR=,theworse-casecomplexityofthegEMalgorithmisO(||^3L^3),whichisthesameasthatoftheprobabilisticEarleyparser.Here,weconsiderthecasewithanunderlyingCFGnotinCNF,andletmbethemaximumnumberofsymbolsontherighthandsideofarule.Then,thecomplexityofthegEMalgorithmcascadedafteraparser,e.g.,theGLRparser,withWFSTsoftheforminEq.~isO(L^m+1).Ontheotherhand,whencascadedaftertheEarleyparser,thecomplexityturnsouttobeO(L^3),i.e.,itdoesnotdependonm.However,theGLRparserhassomeadvantagessuchaspre-compilationofCFGstoLRtablesanditsbottom-upsearchstrategyovertheEarleyparser,andhenceitseemsworthchoosinganappropriateparserdependingonthetargetgrammar.document</subsection>
</root>
