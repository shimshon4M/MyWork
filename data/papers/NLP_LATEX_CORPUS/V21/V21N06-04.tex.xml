<?xml version="1.0" ?>
<root>
  <jtitle>日本語形態素解析における未知語処理の一手法—既知語から派生した表記と未知オノマトペの処理—</jtitle>
  <jauthor>笹野遼平黒橋禎夫奥村学</jauthor>
  <jabstract>本論文では，形態素解析で使用する辞書に含まれる語から派生した表記，および，未知オノマトペを対象とした日本語形態素解析における効率的な未知語処理手法を提案する．提案する手法は既知語からの派生ルールと未知オノマトペ認識のためのパターンを利用し対象とする未知語の処理を行う．Webから収集した10万文を対象とした実験の結果，既存の形態素解析システムに提案手法を導入することにより新たに約4,500個の未知語を正しく認識できるのに対し，解析が悪化する箇所は80箇所程度，速度低下は6%のみであることを確認した．</jabstract>
  <jkeywords>形態素解析，未知語処理，オノマトペ</jkeywords>
  <section title="はじめに">日本語形態素解析における誤り要因の1つに辞書に含まれない語・表記の存在がある．本論文では形態素解析で使用する辞書に含まれない語・表記をまとめて未知語と呼ぶ．形態素解析における未知語は表に示すようにいくつかのタイプに分類することができる．まず，未知語は既知語から派生したものと，既知語と直接関連を持たない純粋な未知語の2つに大きく分けられる．従来の日本語形態素解析における未知語処理に関する研究は，事前に未知語をコーパスから自動獲得する手法と，未知語を形態素解析時に自動認識する手法の2つに大きく分けることができるが，いずれの場合も網羅的な未知語処理が目的とされる場合が多く，特定の未知語のタイプに特化した処理が行われることは稀であった．しかし，未知語はタイプにより適切な処理方法や解析の難しさは異なっていると考えられる．たとえば既知語から派生した表記であれば，それを純粋な未知語として扱うのではなく既知語と関連付けて解析を行うことで純粋な未知語よりも容易に処理することが可能である．また，一般的に純粋な未知語の処理は，単独の出現から正確に単語境界を推定するのは容易ではないことから，コーパス中の複数の用例を考慮し判断する手法が適していると考えられるが，オノマトペのように語の生成に一定のパターンがある語は，生成パターンを考慮することで形態素解析時に効率的に自動認識することが可能である．さらに，節で示すように，解析済みブログコーパスで複数回出現した未知語で，先行手法やWikipediaから得た語彙知識でカバーされないものを分析した結果，既知語から派生した未知表記，および，未知オノマトペに対する処理を行うことで対応できるものは異なり数で88個中27個，出現数で289個中129個存在しており，辞書の拡張などで対応することが難しい未知語の出現数の4割程度を占めていることが分かった．そこで本論文では既知表記から派生した未知表記，および，未知オノマトペに焦点を当て，既知語からの派生ルールと未知オノマトペ認識のためのパターンを形態素解析時に考慮することで，これらの未知語を効率的に解析する手法を提案する．</section>
  <section title="日本語形態素解析"/>
  <subsection title="日本語形態素解析の一般的な流れ">日本語形態素解析では，形態素辞書の存在を前提とした手法が一般的に用いられてきた．以下に一般的な日本語形態素解析の手順を示す．たとえば以下の文が入力された場合，図に示す形態素ラティスが作られ，最終的に太線で記されている組合せに決定される．父は日本人。exe手順1において，文中の各位置から始まる可能性のある形態素を探索する際にはトライ木に基づく高速な探索手法が一般的に用いられる．また，手順3における最尤パスの選択は各形態素ごとに定義された生起コスト，および，各連接ごとに定義された連接コストに基づいて行われる．パス全体のコストは，パスに含まれる形態素の生起コスト，および，それらの連接コストを加算することにより計算され，コストが小さいほど確からしい形態素の並びであることを意味する．コストの設定方法としては人手で行う方法や，機械学習に基づく手法があるが，最尤パスの探索にはいずれもViterbiアルゴリズムが用いられる．</subsection>
  <subsection title="形態素解析における未知語処理">日本語形態素解析における未知語処理に関する研究は多く行われてきた．代表的な手法として，事前に未知語をコーパスから自動獲得する手法と，未知語を形態素解析時に自動認識する手法の2つが挙げられる．前者の手法は後者の手法と比べ，ある1つの未知語候補に対しコーパス中での複数の用例を考慮することができるため，単独の用例では判別の難しい未知語にも対処できるという特長がある．一方，後者の手法は字種や前後の形態素候補を手掛かりとして統計や機械学習に基づく未知語モデルを構築する手法であり，コーパス中に出現しなかった未知語についても認識が可能という特長がある．しかしながら，これらの研究はいずれも基本的に網羅的な未知語処理を目的としており，未知語タイプごとの特徴はあまり考慮されていない．特定の未知語，特にくだけたテキストに出現する未知語に特化した研究としては，風間ら，Kacmarcikら，池田ら，工藤ら，斉藤らの研究がある．風間らKazama1999は，Web上のチャットで使用されるようなくだけたテキストの解析を目的とし，品詞bi-gramモデルに基づく確率的形態素解析器をベースとし，文字の挿入や置換が直前の文字や元の文字に依存していると仮定しそれを考慮に入れるように拡張することで，文字の挿入や置換に対して頑健な形態素解析システムの構築を行っている．しかし，池田らIkeda2010が，風間らの手法を参考に辞書拡張ルールを作成し，200万文のブログ文書に適用して単語区切りに変化が見られた53,488文をサンプリングし評価したところ，37.2%の文はルール適用前と比べて単語区切りが悪化したと報告していることから，風間らの手法はオンラインチャット，および，それに類するテキストにのみ有効な手法であると推察される．本研究で提案する既知語から派生した未知語処理手法も，基本的に風間らと同じくルールに基づくものであるが，未知語のタイプに応じた効率的な辞書の検索を行うことで，高い精度を保ちつつ高速な解析を実現している点に特長がある．KacmarcikらKacmarcik2000は形態素解析の前処理としてテキスト正規化ルールを適用する手法を提案している．池田らIkeda2010はくだけた表現を多く含むブログなどの文書を入力とし，くだけた表現の少ない新聞などの文書からくだけた表現の修正候補を検索することで修正ルールを自動的に生成し，さらに生成した修正ルールを3つの言語的な指標によりスコアリングすることで文脈に適した修正ルールを選択する手法を提案している．これらの研究ではいずれも前処理として入力テキストを正規化・修正しているのに対し，本研究では形態素解析と並行して未知語処理のためのルール・パターンを適用する．このような設計により，従来手法では処理が難しかった連濁化現象により初音が濁音化した語の認識も可能となる．工藤らKudo2012は，ひらがな交じり文が生成される過程を生成モデルでモデル化し，そのパラメータを大規模WebコーパスおよびEMアルゴリズムで推定することで，Web上のくだけたテキストに頻出するひらがな交じり文に頑健な形態素解析手法を提案している．工藤らの手法は必ずしもひらがな交じり文にのみ有効な手法ではなく，本研究で対象とする小書き文字や長音記号を用いた表現に適用することも可能であると考えられるが，本研究ではこれらの表現に対してはコーパスを用いた学習を行わなくても十分に実用的な精度で処理を行うことが可能であることを示す．斉藤らSaito2013,Saito2014はソーシャルメディア上のテキストから抽出した崩れ表記に対し正規表記を付与した正解データを用いて文字列レベルの表記の崩れパターンを自動抽出する手法を提案している．これに対し，本研究では人手でパターンを与える．正解データを用いてパターンを自動抽出する手法の利点としてはパターンを人手で作成する必要がないことが挙げられるが，人が見た場合に明らかなパターンがあった場合でも一定規模の正解データを作成する必要があり，どちらの手法が優れているかは崩れ表記のタイプにより異なると考えられる．教師なし単語分割や形態素解析に関する研究もテキストに出現する未知語処理の1つのアプローチとみなすことができる．また，くだけたテキストに出現する表記バリエーションに対処する方法として，形態素解析に使用する辞書にこれらの表記バリエーションを追加するという方法も考えられる．たとえば，連濁による濁音化も含む多くの表記バリエーションに対応した形態素解析用の辞書としてUniDicがあり，このような辞書を用いることで未知語の数を減らすことが可能であると考えられる．しかし，長音記号は任意の数を挿入することが可能であることからも明らかなように，表記バリエーションの種類は無数に考えられ，すべてを辞書に含めることは不可能である．また，連濁により濁音化した形態素を高精度に認識するためには，直前の形態素の品詞等を考慮する必要があることから，連濁の認識を辞書の改良だけで行うことは難しいと考えられる．</subsection>
  <section title="提案手法"/>
  <subsection title="提案手法の概要">本論文では主に形態素ラティスの生成方法の改良により，形態素解析で使用する辞書に含まれる語から派生した未知表記，および，未知オノマトペを対象とした日本語形態素解析における効率的な未知語処理手法を提案する．具体的には既存の形態素解析システムに，既知語から派生した未知表記に相当する形態素ノードを生成するためのルール，および，未知オノマトペに相当する形態素ノードを生成するためのパターンを導入することで，これらのタイプの未知語の自動認識を行う．たとえば，下記のような文が入力された場合，図で実線で示したノード・経路に加え，新たに破線で示した未知語に相当するノード，および，それを経由する経路を追加し，新たに生成された形態素ラティスから最適な経路を探索することで，下記の文の正しい形態素解析を実現する．ぉぃしかったでーーす。exe本研究では，比較的単純なルールおよびパターンのみを考慮し，さらに，辞書を用いた形態素検索の方法を工夫することで，解析速度を大きく低下させることなく，高精度に一部の未知語の処理が可能であることを示すことを主な目的とする．このため，本研究で使用するルールやパターン，および，置換ルールやオノマトペ認識の対象とする文字種の範囲は，現象ごとにコーパスを分析した結果に基づき，解析結果に大きな悪影響が出ない範囲で出来る限り多くの未知語を解析できるよう人手で定めたものを使用する．同様に，各ルールやパターンを適用するためのコストに関しても，機械学習等により最適な値を求めることは行わず，人手で調整した値を使用し，ベースラインとする形態素解析システムには，各形態素の生起コストや連接コストの調整を人手で行っているJUMANを用いる．</subsection>
  <subsection title="既知形態素から派生した未知語の自動認識"/>
  <subsubsection title="対象とする未知語">本研究では既知形態素から派生した未知語として以下の5つのタイプの未知語を扱う．連濁により濁音化した語長音記号による置換を含む語小書き文字による置換を含む語長音記号の挿入を含む語小書き文字の挿入を含む語以下では，連濁による濁音化，長音記号および小書き文字による置換，長音記号および小書き文字の挿入の3つに分けて，対象とする未知語の詳細，および，それぞれどのようにノードを追加するかについて詳述する．</subsubsection>
  <subsubsection title="連濁による濁音化">連濁とは複合語の後部要素の初頭にある清音が濁音に変化する現象のことを指す．連濁現象により濁音化した形態素表記の多くは辞書に登録されていないため，形態素解析において未知語として扱われる場合が多い．たとえば以下のような文が入力された場合，「こたつ」という表記が辞書に含まれていたとしても，「ごたつ」が辞書に登録されていないと「ごたつ」を1形態素として正しく認識することができない．掘りごたつ。exeそこで，初頭が清音である名詞については，初頭の清音が濁音化したものも形態素候補として形態素ラティスに追加する．この際，1つの元となる形態素に対し濁音化した形態素はたかだか1つであることから，濁音化した形態素をあらかじめ形態素辞書に追加することにより，通常のトライ木に基づく形態素の探索の枠組みで濁音化した形態素候補をラティスに追加する．ただし，連濁は複合語の後部要素にのみ生じる現象であり，さらに，連濁は複合語の後部要素であれば必ず起こるわけではなく表に示すような連濁の発生を抑制する要因が知られていることから以下の制約を課す．直前の形態素が名詞，動詞の連用形，名詞性接尾辞の場合のみ濁音化	したノードを使用代表的な表記がカタカナを含む形態素は濁音化の対象としない	形態素がもともと濁音を含んでいる場合は濁音化の対象としない	新たに生成された濁音化した形態素の生起コストは，その元となった形態素の生起コストよりも大きく設定した．具体的なコストの設定方法については付録に記載した．本研究では，濁音化した形態素をはじめとする未知語の生起コストを通常の形態素の生起コストよりも意図的に大きめに設定している．これは未知語を含む文が新たに正しく解析できるようになることによるユーザの形態素解析システムへの評価の上昇幅よりも，通常解析できることが期待される文が正しく解析できない場合の評価の下落幅の方が大きいと考えたためである．</subsubsection>
  <subsubsection title="長音記号・小書き文字による置換">くだけたテキストでは，「おはよー」，「うらやまし〜」や「ぁなた」などのように形態素辞書中に含まれる語表記の一部が長音記号や小書き文字に置換された表現が出現する．このうち長音記号に置換される文字の多くは，「おはよう」の「う」や，「うらやましい」の「い」などのように直前の文字を伸ばした音に類似していると考えられる．そこで長音記号があった場合，入力文字に対し行う通常の形態素の検索に加え，長音記号をその直前の文字に応じて表に示す母音文字に置き換えた文字列に対しても形態素の検索を行い，検索された形態素を形態素ラティスに追加する．本研究では長音記号として「ー」と「〜」の2つを扱う．小書き文字があった場合も同様に対応する通常の文字に置き換えた文字列を作成し形態素の検索を行う．本研究では，「ぁ」，「ぃ」，「ぅ」，「ぇ」，「ぉ」，「ヵ」，および「ゎ」を置換対象とし，それぞれ「あ」，「い」，「う」，「え」，「お」，「か」，「わ」に置換する．たとえば「ぉぃしー。」という文があった場合，「おいしい。」という文字列に対しても形態素の検索を行い，新たに検索された形態素を「ぉぃしー」から生成された形態素ラティスに追加する．この際，長音記号および小書き文字は何らかの文字の置換により出現した場合だけでなく，以下で述べるように挿入された場合もあると考えられる．しかし，事前の分析の結果，同一形態素内で置換されたものと挿入されたものが混じって出現することは相対的に少ないことが分かったため，解析速度への影響を考慮し，これらの未知語は本研究では扱わない．また，長音記号・小書き文字の置換により新たに生成された形態素の生起コストの設定方法は，長音記号・小書き文字の挿入により生成された形態素の生起コストとともに付録に記載した．</subsubsection>
  <subsubsection title="長音記号・小書き文字の挿入">くだけたテキストでは，「冷たーーーい」や「冷たぁぁぁい」などのように形態素辞書中に含まれる語に長音記号や小書き文字が挿入された表現が出現する．これらの表記において，挿入される文字数は任意であることからこれらの表現をすべて辞書に登録することは難しい．そこで本研究では，長音記号・小書き文字の置換に対する処理と同様に，入力文字列に対し一定の処理を行った文字列に対し形態素の検索を行い，その結果を形態素ラティスに追加することにより，長音記号および小書き文字の挿入に対応する．具体的には，「ー」および「〜」が出現した場合，または，「ぁ」，「ぃ」，「ぅ」，「ぇ」，「ぉ」が出現し，かつ，その直前の文字が小書き文字と同一の母音をもつ平仮名であった場合に，それらを削除した文字列を作成する．たとえば「冷たぁぁーーい。」という文があった場合，「冷たい。」という文字列に対しても形態素の検索を行い，新たに検索された形態素を「冷たぁぁーーい。」から生成された形態素ラティスに追加する．</subsubsection>
  <subsection title="未知オノマトペの自動認識"/>
  <subsubsection title="未知オノマトペのタイプ">オノマトペとは「わくわく」，「しっかり」などのような擬音語・擬声語のことである．日本語では比較的自由にオノマトペを生成できることから特にくだけたテキストでは「ぐじょぐじょ」や「ぐっちょり」などのような辞書に含まれないオノマトペが多く出現する．本研究では多くの未知オノマトペが一定のパターンに従っていることを利用し，特定のパターンに従う文字列をオノマトペの候補とすることで未知オノマトペの自動認識を行う．ここで，オノマトペの品詞としては，副詞，サ変名詞，形容詞などが考えられるが，本研究ではオノマトペが必要以上に細かく分割されるのを防ぐことを主な目的とし，すべて副詞として処理する．以下では「ぐじょぐじょ」などのように反復を含むタイプと，「ぐっちょり」などのように反復を含まないものの2つに分け，それぞれどのようにノードを追加するか詳述する．</subsubsection>
  <subsubsection title="反復型オノマトペ">オノマトペの代表的なパターンの1つに「ぐじょぐじょ」や「うはうは」などのように，同じ音が2度反復されるパターンがある．そこで本研究では2文字から4文字までの平仮名または片仮名が反復されている場合，それらを未知オノマトペの候補として形態素ラティスに追加する．これらのオノマトペは入力文の各位置において，そこから始まる平仮名または片仮名n文字とその直後のn文字が一致しているかどうかを調べることで効率的に探索することが可能である．ただし，「むかしむかし」や「ぜひぜひ」などのように同音が反復された場合でもオノマトペではない表現も存在する．このため，追加された未知オノマトペノードが必要な場合にのみ選択されるように，追加したノードのコストを適切に設定する必要がある．本研究では，基本的に反復文字数ごとにコストを設定し，さらに濁音・半濁音や開拗音を含む表現はオノマトペである場合が多いこと，また，平仮名よりも片仮名の場合の方がオノマトペである場合が多いことを考慮し，コストを人手で設定した．実際に使用したコストは付録に記載した．</subsubsection>
  <subsubsection title="非反復型オノマトペ">反復を含まない場合もオノマトペは一定のパターンに従うものが多い．そこで本研究ではオノマトペを認識するためのパターンを導入し，導入したパターンに従う文字列を形態素候補として形態素ラティスに追加する．本研究で使用したパターンを表に示す．パターン中のH，K，H，Kはそれぞれ平仮名，片仮名，平仮名の開拗音字（「ゃ」，「ゅ」，「ょ」），および，片仮名の開拗音字（「ャ」，「ュ」，「ョ」）を表す．これらは事前にコーパスを分析した結果，出現頻度が高く，かつ，悪影響の少ないパターンである．いずれも2音節の語基を持ち，先頭の4つは2音節の間に促音を持ち「り」語尾が付いたもの，残りの3つは2音節に促音および「と」が付いたものとなっている．本論文ではパターンを導入することの有効性を確認することを目的とし，実験には表に示した7つのパターンのみを使用したが，さらに多くのパターンを導入することで，より多くのオノマトペを認識できると考えられる．また，コストは本研究で使用する形態素解析システムJUMANにおけるコストであり，一般的な副詞のコストを100とした場合の形態素生起コストを表している．非反復型オノマトペを含む形態素ラティスの生成にあたり，入力文の各位置から始まる文字列が表に示すパターンに一致するかどうか検索すると，形態素ラティスの生成速度が大きく低下する可能性が考えられる．そこで本研究では，表に示す各パターンから生成されうる形態素の数はたかだか4,761ないしは14,283であることに着目し，これらの候補をすべて事前に辞書に追加することで，通常のトライ木に基づく辞書検索により未知オノマトペのノードを形態素ラティスに追加できるようにした．</subsubsection>
  <subsection title="未知語処理の流れ">表に本研究で扱う未知語のタイプと，各未知語に相当するノードをどのように形態素ラティスに追加するかをまとめる．これらの未知語処理をすべて行った場合の形態素ラティスの作成手順は以下のようになる．形態素解析に先立ち，連濁により濁音化した形態素，および，非反復	型オノマトペの候補を形態素解析辞書に追加入力文に対し，形態素の検索を行い形態素ラティスを作成入力文中に出現した長音記号・小書き文字を節で述	べたルールに基づき置換した文字列に対し形態素の検索を行い，新た	に検索された形態素を形態素ラティスに追加入力文中に出現した長音記号・小書き文字を節で述	べたルールに基づき削除した文字列に対し形態素の検索を行い，新た	に検索された形態素を形態素ラティスに追加文字列比較により，入力文に含まれる平仮名または片仮名の2文字から	4文字までの反復を探し，存在した場合は形態素ラティスに追加</subsection>
  <section title="実験と考察"/>
  <subsection title="提案手法の再現率">提案手法の有効性を確認するため，まず，再現率，すなわち対象の未知語のうち正しく解析できる語の割合の調査を行った．すべての未知語をタグ付けした大規模なデータを作成するためには大きなコストが必要となることから，本研究では未知語のタイプごとに個別に対象の未知語を含むデータを作成し再現率の調査を行った．未知語のタイプを限定することで，正規表現等により対象の未知語を含む可能性のある文を絞り込むことができ，効率的にデータを作成できるようになる．具体的には，検索エンジン基盤TSUBAKIで使用されているWebページから，各未知語タイプごとに正規表現を用いて未知語を含む文の候補を収集し，そこから未知語を100個含む文集合を作成し，再現率の評価を行った．ただし，ここで使用した文集合には節で説明したルール・パターンの作成の際に参考にした文は含まれていない．結果をUniDicによるカバー率とともに表に示す．ここで，UniDicによるカバー率とは対象の未知語100個のうちUniDicに含まれている語の数を表している．実際にUniDicを用いたシステムにおいて対象の未知語を正しく解析できるかどうかは考慮していないため，UniDicによるカバー率はUniDicを用いたシステムが達成できる再現率の上限とみなせる．表に示した結果から，すべての未知語タイプに対し提案手法は高い再現率を達成できることが確認できる．連濁を除く未知語タイプにおいてはUniDicによるカバー率よりも高い再現率を達成していることから，考えうる多くの未知語を人手で登録するアプローチに比べ，既知語からの派生ルールと未知オノマトペ認識のためのパターンを用いる提案手法のアプローチは，低コストで多くの未知語に対応できると言える．一方，連濁により濁音化した語については正しく認識できた語の数はUniDicでカバーされている語の数よりも少なかった．たとえば以下の文に含まれている「がわら」は正しく認識することができなかった．赤がわらの民家です。exeこれは連濁と関係ない表現を連濁により濁音化したものであると認識しないように，連濁により濁音化した形態素のノードに大きなコストを与えているためである．たとえば以下のような文があった場合，連濁により濁音化した形態素のコストを元の形態素のコストと同程度に設定した場合は「でまわり」を「手回り」が濁音化したものと解析してしまうため，濁音化した形態素のノードには大きめのコストを与える必要がある．笑顔でまわりの人たちを幸せにする。exe続いて，実コーパスにおける再現率の評価を行うため，解析済みブログコーパスを用いた評価を行った．具体的には解析済みブログコーパスで1形態素としてタグ付けされている語のうち，2回以上出現し，かつ，JUMAN5.1の辞書に含まれていない230語を，村脇らによりコーパスから自動生成された辞書でカバーされているもの，それ以外でWikipediaにエントリを持つもの，それ以外で提案手法によりカバーされるもの，その他の4つに分類した．結果を表に示す．村脇らによる辞書，および，Wikipediaのエントリでもカバーされない未知語のうち異なり数でおよそ30%，出現数でおよそ45%が提案手法により解析できており，提案手法による未知語処理が実コーパスに対しても有用であることが確認できる．また，提案手法により解析できた未知語には，連濁による濁音化を除くすべての未知語タイプが含まれており，様々な未知語タイプが実コーパスにおいて出現することが確認できた．</subsection>
  <subsection title="解析精度・速度の評価">本論文で導入したルール・パターンを用いることで新たに認識された未知語の精度，および，解析速度の変化を調べるため，これらのルール・パターンを用いないベースラインモデルと提案手法を用いたモデルを以下の7つの観点から比較することにより提案手法の評価を行った．本節の実験ではJUMAN5.1をデフォルトのコスト設定のまま使用したものをベースラインモデルとした．解析結果が変化した100箇所中，解析結果が改善した箇所の数：P_100D解析結果が変化した100箇所中，解析結果が悪化した箇所の数：N_100D10万文あたりの解析結果が変化した箇所の数：D_100kS10万文あたりの解析結果が改善した箇所の推定数：P^*_100kS10万文あたりの解析結果が悪化した箇所の推定数：N^*_100kS形態素ラティスにおけるノードの増加率：N!ode_inc.解析速度の低下率：SP_loss実験には検索エンジン基盤TSUBAKIで使用されているWebページから収集した10万文を使用した．これらの文は平仮名を1字以上含み，かつ，全体で20文字以上で構成される文であり，節で説明したルール・パターンの作成の際に参考にした文は含まれていない．まず，P_100DとN_100Dを算出するため，各ルール・パターンを用いた場合と用いなかった場合で解析結果が変化した箇所を100箇所抽出し，それらを改善，悪化，その他の3クラスに分類した．この際，基本的に分割箇所が変化した場合は分割箇所の優劣を比較し，分割箇所に優劣がない場合で品詞が変化した場合はその品詞の優劣を比較した．ただし，形態素区切りが改善した場合であっても，名詞であるべき品詞が副詞となっている場合など，明らかに正しい解析と言えない場合はその他に分類した．たとえば「面白がれる」という表現は，JUMANでは子音動詞の可能形は可能動詞として登録されていることから，JUMANの辞書登録基準では1語となるべきである．しかし，連濁ルールを用いなかった場合は下記の例()aのように，連濁ルールを用いた場合は下記の例()bのように，解析結果は異なるものの，いずれの場合も過分割されてしまうことから，このような場合はその他に分類した．面/白/が/れ/る面/白/がれるxlistexeまた，P^*_100kS，および，N^*_100kSは，10万文あたりの解析結果が変化した箇所の数D_100kSを用いて，それぞれ以下の式により算出した．P^*_100kS&amp;=D_100kSP_100D/100N^*_100kS&amp;=D_100kSN_100D/100align*ここで，各未知語タイプごとに推定誤差は異なっていることに注意が必要である．特に解析が悪化した箇所の数は少なことからN^*_100kSの推定誤差は大きいと考えられる．しかしながら，各未知語タイプごとに大規模な評価を行うコストは大きいことから本論文では上記の式から算出された推定数に基づいて考察を行う．解析精度の評価に加えて，最適解の探索時間に影響を与えると考えられることから形態素ラティスにおけるノードの増加率N!ode_inc.，および，全体の解析速度への影響を調べるため速度の低下率SP_lossの計測も行った．これらの評価結果を表に示す．表に示す結果から提案手法を用いることで，ほとんど解析結果を悪化させることなく，また，解析速度を大きく下げることなく，多くの未知語を正しく処理できるようになることが確認できる．具体的には，すべてのルール・パターンを用いることで10万文あたり4,500個以上の未知語処理が改善するのに対し，悪化する解析は80個程度であると推定でき，速度の低下率は6.2%であった．速度の低下率に関してはベースラインとした形態素解析器の実装に大きく依存するため，具体的な数値に大きな意味はないと言えるものの，少なくとも提案手法は大幅な速度低下は引き起こさないと考えられる．また，ノードの増加率に対し解析速度の低下率が大きいことから，速度低下は最適パスの探索ではなく，主に形態素ラティスの生成の時間の増加により引き起されていると考えられる．以下ではルール・パターンごとの解析の変化について詳述する．</subsection>
  <subsubsection title="長音文字の置換">長音文字を置換するルールを導入することで解析結果が変化した例を表に示す．もともと正しく解析できていた表現がルールを導入することにより解析できなくなった例は存在せず，周辺の解析結果が悪化したものが「OKだよ〜ん」の1例のみ存在した．この例ではいずれも形態素区切りは誤っているものの，ベースラインモデルでは「だ」を判定詞であると解析できていたものが，提案手法を用いた場合は普通名詞であると解析されたため，解析結果が悪化したと判定した．</subsubsection>
  <subsubsection title="小書き文字の置換">小書き文字を置換するルールを導入することで解析結果が変化した例を表に示す．長音記号の場合と同様にもともと正しく解析できていた表現がルールを導入することにより解析できなくなった例は存在せず，周辺の解析結果が悪化したものが「ゆみぃの布団」の1例のみ存在した．この例でベースラインモデルでは格助詞であると正しく解析できていた「の」が，「いの」という地名の一部であると解析されたため，解析結果が悪化したと判定した．また，小書き文字を置換するルールを導入することで解析結果が改善した箇所の推定数は10万文あたり1,374箇所であり，全未知語タイプの中でもっとも多く，ほぼ悪影響もないことから，非常に有用なルールであると言える．</subsubsection>
  <subsubsection title="長音文字の挿入">挿入されたと考えられる長音文字を削除するルールを導入することで解析結果が変化した例を表に示す．長音文字の挿入に対処することで解析が悪化した例は存在せず，「苦〜い」や「ぜーんぶ」など多くの表現が正しく解析できるようになった．長音文字を削除するルールを導入することで解析結果が改善した箇所の推定数は10万文あたり1,093箇所であり，小書き文字の置換ルールに次いで多かった．解析結果が悪化した事例は確認できなかったことから，非常に有用性の高いルールであると言える．</subsubsection>
  <subsubsection title="小書き文字の挿入">挿入されたと考えられる小書き文字を削除するルールを導入することで解析結果が変化した例を表に示す．長音文字の挿入の場合と同様に小書き文字に対処することで解析が悪化した例は存在せず，「さぁん」や「でしたぁぁぁ」など小書き文字の挿入を含む表現が正しく解析できるようになった．</subsubsection>
  <section title="まとめ">本論文では，形態素解析で使用する辞書に含まれる語から派生した未知表記，および，未知オノマトペを対象とした日本語形態素解析における効率的な未知語処理手法を提案した．Webから収集した10万文を対象とした実験の結果，既存の形態素解析システムに提案手法を導入することにより，解析が悪化した箇所は80箇所程度，速度低下は6%のみであったのに対し，新たに約4,500個程度の未知語を正しく認識できることを確認した．特に，長音文字・小書き文字の置換・挿入に関するルールのみを導入した場合，10万文あたり推定3,327個の未知語を新たに解析できるようになるのに対し，悪化する箇所は推定27個であり，ほとんど解析結果に悪影響を与えることなく多くの未知語を解析できることが確認できた．今後の展望としては，各形態素の生起コストや連接コストを機械学習を用いて推定した形態素解析システムへの応用や，特に連濁現象への対処としてUniDicなどのように多くの表記バリエーションの情報が付与された辞書と組み合わせることなどが考えられる．</section>
  <section title="濁音化した形態素の生起コスト">濁音化した形態素の生起コストは，濁音化する前の形態素に付与されているコストに，次表に示すコストを加算することにより与える．濁音化する前の形態素のコストは表記ごとに与えられ，JUMAN5.1では名詞，動詞などといった内容語の多くは100，または，160のコストが付与されている．たとえば，動詞「座る」の平仮名表記である「すわる」のコストは100であるので，その連用形が濁音化した「ずわり」のコストは170，名詞「蚕」の平仮名表記である「かいこ」のコストは160であるので，「がいこ」のコストは270となる．ここで，``が''から始まる語に大きな加算コストを与えているのは，格助詞「が」を誤って濁音化した形態素の先頭であると解析されないようにするためである．</section>
  <section title="長音記号・小書き文字が置換・挿入された形態素の生起コスト">長音記号・小書き文字を置換・挿入することにより生成された形態素の生起コストは，置換・挿入前の形態素に付与されている生起コストに，次表に示すコストを加算することにより与える．ここで品詞コストとは，品詞ごとに定義されたコストであり，対象の品詞に属する形態素の標準的な生起コストを表している．JUMAN5.1のデフォルトでは判定詞の場合には11，感動詞の場合には110，動詞，普通名詞，形容詞，副詞には100，副詞的名詞には70などのコストが与えられている．たとえば，普通名詞「あなた」の生起コストが100，普通名詞の品詞コストが100であることから，「ぁなた」という形態素の生起コストは160，感動詞「もしもし」の生起コストは110，感動詞の品詞コストは110であることから，「もしも〜し」という形態素の生起コストは176となる．</section>
  <section title="反復型オノマトペの生起コスト">反復型オノマトペwの生起コストは以下の式により与える．[cost=LEN(w)130-f_v(w)10-f_p(w)40-f_k(w)20]ただし，とする．すなわち，基本的に繰り返し文字数1つにつき130のコストを与えるが，先頭の文字が濁点・半濁点を含む場合は20，それ以外の文字が濁点・半濁点を含む場合は10，開拗音を含む場合は40，片仮名である場合は20，それぞれコストを小さくする．これは，オノマトペは濁点・半濁点，開拗音を含む場合が多く，また，片仮名で表記されることが多いためである．たとえば，「ぐちょぐちょ」という形態素であれば，繰り返し音数は2で最初の文字が濁点を含みで，かつ，開拗音を含むので，生起コストは260から20と40を引いた200となる．</section>
  <section title="非反復型オノマトペの生成に使用した平仮名，片仮名の一覧">document</section>
</root>
