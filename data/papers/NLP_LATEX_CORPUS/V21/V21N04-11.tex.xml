<?xml version="1.0" ?>
<root>
  <section title="Introduction">Themainpurposeofinformationretrieval(IR)istorankdocumentssothatuserscanobtaininformationefficiently.However,appropriaterankingofdocumentsisdifficulttoachievethroughone-offretrievalsbecauseuserqueriesaretypicallyshortandambiguous.Forexample,thequery``Macprice''canbeinterpretedasthepriceofa``Mac''(PC),afooditemat``McDonalds,''orsomeother``Mac.''Ifwedonotknowwhat``Mac''refersto,wecannotrankthedocumentsinawaythatsatisfiesuserinformationneeds.Relevancefeedback(RF)isatechniquethatsolvesthisproblembyincorporatinguserfeedbackintotheIRprocess.ThebasicprocedureforRFisasfollows.TheRF-basedsystempresentstheinitialsearchresultsforagivenquery.Theuserselectssomerelevantdocumentsfromthesearchresults.Thesystemmodifiesthesearchresultsusingthisfeedback.Forexample,ifthesystemobtainsdocumentsaboutthepriceofa``Mac''(PC)asuserfeedback,itassumesthattheuserisinterestedinthistopicandmodifiestheinitialsearchresults.ThereareavarietyofRFmethodsbasedondifferentretrievalmodels.Rocchio'salgorithmandtheIdedec-himethodarewell-knownRFmethodsforthevectorspacemodel.Intheprobabilisticmodel,feedbackcanbeusedtomodifytheweightoftermstochangeorexpandtheoriginalquery.Forlanguagemodelingapproaches,ZhaiandLaffertyZhai2001proposedafundamentalRFmethod.Thebasicideabehindthesemethodsisthesame,i.e.,documentsthataresimilartothefeedbackarere-rankedhigher.Itshouldbenotedthatmostmethodscalculatesimilaritiesusinginformationfromwordsthatonlyappearinthefeedbackandsearchresults.Inotherwords,thesemethodsdonotuseinformationfromwordsthatdonotappearinthegiventexts.However,informationfromhighlyprobablerelevantwordscanbeusefulforre-rankingsearchresultsevenifthewordsdonotappearinthegiventexts.Considerthequery,``Macprice,''andsupposethatthefeedbackcontainsdocumentsaboutthepriceofa``Mac''(PC).Althoughthefeedbackmaynotcontainwordssuchas``CPU''and``HDD,''thesewordsarecloselyrelatedtothefeedbackandare,therefore,highlyprobable.Thesameistrueofotherrelevantdocumentsinthesearchresults.Evenifarelevantdocumentdoesnotcontainwordsspecifictothefeedbackandifitdoesincludecloselyrelatedtowords,thesewordsarehighlyprobable.Thisinformationcanbeusefulforcalculatingsimilaritiesbetweenthefeedbackandotherdocuments.Inthispaper,weproposeanRFmethodthatusesthesurfaceinformationintextsandlatentinformationcontainedinthetexts.Foreachdocumentinthesearchresults,weinferthedistributionofwordsthatarehighlyprobablegiventhelatenttopicsinthedocumentusinglatentDirichletallocation(LDA).Wecalculatethesimilaritiesbetweenthefeedbackandeachdocumentinthesearchresultsusingbothsurfaceandlatentworddistributions.Then,were-rankthesearchresultsonthebasisofthesimilarities.Theremainderofthispaperisorganizedasfollows.InSections~and,weexplainthelanguagemodelingapproachesforIRandLDA,whichformthebasisoftheproposedmethod.InSection~,wepresenttheproposedmethod.Section~reportsexperimentsperformedtoevaluatetheproposedmethod,andconclusionsarepresentedinSection~.</section>
  <section title="Language Modeling Approaches to IR">Inthissection,wedescribethelanguagemodelingapproachesforIRthatformthebasisofourmethod.</section>
  <subsection title="Overview">Languagemodelingapproachescanbeclassifiedintothreetypes:querylikelihoodmodel,documentlikelihoodmodel,andKullback-Leibler(KL)divergenceretrievalmodel.Inthequerylikelihoodmodel,adocumentlanguagemodelP_d_h()isconstructedforeachdocumentd_h;(h=1,,H)inthecollection.Whenaqueryqissubmittedbyauser,thequerylikelihoodP_d_h(q)iscomputedusingthedocumentmodelforeachd_h.Then,thedocumentsinthecollectionarerankedaccordingtotheirlikelihood.Inthedocumentlikelihoodmodel,aquerylanguagemodelP_q()isconstructedforagivenquery.ThequerylanguagemodelisthenusedtocomputethedocumentlikelihoodP_q(d_h)foreachdocumentinthecollection.Thedocumentsarethenrankedbytheirlikelihood.IntheKL-divergenceretrievalmodel,bothaquerymodelP_q()andadocumentmodelP_d_h()areconstructed.ThedocumentsinthecollectionarerankedaccordingtotheKL-divergenceKL(P_q()||P_d_h())betweenthesemodels.</subsection>
  <subsection title="Language Model Construction">Thereareseveralwaystoconstructaquerymodelandadocumentmodel.Onemethodismaximumlikelihoodestimation(MLE).TheMLEofawordwwithrespecttoatextt(aqueryordocument)iscomputedusingwheretf(w,t)representsthefrequencyofwint,and|t|representsthenumberofwordsint.Dirichletpriorsmoothing(DIR)isawell-knownconstructionmethod.TheDIRofwwithrespecttotiscomputedasfollows.whereD_allrepresentsacollection,andrepresentsthesmoothingparameterthatcontrolsthedegreeofconfidenceforthefrequencyofwinD_all(ratherthaninthefrequencyint).</subsection>
  <subsection title="Fundamental RF Method">ZhaiandLaffertyproposedafundamentalRFmethodforlanguagemodeling~.WhenuserfeedbackF=(f_1,,f_G)isavailable,theyconstructalanguagemodelP_F()forthefeedback.Then,anewquerymodelisconstructedbyinterpolatingthefeedbackmodelwiththeoriginalquerymodelthatwasusedtoobtaintheinitialsearchresults.Finally,theymodifythesearchresultsusingthenewquerymodel.Theirexperimentsdemonstratethattheirproposedmethodiseffective.However,theyonlyusetheinformationofwordsthatappearinatextfortheRF.Inourproposedmethod,wealsouseinformationaboutwordsthatdonotappearinatextbutarehighlyprobablegiventhelatenttopicsinthetext.</subsection>
  <section title="LDA">Inthissection,weexplainLDA,whichtheproposedmethodusestodeterminewordsthatarehighlyprobablegiventhelatenttopicsofatext.</section>
  <subsection title="Parameter Estimation">Therearetwowaystoestimatetheparameters:Gibbssamplingandavariationalmethod.Gibbssamplingismorepopularbecauseitdeterminesbetterparametervaluesandissimplertoimplement.However,Gibbssamplingforparameterestimationtakesmuchlongertoexecutethanvariationalmethods.Therefore,weuseavariationalmethodbecausesearchsystemsshouldreturnresultsasquicklyaspossible.First,variationalparameters_i=(_i1,,_iK)and_i=(_i1,,_iJ)areintroducedforeachdocumentd_i;(i=1,,I)inthetrainingdata.Notethat_ij=(_ij1,,_ijK).Then,optimumparametervaluesarefoundbyrepeatedlycomputingthefollowingpairofupdatedequations:_ijk&amp;_kj((_ik)-(_k'=1^K_ik'))_ik&amp;=_k+_j=1^J_ijk,tf(w_j,d_i),alignwhereisthefirstderivativeofthelogfunction.Next,_kand_kareupdatedusing_iand_i.ANewton-Raphsonmethodhasbeenusedtoestimateeach_k~.However,thefixed-pointiterationmethod~isabetterestimationtechnique;therefore,wehaveusedupdatedequationsbasedonthismethod.Theupdatedequationsfor_kand_k,respectively,areasfollows:_kj&amp;_i=1^I_ijk,tf(w_j,d_i)_k&amp;=_i=1^I(_k+n_ik)-(_k)_i=1^I(_0+|d_i|)-(_0),_k^old,alignwheren_ik=_j=1^J_ijk,tf(w_j,d_i),_0=_k'=1^K_k',and_k^oldrepresents_kbeforetheupdate.Finally,updatesof_iand_iforeachd_iandthoseof_kand_kareiterateduntilconvergence.When_kand_khavebeenestimated,weobtaintheprobabilityofdocumentd_iusingEq.~().Inaddition,wecanobtainP^LDA_d_i(w_j)usingtheestimated_iandthefollowingequation:where_ik/_k'=1^K_ik'isadistributionoverthelatenttopicsofd_i.Weinterpolateeach_kjaccordingtothedistributionandobtaintheprobabilitiesofw_jthatarehighlyprobablegivend_i.</subsection>
  <subsection title="Inference of Unseen Documents">LDAisconsideredaBayesianextensionofprobabilisticlatentsemanticanalysis~.AmajoradvantageofLDAisthatitcaninfertheprobabilitiesofunseendocumentsthatarenotincludedinthetrainingdata.Whenwecomputetheprobabilitiesofanunseendocumentd_I+1,thevariationalparameters_I+1and_I+1areestimatedusingEqs.~()and(),respectively.Theestimatedvaluesobtainedusingthetrainingdocumentsetareusedfor_kand_k.When_I+1hasbeenestimated,wecanobtaintheprobabilityP_d_I+1^LDA(w_j)usingEq.~().Intheproposedmethod,thisadvantageofLDAallowsustocalculatetheprobabilitiesofwordsthatarehighlyprobablegiventhefeedback.</subsection>
  <subsection title="LDA in IR">LDAhasbeensuccessfullyusedinvariousfieldssuchasnaturallanguageprocessing,imageprocessing,andspeechrecognition.IntheIRfield,WeiandCroftWei2006incorporatedLDAintoaquerylikelihoodmodel,andYiandAllanYi2009haveincorporatedLDAintoadocumentlikelihoodmodel.ZhouandWadeZhou2009incorporatedLDAintoaKL-divergenceretrievalmodel.ThesemethodsconstructalanguagemodelforeachdocumentusingLDAandtheobtainedsearchresultsforagivenqueryaccordingtotheirscores(e.g.,querylikelihood).Inthisstudy,wefocusonuserfeedback.WeconstructalanguagemodelforthefeedbackusingLDA,whichweusetomodifythesearchresults.</subsection>
  <section title="Proposed Method"/>
  <subsection title="Acquisition of Initial Search Results">Intheproposedmethod,weuseaKL-divergenceretrievalmodel~toobtaintheinitialsearchresultsforagivenquery.Foreachdocumentd_h;(h=1,,H)inthecollectionD_all,aDIR-baseddocumentmodelP^DIR_d_h()isconstructedinadvance.Foragivenqueryq,weconstructtheMLE-basedquerymodelP^MLE_q().Then,foreachdocumentcontainingqinD_all,wecomputetheKL-divergencebetweentheDIR-baseddocumentmodelandtheMLE-basedquerymodel.Thatis,wedefinethescoreofadocumentd_hforaqueryqasTheinitialsearchresultsD_qareobtainedbyrankingthedocumentsaccordingtotheirscores.WeuseMLEtoconstructthequerymodel~&lt;e.g.,&gt;Zhai2001.WhenaquerymodelisconstructedusingMLE,therankingbasedontheKL-divergenceretrievalmodelisequivalenttothatbasedonthequerylikelihoodmodel~.</subsection>
  <subsection title="Hybrid Document Model Construction">WeconstructahybridlanguagemodelP^HYB_d_i()foreachdocumentd_i,(i=1,,I)inD_q.Inthismodel,weconsiderboththesurfaceandlatentinformationinthedocuments.First,anLDA-baseddocumentmodelP^LDA_d_i()isconstructedforeachd_i.WeperformLDAonD_qtoinferthetopicdistributionineachd_i,andestimatetheparameters_k,_k;(k=1,,K)and_iforeachd_i.Then,weconstructP^LDA_d_i()usingtheestimatedparametersandEq.~().AsdescribedinSection~,P_d_i^LDA()isconstructedonthebasisofhighlyprobablewordsgiventhelatenttopicsind_i.Next,foreachd_i,weconstructP^HYB_d_i()byinterpolatingtheconstructedP_d_i^LDA()withP_d_i^DIR()asfollows.where0a1.P^DIR_d_i()isconstructedusingthewordsthatappearind_i.Byinterpolatingthetwomodels,ourmethodconstructsadocumentmodelthatcontainsthesurfaceandlatentinformationind_i.</subsection>
  <subsection title="Hybrid Feedback Model Construction">WeconstructahybridlanguagemodelP^HYB_F()foruserfeedback.First,weperformLDAonFtoinferthetopicdistributioninFandestimatethevariationalparametersforF,asdescribedinSection~.Then,weconstructtheLDA-basedfeedbackmodelP^LDA_F()usingtheestimatedparametersandEq.~().SimilartoP^LDA_d_i(),P^LDA_F()isconstructedonthebasisofthehighlyprobablewordsfromthelatenttopicsinF.Finally,P^HYB_F()isconstructedinthesamemannerasP^HYB_d_i().whereP^DIR_F()isconstructedusingEq.~().Byinterpolatingthetwomodels,ourmethodconstructsafeedbackmodelthatcontainsthesurfaceandlatentinformationinF.</subsection>
  <subsection title="Re-ranking Search Results">Weconstructanewquerymodelthatisusedtore-ranktheinitialsearchresultsD_q.ThenewquerymodelP^NEW_q()isconstructedbyinterpolatingtheoriginalquerymodelP^MLE_q()withthehybridfeedbackmodelP^HYB_F()asfollows:where0b1.Then,foreachd_iinD_q,wecomputetheKL-divergencebetweenP^HYB_d_i()andP^NEW_q().Thatis,thescoreofdocumentd_iforqueryq(givenfeedbackF)isdefinedasFinally,weobtaintherevisedsearchresultsbyre-rankingthedocumentsinD_qaccordingtotheirscores.</subsection>
  <section title="Experiments">Inthissection,wepresenttheresultsofexperimentsperformedtoevaluatetheproposedmethod.</section>
  <subsection title="Test Set">Intheexperiments,weusedthetestsetfromtheWebRetrievalTaskfromtheThirdNTCIRWorkshop.Thetestsetconsists11,038,720Japanesewebpagesand47informationneeds.Foreachinformationneed,2,000documentsareratedashighlyrelevant,fairlyrelevant,partiallyrelevantorirrelevant.Wecanevaluatetherankingofsearchresultsusingtheseannotateddocuments.Figure~givesanexampleofaninformationneedfortheWebRetrievalTask.Themeaningofeachelementisgivenbelow.Inourexperiments,weusedthefirsttwotermsintheTITLEtagasthequery.Wecollectedeachdocumentcontainingaquery(Section~).WhenweusedallthetermsintheTITLE,thereweretoofewdocumentsinthesearchresults.Forexample,foridentificationnumbers0027,0047,and0058,wecouldonlyobtain17,5,and14documents,respectively.Foridentificationnumber0061,wecouldnotfindanydocuments.Thiscausedunreliableevaluationresults.Inotherwords,ifanRFmethodimprovedtherankingoftheinitialsearchresults,theimprovementwasnotreflectedbyevaluationmeasuressuchasprecisionat10(P@10),andwecouldnotdeterminehowwellthemethodperformed.Thus,toobtainasufficientnumberofdocuments,weusedonlythefirsttwotermsintheTITLEtag.Itshouldbenotedthatgreaterthan100documentswasdefinedassufficient.WeusedthedocumentsintheRDOCtagastheuserfeedback.Thesearerelevantdocumentsselectedbyassessorsandcanbetreatedasuserfeedback.Theywerenotnecessarilyincludedintheinitialsearchresults.Insuchcases,onemaythinkthatthesedocumentsshouldnotbeusedasuserfeedback.However,whenweevaluatedtheRFmethod,weremovedthesedocumentsfromthesearchresultsregardlessofwhethertheywereincludedintheinitialresults(Section~).Inotherwords,whetherthesedocumentswereincludedinthesearchresultswasnotimportantbecauseweremovedthemfromtheinitialsearchresultsandthere-rankedresults.Wedidnotusesevenoftheinformationneeds(identificationnumbers:0011,0018,0032,0040,0044,0047,and0061)becausewewereunabletoretrieveasufficientnumberofdocuments(i.e.,100documents)forthemevenwhenusingthefirsttwotermsasthequery.Wedividedtheremaining40informationneedsintodevelopmentandtestdata.Thedevelopmentdataconsistedof8informationneeds(identificationnumbers0008--0017),whichwereusedtotuneourmethod.Thetestdataconsistedof32informationneeds(identificationnumbers0018--0063),whichwereusedtoevaluateourmethod.</subsection>
  <subsection title="Search Engine">Intheseexperiments,weimplementedasearchenginethatobtainedtheinitialsearchresultsforagivenqueryandre-rankedthemusingtheproposedmethod.Thedetailsoftheimplementationareasfollows.Weusedthe11,038,720webpagesinourtestsetasthecollection(i.e.,D_all).Eachdocumentwasconvertedintotheformatpresentedby.Inthisformat,eachsentenceinadocumentwassegmentedintowords.EachwordwasgivenarepresentativeformusingJUMAN,aJapanesemorphologicalanalyzer.Then,weconstructedtheDIR-baseddocumentmodelforeachdocument.Wesetthesmoothingparameter=1,000,whichisconsistentwithpreviousstudies.Whengivenaquery,weconverteditstermsintoarepresentativeformusingJUMAN,constructeditsMLE-basedlanguagemodel,andobtainedtheinitialsearchresultsbyrankingdocumentsinthecollection.TheLDAconfigurationisgivenbelow.Wesettheinitialvaluesof_k,(k=1,,K)to1,andtheinitialvalueofeach_kj,(k=1,,K,,j=1,,J)torandomvalues.Thenumberofiterationsforthevariationalparametersandthatfor_kand_kweresetto10.WelimitedthesizeofthevocabularyinLDA,denotedasJ,to100.Weselected100wordsonthebasisoftheirimportanceinthesearchresults.NotethattheimportanceofawordwtothesearchresultsD_qisdefinedasdf(w,D_q)*(|H|/df(w,D_all)),wheredf(w,D)representsthedocumentfrequencyofwindocumentsD.</subsection>
  <subsection title="Evaluation Method">Weremovedthefeedbackdocumentsfromboththeinitialandre-rankedresults.WecanevaluatetheperformanceofanRFmethodbycomparingtheinitialsearchresultswiththere-rankedresults.Acommonevaluationproblemishowtohandledocumentsthatusershavemarkedasrelevant.Iftheinitialandre-rankedresultsarecomparedinastraightforwardmanner,thelatterhaveanadvantagebecausedocumentsthatareknowntoberelevanttendtobere-rankedhigher.However,ifweremovethemfromthere-rankedresults,theyaredisadvantaged.Thisisespeciallytrueiftherearefewrelevantdocuments.Therefore,weremovedthedocumentsusedasuserfeedbackfrombothresults.Thisallowedustomakeafaircomparisonbetweentheinitialandre-rankedresults.WeevaluatedthemethodusingP@10,meanaverageprecision(MAP),andnormalizedcumulativegainforthe10top(re-)rankeddocuments(NDCG@10).WhencalculatingP@10andMAP,documentsthatwereratedashighlyrelevant,fairlyrelevant,andpartiallyrelevantwereregardedasrelevant,whiledocumentsratedasirrelevantandunrateddocumentswereregardedasirrelevant.WhencalculatingNDCG,weassessedtherelevancescoreofdocumentsratedhighlyrelevant,fairlyrelevant,andpartiallyrelevantas3,2,and1,respectively.</subsection>
  <subsection title="Performance of the Proposed Method">Weexaminedtheeffectivenessoftheproposedmethodinre-rankingtheinitialsearchresultsusingexplicitfeedback.AsdescribedinSection~,weusedthetestdataandthefirsttwotermsintheTITLEasthequeryforeachinformationneed.Wedefinedtheinitialsearchresultsasthe100documentswiththehighestinitialscoresandthenre-rankedthemusingtheproposedmethod.WeusedthefirsttwodocumentsintheRDOCtagforeachinformationneedastheexplicitfeedback.Theaveragenumberofwordsinadocumentwas3,589.Weset(a,b,K)=(0.2,0.9,50)becausethissettingobtainedthebestresultsinthepreliminaryexperimentdescribedinSection~.TheresultsarelistedinTable~.INITrepresentstherankingoftheinitialsearchresults,andOURSrepresentsthere-rankedresultsusingtheproposedmethod.Forcomparison,wealsoshowtheperformanceofsomebaselinemethods,ZHAIrepresentsthemethodbyZhaiandLaffertyZhai2001andOURS(a=0.0)representstheproposedmethodwithoutlatentinformation.ZHAIisessentiallythesameasOURS(a=0.0).Bothmethodsconstructthefeedbackmodelbymodifyingthesurfaceworddistributionofthefeedbackusingthatofthecollection.Thedifferenceliesinthewaytheworddistributionismodified.Theformerusesanexpectation-maximizationalgorithmforthemodification,whilethelatterusesDIRestimation.InOURS(a=0.0),wesetb=0.5.Thisvaluewasdeterminedinthepreliminaryexperiment.DICalsorepresentsabaselinemethod.Theproposedmethodusesinformationaboutwordsthatarehighlyprobablegivenatext.Dictionariesofsynonymsandrelatedwordscanalsobeusedforthispurpose.DICisanextensionofOURS(a=0.0);DICusessynonymsofthesurfacewordsfromthefeedbackandsearchresults.Forthismethod,weconstructedasynonymdictionaryfromJapanesedictionariesusingthemethodproposedby.FortheJapanesedictionaries,weusedReikaiShougakuKokugoJitenandIwanamiKokugoJiten.Theconstructeddictionarycontained4,597entries(e.g.,``computer''=``electronicbrain'').TheresultsshowninTable~indicatethatOURSoutperformedINITforallmetrics.Forexample,theproposedmethodimprovedtheinitialsearchresultsby27.6%inP@10.Theseresultssuggestthattheproposedmethodeffectivelyre-rankedtheinitialsearchresults.Inaddition,theproposedmethodoutperformedZHAIandOURS(a=0.0),whichdonotuselatentinformationfromtexts.Thissuggeststhatlatentinformationisusefulwhenre-rankingsearchresults.Weinvestigatedfurtherandconfirmedthattheproposedmethodmadegooduseofthewordsthatdidnotappearinthefeedbackbutwereconsideredhighlyprobable.ConsidertheinformationneedshowninFigure~.Theuserfeedbackdidnotcontainthewords``religion,''``holiday,''or``bible,''whicharerelatedtotheinformationneed.Assuch,ZHAIandOURS(a=0.0)couldnotusethesewords.Incontrast,thesehighlylikelywordshadacertaindegreeofprobabilityinthehybridlanguagemodeleventhoughthewordsdidnotappearinthefeedback.Forexample,themethodcouldallocatetheprobabilities0.0046,0.0037,and0.0024tothewords``religion,''``holiday,''and``bible,''respectively.Theprobabilitiesallocatedtothewords``Christmas''and``easter,''whichappearedonceinthefeedback,were0.0093and0.0060,respectively.Usingtheseprobabilities,theproposedmethodraisedthescoreofdocumentsthatcontainedthesewords.AlthoughDICoutperformedZHAIandOURS(a=0.0),itdidnotoutperformOURS.Thismaybeduetothecoverageofthesynonymdictionary.DICmayperformbetterifwide-coveragesynonymdictionariesareused.However,constructingsuchdictionariesisdifficult.Theproposedmethodalsoneedstoknowthatawordisrelatedtootherwords;however,unlikeDIC,itdoesnotneedanydictionaries.UsingLDA,theproposedmethoddynamicallyacquirestherequiredknowledgefromthesearchresults.Considerthequery``Macprice''describedinSection~.Supposethatthesearchresultscontainwordssuchas``CPU,''``HDD,''``hamburger,''and``potato.''OurmethodperformsLDAonthesearchresultsanddynamicallyacquirestheknowledgethat``CPU''isrelatedto``HDD,''and``hamburger''isrelatedto``potato.''Inaddition,evenif``HDD''doesnotappearinadocument,theproposedmethodcanassignacertaindegreeofprobabilitytothewordfromotherrelatedwords,suchas``CPU.''Thus,theproposedmethoddoesnotrequireanydictionaries.TheproposedmethodcanalsobeappliedtopseudoRF.InpseudoRF,thetopndocumentsintheinitialsearchresultsareassumedtoberelevant,andthesearchresultsarere-rankedonthebasisofthisassumption.WeimplementedpseudoRFusingtheproposedmethodforn=10andcomparedtheinitialresultswiththere-rankedresults.NotethattherearenorelevantdocumentsinpseudoRF.Thus,weevaluatedtheperformanceofeachmethodusingtheraw(re-)rankedresults.TheevaluationresultsareshowninTable~.TheresultsforINITinthistabledifferfromthoseinTable~becausethedocumentsusedasfeedbackwerenotremovedfromthesearchresults.TheproposedmethodimprovedtheinitialsearchresultsinP@10andNDCG@10.Forexample,theproposedmethodimprovedtheinitialsearchresultsby8.2%inP@10.TheseresultsdemonstratethattheproposedmethodisapromisingcandidateforpseudoRFaswellasexplicitRF.</subsection>
  <subsection title="Effect of the Amount of Feedback">Inthesecondexperiment,wesimulatedasituationwhereonlyasmallamountofuserfeedbackcanbeobtained.Weinvestigatedhowtheamountoffeedbackaffectedtheperformanceoftheproposedmethod.Inpractice,largequantitiesofuserfeedbackarerarelyavailable.Thus,anRFmethodshouldperformwellonlywhenasmallamountofuserfeedbackisavailable.WeincrementallyreducedtheamountofexplicitfeedbackandobservedthechangeinP@10.Forthisexperiment,weusedsevendifferentquantitiesofexplicitfeedback:G=2^1,2^0,2^-1,2^-2,2^-3,2^-4,and2^-5relevantdocuments.Notethat,forexample,G=2^1meansthatweusedtworelevantdocumentsasuserfeedback.G=2^-1representstheuseofhalfadocument,i.e.,halfthewordsfromthefeedbackwererandomlysampledandonlythesewordswereusedforRF.Thisallowedustoconsiderthecasewherepartofadocument(e.g.,titleorsnippet)isgivenasuserfeedback.Figure~showstheeffectoftheamountoffeedbackontheperformanceoftheproposedmethod.Forcomparison,wealsopresenttheresultsoftheproposedmethodwithoutthelatentinformation(OURS(a=0.0)).INITrepresentstheprecisionoftherankingoftheinitialsearchresults.FromFigure~,itisevidentthattheproposedmethodperformedconsistentlywell.Forexample,whenonerelevantdocumentwasgivenasuserfeedback,theproposedmethodimprovedtheinitialsearchresultsby24.5%inP@10.Inaddition,theproposedmethodachieveda5.3%improvementwithonly2^-5documents.WhenG=2^-5,therewereonaverage57wordsinthefeedback,i.e.,|F|was57.Ontheotherhand,whenGwassmall,theimprovementsachievedbyOURS(a=0.0)werenegligible.AsGbecomessmaller,theamountofavailablesurfaceinformationbecomessmallerandthemethodcannotimprovetheinitialsearchresults.Ontheotherhand,OURSusesbothsurfaceandlatentinformation.Evenwhenonlyasmallamountoffeedbackisavailable,OURSimprovedtheinitialsearchresultsbecausethemethodusesmoreinformation.</subsection>
  <subsection title="Sensitivity to Parameters">Theproposedmethodusesthefollowingthreeparameters:a,b,andK.ParameteracontrolsthereliabilityofanLDA-basedlanguagemodelinahybridlanguagemodel.Parameterbcontrolsthereliabilityofafeedbackmodelinanewquerymodel,andparameterKrepresentsthenumberoftopics.Inourexperiments,weset(a,b,K)=(0.2,0.9,50)forOURSandb=0.5forOURS(a=0.0).Thesevaluesweredeterminedinapreliminaryexperiment.Inthepreliminaryexperiment,were-rankedtheinitialsearchresultsusingdifferentparametervaluesandmeasuredthechangesinperformanceusingtheproposedmethod.Weusedthedevelopmentdata,appliedourmethodwithaandbrangingfrom0.0to1.0instepsof0.1andKrangingfrom10to100instepsof10,andobtainedtheaverageofP@10forallinformationneeds.WeusedthefirsttwotermsintheTITLEasthequeryandthefirsttwodocumentsintheRDOCastheuserfeedback.TheresultsofthepreliminaryexperimentareshowninTable~andFigure~.Table~summarizestheresultswithrespectto(a,b).ThevalueofeachcellinthetableistheaverageofP@10obtainedforeachK.Forexample,thevalueofcell(a,b)=(0.1,0.2)denotesthattheaverageofP@10obtainedfor(a,b,K)=(0.1,0.2,10),(0.1,0.2,20),,(0.1,0.2,100)is0.286.Thehighestvalueineachcolumnisshowninbold,andthehighestvalueineachrowisunderlined.Ascanbeseenfromthetable,theproposedmethodachievedthebestperformancewith(a,b)=(0.1,0.9)or(0.2,0.9).Theresultswitha=0.0(notusinglatentinformation)demonstratethatthemethodperformedwellwithb=0.3--0.5.Ontheotherhand,theresultswitha0.1(usinglatentinformation)demonstratethattheproposedmethodperformedwellwithb=0.8--1.0.Thevalueofb(andtheperformancewiththisb)witha0.1isgreaterthanthatwitha=0.0.Thisresultsuggeststhatlatentinformationincreasesthereliabilityofthefeedbackmodel.Figure~illustratestheeffectofKontheperformanceoftheproposedmethod.Forclarity,onlyshowtheresultswith(a,b)=(0.1,0.9),(0.2,0.9),and(0.3,0.9),whichproducedgoodresults~(Table~).AccordingtotheresultpresentedinFigure~,theproposedmethodperformedwellwithK=50--70.Theseresultsindicatethattheproposedmethodachievesthebestperformancewith(a,b)=(0.1,0.9)or(0.2,0.9),andK=50--70.</subsection>
  <subsection title="Execution Time">Intheproposedmethod,weperformLDAonthesearchresultstoconstructanLDA-baseddocumentmodelforeachdocument.WealsoperformLDAonthefeedbacktoconstructanLDA-basedfeedbackmodel.Here,wereporttheexecutiontimesoftheseprocedures.Inourexperiments,theproposedmethodtook13.1--16.0~secstoperformLDAonthesearchresults(100documents).NotethatweimplementedLDAusingPerlandC.Webelievethatthisisanacceptableexecutiontimebecauseuserstypicallybrowsedocumentsinsearchresultstoselectrelevantdocuments.Thisprocessgenerallytakesatleast1~min.Inotherwords,wecanperformLDAonthesearchresultswhiletheusersarebrowsingthedocuments.Thus,LDAcanbecompletedbeforetheusersre-ranktheinitialsearchresults.However,thenumberofretrieveddocumentsissometimesgreaterthan100.Ifalargenumberofdocumentsisretrieved,LDArequiresasignificantamountoftimetoexecute.Onewaytoavoidthisproblemistouseonlythetoprankeddocumentsasthesearchresults.ThetimerequiredforLDAisnotamatterofconcernifweusethetop100documents.AnotheralternativeistoparallelizetheestimationofthevariationalparametersinLDA,aprocessthattakesthemajorityoftheexecutiontime.Variationalparametersforeachdocumentareindependentofthoseforotherdocuments.Thus,wecanparallelizetheestimationoftheparametersandreducethetimerequiredfortheprocedure.Forexample,achieveda14.5timesspeedupusing50clusternodes.Therefore,itisexpectedthatwecanreducetheexecutiontimebasedonthesestudies.Ittooklessthan1~sectoperformLDAonthefeedback.Forexample,theexecutiontimewasonly0.1--0.2~secswhenusingtwodocumentsasfeedback.Thus,thetimerequiredtoperformLDAonthefeedbackisnegligible.</subsection>
  <section title="Conclusion">WehaveproposedanRFmethodusingsurfaceandlatentinformationfromtextsandinvestigateditseffectiveness.UsingLDA,ourmethodinfersthedistributionsoverwordsthatarehighlyprobablegiventheuserfeedbackandeachdocumentinthesearchresults.Then,ahybridworddistributionisconstructedbyinterpolatingthelatentworddistributionwiththesurfaceworddistributionforthefeedbackandeachdocument.Finally,documentswhosehybridworddistributionsresemblethefeedbackareregardedasrelevanttotheuser'sinformationneed,andarere-rankedhigher.Throughourexperiments,weconfirmedthattheproposedmethodperformswellforbothexplicitandpseudoRF.Theproposedmethodalsoperformswellwhenonlyasmallamountoffeedbackisavailable.Infuture,weintendtousenegativefeedbackintheproposedmethod.Inthisstudy,onlyusepositivefeedback(relevantdocumentsforaquery)wasusedforre-rankingsearchresults;however,webelievethatnegativefeedback(irrelevantdocuments)canalsobeuseful.document</section>
</root>
