    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}

\newcommand{\changed}[1]{}
\renewcommand{\changed}[1]{}
\usepackage{mygb4e} 
\usepackage{xspace}
\usepackage[e,j]{mtg2e}
    \newcommand{\bccwj}{}
    \newcommand{\ehon}{}
    \newcommand{\first}{}
    \newcommand{\kodomo}{}
\newcommand{\Total}{}
\newcommand{\TOTAL}{}
    \newcommand{\kod}[1]{}
    \newcommand{\kyoto}{}
    \newcommand{\mecab}{}
    \newcommand{\kytea}{}
    \newcommand{\chasen}{}
    \newcommand{\juman}{}
    \newcommand{\lxd}{}
    \newcommand{\GT}{}
    \newcommand{\naistj}{}
    \newcommand{\ntj}{}
    \newcommand{\hinoki}{}
    \newcommand{\unidic}{}
    \newcommand{\hira}{}
    \newcommand{\kata}{}
    \newcommand{\kanji}{}
    \newcommand{\entire}{}
    \newcommand{\random}{}
    \newcommand{\bestHINOKI}{}
\newcommand{\Org}{}  
\newcommand{\Del}{}  
\newcommand{\Sp}{} 
\newcommand{\Han}{} 
\newcommand{\HanDel}{} 
\newcommand{\HanSp}{}
\newcommand{\Def}{}
\newcommand{\up}[1]{}
\newcommand{\dn}[1]{}
\newcommand{\refsec}[1]{} 
\newcommand{\refs}[1]{}
\newcommand{\exs}[1]{} 
\newcommand{\ul}{}
\newcommand{\izj}[1]{}
\newcommand{\pos}[1]{}
\newcommand{\gm}{}

\Volume{21}
\Number{3}
\Month{June}
\Year{2014}

\received{2013}{10}{28}
\revised{2013}{12}{27}
\accepted{2014}{2}{26}

\setcounter{page}{515}

\jtitle{絵本のテキストを対象とした形態素解析}
\jauthor{藤田　早苗\affiref{Author} \and 平　　博順\affiref{Author} \and 小林　哲生\affiref{Author} \and 田中　貴秋\affiref{Author}}
\jabstract{
これまで，主に新聞などのテキストを対象とした解析では，形態素解析器を始めとし
て高い解析精度が達成されている．しかし分野の異なるテキストに対しては，既存
の解析モデルで，必ずしも高い解析精度を得られるわけではない．そこで本稿では，
既存の言語資源を対象分野の特徴にあわせて自動的に変換する手法を提案する．本
稿では，絵本を解析対象とし，既存の言語資源を絵本の特徴にあわせて自動的に変
換し，学習に用いることで相当な精度向上が可能であることを示す．学習には既存
の形態素解析器の学習機能を用いる．さらに，絵本自体にアノテーションしたデー
タを学習に用いる実験を行い，提案手法で得られる効果は，絵本自体への約~11,000
行，90,000 形態素のアノテーションと同程度であることを示す．また，同じ絵本の
一部を学習データに追加する場合と，それ以外の場合について，学習曲線や誤り内
容の変化を調査し，効果的なアノテーション方法を示す．考察では，絵本の対象年
齢と解析精度の関係や，解析精度が向上しにくい語の分析を行い，更なる改良案を
示す．また，絵本以外への適用可能性についても考察する．
}

\jkeywords{ひらがな，対象年齢，分野適応，アノテーション}

\etitle{Japanese Morphological Analysis of Picture Books}

\eauthor{Sanae Fujita\affiref{Author} \and Hirotoshi Taira\affiref{Author} \and Tessei Kobayashi\affiref{Author} \and Takaaki Tanaka\affiref{Author}} 
\eabstract{
  Picture books have a significant influence on children's language
  development. However, the sentences in picture books are difficult
  to analyze automatically. Therefore, to improve the accuracy of the
  morphological analysis of such sentences, we propose an automatic
  method to transform existing resources into applicable training data
  for picture books. In this paper, we first compare picture books
  with common corpora and then analyze the reasons for the difficulty
  in morphological analysis. Based on this analysis, we propose a
  transforming method for existing resources and show its
  effectiveness using the learning function of an existing
  morphological analyzer. Second, we perform further experiments using
  annotated data of picture books themselves. Then we reveal that our
  proposed method provides us with the same effect, with around 11,000
  lines, that is 90,000 morphological annotations of picture books. In
  addition, we demonstrate an effective annotation strategy by
  investigating the learning curves and change in error types. In a
  discussion, we analyze the results focused on a picture book's
  target ages and difficult to learn words and then further refine our
  proposed method. Finally, we also briefly consider the applicability
  of our method to other domains.  }


\ekeywords{Japanese syllabary characters, Target age, Domain adaptation, Annotation}

\headauthor{藤田, 平, 小林, 田中}
\headtitle{絵本のテキストを対象とした形態素解析}

\affilabel{Author}{NTT コミュニケーション科学基礎研究所}{NTT Communication Science Laboratories}



\begin{document}
\maketitle

\section{はじめに} \label{sec:introduction}

これまで，主に新聞などのテキストを対象とした解析
では，形態素解析器を始めとして高い解析精度が達成されている．しかし
近年，解析対象はWebデータなど多様化が進んでおり，これらのテキストに対して
は既存の解析モデルで，必ずしも高い解析精度を得られるわけではない
\cite{Kudo:Ichikawa:Talbot:Kazawa:2012j,Katsuki:Sasano:Kawahara:Kurohashi:2011j}．

本稿では，そうしたテキストの一つである絵本
を対象とした形態素解析の取り組みについて述べる．
絵本は幼児の言語発達を支える重要なインプットの一つであり
\cite{Mother-child:Ehon:2006}，高い精度で解析できれ
ば，発達心理学における研究や教育支援，絵本のリコメンデーション\cite{Hattori:Aoyama:2013j}
などへの貢献が期待できる．

\begin{table}[b]
\caption{絵本の文の解析例}\label{tb:morph-ex}
\input{1008table01.txt}
\par\vspace{4pt}
\small
解析結果の出現形，原形，品詞を記載．\\
ただし，\kytea の配布モデルでは原形は出力されない．品詞は適宜簡略化して表示．
\par
\end{table}

絵本の多くは子供向けに書かれており，わかりやすい文章になっていると考えら
れる．それにも関わらず，既存の形態素解析器とその配布モデル
では，必ずしもうまく解析できない．
なお本稿では，\pos{モデル}を，
既存の形態素解析器に与えるパラメタ群という意味で用いる．
表~\ref{tb:morph-ex}に，既存の形態素解析器である
\juman\footnote{http://nlp.ist.i.kyoto-u.ac.jp/index.php?JUMAN, ver.7.0を利用．} \cite{juman:7.0j}， 
\chasen\footnote{http://chasen-legacy.sourceforge.jp/, ver.2.4.4を利用．} \cite{chasen:2.4.4j}，
\mecab\footnote{http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html, 
ver 0.996, 辞書はmecab-ipadic-2.7.0-20070801を利用．} \cite{Mecab}，
\kytea\footnote{http://www.phontron.com/kytea/, ver.0.4.3を利用．}
\cite{Mori:Nakata:Graham:Kawahara:2011j}
とその配布モデルで
絵本の文を解析した場合の例を示す．
解析器によって誤り方は異なるが，すべて正しく解析できた解析器はなく，既存のモデルでは
絵本の解析が難しいことがわかる．

これは，一般的な形態素解析モデルを構築するときに用いられる学習データ（ラベルありデータ）と，
解析対象である絵本のテキストでは傾向が大きく異なるためだと考えられる．
このように，学習データと解析対象の分野が異なる場合には，形態素解析に限らず
機械学習を用いる多くのタスクで精度が低下する
ため，それに対応するための様々な手法が
提案されてきた．

\citeA{Kamishima:2010j}は，
この問題に対処するための機械
学習の方針として，半教師あり学習，能動学習，転移学習の
三つを挙げている．
まず，半教師あり学習は，少数のラベルありデータを準備し，多数のラベルな
しデータを活用して予測精度を向上させる手法であり，日本語では単語分割を
行う手法が提案されてい
る\cite{Hagiwara:Sekine:2012j}．
能動学習は，より効率的な分類ができるように選んだ事例にラベルを付与する．
日本語形態素解析では，
確信度の低い解析結果に対して優先的に正解ラベルを付与していくことで，対象分野の解析精度を効率的
に改善する方法が提案されている\cite{Mori:2012j,Neubig:Nakata:Mori:2011}．
転移学習は，
関連しているが異なる部分もあるデータから，目的の問題にも利用で
きる情報・知識だけを取り込んで，より予測精度の高い規則を得る
ことを目標とする\cite{Kamishima:2010j}．
転移学習は，
元の分野と対象分野のラベルありデータの有無によって分類ができる．
本稿では，対象分野のラベルありデータが無い場合を教師なし分野適応，
ある場合を教師あり分野適応と呼ぶ．
\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}が提案した，Web上のひらがな交
じり文に対する形態素解析精度向上の手法では，
大量のWeb上の生コーパスを利用しているが，
対象分野のラベルありデータは用いておらず，教師なし分野適応の一種と言える．


いずれの先行研究も優れた利点がある．しかし，本稿で対象とする絵本のよう
に，これまで対象とされてきたコーパスと全く異なり，かつ，大量のデータの
入手が困難な場合，これらの先行研究をそのまま適用しても高い精度を得るこ
とは難しい．

まず，絵本の大量の生コーパスが存在するわけではないため，Webデータを対象とする
場合のような，大量の生コーパスを用いた半教師あり学習は適さないと考えられる．
能動学習はすぐれた分野適応の方法であるが，本稿のように，ベースとなる初期モデルの
学習に利用できる学習データと対象分野との差異が非常に大きい場合，解析誤り
が多すぎ，結局ほぼ全文の解析結果を修正しつつラベルを付与する必要に迫ら
れることになる．
\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}の方法は，ひらがな交じり文を対
象としており，絵本の解析にも比較的適していると考えられる．
しかし，絵本の場合，ひらがな交じりというより，
全文がひらがなで記述されることも多く，高い精度で解析できるとは言えな
い．

そもそも，対象分野のラベルありデータを十分に得ることができれば，通常，
教師あり学習により高い精度が得られる．しかし，対象分野のラベルありデー
タを作成するためにも，何らかの形態素解析器による解析結果を修正する方法
が一般的であり，そもそもの形態素解析精度が低いとラベルありデータの作成
に，コストと時間が非常にかかることになる．

そこで本稿では，既存の辞書やラベルありデータを，対象分野の特徴にあわせ
て自動的に変換し，それを使って形態素解析モデルを構築する教師なし分野適
応手法を提案する．提案手法では，既存の言語資源を活用することで，コスト
と時間をかけずに，対象分野の解析に適した形態素解析モデルを得ることが出
来る．また，こうして得た初期モデルの精度が高ければ，さらに精
度を高めるための能動学習や，ラベルありデータの構築にも有利である．本稿
では，提案手法で構築したモデルをさらに改良するため，絵本自体へのアノテー
ションを行って学習に利用した教師あり分野適応についても紹介する．


以降，まず\ref{sec:target}章では，解析対象となる絵本データベースの紹介を行い，
新聞などの一般向けテキストと絵本のテキストを比較し，
違いを調査する．
\ref{sec:morph-kytea}章では，本稿で形態素解析モデルの学習に利用する
解析器やラベルありデータ，辞書，および，評価用データの紹介を行う．
\ref{sec:bunseki}章では，絵本のテキストを漢字に変換した場合などの精度変化を調査することで，
絵本の形態素解析の問題分析を行う．
\ref{sec:morph}章では，\ref{sec:target}章，\ref{sec:bunseki}章の調査結果に基づき，
解析対象である絵本に合わせて，既存の言語資源であるラベルありデータと辞書を変換する方法を提案する．
\ref{sec:exp-adult}章では，
これらを学習に用いる教師なし分野適応の
評価実験を行い，提案手法による言語資源の変換の効果を示す．
さらに，
\ref{sec:exp-add-ehon}章では，
絵本のラベルありデータを学習に利用する教師あり分野適応の評価実験を行う．
また同時に，提案手法によって得られるラベルありデータが，
どの程度の絵本自体のラベルありデータと同程度の効果になるかも評価する．
\ref{sec:kousatsu}章では，
前章までに得たモデルをさらに
改良するための問題分析と改良案の提示を行い，
提案手法の絵本以外のコーパスへの適用可能性についても考察する．
最後に\ref{sec:conclusion}章では，本稿をまとめ，
今後の課題について述べる．


\section{解析対象}
\label{sec:target}

本章では，まず，解析対象である絵本データベースの紹介を行う（\ref{sec:ehon-db}節）．
次に，新聞などの一般向けテキストと絵本のテキストを比較し，違いを調査する（\ref{sec:mojisyu}節）．
また，評価，実験用に形態素情報を付与した絵本のラベルありデータ（フルアノテーションデータ）を紹介する（\ref{sec:full-ano}節）．


\subsection{絵本データベース}
\label{sec:ehon-db}

本稿では構築中の絵本データベースを解析対象とする
\cite{Taira:Fujita:Kobayashi:2012j}．絵本データベースは，発達心理学におけ
る研究や，子供の興味や発達に応じた絵本リコメンデーションを目的として構築
されている．


含まれる絵本は，2010年度の紀伊国屋書店グルー
プの売上冊数が上位のファーストブック（以下，\first{}）と絵本（以下，\ehon）\footnote{
	絵本とファーストブックの分類は紀伊国屋書店による．絵本には，大人向けと見られる絵本も一部含まれていた．}
計 1,010冊，および，福音館書店の月刊誌（以下，\kodomo）190冊，合計 1,200冊である\footnote{含まれる絵本のリストは http://www.kecl.ntt.co.jp/icl/lirg/members/sanae/ehon-list.html で閲覧可能である．}．
これらの選定理由は，
前者は多くの子供に読まれていると考えられること，
後者は対象年齢が比較的はっきりしていることである．
後者の対象年齢は0・1・2歳向け（以下，\kod{012}），年少（3歳児）向け（以下，\kod{3}），年中（4歳児）向け（以下，\kod{4}），
年長（5歳児）向け（以下，\kod{5}）とわかれている．
本稿では，これらをまとめて絵本と呼ぶこととする．
なお，\kodomo 以外で対象年齢が記載されていた絵本は，463冊 (45.8\%) にとどまり，
その記載方法も「3歳から小学校初級むき」「乳児から」「4才から」のように多様で，
\kodomo のように 1 歳単位で対象年齢が設定されている絵本は少ない．

\begin{table}[b]
 \caption{絵本データベースのサイズ}\label{tb:size}
\input{1008table02.txt}
\end{table}

本稿では，絵本の本文のテキストを解析対象とする．
本文のテキストは人手で入力されている\footnote{当初，既存OCRによる自動的
な文字認識を試したが，絵と文字の判別が難しく，高精度な自動認識は困難
だった．}．
また文や文節の途中での改行など元のページのレイアウトも
忠実に再現されている
（例\refs{ex-org}）．
なお，絵本データベースの 1,200冊のサイズは
表~\ref{tb:size}の通りである．
\begin{exe}
 \ex \label{s:ex-org}
もう　いつ　はるが　きて、なつが　きたのか、いつが\\
あきで、いつが　ふゆなのか、わかりません。\\
\small （バージニア・リー・バートン，石井桃子・訳「ちいさいおうち」p.~24（1954，岩波書店））
\end{exe}


\subsection{絵本と他のコーパスの比較}
\label{sec:mojisyu}

絵本のテキストの特徴を調べるため，絵本と一般的なコーパスにおける
文字種の割合を比較する．
表~\ref{tb:mojisyu}に，
絵本 1,200冊（表 \ref{tb:size}）における
文字種と，
現代日本語書き言葉均衡コーパス\footnote{http://www.ninjal.ac.jp/kotonoha/}（以下，\bccwj），
京都大学テキストコーパス\footnote{http://nlp.ist.i.kyoto-u.ac.jp/index.php}（以下，京大コーパス）
，および，基本語データベース\cite{Lexeed:2004j} （以下，\lxd）
の定義文，例文に出現する文字種の数と割合を示す．

\begin{table}[t]
\caption{文字種毎の数と割合：絵本と他のコーパスの比較}
\label{tb:mojisyu}
\input{1008table03.txt}
\end{table}

表 \ref{tb:mojisyu}から，他のコーパスに比べ，
絵本の場合，ひらがなと空白が占める割合が圧倒的に高いことがわかる．
また逆に，漢字が占める割合は非常に低い．
表~\ref{tb:mojisyu}には，参考として，
一文に含まれる平均文字数，および，平均形態素数も記載した．但し，絵本の場合は，一行に含まれる平均文字
数を記載しており，必ずしも文単位ではない．また，平均形態素数について，絵本は未知であり，
\bccwj は品詞体系が異なるため記載していない．


\subsection{絵本のフルアノテーションデータ}
\label{sec:full-ano}

精度評価
のために，絵本の一部に正解の形態素区切り，IPA品詞，読み，できるだけ漢字表記にした原形を
付与したフルアノテーションデータ（ラベルありデータ）を作成した．
ただし，活用型と活用形は付与していない．
付与自体が難しいことと，
作業量が増えるためにコストと時間がかかること，
これらの情報を今後利用する予定がないことが理由である．

絵本に出現した文\refs{eva-org}に対するフルアノテーションデータを
\refs{ehon-full}に示す．
ただし\refs{ehon-full}では，形態素区切りは\jpn[,]{}で示し，
形態素は\jpn[出現形/品詞/読み/原形]{}の形で示し，
漢字表記にした原形には\ul{下線}を引いた（以降の例でも同様）．

\begin{exe}
 \ex \label{s:eva-org}
めには、いちごの　あかい　みを　いれました。\\
\small （舟崎靖子「もりのおかしやさん」p.~11（1979，偕成社））
\end{exe} 

\begin{exe}
 \ex \label{s:ehon-full}
め/名詞-一般/メ/\ul{目},
に/助詞-格助詞-一般/ニ/に,
は/助詞-係助詞/ハ/は,
、/記号-読点/、/、,
いちご/名詞-一般/イチゴ/\ul{苺},
の/助詞-連体化/ノ/の,
　/記号-空白/　/　,
あかい/形容詞-自立/アカイ/\ul{赤い},
　/記号-空白/　/　,
み/名詞-一般/ミ/\ul{実},
を/助詞-格助詞-一般/ヲ/を,
　/記号-空白/　/　,
いれ/動詞-自立/イレ/\ul{入れる},
まし/助動詞/マシ/ます,
た/助動詞/タ/た,
。/記号-句点/。/。
 \end{exe}

アノテーションは，言語学者や研究者ではない一般の作業者によって行ったが，
特に活用語に対するアノテーションは難しく，既存のラベルありデータを参照しながら作業を行った．
また，作業者による不一致や判断のゆれをなくすため，一定の作業の後には
同じ出現形の形態素に異なる品詞や原形が振られたもの\footnote{例えば，\jpn[ごしごし]{}を\pos{名詞-サ変接続}にするか，\pos{副詞-一般}にするか，といった判断のゆれが多かった．}をリストアップし，
統一的に確認，修正を行う作業を繰り返した．
なお，実際の作業では，アノテーションしたデータを順次学習データに追加することで，
解析精度自体を高めながら作業を進めた（\ref{sec:exp-add-ehon}章参照）．


フルアノテーションを行う
対象データは 2 通りの方法で選んだ．まず，
対象年齢がはっきりしている\kodomo\ 190 冊を対象とした．
また，それ以外の\first, \ehon の中から，絵本をランダムに選び，さらにラン
ダムに 1 ページずつ選んで対象とした（以下，\random）．サイズは表~\ref{tb:test-size}の通りである．
フルアノテーションデータは，\ref{sec:exp-adult}章の
教師なし分野適応実験の評価用データとして利用するほか，
\ref{sec:exp-add-ehon}章の
教師あり分野適応実験の学習，評価用データとして利用する．

\begin{table}[t]
\caption{絵本のフルアノテーションデータのサイズ}
\label{tb:test-size}
\input{1008table04.txt}
\end{table}


\section{形態素解析器}
\label{sec:morph-kytea}

本稿では，既存の辞書やラベルありデータを，対象分野である絵本の特徴にあ
わせて自動的に変換する手法を提案する．学習器は学習データと独立に選ぶこ
とができるが，本稿では，京都テキスト解析ツールキッ
ト\kytea\ \cite{Mori:Nakata:Graham:Kawahara:2011j} の学習機能を利用する．

\kytea では，点予測を採用しており，分類器の素性として，周囲の単語境界や品詞等の推定値を利用せ
ずに，周囲の文字列の情報のみを利用する．
そのため，柔軟に言語資源を利用することができ，分野適応が容易だという
特徴がある\cite{Mori:Nakata:Graham:Kawahara:2011j}．


\kytea のモデル学習時には，フルアノテーションデータ，部分アノテーショ
ンデータ，辞書などの言語資源が利用できる．これらの言語資源は，それぞれ
複数利用することができる．また，辞書と部分アノテーションデータはなくて
もよい．

ここで，フルアノテーションデー
タとは，文全体に形態素情報が付与されたデータである（\ref{sec:full-ano}節，
例\refs{ehon-full}）．また，部分アノテーションデータとは，文の一部に
だけ単語境界や形態素情報が付与されたデータである．
例えば，例\refs{ehon-part}のように，文\refs{eva-org}の\jpn[め]{}と
\jpn[み]{}にだけ形態素情報をアノテーションしたデータを，部分アノ
テーションデータとして利用することができる．
誤りやすい語や分野特有の語にだけ集中的にアノテーションを付与して利用
できるため，能動学習や分野適応に有効である．
 \begin{exe}
 \ex \label{s:ehon-part}
め/名詞-一般/メ/\ul{目},に は 、 い ち ご の 　 あ か い 　,み/名詞-一般/ミ/\ul{実},を 　 い れ ま し た 。
 \end{exe}

なお，\kytea の配布版モデルでは，単語分割とUniDicの品詞大分類，読みの付与を行っているが，
他の種類の品詞や情報を推定するモデルの構築も可能である．
本稿では，既存言語資源との整合性を考慮し，品詞はIPA品詞体系に準拠した．
さらに，元の漢字表記の推定も同時に行う．つまり，
単語分割，IPA品詞体系の品詞，読み，漢字表記による原形推定を出力とするモデルを構築する．

本稿では，フルアノテーションデータとして，
コーパス\hinoki\ \cite{Bond:Fujita:Tanaka:2006}を用いる．\hinoki に
は，\lxd の定義文，例文，京大コーパスの全文\footnote{但し，IPA品詞体系で解析
しなおしてある．}が含まれている．さらに教師あり分野適応
の実験（\ref{sec:exp-add-ehon}章）では，絵本のフルアノテーションデータも利用する．

辞書には，
\naistj \footnote{http://sourceforge.jp/projects/naist-jdic/} （以下，
\ntj），\lxd，および，日本語語彙大系\cite{GoiTaikeij}の固有名詞，および，動植物名\footnote{
具体的には，日本語語彙大系の日本語辞書のうち，\izj{543:生物}配
下の意味クラスが付与されている語を追加した．}を利用する．但し，\lxd と日
本語語彙大系は，本来IPA品詞体系ではないため，自動的に品詞を変換した．


\section{絵本を対象とした形態素解析における問題分析}
\label{sec:bunseki}

本章では，絵本を形態素解析するときに起こる精度低下の原因を調査する．

\ref{sec:mojisyu}節では，一般的なテキストと比べて，絵本のテキストでは，
空白，ひらがなが圧倒的に多く，漢字が非常に少ないことを示した．これらの
違いのうち，直感的には，ひらがなによる曖昧性の増加が精度低下の主要因で
あり，空白は解析の手がかりとなるように感じられる．しかしこれまで，この
直感が正しいかどうか，また，実際にどの程度精度への影響があるのかを調査
した研究はない．そこで本章では，ひらがなと空白の形態素解析への影響を調
査する．


\subsection{実験用解析対象文の作成}
\label{sec:bunseki-bun}

調査用の評価データとして，絵本の\kodomo の
フルアノテーションデータをいくつかのルールに沿って自動的に変換したデータを作成する．
つまり，
絵本に出現した文\refs{eva-org} （\ref{sec:full-ano}節）
から空白を削除したもの（文\refs{eva-del}），
空白を読点に変換したもの（文\refs{eva-punc}），
ひらがなをできるだけ漢字に変換したもの（文\refs{eva-han}），
漢字に変換し，かつ，空白を削除したもの（文\refs{eva-handel}），
漢字に変換し，かつ，空白を読点に変換したもの（文\refs{eva-hanpunc}）
を作成した．

 \begin{exe}
 \ex \label{s:eva-del}
めには、いちごのあかいみをいれました。
 \ex \label{s:eva-punc}
めには、いちごの、あかい、みを、いれました。
 \ex \label{s:eva-han}
目には、苺の　赤い　実を　入れました。
  \ex \label{s:eva-handel}
目には、苺の赤い実を入れました。
  \ex \label{s:eva-hanpunc}
目には、苺の、赤い、実を、入れました。
\end{exe} 


\subsection{実験と結果}
\label{sec:bunseki-exp}

調査のため，
\hinoki コーパスと\naistj などの辞書（\ref{sec:morph-kytea}章）をそのま
ま学習に利用したモデル（以下，\kytea（\Def））を構築する．これは，一般的
な形態素解析モデルと同じような学習条件に相当する．
また，表~\ref{tb:morph-ex} （\ref{sec:introduction}章）で利用した
既存の形態素解析モデルの中で最も誤りの少なかった \mecab も利用する．

\begin{table}[b]
\caption{評価結果: 形態素区切り，および，品詞が一致した数と割合 (\kodomo)}
\label{tb:res-bunseki}
\input{1008table05.txt}
\par\vspace{4pt}
\small
ただし，\refs{eva-org}から\refs{eva-handel}は，対応する評価用データの例の番号を示している．
\par
\end{table}

表~\ref{tb:res-bunseki}に，評価用データ（文\refs{eva-org}，および，
文\refs{eva-del}から文\refs{eva-hanpunc}）のそれぞれに対し，形態素解析を
実行し，形態素区切りと品詞一致精度を調べた結果を示す．



\subsection{分析}
\label{sec:ana-sphan}


表~\ref{tb:res-bunseki}の\pos{\Org \refs{eva-org}}の列が，
絵本のテキストをそのまま解析した場合の精度であり，
\kytea（\Def）では 63.0\%，\mecab では 83.2\%だった．
\mecab は
ひらがなのままの評価データの場合でも，ひらがなを考慮しない一般的な学習条件で学習し
た\kytea（\Def）よりも精度が高い．しかし，
新聞である京大コーパスを対象とした場合
98\% 以上の精度が報告されているのに比べると\footnote{\mecab\ ver.0.90 の場合．http://mecab.googlecode.com/svn/trunk/mecab/doc/feature.htmlより．}，
はるかに低い精度である．

ここで，空白の影響を分析する．\kytea（\Def）では，空白を削除す
ると精度が向上する．また，空白を読点に変更すると精度はさらに向上する．
これは，学習データに空白が出現しないため，学習できていないためだと考えられる．
空白をただ削除するよりも，読点に変更した方が精度が高くなることから，
空白の働きをうまく学習することができれば，区切りの判別の手がかりとして有効に働く
だろうことが予想できる．

実際，\mecab の場合，空白は区切りの判別のための手がかりと
して有効に利用されているようであり，空白を削除するとむしろ精度は低下す
る．また，空白を読点に変更した場合と空白のままの場合の精度は同程度で
あり，空白が読点の代わりを果たしていることが伺える．


特に，\refs{err-del}のように，擬音語や擬態語が連なる場合，
空白を削除すると，解析が非常に困難になっており，
空白の有無が形態素の判別に有効な手がかりであることがわかる．
 \begin{exe} 
 \ex \label{s:err-del}
  「こちょ　こちょ　こちょ　こちょ \\
 {\small （豊田一彦 「こちょこちょももんちゃん」p.~24（2010，童心社））}\\
  COR:「,\ul{こちょ,　,こちょ,　,こちょ,　,こちょ}\\
  RES:「,\ul{こ,ちょこ,ちょこちょこ,ちょ}\\
 \small （ただし，COR: は正解，RES: は空白を削除した場合の結果）
 \end{exe} 

次に，ひらがなが多いことによる影響を分析する．
評価データ中のひらがなを漢字に変換した場合，
\kytea（\Def）でも\mecab でも，ひらがなのままの評価データより高い精度
が得られる．空白を読点に変換した場合の精度
（表~\ref{tb:res-bunseki}の
\pos{\Sp\ \refs{eva-punc}}と
\pos{\HanSp\ \refs{eva-hanpunc}}）で
比較すると，
\kytea（\Def）では $+11.4$\%，\mecab では $+8.2$\% 精度が向上しており，
漢字は大きな手がかりとなっていることがわかる．
つまり，一般的なテキストとの大きな違いのうち，
ひらがなによる曖昧性の増大が解析精度の低下の主な要因だといえる．


なお，元データのままだと解析に失敗するが，漢字に変換すると正解する例には，
\refs{err-org}などがあった．
 \begin{exe}
 \ex \label{s:err-org}
  みずを　のみにきた　うしさんに \hfill
{\small （たちもとみちこ「おほしさま」p.~10（2006，教育画劇））}\\
COR: みず,を,　,のみ,に,き,た,　,うし,さん,に,\\
RES: みず,を,　,のみ,に,\ul{きた},　,\ul{うしさん},に\\
RES2: 水,を,　,飲み,に,\ul{来,た},　,\ul{牛,さん},に\\
\small （ただし，COR: は正解，RES: は結果，RES2: は漢字に変換した場合の結果）
 \end{exe} 


\section{提案手法}
\label{sec:morph}

 本章では，絵本の特徴に合わせたラベルありデータと辞書の変換方法を提案す
 る（\ref{sec:train-data}，\ref{sec:dic}節）．また，ラベルありデータと辞
 書の変換と追加の必要性について議論する（\ref{sec:comp-kudo}節）．


\subsection{ラベルありデータの変換方法}
\label{sec:train-data}


\ref{sec:bunseki}章で示したように，絵本の解析では，空白の働きを学習することと，
ひらがなが多い文でも解析できることが必要である．
そこで，既存のラベルありデータである\hinoki コーパスを 3 通りの方法で自動的に変換する．
例えば，文\refs{lxdex-org}は，\lxd での見出し語\jpn[きしめん]{}に付与さ
れた例文である．
この文に，まず，句読点の直後を除く文節毎に空白を挿入する（文\refs{lxdex-sp}）．
また，すべての漢字をひらがなの読みに変換する（文\refs{lxdex-hira}）．
句読点の直後を除く文節毎に空白を挿入し，かつ，ひらがなに変換する
（文\refs{lxdex-hirasp}）．このように，元の文に対して 3 通りの変換を行い，ラベルありデータデータを作成する．

 \begin{exe} 
 \ex \label{s:lxdex-org}
寄せ鍋,に,きしめん,を,入れる,。
 \ex \label{s:lxdex-sp}
寄せ鍋,に,　,きしめん,を,　,入れる,。
 \ex \label{s:lxdex-hira}
よせなべ,に,きしめん,を,いれる,。
 \ex \label{s:lxdex-hirasp}
よせなべ,に,　,きしめん,を,　,いれる,。
 \end{exe}

 さらに，元の漢字表記の推定も同時に行うため，元の漢字表記による原形を利
 用する．つまり，文\refs{lxdex-hira}や\refs{lxdex-hirasp}のようにひらが
 なに変換した場合でも，原形は漢字表記を利用する．そのため，例え
 ば\refs{lxdex-hira}は，実際には\refs{lxdex-hira-full}のような形で与えられる．

 \begin{exe}
 \ex \label{s:lxdex-hira-full}
よせなべ/名詞-一般/ヨセナベ/\ul{寄せ鍋},に/助詞-格助詞-一般/ニ/に,きしめん/名詞-一般/キシメン/きしめん,を/助詞-格助詞-一般/ヲ/を,いれる/動詞-自立/イレル/\ul{入れる},。/記号-句点/。/。
 \end{exe}

\ref{sec:exp-adult}章では，ラベルありデータの変換方法毎の
 効果を検証するため，これらの組み合わせを変えて利用した場合の精度評価を
 行う．

なお，空白の挿入に利用した文節区切りや，ひらがなへの変換に利用した読みは，
元々コーパスに付与されていたものであり，自動的に変換することができる．
本稿では\hinoki コーパスを利用したが，京大コーパスでも文節
情報や読みは付与されているため，同様の変換ができる．また\bccwj 
にも読みは付与されている．文節情報は付与されていないが，形態素情
報は付与されているため，助詞と自立語が連続する箇所に空白をいれるなどの
簡単なルールによって，同様の自動的変換が可能である．


\subsection{辞書の変換方法}
\label{sec:dic}

\ref{sec:morph-kytea}章で紹介した通り，辞書には
\ntj，\lxd，日本語語彙大系の固有名詞，および，動植物名を利用しており，
これらを絵本の特徴にあわせて変換する．

まず，\ntj と\lxd の漢字やカタカナのエントリ
をひらがなに変換したエントリも作成し，辞書に追加する．
固有名詞や動植物名は，カタカナで表記されることも多いため，
カタカナ，ひらがなの両方に変換したエントリも作成し，辞書に追加する．
このとき，原形には漢字やカタカナの表記を用いる．
例えば，
\jpn[伊予柑]{}の場合，元の見出し語か
ら得られる辞書エントリは\refs{iyokan-org}となるが，ひらがなのエントリ
\refs{iyokan-hira}とカタカナのエントリ\refs{iyokan-kata}も追加した．
しかし，人名の固有名詞だけは，カタカナはカタカナのまま，
ひらがなはひらがなのまま原形とした．
これは，ひらがなで出てくる人名の漢字表記が何かは決められないためである．
最終的に利用した辞書サイズは，表~\ref{tb:dic-size}の通りで
ある．

\begin{exe}
  \ex \label{s:iyokan-org}
  伊予柑/名詞-一般/イヨカン/伊予柑
  \ex \label{s:iyokan-hira}
  いよかん/名詞-一般/イヨカン/伊予柑
  \ex \label{s:iyokan-kata}
  イヨカン/名詞-一般/イヨカン/伊予柑
\end{exe}

\begin{table}[b]
\caption{辞書サイズ：ひらがなやカタカナに展開済み}
\label{tb:dic-size}
\input{1008table06.txt}
\end{table}


\subsection{辞書と学習データの追加の必要性についての議論}
\label{sec:comp-kudo}

\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}は，
Web上のひらがな交じり文に対する形態素解析手法の提案にあたり，
次のように述べている．
\begin{quote}
ひらがな交じりの解析も，通常の日本語の文の解析であ
ることには変わりがないため，
以下のような一般的に用いられている既存手法で解析精度を向上させること
が可能である．\\
1. ひらがな単語のユーザ辞書への追加\\
2. ひらがな交じり文を含む学習データを人手で作成し，再学習\\
1. は簡単な手法であるが，ひらがなは日本語の機能語に用いられているた
め，むやみにひらがな語を追加すると副作用により精度が低下する可能性
がある．2. の方法は学習データの作成が必要なためコストが高い．
\end{quote}

これらの理由によって，\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}では，
辞書への追加や学習データの追加は行われていない．
\citeA{Kudo:Ichikawa:Talbot:Kazawa:2012j}の手法は，広い分野に対して安定
的に比較的高い精度で解析を行える．しかし，特定の分野における実用を考え
た場合，対象分野においてより高い精度を得ることが重要である．
確かに，1. に関して，ひらがな語を多く追加することによる副作用の可能性は
否定できないが，絵本の場合，いずれの語でもひらがなで記述される可能性が
あるため，すべてのエントリをひらがなにする必要がある．また，2. に関して
は，提案手法では自動的に学習データを作成するので問題ない．

本稿では，提案手法で変換・作成した
辞書と学習データを学習に用いることで，絵本に対しては
既存モデルより高い精度が得られることを示す（\ref{sec:exp-adult}章）．
ただし，本提案手法で得られる精度
は，既存モデルよりは高いが，実用的にはまだ改良の必要がある．
そのため，さらなる精度向上のためには，能動学習や対象分野のラベルありデータの構築が必要となるが，
その際も，ベースとなるモデルの精度がより高い方がより効率的である．


\section{評価実験(1): 教師なし分野適応}
\label{sec:exp-adult}

本章では，前章で提案した手法により変換した既存言語資源だけを学習に利用する
評価実験，つまり，教師なし分野適応の実験を行う．

前章で紹介した通り，ラベルありデータは3通りの変換により作
  成した．これらと，変換前のラベルありデータを組み合わせて学習に用いた
  場合の精度評価を行った（表~\ref{tb:res}）．
表~\ref{tb:res}では，形態素区切り，および，品詞の細分類までが一致した精度を示している．
表~\ref{tb:res}は，絵本に出現した
文に対する解析精度であり，表~\ref{tb:res-bunseki}の左端\pos{元データ \refs{eva-org}}の列に当たる．
比較のため，表~\ref{tb:res}にも結果を再掲した．


\begin{table}[b]
\caption{評価結果: 形態素区切り，および，品詞が一致した数と割合 (\kodomo)}
\label{tb:res}
\input{1008table07.txt}
\vspace{4pt}
\small
ただし，\refs{lxdex-org}から\refs{lxdex-hirasp}は，対応する学習データの例の番号を示している．\\
また，[A]--[C]は参照用に付与した記号である．
\par
\end{table}

既存言語資源をそのまま学習に利用した場合，精度は 63.0\%と非常に低いが，
空白を追加したり，ひらがなに変換した学習データを利用することで，
88.5\%まで精度を向上できた．
つまり，新聞データなどの一般向けのテキストを学習データに利用する場合でも，
絵本での出現傾向にあわせて変換することで，相当な精度向上が出来た．

ここで，空白を追加した学習データだけを利用する場合[B]より，空白を追加し
ない学習データも利用する[C]の方が精度が高かった．これは，すべての絵本で
全文節ごとに空白が入るわけではないので，両方を学習に利用した方が良かっ
たのだと考えられる．同様に，ひらがなに変換した学習データだけを利用する
より，漢字のままの学習データも利用する方が若干精度が高かった．これは，
すべての絵本で漢字が全く出現しないわけではないためだと考えられる．

以降，最も高い精度を得られたラベルありデータ（表~\ref{tb:res} [C] の ``両方利用 \refs{lxdex-org}〜\refs{lxdex-hirasp}''）を\bestHINOKI，
得られたモデルを用いた解析器を\kytea\ (\bestHINOKI)と呼び，これ
をベースに，さらに改良を加えることを検
討したい．
また，絵本によって，空白や漢字の含有率は非常に異なるため，
これらの含有率によって
学習に利用するデータを変更することも考えられる．


\section{評価実験(2): 教師あり分野適応}
\label{sec:exp-add-ehon}

\ref{sec:exp-adult}章の実験では，ラベルありデータとして既存言語資源から得た
コーパスだけを用いた．
しかし分野適応では，同じ分野のラベルありデータを追加すると精度が向上す
ることはよく知られており，本章では，絵本自体のラベルありデータを学習に
用いた実験を行う．

本章の目的は二つある．一つは，
提案手法によって既存言語資源から自動的に獲得し
たラベルありデータが，どの程度の絵本自体のフルアノテーションデータと
同程度の効果があるかを調べることである．
もう一つは，絵本自体へアノテーションするときの効率的な方法
を示すことである．


\subsection{学習曲線}
\label{sec:exp-add-ehon-full}

本節では，
フルアノテーションデータ\kodomo（\ref{sec:full-ano}節）の
各絵本をそれぞれ10分割し，それらを徐々に学習データに追加した場合
の学習曲線を調べる．ここで，\ref{sec:exp-adult}章で最も良い精度を得
た学習データである\bestHINOKI と絵本を両方学習に利用する場合
と，絵本だけを学習に利用する場合の両方の実験を行った．

また，評価は2通り行う．
つまり，学習データを追加した絵本と，
(1) 同じ絵本のテキストによる評価（\kodomo を利用），
(2) 違う絵本のテキストによる評価（\random を利用），
を行う．

本節での精度評価は，品詞まで一致した精度に加え，原形まで一致した精度評価も行っている．
本稿で構築している形態素解析モデルでは，
出現形がひらがなでも，原形は出来る限り漢字表記を推定している（\ref{sec:train-data}節）．
ひらがなで出現した語に対し，漢字表記を推定することができれば，
その後の解析に有用だからである．
例えば，\jpn[め]{}という語が\jpn[目]{}なのか\jpn[芽]{}なのか，
\jpn[はな]{}という語が\jpn[鼻]{}なのか\jpn[花]{}なのか，などは，幼児の言語発達を調べる
ときにも区別する必要がある\cite{Ogura:Watamaki:2008}．
これは，本来，語義曖昧性解消問題として取り組むべき課題かもしれないが，
形態素解析時に同時に推定が可能なら利便性が高い．
そこで，本節では，形態素解析時の漢字の原形推定をどの程度の精度で行うことができるかも
同時に調査した．

 \begin{figure}[b]
\setlength{\captionwidth}{197pt}
  \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f1.eps}
    \hangcaption{学習曲線：同じ絵本を学習データに追加（\kodomo, 品詞一致）}
    \label{fig:lc-self-POS}
  \end{minipage}
\hfill
  \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f2.eps}
   \hangcaption{学習曲線：異なる絵本を学習データに追加（\random, 品詞一致）}
    \label{fig:lc-rand-POS}
  \end{minipage}
\end{figure}
\begin{figure}[b]
\setlength{\captionwidth}{197pt}
  \begin{minipage}[t]{199pt}
    \includegraphics{21-3ia1008f3.eps}
   \hangcaption{学習曲線：同じ絵本を学習データに追加（\kodomo, 原形一致）}
    \label{fig:lc-self-BS2}
  \end{minipage}
\hfill
  \begin{minipage}[t]{197pt}
   \begin{center}
    \includegraphics{21-3ia1008f4.eps}
   \end{center}
   \hangcaption{学習曲線：異なる絵本を学習データに追加（\random, 原形一致）}
    \label{fig:lc-rand-BS2}
  \end{minipage}
 \end{figure}

ここで，図~\ref{fig:lc-self-POS}, \ref{fig:lc-self-BS2}は，\kodomo の
各絵本の1/10を評価データとし，それ以外を順次追加した場合の学習曲線を示
している．また，図~\ref{fig:lc-rand-POS}, 
\ref{fig:lc-rand-BS2}は，\random を評価データとした場合の精度を示して
おり，\kodomo のすべてを学習データに追加した場合の精度も示している．ま
た，図~\ref{fig:lc-self-POS}, \ref{fig:lc-rand-POS}は，品詞一致の精度，
図~\ref{fig:lc-self-BS2}, \ref{fig:lc-rand-BS2}は，原形まで一致した精度
を示している．
ただし，学習データでは，コーパス\hinoki の漢字等による原形をそのまま原形として利用したため，
学習データの原形に表記ゆれが存在する．
そこで，原形一致精度の評価時には，\jpn[仔牛]{}と\jpn[子牛]{}，
\jpn[雄]{}と\jpn[オス]{}のように，表記ゆれだとみなせるものは正解に含めている
\footnote{表記ゆれの判断は，日本語語彙大系によった．}．
また，\mecab は漢字表記による原形推定はしないため，ひらがなの原形も正解とした．
標準表記の決定，学習データの標準表記への変換は今後の課題としたい．


\subsection{提案手法の効果：評価(2)}
\label{sec:eva2}

提案手法で作成した\bestHINOKI の効果を調べる．
図~\ref{fig:lc-self-POS}〜\ref{fig:lc-rand-BS2}から，
すべての場合で，\bestHINOKI に
絵本データを追加した方が，絵本データだけの
場合や，\bestHINOKI だけの場合より精度が向上しており，
絵本とは全く異なる一般向けのテキストであっても，
\bestHINOKI を学習に利用する方が良いことがわかる．

特に，図~\ref{fig:lc-rand-POS}, \ref{fig:lc-rand-BS2}に示した通り，
別の絵本(\random)に対する精度は，学習データに絵本だけを用いる場合より非常に高い．
\random の場合，品詞一致でも，原形一致でも，絵本の学習データだけで
\kytea\ (\bestHINOKI)と同等の精度を得るには，
\kodomo のフルアノテーションデータ約 11,000行，90,000形態素が必要である．
これは，\kodomo のフルアノテーションデータの 8/10近くにあたる．
これだけのフルアノテーション作業には相当な時間とコストがかかっており，
提案手法による自動的な変換による精度向上の効果は高い．


なお，\random に対する精度は，すべての\kodomo を学習データに追加した場合で，
形態素区切り 98.3\%，品詞完全一致 91.1\%，品詞大分類 94.7\%，原形一致 89.0\%だった．
これが，新しい絵本を解析する場合の精度にあたる．


\subsection{アノテーション方針の提案}
\label{sec:ano-houshin}

本節では，同じ絵本を学習データとして追加した場合の効果を調べる．
図~\ref{fig:lc-self-POS}, \ref{fig:lc-self-BS2}から，
同じ絵本の学習データは非常に有効であることがわかる．
\bestHINOKI を使わない場合でも，同じ絵本の 10 分の 2 を学習データとして用いただけで
\kytea\ (\bestHINOKI)の精度より高い精度を得ることができる．
このように，同じ絵本のデータの追加のほうが効果が圧倒的に高いため，
同じ分量のアノテーションを行うのであれば，少しずつでも，
できるかぎり全ての絵本からアノテーションすることが望ましい．
同じ絵本のアノテーションが特に有効な理由には，同じ固有名詞（\ref{sec:errors}, \ref{sec:add-proc}節参照）
や，同じ表現が出現することがあげられるだろう．
絵本は，例えば，例\refs{ex-repeat}のように
一部の語を変えて同じ表現が繰り返されることが多く，一部をアノテーションする効果が高い．
なお，\refs{ex-repeat}の絵本の場合，\jpn[なんて　なく？]{}は11 回出現している．

 \begin{exe} 
 \ex \label{s:ex-repeat}
 かえるは\\
 \ul{なんて　なく？}\\
 にわとりは\\
 \ul{なんて　なく？} \hspace{5mm}
\small （凹工房 「どうぶつ　なんて　なく？」p.~2--3 （2008，ポプラ社））
 \end{exe}


\subsection{誤り内容の変化}
\label{sec:errors}

\newcommand{\COM}{}

\begin{figure}[b]
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f5.eps}
   \end{center}
  \caption{\COM（\kodomo, 動詞）}
   \label{fig:lc-self-err-VERB}
 \end{minipage}
\hfill
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f6.eps}
   \end{center}
  \caption{\COM（\random, 動詞）}
   \label{fig:lc-rand-err-VERB}
 \end{minipage}
\end{figure}
\begin{figure}[b]
\setlength{\captionwidth}{197pt}
 \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f7.eps}
  \hangcaption{\COM（\kodomo, 名詞-固有名詞）}
   \label{fig:lc-self-err-PROP}
 \end{minipage}
\hfill
 \begin{minipage}{199pt}
    \includegraphics{21-3ia1008f8.eps}
  \hangcaption{\COM（\random, 名詞-固有名詞）}
   \label{fig:lc-rand-err-PROP}
 \end{minipage}
\end{figure}

\begin{figure}[t]
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f9.eps}
   \end{center}
  \caption{\COM（\kodomo, 感動詞）}
   \label{fig:lc-self-err-KANDO}
 \end{minipage}
\hfill
 \begin{minipage}{0.48\hsize}
   \begin{center}
    \includegraphics{21-3ia1008f10.eps}
   \end{center}
  \caption{\COM（\random, 感動詞）}
   \label{fig:lc-rand-err-KANDO}
 \end{minipage}
\end{figure}

本節では，絵本を学習データに追加した場合の，誤り内容の変化を調査する．
解析を誤った語を品詞毎に集計し，\pos{動詞}\pos{名詞-固有名詞}\pos{感動詞}について，それぞれ
図~\ref{fig:lc-self-err-VERB}と\ref{fig:lc-rand-err-VERB}，
\ref{fig:lc-self-err-PROP}と\ref{fig:lc-rand-err-PROP}，
\ref{fig:lc-self-err-KANDO}と\ref{fig:lc-rand-err-KANDO}
に示した．
図~\ref{fig:lc-self-err-VERB}〜\ref{fig:lc-rand-err-KANDO}
では，誤りの絶対数と，全誤り数に占める対象品詞の割合をプロットしている．

誤りの絶対数はどの品詞でも減少しているが，全誤りに占める各品詞の割合を
見ると，比較的学習しにくい品詞がわかる．\pos{動詞}（図~\ref{fig:lc-self-err-VERB}, \ref{fig:lc-rand-err-VERB}）は
\kodomo でも\random でも相対的に上昇している．
\pos{固有名詞}（図~\ref{fig:lc-self-err-PROP}, \ref{fig:lc-rand-err-PROP}）の場合，\kodomo では急激に割合が下がるが，
\random では逆に相対的に上昇している．
\pos{固有名詞}は，絵本間で共通のものが少なく，しかも，
ひらがな（\mbox{\jpn[ぐり]{}}\footnote{\label{prop1}「ぐりとぐら」（なかがわりえこ　と　やまわきゆりこ（1963，福音館書店））などより．}，
\jpn[ぐら]{}$^{\ref{prop1}}$，
\jpn[もものこ]{}\footnote{「もものこさん」（あまんきみこ　さく　かのめかよこ　え（2011，福音館書店））より．}など）や，
ひらがなカタカナ混じり
（\jpn[ウサこ]{}\footnote{\label{prop2}「いけるといいね　トイレ」（原作やなせたかし　作画東京ムービー（2001，フレーベル館））などより．}，
\jpn[ネコみ]{}$^{\ref{prop2}}$など）など，
非常に解析が難しいものが多いからだと思われる．
対照的に，\pos{感動詞}（図~\ref{fig:lc-self-err-KANDO}, \ref{fig:lc-rand-err-KANDO}）は，\random でも誤る割合が下がっている．
これは，異なる絵本でも共通の表現が多いためだと考えられる．
例えば，\random 側で，\bestHINOKI だけでは正解しなかったが，
絵本を追加していくことで正解するようになった感動詞には，
\jpn[あっぷっぷ]{}，\jpn[ごくろうさま]{}，
\mbox{\jpn[ギャオー]{}}などがあった．


\section{考察}
\label{sec:kousatsu}


本章では，前章までに得たモデルをさらに改良するための問題分析と改良案の提示を行う．
まず，\ref{sec:age-acc}節では，対象年齢と形態素解析精度の関係に着目し，精度低下のより詳細な原因調査を行う．
\ref{sec:add-proc}節では，絵本のラベルありデータを追加しても精度が向上しにくかった
固有名詞に焦点をあて，固有名詞の部分アノテーションによる精度向上の効果を検証する．
さらに，\ref{sec:other}節では，提案手法の絵本以外のコーパスへの適用可能性についても考察する．


\subsection{対象年齢と形態素解析精度}
\label{sec:age-acc}

\ref{sec:ehon-db}節で述べたように，\kodomo は対象年齢がはっ
きり設定されている．そこで本節では，\kodomo を用いて，対象年齢と形態素
解析精度の関係を分析する．\kytea\ (\bestHINOKI)と，\mecab を使って
元データを解析した場合の対象年齢と精度の関係を図~\ref{fig:age-acc}に示
す．ただし，図~\ref{fig:age-acc}では，\kod{012}を2歳児にプロットしてい
る．

 図~\ref{fig:age-acc}から，\kytea\ (\bestHINOKI)でも\mecab でも，対
 象年齢が低いほど形態素解析精度も低いことがわかる．
どちらの解析器も，基本的に一般向けのコーパスを学習データとして
モデルが作成されており，対象年齢が上がるとより一般向けの文に
近づいていることが図~\ref{fig:age-acc}からも読み取れる．

 \begin{figure}[b]
   \begin{center}
    \includegraphics{21-3ia1008f11.eps}
   \end{center}
 \caption{対象年齢と形態素解析（形態素区切りと品詞一致）精度の関係(\kodomo)}
  \label{fig:age-acc}
 \end{figure}
\begin{table}[b]
\caption{文字種毎の数と割合：絵本の対象年齢ごと (\kodomo)}
\label{tb:mojisyu-kodomo}
\input{1008table08.txt}
\end{table}


表~\ref{tb:mojisyu}（\ref{sec:mojisyu}節）で示したように，絵本と
京大コーパスなど
に出現する文字種を比較すると，
絵本はひらがなと空白が多く，漢字が少ない点が顕著に異なっていた．また，
\ref{sec:ana-sphan}節では，特にひらがなが形態素解析精度の低下に非常に関わることを
示した．
そこで，対象年齢によってそれらの文字種の出現傾向が変わるかどうか
を，\kodomo のデータを使って調査した（表~\ref{tb:mojisyu-kodomo}）．


 表~\ref{tb:mojisyu-kodomo}によると，文字種の出現傾向に絵本全体の傾向と
 顕著な違いは見られず，対象年齢によって明らかな変化は見られなかった．つ
 まり，ひらがなの多さだけが精度低下の原因ではないことがわかる．ただし，
 表~\ref{tb:mojisyu-kodomo}に参考として示した，行平均の文字数と形態素数
 は，対象年齢が上がるにつれ増加している．京大コーパスと\lxd の文平均の
 文字数や形態素数（表~\ref{tb:mojisyu}）と比較すると，文平均か，行平均か
 の差はあるが，対象年齢が上がるにつれ\lxd の数値に近づいており，辞書の
 例文や定義文に近い長さになってきていることがわかる．つまり，語の羅列で
 はなく，文になってきていると考えられる．


そこで，文字種だけではわからない差分を調査するため，
空白を除く全形態素に占める品詞毎の割合を調査した．
その結果，対象年齢によってもっとも変化が大きかった品詞は，\pos{助詞}\pos{記号}
\pos{副詞}\pos{感動詞}だった．
図~\ref{fig:age-hinshi}に，これらの品詞の占める割合の対象年齢毎の変化と，\lxd での割合を示す．
ここで，\pos{助詞}の割合は対象年齢と共に単調増加しており，
単語の羅列から助詞などを含む文となっていることがわかる．
\pos{記号}は，句読点や括弧などを含むため，句読点を使った文や会話文の量や長さに関係すると考えられる．
\pos{記号}は，\kod{012}と\kod{3}の間で大きく増加しているが，単調増加で
はなく，\kod{5}や\lxd での割合はむしろ\kod{3}や\kod{4}より低い．これは
文が長くなるため記号の占める割合が低くなるのだと考えられ
る．例えば，会話文の場合，記号である\jpn[「]{}と\jpn[」]{}の間
  に発話内容が記述されるが，発話内容が長くなれば，記号の占める割合は低
  くなる．一方，\pos{副詞}の割合は対象年齢に応じて単調減少してい
る．\pos{副詞}には擬音語や擬態語が多く含まれ，対象年齢が低いほど，そう
した語の含まれる割合が高いことがわかる．また，\pos{感動詞}の割合
は\kod{012}と\kod{3}の間で大きく減少している．\pos{感動詞}には挨拶など
が含まれ，より小さな子供向けの絵本では，挨拶などが多く出現するためだと
思われる．

 \begin{figure}[b]
   \begin{center}
    \includegraphics{21-3ia1008f12.eps}
   \end{center}
 \caption{空白を除く全形態素に占める品詞割合：絵本対象年齢毎(\kodomo)と\lxd}
  \label{fig:age-hinshi}
 \end{figure}

なお，絵本毎に精度を調査すると，品詞一致精度で最も精度の高かった絵本と，最も精度の低かった絵本は，
両方とも\kod{012}に含まれた．
これらは，一行一形態素程度の非常に短い文からなっており，
\jpn[ぴょん]{}\jpn[ぼちゃん]{}\jpn[ぶらぶら]{}などの擬音語や擬態語の繰り返しがほとんどだった．
文脈はほぼないため，学習データや辞書に該当する語が
存在するかどうかに依存して精度が大きく変化したとみられる．
そのため，より対象年齢の低い子供向け絵本の解析精度の向上は，
擬音語や擬態語の辞書や学習データの拡充にかかっているといえるだろう．
今後は，擬音語や擬態語の収集による精度向上にも取り組みたい．


\subsection{固有名詞のアノテーション}
\label{sec:add-proc}

\ref{sec:errors}節で述べたように，固有名詞は
他の絵本を追加しても解析精度が向上しにくく，学習データなしでは
解析が難しい語が多い．その上，固有名詞の誤りは数値以上に精度が悪い印象を与えかねない．
しかし一方で，活用語や非自立語などに比べ，固有名詞のアノテーションや辞書への追加は非常に容易である．

ここで，\random に出現した固有名詞でもっとも誤り回数が多かった（各 4 回）
\jpn[ぐり]{}と\jpn[ぐら]{}に着目する．
これらを辞書登録しただけでは解析精度は変わらなかったが，
\kytea では，部分アノテーションしたデータを学習データに加えることがで
きる（\ref{sec:morph-kytea}章）．
そこで，\jpn[ぐり]{}と\mbox{\jpn[ぐら]{}}に対し部分アノテーションを行い，その効果を検証した．


部分アノテーションは以下の流れで行った．
まず，[1] 対象語を含む文を字面一致で抽出し，
次に，[2] 人手で該当箇所に対象語以外の語が含まれないか確認し，
最後に，[3] 自動的に部分アノテーションを実行した．

ここで，
\jpn[ぐり]{}と\jpn[ぐら]{}の場合，[2]の確認作業で，
\jpn[どん\ul{ぐり}]{}，
\jpn[うす\ul{ぐら}い]{}，
\mbox{\jpn[\ul{ぐら}い]{}}が混じっていることがわかった．
[3]では，最長一致によってこれらの語のアノテーションも自動的に行った．
例えば，文\refs{gurigura}の場合，
下線部をそれぞれ，
\jpn[ぐり/名詞-固有名詞-人名-一般/グリ/ぐり]{}，
\jpn[ぐらい/助詞-副助詞/グライ/ぐらい]{}
として部分アノテーションした．

 \begin{exe} 
 \ex \label{s:gurigura}
\ul{ぐり}が　けいとを　まくと、えんどうまめ\ul{ぐらい}になりました。\\
\small （なかがわりえこ　と　やまわきゆりこ「ぐりとぐらのえんそく」p.~15 （1979, 福音館書店））
 \end{exe}

これにより部分アノテーションされたのは，
\jpn[ぐら]{} 135箇所，
\jpn[ぐり]{} 131箇所，
\jpn[どんぐり]{} 1箇所，
\jpn[うすぐらい]{} 2箇所，
\jpn[ぐらい]{} 6箇所だった．
これらの部分アノテーションデータを学習データに追加したところ，
原形一致の精度が $+0.2$\% 改良された．品詞一致までの精度は，
小数点第一位までの比較では同じだったが，
\jpn[ぐり]{}と\jpn[ぐら]{}に関する誤りはなくなった．
固有名詞は学習しにくく，かつ，同じ絵本では何度も出現
するため，固有名詞のみを先にアノテートすることは有効だと考えられる．


固有名詞を含めた固有表現や未知語の抽出方法に関する研究は多
く\cite{Murawaki:Kurohashi:2010j,Katsuki:Sasano:Kawahara:Kurohashi:2011j,Sasano:Kurohashi:2007j}
，特に格フレーム情報を利用する方法\cite{Sasano:Kurohashi:2008j}は，
絵本でも有効だと考えられる．今後は，
絵本やシリーズ毎の固有名詞の抽出や，該当固有名詞を含む他の語の確認・抽
出を自動・半自動化することにより，精度向上を目指したい．
また，\citeA{Neubig:Nakata:Mori:2011}
は，SVM平面からの距離を用いて
確信度の低いデータを選び，部分アノテーションして学習データに追加
する能動学習を提案している．
固有名詞のように，一気にアノテートできる部分を学習に追加した後は，
\citeA{Neubig:Nakata:Mori:2011}
と同様に能動学習を行うことが考えられる．


\subsection{他分野への適用可能性}
\label{sec:other}

本節では，提案手法の絵本以外への適用可能性について考察する．

提案手法は，既存の言語資源と解析対象の言語資源の特徴が大きく異なる場合
に有用である．

例えば，小学生は学年毎に習う配当漢字が決められている．そのため教科書では，習っていな
い漢字をひらがなで記載するため，漢字とひらがなが一般向け文章とは全く異なる交じり方を
する場合があり，形態素解析を難しくしている．例えば，\mbox{\jpn[音楽]{}}の場合，
\jpn[音]{}は 1 年生，\mbox{\jpn[楽]{}}は
2 年生の配当漢字であるため，\mbox{\jpn[音がく]{}}
と記載される場合がある\footnote{畑中良輔ほか「小学生の音楽 2」（2006，教育芸術社）より．}．
そこで，教科書等の学
童用の文章の解析用には，学年配当漢字に基づいて利用できる漢字を制限し，それ以外はひら
がなに変換して学習データを作成することが考えられる．


あるいは，Webなどに出現するくだけた文章の解析用として，文末表現の変換，
利用語彙の制限などにより，学習データを変換することも考えられる．

このように，
学習データを対象分野に合わせて自動的に変換するルールを決定できる場合には，
本提案手法が適用できると考えられる．


\section{まとめと今後の課題}
\label{sec:conclusion}

これまで，主に新聞などのテキストを対象とした解析
では，形態素解析器を始めとして高い解析精度が達成されている．しかし
分野の異なるテキストに対しては，
既存の解析モデルで，必ずしも高い解析精度を得られるわけではない．
そこで本稿では，既存の言語資源を対象分野の特徴にあわせて自動的に変換する手法を提案した．
本稿では，絵本を解析対象とし，既存の言語資源を絵本の特徴にあわせて自動的に変換し，
学習に用いることで精度向上できることを示した．


まず，\ref{sec:target}章では，解析対象である絵本データベースの紹介を行っ
た．また，新聞などのテキストと絵本のテキストの文字種毎の割合を比較し，
絵本では，漢字が少なく，空白とひらがなが多いことを示した．
\ref{sec:morph-kytea}章では，実験で利用する形態素解析器\kytea の学習機
能について紹介した．
また，\ref{sec:bunseki}章では，絵本の形態素解析における問題分析のため，
絵本の評価用データに対し，ひらがなを漢字に変換したり，空白を削除するな
どの処理を行った場合の解析精度の変化を調査し，ひらがなが多いことが
解析精度低下の主な原因であることを示した．

\ref{sec:morph}章では，\ref{sec:target}章と\ref{sec:bunseki}章の
分析結果に基づき，既存の言語資源を絵本の特徴にあわせて変換する手法を提案した．
\ref{sec:exp-adult}章では，提案手法によって得た言語資源だけを学習に用いた
教師なし分野適応の実験を行い，既存の一般的な形態素解析モデルより高い
精度（品詞一致精度で 88.5\%）が得られることを示した．
また\ref{sec:exp-add-ehon}章では，絵本自体のラベルありデータを学習
に用いた教師あり分野適応の実験を行い，学習曲線を調べた．
ここで，提案手法によって得た既存言語資源によるラベルありデータは，
絵本自体のラベルありデータ約11,000行，90,000形態素と同程度の効果が
あることを示した．
さらに，絵本自体にアノテーションを行う場合，できるかぎり全ての絵本から，
アノテーション対象を選択することが効率的であることを示した．
また，新しい絵本に対する解析精度は，
形態素区切り 98.3\%，品詞完全一致で 91.1\%，品詞大分類で 94.7\%，漢字の原形一致で 89.0\% が見込めることを示した．

\ref{sec:kousatsu}章の考察では，
絵本の対象年齢毎の形態素解析精度
の変化を調査し，対象年齢が低いほど解析精度も低く，その原因としては，文字種より，助詞な
どを含む文としての形態を取るかどうかに関連することを示した（\ref{sec:age-acc}節）．
また，
他の絵本を学習データに追加しても，固有名詞の推定精度の向上は難し
いが，固有名詞のアノテーションは，活用語などに比べて容易であることから，
固有名詞に対して半自動的に部分アノテーションを行うことで，固有名詞の解
析精度が向上できることを示した（\ref{sec:add-proc}節）．


今後は，標準表記を決定し，学習データの標準表記への変換と，
漢字による原形推定精度の向上に取り組みたい．
また，
絵本やシリーズ単位での，固有名詞（人や動物の名前）の自動的発見，および，
固有名詞の（半）自動的な部分アノテーションに取り組みたい．

また，本稿で紹介した絵本用形態素解析モデルを利用し，
子供向けの文を対象とした難易度測定や
絵本の対象年齢の推定\cite{Fujita:Kobayashi:Taira:Minami:Tanaka:2014j}，
子供の発達や興味に応じた絵本リコ
メンデーションを行う予定である．


\acknowledgment

\kytea の利用に際して大変ご協力をいただいた
京都大学森信介先生，奈良先端科学技術大学院大学 Graham Neubig先生に感謝する．




\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Bond, Fujita, \BBA\ Tanaka}{Bond
  et~al.}{2006}]{Bond:Fujita:Tanaka:2006}
Bond, F., Fujita, S., \BBA\ Tanaka, T. \BBOP 2006\BBCP.
\newblock \BBOQ {The Hinoki Syntactic and Semantic Treebank of Japanese.}\BBCQ\
\newblock {\Bem Language Resources and Evaluation (Special issue on Asian
  language technology)}, {\Bbf 40} (3--4), \mbox{\BPGS\ 253--261}.


    \bibitem[\protect\BCAY{藤田, 小林, 平, 南, 田中}{藤田ら}{2014}]{Fujita:Kobayashi:Taira:Minami:Tanaka:2014j}
藤田早苗\JBA 小林哲生\JBA 平博順\JBA 南泰浩\JBA 田中貴秋\BBOP 2014\BBCP.
\newblock 絵本を基にした対象年齢推定方法の検討. 
\newblock \Jem{人工知能学会第28回全国大会発表論文集}, 3D4-4.


\bibitem[\protect\BCAY{萩原\JBA 関根}{萩原\JBA 関根}{2012}]{Hagiwara:Sekine:2012j}
萩原正人\JBA 関根聡 \BBOP 2012\BBCP.
\newblock 半教師あり学習に基づく大規模語彙に対応した日本語単語分割. 
\newblock \Jem{言語処理学会第18回年次大会発表論文集},
\mbox{\BPGS\ 1280--1283}.


\bibitem[\protect\BCAY{服部\JBA\ 青山}{服部\JBA\ 青山}{2013}]{Hattori:Aoyama:2013j}
服部正嗣\JBA 青山一生 \BBOP 2013\BBCP.
\newblock \JBOQ {グラフ索引を用いた絵本の類似探索〜特徴の融合と結果の
グラフ可視化〜}.\JBCQ\
\newblock \Jem{情報処理学会研究会第10回ネットワーク生態学シンポジウム}.


\bibitem[\protect\BCAY{池原\JBA 宮崎\JBA 白井\JBA 横尾\JBA 中岩\JBA 小倉\JBA 大山\JBA 林}{池原ら}{1997}]{GoiTaikeij}
池原悟\JBA 宮崎雅弘\JBA 白井諭\JBA 横尾昭男\JBA 中岩浩巳\JBA 小倉健太郎\JBA
  大山芳史\JBA 林良彦 \BBOP 1997\BBCP.
\newblock 日本語語彙大系. 
\newblock 岩波書店.


\bibitem[\protect\BCAY{神嶌}{神嶌}{2010}]{Kamishima:2010j}
神嶌敏弘 \BBOP 2010\BBCP.
\newblock 転移学習. 
\newblock \Jem{人工知能学会誌 (JSAI)}, {\Bbf 25} (4),
\mbox{\BPGS\ 572--580}.


\bibitem[\protect\BCAY{笠原\JBA 佐藤\JBA Bond\JBA 田中\JBA 藤田\JBA 金杉\JBA 天野}{笠原ら}{2004}]{Lexeed:2004j}
笠原要\JBA 佐藤浩史\JBA Bond F.\JBA 田中貴秋\JBA 藤田早苗\JBA 金杉友子\JBA
  天野昭成 \BBOP 2004\BBCP.
\newblock 「基本語意味データベース：Lexeed」の構築.
\newblock \Jem{情報処理学会 自然言語処理研究会 (2004-NL-159)}, \mbox{\BPGS\
  75--82}.

\bibitem[\protect\BCAY{勝木\JBA 笹野\JBA 河原\JBA 黒橋}{勝木ら}{2011}]{Katsuki:Sasano:Kawahara:Kurohashi:2011j}
勝木健太\JBA 笹野遼平\JBA 河原大輔\JBA 黒橋禎夫 \BBOP 2011\BBCP.
\newblock Web上の多彩な言語表現バリエーションに対応した頑健な形態素解析. 
\newblock \Jem{言語処理学会第17回年次大会発表論文集}, \mbox{\BPGS\ 1003--1006}.

\bibitem[\protect\BCAY{工藤\JBA 市川\JBA Talbot\JBA 賀沢}{工藤ら}{2012}]{Kudo:Ichikawa:Talbot:Kazawa:2012j}
工藤拓\JBA 市川宙\JBA Talbot D.\JBA 賀沢秀人 \BBOP 2012\BBCP.
\newblock Web上のひらがな交じり文に頑健な形態素解析. 
\newblock \Jem{言語処理学会第18回年次大会発表論文集}, \mbox{\BPGS\ 1272--1275}.


\bibitem[\protect\BCAY{Kudo, Yamamoto, \BBA\ Matsumoto}{Kudo et~al.}{2004}]{Mecab}
Kudo, T., Yamamoto, K., \BBA\ Matsumoto, Y. \BBOP 2004\BBCP.
\newblock \BBOQ Applying {C}onditional {R}andom {F}ields to {J}apanese
  {M}orphological {A}nalysis.\BBCQ\
\newblock In Lin, D.\BBACOMMA\ \BBA\ Wu, D.\BEDS, In {\Bem Proceedings of the 2004
  Conference on Empirical Methods in Natural Language Processing (EMNLP-2004)},
  \mbox{\BPGS\ 230--237}. 

\bibitem[\protect\BCAY{京都大学黒橋・河原研究室}{京都大学黒橋・河原研究室}{2012}]{juman:7.0j}
京都大学黒橋・河原研究室 \BBOP 2012\BBCP.
\newblock 日本語形態素解析システム JUMAN version 7.0 使用説明書.

\bibitem[\protect\BCAY{松本\JBA 高岡\JBA 浅原}{松本ら}{2008}]{chasen:2.4.4j}
松本裕治\JBA 高岡一馬\JBA 浅原正幸 \BBOP 2008\BBCP.
\newblock 形態素解析システム『茶筌』version 2.4.4 使用説明書.




\bibitem[\protect\BCAY{森}{森}{2012}]{Mori:2012j}
森信介 \BBOP 2012\BBCP.
\newblock 自然言語処理における分野適応. 
\newblock {\Jem 人工知能学会誌 (JSAI)}, {\Bbf 27} (4),
\mbox{\BPGS\ 365--372}.

\bibitem[\protect\BCAY{森\JBA 中田\JBA Neubig\JBA 河原}{森ら}{2011}]{Mori:Nakata:Graham:Kawahara:2011j}
森信介\JBA 中田陽介\JBA Neubig, G.\JBA 河原達也 \BBOP 2011\BBCP.
\newblock 点予測による形態素解析.
\newblock {\Jem 自然言語処理}, {\Bbf 18} (4),
  \mbox{\BPGS\ 367--381}.




\bibitem[\protect\BCAY{村脇\JBA 黒橋}{村脇\JBA 黒橋}{2010}]{Murawaki:Kurohashi:2010j}
村脇有吾\JBA 黒橋禎夫 \BBOP 2010\BBCP.
\newblock 形態論的制約を用いたオンライン未知語獲得.
\newblock \Jem{自然言語処理}, 
{\Bbf 17} (1), \mbox{\BPGS\ 55--75}.


\bibitem[\protect\BCAY{Neubig, Nakata, \BBA\ Mori}{Neubig et~al.}{2011}]{Neubig:Nakata:Mori:2011}
Neubig, G., Nakata, Y., \BBA\ Mori, S. \BBOP 2011\BBCP.
\newblock \BBOQ {Pointwise Prediction for Robust, Adaptable Japanese
  Morphological Analysis}.\BBCQ\
\newblock In {\Bem Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Techologies}, \mbox{\BPGS\
  529--533}. 


\bibitem[\protect\BCAY{小椋\JBA 綿巻}{小椋\JBA\ 綿巻}{2008}]{Ogura:Watamaki:2008}
小椋たみ子\JBA 綿巻徹 \BBOP 2008\BBCP.
\newblock 日本の子どもの語彙発達の規準研究：
日本語マッカーサー乳幼児言語発達質問紙から. 
\newblock \Jem{発達・療育研究}, {\Bbf 24}, \mbox{\BPGS\ 3--42}.

\bibitem[\protect\BCAY{Raikes, Pan, Luze, Tamis-LeMonda, Brooks-Gunn, Constantine, Tarullo, Raikes, \BBA\ Rodriguez}{Raikes et~al.}{2006}]{Mother-child:Ehon:2006}
Raikes, H., Pan, B.~A., Luze, G., Tamis-LeMonda, C.~S., Brooks-Gunn, J.,
  Constantine, J., Tarullo, L.~B., Raikes, H.~A., \BBA\ Rodriguez, E.~T. \BBOP
  2006\BBCP.
\newblock \BBOQ {Mother-child Bookreading in Low-income Families: Correlates
  and Outcomes During the First Three Years of Life}.\BBCQ\
\newblock {\Bem Child Development}, {\Bbf 77}  (4), \mbox{\BPGS\ 924--953}.

\bibitem[\protect\BCAY{笹野\JBA 黒橋}{笹野\JBA 黒橋}{2007}]{Sasano:Kurohashi:2007j}
笹野遼平\JBA 黒橋禎夫 \BBOP 2007\BBCP.
\newblock 形態素解析における連濁および反復形オノマトペの自動認識. 
\newblock \Jem{言語処理学会第13回年次大会発表論文集}, \mbox{\BPGS\ 819--822}.

\bibitem[\protect\BCAY{笹野\JBA 黒橋}{笹野\JBA 黒橋}{2008}]{Sasano:Kurohashi:2008j}
笹野遼平 \JBA 黒橋禎夫 \BBOP 2008\BBCP.
\newblock 大域的情報を用いた日本語固有表現認識. 
\newblock \Jem{情報処理学会論文誌}, 
{\Bbf 49} (11), \mbox{\BPGS\ 3765--3776}.

\bibitem[\protect\BCAY{平\JBA 藤田\JBA 小林}{平ら}{2012}]{Taira:Fujita:Kobayashi:2012j}
平博順\JBA 藤田早苗\JBA 小林哲生 \BBOP 2012\BBCP.
\newblock 絵本テキストにおける高頻度語彙の分析.
\newblock \Jem{情報処理学会関西支部支部大会, F-103}.


\end{thebibliography}


\begin{biography}

\bioauthor{藤田　早苗}{
1999年奈良先端科学技術大学院大学情報科学研究科博士前期課程修了．
同年，NTT日本電信電話株式会社入社．
現在，NTT コミュニケーション科学基礎研究所研究主任．博士（工学）．
自然言語処理の研究に従事．2013年言語処理学会優秀
論文賞受賞，言語処理学会，ACL各会員．
}


\bioauthor{平　　博順}{
1996年東京大学理学部化学科大学院修士課程修了．同年，日本電信電
話株式会社入社．2014年までNTT コミュニケーション科学基礎研究所．
現在，大阪工業大学情報科学部准教授．博士（工学）．
自然言語処理等の研究に従事．2013年言語処理学会優秀
論文賞受賞，情報処理学会，人工知能学会，言語処理学会，ACL各会員．
}

\bioauthor{小林　哲生}{
2004年東京大学大学院総合文化研究科博士課程修了．博士（学術）．
現在，NTT コミュニケーション科学基礎研究所メディア情報研究部
主任研究員（特別研究員）．幼児の言語発達研究に従事．
}

\bioauthor{田中　貴秋}{
1994年大阪大学基礎工学部制御工学科卒業．1996年同大学院修士課程修了．
同年，日本電信電話株式会社入社．
2007年〜2012年 西日本電信電話株式会社研究開発センタ勤務．
現在，NTT コミュニケーション科学基礎研究所研究主任．
自然言語処理の研究に従事．言語処理学会，ACL各会員．
}

\end{biography}

\biodate



\end{document}
