    \documentclass[japanese]{jnlp_1.4}

\usepackage{jnlpbbl_1.3}
\usepackage[dvipdfm]{graphicx}
\usepackage{amsmath}
\usepackage{array}
\usepackage{gb4e}
\usepackage{cgloss4e}
\noautomath

\usepackage{arydshln}
\renewcommand{\labelenumi}{}


\Volume{21}
\Number{6}
\Month{December}
\Year{2014}

\received{2014}{3}{28}
\revised{2014}{6}{22}
\accepted{2014}{8}{12}

\setcounter{page}{1183}

\jtitle{日本語形態素解析における未知語処理の一手法\\—既知語から派生した表記と未知オノマトペの処理—}

\jauthor{笹野　遼平\affiref{TITECH} \and 黒橋　禎夫\affiref{KU} \and 奥村　　学\affiref{TITECH}}

\jabstract{本論文では，形態素解析で使用する辞書に含まれる語から派生した表
記，および，未知オノマトペを対象とした日本語形態素解析における効率的な未
知語処理手法を提案する．提案する手法は既知語からの派生ルールと未知オノマ
トペ認識のためのパターンを利用し対象とする未知語の処理を行う．Webから収集
した10万文を対象とした実験の結果，既存の形態素解析システムに提案手法を導
入することにより新たに約4,500個の未知語を正しく認識できるのに対し，解析が
悪化する箇所は80箇所程度，速度低下は6\%のみであることを確認した．}

\jkeywords{形態素解析，未知語処理，オノマトペ}

\etitle{A Simple Approach to Unknown Word Processing \\ in Japanese Morphological Analysis}

\eauthor{Ryohei Sasano\affiref{TITECH} \and Sadao Kurohashi\affiref{KU} \and Manabu Okumura\affiref{TITECH}}

\eabstract{This paper presents a simple but effective approach to
unknown word processing in Japanese morphological analysis, which
handles 1) unknown words that are derived from words in a pre-defined
lexicon and 2) unknown onomatopoeias. Our approach leverages derivation
rules and onomatopoeia patterns, and correctly recognizes certain types
of unknown words. Experiments revealed that our approach recognized
about 4,500 unknown words in 100,000 Web sentences with only roughly 80
harmful side effects and a 6\% loss in speed.}

\ekeywords{Morphological Analysis, Unknown Word Processing, Onomatopoeias}

\headauthor{笹野，黒橋，奥村} 
\headtitle{日本語形態素解析における未知語処理の一手法}

\affilabel{TITECH}{東京工業大学精密工学研究所}{Precision and Intelligence Laboratory, Tokyo Institute of Technology}
\affilabel{KU}{京都大学大学院情報学研究科}{Graduate School of Informatics, Kyoto University}



\begin{document}
\maketitle

\vspace{0.5\Cvs}
 \section{はじめに}

 日本語形態素解析における誤り要因の1つに辞書に含まれない語・表記の存在が
 ある．本論文では形態素解析で使用する辞書に含まれない語・表記をまとめて未
 知語と呼ぶ．形態素解析における未知語は表
 \ref{Table::UnknownWordClassification}に示すようにいくつかのタイプに分類
 することができる．まず，未知語は既知語から派生したものと，既知語と直接関
 連を持たない純粋な未知語の2つに大きく分けられる．従来の日本語形態素解析
 における未知語処理に関する研究は，事前に未知語をコーパスから自動獲得する
 手法\cite{Mori1996s,Murawaki2008}と，未知語を形態素解析時に自動認識する
 手法\cite{Nagata1999,Uchimoto2001,Asahara2004c,Azuma2006,Nakagawa2007a}
 の2つに大きく分けることができるが，いずれの場合も網羅的な未知語処理が目
 的とされる場合が多く，特定の未知語のタイプに特化した処理が行われることは
 稀であった．

 \begin{table}[t]
  \caption{形態素解析における未知語の分類}
\label{Table::UnknownWordClassification}
\input{04table01.txt}
\end{table}

 しかし，未知語はタイプにより適切な処理方法や解析の難しさは異なっていると
 考えられる．たとえば既知語から派生した表記であれば，それを純粋な未知語と
 して扱うのではなく既知語と関連付けて解析を行うことで純粋な未知語よりも容
 易に処理することが可能である．また，一般的に純粋な未知語の処理は，単独の
 出現から正確に単語境界を推定するのは容易ではないことから，コーパス中の複
 数の用例を考慮し判断する手法が適していると考えられるが，オノマトペのよう
 に語の生成に一定のパターンがある語は，生成パターンを考慮することで形態素
 解析時に効率的に自動認識することが可能である．さらに，\ref{SEC::RECALL}
 節で示すように，解析済みブログコーパス\cite{Hashimoto2011}で複数回出現し
 た未知語で，先行手法\cite{Murawaki2008}やWikipediaから得た語彙知識でカバー
 されないものを分析した結果，既知語から派生した未知表記，および，未知オノ
 マトペに対する処理を行うことで対応できるものは異なり数で88個中27個，出現
 数で289個中129個存在しており，辞書の拡張などで対応することが難しい未知語
 の出現数の4割程度を占めていることが分かった．そこで本論文では既知表記か
 ら派生した未知表記，および，未知オノマトペに焦点を当て，既知語からの派生
 ルールと未知オノマトペ認識のためのパターンを形態素解析時に考慮すること
 で，これらの未知語を効率的に解析する手法を提案する．


 \section{日本語形態素解析}

  \subsection{日本語形態素解析の一般的な流れ}
  日本語形態素解析では，形態素辞書の存在を前提とした手法が一般的に用いら
  れてきた．以下に一般的な日本語形態素解析の手順を示す．

  \begin{description}
   \item[手順1] 文中の各位置から始まる可能性のある形態素を事前に準備した辞書から検索
   \item[手順2] 形態素の候補を列挙した形態素ラティスを作成
   \item[手順3] 形態素ラティスから文として最も確からしい形態素の並びを決定
  \end{description}

  たとえば以下の文が入力された場合，図\ref{Figure::lattice}に示す形態素ラ
  ティスが作られ，最終的に太線で記されている組合せに決定される．

  \begin{figure}[b]
   \begin{center}
    \includegraphics{21-6ia4f1.eps}
   \end{center}
   \caption{形態素ラティスの例}
   \label{Figure::lattice}
  \end{figure}

\begin{exe}
  \ex{父は日本人。}
\end{exe}

  手順1において，文中の各位置から始まる可能性のある形態素を探索する際には
  トライ木に基づく高速な探索手法が一般的に用いられる．また，手順3における
  最尤パスの選択は各形態素ごとに定義された生起コスト，および，各連接ごと
  に定義された連接コストに基づいて行われる．パス全体のコストは，パスに含
  まれる形態素の生起コスト，および，それらの連接コストを加算することによ
  り計算され，コストが小さいほど確からしい形態素の並びであることを意味す
  る．コストの設定方法としては人手で行う方法\cite{Juman1994}や，機械学習
  に基づく手法\cite{Asahara2000,Kudo2004}があるが，最尤パスの探索にはいず
  れもViterbiアルゴリズムが用いられる．


  \subsection{形態素解析における未知語処理}

  日本語形態素解析における未知語処理に関する研究は多く行われてきた．代表
  的な手法として，事前に未知語をコーパスから自動獲得する手法
  \cite{Mori1996s,Murawaki2008}と，未知語を形態素解析時に自動認識する手法
  \cite{Nagata1999,Uchimoto2001,Asahara2004c,Azuma2006,Nakagawa2007a}の
  2つが挙げられる．前者の手法は後者の手法と比べ，ある1つの未知語候補に対
  しコーパス中での複数の用例を考慮することができるため，単独の用例では判
  別の難しい未知語にも対処できるという特長がある．一方，後者の手法は字種
  や前後の形態素候補を手掛かりとして統計や機械学習に基づく未知語モデルを
  構築する手法であり，コーパス中に出現しなかった未知語についても認識が可
  能という特長がある．しかしながら，これらの研究はいずれも基本的に網羅的
  な未知語処理を目的としており，未知語タイプごとの特徴はあまり考慮されて
  いない．

  特定の未知語，特にくだけたテキストに出現する未知語に特化した研究として
  は，風間ら\cite{Kazama1999}，Kacmarcikら\cite{Kacmarcik2000}，池田ら
  \cite{Ikeda2010}，工藤ら\cite{Kudo2012}，斉藤ら
  \cite{Saito2013,Saito2014}の研究がある．

  風間ら\citeyear{Kazama1999}は，Web上のチャットで使用されるようなくだけたテ
  キストの解析を目的とし，品詞bi-gramモデルに基づく確率的形態素解析器をベー
  スとし，文字の挿入や置換が直前の文字や元の文字に依存していると仮定しそ
  れを考慮に入れるように拡張することで，文字の挿入や置換に対して頑健な形
  態素解析システムの構築を行っている．しかし，池田ら\citeyear{Ikeda2010}が，
  風間らの手法を参考に辞書拡張ルールを作成し，200万文のブログ文書に適用し
  て単語区切りに変化が見られた53,488文をサンプリングし評価したとこ
  ろ，37.2\%の文はルール適用前と比べて単語区切りが悪化したと報告している
  ことから，風間らの手法はオンラインチャット，および，それに類するテキス
  トにのみ有効な手法であると推察される．本研究で提案する既知語から派生し
  た未知語処理手法も，基本的に風間らと同じくルールに基づくものであるが，
  未知語のタイプに応じた効率的な辞書の検索を行うことで，高い精度を保ちつ
  つ高速な解析を実現している点に特長がある．

  Kacmarcikら\citeyear{Kacmarcik2000}は形態素解析の前処理としてテキスト正規化
  ルールを適用する手法を提案している．池田ら\citeyear{Ikeda2010}はくだけた表
  現を多く含むブログなどの文書を入力とし，くだけた表現の少ない新聞などの
  文書からくだけた表現の修正候補を検索することで修正ルールを自動的に生成
  し，さらに生成した修正ルールを3つの言語的な指標によりスコアリングするこ
  とで文脈に適した修正ルールを選択する手法を提案している．これらの研究で
  はいずれも前処理として入力テキストを正規化・修正しているのに対し，本研
  究では形態素解析と並行して未知語処理のためのルール・パターンを適用す
  る．このような設計により，従来手法では処理が難しかった連濁化現象により
  初音が濁音化した語の認識も可能となる．

  工藤ら\citeyear{Kudo2012}は，ひらがな交じり文が生成される過程を生成モデルで
  モデル化し，そのパラメータを大規模Web コーパスおよびEMアルゴリズムで推
  定することで，Web上のくだけたテキストに頻出するひらがな交じり文に頑健な
  形態素解析手法を提案している．工藤らの手法は必ずしもひらがな交じり文に
  のみ有効な手法ではなく，本研究で対象とする小書き文字や長音記号を用いた
  表現に適用することも可能であると考えられるが，本研究ではこれらの表現に
  対してはコーパスを用いた学習を行わなくても十分に実用的な精度で処理を行
  うことが可能であることを示す．

  斉藤ら\citeyear{Saito2013,Saito2014}はソーシャルメディア上のテキストから抽
  出した崩れ表記に対し正規表記を付与した正解データを用いて文字列レベルの
  表記の崩れパターンを自動抽出する手法を提案している．これに対し，本研究
  では人手でパターンを与える．正解データを用いてパターンを自動抽出する手
  法の利点としてはパターンを人手で作成する必要がないことが挙げられるが，
  人が見た場合に明らかなパターンがあった場合でも一定規模の正解データを作
  成する必要があり，どちらの手法が優れているかは崩れ表記のタイプにより異
  なると考えられる．

  教師なし単語分割\cite{Goldwater2006}や形態素解析\cite{Mochihashi2009}に
  関する研究もテキストに出現する未知語処理の1つのアプローチとみなすことが
  できる．また，くだけたテキストに出現する表記バリエーションに対処する方
  法として，形態素解析に使用する辞書にこれらの表記バリエーションを追加す
  るという方法も考えられる．たとえば，連濁による濁音化も含む多くの表記バ
  リエーションに対応した形態素解析用の辞書としてUniDic\cite{Den2007}があ
  り，このような辞書を用いることで未知語の数を減らすことが可能であると考
  えられる．しかし，長音記号は任意の数を挿入することが可能であることから
  も明らかなように，表記バリエーションの種類は無数に考えられ，すべてを辞
  書に含めることは不可能である．また，連濁により濁音化した形態素を高精度
  に認識するためには，直前の形態素の品詞等を考慮する必要があることから，
  連濁の認識を辞書の改良だけで行うことは難しいと考えられる．
 

 \section{提案手法}
 \label{SEC::PRO}

  \subsection{提案手法の概要}

  本論文では主に形態素ラティスの生成方法の改良により，形態素解析で使用す
  る辞書に含まれる語から派生した未知表記，および，未知オノマトペを対象と
  した日本語形態素解析における効率的な未知語処理手法を提案する．具体的に
  は既存の形態素解析システムに，既知語から派生した未知表記に相当する形態
  素ノードを生成するためのルール，および，未知オノマトペに相当する形態素
  ノードを生成するためのパターンを導入することで，これらのタイプの未知語
  の自動認識を行う．たとえば，下記のような文が入力された場合，図
  \ref{Figure::oisii}で実線で示したノード・経路に加え，新たに破線で示した
  未知語に相当するノード，および，それを経由する経路を追加し，新たに生成
  された形態素ラティスから最適な経路を探索することで，下記の文の正しい形
  態素解析を実現する．

  \begin{figure}[t]
   \begin{center}
    \includegraphics{21-6ia4f2.eps}
   \end{center}
   \caption{提案システムの概要}
   \label{Figure::oisii}
  \end{figure}

\begin{exe}
  \ex{ぉぃしかったでーーす。}
\end{exe}

  本研究では，比較的単純なルールおよびパターンのみを考慮し，さらに，辞書
  を用いた形態素検索の方法を工夫することで，解析速度を大きく低下させるこ
  となく，高精度に一部の未知語の処理が可能であることを示すことを主な目的
  とする．このため，本研究で使用するルールやパターン，および，置換ルール
  やオノマトペ認識の対象とする文字種の範囲は，現象ごとにコーパスを分析し
  た結果に基づき，解析結果に大きな悪影響が出ない範囲で出来る限り多くの未
  知語を解析できるよう人手で定めたものを使用する\footnote{具体的には，タ
  イプごとに10程度の代表的な表現を列挙し，それらの用例を検索エンジン基盤
  TSUBAKI\cite{Shinzato2008}で使用されているWebページから数例ずつ収集した
  上で，できるだけ多くの用例が正しく解析できるように使用するルール，パター
  ン，文字種の調整を行った．}．同様に，各ルールやパターンを適用するための
  コストに関しても，機械学習等により最適な値を求めることは行わず，人手で
  調整した値を使用し，ベースラインとする形態素解析システムには，各形態素
  の生起コストや連接コストの調整を人手で行っているJUMAN\footnote{JUMAN
  Ver.~5.1:
  http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/juman/juman-5.1.tar.gz}を用
  いる．


  \subsection{既知形態素から派生した未知語の自動認識}
  \label{SUBSEC::PRO}

   \subsubsection{対象とする未知語}

   本研究では既知形態素から派生した未知語として以下の5つのタイプの未知語
   を扱う．

   \begin{enumerate}
    \item 連濁により濁音化した語
    \item 長音記号による置換を含む語
    \item 小書き文字による置換を含む語
    \item 長音記号の挿入を含む語
    \item 小書き文字の挿入を含む語
   \end{enumerate}

   以下では，連濁による濁音化，長音記号および小書き文字による置換，長音記
   号および小書き文字の挿入の3つに分けて，対象とする未知語の詳細，およ
   び，それぞれどのようにノードを追加するかについて詳述する．


   \subsubsection{連濁による濁音化}

   連濁とは複合語の後部要素の初頭にある清音が濁音に変化する現象のことを指
   す．連濁現象により濁音化した形態素表記の多くは辞書に登録されていないた
   め，形態素解析において未知語として扱われる場合が多い．たとえば以下のよ
   うな文が入力された場合，「こたつ」という表記が辞書に含まれていたとして
   も，「ごたつ」が辞書に登録されていないと「ごたつ」を1形態素として正し
   く認識することができない．

\begin{exe}
   \ex{掘りごたつ。}
\end{exe}

   そこで，初頭が清音である名詞については，初頭の清音が濁音化したものも形
   態素候補として形態素ラティスに追加する．この際，1つの元となる形態素に
   対し濁音化した形態素はたかだか1つであることから，濁音化した形態素をあ
   らかじめ形態素辞書に追加することにより，通常のトライ木に基づく形態素の
   探索の枠組みで濁音化した形態素候補をラティスに追加する．

   ただし，連濁は複合語の後部要素にのみ生じる現象であり，さらに，連濁は複
   合語の後部要素であれば必ず起こるわけではなく表
   \ref{Table::Stop_Rendaku}に示すような連濁の発生を抑制する要因が知られ
   ていることから以下の制約を課す．

   \begin{table}[b]
    \caption{連濁の発生を抑制する要因}
\label{Table::Stop_Rendaku}
\input{04table02.txt}
\end{table}

   \begin{itemize}
    \item 直前の形態素が名詞，動詞の連用形，名詞性接尾辞の場合のみ濁音化
	  したノードを使用\footnote{ただし，直前の形態素が接尾辞以外で平
	  仮名1文字の場合は解析に悪影響を与えることが多かったため，直前の
	  形態素が名詞または動詞連用形であった場合も平仮名1文字である場合
	  は濁音化したノードを使用しないようにした．}
    \item 代表的な表記がカタカナを含む形態素は濁音化の対象としない
	  \footnote{本論文における実験では使用する形態素解析システム
	  JUMANの辞書に含まれている代表表記\cite{Okabe2007}を使用し判定し
	  た．ここで代表表記とは，表記揺れに対応するために各語に対して与
	  えられた代表的な表記方法とその読みのペアであり，多くの場合，代
	  表的な表記方法は和語に対しては漢字および平仮名を，漢語に対して
	  は漢字を，外来語に対しては片仮名を用いて表される．}
    \item 形態素がもともと濁音を含んでいる場合は濁音化の対象としない
	  \footnote{ただし，例外である「はしご」については辞書中に濁音化
	  できることを記述し濁音化の対象とした．}
   \end{itemize}

   新たに生成された濁音化した形態素の生起コストは，その元となった形態素の
   生起コストよりも大きく設定した．具体的なコストの設定方法については付録
   \ref{APPEND::A}に記載した．本研究では，濁音化した形態素をはじめとする
   未知語の生起コストを通常の形態素の生起コストよりも意図的に大きめに設定
   している．これは未知語を含む文が新たに正しく解析できるようになることに
   よるユーザの形態素解析システムへの評価の上昇幅よりも，通常解析できるこ
   とが期待される文が正しく解析できない場合の評価の下落幅の方が大きいと考
   えたためである．
 

   \subsubsection{長音記号・小書き文字による置換}

   くだけたテキストでは，「おはよー」，「うらやまし〜」や「ぁなた」などの
   ように形態素辞書中に含まれる語表記の一部が長音記号や小書き文字に置換さ
   れた表現が出現する．このうち長音記号に置換される文字の多くは，「おはよ
   う」の「う」や，「うらやましい」の「い」などのように直前の文字を伸ばし
   た音に類似していると考えられる．そこで長音記号があった場合，入力文字に
   対し行う通常の形態素の検索に加え，長音記号をその直前の文字に応じて表
   \ref{Table::ProlongRule}に示す母音文字に置き換えた文字列に対しても形態
   素の検索を行い，検索された形態素を形態素ラティスに追加する．本研究では
   長音記号として「ー」と「〜」の2つを扱う．小書き文字があった場合も同様
   に対応する通常の文字に置き換えた文字列を作成し形態素の検索を行う．本研
   究では，「ぁ」，「ぃ」，「ぅ」，「ぇ」，「ぉ」，「ヵ」，および「ゎ」を
   置換対象とし，それぞれ「あ」，「い」，「う」，「え」，「お」，「か」，
   「わ」に置換する．たとえば「ぉぃしー。」という文があった場合，「おいし
   い。」という文字列に対しても形態素の検索を行い，新たに検索された形態素
   を「ぉぃしー」から生成された形態素ラティスに追加する．

   \begin{table}[b]
    \caption{直前の文字ごとの長音記号を置き換える母音文字}
\label{Table::ProlongRule}
\input{04table03.txt}
   \end{table}

   この際，長音記号および小書き文字は何らかの文字の置換により出現した場合
   だけでなく，以下で述べるように挿入された場合もあると考えられる．しか
   し，事前の分析の結果，同一形態素内で置換されたものと挿入されたものが混
   じって出現することは相対的に少ないことが分かったため\footnote{解析済み
   ブログコーパス\cite{Hashimoto2011}では，置換と挿入が混在していると考え
   られる未知語は「あぁー」の1例のみであった．}，解析速度への影響を考慮
   し，これらの未知語は本研究では扱わない．また，長音記号・小書き文字の置
   換により新たに生成された形態素の生起コストの設定方法は，長音記号・小書
   き文字の挿入により生成された形態素の生起コストとともに付録
   \ref{APPEND::B}に記載した．


   \subsubsection{長音記号・小書き文字の挿入}

   くだけたテキストでは，「冷たーーーい」や「冷たぁぁぁい」などのように形
   態素辞書中に含まれる語に長音記号や小書き文字が挿入された表現が出現す
   る．これらの表記において，挿入される文字数は任意であることからこれらの
   表現をすべて辞書に登録することは難しい．そこで本研究では，長音記号・小
   書き文字の置換に対する処理と同様に，入力文字列に対し一定の処理を行った
   文字列に対し形態素の検索を行い，その結果を形態素ラティスに追加すること
   により，長音記号および小書き文字の挿入に対応する．

   具体的には，「ー」および「〜」が出現した場合，または，「ぁ」，「ぃ」，
   「ぅ」，「ぇ」，「ぉ」が出現し，かつ，その直前の文字が小書き文字と同一
   の母音をもつ平仮名\footnote{本研究では特に断りがない場合，平仮名として
   Unicodeの3040〜309Fの範囲を，また，片仮名としてUnicodeの30A0〜30FFの範
   囲を使用する．}であった場合に，それらを削除した文字列を作成する．たと
   えば「冷たぁぁーーい。」という文があった場合，「冷たい。」という文字列
   に対しても形態素の検索を行い，新たに検索された形態素を「冷たぁぁーー
   い。」から生成された形態素ラティスに追加する．


  \subsection{未知オノマトペの自動認識}

   \subsubsection{未知オノマトペのタイプ}

   オノマトペとは「わくわく」，「しっかり」などのような擬音語・擬声語のこ
   とである．日本語では比較的自由にオノマトペを生成できることから特にくだ
   けたテキストでは「ぐじょぐじょ」や「ぐっちょり」などのような辞書に含ま
   れないオノマトペが多く出現する．本研究では多くの未知オノマトペが一定の
   パターンに従っていることを利用し，特定のパターンに従う文字列をオノマト
   ペの候補とすることで未知オノマトペの自動認識を行う．ここで，オノマトペ
   の品詞としては，副詞，サ変名詞，形容詞などが考えられるが，本研究ではオ
   ノマトペが必要以上に細かく分割されるのを防ぐことを主な目的とし，すべて
   副詞として処理する．以下では「ぐじょぐじょ」などのように反復を含むタイ
   プと，「ぐっちょり」などのように反復を含まないものの2つに分け，それぞ
   れどのようにノードを追加するか詳述する．


   \subsubsection{反復型オノマトペ}

   オノマトペの代表的なパターンの1つに「ぐじょぐじょ」や「うはうは」など
   のように，同じ音が2度反復されるパターンがある\cite{Kakai1993}．そこで
   本研究では2文字から4文字までの平仮名または片仮名が反復されている場合，
   それらを未知オノマトペの候補として形態素ラティスに追加する．これらのオ
   ノマトペは入力文の各位置において，そこから始まる平仮名または片仮名$n$
   文字とその直後の$n$文字が一致しているかどうかを調べることで効率的に探
   索することが可能である．

   ただし，「むかしむかし」や「ぜひぜひ」などのように同音が反復された場合
   でもオノマトペではない表現も存在する．このため，追加された未知オノマト
   ペノードが必要な場合にのみ選択されるように，追加したノードのコストを適
   切に設定する必要がある．本研究では，基本的に反復文字数ごとにコストを設
   定し，さらに濁音・半濁音や開拗音を含む表現はオノマトペである場合が多い
   こと，また，平仮名よりも片仮名の場合の方がオノマトペである場合が多いこ
   とを考慮し，コストを人手で設定した．実際に使用したコストは付録
   \ref{APPEND::C}に記載した．


   \subsubsection{非反復型オノマトペ}

   \begin{table}[b]
    \caption{非反復型オノマトペのパターンとコスト}
    \label{Table::OnoPattern}
\input{04table04.txt}
   \end{table}
   
   反復を含まない場合もオノマトペは一定のパターンに従うものが多い
   \cite{Kakai1993}．そこで本研究ではオノマトペを認識するためのパターンを
   導入し，導入したパターンに従う文字列を形態素候補として形態素ラティスに
   追加する．本研究で使用したパターンを表\ref{Table::OnoPattern}に示す．
   パターン中のH，K，{\scriptsize H}，{\scriptsize K}はそれぞれ平仮名，片
   仮名\footnote{本研究で平仮名，片仮名として使用したそれぞれ69文字の一覧
   は付録\ref{APPEND::D}に記載した．}，平仮名の開拗音字（「ゃ」，「ゅ」，
   「ょ」），および，片仮名の開拗音字（「ャ」，「ュ」，「ョ」）を表す．これ
   らは事前にコーパスを分析した結果，出現頻度が高く，かつ，悪影響の少ない
   パターンである．いずれも2音節の語基を持ち，先頭の4つは2音節の間に促音
   を持ち「り」語尾が付いたもの，残りの3つは2音節に促音および「と」が付い
   たものとなっている．本論文ではパターンを導入することの有効性を確認する
   ことを目的とし，実験には表\ref{Table::OnoPattern}に示した7つのパターン
   のみを使用したが，さらに多くのパターンを導入することで，より多くのオノ
   マトペを認識できると考えられる．また，コストは本研究で使用する形態素解
   析システムJUMANにおけるコストであり，一般的な副詞のコストを100とした場
   合の形態素生起コストを表している\footnote{JUMANでは単語の生起コスト
   を，辞書に付与された形態素の各表記のコストに，品詞コストを乗じることに
   より算出している．一般的な副詞の場合，表記のコストが1.0，副詞の品詞コ
   ストが100であることから，一般的な副詞の生起コストは100となる．}．

   非反復型オノマトペを含む形態素ラティスの生成にあたり，入力文の各位置か
   ら始まる文字列が表\ref{Table::OnoPattern}に示すパターンに一致するかど
   うか検索すると，形態素ラティスの生成速度が大きく低下する可能性が考えら
   れる．そこで本研究では，表\ref{Table::OnoPattern}に示す各パターンから
   生成されうる形態素の数はたかだか4,761ないしは14,283である\footnote{非
   反復型オノマトペの生成に使用した平仮名，片仮名の種類は69，開拗音字の種
   類は3であることから，2つの任意の平仮名，または，片仮名のみを含むパター
   ンの場合は4,761，拗音も含むパターンの場合は14,283の形態素候補が生成さ
   れる．}ことに着目し，これらの候補をすべて事前に辞書に追加することで，
   通常のトライ木に基づく辞書検索により未知オノマトペのノードを形態素ラティ
   スに追加できるようにした．


   \subsection{未知語処理の流れ}

   表\ref{Table::Summary}に本研究で扱う未知語のタイプと，各未知語に相当す
   るノードをどのように形態素ラティスに追加するかをまとめる．これらの未知
   語処理をすべて行った場合の形態素ラティスの作成手順は以下のようになる．

   \begin{table}[b]
    \caption{提案手法で扱う未知語のタイプと未知語ノードの形態素ラティスへの追加方法}
 \label{Table::Summary}
\input{04table05.txt}
   \end{table}

   \begin{enumerate}
    \item 形態素解析に先立ち，連濁により濁音化した形態素，および，非反復
	  型オノマトペの候補を形態素解析辞書に追加
    \item 入力文に対し，形態素の検索を行い形態素ラティスを作成
    \item 入力文中に出現した長音記号・小書き文字を\ref{SUBSEC::PRO}節で述
	  べたルールに基づき置換した文字列に対し形態素の検索を行い，新た
	  に検索された形態素を形態素ラティスに追加
    \item 入力文中に出現した長音記号・小書き文字を\ref{SUBSEC::PRO}節で述
	  べたルールに基づき削除した文字列に対し形態素の検索を行い，新た
	  に検索された形態素を形態素ラティスに追加
    \item 文字列比較により，入力文に含まれる平仮名または片仮名の2文字から
	  4文字までの反復を探し，存在した場合は形態素ラティスに追加
   \end{enumerate}   


 \section{実験と考察}
 
  \subsection{提案手法の再現率}
\label{SEC::RECALL}

提案手法の有効性を確認するため，まず，再現率，すなわ
  ち対象の未知語のうち正しく解析できる語の割合の調査を行った．すべての未
  知語をタグ付けした大規模なデータを作成するためには大きなコストが必要と
  なることから，本研究では未知語のタイプごとに個別に対象の未知語を含むデー
  タを作成し再現率の調査を行った．未知語のタイプを限定することで，正規表
  現等により対象の未知語を含む可能性のある文を絞り込むことができ，効率的
  にデータを作成できるようになる．具体的には，検索エンジン基盤
  TSUBAKI\cite{Shinzato2008}で使用されているWebページから，各未知語タイプ
  ごとに正規表現を用いて未知語を含む文の候補を収集し，そこから未知語を
  100個含む文集合を作成し，再現率の評価を行った．ただし，ここで使用した文
  集合には\ref{SEC::PRO}節で説明したルール・パターンの作成の際に参考にし
  た文は含まれていない．結果をUniDic\cite{Den2007}によるカバー率とともに
  表\ref{Table::Recall}に示す．ここで，UniDicによるカバー率とは対象の未知
  語100個のうちUniDicに含まれている語の数を表している．実際にUniDicを用い
  たシステムにおいて対象の未知語を正しく解析できるかどうかは考慮していな
  いため，UniDicによるカバー率はUniDicを用いたシステムが達成できる再現率
  の上限とみなせる．
  
  \begin{table}[b]
   \caption{未知語タイプごとの再現率とUniDicによるカバー率}
   \label{Table::Recall}
\input{04table06.txt}
  \end{table}  

  表\ref{Table::Recall}に示した結果から，すべての未知語タイプに対し提案手
  法は高い再現率を達成できることが確認できる．連濁を除く未知語タイプにお
  いてはUniDicによるカバー率よりも高い再現率を達成していることから，考え
  うる多くの未知語を人手で登録するアプローチに比べ，既知語からの派生ルー
  ルと未知オノマトペ認識のためのパターンを用いる提案手法のアプローチは，
  低コストで多くの未知語に対応できると言える．一方，連濁により濁音化した
  語については正しく認識できた語の数はUniDicでカバーされている語の数より
  も少なかった．たとえば以下の文に含まれている「がわら」は正しく認識する
  ことができなかった．

\begin{exe}
  \ex{赤\underline{がわら}の民家です。}
\end{exe}
  
  これは連濁と関係ない表現を連濁により濁音化したものであると認識しないよ
  うに，連濁により濁音化した形態素のノードに大きなコストを与えているため
  である．たとえば以下のような文があった場合，連濁により濁音化した形態素
  のコストを元の形態素のコストと同程度に設定した場合は「でまわり」を「手
  回り」が濁音化したものと解析してしまうため，濁音化した形態素のノードに
  は大きめのコストを与える必要がある．

\begin{exe}
  \ex{笑顔\underline{でまわり}の人たちを幸せにする。
  \label{EX::DEMAWARI}}
\end{exe}

  \begin{table}[t]
   \caption{解析済みブログコーパスにおいて2回以上出現した未知語の分類}
   \label{Table::Coverage}
\input{04table07.txt}
  \end{table}
 
  続いて，実コーパスにおける再現率の評価を行うため，解析済みブログコーパ
  ス\cite{Hashimoto2011}\footnote{Kyoto-University and NTT Blogコーパス 
  http://nlp.ist.i.kyoto-u.ac.jp/kuntt/}を用いた評価を行った．具体的には
  解析済みブログコーパスで1形態素としてタグ付けされている語のうち，2回以
  上出現し，かつ，JUMAN5.1の辞書に含まれていない230語を，村脇らによりコー
  パスから自動生成された辞書\cite{Murawaki2008}でカバーされているもの，そ
  れ以外でWikipediaにエントリを持つもの，それ以外で提案手法によりカバーさ
  れるもの，その他の4つに分類した．結果を表\ref{Table::Coverage}に示す．
  村脇らによる辞書，および，Wikipediaのエントリでもカバーされない未知語の
  うち異なり数でおよそ30\%，出現数でおよそ45\%が提案手法により解析できて
  おり，提案手法による未知語処理が実コーパスに対しても有用であることが確
  認できる．また，提案手法により解析できた未知語には，連濁による濁音化を
  除くすべての未知語タイプが含まれており，様々な未知語タイプが実コーパス
  において出現することが確認できた．


  \subsection{解析精度・速度の評価}   

  本論文で導入したルール・パターンを用いることで新たに認識された未知語の
  精度，および，解析速度の変化を調べるため，これらのルール・パターンを用
  いないベースラインモデルと提案手法を用いたモデルを以下の7つの観点から比
  較することにより提案手法の評価を行った．本節の実験ではJUMAN5.1をデフォ
  ルトのコスト設定のまま使用したものをベースラインモデルとした．
 
  \begin{enumerate}
   \item 解析結果が変化した100箇所中，解析結果が改善した箇所の数：$P_{100D}$
   \item 解析結果が変化した100箇所中，解析結果が悪化した箇所の数：$N_{100D}$
   \item 10万文あたりの解析結果が変化した箇所の数：$D_{100kS}$
   \item 10万文あたりの解析結果が改善した箇所の推定数：$P^{*}_{100kS}$
   \item 10万文あたりの解析結果が悪化した箇所の推定数：$N^{*}_{100kS}$
   \item 形態素ラティスにおけるノードの増加率：$N\!ode_{inc.}$
   \item 解析速度の低下率：$SP_{loss}$
  \end{enumerate}

  実験には検索エンジン基盤TSUBAKI\cite{Shinzato2008}で使用されているWebペー
  ジから収集した10万文を使用した．これらの文は平仮名を1字以上含み，かつ，
  全体で20文字以上で構成される文であり，\ref{SEC::PRO}節で説明したルール・
  パターンの作成の際に参考にした文は含まれていない．

  まず，$P_{100D}$と$N_{100D}$を算出するため，各ルール・パターンを用いた
  場合と用いなかった場合で解析結果が変化した箇所を100箇所抽出し，それらを
  改善，悪化，その他の3クラスに分類した．この際，基本的に分割箇所が変化し
  た場合は分割箇所の優劣を比較し，分割箇所に優劣がない場合で品詞が変化し
  た場合はその品詞の優劣を比較した．ただし，形態素区切りが改善した場合で
  あっても，名詞であるべき品詞が副詞となっている場合など，明らかに正しい
  解析と言えない場合はその他に分類した．たとえば「面白がれる」という表現
  は，JUMANでは子音動詞の可能形は可能動詞として登録されていることか
  ら，JUMANの辞書登録基準では1語となるべきである．しかし，連濁ルールを用
  いなかった場合は下記の例(\ref{EX::OMOSHIRO})aのように，連濁ルールを用
  いた場合は下記の例(\ref{EX::OMOSHIRO})bのように，解析結果は異なるもの
  の，いずれの場合も過分割されてしまうことから，このような場合はその他に
  分類した．

\begin{exe}
\ex \label{EX::OMOSHIRO}
\begin{xlist}
  \ex 面/白/が/れ/る
  \ex 面/白/がれる
\end{xlist}
\end{exe}

  また，$P^{*}_{100kS}$，および，$N^{*}_{100kS}$は，10万文あたりの解析結
  果が変化した箇所の数$D_{100kS}$を用いて，それぞれ以下の式により算出し
  た．
  \begin{align*}
   P^{*}_{100kS} & = D_{100kS} \times P_{100D}/100\notag\\   
   N^{*}_{100kS} & = D_{100kS} \times N_{100D}/100\notag
  \end{align*}
  ここで，各未知語タイプごとに推定誤差は異なっていることに注意が必要であ
  る．特に解析が悪化した箇所の数は少なことから$N^{*}_{100kS}$の推定誤差は
  大きいと考えられる．しかしながら，各未知語タイプごとに大規模な評価を行
  うコストは大きいことから本論文では上記の式から算出された推定数に基づい
  て考察を行う．

  解析精度の評価に加えて，最適解の探索時間に影響を与えると考えられること
  から形態素ラティスにおけるノードの増加率$N\!ode_{inc.}$，および，全体の
  解析速度への影響を調べるため速度の低下率$SP_{loss}$の計測も行った．これ
  らの評価結果を表\ref{Table::ResultAll}に示す．
  
  \begin{table}[t]
    \caption{各ルール・パターンを使用した場合の精度と速度}
 \label{Table::ResultAll}
\input{04table08.txt}
  \end{table}      

  表\ref{Table::ResultAll}に示す結果から提案手法を用いることで，ほとんど
  解析結果を悪化させることなく，また，解析速度を大きく下げることなく，多
  くの未知語を正しく処理できるようになることが確認できる．具体的には，す
  べてのルール・パターンを用いることで10万文あたり4,500個以上の未知語処理
  が改善するのに対し，悪化する解析は80個程度であると推定でき，速度の低下
  率は6.2\%であった．速度の低下率に関してはベースラインとした形態素解析器
  の実装に大きく依存するため，具体的な数値に大きな意味はないと言えるもの
  の，少なくとも提案手法は大幅な速度低下は引き起こさないと考えられる．ま
  た，ノードの増加率に対し解析速度の低下率が大きいことから，速度低下は最
  適パスの探索ではなく，主に形態素ラティスの生成の時間の増加により引き起
  されていると考えられる．以下ではルール・パターンごとの解析の変化につい
  て詳述する．


  \subsubsection{連濁による濁音化}

  表\ref{Table::ResultAll}に示したとおり，連濁パターンを導入した場合，新
  たに正しく解析できるような表現がある一方で，解析結果が悪化する表現が長
  音文字や小書き文字の置換・挿入ルールと比べ多く存在する．これは，長音文
  字や小書き文字を含む形態素はもともと非常に少ないのに対し，濁音を含む形
  態素は多く存在しているため，濁音が含まれているからといって連濁による濁
  音化であるケースが限定的であるためと考えられる．表\ref{Table::Rendaku}
  に連濁ルールを導入することにより解析結果が変化した例を示す．解析結果の
  変化を示した表において`/'は形態素区切りを，太字は解析結果が正解と一致し
  ていることを表す．「はさみ」が濁音化した形態素「ばさみ」や「ためし」が
  濁音化した形態素「だめし」など正しく認識できるようになった表現がある一
  方で，本来，格助詞「が」と形容詞「ない」から構成される「がない」という
  文字列を「かない」が濁音化した表現であると誤って解析されてしまうような
  表現が8例存在した．このような例を改善するためには，連濁化に関する静的な
  情報を活用して連濁処理の対象を制限することが考えられる．たとえばUniDic
  には連濁によって濁音化する語の情報が登録されておりこれを利用することが
  考えられる．
  
  \begin{table}[b]
   \caption{連濁ルールを導入することで解析結果が変化した例}
   \label{Table::Rendaku}
\input{04table09.txt}
  \end{table}

  \subsubsection{長音文字の置換}

  長音文字を置換するルールを導入することで解析結果が変化した例を表
  \ref{Table::MacronR}に示す．もともと正しく解析できていた表現がルールを
  導入することにより解析できなくなった例は存在せず，周辺の解析結果が悪化
  したものが「OKだよ〜ん」の1例のみ存在した．この例ではいずれも形態素区切
  りは誤っているものの，ベースラインモデルでは「だ」を判定詞であると解析
  できていたものが，提案手法を用いた場合は普通名詞であると解析されたた
  め，解析結果が悪化したと判定した．

  \begin{table}[b]
   \caption{長音文字を置換するルールを導入することで解析結果が変化した例}
   \label{Table::MacronR}
\input{04table10.txt}
  \end{table}


  \subsubsection{小書き文字の置換}

  小書き文字を置換するルールを導入することで解析結果が変化した例を表
  \ref{Table::KogakiR}に示す．長音記号の場合と同様にもともと正しく解析で
  きていた表現がルールを導入することにより解析できなくなった例は存在せ
  ず，周辺の解析結果が悪化したものが「ゆみぃの布団」の1例のみ存在した．こ
  の例でベースラインモデルでは格助詞であると正しく解析できていた「の」
  が，「いの」という地名の一部であると解析されたため，解析結果が悪化した
  と判定した．また，小書き文字を置換するルールを導入することで解析結果が
  改善した箇所の推定数は10万文あたり1,374箇所であり，全未知語タイプの中で
  もっとも多く，ほぼ悪影響もないことから，非常に有用なルールであると言え
  る．
  
  \begin{table}[b]
   \caption{小書き文字を置換するルールを導入することで解析結果が変化した例}
   \label{Table::KogakiR}
\input{04table11.txt}
  \end{table}


  \subsubsection{長音文字の挿入}

  挿入されたと考えられる長音文字を削除するルールを導入することで解析結果
  が変化した例を表\ref{Table::MacronI}に示す．長音文字の挿入に対処するこ
  とで解析が悪化した例は存在せず，「苦〜い」や「ぜーんぶ」など多くの表現
  が正しく解析できるようになった．長音文字を削除するルールを導入すること
  で解析結果が改善した箇所の推定数は10万文あたり1,093箇所であり，小書き文
  字の置換ルールに次いで多かった．解析結果が悪化した事例は確認できなかっ
  たことから，非常に有用性の高いルールであると言える．

  \begin{table}[b]
   \caption{長音文字を削除するルールを導入することで解析結果が変化した例}
   \label{Table::MacronI}
\input{04table12.txt}
  \end{table}


  \subsubsection{小書き文字の挿入}

  \begin{table}[b]
   \caption{小書き文字を削除するルールを導入することで解析結果が変化した例}
   \label{Table::KogakiI}
\input{04table13.txt}
  \end{table}

  挿入されたと考えられる小書き文字を削除するルールを導入することで解析結
  果が変化した例を表\ref{Table::KogakiI}に示す．長音文字の挿入の場合と同
  様に小書き文字に対処することで解析が悪化した例は存在せず，「さぁん」や
  「でしたぁぁぁ」など小書き文字の挿入を含む表現が正しく解析できるように
  なった．


  \subsubsection{反復型オノマトペ}

  反復型オノマトペの認識パターンを導入することで解析結果が変化した例を表
  \ref{Table::OnoR}に示す．解析結果に変化があった100箇所中，感動詞の反復
  である「あらあら」と「うんうん」の2例は誤ってオノマトペであると解析され
  たものであったが，この2例以外には解析が悪化した事例はなかった．反復型オ
  ノマトペの認識パターンを導入することで解析結果が改善した箇所の推定数は
  10万文あたり860箇所であり，小書き文字の置換ルール，長音文字の削除ルール
  に次いで多かった．

  \begin{table}[b]
   \caption{反復型オノマトペパターンを導入することで解析結果が変化した例}
\label{Table::OnoR}
\input{04table14.txt}
  \end{table}


  \subsubsection{非反復型オノマトペ}
  非反復型オノマトペの認識パターンを導入することで解析結果が変化した例を
  表\ref{Table::OnoP}に示す．解析結果が悪化した例は存在せず，「のっちょり」
  などのように本来オノマトペではない表現を誤ってオノマトペであると解析し
  た例は存在したが，それらはいずれもベースライン手法でも正しく解析できな
  い表現であった．また，非反復型オノマトペの処理を行うことによる速度の低
  下は確認できなかった．生成される形態素ラティスのノード数の増加率が
  0.008\%にとどまっていることから，正しいオノマトペ以外にはほとんどパター
  ンに該当する文字列が存在しなかったためであると考えられる．

  \begin{table}[b]
   \caption{非反復型オノマトペパターンを導入することで解析結果が変化した例}
 \label{Table::OnoP}
\input{04table15.txt}
  \end{table}



 \section{まとめ}

 本論文では，形態素解析で使用する辞書に含まれる語から派生した未知表記，お
 よび，未知オノマトペを対象とした日本語形態素解析における効率的な未知語処
 理手法を提案した．Webから収集した10万文を対象とした実験の結果，既存の形
 態素解析システムに提案手法を導入することにより，解析が悪化した箇所は80箇
 所程度，速度低下は6\%のみであったのに対し，新たに約4,500個程度の未知語を
 正しく認識できることを確認した．特に，長音文字・小書き文字の置換・挿入に
 関するルールのみを導入した場合，10万文あたり推定3,327個の未知語を新たに
 解析できるようになるのに対し，悪化する箇所は推定27個であり，ほとんど解析
 結果に悪影響を与えることなく多くの未知語を解析できることが確認できた．今
 後の展望としては，各形態素の生起コストや連接コストを機械学習を用いて推定
 した形態素解析システムへの応用や，特に連濁現象への対処としてUniDicなどの
 ように多くの表記バリエーションの情報が付与された辞書と組み合わせることな
 どが考えられる．
 


\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Asahara \BBA\ Matsumoto}{Asahara \BBA\
  Matsumoto}{2000}]{Asahara2000}
Asahara, M.\BBACOMMA\ \BBA\ Matsumoto, Y. \BBOP 2000\BBCP.
\newblock \BBOQ Extended Models and Tools for High-performance Part-of-speech
  Tagger.\BBCQ\
\newblock In {\Bem Proceedigs of COLING'00}, \mbox{\BPGS\ 21--27}.

\bibitem[\protect\BCAY{Asahara \BBA\ Matsumoto}{Asahara \BBA\
  Matsumoto}{2004}]{Asahara2004c}
Asahara, M.\BBACOMMA\ \BBA\ Matsumoto, Y. \BBOP 2004\BBCP.
\newblock \BBOQ Japanese Unknown Word Identification by Character-based
  Chunking.\BBCQ\
\newblock In {\Bem Proceedigs of COLING'04}, \mbox{\BPGS\ 459--465}.

\bibitem[\protect\BCAY{東\JBA 浅原\JBA 松本}{東 \Jetal }{2006}]{Azuma2006}
東藍\JBA 浅原正幸\JBA 松本裕治 \BBOP 2006\BBCP.
\newblock 条件付確率場による日本語未知語処理.\
\newblock \Jem{情報処理学会研究報告，自然言語処理研究会報告 2006-NL-173}, \mbox{\BPGS\
  67--74}.

\bibitem[\protect\BCAY{伝\JBA 小木曽\JBA 小椋\JBA 山田\JBA 峯松\JBA 内元\JBA
  小磯}{伝 \Jetal }{2007}]{Den2007}
伝康晴\JBA 小木曽智信\JBA 小椋秀樹\JBA 山田篤\JBA 峯松信明\JBA 内元清貴\JBA
  小磯花絵 \BBOP 2007\BBCP.
\newblock
  コーパス日本語学のための言語資源：形態素解析用電子化辞書の開発とその応用.\
\newblock \Jem{日本語科学}, {\Bbf 22}, \mbox{\BPGS\ 101--122}.

\bibitem[\protect\BCAY{Goldwater, Griffiths, \BBA\ Johnson}{Goldwater
  et~al.}{2006}]{Goldwater2006}
Goldwater, S., Griffiths, T.~L., \BBA\ Johnson, M. \BBOP 2006\BBCP.
\newblock \BBOQ Contextual Dependencies in Unsupervised Word
  Segmentation.\BBCQ\
\newblock In {\Bem Proceedings of the 21st International Conference on
  Computational Linguistics and 44th Annual Meeting of the Association for
  Computational Linguistics}, \mbox{\BPGS\ 673--680}.

\bibitem[\protect\BCAY{橋本\JBA 黒橋\JBA 河原\JBA 新里\JBA 永田}{橋本 \Jetal
  }{2011}]{Hashimoto2011}
橋本力\JBA 黒橋禎夫\JBA 河原大輔\JBA 新里圭司\JBA 永田昌明 \BBOP 2011\BBCP.
\newblock 構文・照応・評判情報つきブログコーパスの構築.\
\newblock \Jem{自然言語処理}, {\Bbf 18}  (2), \mbox{\BPGS\ 175--201}.

\bibitem[\protect\BCAY{池田\JBA 柳原\JBA 松本\JBA 滝嶋}{池田 \Jetal
  }{2010}]{Ikeda2010}
池田和史\JBA 柳原正\JBA 松本一則\JBA 滝嶋康弘 \BBOP 2010\BBCP.
\newblock くだけた表現を高精度に解析するための正規化ルール自動生成手法.\
\newblock \Jem{情報処理学会論文誌データベース}, {\Bbf 3}  (3), \mbox{\BPGS\
  68--77}.

\bibitem[\protect\BCAY{Kacmarcik, Brockett, \BBA\ Suzuki}{Kacmarcik
  et~al.}{2000}]{Kacmarcik2000}
Kacmarcik, G., Brockett, C., \BBA\ Suzuki, H. \BBOP 2000\BBCP.
\newblock \BBOQ Robust Segmentation of Japanese Text into a Lattice for
  Parsing.\BBCQ\
\newblock In {\Bem Proceedigs of COLING'00}, \mbox{\BPGS\ 390--396}.

\bibitem[\protect\BCAY{筧\JBA 田守}{筧\JBA 田守}{1993}]{Kakai1993}
筧寿雄\JBA 田守育啓 \BBOP 1993\BBCP.
\newblock \Jem{オノマトピア—擬音・擬態語の楽園}.
\newblock 勁草書房.

\bibitem[\protect\BCAY{風間\JBA 光石\JBA 牧野\JBA 鳥澤\JBA 松田\JBA 辻井}{風間
  \Jetal }{1999}]{Kazama1999}
風間淳一\JBA 光石豊\JBA 牧野貴樹\JBA 鳥澤健太郎\JBA 松田晃一\JBA 辻井潤一 \BBOP
  1999\BBCP.
\newblock チャットのための日本語形態素解析.\
\newblock \Jem{言語処理学会第5回年次大会発表論文集}, \mbox{\BPGS\ 509--512}.

\bibitem[\protect\BCAY{工藤\JBA 市川\JBA Talbot\JBA 賀沢}{工藤 \Jetal
  }{2012}]{Kudo2012}
工藤拓\JBA 市川宙\JBA Talbot, D., 賀沢秀人 \BBOP 2012\BBCP.
\newblock Web上のひらがな交じり文に頑健な形態素解析.\
\newblock \Jem{言語処理学会第18回年次大会発表論文集}, \mbox{\BPGS\
  1272--1275}.

\bibitem[\protect\BCAY{Kudo, Yamamoto, \BBA\ Matsumoto}{Kudo
  et~al.}{2004}]{Kudo2004}
Kudo, T., Yamamoto, K., \BBA\ Matsumoto, Y. \BBOP 2004\BBCP.
\newblock \BBOQ Applying Conditional Random Fields to Japanese Morphological
  Analysis.\BBCQ\
\newblock In {\Bem Proceedigs of EMNLP'04}, \mbox{\BPGS\ 230--237}.

\bibitem[\protect\BCAY{Kurohashi, Nakamura, Matsumoto, \BBA\ Nagao}{Kurohashi
  et~al.}{1994}]{Juman1994}
Kurohashi, S., Nakamura, T., Matsumoto, Y., \BBA\ Nagao, M. \BBOP 1994\BBCP.
\newblock \BBOQ Improvements of {J}apanese Morphological Analyzer
  {JUMAN}.\BBCQ\
\newblock In {\Bem Proceedigs of The International Workshop on Sharable Natural
  Language Resources}, \mbox{\BPGS\ 22--38}.

\bibitem[\protect\BCAY{Lyman}{Lyman}{1894}]{Lyman1894}
Lyman, B.~S. \BBOP 1894\BBCP.
\newblock {\Bem The Change from Surd to Sonant in Japanese Compounds}.
\newblock Philadelphia: Oriental Club of Philadelphia.

\bibitem[\protect\BCAY{Mochihashi, \mbox{Yamada,} \BBA\ Ueda}{Mochihashi
  et~al.}{2009}]{Mochihashi2009}
Mochihashi, D., Yamada, T., \BBA\ Ueda, N. \BBOP 2009\BBCP.
\newblock \BBOQ Bayesian Unsupervised Word Segmentation with Nested Pitman-Yor
  Language Modeling.\BBCQ\
\newblock In {\Bem Proceedigs of ACL-IJCNLP'09}, \mbox{\BPGS\ 100--108}.

\bibitem[\protect\BCAY{Mori \BBA\ Nagao}{Mori \BBA\ Nagao}{1996}]{Mori1996s}
Mori, S.\BBACOMMA\ \BBA\ Nagao, M. \BBOP 1996\BBCP.
\newblock \BBOQ Word Extraction from Corpora and Its Part-of-Speech Estimation
  Using Distributional Analysis.\BBCQ\
\newblock In {\Bem Proceedigs of COLING'96}, \mbox{\BPGS\ 1119--1122}.

\bibitem[\protect\BCAY{Murawaki \BBA\ Kurohashi}{Murawaki \BBA\
  Kurohashi}{2008}]{Murawaki2008}
Murawaki, Y.\BBACOMMA\ \BBA\ Kurohashi, S. \BBOP 2008\BBCP.
\newblock \BBOQ Online Acquisition of {J}apanese Unknown Morphemes using
  Morphological Constraints.\BBCQ\
\newblock In {\Bem Proceedigs of EMNLP'08}, \mbox{\BPGS\ 429--437}.

\bibitem[\protect\BCAY{Nagata}{Nagata}{1999}]{Nagata1999}
Nagata, M. \BBOP 1999\BBCP.
\newblock \BBOQ A Part of Speech Estimation Method for Japanese Unknown Words
  using a Statistical Model of Morphology and Context.\BBCQ\
\newblock In {\Bem Proceedigs of ACL'99}, \mbox{\BPGS\ 277--284}.

\bibitem[\protect\BCAY{Nakagawa \BBA\ Uchimoto}{Nakagawa \BBA\
  Uchimoto}{2007}]{Nakagawa2007a}
Nakagawa, T.\BBACOMMA\ \BBA\ Uchimoto, K. \BBOP 2007\BBCP.
\newblock \BBOQ A Hybrid Approach to Word Segmentation and POS Tagging.\BBCQ\
\newblock In {\Bem Proceedigs of ACL'07}, \mbox{\BPGS\ 217--220}.

\bibitem[\protect\BCAY{岡部\JBA 河原\JBA 黒橋}{岡部 \Jetal }{2007}]{Okabe2007}
岡部浩司\JBA 河原大輔\JBA 黒橋禎夫 \BBOP 2007\BBCP.
\newblock 代表表記による自然言語リソースの整備.\
\newblock \Jem{言語処理学会第13回年次大会}, \mbox{\BPGS\ 606--609}.

\bibitem[\protect\BCAY{斉藤\JBA 貞光\JBA 浅野\JBA 松尾}{斉藤 \Jetal
  }{2013}]{Saito2013}
斉藤いつみ\JBA 貞光九月\JBA 浅野久子\JBA 松尾義博 \BBOP 2013\BBCP.
\newblock
  正規-崩れ表記のアライメントに基づく表記崩れパタンの抽出と形態素解析への導入.\
\newblock \Jem{情報処理学会研究報告，自然言語処理研究会報告 2013-NL-214}, \mbox{\BPGS\
  1--9}.

\bibitem[\protect\BCAY{斉藤\JBA 貞光\JBA 浅野\JBA 松尾}{斉藤 \Jetal
  }{2014}]{Saito2014}
斉藤いつみ\JBA 貞光九月\JBA 浅野久子\JBA 松尾義博 \BBOP 2014\BBCP.
\newblock
  正規-崩れ文字列アライメントと文字種変換を用いた崩れ表記正規化に基づく日本語
形態素解析.\
\newblock \Jem{言語処理学会第18回年次大会発表論文集}, \mbox{\BPGS\ 777--780}.

\bibitem[\protect\BCAY{Shinzato, Shibata, Kawahara, Hashimoto, \BBA\
  Kurohashi}{Shinzato et~al.}{2008}]{Shinzato2008}
Shinzato, K., Shibata, T., Kawahara, D., Hashimoto, C., \BBA\ Kurohashi, S.
  \BBOP 2008\BBCP.
\newblock \BBOQ TSUBAKI: An Open Search Engine Infrastructure for Developing
  New Information Access Methodology.\BBCQ\
\newblock In {\Bem Proceedigs of IJCNLP'08}, \mbox{\BPGS\ 189--196}.

\bibitem[\protect\BCAY{Uchimoto, Sekine, \BBA\ Isahara}{Uchimoto
  et~al.}{2001}]{Uchimoto2001}
Uchimoto, K., Sekine, S., \BBA\ Isahara, H. \BBOP 2001\BBCP.
\newblock \BBOQ The Unknown Word Problem: A Morphological Analysis of Japanese
  using Maximum Entropy Aided by a Dictionary.\BBCQ\
\newblock In {\Bem Proceedigs of EMNLP'01}, \mbox{\BPGS\ 91--99}.

\end{thebibliography}


\appendix

 \section{濁音化した形態素の生起コスト}
 \label{APPEND::A}
 濁音化した形態素の生起コストは，濁音化する前の形態素に付与されているコス
 トに，次表に示すコストを加算することにより与える．
 
 \begin{table}[h]
\input{04tableA1.txt}
 \end{table}

濁音化する前の形態素のコストは表記ごとに与えられ，JUMAN5.1では名詞，動
 詞などといった内容語の多くは100，または，160のコストが付与されている．た
 とえば，動詞「座る」の平仮名表記である「すわる」のコストは100であるの
 で，その連用形が濁音化した「ずわり」のコストは170，名詞「蚕」の平仮名表
 記である「かいこ」のコストは160であるので，「がいこ」のコストは270とな
 る．ここで，``が''から始まる語に大きな加算コストを与えているのは，格助詞
 「が」を誤って濁音化した形態素の先頭であると解析されないようにするためで
 ある．
    

 \section{長音記号・小書き文字が置換・挿入された形態素の生起コスト}
 \label{APPEND::B}

 長音記号・小書き文字を置換・挿入することにより生成された
 形態素の生起コストは，置換・挿入前の形態素に付与されている生起コストに，
 次表に示すコストを加算することにより与える．

\begin{table}[h]
\input{04tableB1.txt}
 \end{table}

 ここで品詞コストとは，品詞ごとに定義されたコストであり，対象の品詞に属す
 る形態素の標準的な生起コストを表している．JUMAN5.1のデフォルトでは判定詞
 の場合には11，感動詞の場合には110，動詞，普通名詞，形容詞，副詞には100，
 副詞的名詞には70などのコストが与えられている．たとえば，普通名詞「あなた」
 の生起コストが100，普通名詞の品詞コストが100であることから，「ぁなた」と
 いう形態素の生起コストは160，感動詞「もしもし」の生起コストは110，感動詞
 の品詞コストは110であることから，「もしも〜し」という形態素の生起コスト
 は176となる．


 \section{反復型オノマトペの生起コスト}
 \label{APPEND::C}

 反復型オノマトペ$w$の生起コストは以下の式により与える．
 \[
  cost = LEN(w) \times 130 - f_v(w) \times 10 - f_p(w) \times 40 - f_k(w)
  \times 20
 \]
  ただし，

 \begin{tabular}{r@{\ }p{360pt}}
  $LEN(w)$:& $w$ に含まれる繰り返し文字数（ただし，ここでは「きゃ」などの開拗音は全体で1文字として扱う）\\
  $f_v(w)$:& $w$の先頭の文字が濁点または半濁点を含むなら2，それ以外の文字が濁点または半濁点を含むなら1，それ以外は0となる関数\\
  $f_p(w)$:& $w$が開拗音を含むなら1，それ以外は0となる関数\\
  $f_k(w)$:& $w$が片仮名であるなら1，それ以外は0となる関数
 \end{tabular}

\noindent
とする．

 すなわち，基本的に繰り返し文字数1つにつき130のコストを与えるが，先頭の文
 字が濁点・半濁点を含む場合は20，それ以外の文字が濁点・半濁点を含む場合は
 10，開拗音を含む場合は40，片仮名である場合は20，それぞれコストを小さくす
 る．これは，オノマトペは濁点・半濁点，開拗音を含む場合が多く，また，片仮
 名で表記されることが多いためである．たとえば，「ぐちょぐちょ」という形態
 素であれば，繰り返し音数は2で最初の文字が濁点を含みで，かつ，開拗音を含
 むので，生起コストは260から20と40を引いた200となる．

\clearpage
 \section{非反復型オノマトペの生成に使用した平仮名，片仮名の一覧}
 \label{APPEND::D}  

 \begin{table}[h]
\input{04tableD1.txt}
 \end{table}


\begin{biography}
 \bioauthor{笹野　遼平}{2009年東京大学大学院情報理工学系研究科博士課程修
 了．博士（情報理工学）．京都大学大学院情報学研究科特定研究員を経て2010年よ
 り東京工業大学精密工学研究所助教．自然言語処理，特に照応解析，述語項構造
 解析の研究に従事．言語処理学会，情報処理学会，人工知能学会，ACL各会員．}

 \bioauthor{黒橋　禎夫}{1994年京都大学大学院工学研究科電気工学第二専攻博士
 課程修了．博士（工学）．2006年4月より京都大学大学院情報学研究科教授．自
 然言語処理，知識情報処理の研究に従事．言語処理学会10周年記念論文賞，同
 20周年記念論文賞，第8回船井情報科学振興賞，2009 IBM Faculty Award等を受
 賞．2014年より日本学術会議連携会員．}

 \bioauthor{奥村　　学}{1962年生．1984年東京工業大学工学部情報工学科卒
 業．1989年同大学院博士課程修了．同年，東京工業大学工学部情報工学科助
 手．1992年北陸先端科学技術大学院大学情報科学研究科助教授，2000年東京工業
 大学精密工学研究所助教授， 2009年同教授，現在に至る．工学博士．自然言語
 処理，知的情報提示技術，語学学習支援，テキスト評価分析，テキストマイニン
 グに関する研究に従事．情報処理学会，電子情報通信学会，人工知能学会，
 AAAI，言語処理学会，ACL, 認知科学会，計量国語学会各会員．}
\end{biography}


\biodate


\end{document}
