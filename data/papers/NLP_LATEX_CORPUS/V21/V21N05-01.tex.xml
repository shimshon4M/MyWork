<?xml version="1.0" ?>
<root>
  <section title="Introduction">Statisticallanguagemodelsareafundamentalcomponentofspeechrecognitionsystems,machinetranslationsystemsandsoforth.Atpresent,theN-gramlanguagemodelisthemostwidelyusedapproach.Thismodelfocusesonsequencesofneighboringlexicalwords(Figure~)andusestheprobabilitiesofthesesequencesasmodelparameters.DuetothecompletelexicalizationoftheN-gramlanguagemodel,localfeaturesofwordsequencescanbewellmodeled.However,anN-gramlanguagemodelcannotcapturerelativelylong-rangefeatures,becauseitconsidersasentenceasaflatstringandignoresitsstructure.Revealingasentencestructureisthetaskofparsing,whichisbasedonlinguisticallyorientedformulations,anditfocusesongeneratingthelikelieststructureforagivensentence,usingconstituency-ordependency-basedformulations.Theformerorganizescontinuouswordsequencesinahierarchyofsmalltolargerangegroupswithlinguisticallyorientedlabels,whilethelatterdirectlylinkswordswithdependencyrelations(Figure~).Inthisstudy,wefocusonintroducingsentencestructureintolanguagemodeling.WeproposeagenerativedependencyN-gramlanguagemodelthatintegratesthegenerativedependencystructureofasentenceintotheoriginalN-gramlanguagemodel.Wepreferthedependency-basedformulationbecauseitcandirectlymodeltherelationsbetweenwords.Intheproposedmodel,theparameteristheprobabilityofthedependencyN-gram,whichisasequenceofwordsalongthedependencystructureratherthanalongaflatleft-to-rightstring.TheproposedmodelisthusascompletelylexicalastheoriginalN-gramlanguagemodel.Wefurtherproposeanexpectation-maximization(EM)algorithmforestimatingtheprobabilityofarbitraryorderdependencyN-grams,byconsideringallpossibledependencystructuresOnlyprojectivedependencystructuresareconsidered.ofasentence(Figure~).Theproposedalgorithmisunsupervised,language-independentandneedsnolinguisticinformation.</section>
  <section title="Related Work">ThetechnicalreportbyhascomparedvariousapproachestotheN-gramlanguagemodelandthemodifiedKneser-Ney(KN)discountingproposedinitisstillthestate-of-the-art.SincetheN-gramlanguagemodelonlycaptureslocallexicalfeatures,therehavebeenproposalstogeneralizethelexicalN-grambywordclassortomodellong-rangewordco-occurrencesbywordtriggers.However,thesemodelsareunawareofthesentencestructure,andtheybasicallytakeasentenceasaflatstring.Manyapproacheshavebeenproposedforconstituency-basedparsingandfordependency-basedparsing.Discriminativeapproachesareusedmorethangenerativeonesfordependency-basedparsing,becauseagenerativemodelisusuallyrestrictedtobeingbi-lexical(i.e.,thecomponentsarebi-gramsofhead-modifierpairs).Specificalgorithmshavebeendesignedtohandlemorecomplexdependencyrelations,andtheseallowtheconsiderationofmorelexicalinformationinagenerativemodel.Therehavebeenattemptstointegratesentencestructureintolanguagemodeling.haveproposedaconstituency-basedapproach,buttheuseoflanguage-dependentnon-terminalscannotbeavoided.Therearealsodependency-basedapproaches.Onestraightforwardmethodistoconstructalanguagemodelbasedonthedecisivelybeststructureproducedbyaparser.Theseapproachescanbeconsideredtoconverttheleft-to-rightstringintheoriginalN-grammodeltoacompletelysyntax-driventreestructure.Amorereasonablemethodistoconsideralldependencystructuresofasentence.Onesuchattemptisthebi-gramhead-modifiermodelof,whichisbasedontheparsingapproachof.Inourapproach,weconsideralldependencystructuresofasentenceandtrytoincludemorelexicalinformation.Weextendtheapproachoftohead-modifierchainsofarbitrarywords,ratherthanhead-modifierpairs.Wealsouseextratagsofthetypetypicallyfoundinparsingmodels.Thesetagsaretreatedasgenerallexicalwordsandareusedtomodelthevalenceofaheadword.Theparsingapproachesofalsohandlemorelexicalinformationinadependencystructure,includingcomplexrelations,suchasthesiblingrelation.However,theuseofhigh-orderdependencypatternsintheapproachislimited.Asdescribedin,arbitraryordersoflexicalinformationwitharbitrarydependencyrelationscanbehandledonlyiftheproperalgorithmsaredesigned,anddesigningthesebecomesmorecomplexwiththeincreasingnumberoflexicalwordsanddependencyrelations.Ourapproachconcentratesonlyonthehead-modifierchain,thatis,asequenceofparent-childrelations.Therefore,ourapproachisadirectextensionoftheoriginalN-grammodel,whichmodelsalexicalwordsequence,withoutbranching.Wewillalsoshowthatahead-modifierchainofarbitraryordercanbemodeledinauniformalgorithm,whichwillnotincreaseinformulationcomplexitywhentheorderincreases.</section>
  <section title="Generative Dependency Model">WemodelthemarginalprobabilityofasentenceSoversetDofallpossibledependencystructuresofS:P(S)=_dDP(S,d).Asdescribedin,ifweseparatethedependencystructureandlexicalization,then_dDP(S,d)=_dDP(d)P(S|d).ThetermP(S|d)isgivenbyamodelofcompletelylexicalwordsequenceswithdependencyrelations.However,thetermP(d),whichistheprobabilityofadependencygraphwithoutlexicalwords,isdifficulttomodel.Inearlierstudies,theP(d)termistakenasaconstantoromitted(i.e.,takenas1)forsimplicity,asin.Forexample,in,theprobabilityofasentenceSiscalculatedasP(S)=_dD_(xy)dP(xy),wheretheelement(xy)isalexicalhead-modifierpairinagivendependencystructured.Thus,theterm_xydP(xy)isequivalenttoP(S|d).Tocombinethedependencystructureandlexicalization,thevalence,whichrepresentsthemodifiernumbersofaheadword,shouldbemodeled.Adependencymodelwithvalence(DMV)isproposedby.DMVisagenerativemodelthatincludesaspecialmark,STOP,toterminatethemodifiersequenceofaheadword.WiththehelpoftheSTOPmark,thenumberofmodifierscanbecontrolled.Itisnecessarytodistinguishthetwotypesofparameters,i.e.,P_STOPandP_CHOOSEinthebi-gramestimation,whichmakesitdifficulttoextendtheapproachtohigherorders.InasimilarapproachtothatusedinDMV,weintroducefourtypesoftagtonormalizethedistributionofmodifiernumbers(thevalence)ofaheadword.Inthisstudy,weuseL(resp.L)andR(resp.R)toshowthestart(resp.end)oftheleftandrightmodifierwordsequencesofaheadword.Thedependencystructurecanthusbeorganizedasnestedwordsequences.Specifically,modifierwordsequencesofaheadwordareoftheformM=m_0^+1m_0,m_1,,m_+1,wherem_0O,m_+1O(OL,R),andm_1^isalexical-wordsequence.WeshowanexampleofthedependencystructureinFigure~.Forexample,inFigure~,thewordgethasaleftmodifierwordsequence``LiL''andarightmodifierwordsequence``RbookfromR''.IncontrasttothetreatmentinDMV,wetreattagsasordinarywordsintheparameterestimation.Thismeansparametersofourmodelhaveauniformrepresentation,bywhichourapproachcanbeeasilyextendedtoarbitraryhighorders.OurmodelisessentiallyequivalenttothegenerativeModelCin.Inotherwords,thesequenceOm_1^O(OL,R)isgeneratedasaMarkovsequencetoserveasthemodifierwordsequences(left/rightseparately)oftheheadword.The``starttag''OalwayssatisfiesP(m_0=O)1torepresentthenestedstructure.The``endtag''Oterminatesthegenerationprocess:thelargerP(m_+1=O)is,thesmaller,whichisthenumberofgeneratedwords,becomesandviceversa.P(S)=1foreverypossiblesentenceSinalanguageL,wenotethatitcannotbeguaranteedbythegenerativestructurealone.Asdiscussedin,alanguagegeneratedbyaprobabilisticcontext-freegrammarcannotbeguaranteedtobeconsistent,becausethegenerationprocesscannotbeguaranteedtofinish,evenwhentheprobabilitiesarenormalized.However,inthissituation,theprobabilitiesofterminalsequences(i.e.sentences)willbeverylow,whichwillleadtoapoorperformanceofthelanguagemodel.Thus,theresultsfortheproposedapproachreportedinthisstudymayunderestimateprobabilitiesbutwillnotoverestimatethem.Withoutlossofgenerality,theprobabilityofm_+1(0&lt;)inM=m_0^+1canberepresentedbyP(m_+1|m_0^,H),whereHisthehistoryofMalongthegeneratedpath.Weusetheindependentassumptionthattheprobabilityofawordinthegenerationprocessonlydependsonitsdirectancestorsandtheorientationbetweenthem.Theprobabilitycanbesimplifiedto:whereh^k(k[1,n-1])istheheadwordofh^k-1ando^k(k[1,n-1])showstheorientationbetweenthem.Specifically,h^k(k[0,n-1])canbeanyofthefollowing:alexicalwordinagivensentence,aO(OL,R)tag,thesentence-endingtags,whichistakenastherootofasentence,orthesentence-beginningtags,whichistakenasatrivialplaceholder,ando^k(k[1,n-1])isaO(OL,R)tag.The``slash''tags,s,LandR,aretakenaslexicalwords,whicharerepresentedbyh^k.The``no-slash''tags,LandR,showthedirectionofamodifierwordagainstitsheadword,whichisrepresentedbyo^k.Specifically,fork[1,n-1],wehaveo^k=Lwhenh^k-1isontheleftsideofh^k,ando^k=Rwhenh^k-1isontherightsideofh^k.,whichisontheo^n-1sideofitsheadwordh^n-1.Further,thesentence-beginningtagsisusedasatrivialplaceholdertoincreasetheorderofExp.()ton.Itisusedonlywhenh^k=sforsomek&lt;n-1.Forthetags,therearesomenoticeableproperties,suchasthefollowing:ifh^k=O(OL,R),thenk0;becauseO(OL,R)cannothavemodifiers,ifh^0=L,theno^1L,andifh^0=R,theno^1R,ifh^k=s(k[1,n-1]),theno^kL,ifh^k=s(k[1,n-2]),thenbotho^k+1Randh^k+1=s,ifh^k=s(k[1,n-2]),thenbotho^k+1Randh^k+1=s.Forexample,adependencyN-gramis(L,L,him,R,from,R,get,L,.,L,s)inthedependencystructureillustratedinFigure~.WecanseeO(OL,R)tagsbetweenwordsshowtherelevantpositionbetweenheadandmodifierwords.Infact,allwordsinamodifiersequencesharethesameO(OL,R).Forexample,inFigure~,the``book''and``from''sharethesameRtagastheyarebothintherightmodifierwordsequenceoftheheadword``get''.Thesequence(h^0,o^1,h^1,,o^n-1,h^n-1)inExp.()isreferredasadependencyN-gram.Exp.()istheprobabilityofthedependencyN-gramandthustheparameterofourmodel,wherethedependencyrelationandvalencearemodeleduniformlyforarbitraryorders.FromtheprobabilityofthedependencyN-gramofExp.(),theprobabilityofagivendependencystructuredofasentenceScanbecalculatedas_h^0dp(h^0|o^1,h^1,,o^n-1,h^n-1).BecauseofhowweuseO(OL,R)tags,the_h^0dp(h^0|o^1,h^1,,o^n-1,h^n-1)isequivalenttoP(S,d)ratherthantoP(S|d),asin.WeshowanexampleoftheP(S,d)fromExp.()toExp.()accordingtothestructureinFigure~,proceedinglayerbylayer.Wecanseetherearemanytermsofthetypeh^0=O(OL,R)inthecalculation.Thiscanbeconsidereda``discount''fortheproductoflexicaltermstorepresentthe``structureprobability''p(d),althoughp(d)isneverseparatedasanindividualtermbecausewemergethelexicalizationanddependencystructureinourcalculations.P&amp;(S,d)=&amp;P(.|Ls)&amp;P(get|L.Ls)P(L|L.Ls)	P(R|R.Ls)&amp;P(i|LgetL.)P(L|LgetL.)layer3&amp;P(book|RgetL.)P(from|RgetL.)P(R|RgetL.)&amp;P(L|LiLget)P(R|RiLget)&amp;P(a|LbookRget)P(L|LbookRget)P(R|RbookRget)&amp;P(L|LfromRget)P(him|RfromRget)P(R|RfromRget)&amp;P(L|LaLbook)P(R|RaLbook)&amp;P(L|LhimRfrom)P(R|RhimRfrom)alignTheprobabilityofasentenceScanthenbecalculatedbyP(S)=_dDP(S,d),wheretheleft-to-rightgenerationoftheoriginalN-grammodelisnaturallyincluded,andtheprobabilityofitwillbediscountedbythetermsoftheformh^0=O(OL,R).</section>
  <section title="Parameter Estimation"/>
  <subsection title="Notation">WedenoteasentencewithlwordsasS=w_0^l+1w_0,w_1,,w_l+1,wherew_0sandw_l+1s;eachw_k(k[1,l])isanordinarylexicalword.InasentenceS=w_0^l+1,wedenoteadependencyN-gram(h^0,o^1,h^1,,o^n-1,h^n-1)byanN-tupled=(d_0,d_1,,d_n-1)accordingtothefollowingdefinition.Thedefinitionofd_kinExp.()thusshowstherelationbetweenh^kandd_k.Becausethes,s,LandRtagsaretakenaslexicalwordsinadependencyN-gram,theycanappearinad.Inournotation,sandsareassignedabsolutepositionsof0andl+1,respectively,inanl-wordsentence,sotheycanbetriviallyintegratedinad.Conversely,asLandRtagsareattachedtoeverywordinasentence,wecannotassignabsolutepositionstothem,so,theyremaininadwithnotransformationtoabsoluteposition.Consequently,d_kinadcanbeanintegerin[0,l+1]oraO(OL,R)tag.Infact,becauseLandRtagscanappearonlyash^0inadependencyN-gram,theyonlyappearasd_0inad.TheN-tupledwithad_0=O(OL,R)willplayaspecialroleintherecursivedefinitioninSection.Becausethemagnitudesofd_kandd_k+1(k[0,n-2])showtheorientation,o^k+1canbeomitted.Inaddition,o^k+1canbeunambiguouslyomittedfortheLandRtagsbecauseofthepropertieswementionedintheprevioussection.Consequently,theLandRtagsneverneedtoappearinad.Asanexample,thedependencyN-gram(L,L,him,R,from,R,get,L,.,L,s)inthedependencystructureillustratedinFigure~canbedenotedbyad=(L,6,5,2,7,8)giventhesentence``i(1)get(2)a(3)book(4)from(5)him(6).(7)''.proposethecomplete-linksetandcomplete-sequencesetforhead-modifierpairs(i.e.,adependencybi-graminourmodel)tohandleallpossibleprojectivedependencystructuresofasentenceinarecursivemanner.WefollowthetermstheyuseandextendtheirdefinitionstoadaptthemtoourdependencyN-grammodel.WeuseLink(d)todenotethecomplete-linksetofanN-tupledandSeq(d)forthecomplete-sequenceset.In,thecomplete-linksetofaspan[i,j]inasentenceiscomposedofallpossibledependencystructureswithinthespan,withthedirectionaldependencylinkofthetwowordsw_iandw_j.Thecomplete-sequencesetofaspan[i,j]isdefinedasthesetofallpossiblesequenceswithanynumber(includingzero)ofadjacentcomplete-linksetshavingthesamedirectionwithinthespan.Byournotation,thewordatd_1isthedirectheadofthewordatd_0forLink(d_0,d_1),butthewordatd_1isanancestor(notonlyadirecthead)ofthewordatd_0forSeq(d_0,d_1).Thetwotypesofsetcanbedefinedrecursively,andthesetofallpossibledependencystructuresofasentenceS=w_0^l+1isthecomplete-sequencesetoverthespan[1,l+1]oristhecomplete-linksetoverthespan[0,l+1].WeillustratetheserecursiverelationsinFigure~and.BecausemorethantwowordsareinvolvedintheproposeddependencyN-gram,wegeneralizethetwotypesofsetfortheN-tuplesd,ratherthanjustspans.Thegeneralizationstillretainsthepropertiesofd_0andd_1inLink(d)andSeq(d),aswellastherecursivepropertiesofthetwotypesofset.Weshowtheexamplesofadependencytri-graminFigure~and.</subsection>
  <subsection title="Recursive Definition">Here,weprovidetheformulationoftherecursivedefinitionofthecomplete-linksetandcomplete-sequencesetforanarbitraryorderdependencyN-gram.InthedescriptionofthecalculationexampleshownfromExp.()toExp.()inSection,wementionedthatthosetermsh^0=O(OL,R)canbeconsideredasa``discount''oftheproductoflexicalterms.BythedefinitioninExp.()inSection,wecanfurtherseethath^0=O(OL,R)termsarerepresentedbytheN-tupledwithd_0=O(OL,R)andtheotherlexicaltermsarerepresentedbytheN-tupledinwhichallthed_k(k[0,n-1])areintegers.Forclarity,inthissection,wewillfirstdescribetherecursiondefinitionoflexicaltermswithoutd_0=O(OL,R)involveduptoExp.().Next,weturntothe``discount''terms,thatis,thecaseofd_0=O(OL,R),fromExp.()toExp.().First,duetothepropertiesoftheprojectivedependencystructure,anyd_k(k[1,n-1])intheN-tupled=(d_0,d_1,,d_n-1)needstosatisfythefollowingconstraintofExp.()toguaranteethataheadwordisoutsidetherangecoveredbyachainofitsdescendants.The()and()operationsareusedtogetthemaximumandminimumfromatuplecomposedofintegers.Trivially,wetakesastherootmarkofasentenceS=w_0^l+1,andthesastheheadofitselforastheheadofthes.So,wehavethefollowingconstraints:TorevealtherelationsbetweenN-tuples,weintroducethreebasicoperations,Push,CoverandInsert,overanindexx(absolutewordposition)andanN-tupled=(d_0,d_1,,d_n-1):Push(x,d)&amp;=(x,d_0,d_1,,d_n-2)Cover(x,d)&amp;=(x,d_1,d_2,,d_n-1)Insert(x,d)&amp;=(d_0,x,d_1,,d_n-2)alignWiththethreeoperations,wecanexpresstherelationshowninFigure~asfollows:Here,thesymbolindicatesthedirectproductofsets.ThatSeq(Push(x,(i,j,k)))Seq(x,i,j)andSeq(Cover(x+1,(i,j,k)))Seq(x+1,j,k)followsfromtheirdefinitions.Moreover,therelationshowninFigure~canbeexpressedasfollows:Here,thatSeq(Insert(x,(i,j,k)))Seq(i,x,j)andLink(Cover(x,(i,j,k)))Link(x,j,k)followsfromthedefinitions.Then,wecanprovidetheformaldefinitionoftheLink(d)andSeq(d)foranarbitraryorderdbyExp.()andExp.()below.&amp;Link(d)=_ifd_1=l+1,theni=d_1-1;elsei[(d_0,d_1),(d_0,d_1)-1]	Seq(Left(i,d))Seq(Right(i+1,d))d	&amp;where	(Left,Right)=		(Push,Cover),ifd_0&lt;d_1	(Cover,Push),ifd_0&gt;d_1	cases	&amp;Seq(d)=_i[(d_0,d_1),(d_0,d_1)]andid_1	Seq(Insert(i,d))Link(Cover(i,d))	alignExp.()showsthatacomplete-linksetisrecursivelycomposedofthedirectproductofallpossiblecomplete-sequencesetpairs,withtheN-tupleditself.markstotakeonlyonemodifier(thesituationwhend_1=l+1inExp.()),accordingtothegeneralrestrictionsofthedependencygrammar.Exp.()showsthatacomplete-sequencesetisrecursivelycomposedofthedirectproductofallpossiblepairsofacomplete-linksetandasmallercomplete-sequenceset.InExp.()andExp.(),ifd_0=d_1,whichviolatestherestrictionofExp.(),wethenreplaced_0byLandRasfollows.Infact,inthissituationalone,LandRcanappearinadasd_0,whichismentionedinthedefinitionofExp.()andrelatedproperties.ThecompletesetscontainingO(OL,R)tagsstarttherecursivedefinition.Left(x,d)=Left(R,d),&amp;ifx=(d_0,d_1)inExp.()Right(x,d)=Right(L,d),&amp;ifx=(d_0,d_1)inExp.()Insert(x,d)=Push(L,d),&amp;ifx=d_0,andd_0&lt;d_1inExp.()Insert(x,d)=Push(R,d),&amp;ifx=d_0,andd_0&gt;d_1inExp.()align</subsection>
  <subsection title="Estimation">Accordingtotherecursivedefinitions,itisnaturaltoderiveaninside-outsidealgorithm,whichisanadaptionoftheEMalgorithmtotreestructures,toconductparameterre-estimationbycalculatingtheinsideandoutsideprobabilitiesofallcompletesetsinsentences.WegeneralizetheexpressionsinExp.()andExp.()toExp.()andExp.(),respectively.InExp.(),Sub_1andSub_2meantheSeq(Left())andtheSeq(Right()),respectively,ontheright-handsideofExp.().InExp.(),Sub_1andSub_2meantheSeq(Insert())andtheLink(Cover()),respectively,ontheright-handsideofExp.().Thenotation,inExp.()andExp.()representsanunorderedtwo-tupleofacomplete-setpair.Link(d)=&amp;_Sub_1,Sub_2Sub_1Sub_2dSeq(d)=&amp;_Sub_1,Sub_2Sub_1Sub_2alignWefurtherdefineR_Link(Link(d),Sub_1,Sub_2)asarelationforLink(d),Sub_1,Sub_2satisfyingExp.().Similarly,R_Seq(Seq(d),Sub_1,Sub_2)isarelationforSeq(d),Sub_1,Sub_2satisfyingExp.().Then,theinsideprobabilityandoutsideprobabilityofthetwotypesofcompletesetcanbecalculatedbyExp.()toExp.(),wherep(d)istheprobabilityofthelexicaldependencyN-gram,representedbydinasentence.&amp;(Link(d))=_Sub_1,Sub_2,s.t.R_Link(Link(d),Sub_1,Sub_2)(Sub_1)(Sub_2)p(d)&amp;(Seq(d))=_Sub_1,Sub_2,s.t.R_Seq(Seq(d),Sub_1,Sub_2)(Sub_1)(Sub_2)&amp;(Link(d))=_Sup,Con,s.t.R_Seq(Sup,Link(d),Con)(Sup)(Con)&amp;(Seq(d))=_Sup,Con,s.t.R_Link(Sup,Seq(d),Con)(Sup)(Con)p(d')+_Sup,Con,s.t.R_Seq(Sup,Seq(d),Con)(Sup)(Con)&amp;(whered'istheN-tupleofSup)splitalignSpecifically,Exp.()andExp.()canbedirectlyderivedfromtherespectivedefinitionsofExp.()andExp.().Further,acomplete-linksetcanonlybeacomponentofacomplete-sequencesetfromExp.(),whileacomplete-sequencesetcanbebothacomponentofacomplete-linksetfromExp.()andacomponentofacomplete-sequencesetfromExp.().Consequently,Exp.()andExp.()canbothbederived.ForallSeq(d)withLorR,weuseasthestartofthecalculation.Attheendofthecalculation,theprobabilityoftheentiresentenceS=w_0^l+1canbeobtainedasfollows:Forre-estimation,wecanobtaintheprobabilisticcountsofadependencyN-gramrepresentedbydinasentenceusing:accordingtotheinside-outsidealgorithm.Finally,allthecountsofthedependencyN-graminthetrainingcorpusareaddedandnormalizedusingExp.()toupdatethemodelparameters.Weshowthedetailsofthere-estimationalgorithmwithpseudocodeinAppendixA.</subsection>
  <section title="Experiments"/>
  <subsection title="Experiment Setting">AstheproposeddependencyN-grammodelandestimationalgorithmareindependentfromlanguage,weconductexperimentsusingfourdifferentlanguages,i.e.,English,German,SpanishandJapanese.ThecorporaweuseforEnglish,GermanandSpanisharesetsofsentenceswith5--15wordsfromthecorrespondingsingle-languagecorporaofEuroparl.ThecorpusforJapaneseisasetofsentenceswith5--20wordsfromtheJapanesesideoftheNTCIR-8corpus.Wetake1200ofthesentencesfromacorpustoformeachofthedevelopmentandtestsetsusedinexperiments,andtheremainingsentencesareusedfortraining.Thedetailsoftraining,development(denoteddev.)andtestsetsareshowninTableand.Toinvestigatethefundamentalpropertiesofthemodelandalgorithm,wedonotuseanypruningorapproximatingmethodsintheparameterestimation.Specifically,wecollectallpossiblelexicaldependencyN-gramsfromtherawcorporawithoutanycut-offthresholdsformodelsofanyorder.Beforeestimation,weuserelativefrequencytoinitializetheprobabilities.</subsection>
  <subsection title="Results"/>
  <subsubsection title="Algorithm Convergence">FigureshowsthechangeofEnglishtrainingsetperplexitiesbeforeeachiterationbytheproposedestimationalgorithm,for2(bi-)and3(tri-)orderdependencyN-grammodels.Theconvergencetrendalongwiththeiterationtimescanbeobserved.Forthedependencybi-gram,thetrainingsetperplexitybecomesnearlystableafterfiveiterations.However,forthedependencytri-gram,thefirstiterationisatverylowtrainingsetperplexity,anditdoesnotchangemuchinfurtheriterations.Thisphenomenonsuggeststhatthenon-pruneddependencytri-grammodelmaybecomplexwithmanyparameters,sothefeaturesofthetrainingsetarerepresentedwell,resultinginalowperplexity.Thissuggeststhemodelisoverfittingthedata.WediscussthisinSection.</subsubsection>
  <subsubsection title="Test Set Perplexity">Aswellasthetrainingsetperplexity,theperplexityofatestsetwhichhasnotbeenusedinparameterestimationshouldbeinvestigatedinevaluation.BecausedifferentorderdependencyN-grammodelsaretrainedseparately,weuselinearinterpolationincalculatingthetestsetperplexity.Specifically,weusetheheld-outdevelopmentsettotunetheinterpolationcoefficients(weights)andtoselecttheiterationtimesofdifferentordermodelstominimizethedevelopmentsetperplexity.Nextweusethetunedweightstocombinetheiteration-time-selectedmodelsinthetestsetperplexitycalculation.Thereasonforusingsimpleandstraightforwardlinearinterpolationisthatwewanttodiscovertheessentialaspectsoftheproposedmodelandalgorithm,soweusenofurthersmoothingapproaches.AsthelowestorderofadependencyN-gramistwo,weuseauni-grammodelwithmodifiedKNdiscountingtohandletheunknownwords.Theuni-grammodelisinterpolatedwiththedependencybi-grammodel.Furthermore,astheLandRtagsaretakenasgeneralwords,whichneverreallyappearinatrainingset,wetreatthemseparately,andinterpolatethemwiththeuni-grammodel.Becausethes,LandRtagsonlyappearinthehistory,noothermodelisneededtohandlethem.InTable,weshowthedevelopmentandtestsetperplexitiesofthelinear-interpolateddependencybi-andtri-grammodels.Forcomparison,weusedSRILMstolcke2002srilmtobuildtwooriginalN-gramlanguagemodelsonthesametrainingsets:oneisconstructedbymaximumlikelihoodestimationwithoutanysmoothing,andtheotherisconstructedbythestate-of-the-artinterpolatedmodifiedKNdiscounting.WecalculatethetestsetperplexitiesofthetwoN-gramlanguagemodelsonthesametestsets.TheresultsarelistedinTable.InbothTableand,theperplexitiesarecalculatedaccordingtothenumberoflexicalwords,andthetagsusedfornormalizationarenotcounted.WediscusstheseresultsinSection.</subsubsection>
  <subsection title="Discussion">InTable,and,weshowtheexamplesoflexicaldependencyfeatureswithhighestimatesoflogarithmicprobability(log-prob.)withourunsupervisedapproach.InTable,theexamplesofdependencybi-gramsaroundgeneralwordsareshown.Wecanseethatthedependencyrelationsbetweenthemarewellmodeled.Moreover,inTable,weshowthefeaturesoftherootmarksofsentences.Wecanseethatthefinalpunctuationmarksandfinal-positionparticlesareautomaticallylearnedasmodifiersoftherootmark(i.e.,oftherootwordofasentence).InTable,weshowanexampleofaspecialChineseexpressionontheInternet.Theword``795E9A6C'',readassh'en-ma,means``what''onthebasisofsimilarityinpronunciationtotheoriginalwordsh'en-me.Ourunsuperviseddata-drivenapproachrevealsthebehaviorsofthisneologism,whichisnaturalforaChinesenativespeaker.InTable,weshowanexampleofadependencytri-gram.Theexpression``670967286709''(you-m`u-you)isalsoanInternet-basedneologism,whichmeans``toexistornot'',becausetheoriginalexpression``67096CA16709''(you-m'ei-you)hasasimilarpronunciationinsomedialects.Weshowallfourpossiblestructurepatternsforbothofthem.Wecanseethatallofthesestructureshaverelativelyhighestimates,whichshowsstrongdependencyrelations.However,ifweuseageneralChineseparser,thecharacter``6728''isalwaystreatedasanounduetoitsoriginalmeaningof``wood'',andthetri-orderrelationoftheexpression``670967286709''isnotrecognized.InFigure~,weshowthebestdependencystructuregivenbytheViterbialgorithmforasentenceinthetrainingset.Figure~isthedependencystructuregeneratedbytheStanfordDependencyParser^.Althoughtherearenoneologismsinthissentence,theChineseword5FC3''isageneralwordandordinarilyusedasanounoranadjective,meaning``sincerity''or``sincere''respectively.However,ithasrecentlybeenusedasanadverbtoexpressthemeaningof``really''inaslightlyemphaticmanner.Thisfeatureisalsocapturedbyourapproachfromtrainingdataandcontextualizedwithintheentiresentencestructure,resultinginacorrectanalysis.Astandardparsercannotefficientlyhandlethistypeofflexibleusageofgeneralwords.</subsection>
  <subsubsection title="Parameter Number">Forasentencewithlwords,thenumberofdependencyN-gramsthatcanbecollectedincreasesexponentiallyasO(l^N)ifweconsiderallpossiblecombinations.AlthoughforagivenN,theproposedalgorithmtakesatimewhichispolynomialinsentencelengthl,alargeNwillbepracticallyintractable,especiallyforlongsentences.InFigure,weshowthenumberofcompletesetsofdifferentorderdependencyN-grammodelsfordifferentsentencelengths.Thisbehaviorisalsorelatedtotheoverfittingproblem,becauseouralgorithmisessentiallyaniterativemaximumlikelihoodestimation.Amodelthatisverycomplexwillbeextremelyspecifictothetrainingset.FromTable,weseethattheperformanceofadependencytri-grammodelwillsaturateafteronlyoneiteration,whichisalsoindicatedinFigure,anddoeslittletoimprovethetestsetperplexities.TheexceptionisJapanese,wherethedependencytri-gramdoesimprovetheperformance.ThelinguisticreasonforthisisthatJapaneseisahead-finallanguagewithasimplersyntacticstructure,sowerestrictthedependencylinkinJapaneseto``leftonly'',whichleadstoamodelwithfewerparameters.Consequently,thehighordermodelperformsbetter.Fromtheexperimentalresults,wecanseethattheproposedalgorithmhastheusualstrengthsandweaknessesofanEMalgorithm.</subsubsection>
  <subsubsection title="Model Preference">InFigure~to,wepresenttheexamplesofthebestdependencystructuresofsentencesintestsetgeneratedbyourapproach.WeusedthesettingsinTableandgeneratedthemusingtheViterbialgorithm.Itcanbeseenthattheproposedapproachcanrevealfeaturesofspecificlanguages,eventhoughitisunsupervised,suchasforthefinal-positionverb``stellen''anditsrelationwiththesecond-positionauxiliaryverb``m&quot;ochte''intheGermansentenceinFigure~.Theresultsalsoshowapreferenceforassociatingsemanticrelationsandmakingthefunctionwordsofalanguagethemodifiersofthecontentwords.ThistendencyisnoticeableintheEnglishexamples,suchastheparticle``to''inFigure~andandthe``'s''inFigure~.Inaddition,thearrangementofcommasaround``however''inFigure~andaround``therefore''inFigure~isimpressive.AnotherexampleisintheSpanishsentenceinFigure~.Syntactically,thepreposition``a''istheheadofthenoun``respecto'',butinunsupervisedtraining,ourmodelpreferstoassign``a''tobethemodifierof``respecto''anddirectlylinktwocontentwords,i.e.``respecto''andtheverb``haciendo''.WethinkthisisbecausetheprobabilitiesofLandtagshavelargeestimates,especiallywhentheyappearafterfunctionwords,whichpreventsthemfromhavingmodifiers.Thistendency,however,iscorrectforarticles,suchasthe``der''inGermanand``la''inSpanish.Furthermore,aninterestingphenomenoncanbeobservedintheJapanesesentenceinFigure~.Intheexample,theverbstem“応用”islinkedtotheauxiliaryverb“できる”,andthewordsof“することが”arearrangedasadependencychainandattachedto“できる”aswell.Semantically,theexpressionsof“応用できる”(literally:canapply)and“応用することができる”(literally:thething,thatapplies,can)havenearlythesamemeaningandaregenerallyinterchangeable.Consequently,themodelpreferstodesignate“することが”,whichhasaweaksemanticfunction,asabranchandlinkthesemantically-crucialwords“応用”and“できる”directly.Alltheseexamplessuggestthattheproposedmodelwithunsupervisedtraininghasastrongpreferencefororganizingasentencebysemanticrelationsandforassigningrelationsbetweenthosewordsthatplayacentralroleinsuchasemanticunit.</subsubsection>
  <section title="Application to Microblog Data"/>
  <subsection title="Task and Corpus">Microbloggingisanemergingapplicationthatprovidesanewplatformforcommunicating.Postingsonmicroblogsareusuallybriefduetorestrictionsonmessagelengthsuchthatnomorethan140charactersmaybeused.Moreover,microblogsusemanynon-standardexpressionsandInternet-basedneologisms.Thesewordsandexpressionsarehardforgeneralnaturallanguageprocessingtools,whichareusuallytrainedonstandarddatasets,tohandle.Therefore,tasksusingmicroblogsasahugedatasourcemustconsiderthecharacteristicsofuser-generatedcontent.Oneexampleofthisisthepart-of-speechtaggingtaskonmicroblogs.However,themoreexplicitandstructuredwewanttheinformationextractedfromamicroblogtobe,themoredifficultthetaskturnsouttobe,duetotheflexibleandnon-standarduseoftheexpressions.Becauseourproposedapproachiscompletelydatadriven,wethinkitcanefficientlycapturefeaturesinuser-generatedcontent.Inthissection,usingourproposedmodel,wefocusonextractingandinvestigatinglexicaldependencyfeaturesfromChinesemicroblogdata.WeusetheNLPIRChineseWeibocorpusinourexperiment.Thecorpuscontains230,000postscollectedfromSinaWeiboandTencentWeibo.Duringpreprocessing,wesplitthepostsintosentences,deletethetagsbeginningwith@and\#andalltheURLs.WeusetheStanfordChineseWordSegmenterwiththeChinesePennTreebankstandardtosegmenteachChinesesentenceandtakethosesentenceswith5--30wordsasthetrainingcorpusinourexperiment.WefurthernormalizethepunctuationmarksinthetrainingcorpusandreplaceallwordsappearingfewerthanfivetimeswithasymbolicUNKtoken.ThedetailsofthetrainingcorpusareshowninTable.WecollectallpossiblelexicaldependencyN-gramsfromthetrainingcorpusanduserelativefrequencytoinitializetheprobabilities.Figure~showsthechangeoftrainingcorpusperplexitiesbeforeeachiterationfor2(bi-)and3(tri-)orderdependencyN-grammodels.WecanobservethesametrendshowninFigure~.However,ourinterestisthelearnedfeaturesofthetrainingset.Wediscusstheexamplesoflexicalparametersandparsingusingathree-timeiterateddependencybi-grammodelandaone-timeiterateddependencytri-grammodelinthenextsection.</subsection>
  <section title="Conclusion and Future Work">Inthisstudy,wefocusedonintroducingsentencestructureintolanguagemodeling.WeproposedagenerativedependencyN-gramlanguagemodel,whichextendstheoriginalN-gramlanguagemodeltoincludesentencedependencystructures,aswellasadefinitionofcompletesetsforarbitraryorder,whichfacilitatesanunsupervisedparameterestimationalgorithm.Theexperimentalresultsdemonstratetheapplicabilityandthepropertiesoftheproposedapproach.Wealsoappliedacompletedata-drivenapproachforlexicaldependencyfeatureextractiontoatextualmicroblogdataset.Theexperimentalresultsshowthatourapproachcanhandlenon-standardlinguisticphenomenainuser-generatedcontent.Infuture,wewilldevelopmethodsforparameterpruninganddiscountingtohandletheoverfittingproblem.Astheproposeddependencylanguagemodelisintrinsicallycomplex,wealsoplanmorefundamentalsimplifications.Inaddition,althoughourproposedalgorithmisunsupervised,theoutputofatrainedparser,whichwouldprovideclearandlexicalheuristics,canbeintegratedinit.Weplantoinvestigatethispossibilityandevaluatetheperformanceachievedbyusinglinguisticallymotivatedcriteria.earlierversionofthisstudyhasbeenpresentedatthe6thInternationalJointConferenceonNaturalLanguageProcessing(IJCNLP2013).Wewouldliketothanktheanonymousreviewersfortheirvaluablecommentsandsuggestions.ThisstudywassupportedbyJSPSKAKENHIGrantNumber24650063.</section>
  <section title="Calculation of the Estimation Algorithm">InSection,weprovideare-estimationmethodasaninside-outsidealgorithm.Whentheorderisrestrictedtotwo,asin,thecalculationofalltheinside(())andoutside(())probabilitiescanbeconductedonaCKY-wisetriangletable.Specifically,theinsideprobabilitiesarefirstcalculatedfromsmalltolargespansinabottom-upway;thentheoutsideprobabilitiesarecalculatedinatop-downwaybyusingthecalculatedinsideprobabilities.BecausetheproposedapproachextendsthedependencyN-gramtoanarbitraryorder,atwo-dimensionaltriangletableisnotsufficient.Ingeneral,there-estimationofamodelwithN-orderlexicalparametersneedsanN-dimensiontable,whichceasestobeintuitive.Anaivemethodofcalculatingtheinside-outsideprobabilityofasentencecanbeperformedbythepseudocodeofNaive-Inside-Outside.Moreefficiently,wecanfirstgenerateaprocesslisttorecordtheprocessingorderforallthenecessaryinsideandoutsideprobabilitiesofasentence,andthencalculatethemaccordingtotheprocesslist.Inpractice,theprocessgiveninNaive-Inside-Outside,whichidentifiestheprocessingorder,needstoexecuteonlyonce,whichcanbeperformedduringpre-processing.ThegenerationoftheprocesslistisshownbythepseudocodeofProcess-List.ThiscodeisbasicallyidenticaltotheprocessNaive-Inside-Outside;insteadofcalculating,the``name''tokens(generatedbyGet-Tuple)ofalltheinsideandoutsideprobabilitiesarerecorded.Forcreatingtheprocesslist,thecalculationstepofInside-Outsideistrivial,becausethecalculationisfoundfromtherecorded``name''byusingGet-Probability.5mmNaive-Inside-Outside(Sentence)calculate(Set)accordingtoExp.()	allinsideprobabilities(Set)ofSentence		accordingtoExp.(),Exp.()				all(Sub_1),(Sub_2)ontherightsideareavailable				calculate(Set)								allinsideprobabilities(Set)arecalculated	alloutsideprobabilities(Set)ofSentence		accordingtoExp.()orExp.()				all(Sup)ontherightsideareavailable				calculate(Set)								alloutsideprobabilities(Set)arecalculatedcodeboxInside-Outside(Sentence,ProcessList)i1length(ProcessList)		Get-Probability(ProcessList[i])	codeboxGet-Probability(X,Y,Z)	X(Y(Z))accordingtoExp.(),Exp.(),Exp.(),Exp.()orExp.()codeboxProcess-List()Process-List[]allSeq(d)ofExp.()	appendGet-Tuple((Seq(d)))toProcess-List		allcompletesetsSet	accordingtoExp.()orExp.()				allGet-Tuple((Sub_1)),Get-Tuple((Sub_2))Process-List			appendGet-Tuple((Set))toProcess-List						Get-Tuple((Set))Process-ListforallSetallcompletesetsSet	accordingtoExp.()orExp.()				allGet-Tuple((Sup))Process-List			appendGet-Tuple((Set))toProcess-List						Get-Tuple((Set))Process-ListforallSetProcess-ListcodeboxGet-Tuple(X(Y(Z)))	(X,Y,Z)codeboxdocument</section>
</root>
