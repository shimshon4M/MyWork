<?xml version="1.0" ?>
<root>
  <jtitle>述語と項の位置関係ごとの候補比較による日本語述語項構造解析</jtitle>
  <jauthor>林部祐太小町守松本裕治*0.5</jauthor>
  <jabstract>一般に，項は述語に近いところにあるという特性がある．そのため，従来の述語項構造解析の研究では，候補を述語との位置関係でグループ分けし，あらかじめ求めておいたグループ間の優先順序に従って正解項を探索してきた．しかしながら，その方法には異なるグループに属する候補同士の比較ができないという問題がある．そこで我々は，異なるグループごとに最尤候補を選出し，それらの中から最終的な出力を決めるモデルを提案する．このモデルは優先度の高いグループに属する候補以外も参照することによって最終的な決定を行うことができ，全体的な最適化が可能である．実験では，提案手法は優先順序に従う解析よりも精度が向上することを確認した．</jabstract>
  <jkeywords>述語項構造解析，項と述語の位置関係，探索先行分類型モデル*1</jkeywords>
  <subsubsection title="IIDA2007+">INTRA_Dの探索後，最尤候補が項としてふさわしいかどうかの判断（適格性判定）を行う．適格であればそれを出力し終了する．非適格であればINTRA_Zの探索を行い，同様に適格性判定を行う．それも非適格であればINTERの探索を行い，適格であればそれを出力し，非適格であれば項は無いと判断する．IIDA2005とIIDA2007の自然な拡張で，述語から統語的な距離の近いものを優先的に探索する．IIDA2007と比較することで，文内候補を細かくINTRA_DとINTRA_Zに分けて優先順序をつけることの効果を調べる．</subsubsection>
  <section title="はじめに">述語項構造解析の目的は，述語とそれらの項を文の意味的な構成単位として，文章から「誰が何をどうした」という意味的な関係を抽出することである．これは，機械翻訳や自動要約などの自然言語処理の応用において重要なタスクの1つである.述語は文の主要部で，他の要素とともに文を構成する．日本語では，述語は品詞によって，形容詞述語・動詞述語・名詞述語の3種類に分けられる．述語が意味をなすためには，補語（主語を含む）が必要であり，それらは項と呼ばれる．また，述語と項の意味的関係を表すラベルを格と呼ぶ．項は前後文脈から推測できるとき省略されることがあり，省略された項をゼロ代名詞，ゼロ代名詞が指示する要素を先行詞と呼ぶ．この言語現象はゼロ照応と呼ばれ，日本語では項の省略がたびたび起きることから，述語項構造解析はゼロ照応解析としても扱われてきた．本稿では，項と述語の位置関係の種類を次の4種類に分類する．述語と同一文内にあり係り受け関係にある項，（ゼロ代名詞の先行詞として同一文中に存在する）文内ゼロ，（ゼロ代名詞の先行詞として述語とは異なる文中に存在する）文間ゼロ，および（文章中には存在しない）外界項である．本稿では，それぞれINTRA_D,INTRA_Z,INTER,EXOと呼ぶ．ある述語がある格にて項を持たないときは，その述語の項はARG_NULLだとし，その述語とARG_NULLはNULLという位置関係にあるとして考える．本稿では，EXOとNULLを総称してNO-ARGと呼ぶ．例えば，exs-atypeにおいて，「受け取った」と「食べた」のヲ格項「コロッケ」はそれぞれINTRA_D・INTRA_Z，「飲んだ」のガ格項「彼女」はINTERで，ニ格項はARG_NULLである．コロッケを受け取った彼女は，急いで食べた．（が）ジュースも飲んだ．exs-atype一般に，項は述語に近いところにあるという特性（近距離特性）を持つ．そのため，これまでの述語項構造解析の研究では，この特性の利用を様々な形で試みてきた．Kawahara:2004:JNLPやTaira:2008:EMNLPは項候補と述語の係り受け関係の種類ごとに項へのなりやすさの順序を定義し，その順序に従って項の探索を行った．また，Iida:2007:TALIPは述語と同一文内の候補を優先的に探索した．これらの先行研究ではあらかじめ定めておいた項の位置関係に基づく順序に従った探索を行い，項らしいものが見つかれば以降の探索はしない．そのため，異なる位置関係にある候補との「どちらがより項らしいか」という相対的な比較は行えず，述語と項候補の情報から「どのくらい項としてふさわしいか」という絶対的な判断を行わなければならないという問題点がある．そこで，本稿では，項の位置関係ごとに独立に最尤候補を選出した後，それらの中から最尤候補を1つ選出するというモデルを提案する．位置関係ごとに解析モデルを分けることで，柔軟に素性やモデルを設計できるようになる．また，位置関係の優先順序だけでなく，その他の情報（素性）も用いて総合的にどちらがより``項らしい''かが判断できるようになる．本稿の実験では，まず，全ての候補を参照してから解析するモデルと，特定の候補を優先して探索するモデルを比較して，決定的な解析の良し悪しを分析する．また，陽に項の位置関係ごとの比較を行わないモデルや，優先順序に則った決定的な解析モデルと提案モデルを比較して，ガ格・ヲ格ではより高い性能を達成できたことも示す．本稿の構成は以下のようになっている．まず2章で述語項構造解析の先行研究での位置関係と項へのなりやすさの優先順序の扱いについて紹介する．3章では提案手法について詳述し，4章では評価実験の設定について述べる．5章・6章では実験結果の分析を行い，7章でまとめを行う．</section>
  <section title="関連研究">ここでは，述語項構造解析の先行研究における，位置関係と項へのなりやすさの優先順序の扱いについて紹介する．先行研究と提案手法の概要をtbl:rworkにまとめた．</section>
  <subsection title="決定的な解析を行う方法"/>
  <subsubsection title="優先順序を統計的に求める方法">savenotesKawahara:2004:JNLPは，解析をゼロ代名詞検出と先行詞同定の2段階に分け，統計的に求めた優先順序を先行詞同定の際に用いた．彼らの手法では，まず，格フレーム辞書に基づく格解析によって，ゼロ代名詞の検出を行う．そして，項が存在すると判断された場合は，あらかじめ求めておいた優先順序に従って候補を探索し，候補と格フレーム用例の類似度が閾値以上かつ分類器でも正例と分類される候補を先行詞として同定する．分類器は項の位置関係に関わらず，共通のものを作成した．素性には，格フレームとの類似度や品詞などを用いた．彼らは，従属節，主節，埋め込み文などといった文・文章中の構造をもとに，項の位置関係（彼らは「位置カテゴリ」と呼んだ）を20種類に分類した．彼らは，位置カテゴリごとに，先行詞の取りやすさをでスコア化した．そして，位置カテゴリごとに，京都大学テキストコーパスからスコアを算出し，得られたスコアを降順にソートしてそれぞれの格について優先順序を得た．</subsubsection>
  <subsubsection title="文内候補を優先的に探索する方法">Iida:2007:TALIPは，先行詞候補とゼロ代名詞の統語的関係をパターン化するために，木を分類するブースティングアルゴリズムBACTを用いた．BACTは木構造データを入力とし，全ての部分木の中から分類に寄与する部分木に対して大きな重みをつける．彼らは，先行詞候補とゼロ代名詞間の係り受け木や，関係を表す素性を，根ノードに子としてつなげてBACTの入力とした．文間先行詞の同定には係り受け関係を利用できないため，彼らは先行詞の同定モデルを文内と文間に分け，文内候補を優先的に探索する以下の方法をとった．最尤先行詞同定モデルM_10で，文内最尤先行詞C_1^*を求める照応性判定モデルM_11で，C_1^*の先行詞らしさのスコアp_1を求める．あらかじめ定めておいた閾値_intraに対して，p_1_intraであれば，C_1^*を先行詞として決定する．そうでなければ()に進む．最尤先行詞同定モデルM_20で，文間最尤先行詞C_2^*を求める照応性判定モデルM_21で，C_2^*の先行詞らしさのスコアp_2を求める．あらかじめ定めておいた閾値_interに対して，p_2_interであれば，C_2^*を先行詞として決定する．そうでなければ，先行詞なしとする．M_10M_21はそれぞれBACTを使って学習・分類し，パラメータ_intraと_interは，開発データを用いて最適なものを求める．この手法では，文内の最尤先行詞同定や照応性判定には文間の候補の情報は参照せずに，決定的に解析している．</subsubsection>
  <subsubsection title="優先順位を経験的に決める方法">Taira:2008:EMNLPは，決定リストを用いて全ての格の解析を同時に行う方法を提案した．決定リストは規則の集合に適用順位を付けたものであり，機械学習の結果を人が分析しやすいという特長がある．彼らは項の位置関係やヴォイス・機能語に加えて，単語の出現形・日本語語彙大系から得られる意味カテゴリ・品詞のいずれか1つを加えたものを組として扱い，それぞれの組を1つの素性とした．そして，述語ごとにSupportVectorMachineの学習で素性の重みを得て，素性を重みでソートしたものを決定リストとした．すなわち，1つの素性を1つの決定リストのルールとして扱った．彼らは項の単位を単語とし，項の位置関係を係り受け関係に基づいて次の7種類に定義している．なお，fwとbwは追加的な種類で，その他の種類と兼ねることができる．IncomingConnectionType(ic):項を含む文節が述語を含む文節に係っている日米交渉_ガ:進展が進展したOutgoingConnectionType(oc):述語を含む文節が項を含む文節に係っている衝動買いした新刊本_ガ:買いWithintheSamePhraseType(sc):項が述語と同じ文節内にある日米交渉_ガ:日がConnectionintoOtherCaseroleTypes(ga_c,wo_c,ni_c):項を含む文節が述語を含む文節に，他の格の項を介して係っているトム_ヲ:説得,ga_cへの友人_ガ:説得による説得Non-connectionType(nc):項が述語とは異なる文にあるForwardType(fw):文章内にて，項が述語の前方にあるBackwardType(bw):文章内にて，項が述語の後方にある実際の解析は，各述語について次の手順で行った．ic,oc,ga_c,wo_c,ni_cについて，決定リストを用いて項を決定する()で決まらなかった格について，scの決定リストを用いて項を決定する対象の述語が項を持つ確率が50%以上であれば()に進むnc,fw,bwに関する決定リストを用いて項を決定するこの手法は経験的に，優先順序をic,oc,ga_c,wo_c,ni_c&gt;sc&gt;&gt;nc,fw,bwのように定めたといえる．ic,oc,ga_c,wo_c,ni_c間での，探索の優先関係はない．この方法は，格と項の位置関係を考慮しつつ，項になりやすいものから決めていくのが特徴である．ただし，着目している候補と述語の情報のみを用いて項らしいかどうかを判断していくため，必ずしも全ての候補を参照してから最終的な出力を決定するわけではなく，候補間でどれが項らしいかの相対的な判断は行われない．</subsubsection>
  <subsubsection title="述語と係り受け関係にある候補を優先的に項であるとみなす方法">Sasano:IPSJ:2011は，解析対象述語の格フレーム候補それぞれに対して，次の手順で格フレームと談話要素の対応付け候補を生成した．解析対象述語と直接係り受け関係にある談話要素を，選ばれた格フレームの格スロットと対応付ける．談話要素が係助詞をともなって出現した場合や，被連体修飾節に出現した場合など，複数の格スロットとの対応付けが考えられる場合は，考えうるすべての対応付けを生成する．上記の処理で生成された対応付け候補に対し，対応付けられなかったガ格・ヲ格・ニ格と，解析対象述語と係り受け関係にない談話要素の対応付けを行う．そして，対数線形モデルにて最も確率的評価が高い対応付けを解析結果として出力した．素性には，意味クラスや固有表現情報の他に，出現格と出現位置に関する85個の2値素性も用いた．この手法では，格ごとに独立に解析を行なっているのではなく，同時に解析を行なう．しかし，述語と係り受け関係にある候補を優先的に項であるとみなすため，係り受け関係にある候補と，係り受け関係にない候補または他の文にある候補との比較は行えない．</subsubsection>
  <subsection title="優先順序を素性として表現する方法">位置関係と項へのなりやすさの関係を優先順序として利用し決定的な解析を行うのではなく，素性として利用した研究もある．</subsection>
  <subsubsection title="最大エントロピー法を用いる方法">Imamura:2009:ACLは，最大エントロピー法に基づく識別的モデルを用いた．彼らは，位置関係ごとにモデルを分けるのではなく，素性として，述語と候補の位置関係，係り受け関係を用いた．そして候補集合に，項を持たないことを示す特別な名詞句NULLを加え，その中から最尤候補を同定するというモデル化を行った．なお，候補数削減のため，文間項候補は述語を含む文の直前の文に出現したものと，これまでの解析ですでに項として同定されたものに限定している．この方法では格ごとにモデルは1つだけ学習すればよい．ただし，この手法では，候補間の関係を素性として用いることはできない．</subsubsection>
  <subsubsection title="Markov Logicを用いる方法">Yoshikawa:2013:JNLPは，MarkovLogicを利用して，文内の複数の述語の	項構造解析を同時に行う手法を提案した．MarkovLogicは一階述語論理とMarkovNetworksを組み合わせたもので，一階述語論理式の矛盾をある程度のペナルティの上で認めることができる統計的関係学習の枠組みである．彼らは項同定・項候補削減・格ラベル付与を同時に行うモデルを提案した．彼らは，文間の項候補を加えるのは計算量の問題から困難だとしている．素性（観測述語）は述語と候補の係り受け関係などを用いた．</subsubsection>
  <section title="述語と項の位置関係ごとの候補比較による日本語述語項構造解析">先行研究では，優先順位の低い位置関係にある候補は参照されずに，解析が行われていた．この方法は，優先順位の高い位置関係にある項の同定の性能は上げることができるが，優先順位の低い位置関係にある候補の再現率は下げてしまうという問題点がある．また，優先順位の低い位置関係にある候補も参照してから最終的な決定を行った方が，全体的な解析性能が向上すると考える．そこで我々は，探索とトーナメントの2つのフェーズからなる，位置関係ごとに最尤候補を求めてから最終的な出力を決めるモデルを提案する．これは，「探索」・「分類」という2つのフェーズを持つ探索先行分類型モデルに着想を得て，後半の分類フェーズをトーナメント式に置き換えたものである．なお，このモデルは格ごとに解析器を学習・使用する．</section>
  <subsection title="項構造解析における探索先行トーナメントモデル"/>
  <subsubsection title="探索">はじめのフェーズでは任意の項同定モデルを用いてINTRA_D,INTRA_Z,INTERの最尤候補を選出する．それぞれ異なる素性やモデルを用いてもよい．モデルには，述語と探索対象の候補を入力として与え，探索対象の候補の中の1つを出力させる．</subsubsection>
  <subsubsection title="トーナメント">次のフェーズでは探索フェーズで得られた3つの最尤候補を入力とし，そのうちの1つか``NO-ARG''を出力する．これにより，最尤候補のうちどれが正解項であるか，もしくは項を持たないかを判断する．このフェーズはfig:anap-tournament-modelに示したように(a)から(c)の3つの2値分類モデルで構成される．なお，予備実験にて異なる順序を試したが，文内最尤候補同士を(a)にて直接比較できるこの順序の性能が最も高かった．	0cm	0cmINTRA_DとINTRA_Zを比較して，よりその述語の項らしい方を選ぶINTERと(a)で選出された候補を比較して，よりその述語の項らしい方を選ぶ(b)で選出された候補と``NO-ARG''を比較して，よりその述語の項らしい方を選ぶ(a)から(c)の分類器の学習事例には，Algorithmで示すように探索フェーズで得られた最尤候補を用いる．</subsubsection>
  <subsection title="提案手法の関連研究">提案手法は2つのモデルを参考にしている．1つ目は名詞句の照応解析における探索先行分類型モデル(selection-then-classificationmodel)である．このモデルは最初に，最尤先行詞を求める（彼らはこれを``探索''と呼んだ）．次に，その最尤先行詞を用いて，名詞句が実際に照応詞であるかどうかを判定する（彼らはこれを``分類''と呼んだ）．このモデルの利点は，照応性を持たない名詞句も学習事例の生成に使えることである．彼らは実験で，最尤先行詞を用いて照応性判定を行ったほうが，最尤先行詞を用いない場合よりも高い性能が出ること確かめた．提案手法も，位置関係ごとに最尤候補を求めた後，どの候補が実際に項であるのかを判定する．最尤候補の探索を先に行なうことで，位置関係ごとの最尤候補を学習事例の生成に用いることができる．2つ目はゼロ照応解析におけるトーナメントモデルである．そのモデルは，全ての先行詞候補（実際には先行する全ての名詞句）のペアに対して，どちらがより先行詞らしいかの2値分類を繰り返す．トーナメントモデルの利点は候補間の関係性の素性を使うことができる点である．提案手法のトーナメントフェーズでも同様に，トーナメントモデルを用いて，位置関係ごとに選出された最尤候補のペアからどちらが正解項らしいかの2値分類を繰り返し，候補間の比較を行うことができる．[p]trainpredicate,gold_argument,candidatesgold_argument_typegetArgumentType(predicate,gold_argument)正解項の位置関係を取得する位置関係ごとに最尤候補を取得するmost_likely_candidate_INTRA_DgetMostLikelyCandidate(predicate,candidates,INTRA_D)most_likely_candidate_INTRA_ZgetMostLikelyCandidate(predicate,candidates,INTRA_Z)most_likely_candidate_INTERgetMostLikelyCandidate(predicate,candidates,INTER)gold_argument_type=NO_ARG	MakeExample(classifier_c,NO_ARG,predicate,most_likely_candidate_INTRA_D)	MakeExample(classifier_c,NO_ARG,predicate,most_likely_candidate_INTRA_Z)	MakeExample(classifier_c,NO_ARG,predicate,most_likely_candidate_INTER)	returnMakeExample(classifier_c,HAVE_ARG,predicate,gold_argument)gold_argument_type=INTRA_D	MakeExample(classifier_a,INTRA_D,predicate,gold_argument,		*88ptmost_likely_candidate_INTRA_Z)	MakeExample(classifier_b,INTRA,predicate,gold_argument,most_likely_candidate_INTER)gold_argument_type=INTRA_Z	MakeExample(classifier_a,INTRA_Z,predicate,gold_argument,		*88ptmost_likely_candidate_INTRA_D)	MakeExample(classifier_b,INTRA,predicate,gold_argument,most_likely_candidate_INTER)gold_argument_type=INTER	MakeExample(classifier_b,INTER,predicate,gold_argument,most_likely_candidate_INTRA_D)	MakeExample(classifier_b,INTER,predicate,gold_argument,most_likely_candidate_INTRA_Z)returnMakeExampleclassifier,label,predicate,candidate1,candidate2candidate2は省略できる項候補candidate1,candidate2が照応関係にあれば事例は作成しない．述語predicateと項候補candidate1,candidate2に対して，	素性集合Fを取得する．学習器classifierに対して，Fを用いて，labelをラベルとする学習事例を1つ作成する．algorithmicalgorithm</subsection>
  <section title="評価実験"/>
  <subsection title="実験データセット">評価実験にはNAISTテキストコーパス1.4を用いた．これは京都大学テキストコーパス3.0を基にしており，述語項構造，事態性名詞の項構造，共参照に関する情報が約40,000文の新聞記事にわたって付与されている．なお，アノテーションの誤りのため6記事を除外した．このコーパスの記事をtbl:corpus-staticsで示すように学習・開発（パラメータチューニング）・評価のために3分割した．これは，Taira:2008:EMNLPやYoshikawa:2013:JNLPと同じ分割方法である．tbl:corpus-arg-distに項の分布の統計情報を示す．</subsection>
  <subsection title="実験設定">実験では，MeCab0.996・IPADIC-2.7.0-20070801で解析して得られた形態素情報，京都大学テキストコーパス3.0で付与されている文節情報，CaboCha0.66で解析して得られた係り受け関係を用いた．項の候補は文節単位で抽出した．解析は文頭から文末の順で行い，述語を含む文以降からは項候補を抽出しない．なお，ある述語の格についての解析結果は同じ述語の他の格についての解析に影響を及ぼさない．本稿では項同定に焦点を絞るため，述語同定タスクには取り組まない．言い換えると，どれが述語であるかはあらかじめシステムに与えておく．述語には軽動詞「する」や複合動詞も含む．最尤候補同定には，トーナメントモデルを用いた．その際，最尤候補の探索範囲ごとに異なるモデルを作成し，モデルの学習方法もに従った．例えば，提案手法は探索フェーズではINTRA_D,INTRA_Z,INTERの最尤候補を同定するが，それぞれ異なる合計3つの解析モデルを最尤候補同定に用いる．</subsection>
  <subsection title="分類器と素性">探索フェーズ・トーナメントフェーズで用いる分類器には，SupportVectorMachineを線形カーネルで用いた．具体的にはLIBLINEAR1.93の実装を用い，開発データを用いたパラメータチューニングを行った．素性にはで用いられたものとほぼ同一の素性を用いた．述語・項候補の主辞・機能語・その他の語の出現形・形態素情報述語が受け身の助動詞を含むときはその原形係り受け木上の述語と項候補の関係係り受け木上の項候補ノードN_aと述語ノードN_pからそれぞれROOT方向に辿っていくときに初めて交叉するノードをN_cとし，N_aからN_cまでの道のりに含むノード列をA_ac，N_pからN_cまでの道のりに含むノード列をA_pcとする．また，N_cから木のROOTまでの道のりに含むノード列をA_c_1,c_2,c_rとする．本実験では，ノード列の文字列表現として，主辞の原形主辞の品詞機能語の原形機能語の品詞機能語の原形+機能語の品詞の5通りを用いた．A_acの文字列表現をS_ac，A_pcの文字列表現をS_pcとし，それらの連結をS_ac+S_pcとする．素性には，S_ac+S_pc，S_ac+S_pc+S_c_1，S_ac+S_pc+S_c_1,c_2，S_ac+S_pc+S_c_1,c_2,,c_rのr+1個の文字列を用いた．つまり．述語と項候補の関係を5(r+1)個の文字列で表現した．係り受け木上の2つの項候補の関係上と同様の素性表現を行った．述語と項候補・2つの項候補間の距離（文節単位・文単位ともに）「述語・項候補の主辞・助詞」のコーパス中の共起スコア動詞と項の共起のモデル化はに従った．名詞nが格助詞cを介して動詞vに係っているときの共起確率P(v,c,n)を推定するため，v,c,nをv,cとnの共起とみなす．共起尺度には自己相互情報量を用いた．[PMI(v,c,n)=P(v,c,n)P(v,c)P(n)]なお，スムージングは行わなかった．自己相互情報量の算出には次の2つのコーパスを用い，2つの値をそれぞれ二値素性として用いた．[0.5]NEWS:1995年を除く1991年から2003年までの毎日新聞約1,800万文．MeCab0.98で形態素解析を行いCaboCha0.60pre4で係り受け解析を行った．辞書はNAISTJapaneseDictionary0.6.3を用いた．約2,700万対の動詞,格助詞,名詞の組を抽出した．[0.5]WEB:Kawahara:2006:LRECがウェブから収集した日本語約5億文．JUMANで形態素解析を行い，KNPで係り受け解析を行なっている．KNPの項構造解析結果から約53億対の述語,格助詞,項の組を抽出した．項候補が以前の項構造解析で項となったか否かを示す2値情報項候補の主辞のSalientReferenceListにおける順位</subsection>
  <subsection title="比較対象">先行研究では，我々のものと異なる素性や機械学習の手法を使っており実験設定が異なる．そのため，ベースラインモデルとしてIIDA2005，比較対象モデルとしてIIDA2007・IIDA2007+・PPR-を実装し，位置関係ごとに最尤候補を求めてから最終的な出力を決める提案モデルPPR(PreferencesbasedonPositionalRelations)と比較する．</subsection>
  <subsubsection title="IIDA2005">位置関係に関わらずに，全ての候補の中から最尤の候補を探索フェーズで1つ選出した後，トーナメントフェーズでそれが項としてふさわしいか否かを判断するモデル．の探索先行分類型モデルである．全ての候補の中から1つを選ぶという点でとほぼ同等のモデルである．彼らのモデルと異なる主な点は，最尤候補同定と照応性判定を異なるモデルで行う点と，最尤候補同定時に2候補間の関係性も素性として用いる点である．このベースラインモデルとその他のモデルと比較することで，項の位置関係によって探索の優先順序をつけることの効果や，位置関係ごとに最尤候補同定モデルを作り最尤候補同士の比較を陽に行う効果を調べる．</subsubsection>
  <subsubsection title="IIDA2007">文内最尤候補を選出した後，分類器が項としてふさわしいと判断すればそれを項として出力し，そうでなければ同様に文間候補の探索を行うモデル．iida-bactで述べたの文内候補を優先的に探索するモデルである．彼らのモデルと異なる主な点は，最尤候補同定や候補の適格性判定を行う分類器にBACTではなくSVMを用いる点である．IIDA2005と比較することで，文内候補を優先的に探索することの効果を調べる．</subsubsection>
  <subsubsection title="比較対象とする先行研究">NAISTテキストコーパスを使い，全ての項の位置関係で実験を行なっているととの比較も行う．ただし，本実験とは微妙に実験設定が異なるため，厳密な比較はできないことに注意してほしい．の実験では19,501個の述語をテストに，49,527個を学習に，11,023個を開発に使っている．また学習では京都大学テキストコーパス4.0で付与されている係り受け情報と形態素情報を用いていているが，テストでは独自の係り受け解析器を用いている．の実験では，25,500個の述語をテストに，67,145個を学習に，13,594個を開発に使っている．我々は京都大学テキストコーパス3.0を用いたが，は京都大学テキストコーパス4.0で付与されている係り受け情報と形態素情報を学習とテストに用いている．</subsubsection>
  <subsubsection title="その他の先行研究">は，提案システムは表層格の解析を行うことから，受け身・使役形である述語は評価から除外しており，本稿では比較対象としない．は，文間項は解析対象としていないため，本稿では比較対象としない．は述語語義と項の意味役割の依存関係を考慮しながら，双方を同時に学習，解析を行う構造予測モデルを提案している．しかし，本稿とは異なるデータセットを用いていることから，比較対象とはしない．</subsubsection>
  <subsection title="評価尺度">Precision,Recall,F値で位置関係ごとに評価を行う．システムが出力した位置関係がTであるもののうち，正しく同定できているものの数をtp_(T)，できていないものの数をfp_(T)，システムに同定されなかった項のうち位置関係がTであるものの数をfn_(T)とすると，[Precision=tp_(T)tp_(T)+fp_(T),=tp_(T)tp_(T)+fn_(T),=2PrecisionRecallPrecision+Recall]と定義できる．また，システム全体(ALL)のtp,fp,fnとPrecision,Recall,F値も，同様に定義できる．</subsection>
  <section title="議論">tbl:result-ga,,にガ格・ヲ格・ニ格の実験結果を示す．P,R,F,A_MはそれぞれPrecision,Recall,F値,F値のマクロ平均（INTRA_D,INTRA_Z,INTERのF値の算術平均）を示す．ALLのF値に関して，PPR-とPPRがIIDA2007と比較して有意差があるかどうかの検定をTakamuraによるスクリプトを用いてApproximateRandomizationTestを行った．0.05水準で有意であったものに，記号^*を付記した．</section>
  <subsection title="決定的に項を同定していくモデルの比較">IIDA2005,IIDA2007,IIDA2007+のALLのF値を比較することで，システム全体の性能について論じる．</subsection>
  <subsubsection title="ガ格の性能">ALLの性能を比較すると，ガ格の性能はIIDA2007&gt;IIDA2005&gt;IIDA2007+である．IIDA2007とIIDA2005の性能を比較すると，PrecisionはIIDA2007の方が高く，RecallはIIDA2005の方が高い．探索範囲を文内に限定することで，Precisionが上がることが分かる．IIDA2007のINTERのRecallは減少しているが，文間項よりも文内項の方が3倍以上多いため，システム全体の性能としては向上することが分かる．IIDA2005とIIDA2007+の性能を比較すると，INTRA_Dを優先的に探索することで，INTRA_DのPrecisionが上昇し，F値も上昇することが分かる．INTRA_ZのPrecisionも上昇するが，Recallは悪化し，INTRA_Zの分量が相当数あるため，全体としては性能が悪化することが分かる．</subsubsection>
  <subsubsection title="ヲ格の性能">ガ格と同様であるが，INTRA_Zの数は比較的少ないためINTRA_Dを優先的に探索しても，精度はガ格ほど悪化しない．</subsubsection>
  <subsubsection title="ニ格の性能">ニ格の性能はガ格・ヲ格とは異なり，IIDA2007+IIDA2007&gt;IIDA2005である．この傾向は項の分布が影響している．ニ格はtbl:corpus-arg-distによると全ての項のうち，全体の90%以上がINTRA_Dである．このため，INTRA_Dの探索を優先し，INTRA_DのRecallを上昇させることで，全体としての性能を上昇させることができる．</subsubsection>
  <subsection title="提案手法の効果">決定的な解析では優先度の低い位置関係にある候補の再現率とF値が低下するため，優先順序をつけるほどマクロ平均は下がっていく．しかし，提案手法は全ての位置関係について最尤候補を比較するので，マクロ平均を大きく下げずにマイクロ平均（ALLのF値）も向上させることができている．PPRとPPR-のいずれも，IIDA2005・IIDA2007・IIDA2007+より性能が向上している．そのため，トーナメントフェーズで最尤候補を陽に比較する提案モデルは，決定的に項を同定していくモデルよりも効果があるといえる．また，PPRはPPR-と比較して，ガ格・ニ格では性能はほとんど変わないが，ヲ格ではINTRA_DのPrecisionが向上したため，全体の性能も向上していることが分かる．そのため，文内項もINTRA_DとINTRA_Zで，最尤候補の同定モデルを分けて陽に比較することで，さらに性能を向上することがあると分かる．</subsection>
  <subsection title="先行研究との比較">ガ格において，提案手法はとの性能を上回っている．は候補同士の比較をせず，は優先順序を用いた決定的な解析を行なっており，それらが，提案手法と比べて性能が低い原因であると考える．ヲ格では，提案手法はの性能を上回っており，とも同程度の性能を達成している．しかしながら，ニ格では，が最も性能が高い．も，ガ格・ヲ格ではを上回る性能を発揮しているのにも関わらず，ニ格ではよりも性能が低い．この理由として，ニ格はINTRA_Dが最も多く，他の格の解析結果に依存することが挙げられる．一般に，1つの述語に対して異なる格で項を共有することはない．しかし，提案手法もも各格で独立に解析を行なっており，他の格の解析結果の利用ができない．一方，は「項を含む文節が述語を含む文節に,他の格の項を介して係っている」という関係をモデル化(ga_c,wo_c,ni_c)し，他の格の解析結果を利用して同時に解析を行なっている．そのため，INTRA_Dの解析性能が高いと考えられる．</subsection>
  <section title="事例分析"/>
  <subsection title="成功事例"/>
  <subsubsection title="特定の位置関係を優先する決定的な解析モデル(IIDA)では解析できず，提案モデル(PPR)で解析できた事例">位置関係の優先順序を用いる決定的な解析モデルの中で，全体的な性能が最も高いIIDA2007と，優先順位を持たない提案モデル(PPR-・PPR)を比較すると，INTERのPrecisionが少し低下しているが，Recallは上昇し，F値も上昇している．ガ格の解析にて，IIDA2007・PPR-・PPRが解析に誤った事例の内訳をtbl:confusion-matrix-gaにConfusionMatrixで示した．PPR-やPPRでは，誤ってINTERを出力した事例が増えており（3列目を参照），一方で，誤って「項なし」と判断した事例が減っていることが分かる（4列目を参照）．IIDA2007は文間の候補を参照せずに，文内最尤候補が項らしいか否かを判定しなければならないが，PPR-やPPRは文内最尤候補と文間最尤候補を比較した上で，項として何が適切かを判断できるため，INTERのRecallを上昇させることができたと考える．そして，これが全体の性能に影響している．</subsubsection>
  <subsection title="誤り分析">項構造解析に失敗した事例を分析したところ，誤り理由の上位3つは次のものであった．1つ目は，談話の理解が必要な場合である．以下の文で，「絡みつく」のニ格は「ユリカモメ」である．しかし，システムはニ格は項なしと判断してしまった．東京・上野の不忍池で、無残な姿の鳥が目立つ。片足が切れたユリカモメ。釣り糸を引っ掛けて取れなくなって、そのうちに足を切断してしまうケースが多い。竹ぐしが右の首に突き刺さったユリカモメ_ニも。くしが十センチほど体の外にのぞく。水面に浮かんだゴム_ガが絡み付き、もがくうちに首まで入ってしまったらしい。error-1「ユリカモメ」が話題の中心であることが捉えられなかったことが解析に失敗した理由として考えられる．今回の実験で，談話を捉えるために，SalientReferenceListを用いたが，「絡み付く」の解析時に「ユリカモメ」はListには無いため，うまくいかない．これを解析するためには，「ユリカモメは負傷している」「絡み付くは負傷に関する述語である」という知識のもとで，「ユリカモメが絡み付くのニ格である」という推論が必要となる．その知識を本文中から取得するには，「鳥」や2回出てくる「ユリカモメ」が照応関係にあるという知識も必要となることから，固有表現解析や共参照解析などと推論を用いた述語項構造解析を同時に行うことで互いに精度を高めあうことができると考える．2つ目は，格フレームなどの情報を使った格の同時解析が必要な場合である．次の文の「書く」のニ格は「日記」・ヲ格は「矛盾」とアノテートされているが，システムはニ格は「項なし」・ヲ格は「日記」と判断した．日記_ニには、小説の読後感や将来への夢、希望などをつづるようになり、高校生になると、大学受験のこと、沖縄における政治の矛盾_ヲなども書くようになった。error-2一般に，「書く」のニ格に「日記」が来ることは少ない．しかし，京都大学格フレームのような格フレーム辞書を用いれば，「書く」は「日記」をニ格にとりうることがわかる．tbl:kaku-caseに京都大学格フレームにおける「書く」の第1格フレームと第3格フレームを示した．この表は，それぞれの格フレームを構成する格がどのような項をどのくらい取るのかを，WEBコーパス内の頻度付きで表している．tbl:kaku-caseより，ヲ格に``補文''（ここでは「沖縄における政治の矛盾」）をとれば，「問い」をニ格にとりうる，とわかる．3つ目は，一般の述語とは異なる扱いをすべき述語の場合である．NAISTテキストコーパスでは名詞述語『名詞句+コピュラ「だ」』も述語としてアノテーションされている．欧州連合_ガが十五カ国に拡大して初の交渉となる。昨年は欧州市場での乗用車の売れ行き回復を受け、規制枠を若干上方修正したが、今年については「昨年の新車登録台数集計を踏まえて対応したい」と慎重姿勢だ。ex-cしかしながら，名詞述語の振る舞いは他の述語とは明らかに異なり，同一の素性・モデルで項を同定するのは難しい．そのため，他の述語の解析モデルと分けるべきであると考える．実際に，PPRを，名詞述語とそれ以外の述語で単純に解析モデルを分けて学習・テストしたところ，tbl:result-copula-gaに示したようにガ格のALLのF値が77.59から77.75と0.16ポイント上昇した．大きな上昇がみられなかったのは，項と名詞述語の意味的関係を既存の素性ではうまく捉えられないためだと考える．名詞述語文の働きは様々で，「ラッセルは哲学者だ」のようにある事物がどのような範疇に属するのかを述べたり，「この部屋の温度は19度だ」のように記述を満たす値がどれなのかを述べたりする．このような関係はsec:featureでの素性では捉えられない．そのため，京都大学名詞格フレームや日本語語彙大系などの名詞間の関係を捉える知識を用いる必要があると考える．また，動詞にも一般動詞とは異なる振る舞いをする動詞「なる」の解析誤りも多かった．山花氏らにとっては、社会党が離脱を認めるかどうか_ガが、最初の関門_ニとなる。error-naru1長さ_ガ_ニにもなる3両編成の大型トラック、ロードトレインに便乗して大乾燥地帯を行く蛭子。error-naru2福井市の中心から足羽川を上流へ十キロたどると、そこ_ガはもうひなびた農村のたたずまい_ニとなる。error-naru3これらの事例の「なる」自体には意味はあまり持たず，ニ格が名詞述語相当の意味を持っているとも言える．そのため，名詞述語同様，解析モデルを分けるべきであると考える．</subsection>
  <section title="おわりに">本稿では，位置関係ごとに最尤候補同定モデルを作成し，実際の解析時には，各位置関係の最尤候補の中から最終的な出力を選ぶモデルを提案した．従来の研究では位置関係ごとに優先順位をつけ，決定的な解析を行ってきたが，それよりも提案手法が精度良く解析できることを確かめた．今後の課題は，複数の格の解析を同時に行う手法と，本手法を統合させることを考えている．これまでに，同時解析を行うモデルはTaira:2008:EMNLPやSasano:IPSJ:2011によって提案されてきたがを文間候補を考慮するように発展させるのは計算量の問題から困難だと考える．，いずれも，特定の位置関係を優先的に決定する手法である．それらの手法を，異なる位置関係の候補を参照するように発展させることを考えている．また，名詞述語などの特殊な述語については，一般の述語とは解析モデルを分けることで，精度向上を目指すことも考えている．これらは名詞間の意味的知識がなければ解析が難しいことが分かったので，日本語語彙大系などのシソーラスを活用することを考えている．</section>
</root>
