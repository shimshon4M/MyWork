<?xml version="1.0" ?>
<root>
  <jtitle>用例利用型による文間接続関係の同定</jtitle>
  <jauthor>山本和英齋藤真実</jauthor>
  <jabstract>文間の接続関係を同定することは談話解析や複数文書要約，質問応答など多くの分野において重要である．本論文では連続する2文に対して文間の接続関係を同定する手法を提案する．提案手法は，入力文から抽出した構文情報や単語情報を用いて，大量のテキストデータの中から入力の連続2文に最も近い2文を検索し，この接続関係によって入力文の文間接続関係を推定する用例利用型(example-based)の手法によって行う．手法は，クラスタリングによって同じ接続関係を持ちやすい単語のクラスタを生成する．この結果生成された単語クラスタを用いて単語の汎化を行い，必ずしも同じ単語が使われていなくとも接続関係の観点から類似した用例をテキスト中から探す．最後に，この用例の接続関係をもって入力文の接続関係とする．以上の手法によって入力文の文体や語の難易度によらない汎用的な同定手法を実現することが可能となった．評価実験では人手による評価で75%</jabstract>
  <jkeywords>接続関係，談話処理，用例利用型,GETA,単語のクラスタリング</jkeywords>
  <section title="">*使用した言語資源およびツール形態素解析器``茶筌'',Ver.~2.3.3,奈良先端科学技術大学院大学松本研究室,://chasen.org/taku/software/ChaSen/構文解析器``南瓜'',Ver.~0.50,奈良先端科学技術大学院大学松本研究室,://chasen.org/taku/software/chabocha/クラスタリングツール``汎用連想計算エンジン(GETA)'',第二版,http://geta.ex.nii.ac.jp青空文庫.http://www.aozora.gr.jp/TinySVM.http://chasen.org/taku/software/TinySVM/BACT.http://chasen.org/taku/software/bact/本研究で採用した6種類の接続関係と各接続関係に属する接続詞を以下に示す．なお，本研究で使用しなかったその他の接続詞も参考として示す．document</section>
  <section title="はじめに">自然言語処理研究は1文を処理対象として数多くの研究が行われてきたが，2文以上を処理対象とする談話処理の研究は依然として多いとは言えない．これは問題が大幅に難しくなることが一因であろう．例えば，構文解析の係り先同定などに見られるように解が文の中にある場合の選択肢は比較的少数であるが，照応・省略解析などのような問題となると解候補や考慮すべき情報が多大となるため正解を得るのは容易ではない．この結果，多くの報告が示すように概ねどのような談話処理の問題であっても十分な精度が得られることは比較的少ない．しかし，これによって談話処理の重要性は何ら変化することはなく，我々は継続的に取り組んでいかなければならない．本論文では，談話処理のうち文間の接続関係を同定する問題に取り組んだ．文間の接続関係同定は，文生成に関係する様々な応用処理，例えば対話処理，複数文書要約，質問応答などにおいて重要となる．例えば，人間の質問に対話的に答えるシステムを考えた場合，対話をスムーズに行うために，システムは伝えるべき情報を自然な発話になるように繋げなければならない．その際に，文間に適切な接続詞を補う必要が出てくる．また，文書要約では文章中から重要な文を選んで列挙する重要文抽出手法が依然として多く行われているが，飛び飛びになっている文が選ばれた際に接続詞を適切に修正（削除，追加，変更）する必要が出てくる．本研究では以下のように問題設定した．まず，入力は接続詞を持つ文とその前文の連続2文として，この接続詞を与えない場合にどの程度同定できるかというタスクとして問題設定した．タスクの入力を連続2文とすることの妥当性については3節で議論する．次に，同定するのは実在した接続詞そのものではなく，接続関係とした．最終的な文生成を考えると接続詞を選ぶことが最終的な目的となるが，例えば「しかし」と「けれども」のどちらかにするかを使い分けることが本研究の目的ではない．また，多くの場合は接続関係が同じであればその接続関係にある接続詞のどれを選んでも構わないと推察されることからこのようなタスク設定とした．我々の設定した接続関係については2節で議論する．ここで関連研究を概観する．日本語接続詞を利用した要約や文書分類の研究，あるいは接続詞そのものの分析の研究は多数あるが本論文の対象ではないので省略する．接続詞決定に関して，例えば高橋らが考察を行っているが(高橋他1987)，この入力は「文章の意味構造」であり，すなわち接続関係が与えられて接続詞を決める問題であるため本研究とは比較できない．一方，飯田らは気象情報文を生成する過程で「接続詞」を自動同定する処理を行っている(飯田・相川2005)が，順接と逆接のどちらになるかを選択するタスクであり，これ以外の関係を全く想定していない．また，入力は時間，天気，気温，風力などの気象データであり，全く異なるタスクと考えてよい．以上のように，日本語で言語表現を入力として接続詞，もしくは接続関係を同定する研究は我々の知る限り存在しない．Marcuは大規模なテキストデータによる学習からNa&quot;veBayes分類器を用いてセグメント間の接続関係を同定する手法を提案している(Marcuetal.2002)．Marcuは接続関係をCONTRAST（逆接），CAUSE-EXPLANATION-EVIDENCE（因果，並列），CONDITION（条件），ELABORATION（累加）の4種類に限定し，さらに同じテキストから取り出した関係を持たない2つのセグメントと異なるテキストから取り出した関係を持たないセグメントを加えた6種類の接続関係を用いてそのうちの2つの関係間での2値分類を行っている．そこでは2つのセグメントからそれぞれ取り出した単語対を素性とし，大量のコーパスから取り出した単語対の情報がシステムに良い影響を与えていることを示している．さらに，コーパスの量が同じなら単語対に用いる品詞を限定した方が精度が良くなることも述べている．一方，Hutchinsonは機械学習により極性(polarity)，真実性(veridicality)，接続関係の種類(type)の3つの側面から接続関係を分類し，接続関係の分類構造の分析を行っている(Hutchinson2004b)．SporlederはMarcuの研究を受けて，単語の表層形だけでなく，対象とする文のドキュメント内での出現位置や文の長さ，単語のbigram，品詞，テンス・アスペクトなどを素性として用いて，機械学習器BoosTexterによる同定を行っている(Sporlederetal.2005)．ここで，SporlederはMarcuとは異なる5種類の接続関係を対象としている．本論文では大量のWeb文書を用いて，与えられた2文に最も近い用例を探すことで2文間の接続関係を推定する手法を提案する．すなわち，大量のWebテキストを用例として利用することで，接続関係を推定するための規則を作ることなく接続関係を同定する．これは，用例利用型(example-based)の手法と呼ばれ，主に機械翻訳の分野で手法の有効性が確認されている．本研究では，これを談話処理の問題に適用し，手法の有効性を検証する．</section>
  <section title="接続関係の分類">本論文で用いた接続関係について述べる．接続関係の種類に関しては多くの研究者が個々の案を提示している(市川1978;Wolfetal.2005)．例えば，古くから知られているMannandThompsonのRST(RhetoricalStructureTheory)(Lochbaumetal.2000)においてはnucleusとsatelliteの関係として21種類を定義している．日本語では，市川が文の接続関係を，「順接」，「逆接」，「添加」，「対比」，「転換」，「同列」，「補足」，「連鎖」の8つの類型に分類している．我々は，形態素解析器「茶筌」^(1)の辞書(IPADIC,Ver.~2.7.0)に登録されている167個の接続詞を，概ね市川の類型によって分類を試みた．ただし以下の理由から若干の変更を行い，最終的に表1のように分類した．また完全な表を付録に示す．「同列」と「補足」，「逆接」と「対比」を区別するのは容易ではなかったため一緒にした「例示」は市川の類型にはないが，文自体に特徴があったため，別に分類したほうがよいと考えた「連鎖」は市川の分類で定義だけはあるものの，具体的には触れられていないため分類として削除したこの結果，市川の分類における「順接」は概ね「累加」または「因果」に該当する．同様に市川の分類における「添加」も「累加」または「因果」に，「対比」は「並列」（一部「逆接」）に，「同列」は「並列」に，「補足」は「累加」に該当する．この他「なかんずく」，「わけても」など，以下の6分類のどれにも属さない「その他」の分類も存在するが，非常にまれであるためここではこれらは扱わない．表1では，接続関係の分類と共に，本研究で使用したコーパス中での出現割合も示す．コーパスは，接続詞でつながった2文を1事例として，我々がWeb文書から約120万事例を収集した．HutchinsonはWebから自動的に接続詞を含む文を抽出する方法を提案している(Hutchinson2004a)が，ここでは使用したコーパスからIPADICによる接続詞でつながっている2文の組を自動的に抽出した．ところで，接続詞によっては一意に接続関係を決められないものもある．例1，例2の接続詞「したがって」はそれぞれ，「なので」と同様な因果関係，「つまり」と同様な並列関係にそれぞれ分類可能である．本論文では，複数の接続関係に分類される接続詞は取り得る全接続関係の中に分類しているが，テストセットではこれらは除外した．なお，このように多義性により除外された接続詞は167種類のうち1割程度である．=1=4zwto3zw例1)理系の人間だって科学のごく一部しか勉強できない。したがって、文系の人がたくさんの理系の授業を受ける必要はない。=1=4zwto3zw例2)高気圧におおわれた地域は、天気がよくなります。したがって、雨が降らないのです。</section>
  <section title="人手による接続関係の推定">人間は接続関係をどのように判断しているのか，人間は接続関係の同定をどの程度の精度で行うことができるか，などを検証することを目的に被験者実験を行った．本節ではこの実験について報告する．青空文庫^(4)から旧字体のものを除き，ランダムに選んだ23テキストを3人の被験者(A,B,C)に与え，文頭に接続詞をもつ文を対象に300個の接続部分を空欄として穴埋め形式で適当な接続関係を選んでもらった．被験者には前節で述べた接続関係と，各接続関係に属するいくつかの代表的な接続詞を提示した．テキストの長さにはかなりばらつきがあり，短いテキストでは1テキスト中に穴埋め箇所は2箇所，長いテキストでは43箇所あるものもある．被験者が選ぶ接続関係は指定した6種類のうちいくつ選んでもかまわないが，複数選択する場合には優先順位をつけるよう指示した．実験は，同一の問題に対してテキスト全体を与えた場合と穴埋め箇所の前後1文ずつを取り出した2文だけを与えた場合の2通り行った．最初にテキスト全体での推定をしてもらい，その3日後に2文だけを用いた場合の実験を行った．2文だけを用いた実験では，テキスト全体での出力結果を被験者が思い出さないように全てのテキストから取り出した2文の組を無作為に並べ替えて提示した．</section>
  <subsection title="正解率の比較と一致率">各被験者の，テキスト全体を見て判断した場合（全文）と2文の情報のみで判断した場合（2文）での正解率と2種類の出力の一致率を表2に示す．被験者には優先順位をつけて複数選択してもらっているので，それを考慮するため，質問応答でよく使われているMRR(MeanReciprocalRank)の評価手法を応用して正解率を求めた．具体的にはN番目の出力が正解した場合に1/Nのポイントを与え，その合計を全問題数300で割った値を正解率としている．表2から3件の考察を行う．まず，正解率を見ると全文，2文のどちらの場合も5割〜6割程度である．これは，人間にとっても接続関係を同定することが容易ではないか，もしくは正解が一意ではなく複数の解釈，若干の自由度があるかのどちらか，もしくは両方を示している．いずれにしても，実際に記述された正解との単純比較だけでは人間との感覚にずれがあり，注意が必要である．次に，直感ではテキスト全体を見たときの方が2文だけを見て判断するより精度が良くなる，と誰しもが考えるであろう．しかし，表2が示すように，人間が接続関係を推定する際は両者の正解率にあまり差はない．これについては3.3節でさらに議論する．最後に，テキスト全体を見て判断した場合の人間の出力と2文のみで判断した場合の出力の一致率は共に約6割と高くない．つまり，正解率は変わらないが正解している問題は少なからず異なっている．このことから，テキスト全体を見た方が正しく判断できるものと逆に情報を2文に限定したほうがよい場合がそれぞれ存在することを示唆している．</subsection>
  <subsection title="接続関係ごとの正解率">テキスト全体を見た場合と2文だけを見た場合の正解率の異なりを接続関係ごとに分析し，接続関係の持つ特徴を考える．図1，図2にそれぞれ3人の被験者の平均による接続関係毎の正解率と適合率を示す．図1，図2より「転換」においては2文だけで判断するよりテキスト全体を見たほうが正解率と適合率が高い．特に「転換」という接続関係は話題の移り変わりを表すので，直前の1文だけでは判断できないと考えられる．また，「加反」や「例示」はテキスト全体でも2文でもほとんど差がなく，しかも他の接続関係に比べて正解率，適合率共に高い．このことから，「加反」や「例示」は直前の文とのつながりを表しやすいといえる．</subsection>
  <subsection title="テキストと2文の出力の一致度と正解の関係">テキスト全体を見て選んだ接続関係と2文だけを見て選んだ接続関係が一致した問題数と，そのときの正解率から考察を行う．ここでは，簡単のため優先順位の最も高い接続関係を被験者の唯一の出力としている．表3は各被験者の出力結果の内訳である．表中の○，×はそれぞれ正解，不正解を示している．この表から，全文を見なければ正解が出来ない項目b(122)は全体(900)の13.5%であることが分かる．この結果から，全文入力することと比較して入力文を2文に制限することで条件が極端に不利になることはないと考え，本論文の入力を連続する2文とした．表4は2文だけ見たときには誤っているがテキスト全体を見た場合では正解している問題と，逆にテキスト全体では誤っているが2文だけで判断したときには正解している問題の接続関係ごとの割合を示している．表4より，テキスト全体を見た場合に正解した問題と2文だけを見た場合に正解した問題に多少の偏りは見られる．しかし，この結果からは接続関係によってテキスト全体を見た方が正しく判断できるものと情報を2文に限定した方がよいものに分けることはできない．今回のようなタスクで長いテキストから接続関係を判断するとき，まず人は2文だけを見て決めようとする．そこでうまく接続関係が決められない場合には見る範囲を広げていく．しかし全文が見れる以上，2文だけで判断可能な場合でも人は他の文章の影響を受けずにはいられない．そのため，もし2文だけで接続関係を判断するための情報が十分含まれているとしたら，テキスト全体を与えることでかえって判断を迷わす結果となっている可能性がある．また，接続関係を決めるための情報が2文では不十分であるときは，人間の判断も自信のないものとなっている可能性が高い．また，表3においてテキスト全体を見た場合と2文だけを見た場合の出力が一致した問題(a,b)中での正解率(a/(a+b))は62〜77%であり，3人の平均では71%であった．表2に示す3人の被験者それぞれの正解率と比較するとおよそ1割強高い．これは，全体の正解率と比べて出力が一致している問題中での正解率の方が高くなるであろうという人間の直感とも一致する．しかし全体の17%の問題(b)については正解とは異なった関係を選んでいるにもかかわらず，テキスト全体を見て判断した接続関係と2文だけで判断した接続関係が一致していることから，人は迷いなくその関係を選んでいると考えられる．出力がどちらも同じであるということは，接続関係を判断するためには2文の情報だけで十分であるといえるのではないか．</subsection>
  <section title="類似用例による接続関係の推定">本節では，入力の2文に対してコーパス中で2文間の接続関係が同一と判断される類似用例文の検索手法の大まかな流れについて述べる．処理の概要を図3に示す．入力文と類似した2文の組を探すといっても，単純に文が似ているものを探せばよいというものではない．例えば「雨が降った。試合は中止になった。（因果）」と「雨が降った。試合は中止にならなかった。（逆接）」は，単語の一致率などを用いた一般的な類似度計算によって非常によく似た2文の組とされるものであるが，それぞれの文間の接続関係はまったく逆である．反対に，「本を読んだ。つまらなかった。（逆接）」と「評判の映画を観た。僕には退屈で眠くなった。（逆接）」では，一致する単語や一般的に類義語や上位語，下位語とされるものが存在しないにもかかわらず，人間が見ると直感的にこの2つの例文は似ている文であり，接続関係も同じであるといえる．本論文ではこのように，入力に対して同じ接続関係を持つと思われる類似用例文を大量のコーパス中から探し，その用例によって接続関係を推定する手法を提案する．以下に大まかな処理の流れを示す．Step1.前処理として，クラスタリング用に別のコーパスを用意し，接続関係を決定すると考えられる主要な単語を，GETA^(3)を用いてクラスタリングする．「本を読んだ。つまらなかった。」と「評判の映画を観た。僕には退屈で眠くなった。」の例では，「本を--映画を」，「読んだ--観た」，「つまらない--眠い」などの単語ごとにクラスタリングされることが理想である．クラスタリングの際，1文目と2文目から抽出する単語は区別される．詳しくは6節で説明する．Step2.入力の2文から動的に構文パタンを生成し，構文的に似ている文を候補として抽出する．パタンの生成，候補文の抽出に関しては5節で詳しく述べる．Step1のクラスタリングの際にも構文パタンを素性として用いるため，本論文では先にこちらを説明する．Step3.抽出した候補文に対して，単語や構文パタンによるスコア付けを行い，スコアの高い順に出力する．用例利用型(example-based)による解法は主に機械翻訳の分野で使用されてきた．例えば，(Sumita1998)で議論されているように，日本語の「AのB」と記述される際の助詞ノには多義性があり，その結果英語などに翻訳する際には多訳性が生じる．これに対して入力表現の「AのB」に最も類似している表現がどのように翻訳されているかを模倣することによって多義性解消を行う（すなわち翻訳結果を得る）というのが用例利用型翻訳の基本的な考え方である．本論文では，上記のAやBが文であり，助詞ノが接続詞であると仮に見做せばちょうど「AのB」の翻訳と同一の考え方ができるのではないかと考え，用例利用型による解法を目指した．用例利用型手法は万能ではない．我々は，用例利用型を有効に機能させるためには二つの重要なポイントがあると考える．すなわち，(a)広範な用例を収集すること(b)適切な類似度を設定することの2点である．(a)はコーパスを利用する他手法と同様であるが，「大量」である必要がない点は統計的手法などと異なる．すなわち用例利用型は用例の類似度を用い，出現頻度を利用しないため，各事例の出現比率は考慮する必要がない．このため，いくら重要事例であっても同一の事例が複数ある必要はなく，用例が広範に収集されていることのみが性能に影響する．(b)は統計的手法における統計量，規則を用いた手法の条件部に相当する処理を類似度によって制御しているため，類似度をどのように定義するかが制御部の核心である．本研究でどのように類似度を設定したかについては7節で議論する．</section>
  <section title="パタンによる候補文の抽出">本研究では入力文に最も類似した文をコーパス中の文に対するスコア付けによって求めるが，コーパス中の全ての文に対してスコア付けをすると計算量が膨大となるため，入力文から生成した構文パタンに一致したコーパス中の文のみを対象とする．これらコーパス中から抽出された文を入力文に対する候補文と呼ぶ．本節では入力文からの構文パタン生成手法および候補文の抽出について説明する．また，この構文パタンは6節で述べる単語のクラスタリングの素性としても使用する．</section>
  <subsection title="構文パタンの生成">例3のように入力の2文が与えられたとき，まず入力の1文目，2文目それぞれから構文パタンを作成する．ここで，入力の各文から生成される構文パタンを基本パタンと呼ぶ．図4は例3の入力に対する構文解析結果である．構文解析器には「南瓜」^(2)を用いた．to3zw例3)1文目：上海の新生活はサンディにとって心地よいものとなるはずだった。to3zw2文目：しかし、最愛の母親の死は彼女に大きな打撃と計り知れない心痛を与えた。</subsection>
  <subsubsection title="パタン要素の抽出">入力の各文から基本パタンを生成するために必要な要素を文節ごとに抽出する．ここで，「未知語」は全て「名詞」として扱い，句点以外の記号はあらかじめ全て削除しておく．以下に各文節からのパタン要素の抽出方法を説明する．パタンを構成する要素を文節単位で抽出する．1文節から生成される要素をパタンの一要素とする．文節内の助詞，助動詞を抽出し，さらに全ての品詞で「非自立」であるものと，動詞の「ある」を無条件にパタン要素として採用する．同じ文節内のものを連結し，パタンの一要素とする．文節末が名詞または動詞の場合は，それぞれ``NOUN''，``VERB''に一般化し，それで一要素とする．また，文節末尾以外の名詞でNE（固有表現）タグがついているものはNEタグに変換する．例3では「上海」は``LOCATION''になる．「AのB」，「A（し）たB」などの「Aの」や「A（し）た」といった連体修飾節はパタンの要素には採用しない．ただし，NEタグの要素を含む場合を除く．例えば，例3の「最愛の」，「母の」はパタンの要素として採用しないが，「上海の」は「LOCATIONの」という形で採用する．文末文節に関しては他の文節とは異なり，複数のパタン要素が生成される．文末文節の末尾から一形態素ずつ付与して複数のパタンの要素を作成する．ここで，抽出対象となるものは助詞，助動詞，感動詞，および全ての品詞で「非自立」であるもの，動詞の「ある」である．ただし，文末の「助詞」または「助動詞」の連続は切り離さない．例3の1文目の文末文節の「なるはずだった。」からは「はずだった。」と「だった。」の2種類のパタン要素が生成され，これらをそれぞれ末尾として構文パタンを生成する．つまり，ここでは助動詞「た。」の要素は作成されない．また，文末の形態素が形容詞ならば，その「形容詞の出現形+『。』」の要素を作成し，文末が名詞および動詞の場合はi)と同じくそれぞれ``NOUN''，``VERB''に一般化して一要素とする．</subsubsection>
  <subsubsection title="基本パタンの生成">このようにして，各文節からパタン要素を取り出し，それぞれの文節から係り先の文節のパタン要素をつなげて構文パタンを作成する．つまり，同じ文節に係っているものどうしは同時にひとつの構文パタンの中には存在しないことになる．文末については要素が複数存在するので，それぞれの要素について構文パタンを作成する．図5に例3の各文節から抽出したパタン要素と文節ごとの係り受けを，図6には例3の1文目，2文目から生成した全ての基本パタンを示す．また，``＊''は任意の文字列を意味している．各基本パタンにはそのときのパタンの要素数が付与される．文末文節以外の文節からは1文節から抽出された要素に対して一要素とし，文末文節から抽出された要素に対しては，一形態素で一要素として計算している．ただし，句点はカウントしない．例えば，例3の1文目の基本パタン「＊は＊ものと＊はずだった。」では，文末文節以外の文節から抽出された要素が「＊は」，「＊ものと」の2つであり，文末文節から抽出された要素「＊はずだった。」は句点を除いて三形態素からなるので，この基本パタンの要素数は5となる．</subsubsection>
  <subsubsection title="基本パタンの組み合わせによる構文パタンの生成">生成した1文目と2文目の基本パタンのすべての組み合わせを，入力に対する構文パタンとする．各構文パタンの要素数は組み合わせた基本パタンの要素数の合計となる．例えば，図6から1文目の基本パタン「LOCATIONの＊は＊ものと＊はずだった。」と2文目の基本パタン「＊に＊ない＊を＊た。」を組み合わせて，要素数10(6+4)の構文パタン「LOCATIONの＊は＊ものと＊はずだった。＊に＊ない＊を＊た。」ができる．図6では，1文目と2文目からの基本パタンがそれぞれ9パタンと6パタンであるため，最終的に全ての組み合わせで54個の構文パタンが生成されることになる．</subsubsection>
  <subsection title="候補文の抽出">5.1.3節で生成したパタンに適合する2文の組をコーパスから探す．ここで，パタンに適合したコーパス中の2文の組を候補文と呼ぶ．入力に対して最も類似した文はこの候補文の中から探す．パタンの照合に使用したコーパスはWeb文書から抽出した約120万事例である．生成したパタンを要素数の多いものから順に同じ要素数のパタンを一組として照合させる．ここでは120万事例から入力に最も近い1文を探すための絞込みをすることが目的であるので，ある程度の閾値で候補を絞る必要がある．しかしここで絞りすぎるのも問題である．ここでは実験的に，抽出された候補文が100セットを超えたときパタンの照合を終了するとした．つまり，例えば例3の入力文から得られるパタンのうち最も多い要素数をもつパタンは「LOCATIONの＊は＊ものと＊はずだった。＊に＊ない＊を＊た。」と「LOCATIONの＊は＊ものと＊はずだった。＊と＊ない＊を＊た。」である．これらを使って抽出してきた候補文の累計が100に満たない場合，さらに次の要素数9のパタン群（「LOCATIONの＊は＊ものと＊だった。＊に＊ない＊を＊た。」，「＊にとって＊ものと＊はずだった。＊に＊ない＊を＊た。」，…）を用いて候補文を増やす．ここで，抽出した候補文に対して7節の単語によるスコア付けによって入力に最も近い文を探す．</subsection>
  <section title="単語のクラスタリング">本節では，単語のクラスタリングについて説明する．本節で生成した単語のクラスタは入力文と候補文との類似度を測る際に使用する．なお，本研究ではクラスタリングのためのツールとしてGETA^(3)を用いた．GETAは大規模で疎な行列の行間あるいは列間の類似度を高速計算する類似度計算ツールであり，クラスタリングライブラリが提供されているように，クラスタリングとして利用することが可能である．</section>
  <subsection title="クラスタリングに用いた素性">1文目，および2文目の述語と，1文目，2文目それぞれの述語に係る格要素のそれぞれについて接続関係が同じ文で用いられやすい単語のクラスタを作成する．すなわち，ここでは4種類のクラスタリングを行うことになる．単語のクラスタリングではGETAの処理時間との兼ね合いもあり，データセット1万セットで分類を行った．クラスタと単語は一対一ではなく，ある単語が複数のクラスタに属す場合も存在する．183pt例4)15-3ia2-4.epsminipage165pt例5)15-3ia2-5.epsminipage本節で述べる述語とは，茶筌の品詞体系で「動詞」（基本形が「する」，「ある」，「なる」，「せる」，「れる」，「られる」であるものを除く）と「名詞--サ変」および「形容詞」となるもので，文末文節中で最も文末に近いものをいう．ここで，品詞が動詞，及び形容詞であるものは全て基本形にしている．また，品詞が「動詞」で，基本形が「する」，「ある」，「なる」，「せる」，「れる」，「られる」となるもののみが文末文節にある場合はその係り元文節内で同様にして探す．すなわち，例4では「読む」が述語となり，例5では「勉強」が述語となる．ここで，サ変名詞に他の名詞が後続する場合，例えば「勉強方法にある」のような場合も「勉強」を述語とした．述語に係る格要素とは，i)で抽出した述語を含む文節に係る格文節で，文節末が「名詞＋助詞」となるもの全てを指す．さらに名詞が連続している場合は末尾の名詞のみを使用する．「名詞＋の」は格要素として使用していない．また，述語が抽出されなかった場合は文末文節に係る格要素をここでいう述語に係る格要素として使用している．例4では述語「読む」に係る「本＋を」が格要素となる．例5では「勉強」に係る文節が「数学の」のみであるが，これは「名詞＋の」の形であるため採用されない．よって，この例からは格要素は抽出されない．以下では，例えば，1文目の述語をクラスタリングする場合，1文目をtarget,2文目をsourceと呼ぶことにする．2文目の述語をクラスタリングする場合は2文目がtarget,1文目がsourceとなる．述語に係る格要素のクラスタリング素性に関しても同様である．また，今回「述語が無い」または「格要素が無い」という情報は，クラスタリングの素性としては与えていない．本研究では，対象を述語とそれに係る格要素に限定した．これ以外の要素，例えば修飾語などの語句が接続関係の決定に影響する可能性は完全には否定できないが，我々はこれらを考慮することによる利得よりも素性数が増加して統計的な有意性を生じない損失のほうが大きいと考え，クラスタリングの対象素性からは除外した．表5，表6に述語と述語に係る格要素のクラスタリングに用いた素性と重みを示す．これらを素性として，GETAでは文書分類や単語シソーラスの自動構築に用いられている階層的ベイズクラスタリング(Iwayamaetal.1995)での分類を行っている．階層的クラスタリングとは，多次元のデータセットに対して，要素間の類似度に基づいて比較的「近い」要素群をクラスタとして発見する分析手法の1つである．GETAでは各アイテム（ここでは述語および格要素）の中で最も「近い」ものから順にボトムアップで各アイテムをまとめあげていく．一般的な木構造とは違い，同じ階層は存在せず，指定したクラスタ数になるように分割点を決定する（図7）．</subsection>
  <subsection title="クラスタ数の決定">クラスタリングを行う際，クラスタ数をどのように設定すればよいか．本論文ではクラスタ中のエントロピーを用いて自動的にクラスタ数を決定する．あるデータDのエントロピーは次式で求められる．ここで，P_iはデータ中の接続関係iの割合を示す．また，分割後のエントロピーは各クラスタ中のエントロピーの加重平均で表される．例えばクラスタ数2の場合，分割前のデータをD_0，分割後のデータをそれぞれD_1,D_2とし，データD_iのデータの個数を|D_i|，エントロピーをH(D_i)とすると分割後のエントロピーH(D_1+D_2)は以下の式で求められる．さらに，次の条件のいずれかを満たす場合にはクラスタリングを行わないとした．［条件1］任意の単語Aがすべてのクラスに属す場合［条件2］1種類の単語だけで構成されているクラスが存在する場合本論文では，単語のクラスタを単語の汎化の目的で使用するため，1種類の単語しか存在しないクラスタは汎化の意味をもたないと考え2番目の条件を加えた．したがって，1つのクラスタに複数の単語が存在するという条件の下でエントロピーの小さいクラスタを生成する．1文目の述語(V_1),2文目の述語(V_2),1文目の述語に係る格要素(N_1),2文目の述語に係る格要素(N_2)の4種類のクラスタリングについて，それぞれ指定したクラスタ数と分割後のエントロピーの関係を図8に示す．1種類の単語しか持たないクラスタが出現した時点で分割を停止している（条件2）．そのため実験では，図8に示す範囲で最も小さいエントロピーを持つクラスタ数を利用している．表7に各分類器で設定したクラスタ数を示す．例えば，コーパスから抽出してきた1文目の述語1万単語をGETAでクラスタリングする際のクラスタ数は711である．</subsection>
  <section title="候補文のスコア付け">本章では，5節で抽出してきたコーパス中に存在する候補文に対してスコア付けを行い，入力文に最も類似した候補文を探す．</section>
  <subsection title="構文パタンによるスコア">5.2節の構文パタンによる候補文の抽出では要素数の多いパタン順に照合を行った．しかし，要素数はパタン生成に使用した文節数，および形態素数であるため，単に要素が多いというだけでは特徴的なパタンであるとはいえない．そこで，入力文iから生成した候補文cをコーパスから抽出する際に使用したパタンPT(i,c)が特徴的なパタンであるかどうかを表す尺度として，パタンPT(i,c)の尤もらしさをパタンPT(i,c)がコーパス中で一致した2文の組（候補文）の数の逆数で表す．つまり，例えば構文パタンAに一致して抽出された候補文がa,b,cの3セットだったとする．このとき，パタンAの尤もらしさは1/3となる．さらに，このときの構文パタンの尤もらしさを，その構文パタンによって得られた候補文cのパタンスコアS_PT(i,c)とする．すなわち候補文a,b,cのパタンスコアは全て1/3となる．また，構文パタンAに一致する候補文は，構文パタンAから一要素だけ減らした構文パタンBにも一致する．つまり，コーパス中の2文の組Xが構文パタン「＊は＊ものと＊はずだった。＊は＊た。」に一致するならば，Xは構文パタン「＊は＊ものと＊だった。＊は＊た。」にも一致する．しかし，照合の際に使用した構文パタンが違うため，これらは区別して扱う．すなわち，候補文aについて，構文パタンAによって得られたa:A（候補文：使用した構文パタン）と構文パタンBによって得られたa:Bは別物であり，それぞれの構文パタンがコーパス中で一致した2文の組数によってパタンスコアは異なる．</subsection>
  <subsection title="単語スコア">はじめに，5.1節と同様にして入力文から1文目，および2文目の述語(V_1i,V_2i)と，1文目，2文目それぞれの述語に係る格要素(N_1i,N_2i)を抽出する．候補文からも同様に取り出し(V_1c,V_2c,N_1c,N_2c),4種類の単語に対してそれぞれ単語スコアを計算する．入力文iが与えられたときの，1文目の述語による候補文cのスコアと，2文目の述語による候補文cのスコアをそれぞれS_V1(i,c)，S_V2(i,c)とする．S_V1(i,c)の初期値を0.001とし，図9の条件に従ってそれぞれのスコアを加算する．S_V2(i,c)も同様に計算する．入力文iが与えられたときの，1文目の述語に係る格要素による候補文cのスコアと，2文目の述語に係る格要素による候補文cのスコアをそれぞれS_N1(i,c)，S_N2(i,c)とする．また，述語に係る格要素は全て「A（名詞）+B（助詞）」の形になっているが，「助詞」を一般化して「A（名詞）+助詞」にしたものをN'_1,N'_2としている．この場合，参照するクラスタは「助詞」を一般化する前のものと同一のものを使用し，クラスタを参照する際に全ての「助詞」を対象としている．S_N1(i,c)の初期値を0.001とし，図10の条件に従ってそれぞれのスコアを加算する．S_N2(i,c)も同様に計算する．</subsection>
  <subsection title="候補文に対するスコア計算">7.1節と7.2節で求めたパタンスコアと単語スコアを用いて(4)の計算式により候補文cの入力文に対する類似度を計算した．1文目の述語が入力文の1文目の述語と同一もしくは類似であったとしても，2文目の述語がまったく異なるものでは入力文と候補文が類似であるとはいえないため，S_V1(i,c)とS_V2(i,c)を掛け合わせている．また，述語が同一もしくは類似であるときに格要素の類似性が重要になってくるため，1文目と2文目でそれぞれ述語と格要素のスコアを掛け合わせている．式(4)はパタンスコアとそれらを全て掛け合わせたものである．式(4)を簡略化したものを式(5)に示す．この類似度が最も高い候補文の接続関係を入力の2文間の接続関係として出力する．</subsection>
  <section title="評価実験及び考察"/>
  <subsection title="データセット">本実験で，入力文に対して類似した2文の組を探すために使用したコーパスは我々が収集した120万事例のWebコーパスである．記号等を多用したWeb独特の文は収集の対象外としてあらかじめコーパスを作成する際に除外しているが，文法的に不自然なもの等の判断はしていない．接続関係ごとの120万事例中の割合は表1に示した通りである．Web文書を入力としたテストでは，入力としてWeb文書から接続詞でつながった2文を6種類の接続関係に対して50セットずつ無作為に抽出した．これらをシステムの入力とするが，形態素解析の誤り等により入力文から構文パタンが生成されず，候補文がひとつも得られないものが19セット（累加:2，逆接:3，転換:8，例示:6）あったため，これらを除いた合計281問に対して実験を行った．実験では2文目の文頭の接続詞を除いた形で2文を入力としている．ここで，正解は元の接続詞が属す接続関係としている．本論文では複数の接続関係に属す接続詞も対象としているが，それらはテストセットには含んでいない．</subsection>
  <subsection title="Web文書からの入力に対する評価">Web文書を入力としたときの評価結果を表8に示す．類似度の計算で，パタンスコアS_PT(i,c)を用いず，単語スコアによる計算のみで類似度を計算した場合と，式(5)によって求めた場合（単語スコア×パタンスコア）の二通りについて評価実験を行った．単語スコアのみの評価で，どの候補文に対しても単語によって各単語スコアに値が加算されず差が出ない場合，これを不正解として集計した場合を「単語スコア(1)」，コーパス中で最も頻度の高い「累加」を答えとして集計した場合を「単語スコア(2)」の2種類の集計を行った．ここでは接続関係ごとの正解率の異なりも観察できるようにと考え，各接続関係で同等の量のテストセットを用意した．しかし各接続関係の実際の出現頻度には偏りがある．そのため，各接続関係の出現頻度を考慮した場合でも正解率を求めた（合計（頻度を考慮）欄）．また，ベースラインとして，使用したコーパス（120万事例）中で最も多く出現した「累加」とすべて回答した場合とした（ベースライン欄）．実験の結果，同スコアで一位となる候補文が複数出力される場合が多く存在した．この場合の対応としては，得られた複数の候補文のもつ接続関係の中で最も多いものを出力とすることも考えられる．しかし提案手法が出現割合を考慮することは本論文での趣旨とは異なるため，本実験では最も高い類似度を持つ2文から得られる接続関係を全て出力として，出力された接続関係の種類数に対する正解の割合をその入力に対する正解ポイントとし，合計を問題数で割ったものを正解率とした．つまり，例えばある入力に対して最も高い類似度を持つコーパス中の2文の組が4セット得られたとする．それぞれの2文間の接続関係が「因果」，「累加」，「因果」，「逆接」であるならば，システムは「因果」，「累加」，「逆接」の3つを出力する．正解が「因果」であった場合，この入力に対する正解ポイントは1/3となる．正解率はこれらの合計を問題文の総数で割って求める．表8より，単語スコアのみを用いて類似度を計算した場合と単語スコアとパタンスコアの両方を用いて類似度を計算した場合の両者で，ベースラインよりも高い正解率が得られた．また，両者を比較すると，単語スコアとパタンスコアの両方を用いた場合の方がわずかに合計での正解率が高くなっているが，出現頻度を考慮した場合，単語スコアのみの計算で出力が得られなかった場合は全て「累加」を出力するとしたシステムの方が正解率は良くなる．このことから，入力文と候補文の類似度の計算ではパタンスコアにはあまり効果がないといえる．次に，出力が得られた問題に対して出力結果の中に正解が含まれている問題の割合を表9に示す．単語スコアのみで行った実験では，単語によるスコアの加算がどの候補文に対してもされなかった場合，つまり候補文のスコアが全て初期値のままで差がない場合は``出力無し''としてここでは除いている．表9より，類似度の計算によってシステムが出した接続関係の中に正解とする接続関係が存在する割合はおよそ6割であった．単語スコアのみの場合で出力数の平均は1.53であり，それから考えると比較的高い割合を示しているといえる．また，本研究においては文間の接続関係そのものの曖昧性が大きいため，正解を何とするかが問題となる．残りの4割の問題では正解とは異なる接続関係を持つ文が選ばれたことになるが，人間が見たときに正解と判断できるものも含んでいると考える．システムの評価基準のひとつとしてここでは「2文をつなぐ元の文章中の接続詞が属す接続関係」を正解としたが，本システムの応用分野によっても正解の幅は異なる．しかし，一般的に人間が見て適切であると判断できる範囲であれば実用に耐え得ると考える．人手による評価については8.5節で議論する．また，単語のスコアのみの計算で出力が得られなかった問題は281問中41問(14.6%)あり，そのうち入力の2文から単語要素がひとつも抽出されなかったものは23問であった．パタンスコアが類似文検索にあまり効果がみられないことからも，あらゆる候補文に対して何かしらの単語によるスコア付けが必要となる．今回述語とそれに係る格要素のみに限定することで，その文でのメインの話題どうしの接続関係を正確に把握できるのではないかと考えた．しかし本手法での単語の抽出方法では，1文目の述語(V_1),2文目の述語(V_2),1文目の述語に係る格要素(N_1),2文目の述語に係る格要素(N_2)の4種類全てが取り出せる2文の組は1割程度しか存在していなかった．もちろん，常に文間の接続関係がその全ての要素で決まるわけではなく，あるひとつの単語によって関係が定義される場合もある．だが，抽出する単語を限定していることで必要な情報が取れていない場合も多く存在する．今回指定した，述語とそれに係る格要素だけでは万全ではないといえる．かといって入力文が与えられたときにどの単語に注目すべきなのかを自動的に判断するのは容易ではない．述語とそれに係る格要素以外の部分に関しては，係り受けや品詞による限定だけでは文によって必要とされるものが異なる場合に対処できない．しかし，無条件に文中の単語を対象としては悪影響が大きくなると予想される．今後これをどう対応するかは重要な課題である．</subsection>
  <subsection title="機械学習手法との比較">表8で本手法の精度が47.9%（出現頻度を考慮しない場合の平均）であることを示した．この値はベースラインの精度17.1%よりも良好なことは明白であるが，機械学習手法よりも本当に優位なのか．その結果を示したのが表10である．今回の比較では一般的な機械学習手法であるサポートベクターマシン(SVM)^(5)と，BACT(aBoostingAlgorithmforClassificationofTrees)^(6)を使用した．BACTは文構造を明示的に利用した分類器であり，部分木を素性としてブースティングを利用している．SVM,BACT共にデフォルトの設定のまま実験を行った．精度測定に使用した入力文は8.2節で行った実験と全く同一である．SVMは，ある接続関係とそれ以外の接続関係をそれぞれ正例，負例として学習した．正例と負例は同量にして，各10,000文で学習した．素性としては機能語も含む全ての単語集合(bag-of-words)を用いたが，接続詞のみ除外した．BACTについては，単語を要素とする木構造（実際にはリスト構造）を入力として与えた．両分類器共に，各接続関係ごとに2値分類器を作成するため複数の分類器において正例と判定され，結果として出力する接続関係が単独とならないことがある．その場合は，複数解の出力と考え，8.2節で述べたのと同一の方法で精度計算した．表10から，SVMやBACTは共にベースラインよりも良好な結果を示してはいるが，提案手法よりも明らかに精度が低いことが分かる．</subsection>
  <subsection title="エントロピー減少量と正解率の関係">6.2節で各分類器のクラスタ数を「一種類の単語のみで構成されるクラスタが生じない範囲で最も小さいエントロピーを持つクラスタ数」として設定し，そのクラスタ数で単語をクラスタリングした結果を，単語スコアを求める際に使用している．ここでは，式(1)により求めたエントロピーが小さいクラスタには同じ接続関係になりやすい文中の単語が偏っているという考えに基づいている．しかし，本当に式(1)によるエントロピーが小さくなるようにクラスタを生成することで正解率は向上するのだろうか．本論文で用いたデータでは分割前のエントロピーは1.9〜2.0程度であった．また図8をみると，分割前のエントロピーに対して分割後のエントロピーは1.2〜1.4程度であり，元のエントロピーの半分にもなっていない．そこで，6.2節で生成した各単語のクラスタで閾値以上のエントロピーを持つクラスタを削除し，残りの閾値より小さいエントロピーを持つクラスタのみを使用した場合で実験を行った．表11には1文目の述語(V_1),2文目の述語(V_2),1文目の述語に係る格要素(N_1),2文目の述語に係る格要素(N_2)のそれぞれのクラスタにおいて，各条件に合ったクラスタの数を示している．表11の``&lt;X''は6.2節で設定したクラスタ数でクラスタリングした結果生成されたクラスタで，Xより小さいエントロピーを持つクラスタを意味する．また，式(1)によれば，単純に文間の接続詞が同じものでクラスタを生成した場合，生成されたクラスタはどれもエントロピーが0となり，エントロピー減少量はH(D_0)となる．このクラスタを用いたときの結果を``=0.0(Conj)''の欄に示す．また，図11はそれぞれの条件を満たすクラスタのみを使用して実験を行ったときの結果を示している．テストセットは8.2節で使用したWeb文書からのテストセットと同じである．表11，図11より，閾値を高くしていき，エントロピーの小さいクラスタだけを用いて類似度の計算を行った方が出力される問題数は減るが，その中での正解率は高くなっていくことがわかる．このことから式(1)によるエントロピーが小さいクラスタを数多く生成することができればシステムの向上が見込めるということがいえる．今回はクラスタリングツールGETAの処理速度の関係で，V_1,V_2,N_1,N_2それぞれのクラスタリングにおいて1万単語ずつしか分類できなかった．そのため，例えば最もスコアの高い候補文（システムの出力）が1文目の述語が一致している（1文目の述語によるスコアには1が加算される）だけで他の単語は入力文中の単語とは関係のないものであったとする．このとき，他の候補文でより入力文に類似したものがあったとしても，各クラスタ内に入力文とその候補文中の単語が存在しなければスコアは加算されない．本論文ではGETAによる単語の汎化を行ったが，1万単語では不十分であり，やはり過疎性の問題が存在していたといえる．出力結果を観察すると，このような例は少なくなかった．閾値を設けた場合のクラスタではそこからさらに単語数は削られている．そのため，システムが答えを出力できた問題の数は当然減少するが，システムが答えを出力した問題の中でもこの単語数の少なさが誤りの要因として含まれていると考える．クラスタ数の減少量から単純に計算して，エントロピーが0のもののみを使用した場合の単語数は閾値を設ける前の単語数のおよそ3.5%であり，約350単語でしかない．クラスタの削除を行わない場合でシステムは85.4%の問題に対して答えを出力している．そのことから，生成したクラスタからエントロピーが大きいものを削除した後の単語数が合計で数万語程度あれば，エントロピーが0となるものだけを採用した場合(``=0.0'')の正解率で全ての問題に対応できると予測できる．ただし，エントロピーが小さいクラスタであれば何でもよいというわけではない．単純に文間の接続詞が同じものどうしをまとめたクラスタを用いた場合(``=0.0(conj)'')でも各クラスタのエントロピーは0となる．しかし，出力された問題数に対する正解率で見た場合，図11から，6.2節で生成した4種類のクラスタでそれぞれエントロピーが0となるものだけを採用した場合(``=0.0'')の正解率は60.6%で，単純に文間の接続詞が同じものどうしをまとめたクラスタを用いた場合(``=0.0(conj)'')では，45.7%である．この結果から，本手法で生成したクラスタは，少なくとも文間の接続詞によってまとめたクラスタよりは良いものであるといえる．また本論文では，式(1)によるエントロピーは良好なクラスタの一指標とはなりえるが，エントロピーが小さいものが必ずしも良いクラスタであるとはいえないと考える．</subsection>
  <subsection title="人手による評価">3人の被験者にWeb文書を入力とした8.2節の実験でシステムが出力した接続関係と，入力の2文を提示し，システムが出力した接続関係が正しいと思うものに○をつけてもらった．システムの出力としては単語スコアとパタンスコアの両方を用いて類似度を求めたときの出力を提示した．被験者らにはそれぞれの接続関係の定義を表12のように提示し，各接続関係に含まれる接続詞も参考として提示した．しかし，この接続詞の分類は必ずしも一意に決まるものではないので，あくまでも参考として使用することに限定し，被験者らにもそのように教示した．今回のシステムでは複数の接続関係を出力する場合も存在するので，人手による評価では出力数に対する2人以上の被験者が正しいと判断した接続関係割合を正解ポイントとして，Web文書を入力とした8.2節での評価と同様に累計を問題数で割ったものを正解率として求めた．システムの出力として被験者らには単語スコア×パタンスコアで類似度を求めたときの出力結果を提示している．接続関係のコーパス中での出現頻度は考慮していない．結果を表13に示す．人手による評価では，システムの自動評価よりおよそ27ポイント高い評価結果となった．人手による評価で7割以上の正解率を得られたことで，本手法の有効性を確認した．これによって，他のアプリケーションへの応用の可能性がみられたと考える．結果の事例観察から，自動評価と人手評価の精度が大きく異なったのは大きく2つの理由が関係していると考える．1つは入力文を接続詞で連続する前後2文としたため，当該2文以前，及び以後の文脈が接続詞の決定に強く影響していると考えられる場合である．これは例6のような場合に見受けられる．to3zw例6)舌鼓を乱打させました。to3zw食べずに済ませられないのがカレーうどん。この例ではシステムは「逆接」と出力され，被験者3名とも正しいと判断されたが，実際の接続詞は「さて」（転換）である．この例においては，この2文の前後数文も示していれば人間も「転換」の接続関係と判断すると予測される．もう一つは，少なくとも読み手には複数の可能性が存在すると考えられる場合である（例7）．=1=4zwto3zw例7)コンビニエンスストア側にとっては、預金の窓口機能も加えることで店舗の集客力を高める狙いがあります。=1=4zwto3zw金融機関側にとっては、店舗を開設するより少ない投資で拠点を拡大できる利点があります。この例では，システムの出力は「累加」であり，被験者3名は正しいと判断したが，実例は「一方」すなわち並列である．人間は与えられた2文とその接続関係（例7の場合は並列関係）に対して妥当性を検証し，全体として意味が取れた場合に正しいと判断すると推察される．しかし全体として意味が取れる接続関係は必ずしも1つだけではないと考えられ，これによって人手の正解率が高くなったものと考える．換言すれば，この結果は読み手と書き手の理解が一致しないことが少なからずあることを示しているのではないだろうか．</subsection>
  <subsection title="抽出された単語の数">8.4節では本論文で生成した単語のクラスタに含まれる単語数が不十分であったことについて触れたが，その他にも抽出した単語の種類にも不足があった．本論文では文中の修飾部に含まれる語は文間の接続関係を推定する際にはあまり重要ではなく，逆にノイズとなる場合が多いと考え，対象を文の述語とそれに係る格要素に限定したが，1文目の述語(V_1),2文目の述語(V_2),1文目の格要素(N_1),2文目の格要素(N_2)の4種類全てが抽出される2文の組は一割程度であった．図12は本実験で用いたWeb文書からの281セット中での抽出された単語の種類数と問題数の内訳を示している．接続関係を推定するのに必ずしも4種類全ての単語が抽出される必要はないが，抽出される単語数が減るほど正解率も低くなる傾向がある．Web文書などの一般的な文章では修飾部を含まない文は少なく，V_1,V_2,N_1,N_2の4種類では不十分である可能性がある．また，述語が「みる」「思う」等の広く一般的に用いられる語では，接続関係を同定することは難しい．このような場合には逆に修飾部によって接続関係が決定されることがある．このため，その2文での重要語の選別が重要となってくる．ここでいう重要語とは，単にTF・IDFなどから得られるものとは限らない．この重要語の選別が更なる精度向上には必要不可欠であると考える．</subsection>
  <section title="結論">連続する2文の接続関係を同定する手法について議論した．我々は，大量の事例を収集し，そのうち入力の2文に最も類似した事例に倣って問題を解く用例利用型(example-based)の処理手法を提案した．この技術は主に機械翻訳において用いられ，有効性が確認されているが，我々はこれを談話処理の問題に初めて適用した．その結果，本研究で対象としたような接続関係同定問題に対しても用例利用型が有効に機能することを実験によって示した．本研究は日本語を対象とした関連研究がないため相対的な性能の比較は不可能だが，人間による判断で提案手法による出力の75%以上が正しい接続関係であると判断されたことから，満足ではないながらも実用的な技術水準にまで高めることができたと考える．用例利用型の1つの大きな特徴は，事例追加の容易性である．同じコーパスによる手法である統計的手法は，事例が追加されると確率が再計算されるため処理性能が必ずしも向上するとは限らず，偏った事例の追加も悪影響を及ぼす可能性が高い．これに対し用例利用型はより類似した用例が増えるという影響のみであるためさらに性能が向上する可能性が高く，また事例追加による影響が局所的であるため全体的な事例追加のバランスを考慮する必要がない．今後は，こういった用例利用型に関する議論をさらに深めることで手法の特性を検証し，用例利用という手法の優位性並びに問題点をより明らかにしていきたい．</section>
</root>
