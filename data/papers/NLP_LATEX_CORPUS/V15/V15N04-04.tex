    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline
\usepackage{tabularx}


\Volume{15}
\Number{4}
\Month{September}
\Year{2008}
\received{2007}{10}{10}
\revised{2008}{1}{25}
\accepted{2008}{3}{18}

\setcounter{page}{59}

\jtitle{コーパスからの形容詞概念階層の構築と評価\\
	—実データによる形容詞オントロジーの構築にむけて—}
\jauthor{神崎　享子\affiref{Author_1} \and 馬　　青\affiref{Author_2}\affiref{Author_1} \and 山本　英子\affiref{Author_3}\affiref{Author_1} \and 白土　　保\affiref{Author_1}\and 井佐原　均\affiref{Author_1}\affiref{Author_3}}
\jabstract{
本研究は，実データに基づいた形容詞の観点からみた概念体系の自動構築をめざし，その一環として，
形容詞概念の階層関係構築に焦点を当てたものである．包含関係の尺度によって上位下位関係を求め，
その単語間の上位下位関係に基づき概念階層を自動構築した．
結果については，カバー率などの表層的な面と，階層の作られ方についての質的な面での評価を行った．
階層の質的な面での評価にあたって，概念の継承関係と事例（形容詞）の
各概念の成員としての連続性という観点から心理実験を行い，既存の人手によって作られたEDR辞書の階層と比較した．
実験手法はScheffeの一対比較法を用いた．その結果，自動構築がよい，あるいは既存の辞書と有意差がないと判断された階層は，
全体の43\%となった．抽出した概念数の不足や階層構築の際の問題点など課題も抱えているが，自動生成の階層が既存辞書の
階層に対して，その結果の半分弱の階層で問題を提起するという意味で，ベースラインとなる数値と考える．
}
\jkeywords{オントロジー，概念，形容詞，自己組織化マップ，階層関係，シェッフェ法}

\etitle{Acquiring Concept Hierarchies of Adjectives from Corpora: 
	Towards Construction of Ontology \\
	of Adjectives from a real data}
\eauthor{Kyoko Kanzaki\affiref{Author_1} \and Qing Ma\affiref{Author_2}\affiref{Author_1} \and Eiko Yamamoto\affiref{Author_3}\affiref{Author_1} \and \\
	Tamotsu Shirado\affiref{Author_1}\and Hitoshi Isahara\affiref{Author_1}\affiref{Author_3}} 
\eabstract{
The method of organizing word meanings is a crucial issue with lexical databases. We are aiming to extract the semantic structure of concepts of adjectives 
from corpora automatically. The first step to achieving this is to obtain the concepts of adjectives from corpora, for which we used abstract nouns. 
We constructed linguistic data by extracting semantic relations between abstract nouns and adjectives from corpus data. 
This paper describes how to hierarchically organize abstract concepts of adjectives mainly using the Complementary Similarity Measure (CSM) 
which calculates inclusion relations (hypernym/hyponym relations) between words. 
To estimate hypernym/hyponym relations between words, we compared three hierarchical structures of abstract concepts of adjectives: according to CSM, 
CSM with frequency (Freq), and an alternative similarity measure based on coefficient overlap. We evaluated automatically generated concept hierarchies of 
adjectives with those in EDR, and found that 43\% of those automatically generated were better than EDR.
}
\ekeywords{Ontology, Concept, Adjectives, Self-Organizing Map, Hierarchy, Scheffe's \\
	paired comparison}

\headauthor{神崎，馬，山本，白土，井佐原}
\headtitle{コーパスからの形容詞概念階層の構築と評価}

\affilabel{Author_1}{独立行政法人情報通信研究機構知識創成コミュニケーション研究センター}{National Institute of Information and Communications Technology}
\affilabel{Author_2}{龍谷大学理工学部}{Faculty of Science and Technology, Ryukoku University}
\affilabel{Author_3}{神戸大学大学院工学研究科}{Graduate School of Engineering, Kobe University}



\begin{document}
\maketitle

\section{はじめに}

計算機科学でいう「オントロジー」とは，ある行為者や行為者のコミュニティーに対して存在しうる概念と関係の記述であり「概念」というのは，
何らかの目的のために表現したいと思う抽象的で単純化した世界観である
(Gruber 1992)．認知科学では，「概念」について外延的意味（事
例集合で定義された意味）と内包的意味（属性の集合から定義された意味）の見方があるとする\cite{Book_02}．我々の認知活動の中で，
概念化は，語，文，文脈，動作の仕方，事柄，場面など，様々なレベルで行われている．では，なぜ対象の概念化が必要かというと，河原では，
    Medin and Goldstone\nocite{book_24}を引用して「概念」の機能を次のように
述べている(Medin and Goldstone 1990; 河原 2001)「現在の経験を，あるカテゴリの成員とみなす（分類）ことで，その経験を意味のある
まとまりとして解釈し（理解と説明），そこから将来に何がおきるか（予測）や関連する別の知識（推論）を引き出すことが可能になる（コミュニケーション）．
その他，複数の概念を表す語を組み合わせて新たな概念を生成したり，新たな概念の記述を生成してから，その記述にあう事例を検索することもできる」．
つまり，人間や計算機が効率的に柔軟な活動をするために，概念と，（言語化する・しないにかかわらず）概念の具体化された表現（あるいは事例）の
総体である「オントロジー」は重要な役割を担っているといえる．

我々が対象とする言語的オントロジー，特に，語彙の概念を体系化したオントロジーは，概念体系や意味体系と呼ばれ10年以上前から人手で
構築されてきた（EDR電子化辞書（日本電子化辞書研究所 1995）や分類語彙表\cite{book_16}など）．
その目的は，ある特定のアプリケーションでの利用ではなく，我々の言語知識を体系化する
ことであり，その知識体系を利用して計算機に予測・推論・事例の検索・新たな概念の理解など，深い意味処理をさせることを目的としている．本研究が
めざす「形容詞のオントロジー」の目的も，従来の語彙的なオントロジーの目的と同様に，計算機や人間が，形容詞を使って表現する知識の体系化を
はかるものである．ここで本研究の「形容詞」とは，形容詞と形容動詞を含むものとする．

従来のものと異なる点は，実データからの獲得を図るため，運用の実態を反映したオントロジーを得ようとすることである．人間の内省による分析の場合，
概念記述を行う個々人の言語的経験から，概念体系の粒度や概念記述に差異がでてくる．心理実験のように，複数の人が同じタスクをすれば共通の
傾向もとれるが，通常のプロジェクトでは同じ個所に多くの人を投入することは不可能である．自動獲得の目的は，できるだけ実際の言語データから
言語事実を反映した結果を得ることである．一つ一つのテキストは個々人の記述だが，それを量的に集めれば，複数の人のバリエーションを拾うことができ，
結果的に多くの人の言語運用の実態をとることができる．言語データから意味関係を反映した概念体系を捉えられれば，人間の内省によって作られた
オントロジーや言語学的知見，意味分類などと比較することは意義があるのではないかと考える．

ところで，コーパスからの語彙のクラスタリングや上位下位関係の自動構築などについては，Webの自動アノテーションやインデックス，情報検索など，
その目的は様々であるが，そのほとんどが，名詞や動詞を対象にした分類や関係抽出である．形容詞や副詞に関する研究はまだ少ない．
しかし，形容詞や副詞が語彙のオントロジーにとって重要でないわけではなく，たとえば，WordNetで形容詞の意味情報が手薄であることを指摘し，
イタリア語形容詞の意味情報を導入することで，ヨーロッパの複数言語で共同開発しているEuroWordNetの抽象レベルの高い概念体系 (Euro WordNet Top Ontology) に
変更を加えることを試みている研究がある\cite{Inproc_01}．

オントロジーの主要な関係の一つに，類義関係と階層関係がある．形容詞概念を表すような抽象的な名詞の類義関係については，
馬らなどの研究がある\cite{Article_21}．しかし，形容詞概念の階層関係については，まだ研究が進んでいない．
本研究では，形容詞概念の階層関係に着目し，コーパスから取得した概念から階層を構築する方法と，妥当そうな階層を得るための評価について述べる．

本研究で扱う概念数は約365概念であり，それに対しEDR電子化辞書の形容詞の概念数が約2000概念ほどと考えると取り扱うべき概念は
さらに増える可能性があるが，本研究は，現時点よりも多くの概念数を扱うために，まず，現段階での概念数で，階層構築とその評価方法について
実験および考察を行ったものである．

我々は，第2節でオントロジーのタイプの中で本研究がめざすオントロジーについて述べ，第3節で先行研究の言語学的考察から，
形容詞の概念を語彙化したような表現があることを述べ，形容詞の概念をコーパスから抽出する．
第4節では第3節で抽出したデータをもとに複数の尺度での階層構築と，得られた階層のうち，妥当そうな階層を判別するための条件を述べ，
第5節で心理実験によってEDRの形容詞概念階層と比較評価を行う．第6節でオントロジー構築に向けての今後の展望をのべ，第7節でまとめを行う．


\section{オントロジーのタイプ}

「オントロジー」という用語が喚起する定義や種類，目的などは多様化しているため，本研究がどのようなオントロジーで，何を目的として作るのかを明らかにする必要がある．

Sowaは，主なオントロジーのタイプとして，terminological ontology，prototype-based ontology，formal ontologyなどをあげている(Sowa 2003)．
Terminological ontologyは，概念の上位下位関係や部分全体関係などの関係が特定され，他の概念との相対的な関係が決められているタイプのものである．
このタイプのオントロジーは概念を完全に定義するものではない．

意味公理や論理的な定義よりも，プロトタイプや事例によって弁別されるオントロジーが，prototype-based ontologyである．
つまりプロトタイプ集合や事例集合が相対的な関係をもって分類されているタイプのものである．

また，論理形式で書かれる意味公理や定義によって概念が弁別されるオントロジーがformal ontologyである．論理の複雑さの制限はない．
一般的なterminological ontologyとformal ontologyの違いは，種類というより，概念間の関係の深さが異なり，formal ontologyは規模が概して小さいが，
深い記述がされるため推論をサポートするのに用いられる．

Biemannはそれぞれのタイプを図示し（図1），長所と短所を述べている\cite{Article_03}．

このうち，formal ontologyは直接推論に使えるものの，コード化に労力がかかり，大規模になると不整合もおきる危険性がある．
一方，terminological ontologyやprototype-based ontologyは自動化がしやすく作りやすい．
しかし，prototype-based ontologyは，概念ラベルがないので，QAシステムなどには使いにくい．
このオントロジーは語のクラスタリングによってすぐに導出されるのでterminological ontologyより構築しやすいが，利用しにくい．

その他の種類として，シソーラスがあげられる．シソーラスは関連語のまとまりをもち，prototype-based ontologyに似ている．
しかし，関連語などの中には互いに異なった関係も含まれている場合がある．

テキストからオントロジーを学習するのに利用できる手法として，分布特性によるクラスタリングをはじめ，表層的な統語情報や
特定の言語表現パタンなどを利用して，階層関係や部分全体関係などの単語間の関係を獲得する研究などが
ある\cite{Inproc_10,Inproc_09,Inproc_05,Inproc_04}．
これらの研究と関係が深いが，Semantic lexiconの構築としてのオントロジーの学習という観点もある．
Semantic lexiconは，カテゴリと事例のセットという形であるが，オントロジーのように内部的に構造化されていない．
そのアルゴリズムのほとんどがbootstrappingのアプローチである\cite{Inproc_29,Inproc_36,Inproc_18,Inproc_27}．

\begin{figure}[t]
\begin{center}
\includegraphics{15-4ia4f1.eps}
\caption{菜食主義用食物と非菜食主義用食物を区別する食物オントロジー}
    （Biemann 2005\nocite{Article_03} p.79からの引用）
\end{center}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{15-4ia4f2.eps}
\end{center}
\caption{Semantic lexicon}
\end{figure}

    以上，Sowa，Biemann\nocite{Article_03}に従ってオントロジーのタイプを概観したが，
我々が目的とする形容詞のオントロジーは，
形容詞が事例となり，その事例が共通してもつ概念がラベルとなり，その概念ラベルが構造化されたオントロジーという形である．
上記でいえば，Semantic lexiconのように形容詞の事例とそれらが共通にもつ概念を一つのユニットとして，それが，
ラベルつきprototype-based ontologyのように構造化されたものである．これは，EDR電子化辞書や分類語彙表などの
語彙の概念体系／意味体系と同様の形である．ただし，概念名については，EDR電子化辞書は説明的記述を使い，
『分類語彙表』の項目では抽象的な語句あるいは代表的な形容詞を使っているが，
本研究では，概念ラベルを抽象的な名詞で表現している．オントロジーは柔軟に概念と表現を結びつける必要があるので，
概念間の関係は一種類ではなく複数想定され，木構造よりネットワーク的な形態の可能性もある．しかしまずは，概念の
類義関係と階層関係をとらえていきたいと考える．本稿では，その一環として，特に，形容詞の概念の上位・下位関係について焦点をあてる．



\section{言語表現に現れる「概念とその具体事例」という関係}

\subsection{言語現象}

日本語では，高橋が，以下のような例を言語学的に観察している\cite{Article_34}．

　　　(1) やぎは\underline{性質}がおとなしい \par
　　　(2) ぞうは\underline{鼻}が長い 

(1)の「性質」は，主体「やぎ」からみると主体のある一面を表すので「側面語」であり，(2)は，主体「ぞう」からみると身体の一部であるので「部分語」と呼び分けて，
統語的には同じ構造でも，語の文中での役割の違いを指摘した．そして，側面語については，主語が示すものの側面を表すとともに，述語が示す属性の
類概念（上位概念）を表す単語であると考察している．また根本は，「色が白い」「速さがはやい」「年が若い」「背が高い」などは，同義反復的な性格が強いと
述べている\cite{Book_26}．このように，我々の言語活動の中でも，形容詞の上位概念を語彙化した表現がみられる．

本研究では，(1)の「性質—おとなしい」や「色—白い」「速さ—はやい」などの関係を，「概念とその具体事例」という関係と捉え，このような抽象的な
名詞と形容詞の共起をコーパスから抽出する．本稿では，このような抽象的な名詞を「概念」とよび，共起する形容詞を「事例」と考える．


\subsection{コーパスからの抽出方法}

次に抽出方法であるが，上記の例のような「NはXがAdj」というパタンは今回は利用していない．この構文のNとX，Adjの意味関係は様々である．
それは，3.1節の(1)と(2)が構文上同じ形をしているにもかかわらず，NやAdjに対するXの意味関係が違っていることからもわかる．
従って，コーパスから「NはXがAdj」の文型を集めると，量は多いが，「概念とその具体事例」という関係を雑多な関係の中から取捨選択することが難しい．
これにはなんらかの基準が必要である．（なるべくある程度のノイズがあっても自動化したり，あるいは人間が簡単に判別できる基準を求める必要があろうが，
それは今後の課題とする．）

\begin{description}
\item[1]
抽出方法は，毎日新聞94年，95年の2年分のデータから，「XトイウY」の句を抽出することからスタートする．
「トイウ」の直前に現れる表現は，内容節（あるいは内容語）である．寺村，益岡は連体修飾表現を分析しているが，特に益岡では「トイウ」内容節をとる場合は，YがXの属する範疇だとしている\cite{Book_35,Book_19}．
たとえば，「質実剛健という気風」の例では，
「気風」（Yに相当）は「質実剛健」（Xに相当）の属する範疇ということである．

そこで，何かを範疇化する可能性をもつ「Y」の収集を目的として，「XトイウY」を使って「Y」をコーパスから自動的に抽出した．このプロセスは，
具体事例によって説明される被修飾名詞の収集を意図している．具体的には，コーパスを形態素解析（JUMANを使用）したあと，「トイウ」の前後の単語を抽出した．
最終的にYにくる被修飾名詞は15,391語となった．

\item[2]
次に，「トイウ」を介在して内容語を取るYを集めた後，Yと共起する形容詞をコーパスから抽出する．
たとえば，「温和な性格」とは表現しても，「トイウ」を介在させた「温和という性格」のような表現はあまり見られない．
そこで，単にYと共起する形容詞を取り出すことにした．使用したデータは，毎日新聞11年分，日本経済新聞10年分，日経産業金融流通新聞7年分，読売新聞14年分である．
また，新聞以外でも形容詞とY（名詞）の共起をとるため，新潮文庫100選，新書100冊についても使用例を人手によって調べ追加した．
このように取り出した共起関係には，雑多な共起関係が含まれているので，本研究で対象とした，Xが具体事例でYがそれを範疇化した語という
共起対（「赤い」と「色」のような共起対）を，最終的に人手で整理した．

人手によるデータ整理は，一人の作業者が行った．判定基準は，神崎，神崎・井佐原で記述されている，連体用法にみられる形容詞と名詞の統語的・意味的関係の中から，
以下の関係を採用した\cite{Article_12,Article_13}．
\end{description} 

\begin{description}
\item[I]
Adj（形容詞）＋X（名詞）⇒X がAdj\\
Xを限定する表現（そのX，「NはXが〜」など）をとらなくても「XがAdj」に変換可能なもの．\\
被修飾名詞が属性を表現するタイプ．（例）ゆるやかな傾斜
\item[II]
主語述語関係に変換ができない
\begin{description}
\item[II-1]
形容詞は，被修飾名詞の意味を構成する一部の意味だけにかかり，類似した意味を重ねて強調する働き（例）古い昔
\item[II-2]
被修飾名詞の指示対象の内容を表す （例）悲しい思い
\end{description}
\end{description}

I) は直接的な属性—属性値の関係であり，II-1) は被修飾名詞の意味の一部を形容詞で顕在化し重ねることで強調する関係，
II-2) は被修飾名詞の指示対象の内容を具体化する関係となっている．どれも被修飾名詞の意味を含意しつつ形容詞表現で
具体化する関係であるため，これら3つのパタンを採用した．

以上のように，上記プロセスの2のステップでは，最終的に人間の内省で取捨選択しており，やはり労力がかかるが，
1のステップで，被修飾名詞を「何かを範疇化する可能性のある語」に限定することで，抽出対象とする形容詞と概念の共起対を多く含んだ
データを得ようとした．

人間の取捨選択で得られた形容詞とY（名詞）共起対の総数は36,023共起対，異なりが10,524共起対である．
概念数は365で，最大共起形容詞数は，「こと」の1,594語である．出現する共起形容詞数に対する各概念の例は以下のようになる．

\pagebreak

\begin{table}[h]
\caption{形容詞の共起数ごとの概念例}
\begin{center}
\input{04table01.txt}
\end{center}
\end{table}

そして，抽出した概念と形容詞グループを最終的に以下のようなリストにまとめた．

\begin{table}[h]
\caption{抽出した概念と形容詞グループ}
\begin{center}
\includegraphics{15-4ia4t2.eps}
\end{center} 
\end{table}

概念名となる抽象名詞と形容詞集合のリストを作る際，同じ抽象名詞であっても，明らかに指示対象が異なる場合は，
番号をつけて区別した．たとえば，物理的な「形」（たとえば「丸い形」）と，形式的な意味の「形」（たとえば「おだやかな形で〜」）では，
「形」の指すものが異なるので，「形1」「形2」のように区別し，形容詞集合をわけた．

一方，形容詞についてはどのような名詞と共起しているか，だけをみており，ここで形容詞の多義は区別していない．



\section{概念の階層関係の構築—階層構築の手法と閾値の選定基準—}

本節では，包含関係を求める尺度を使い，第3節で抽出した形容詞の概念の階層構築を行う．

概念間の包含関係を求める尺度として，Hagita and Sawakiが開発し山本・梅村が言語データへ応用した
補完類似度(Complementary Similarity Measure, CSM)と，頻度を考慮したCSM (Freq)，そして，CSM以外の尺度として
オーバーラップ相関係数 (Overlap Coefficient，Ovlp)を使う\cite{Inproc_08,Article_37,Book_22}．

2つの概念間の包含関係を計算したのち階層構築を行うが，予備実験を行った結果，全ての包含関係の概念ペアを使うと明らかに
ランダムな長い階層ができた．そこで，包含関係が希薄な概念ペアが階層関係の精度を低くすることを阻止するため，包含関係の値に
閾値を設定することにした．

しかし，閾値設定の問題点として，ゴールドスタンダードがないこのタスクで，複数の尺度や閾値の組み合わせから構築された階層の
明らかな差異を，一見して判定できない場合，どのように妥当そうな階層を特定したらよいのだろうか．第5節では心理実験によって
階層評価を行うが，事前に明らかに不適当な尺度と閾値の組み合わせを除外するために，緩やかな階層の評価方法が必要になる．
本節では，包含関係の尺度を用いて階層構築を述べた後，包含関係の尺度と閾値の組み合わせの妥当性をいくつかの観点から眺め，
妥当そうな類似尺度と閾値をある程度特定する方法を述べる．


\subsection{包含関係の尺度}

包含関係の尺度として，3種類の方法を用いた．

まず，補完類似度(CSM)について述べる．補完類似度は一対多関係を推定する尺度として提案されたが，事象間の一対多関係は，
包含関係（あるいは上位下位関係）を表すので，包含関係を推定する尺度とも考えられる．山本，梅村では，｛沖縄県，那覇市｝のような
一対多関係を推定するタスクを行っており，そのタスクでは，コーパスからの関係抽出に用いられた他の類似尺度や連想規則の抽出に
用いられる類似尺度など（たとえば相互情報量，コサイン関数，ダイス相関係数など）よりもよい結果を示したことが報告されている\cite{Article_37}．

この補完類似度を用いて，対象としている概念の包含関係，つまり上位下位関係を推定する．補完類似度は以下のようになる．

今，共起形容詞のセットで定義した抽象名詞$F$と$T$があるとする．我々のデータでは，FとTの特徴ベクトルは，双方の共起形容詞の
出現状況を0または1で表現したものに相当する．それを以下のように表す．
\begin{align*}
 & \overrightarrow{F}=(f_{1}, f_{2},..., f_{i},... ,f_{n}) \quad (f_{i}=0 または 1) \\
 & \overrightarrow{T}=(t_{1}, t_{2},..., t_{i},..., t_{n}) \quad (t_{i}=0 または 1)
\end{align*}

そして，補完類似度の式は以下のようになる．
\begin{gather}
 CSM(F, T) = \frac{ad-bc}{\sqrt{(a+c)(b+d)}} \\
\begin{aligned}
 & a = \sum_{i=1}^n f_i \cdot t_i, && b = \sum_{i=1}^n f_i \cdot (1 - t_i), \\
 & c = \sum_{i=1}^n (1 - f_i) \cdot t_i, && d = \sum_{i=1}^n (1 - f_i) \cdot (1 - t_i), \\
 & n = a + b + c + d &&
\end{aligned}
\nonumber
\end{gather}
``$a$'' はFとTで共通する共起形容詞の数である．\\
``$b$'' はFとは共起するがTとは共起しない形容詞の数である．\\
``$c$'' はFとは共起しないがTとは共起する形容詞の数である．\\
``$d$'' はFともTとも共起しない形容詞の数である．\\
``$n$'' は，ベクトルの次元数となる．
\vspace{\baselineskip}

FがTを完全に包含する場合，$c=0$となり，TがFを包含する場合，$b=0$となるため，$bc=0$となる．補完類似度では，一致情報(ad)と不一致情報(bc)の差分をとるので，
包含関係にある二語間の類似度は高くなる．

さらに，補完類似度はFからTの類似度とTからFの類似度が非対称であることも特徴の一つである．FからTをみた補完類似度では，$b$はFだけに出現する形容詞の
数，$c$はTだけに出現する形容詞の数である．逆に，TからFをみた補完類似度では，$b$はTだけに出現する形容詞の数となり，$c$はFだけに出現する形容詞の数となる．
計算式の分母をみると，FとTがどちらの方向の類似度を計算するかで，$b$と$c$に代入される数値の大小が逆転し，それに伴って，類似度も非対称になる．

次にCSMと比較する手法として，オーバーラップ相関係数(Ovlp)と頻度つきCSM(Freq)の階層を用いる．

オーバーラップ相関係数について，Manning and Sh\"{u}tzeは包含関係を求める尺度として述べている\cite{Book_22}．
これは，二値ベクトル間の類似尺度で，計算式は以下のようになる．
{\allowdisplaybreaks
\begin{gather}
\begin{aligned}
 & \overrightarrow{F}=(f_{1}, f_{2},..., f_{i},... ,f_{n})\qquad & (f_{i}=0 または 1) \\
 & \overrightarrow{T}=(t_{1}, t_{2},..., t_{i},..., t_{n}) & (t_{i}=0 または 1) 
\end{aligned}
\nonumber\\
\begin{aligned}[b]
 \mathit{Ovlp}(F, T) &= \frac{|F \cap T|}{\mathit{min}(|F|, |T|)}  \\
	 &= \frac{a}{\mathit{min}(a + b , a + c)} 
\end{aligned}\\
\begin{aligned}
 & a = \sum_{i=1}^n f_i \cdot t_i, & b = \sum_{i=1}^n f_i \cdot (1 - t_i), \\
 & c = \sum_{i=1}^n (1 - f_i) \cdot t_i & 
\end{aligned}
\nonumber
\end{gather}
}
$a$，$b$，$c$などのパラメータは，CSMでの定義と同様である．

次に頻度を考慮した補完類似度について計算式を示す．これは，Sawaki, Hagiga, and Ishii が二値画像のための補完類似度を，多値画像解析のために拡張したものである\cite{Inproc_31}．
Yamamoto, Kanzaki, and Isahara ではこれを言語データに応用している\cite{Inproc_39}．これは，多値ベクトル間の類似尺度で，計算式は以下のようになる．
\begin{gather}
\begin{aligned}
 & \overrightarrow{F}_g = (f_{g1}, f_{g2},..., f_{gi},... ,f_{gn}) \qquad & (0 \leq f_{gi} < 1) \\
 & \overrightarrow{T}_g = (t_{g1}, t_{g2},..., t_{gi},..., t_{gn}) & (0 \leq t_{gi} < 1) 
\end{aligned}
\nonumber\\
CSM_{g}(F_{g}, T_{g}) = \frac{a_{g}d_{g}-b_{g}c_{g}}{\sqrt{nT_{g2} - T_{g}^{2}}} \\
\begin{aligned}
 & a_{g} = \sum_{i=1}^n f_{gi} \cdot t_{gi}, && b_{g} = \sum_{i=1}^n f_{gi} \cdot (1 - t_{gi}), \\
 & c_{g} = \sum_{i=1}^n (1 - f_{gi}) \cdot t_{gi}, && d_{g} = \sum_{i=1}^n (1 - f_{gi}) \cdot (1 - t_{gi}), \\
 & T_{g} = \sum_{i=1}^n T_{gi}, && T_{g2} = \sum_{i=1}^n t_{gi}^2 \\
\end{aligned} 
\nonumber
\end{gather}

この定義式において，各要素は，には，抽象名詞（概念に相当）がi番目の形容詞と頻繁に共起するかどうかの状況を表す，共起頻度に基づく重みを用いる．
重みは以下のように求める．
\begin{gather}
 \mathit{Weight}(\mathit{noun}, \mathit{adj}) = \frac{\mathit{Freq} (\mathit{noun}, \mathit{adj})}{\mathit{Freq} (\mathit{noun}, \mathit{adj}) + 1} \\
\text{重みの値域は $0 \leq \mathit{Weight}(\mathit{noun}, \mathit{adj}) < 1$ である．}
\nonumber
\end{gather}

ベクトル$\overrightarrow{F}_g$を持つ抽象名詞を$\mathit{noun}_F$と$\overrightarrow{T}_g$を持つ抽象名詞を$\mathit{noun}_T$とし，
上式の重みで$f_{gi}とt_{gi}$を表すと，ベクトルは以下のように表される．
\begin{align}
 \overrightarrow{F}_g &= (f_{gi}, f_{g2}, ... , f_{gn})  \nonumber \\
    &= (\mathit{Weight}(\mathit{noun}_F, \mathit{adj}_1), 
	\mathit{Weight}(\mathit{noun}_F, \mathit{adj}_2), \dots , 
	\mathit{Weight}(\mathit{noun}_F. \mathit{adj}_n)) \nonumber \\
 \overrightarrow{T}_g &= (t_{gi}, t_{g2}, \dots , t_{gn})  \nonumber \\
     &= (\mathit{Weight}(\mathit{noun}_T, \mathit{adj}_1), 
	\mathit{Weight}(\mathit{noun}_T, \mathit{adj}_2), \dots , 
	\mathit{Weight}(\mathit{noun}_T. \mathit{adj}_n)) 
\end{align}


\subsection{概念階層の構築方法}
CSMなどによって包含関係を計算し，値を正規化して得られたリストの一部を示すと以下のようになる．
\vspace{-1\baselineskip}

\begin{table}[h]
\caption{CSMによって推定された包含関係}
\begin{center}
\includegraphics{15-4ia4t3.eps}
\end{center}
\vspace{-2\baselineskip}
\end{table}

単語Aから単語Bを見たときのCSM値が，単語Bから単語Aを見たときのCSM値より大きければ，単語Aが上位語，単語Bが下位語となる．
たとえば，本稿では概念とは第3節で抽出した抽象的な名詞で定義しており，上記の概念の並びは，左の概念からみた右の概念の包含関係を表している．
たとえば，左の概念が「印象」で右の概念が「感じ」の場合は，「印象」からみた「感じ」を示し，上記ではCSM値は0.936となる．逆に，方向が逆転し，
左の概念が「感じ」で右の概念が「印象」の場合は，「感じ」からみた「印象」の包含関係を表し，0.778となる．この場合「印象」から「感じ」を見るほうが，
CSM値が高いので，「印象」は「感じ」の上位概念となる．ただし，この場合は両方向からのCSM値が高いので，かなり事例に重なりがあると考えられる．

上記のような二単語間の包含関係を求めた後，これを利用して階層を構築する．階層構築方法は次のようになる．
\begin{itemize}
\item[(0)]
初期階層として，CSM値の高い順に二単語をつなげる．\\
ここでは，仮に単語Aが上位語，単語Bが下位語という関係とする．\\
　　　　　階層(0): A-B（``-'' は上位下位関係を示す記号とする）
\item[(1)]
まず，階層(0): A-B　の下位語を探索する．\\
二単語間のCSM値のリストから，単語Bを上位語として，Bの下位語として最大値をとる単語Xを探して，単語Bの後ろに連結し，次に，
その単語Xを上位語として，Xの下位語として最大値をとる単語Yを探して，単語Xの後ろに連結する．
この操作を下位語がなくなるまで繰り返す．これによって以下のような階層ができる．\\
　　　　　階層(1)：A-B-X-Y
\item[(2)]
次に，\pagebreak
階層(0): A-Bの上位語を探索する．\\
二単語間のCSM値のリストから，単語Aを下位語として，Aの上位語として最大値をとる単語Wを探して，単語Aの前に連結し，
次に，その単語Wを下位語として，Wの上位語として最大値をとる単語Vを探す．この操作を上位語がなくなるまで繰り返す．
階層(1)と連結することで以下のような階層ができる．\\
　　　　　階層(2): V-W-A-B-X-Y \\
ただし，上位下位関係は必ず保存する．もし上位下位関係が逆転した場合はその関係は連結しない．
\item[(3)]
長い階層に完全に含まれる短い階層はマージし，二つの階層のうち一単語ずつ異なる場合は，
各階層の差異となる二単語の補完類似度の値を測り，上位下位関係があれば結合した．
\begin{itemize}
\item[例1)]
A-B-C-D-EとA-B-Dという階層があるとき \\
A-B-Dは，順序を保存した状態で長い階層に完全に含まれるのでマージし，短い階層は削除する．\\
A-B-C-D-E 
\item[例2)]
A-B-C-D-EとA-B-X-D-Eがあるとき \\
CとXの補完類似度の値を求め，CとXに上位下位関係があれば結合した．\\
A-B-C-X-D-E
\end{itemize}
\item[(4)]
最後に各階層のトップに「こと」を結合する．「こと」は全ての形容詞と共起するとして，計算時間の便宜上，「こと」は最後に各階層のトップに結合させることとした． \\
　　　　　最終階層: こと-V-W-A-B-X-Y 
\end{itemize}


\subsection{妥当そうな手法と閾値の選定}

4.2節で求めた概念間の包含関係を全て使って階層を構築すると，冗長な意味のない概念階層（つまり単語の羅列）になり，閾値があまりに高いと，
概念階層は非常に短くなる（つまり，連結される名詞があまりにも少なくなる）．そこで，包含関係が希薄な概念ペアが階層関係構築時に悪影響を
及ぼすことを阻止するため，包含関係の値に閾値を設定することにした．CSMについては0.3と0.2，Ovlpについては0.3と0.2，Freqについては0.2と0.1の閾値を設定し，
その閾値以上の概念間の包含関係を用いて階層を構築した．これらの閾値による階層は，概念を連結したある程度の長さの階層であり，かつ，
明らかにおかしい概念の羅列ではない．この閾値以上でも以下でも，前述の弊害が出る．逆にいえば，前述の閾値からできた階層は，一見して妥当なのか，
妥当ではないのか，すぐにはわからないともいえる．手法ごとに多くの階層が生成され，閾値をいくつか設定すれば，その分だけ，また階層が増えるので，
心理実験などで既存辞書との比較評価を行おうと思えば，妥当そうな階層を事前に選定した方が効率的である．

そこで，次のような観点から，階層を分析した．

\begin{itemize}
\item[(1)]形容詞の階層としてできた階層の割合\\
第2節で述べたprototype-based ontologyで構造化された事例集合（図1）をみるとわかるように，
最下位レベルで出現している「チーズ」は，最上位レベルの事例集合にも出現している．

通常，上位概念の特徴は下位概念の特徴に「継承」される．概念の特徴を定義するのが事例集合である場合，
下位レベルで出現する事例は，上位レベルの概念の事例にもなる（「すずめ」は，鳥の事例でもあり，動物の事例でもあり，生物の事例である）．

この認知科学的ルールから，自動構築した階層の，最下位概念の事例集合（形容詞の集合）が，最上位概念までの各概念の事例集合に含まれているかを調べ，
連続して出現していれば，その階層は，当該形容詞の階層と考える．本稿のデータで考えると，「形容詞の階層としてできた階層」とは，ある形容詞が，
最下位から最上位に位置するすべての概念の形容詞集合に出現している場合，その階層を「形容詞の階層としてできた階層」と呼ぶ．もし，ある形容詞が，
階層のどこかの概念の形容詞集合の成員でなければ，形容詞の階層とはよばず，手法によって得られた「階層」とよぶ．

この考えに則って，手法ごとに，得られた階層の中で，形容詞の階層として得られた階層が何割あるか，計算した．分母は，ある手法に基づいて構築された全階層であり，
分子は「形容詞の階層としてできた階層」である．\\
\begin{equation}
形容詞の階層として得られた階層の割合 = \frac{形容詞の階層としてできた階層数}{ある手法に基づいて構築された階層の総数} 
\end{equation}
\item[(2)]
 事例としてコーパスから抽出された全形容詞のうち，何語の形容詞に「形容詞の階層」が得られたか．
\item[(3)]
階層を構成する概念の割合 \\
概念としてコーパスから抽出した抽象名詞は全部で365語あるが，そのうち何割が階層を構成しているか．階層を構成する概念の割合は次のように計算した．
\begin{equation}
階層を構成する概念の割合 = \frac{階層を構成する概念の異なり数}{抽出した全概念数（365語）}
\end{equation}
\end{itemize}

上記3つの観点から各手法の結果を求めると，表4のようになる．

表中で，高い数値の第一位から第三位に「○」，そのうち極端に数値が高い場合は「◎」を数字の前に付与した．また，極端に数値が低いものには「＊」を付与した．

表1から，総合的にみるとCSM0.2とOvlp0.3が，形容詞の階層としてできた階層の割合も，階層ができた形容詞数や365の概念のうちで階層を構成する概念の割合もよいとわかる．
CSM0.3は，6種類の階層の中で形容詞の階層を最も多く作っているが，階層を構成している概念の数が最も低い．これは同じ階層をもつ形容詞のグループが，
未分化である可能性がある．また，Ovlp0.2の階層は，形容詞の階層はあまり作られていないが，対象にしている365の概念をほとんど使って，階層を作っている．
これは，冗長に階層を作っている可能性がある．程度の差こそあれ同様の傾向がみられるのはFreq0.1である．形容詞をカバーする階層は少ないが，
階層を構成している概念が多いことがわかる．Freq0.2は，形容詞をカバーする階層は多めであるが，それより顕著な特徴は，階層を構成する概念の種類が少ないことである．
程度の差こそあれ，その点では，CSM0.3に似た傾向がみられる．

\begin{table}[t]
\caption{階層の作られ方からみた手法別の階層の特徴}
\input{04table04.txt}
\end{table}

上記の結果より，CSM0.2とOvlp0.3は，外見的に妥当そうな階層となっているので，EDRと比較する階層としてこの二者を選択する．
また，頻度を考慮したCSM (Freq) については，両者の閾値とも外見上それほど適当ではないが，異なる種類を比較するということで，形容詞の階層が
比較的得られているFreq0.2を，EDRとの比較実験に加えることとする．


\section{自動構築の階層とEDR辞書の概念階層との比較評価}

本節では，本研究の提案手法によって自動構築した階層と，EDR階層の優劣を心理実験によって定量的に比較する．

EDR電子化辞書は，10年ほどの年月をかけ，言語学者や辞書編纂者などが携わった大規模な計算機用辞書である．
この電子化辞書は概念体系をもち，各語彙は概念IDによって概念体系とリンクしており，概念IDから上位概念や下位概念などを辿ることができる．
EDRの概念体系には局所的な不整合性や冗長性などの問題はあるものの，概念分類と概念間の関係を細かく記述した全品詞にわたる大規模シソーラスである．
本研究が対象とする形容詞概念についても，EDRは広範囲にカバーしているため，本実験ではEDRを比較対象とした．
EDRの概念記述は単語で定義されている場合もあれば，文で説明していることもある．たとえば，EDRの「肯定的な」という形容詞の概念階層の例を示すと次のようになる．


\begin{description}
\item[EDR階層：「肯定的な」] \mbox{} \\
概念(3aa966)→事象(30f7e4)→移動(30f801)→情報の移動(30f832)→情報の受信(3f96e7)→知る(30f876)→認知主体と認知対象との認知的距離減少(3f972c)→（意見などに）同意しているさま(0f0ae2)
\end{description}

一方，自動生成の階層は，各ノードの概念が抽象名詞で表現されている．たとえば以下のような階層である．階層中，「面1」のような名詞の横の番号は，
「面」の意味を区別した際に付与した番号である．（ここでは，「やさしい面がある」のような形式的な意味の「面」と「丸い面」のような物理的な面とを区別し，
前者の形式的な意味の「面」を「面1」とした．）


\begin{description}
\item[自動生成の階層：「肯定的な」]\mbox{}\\
こと→面1→傾向→見方→評価
\end{description}

二つの異なる形式の階層比較をした研究としては，概念記述間の単語の一致度によって表層的に評価した研究がある\cite{Article_38}．
しかし上記の通り，本研究で自動抽出された階層とEDR階層の構造は異なり，また概念の比較評価という抽象的な対象を扱うタスクであるため，
我々は，表層的な比較ではなく，心理実験による優劣の比較を行った．

4.3節(1)でも触れたが，階層関係が成立する重要な条件として，
\begin{itemize}
\item[1)]
上位概念の下位概念への継承性 
\item[2)]
事例（本稿では形容詞）が，事例集合の成員として最下位概念から最上位概念まで出現する連続性 
\end{itemize}
という二つの条件がある．本実験の目的は，上記二つの観点から，自動構築の階層とEDR階層の優劣の程度に関する人間の判断を数値化することにより，
これら二つの階層間の優劣を統計的に比較することである．数値化手法としてはScheffeの一対比較法を用いた\cite{Article_32}．
Scheffeの一対比較法で得られる値は相対的な値であるため，各々の階層の絶対的な優劣の程度は数値化できないが，
異なる階層間の優劣の相対的な程度を数値化することができる．そしてこのような数値化によって，階層間の優劣の判断に関する被験者間のばらつきを考慮した上で，
階層間の優劣を統計的に検定することができる．なお，言語データの評価にScheffeの一対比較法を用いた他の研究として，
丸元らの研究があるが，この研究は敬語表現の丁寧さの程度の数値化にScheffe法を用いたものである\cite{Article_23}．


\subsection{実験データについて}

実験には，下記に示す三種類のデータを用いた．
\begin{itemize}
\item[1)]
30語の形容詞に対して，CSM0.2，Ovlp0.3，Freq0.2の三手法の全て，あるいは，三手法のうち少なくともいずれか二手法で共通して生成された階層
（以下，COMMONと呼ぶ）と，EDRの階層のペア．(COMMON-EDR)
\item[2)]
10語の形容詞に対して，CSM0.2だけで生成された階層とEDRの階層のペア．(CSM-EDR)
\item[3)]
10語の形容詞に対して，Ovlp0.3だけで生成された階層とEDRの階層のペア．(Ovlp-EDR)
\end{itemize}
Freq0.2の階層はCSM0.2の階層と殆ど同じであったので，本実験では，Freq0.2の手法だけで生成された階層は対象外にし，CSM0.2の階層のみをとりあげた．

1)(COMMON-EDR)で対象となる30語の形容詞のリスト，2)(CSM0.2-EDR) で対象となる10語の形容詞のリスト，3)(Ovlp0.3-EDR)で対象となる
10語の形容詞のリストをそれぞれ表5，表6，表7に示す．

\setcounter{table}{4}
\begin{table}[t]
\caption{COMMON-EDRで対象となる形容詞（30語）}
\input{04table05.txt}
\end{table}
\begin{table}[t]
\begin{minipage}{200pt}
\caption{CSM-EDRで対象となる形容詞（10語）}
\input{04table06.txt}
\end{minipage}
\hfill
\begin{minipage}{200pt}
\caption{Ovlp-EDRで対象となる形容詞（10語）}
\begin{center}
\input{04table07.txt}
\end{minipage}
\end{table}



\subsection{被験者}

言語学者，辞書編集者，自然言語処理に関係する人，合計20人が被験者として参加した．

\subsection{実験方法}

各々の被験者には，各々の形容詞に対する自動構築の階層とEDRの階層のペアが各行に記された回答用紙が示された．この例を図3に示す．
各行の左側には自動構築による階層（図中，A-B-C），右にEDR階層（図中，P-Q-R）が記される．ただし左が自動構築の階層で，右がEDRの階層であることは，
被験者には知らせていない．被験者は，各行に記された2つの階層の妥当性を比較し，
“左が妥当”／“どちらかといえば左が妥当”／“どちらともいえない”／“どちらかといえば右が妥当”／“右が妥当”のいずれかを回答するよう求められた．

階層の判定基準として，被験者には概念の階層関係のルールを示した．これは第4節で述べた概念と事例の関係と同様の考え方である．

\noindent
［被験者に示したルール］
\begin{itemize}
\item[1)]
事例の成員としての連続性：もし概念が階層関係であるならば，最下位概念の成員となる事例（本実験では形容詞）は最上位概念まで一貫して成員として出現している．
\item[2)]
概念の継承性：もし概念が階層関係であるならば，下位概念は上位概念から特徴を「継承」しており，下位概念は一方向的に上位概念の特徴を含意している．
\end{itemize}

\begin{figure}[t]
\begin{center}
\includegraphics{15-4ia4f3.eps}
\end{center}
\caption{被験者に提示した刺激と回答フォーム}
\end{figure}

ルール2は，以下の考察に基づいて設定した．即ち Cruse では次の様に述べている\cite{book_06}．もし，「Aはf(X)」であれば，「Aはf(Y)」が成り立つが，
その逆の，「Aはf(Y)」であっても，「Aはf(X)」が必ずしも成り立たない場合には，XがYの下位語で，YはXの上位語であるといえる．
たとえば，「太郎は犬です」が成り立てば必然的に「太郎は動物です」が成り立つが，「太郎は動物です」が成り立つ場合に，必ずしも「太郎は犬です」が成立するとは限らない．
上位から下位へ概念が並んでいるためには，上位から下位への一方向的な概念継承がみられる必要がある．

ルール1および 2によって，下位から上位への事例（共起形容詞）の出現状況と，上位から下位への概念の継承性とを考慮して，階層の妥当性を判定してもらったのである．
階層の妥当性に関し，Scheffe法によって数値化された値に基づき，自動生成で得られた階層とEDRの階層の間の平均値の有意差を，下記に示す検定量Tを用いて検定した．
\begin{equation}
T = \frac{\overline{x_1} - \overline{x_2}} {\sqrt{\frac{s_1^2}{N} + \frac{s_2^2}{N}}} 
\end{equation}
Nは対象とする形容詞の数である，とはMethod 1（自動構築）で得られた階層に対して各被験者について得られた数値の全被験者（20人）にわたる
平均と不偏分散である．とはMethod 2 (EDR) で得られた数値の全被験者にわたる平均と不偏分散である．


\subsection{実験結果}

図4に，$\overline{x_{1}}$（“◆”で示す），$\overline{x_{2}}$（“■”で示す）を標準誤差とともに示す．図中の横軸は形容詞ID，縦軸は計量化した値を表す．縦軸の値が大きいほど，
“より妥当である”ことを意味する．エラーバーはそれぞれの標準誤差を示す．エラーバーが長いほど被験者間のばらつきが大きいことを意味する．


\begin{figure}[b]
\begin{center}
\includegraphics{15-4ia4f4.eps}
\end{center}
\caption{COMMONとEDRの階層の全被験者にわたる平均値と標準誤差}
\end{figure}

\subsubsection{30形容詞に対するCOMMON-EDR階層ペア}


\noindent
［検定結果］
\begin{description}
\item[有意にCOMMON $>$ EDR] \mbox{} \\
 形容詞ID: 22, 26（30個中2個）
\item[有意にCOMMON $<$ EDR] \mbox{} \\
形容詞ID: 1, 2, 4, 7, 8, 9, 11, 16, 19, 20, 21, 23, 24, 25, 27, 29, 30（30個中17個）
\item[両Method間に有意差なし（ただしCOMMON $>$ EDR）] \mbox{} \\
形容詞ID: 3, 13, 14, 18, 28（30個中5個）
\item[両Method間に有意差なし（ただしCOMMON $<$ EDR）] \mbox{} \\
形容詞ID: 5, 6, 10, 12, 15, 17（30個中6個）
\end{description}

\noindent
［COMMON-EDR階層比較の考察］

本提案手法で自動生成 (COMMON) された階層がEDR階層より有意に良かった形容詞は2個であった．
一方，自動生成の階層よりもEDR階層の方が有意に良かった形容詞は17個であった．
また，両者の間に有意差がなかった形容詞は11個であった．例として形容詞IDを挙げるが，その形容詞IDに対する階層については付録に載せる．

本提案手法で得られた階層の方がEDR階層より良かった形容詞は，例えば，ID-22の 「肯定的な」に対する階層である．

本提案手法で得られた階層よりEDR階層の方が優位に良かった形容詞は，例えば，ID-7の「早い」に対する階層である．

両方に有意差がなかった形容詞は たとえば，ID-17の「甘美な」に対する階層である．

以上から，COMMONに関しては，本研究で提案した手法は，43\%（30個中13個）の形容詞に関しEDRと
同程度あるいはEDRより人間の直感にあう階層が生成できたことが示唆された．


\subsubsection{10形容詞に対するCSM-EDR階層比較}

\begin{figure}[b]
\begin{center}
\includegraphics{15-4ia4f5.eps}
\end{center}
\caption{CSMとEDRの階層の全被験者にわたる平均値と標準誤差}
\end{figure}


\noindent
［検定結果］
\begin{description}
\item[有意にCSM $>$ EDR] \mbox{} \\
形容詞ID: 無し（10個中0個）
\item[有意にCSM $<$ EDR] \mbox{} \\
形容詞ID: 1, 5, 6, 9, 10（10個中5個）
\item[両Method間に有意差なし（ただしCSM $>$ EDR）] \mbox{} \\
形容詞ID: 3, 4（10個中2個）
\item[両Method間に有意差なし（ただしCSM $<$ EDR）] \mbox{} \\
形容詞ID: 2, 7, 8（10個中3個）
\end{description}

\noindent
［CSM-EDR階層比較の考察］

CSMでのみ作られた階層では，EDR階層の方が有意によいと判定された形容詞は5個（10個中50\%）であり，
CSMの階層の方が有意によいと判定された形容詞は0個であった．また，CSM階層とEDR階層で有意差がないと判定された形容詞は5個（10個中50\%）であった．

EDR階層の方が有意によいと判定された階層は，ID-1, 5, 6, 9, 10の形容詞であったが，特に，ID-5, 10は，明確な有意差がみられる．
たとえば，ID-5の「狭い」の階層を付録に示す．

また，両手法間で有意差がなかった形容詞のうち，ID-4「開放的な」を付録に示す．

以上から，CSMに関しては，本研究で提案した手法は，50\%（10個中5個）の形容詞に関しEDRと有意差がない階層を生成したことが示唆された．



\subsubsection{ 10形容詞に対するOvlp-EDR階層比較}


\begin{figure}[b]
\begin{center}
\includegraphics{15-4ia4f6.eps}
\end{center}
\caption{OvlpとEDRの階層の全被験者にわたる平均値と標準誤差}
\end{figure}

\noindent
［検定結果］
\begin{description}
\item[有意にOvlp $>$ EDR] \mbox{} \\
形容詞ID: 無し（10個中0個）
\item[有意にOvlp $<$ EDR] \mbox{} \\
形容詞ID: 1, 2, 3, 4, 5, 6, 7, 8, 10（10個中9個）
\item[両Method間に有意差なし（ただしOvlp $>$EDR）] \mbox{} \\
形容詞ID: 無し（10個中0個）
\item[両Method間に有意差なし（ただしOvlp $<$ EDR）] \mbox{} \\
形容詞 ID: 9（10個中1個）
\end{description}

\noindent
［Ovlp-EDR階層比較の考察］ 


Ovlp-EDRの階層比較では，EDR階層の方が有意によいと判定された形容詞が10個中9個あった．
それに対し，Ovlpの階層とEDRの階層とで有意差がないと
判定された形容詞は，ID-9のわずか1個だけであった．

Ovlpの階層よりEDRの階層の方があきらかに有意によい階層としては，たとえば，ID-4「果敢な」に対する階層がある．
階層例は付録に付す．

両手法間で有意差のない階層（一つのみ）はID-9「不公平な」に対する階層である．階層例は付録に付す．

以上から，Ovlpに関しては，本研究で提案した手法は，10\%（10個中1個）の形容詞に関しEDRと同程度の階層を生成したことが示唆された．


\subsection{考察}

本実験では，概念階層関係が成立するための重要な条件である「事例の成員としての連続性」と「概念の継承性」の点から，提案手法の階層とEDR階層の優劣の程度に関して，
人間の判断を数値化することにより，統計的に検定した．
その結果，EDRの階層の方が，「事例の成員としての連続性」と「概念の継承性」の観点で，COMMON，CSM，Ovlp，のどの手法による階層よりも，概ね良いことがわかったが，
COMMONとCSMの階層においては，半分ほどはEDRの階層と同程度くらいであった．
特にOvlpの評価は，全体の90\%ほどもEDRの方が有意に良いという判定となり，かなり悪かった．

しかし，表1（第4節）で表層的な特徴からみると，CSM手法による階層と比較して悪い結果ではなかった．
ここで実験した自動構築手法の階層に共通して言えることであるが，特にOvlpで顕著にみられた原因があった．

では，その原因は何か．それを探るため，被験者のコメントを参考に分析した．
被験者は概して最下位概念と最上位概念との間に中間的な概念がないと，妥当性が低いと判断した．
つまり，ルールで提示した継承性が失われていると判定した．表1の「階層の長さ」をみるとわかるように，Ovlpはノードの深さが9と短い．
逆にCSMは，ノードの深さが13あり，これはほぼEDRのノードの深さと同じくらいである．短い階層を作るOvlpは，中間的なノードが作られていないと判断されたのである．
CSM階層をEDR階層と比較する場合にも，多かれ少なかれ，この判断が反映されていた．

上記の概念の継承性の問題で考えられるのは，概念数の不足があげられる．第4節の表1で示したように，CSM0.2は階層を構成している抽象名詞（本稿では概念に相当）は，
365語中325語で約90\%，Ovlp0.3は，365語中317語で86\%となっており，閾値設定によって，抽象名詞が大幅に削られているわけでない．
では，そもそも365語の名詞が不足なのかどうかについてであるが，365語の名詞は，新聞2年分から第3節で述べたパタン（「XというY」など）を使い
特定の意味関係（「具体事例とそれが属する概念」という意味関係）を抽出したものであり，データスパースネスの問題も考えられる．また，一つの目安としてEDRの形容詞の
概念数を調べると約2000強ほどある．365概念ではまだ不足していると考えられる．今後さらに抽出方法も含めデータを精査していきたい．

また，我々の手法で取り出した365語の抽象名詞は，質的に，形容詞の概念のラベルとして適当かどうかという問題もある．
この問題については，試験的に，我々が抽出した抽象的な名詞（本稿で概念と呼んでいるもの）とその形容詞集合の組をランダムサンプリングして18組用意し，
5人の被験者に，同じ形容詞集合に対するEDRの概念と比較評価してもらった．
この小規模な実験では，提示した形容詞集合に対してEDRの概念より我々が抽出した概念の方が適当という回答が多くみられ
（全90問（18組×5人）中57問，63\%），18組での小規模な実験の範囲ではよい感触を得ているが，さらに実験方法とその結果も含めさらに精査していきたいと考えている．
その他，人手でデータを取捨選択した際に，「具体事例とそれが属する概念」という関係以外の関係も含まれている可能性もあり，データを見直し対象外のものを除く必要があろう．

次に，継承性が低いと評価された階層について考察すると，形容詞の多義性と事例数の関係が問題として考えられる．
EDRに比べ明確に有意に悪い形容詞は，COMMONのID-1「ユニークな」ID-4「古い」，ID-7「早い」，ID-9「遅い」，ID-16「鋭い」ID-23「高い」である．
どれも基本的な抽象度の高い形容詞である．提案手法での自動階層では，多義的な語についてうまく階層を構築できていない可能性がある．

原因として考えられるのは，一つはそもそも多義の場合の概念をすべてコーパスから抽出しきれていない可能性である．
もう一つは，階層構築で考えられる問題点である．ある概念の事例集合に多義的な形容詞が1語しかない，つまり他に手がかりとなる事例がない場合，
概念間の包含関係の質的な判断を必要とする．たとえば，[背丈]にも[金額]にも「高い」「低い」だけが事例として出現している場合，[背丈]と[金額]の「高い」を区別する
必要がある．しかし，階層をみると，現状では，最上位レベルの概念と直接結合したり，多義の別の概念と結びついたり（たとえば，「高い」に対して[背丈]と[金額]が結びつく），
概念の継承性の評価が低いようである．今後の課題として，各概念の事例としての形容詞の網羅性と，事例が少ない概念間の
関係（特に事例が多義的な場合の概念間の関係）についての対応について考える必要がある．

自動抽出した語彙の評価方法には，他にも語義のあいまい性解消，情報検索などへの応用によって評価を行うことも考えられる．
それらの多角的な観点も含め，概念階層の評価方法についても今後，さらに検討していきたいと考える．



\section{今後の展望—類義関係と階層関係をとらえるために—}

第3節で取り出した言語データから形容詞概念を体系的にとらえるためには，階層関係と同時に類義関係も考慮する必要がある．
これまでに，形容詞と抽象的な名詞を類義関係によって自動分類する研究として，Kohonenの自己組織化神経回路網モデル (Self-Organizing map，SOM) を用いた
研究がある\cite{Article_28,Article_21}．Kohonenの自己組織化神経回路網モデルは，高次元入力をもつ2次元配列のノード（ニューロン）で構成され，
自己組織化によって高次元データを2次元空間に，その特徴を反映するように，非線形的に射影する．特徴は，得られる分布が可視的でまた連続的であるということである．
特に，連続的な分布という性質は，言葉の意味の連続性を反映できると考えられ，馬らの研究に用いられている．
出力される2次元平面は，意味的に類似性の高い名詞どうしが近くに配置され，意味的に類似性の低い名詞どうしが遠くに配置されるような，意味的類似性を距離とする
2次元表現である．馬らは出力される2次元平面をマップと呼んでいる．馬らの研究では，SOMの分類能力を多変量解析や階層型クラスタリング手法等と比較実験し，
その結果，他手法より劣らない，あるいは彼らのタスクに関してはむしろよい結果を得たと報告している．

しかし，提案されたSOMによる分類では，類義関係以外の意味関係は求めることができなかった．Kanzaki et~al. では，上位下位関係（包含関係）をSOMに導入する
実験を行っている\cite{Inproc_14}．この実験でSOMの入力データとなる単語の特徴ベクトルは，当該単語に対する全対象単語との包含関係値を多次元ベクトルに
したものである．つまり，この特徴ベクトルをSOMの入力とすることにより，類似した包含関係をもつ単語どうしが類義関係をもつことになる．SOMは通常，類義関係を
可視化するので，SOMに包含関係を導入した場合，出力されるマップは，上位下位関係が反映された方向性ある分布になるか，あるいは方向性の全くみられない
分布になるかの可能性が考えられる．包含関係を導入したSOMの分布は，評価方法が提案されていないためさらに検討する必要があるものの，抽象度が高い名詞から
抽象度の低い名詞へと方向性ある分布を示唆したものとなった．

SOMによるマップに，概念の階層関係が反映されれば，同じような上位下位関係をもつ概念が類義関係となって近くに分布することになり，
階層関係と類義関係を同時に反映した分類をえられる可能性がある．結果は，既存のシソーラスなどと比較して差異を考察すると共に，
形容詞側から，得られた概念体系に従って形容詞表現の様相をとらえていきたい．



\section{まとめ}

本研究では，将来的に実データに基づいた形容詞の観点からみた上位下位関係と類義関係をとらえるため，その一環として形容詞の概念の階層関係に着目し，
コーパスから取得した概念から階層を構築する方法と，妥当そうな階層を得るための評価について述べたものである．

階層の評価は，事例（形容詞）の各概念の成員としての連続性と概念の継承関係という観点から評価し，まず，収集した形容詞の出現状況や
構築された概念の表層的な面からと，心理実験でEDRとの比較を行う質的な面から評価した．

表層的な観点からの評価で，CSM，Ovlp，Freqの三つの手法と複数の閾値を組み合わせた階層の中で，CSMの手法で閾値0.2以上を使った階層と，
Ovlpの手法で閾値0.3以上を使った階層を外見的に妥当そうな階層として絞った．そして次のステップの心理実験で，EDR概念階層との比較評価の対象として採用した．

心理実験によるEDR概念階層との比較評価では，「概念の継承性」と「事例の成員としての連続性」という観点で，自動構築とEDRとで概念階層の優劣を判定してもらい
統計的に数値化した．その結果上記二つの観点からの評価では，EDRの階層の方が，COMMON（Ovlp，CSM，Freq共通），CSM，Ovlpのどの手法による階層よりも，
概ね，有意に良いことがわかったが，COMMONとCSMの階層においては，半分ほどはEDRの階層と同程度くらいであった．
自動生成の階層が既存辞書の階層に対して，その結果の半分弱の階層で問題を提起するという意味で，ベースラインとなる数値と考える．

自動階層の評価が低かった主な要因は，最下位概念と最上位概念との間に中間的な概念がないと，妥当性が低いと判断されたことであった．
原因としては，概念数の不足，形容詞の概念ラベルの妥当性，形容詞の多義性などが考えられる．これらの点をさらに精査し，今後，SOMによる概念分布に対応させ，
類義関係とあわせタクソノミー的な構造として，形容詞の概念体系をとらえていきたい．

オントロジーは必ずしも木構造ではないかもしれないが，階層関係と類義関係については，それを計算する尺度が利用できることもあり，
最初にこれらの関係を明らかにしていきたいと考える．



\bibliographystyle{jnlpbbl_1.3}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Alonge, Bertagna, Calzolari, Roventini, \BBA\
  Zampolli}{Alonge et~al.}{2000}]{Inproc_01}
Alonge, A., Bertagna, F., Calzolari, N., Roventini, A., \BBA\ Zampolli, A.
  \BBOP 2000\BBCP.
\newblock \BBOQ Encoding information on adjectives in a lexical-semantic net
  for computational applications\BBCQ\
\newblock In {\Bem the 1st Conference of the North American Chapter of the
  Association for Computational Linguistics (ACL)}.

\bibitem[\protect\BCAY{安西}{安西}{1989}]{Book_02}
安西祐一郎 \BBOP 1989\BBCP.
\newblock \Jem{岩波講座ソフトウエア科学　認識と学習，第16巻}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{Berland \BBA\ Charniak}{Berland \BBA\
  Charniak}{2000}]{Inproc_04}
Berland, M.\BBACOMMA\ \BBA\ Charniak, E. \BBOP 2000\BBCP.
\newblock \BBOQ Finding Parts in Very Large Corpora\BBCQ\
\newblock In {\Bem 38th Annual Meeting of the Association for Computational
  Linguistics (ACL)}.

\bibitem[\protect\BCAY{Biemann}{Biemann}{2005}]{Article_03}
Biemann, C. \BBOP 2005\BBCP.
\newblock \BBOQ Ontology Learning from Text: A Survey of Methods\BBCQ\
\newblock {\Bem LDV-Forum}, {\Bbf 20}  (2), \mbox{\BPGS\ 75--93}.

\bibitem[\protect\BCAY{Caraballo}{Caraballo}{1999}]{Inproc_05}
Caraballo, A.~S. \BBOP 1999\BBCP.
\newblock \BBOQ Automatic Acquisition of a Hypernym-Labeled Noun Hierarchy from
  Text\BBCQ\
\newblock In {\Bem 37th Annual Meeting of the Association for Computational
  Linguistics (ACL)}.

\bibitem[\protect\BCAY{Cruse}{Cruse}{1986}]{book_06}
Cruse, D.~A. \BBOP 1986\BBCP.
\newblock {\Bem Lexical Semantics}.
\newblock Cambridge University Press.

\bibitem[\protect\BCAY{Hagita \BBA\ Sawaki}{Hagita \BBA\
  Sawaki}{1995}]{Inproc_08}
Hagita, N.\BBACOMMA\ \BBA\ Sawaki, M. \BBOP 1995\BBCP.
\newblock \BBOQ Robust Recognition of Degraded Machine-Printed Characters using
  Complimentary Similarity Measure and Error-Correction Learning\BBCQ\
\newblock In {\Bem the SPIE---The International Society for Optical
  Engineering, 2442}.

\bibitem[\protect\BCAY{Hearst}{Hearst}{1992}]{Inproc_09}
Hearst, A.~M. \BBOP 1992\BBCP.
\newblock \BBOQ Automatic Acquisition of Hyponyms from Large Text Corpora\BBCQ\
\newblock In {\Bem the 14th International Conference on Computational
  Linguistics}.

\bibitem[\protect\BCAY{Hindle}{Hindle}{1990}]{Inproc_10}
Hindle, D. \BBOP 1990\BBCP.
\newblock \BBOQ Noun Classification From Predicate-Argument Structures\BBCQ\
\newblock In {\Bem the 28th Annual Meeting of the Association for Computational
  Linguistics (ACL)}.

\bibitem[\protect\BCAY{Kanzaki, Ma, Yamamoto, \BBA\ Isahara}{Kanzaki
  et~al.}{2004}]{Inproc_14}
Kanzaki, K., Ma, Q., Yamamoto, E., \BBA\ Isahara, H. \BBOP 2004\BBCP.
\newblock \BBOQ Construction of an Objective Hierarchy of Abstract Concepts via
  Directional Similarity\BBCQ\
\newblock In {\Bem 21st International Conference on Computational Linguistics
  (COLING)}.

\bibitem[\protect\BCAY{神崎}{神崎}{1997}]{Article_12}
神崎享子 \BBOP 1997\BBCP.
\newblock \JBOQ 連体修飾関係を結ぶ形容詞類と名詞\JBCQ\
\newblock \Jem{計量国語学}, {\Bbf 21}  (2), \mbox{\BPGS\ 53--68}.

\bibitem[\protect\BCAY{神崎\JBA 井佐原}{神崎\JBA 井佐原}{1999}]{Article_13}
神崎享子\JBA 井佐原均 \BBOP 1999\BBCP.
\newblock \JBOQ 形容詞類の連体用法にみられる連用的な意味\JBCQ\
\newblock \Jem{計量国語学}, {\Bbf 22}  (2), \mbox{\BPGS\ 51--65}.

\bibitem[\protect\BCAY{国立国語研究所}{国立国語研究所}{1964}]{book_16}
国立国語研究所 \BBOP 1964\BBCP.
\newblock \Jem{分類語彙表}.
\newblock 秀英出版.

\bibitem[\protect\BCAY{Lin \BBA\ Pantel}{Lin \BBA\ Pantel}{2002}]{Inproc_18}
Lin, D.\BBACOMMA\ \BBA\ Pantel, P. \BBOP 2002\BBCP.
\newblock \BBOQ Concept Discovery from Text\BBCQ\
\newblock In {\Bem the 19th International Conference on Computational
  Linguistics(COLING)}.

\bibitem[\protect\BCAY{馬\JBA 神崎\JBA 村田\JBA 内元\JBA 井佐原}{馬\Jetal
  }{2001}]{Article_21}
馬青\JBA 神崎享子\JBA 村田真樹\JBA 内元清貴\JBA 井佐原均 \BBOP 2001\BBCP.
\newblock \JBOQ 日本語名詞の意味マップの自己組織化\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 42}  (10), \mbox{\BPGS\ 2379--2391}.

\bibitem[\protect\BCAY{Manning \BBA\ Sh{\"u}tze}{Manning \BBA\
  Sh{\"u}tze}{1999}]{Book_22}
Manning, C.~D.\BBACOMMA\ \BBA\ Sh{\"u}tze, H. \BBOP 1999\BBCP.
\newblock {\Bem Foundations of Statistical Natural language Processing}.
\newblock The MIT Press.
\newblock pp.~298--303.

\bibitem[\protect\BCAY{丸元\JBA 白土\JBA 井佐原}{丸元\Jetal
  }{2005}]{Article_23}
丸元聡子\JBA 白土保\JBA 井佐原均 \BBOP 2005\BBCP.
\newblock \JBOQ
  動詞待遇表現に対する丁寧さの印象に関する定量的分析—接頭辞オを用いた表現と接
頭辞ゴを用いた表現との比較—\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (5), \mbox{\BPGS\ 71--90}.

\bibitem[\protect\BCAY{益岡}{益岡}{1994}]{Book_19}
益岡隆志 \BBOP 1994\BBCP.
\newblock \Jem{名詞修飾節の接続形式—内容節を中心に—.
  田窪行則編『日本語の名詞修飾表現』}.
\newblock くろしお出版.
\newblock pp.~5--27.

\bibitem[\protect\BCAY{Medin \BBA\ Goldstone}{Medin \BBA\
  Goldstone}{1990}]{book_24}
Medin, D.~L.\BBACOMMA\ \BBA\ Goldstone, R.~L. \BBOP 1990\BBCP.
\newblock {\Bem Concept in Eysenck, M. W. Ed., The Blackwell Dictionary of
  Cognitive psychology, \textup{Cambridge, MA: Basic Blackwell Inc}}.

\bibitem[\protect\BCAY{根本}{根本}{1969}]{Book_26}
根本今朝男 \BBOP 1969\BBCP.
\newblock \JBOQ 「が格」の名詞と形容詞とのくみあわせ\JBCQ\
\newblock \Jem{国立国語研究所報告書，電子計算機のための国語研究II}.

\bibitem[\protect\BCAY{Pantel \BBA\ Ravichandran}{Pantel \BBA\
  Ravichandran}{2004}]{Inproc_27}
Pantel, P.\BBACOMMA\ \BBA\ Ravichandran, D. \BBOP 2004\BBCP.
\newblock \BBOQ Automatically Labeling Semantic Classes\BBCQ\
\newblock In {\Bem Human Language Technology/North American Association for
  Computational Linguistics (HLT/NAACL)}.

\bibitem[\protect\BCAY{Riloff \BBA\ Shepherd}{Riloff \BBA\
  Shepherd}{1997}]{Inproc_29}
Riloff, E.\BBACOMMA\ \BBA\ Shepherd, J. \BBOP 1997\BBCP.
\newblock \BBOQ A corpus based approach for building semantic lexicons\BBCQ\
\newblock In {\Bem the Second Conference on Empirical Methods in Natural
  Language Processing (EMNLP)}.

\bibitem[\protect\BCAY{Ritter \BBA\ Kohonen}{Ritter \BBA\
  Kohonen}{1989}]{Article_28}
Ritter, H.\BBACOMMA\ \BBA\ Kohonen, T. \BBOP 1989\BBCP.
\newblock \BBOQ Self-Organizing Semantic Maps\BBCQ\
\newblock {\Bem Biological Cybernetics}, {\Bbf 61}, \mbox{\BPGS\ 241--254}.

\bibitem[\protect\BCAY{Sawaki, Hagiga, \BBA\ Ishii}{Sawaki
  et~al.}{1997}]{Inproc_31}
Sawaki, M., Hagiga, N., \BBA\ Ishii, K. \BBOP 1997\BBCP.
\newblock \BBOQ Robust Character Recognitionof Gray-Scaled Images with
  Graphical Designs and Noise\BBCQ\
\newblock In {\Bem the International Conference on Document Analysis and
  Recognition. IEEE. Computer Sciety}.

\bibitem[\protect\BCAY{Scheffe}{Scheffe}{1952}]{Article_32}
Scheffe, H. \BBOP 1952\BBCP.
\newblock \BBOQ An analysis of variance for paired comparison\BBCQ\
\newblock {\Bem Journal of the American Statistical Association}, {\Bbf 47},
  \mbox{\BPGS\ 381--400}.

\bibitem[\protect\BCAY{高橋}{高橋}{1975}]{Article_34}
高橋太郎 \BBOP 1975\BBCP.
\newblock \JBOQ 文中にあらわれる所属関係の種々相\JBCQ\
\newblock \Jem{国語学}, {\Bbf 103}, \mbox{\BPGS\ 1--16}.

\bibitem[\protect\BCAY{寺村}{寺村}{1991}]{Book_35}
寺村秀夫 \BBOP 1991\BBCP.
\newblock \Jem{日本語のシンタクスと意味 III}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{Thelen \BBA\ Riloff}{Thelen \BBA\
  Riloff}{2002}]{Inproc_36}
Thelen, M.\BBACOMMA\ \BBA\ Riloff, E. \BBOP 2002\BBCP.
\newblock \BBOQ A Bootstrapping Method for Learning Semantic Lexicons using
  Extraction Pattern Contexts\BBCQ\
\newblock In {\Bem the 2002 Conference on Empirical Methods in Natural Language
  Processing (EMNLP)}.

\bibitem[\protect\BCAY{Yamamoto, Kanzaki, \BBA\ Isahara}{Yamamoto
  et~al.}{2005}]{Inproc_39}
Yamamoto, E., Kanzaki, K., \BBA\ Isahara, H. \BBOP 2005\BBCP.
\newblock \BBOQ Extraction of Hierarchies Based on Inclusion of Co-occurring
  Words with Frequency Information\BBCQ\
\newblock In {\Bem 19th International Joint Conference on Artificial
  Intelligence (IJCAI)}.

\bibitem[\protect\BCAY{山本\JBA 神崎\JBA 井佐原}{山本\Jetal
  }{2006}]{Article_38}
山本英子\JBA 神崎享子\JBA 井佐原均 \BBOP 2006\BBCP.
\newblock \JBOQ 出現状況の包含関係による語彙の階層構造の構築\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 47}  (6), \mbox{\BPGS\ 1872--1883}.

\bibitem[\protect\BCAY{山本\JBA 梅村}{山本\JBA 梅村}{2002}]{Article_37}
山本英子\JBA 梅村恭司 \BBOP 2002\BBCP.
\newblock \JBOQ コーパス中の一対多関係を推定する問題における類似尺度\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 9}  (2), \mbox{\BPGS\ 46--75}.

\end{thebibliography}

\appendix

\noindent
5.4.1. 30形容詞に対するCOMMON-EDR階層ペア \\
5.4.2. 10形容詞に対するCSM-EDR階層比較\\
5.4.3. 10形容詞に対するOvlp-EDR階層比較

上記3節に挙げた形容詞の階層を以下に示す．



\section{5.4.1. 30形容詞に対するCOMMON-EDR階層ペア}
\noindent
［自動階層の方がEDR階層より良いと判定された形容詞の階層］

\noindent
ID-22 肯定的な
\begin{description}
\item[自動階層：]\mbox{}\\
こと→面1→傾向→見方→評価
\item[EDR階層：]\mbox{}\\
概念(3aa966)→事象(30f7e4)→行為(30f83e)→対象行為(444dd) →ものを対象とする行為(444dd9)→情報の移動(30f832)→
情報の受信(3f96e7)→知る(30f876)→認知主体と認知対象との認知的距離減少(3f972c)
\end{description}

\noindent
［EDR階層の方が有意に良いと判定された形容詞の階層］

\noindent
ID-7 早い
\begin{description}
\item[自動階層：]\mbox{}\\
こと→時→速度→時刻
\item[EDR階層：]\mbox{}\\
概念(3aa966)→時(30f776)→時間点(3f9882)→
基準時点の前後の時(444da3)→ある時間点よりも前の時点(444cc3)→基準になる時刻や時期より前であること(3cf6d9)
\end{description}

\noindent
［両方に有意差がなかった形容詞の階層］

\noindent
ID-17 甘美な
\begin{description}
\item[自動階層：]\mbox{}\\
こと→面1→イメージ→感覚→雰囲気→空気→気配→魅惑
\item[EDR階層：]\mbox{}\\
概念(3aa966)→事象(30f7e4)→状態(3aa963)→性状・性向(3f9871)→性状(444e60)→人のありさま(444db3)→人の気持ち(30f7b7)→
人の気持ちの様子(3f98bd)→自分自身の感情や心境(444ded)→愉快・不愉快(30f961)→良い気持(0e89db)→心地よい(3cf426)
\end{description}



\section{5.4.2. 10形容詞に対するCSM-EDR階層比較}

\noindent
［EDR階層の方が有意によいと判定された形容詞の階層］

\noindent
ID-5 狭い
\begin{description}
\item[自動階層：]\mbox{}\\
こと→方→空間→面積
\item[EDR階層：]\mbox{}\\
概念(3aa966)→事象(30f7e4)→状態(3aa963)→性状・性向(3f9871)→事物の属性(444db1)→具体物の属性(3aa962)→
具体物の空間的属性(444ce7)→形の値(444ce8)→形の広狭(3f9876)→空間的に小さいさま(1e88a8)
\end{description}

\noindent
［両手法間で有意差がなかった形容詞の階層］

\noindent
ID-4　開放的な
\begin{description}
\item[自動階層：]\mbox{}\\
こと→面1→イメージ→印象→態度→人柄→気質→気風→気性
\item[EDR階層：]\mbox{}\\
概念(3aa966)→*事象(30f7e4)→状態(3aa963)→性状・性向(3f9871)→事物の属性(444db1)→人間の属性(3aa961)→人の性格や態度(3f98c9)→
態度や性格の値(444ce3)→善良(30f96d)→かくしだてをせず，あけっぴろげであること(3cf4b7)→かくしだてをすることなく，あけっぴろげであるさま(3ce57e)
\end{description}



\section{5.4.3.   10形容詞に対するOvlp-EDR階層比較}

\noindent
［EDR階層の方が有意によいと判定された形容詞の階層］

\noindent\
ID-4果敢な
\begin{description}
\item[自動階層：]\mbox{}\\
こと→性格→勇気
\item[EDR階層：]\mbox{}\\
概念(3aa966)→事象(30f7e4)→状態(3aa963)→性状・性向(3f9871)→事物の属性(444db1)→人間の属性(3aa961)→人の性格や態度(3f98c9)→
態度や性格の値(444ce3)→豪胆・臆病(30f96f)→勇敢(30f96b)→思い切ったことをすること(3cefc5)
\end{description}

\noindent
［両手法間で有意差がなかった形容詞の階層］

\noindent
ID-9不公平な
\begin{description}
\item[自動階層：]\mbox{}\\
こと→関係→差別
\item[EDR階層：]\mbox{}\\
概念(3aa966)→事象(30f7e4)→状態(3aa963)→性状・性向(3f9871)→さまざまな属性(444d17)→いろいろな抽象物の属性(444d27)→かたよりがあって平等でないようす(3cfcd6)
\end{description}


\begin{biography}
\bioauthor{神崎　享子}{
1994年早稲田大学大学院文学研究科日本語日本文化専攻修士課程修了．
1998年同大学院文学研究科日本語日本文化専攻博士課程単位取得後満期退学．
2001年 神戸大学大学院自然科学研究科修了．博士（学術）．
1998年〜2005年郵政省通信総合研究所．
2005年〜独立行政法人情報通信研究機構．
現在，独立行政法人情報通信研究機構主任研究員．
自然言語処理，言語学の研究に従事．
言語処理学会，計量国語学会，日本言語学会，日本語学会，会員．
}
\bioauthor{馬　　　青}{
1983年北京航空航天大学自動制御学科卒業．
1987年筑波大学大学院修士課程理工学研究科修了．
1990年同大学院博士課程工学研究科修了工学博士．
1990--19931年株式会社小野測器勤務．
1993年郵政省通信総合研究所入所．
1994年同所主任研究官．
2003年龍谷大学理工学部教授．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，電子情報通信学会，日本神経回路学会，各会員
}
\bioauthor{山本　英子}{
1998年豊橋技術科学大学大学院工学研究科情報工学専攻修士課程修了．
2002年同大学大学院工学研究科電子・情報工学専攻博士後期課程修了．博士（工学）．
2002年--2007年10月独立行政法人情報通信研究機構専攻研究員．
現在，神戸大学工学研究科プロジェクト奨励研究員．
自然言語処理の研究に従事．
言語処理学会，情報処理学会各会員．
}
\bioauthor{白土　　保}{
1999年電気通信大学博士（工学）．
情報通信研究機構知識創成コミュニケーション研究センター推進室研究マネージャ．専門分野は，言語心理，音楽音響，感性情報処理．言語処理学会，電子情報通信学会，日本音響学会各会員．
}
\bioauthor{井佐原　均}{
1980年京都大学大学院工学研究科電気工学専攻修士課程修了．博士（工学）．
1980年通商産業省工業技術院電子技術総合研究所入所．
1995年郵政省通信総合研究所知的機能研究室長．
現在，独立行政法人情報通信研究機構上席研究員．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，日本認知科学会，人工知能学会各会員．
}


\end{biography}


\biodate


\end{document}
