<?xml version="1.0" ?>
<root>
  <jtitle>トーナメントモデルを用いた日本語係り受け解析</jtitle>
  <jauthor>岩立将和浅原正幸松本裕治</jauthor>
  <jabstract>日本語係り受け解析においては，工藤らの相対的な係りやすさを考慮した日本語係り受け解析モデルが，決定的解析アルゴリズムや文脈自由文法のパージングアルゴリズムに基づく手法を上回る精度を示している．決定的解析手法では係り先候補文節を同時に一つしか考慮しないが，工藤らの相対モデルではすべての係り先候補文節間の選択選好の強さをlog-linearモデルで推定している．これに対し本稿では，同時に対象とする係り先候補文節を二候補に限定し，選択選好を二つの候補同士の対戦からなるトーナメントで直接表現したモデルを提案する．京大コーパスVersion4.0を使用した実験において，提案手法は従来手法を上回る精度を示した．</jabstract>
  <jkeywords>日本語係り受け解析，構文解析，トーナメントモデル</jkeywords>
  <section title="はじめに">多言語依存構造解析器に関して，CoNLL-2006CoNLL-2006やCoNLL-2007CoNLL-2007といった評価型SharedTaskが提案されており，言語非依存な解析アルゴリズムが多く提案されている．これらのアルゴリズムは対象言語の様々な制約---交差を許すか否か，主辞が句の先頭にあるか末尾にあるか---に適応する必要がある．この問題に対し様々な手法が提案されている．EisnerEisner:1996は文脈自由文法に基づくアルゴリズムを提案した．山田らYamada:2003，およびNivreらNivre:2003,Nivre:2004はshift-reduce法に基づくアルゴリズムを提案した．Nivreらはのちに，交差を許す言語に対応する手法を提案したNivre:2005．McDonaldらMcDonald:2005bはChu-Liu-Edmondsアルゴリズム（以下「CLEアルゴリズム」）Chu:1965,Edmonds:1967を用いた，最大全域木の探索に基づく手法を提案した．多くの日本語係り受け解析器は入力として文節列を想定している．日本語の書き言葉の係り受け構造に関する制約は他の言語よりも強く，文節単位には左から右にしか係らず，係り受け関係は非交差であるという制約を仮定することが多い．図は日本語の係り受け構造の例である．ここで係り受け関係は，係り元から係り先に向かう矢印で表される．文(a)は文(b)と似ているが，両者の構文構造は異なる．特に「彼は」と「食べない」に関して，(a)は直接係り受け関係にあるのに対して，(b)ではそうなっていない．この構文構造の違いは意味的にも，肉を食べない人物が誰であるかという違いとして現れている．日本語係り受け解析では，機械学習器を用いた決定的解析アルゴリズムによる手法が，確率モデルを用いた，CKY法等の文脈自由文法の解析アルゴリズムによる手法よりも高精度の解析を実現している．工藤らKudo:2002はチャンキングの段階適用（cascadedchunking，以下「CCアルゴリズム」）を日本語係り受け解析に適用した．颯々野Sassano:2004はShift-Reduce法に基づいた時間計算量O(n)のアルゴリズム（以下「SRアルゴリズム」）を提案している．これらの決定的解析アルゴリズムは入力文を先頭から末尾に向かって走査し，係り先と思われる文節が見つかるとその時点でそこに掛けてしまい，それより遠くの文節は見ないので，近くの文節に係りやすいという傾向がある．節で述べるように，我々はCLEアルゴリズムを日本語係り受け解析に適用した実験を行ったが，その精度は決定的解析手法に比べて同等あるいは劣っていた．実際CLEアルゴリズムは，左から右にしか係らないかつ非交差という日本語の制約に合っていない．まず全ての係り関係の矢印は左から右に向かうので，各ステップにおいて係り受け木にサイクルができることはない．加えて，CLEアルゴリズムは交差を許す係り受け解析を意図しているので，日本語の解析の際には非交差のチェックをするステップを追加しなければならない．工藤らKudo:2005jは候補間の相対的な係りやすさ（選択選好性）に基づいたモデルを提案した．このモデルでは係り先候補集合から最尤候補を選択する問題を，係り元との選択選好性が最大の候補を選択する問題として定式化しており，京大コーパスVersion3.0に対して最も高い精度を達成している．決定的手法においては候補間の相対的な係りやすさを考慮することはせず，単に注目している係り元文節と係り先候補文節が係り受け関係にあるか否かということのみを考える．また，この手法は，先に述べたCLEアルゴリズムに，左から右にのみ掛ける制約と非交差制約を導入した方法を拡張したものになっている．上にあげた手法はいずれも，係り元とある候補の係りやすさを評価する際に他の候補を参照していない．これに対し内元らUchimoto:2000は，（係り元，係り先候補）の二文節が係るか否かではなく，二文節の間に正解係り先がある・その候補に係る・その候補を越えた先に正解係り先がある，の3クラスとして学習し，解析時には各候補を正解と仮定した場合の確率が最大の候補を係り先として選択する確率モデルを提案している．また，金山らKanayama:2000はHPSGによって係り先候補を絞り込み，さらに，三つ以下の候補のみを考慮して係り受け確率を推定する手法を提案している．本稿では，飯田らIida:2003が照応解析に用いたトーナメントモデルを日本語係り受け解析に適用したモデルを提案する．同時に係り元と二つの係り先候補文節を提示して対決させるという一対一の対戦をステップラダートーナメント状に組み上げ，最尤係り先候補を決定するモデルである．2節ではどのようにしてトーナメントモデルを日本語係り受け解析に適用するかについて説明する．3節ではトーナメントモデルの性質について関連研究と比較しながら説明する．4節では評価実験の結果を示す．5節では我々の現在の仕事および今後の課題を示し，6章で本研究をまとめる．</section>
  <section title="トーナメントモデル">トーナメントモデルは飯田らIida:2003が照応解析のために提案したモデルである．このモデルでは，与えられた照応表現の先行詞候補集合から二つを提示し，そのどちらがより先行詞らしいかをSVMなどの二値分類器を用いて判断するという勝ち抜き戦を行っていくことで，最尤先行詞候補を選択する．日本語係り受け解析も，ある係り元文節の複数の係り先候補の中から最尤候補を一つ選出する問題であるから，照応解析における最尤先行詞候補選出と類似した問題である．このトーナメントモデルを，日本語の係り受け構造の制約を考慮しつつ日本語係り受け解析に適用することを考える．図(b)の文の解析において，「彼は」の係り先を同定するトーナメントの例を図に示す．左から右にしか係らない制約に従うと，係り先候補集合は係り元より右側に位置する四文節（「肉を」，「食べない」，「人と」，「結婚した」）である．このトーナメントは，候補集合の中からまず「肉を」と「食べない」を戦わせ，次にその勝者と「人と」を戦わせ，最後に第二試合の勝者と「結婚した」を戦わせる，ステップラダートーナメントである．このトーナメントの結果，最終的な勝者である「結婚した」が最尤係り先候補として選ばれ，「彼は」の係り先文節として認定される．図では明記していないが，非交差制約をトーナメントモデルに導入するのは容易である．係り先候補集合から最尤候補を選択する際に，交差を生じない候補のみを候補集合として考えればよい．以下に具体的なアルゴリズムを示す．</section>
  <subsection title="訓練事例生成アルゴリズム">このアルゴリズムは図に示すように，全ての文節を係り元文節として見ていき，各係り元文節について，正解係り先候補とその他の全ての係り先候補との組について訓練事例を生成する．訓練事例生成の際は非交差制約を考慮せず，係り元の右側に位置するすべての文節を係り先候補として扱う．トーナメントモデルでは二値分類器で係り先を判定するため，左右いずれかの文節が正解係り先となる事例のみを生成する．このアルゴリズムに図に示した文を入力すると，表のような訓練事例が生成される．決定的手法や相対モデルなど，同時に一つの候補のみを見て（係り元，候補）の形の訓練事例を生成するモデルでは，「係り元：彼は，候補：食べない，クラスラベル：係る」と「係り元：彼は，候補：食べない，クラスラベル：係らない」というクラスラベルの異なる二つの矛盾した訓練事例が生成されるが，トーナメントモデルではこれらを区別し矛盾のない訓練事例を生成できる．</subsection>
  <subsection title="解析アルゴリズム">CCアルゴリズムやSRアルゴリズムには，訓練事例生成と解析のアルゴリズムを同一にしなければならないという制限があるが，トーナメントモデルにはそのような制限はない．そのためトーナメントモデルの解析アルゴリズムには主に，文頭に近い文節から係り先を同定していくか文末に近い文節から係り先を同定していくか，トーナメントをどう組むか，交差を許すか否か，といった自由度がある．図は，文末に近い文節から係り先を同定し，トーナメントの組み方としては図のような文頭に近い候補から先に戦わせるステップラダートーナメントとし，非交差制約を考慮する解析アルゴリズムである．同定順が文末から文頭であるため，注目している係り元より右側の係り受け関係はすべて決まっている．headは各文節の係り先を格納する配列であるとともに，非交差制約に違反しない候補をつなぐ線形リストの役目も果たしている．</subsection>
  <section title="議論">以下でトーナメントモデルの性質について先行研究と比較しながら論じる．</section>
  <subsection title="文脈の識別性">CCアルゴリズムとSRアルゴリズムは，二文節つまり一つの係り元文節と一つの係り先文節のみを参照してアクション（掛けるか掛けないか）を選択する．だが，たとえば図における「彼は」と「食べない」のように，ある二文節が係り受け関係にあるか否かが文脈に依存する場合がある．決定的解析アルゴリズムや相対モデルのような二文節のみを見るモデルでは，文脈素性によらなければこの二つの場合を識別することができない．なお，文脈素性とは，係り元文節と係り先候補文節自身以外の文節に関する素性のこととする．具体的にはたとえば，候補文節に隣接する左右の文節の情報（周辺文節素性）や，解析済みの係り受け関係に関する素性（動的素性）などである．動的素性が利用できるのは，ある係り元文節の係り先の同定を終えてから別の係り元文節の係り先の同定を行うようなモデルに限られる．日本語係り受け解析においては周辺文節素性はあまり使われていない．同時に参照する文節数に基づく分類によると，トーナメントモデルは三文節つまり一つの係り元文節と二つの係り先候補文節を同時に見る三つ組モデルということができる．三つ組モデルでは二つの候補のどちらがより係り先としてふさわしいかを直接比較し，最適な係り先を決定することができるので，文脈の識別性は二つ組モデルより高い．再び図の文について考えてみると，(b)では「彼は」は「食べない」に係っていない．これは，より適切な係り先「結婚した」が「食べない」の右に存在するからである．二つ組モデルにおいて，二文節の外に「結婚した」が存在することは動的素性によって検出できる可能性があるが，確実ではないので，二つ組モデルは「結婚した」が存在することを知らないまま係り先を選ばなければならないかもしれない．なお，金山らも一つの係り元文節と二つの係り先候補文節を同時に見るモデルを三つ組モデルと呼んでいる．トーナメントモデルと金山らのモデルは，複数の候補を同時に提示することで〜節の性質を備えているという点で共通している．両手法の主な相違点は，k個の係り先候補集合から一つの係り先を選ぶという問題を二つ（金山モデルでは二つまたは三つ）の候補から最も係り先として適切なものを選ぶという問題に落とし込む方法として，金山モデルではHPSGおよびヒューリスティック，トーナメントモデルではトーナメントを用いている点である．提案手法はHPSGのような人手による文法規則を用いる必要がない．</subsection>
  <subsection title="文中における相対的な位置の表現">三つ組モデルにおける二つの候補のうち係り元に近い方を「左候補」，遠い方を「右候補」と区別して呼ぶことにする．そうすると，トーナメントモデルの対戦においては係り元，左候補，右候補がこの順で文頭から文末の方向に並んでいることが保証されている．先行研究では，係り元と候補との間の距離（絶対距離）を1or2-5or6+といったバケツ素性で表現しており，後述のようにトーナメントモデルでもこの素性を使用している．絶対距離素性は相対位置を表す素性の一種であるとも考えられるが，ある候補との距離が1であるか否かの情報は重要だとしても，日本語は語順自由なので距離の絶対値はあまり重要ではない．たとえば図(b)の文において「彼は」を係り元とするとき，候補「食べない」と「結婚した」との距離はそれぞれ2と4であるため，どちらも「2-5」のバケツに分類される．したがって文脈素性を用いない場合，二つ組モデルはこの二つの候補のどちらが係り元により近い位置にあるかという相対的な位置関係を認識することができない．決定的解析アルゴリズムは先に相対的に近い対から判定するため，暗に相対位置の情報を用いている．これに対し提案手法は，相対位置をより直接的に，ラベルとして表現している．また，相対位置の認識は，ある種の格要素が他の格要素より近くに現れやすいといった傾向の学習にも有用と考えられる．たとえば目的語は他の要素より述語の近くに置かれやすい．決定的解析アルゴリズムは係り元に近い候補を選択しやすいため，工藤らKudo:2005jが指摘しているように，決定的解析アルゴリズムは長距離の係り関係を正しく解析するのが苦手である．その理由としては，節および節のような文脈識別能力が低いことが大きいと考えられる．なお，正解係り先は係り元に近いことが多いので，近い候補を選択しやすいという傾向のために生じる解析誤りはそれほど多くない．</subsection>
  <subsection title="選択選好">相対モデルKudo:2005jは係り先候補間の選択選好性の強さを直接学習し，log-linearモデルの尤度として全順序にエンコードする．CLEアルゴリズムを用いたMcDonaldらMcDonald:2005bの手法では，選択選好性をMIRACrammer:2003とよばれるパーセプトロンアルゴリズムで学習する．これに対してトーナメントモデルは候補間の一対一対戦のトーナメントで選択選好性を学習するため，全順序ではなく半順序の学習を行っている．相対モデルやMcDonaldらの手法が全候補を識別モデルで独立して見るのに対し，トーナメントモデルではどの候補がより適切かを前の試合の勝者と新しい候補で評価する．前の試合の勝者はそれ以前の候補をすべて倒しているので，新しい候補が前の試合の勝者を倒したということは，半順序の束において先行した全ての候補より係り先としてふさわしいということである．このことから，トーナメントモデルは全ての候補を独立に見る手法より選択選好性に関してより豊かな情報を学習することができる可能性がある．</subsection>
  <subsection title="文節の挿入に対する頑健性">日本語においては様々な文節が任意の位置に挿入されることがある．その要因としては，かき混ぜ構文，ゼロ代名詞，任意格等がある．CCアルゴリズムは距離の短い係り受け関係から決定していくという戦略をとっている．ある挿入文節の係り先が，あるcascadedchunkingステップにおいて決定されると，それ以降のcascadedchunkingステップではその挿入文節は無視される．たとえば，「肉をあまり食べない」と「肉を食べない」という文について考える．CCアルゴリズムではまず各文節が隣の文節に係るかどうかをチェックし係り先が決まった文節を徐々に取り除いていくので，前者の文は最初のステップで「あまり」が隣の「食べない」に係ると解析され，次のステップでは「あまり」が取り除かれて「肉を食べない」という後者の文と同じ形になる．したがって，前者の文が訓練データに出現していれば後者の文も正しく解析できることを期待できるし，逆も然りである．このように，文節の挿入の影響を受けないようにする仕組みが解析器の文節の挿入に対する頑健性を実現している．トーナメントモデルにもこれと同様の仕組みがある．一文あるいは二文の訓練データから表~の事例が生成されたなら，「彼は肉をあまり食べない」という文の解析において「彼は」の係り先を同定する際にまず「あまり」と「食べない」と戦わせて「あまり」を敗退させれば，「彼は肉を食べない」という文の解析と同様の状況になる．このようにうまくトーナメントを組むことができれば，挿入文節が最終決定を妨害しないような解析をすることができると考えられる．</subsection>
  <section title="評価実験"/>
  <subsection title="設定">我々はトーナメントモデル，CCアルゴリズムKudo:2002，SRアルゴリズムSassano:2004，CLEアルゴリズムMcDonald:2005bをSVMを用いて実装し，係り受け正解率と文正解率を京大コーパスVersion4.0を用いて評価した．係り受け正解率とは係り先文節を正しく同定できた文節の割合であり，文正解率とは文中の全ての文節の係り先を正しく同定できた文の割合である．係り受け正解率は各文の末尾の文節（係り先を持たない）を除いて計算する．また，一文節からなる文は本実験では一切使用しておらず，以下の文数も一文節からなる文を除いた数である．1月1日〜1月8日分の記事（7,587文）を訓練データとし，1月9日分（1,213文），1月10日分（1,479文），1月15日分（1,179文）の記事をそれぞれテストデータとした．二値分類器としてはTinySVMchasen.org~takusoftwareTinySVMを用いた．以下のすべての実験・手法において，多くの先行研究と同じく三次の多項式カーネルを使用し，誤分類のコストは1.0とした．すべての実験はDualCoreXeon3GHzx2のLinux上で行った．</subsection>
  <subsection title="使用した素性">使用した素性を表に示す．文節の主辞とは，文節の形態素のうち品詞が特殊・助詞・接尾辞以外の形態素のうち最も右側のもの，語形とは品詞が特殊以外の形態素のうち最も右側のものである．また，文節の子文節とは，その文節に係っている文節のこととする．なお，トーナメントモデルは同時に候補を二つ見るため，候補に関する素性はそれぞれの候補について別々に作成する．標準素性と追加素性は颯々野Sassano:2004の用いたのとほぼ同じものを使用した．格助詞素性は，ある格要素がすでに埋まっているかどうかを認識させ，「複数のヲ格が単一の文節に係ることはない」といった現象を学習させることを意図したものである．ある動的素性が使用できるかは解析アルゴリズムに依存する．たとえば表の素性の中では格助詞素性のみが動的素性であるが，この格助詞素性はトーナメントモデルにおいて文末から文頭に向かって係り先を決定していく解析アルゴリズムでは「候補の全ての子文節」とは候補の子文節のうち係り元より右側にあるものに限られる．SRアルゴリズムでも同様に，係り元より右側にあるものに限られる．CCアルゴリズムでは片側に限られるということはないものの，候補から遠い子文節については未解析である場合がある．またCLEアルゴリズムではすべての係り関係を独立と考える都合上，動的素性は使用できない．</subsection>
  <subsection title="解析精度">解析精度を表に示す．係り受け正解率に関するマクネマー検定(p&lt;0.01)によると，トーナメントモデルは，素性セット：全素性，テストデータ：1月10日分のSRアルゴリズム(p=0.083)およびCCアルゴリズム(p=0.099)以外の全ての条件で他の手法より優位であった．テストデータ：1月9日分に対して報告されている最高の係り受け正解率は颯々野Sassano:2004の89.56%であるが，トーナメントモデルはこの係り受け正解率を上回っている．ただし，颯々野の実験の出力が手元にないためにマクネマー検定の代わりに符号検定(p&lt;0.01)を行ったところ，この差は有意ではなかった(p=0.097)．追加素性と格助詞素性の有無による精度の差に注目すると，トーナメントモデルは他のモデルより精度差が小さいことが分かる．このことは単に「元の精度が高い方が大幅な精度向上が難しい」と解釈できるが，「トーナメントモデルは他の手法よりモデル自身で周辺情報を多くとらえられている」とも解釈できる．なお，素性の追加による係り受け正解率の向上に関しては，テストデータ：1月9日分のトーナメントモデルのみ有意ではなかった(p=0.25)．また結果からは，同じ素性を用いたときSRアルゴリズムとCCアルゴリズムの精度がほぼ同じということも分かる．だがこの結果は両アルゴリズムの能力が同程度ということを示しているわけではなく，解析順が違えば使用できる動的素性も異なるため，各アルゴリズムに最適な素性を使ったときの能力には差が出る可能性がある．</subsection>
  <subsection title="解析時間と訓練事例の規模">各方式において全素性を使用し，テストデータ：1月9日分全体を解析するのに要した時間と，訓練事例の規模を表に示す．ステップ数とは，SVMclassifyの実行回数である．時間計算量はトーナメントモデルとCCアルゴリズムがO(n^2)，SRアルゴリズムがO(n)である．結果からはSRアルゴリズムが最も高速でCCアルゴリズムもそれに準ずる速度，トーナメントモデルはSRアルゴリズムの4倍以上の時間がかかっていることがわかる．ステップ数でみるとトーナメントモデルはSRアルゴリズムの1.7倍程度であるのに解析時間では4倍以上の差が開く理由は，トーナメントモデルは訓練事例数の規模が大きくSVMモデルが巨大になるためアクションの決定に時間がかかるからである．</subsection>
  <subsection title="解析順等の精度への影響">節において，トーナメントモデルには係り先の同定順，トーナメントの組み方，非交差制約の考慮に関して自由度があると述べた．そこで，これらの自由度および動的素性である格助詞素性の有無に関して実験を行った．その解析精度を表に示す．なお，唯一の動的素性である格助詞素性を使用せず非交差制約も仮定しない場合，各係り元文節の係り先の同定は独立となるので，同定順は解析結果に影響を与えない．精度の変化は多くの場合0.1%程度と小さいが，係り受け正解率に関しては一貫して格助詞素性あり，同定順：右から左，トーナメント：右から左，非交差制約：ありという設定が最もよい．また，格助詞素性を使用することでほとんどの場合精度が向上しているが，向上幅はそれほど大きくない．なお，動的素性である格助詞素性を使用しているため，トーナメントの組み方と非交差制約の考慮の有無を変更する場合には同一のモデルを共用できるが，同定順の変更はモデルの再学習を必要とする．なぜなら，解析時に有効な係り先候補の子文節は，同定順が左から右の場合には係り元より左にあって候補に係っている文節に限られ，同定順が右から左の場合は係り元より右にある子文節に限られるので，訓練事例生成時には格助詞素性における子文節をそのように制限する必要があるからである．</subsection>
  <subsection title="相対モデルとの比較">我々は相対モデルを実装していないため，京大コーパスVersion3.0を使い，工藤らKudo:2005jと実験設定を合わせた実験を行った．ただし素性は統一していない．訓練データは1月1日〜1月11日分の記事と1月〜8月分の社説（24,263文），テストデータは1月14日〜1月17日分の記事と10〜12月分の社説（9,287文）である．工藤らKudo:2005jは誤分類のコストをディベロップメントデータを用いて調整しているが，本実験ではしておらずすべての実験・手法において1.0に固定した．また，本実験の解析順等は節の実験と同じく，同定順：右から左，トーナメント：左から右，非交差制約：ありとした．係り受け正解率の計算法は上の実験と同じだが，文正解率は工藤らKudo:2005jの基準に合わせ，一文節からなる文であっても計算に含めた．結果を表に示す．工藤らKudo:2005jの実験と本実験では使用した素性が異なるので直接的な比較はできないが，唯一両方の素性で実験されているCCアルゴリズムの結果を比較すると我々の素性の方が優れているように見える．係り受け正解率に関するマクネマー検定(p&lt;0.01)によると，トーナメントモデルはSRアルゴリズムおよびCCアルゴリズムに対して優位である．相対モデルに関しては出力が手元にないのでマクネマー検定は行えないが，係り受け正解率に関する符号検定(p&lt;0.01)によるとトーナメントモデルは相対モデルKudo:2005jより優位であった．一方，トーナメントモデルは「組み合わせ」モデルKudo:2005jを係り受け正解率において上回っているものの，符号検定によるとその差は有意ではなかった(p=0.014)．ただし，工藤らKudo:2005jの実験で用いているlog-linearモデルはSVMに比べて訓練時間が短いが，精度の面では不利といえる．というのは，SVMは多項式カーネルによって組み合わせ素性が自動的に考慮されるが，log-linearモデルは明示的に組み合わせ素性を導入する必要があるからである．</subsection>
  <section title="議論と今後の課題">われわれのエラー分析によると，エラーの多くは並列構造に関係したものであった．颯々野Sassano:2004は，各文節が並列構造のキー文節であるか否かを素性として入れることで解析精度が向上したと報告している．京大コーパスには係り受け関係のタグとして並列や同格がタグづけされているが，今回の実験ではこれらのタグは一切使用していないので，何らかの形で使用することで精度向上が期待できる．単純な導入法としては，各タグごとにone-vs-restSVMを作成し，係り先とタグを同時に決めるようにすることが考えられる．また，新保らShimbo:2007のように，並列構造解析を係り受け解析の前処理として行う方法も考えられる．共起情報の導入によって精度向上を図ることも考えられる．一つの使い方としては，動詞--名詞の共起情報を，現在の格助詞素性のような形で入れることである．阿辺川らAbekawa:2006はk-best解を出力できる解析器の出力を，共起情報を用いてリランキングする手法を提案している．我々はすでにトーナメントモデルにおけるk-best解出力アルゴリズムを考案しており，そのようなリランキング法の導入も検討している．トーナメントモデルを英語などの他の言語に対応させることも，別の課題としてあげられる．日本語は書き言葉においては左から右にしか係らないが，多くの言語にはこの制約はないため，係り先候補が係り元の左側にあるか右側にあるかを区別する仕組みが必要となる．単純な解決法としては，左右どちら側にあるかを識別できるようなモデル（素性名）にすることである．非交差制約の有無に関しては問題にならない．現在のアルゴリズムではわざわざ非交差制約を満たさないものを候補から除外しているので，この処理をなくすことで対応できる．また，日本語では文節列に対して解析を行っているが，たとえば英語において単語列に対して解析する場合には時間計算量O(n^2)のnが大きくなるため計算量の問題が深刻になる．この問題は，必要に応じて基本句同定を行うことで軽減できると考える．</section>
  <section title="まとめ">本稿ではトーナメントモデルを用いた日本語係り受け解析手法を提案した．トーナメントモデルは（係り元，候補1，候補2）の三つ組を同時に見て，係り元文節の最尤係り先候補を候補同士の一対一対戦で構成されるステップラダートーナメントによって決定する．この三つ組を同時に見ることによって，従来の（係り元，候補）のみを見るモデルと比べて素性による文脈識別能力の向上が期待できる．また，二つの候補を係り元に近い方の候補，遠い方の候補と区別することによって候補間の相対的な位置関係を把握できる．さらに決定的解析手法と比べると，すべての候補を考慮できるという長所がある．トーナメントモデルの解析精度はほとんどの実験設定において従来手法を有意に上回った．解析速度の面での問題はあるものの，二つ以上の候補を同時に見ることで解析精度を向上させる可能性を示した．document</section>
</root>
