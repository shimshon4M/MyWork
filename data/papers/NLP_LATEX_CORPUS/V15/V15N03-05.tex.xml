<?xml version="1.0" ?>
<root>
  <jtitle>Webを用いた未知語検索キーワードのシソーラスノードへの	割付け手法</jtitle>
  <jauthor>後藤和人土屋誠司渡部広一河岡司</jauthor>
  <jabstract>日常的な会話の中では，新語や固有名詞などシソーラスに定義されていない単語（未知語）が使用される．未知語についての知識がなければ，適切に会話を行うことができない．Webを利用することで，未知語について調べることができる．しかし，Webには膨大な情報が存在するため，必要な情報を効率的に得ることは困難である．未知語に対する適切なシソーラスのノードを提示することによって，未知語の意味を獲得することができる．未知語理解はコーパスなど言語データに依存する研究が多く，対応できない未知語が存在するという問題点がある．本論文では，連想メカニズムを構成する概念ベースと関連度計算，さらにWebを用いて，未知語を概念化することで各ノードとの関連性を評価し，固有名詞を含んだ未知語をシソーラス上の最適なノードへ分類する手法を提案する．</jabstract>
  <jkeywords>シソーラス，概念ベース，関連度計算，未知語</jkeywords>
  <section title="はじめに">我々は，人間と自然な会話を行うことができる知的ロボットの実現を目標に研究を行っている．ここで述べている「知的」とは，人間と同じように常識的に物事を理解・判断し，応答・行動できることである．人間は会話をする際に意識的または無意識のうちに，様々な常識的な概念（場所，感覚，知覚，感情など）を会話文章から判断し，適切な応答を実現しコミュニケーションをとっている．本論文では，それらの常識的な判断のうち，未知語の理解に着目し，研究を行っている．知的ロボットとの円滑なコミュニケーションを実現するにあたり，重要となる技術が自然言語処理である．近年，自然言語処理において，単語を意味的に分類したシソーラス，が数多く構築されている．これらのシソーラスは，情報検索や機械翻訳など多くの分野で利用されている．会話処理にシソーラスを用いた場合，会話文中にシソーラスに定義されていない単語（以下，未知語と呼ぶ）が含まれると，その会話文を理解することができない．そのため，未知語が大局的にどのような意味を持つのかを知る必要がある．未知語が所属するべきシソーラスのノードを提示することで，未知語の内容を簡明に表示することができると考える．これを実現するためには，ある単語から概念を想起し，さらに，その概念に関係のある様々な概念を連想できる能力が重要な役割を果たす．これまで，ある概念から様々な概念を連想できるメカニズムを，概念ベースと関連度計算により構成し，実現する方法が提案されている．そこで本論文では，連想メカニズムおよびシソーラスの体系的特徴を基に未知語を所属するべき最適なノードへ分類する手法を提案する．これまでにも同種の研究がなされている．では，言語データとしてISAMAPを利用し，未知語をシソーラスに分類する手法としてコーパス中の出現回数などの統計情報を用いている．またでは，言語データとしてNTTシソーラスを利用し，未知語をシソーラスに分類する手法として統計的決定理論の1つであるベイズ基準を用いている．一方ででは，検索エンジンのヒット件数に対して^2値を用いた関連度の指標を用いることで，シソーラスの自動構築を行う手法が提案されている．またでは，コーパスにおける単語同士の共起頻度を用いて単語をベクトル表現で表すことで，概念ベースを作成している．そして，概念ベースに登録していない単語のベクトル表現を，意味空間への射影による手法および分散最小性に基づく手法を用いて推定し，概念ベースを拡張する方法が提案されている．このようにこれまでの研究は，コーパスやシソーラスなどの言語データに存在する単語と未知語の共起頻度を利用することで，両者の関連性を比較し，未知語を既存のシソーラスに分類するものである．そのため，これまでの研究は，用いる言語データに存在しない未知語の場合，共起頻度を獲得することができないため，対応できないという問題を抱えている．本論文では，共起頻度に加えて，ある概念から様々な概念を連想できる連想メカニズムを用いている．その結果，固有名詞を含んだ未知語に対応した柔軟なメカニズムの構築を実現している．</section>
  <section title="未知語分類システム">未知語分類システムの構成を図に示す．未知語分類システムは，単語を意味的に分類した分類体系の1つであるNTTシソーラスと，未知語をNTTシソーラスのノードに分類するための未知語分類処理により構成されている．また，未知語分類処理においては，複数の国語辞書や新聞などから機械的に構築した大規模な知識ベースである概念ベースと，概念と概念の関連の強さを定量的に評価する関連度計算（以下，これらを合わせて連想メカニズムと呼ぶ）を用いることにより，未知語とNTTシソーラスのノードとの関連付けを行っている．なお本論文では，未知語とNTTシソーラスのノードに対して関連度計算を行うために，概念化という処理を行っている．概念化とは，ある単語に属性と重みの集合を与えることである．本論文では，常識的な会話処理において用いられる一般名詞については，ノードとリーフをあわせて13万語の以上の単語が収録されているシソーラスと，約9万語の概念を収録する概念ベースを用いることで対応することができると考え，未知語に関する表現として，固有名詞を扱う．さらに，固有名詞の中でも，1つの単語のみから人間がその単語の意味を判断できる固有名詞を扱う．例えば，「Gショック」は「時計」，「クイニーアマン」は「パン」であると判断できる．逆に，「イオン」であれば，「企業」と判断する人間だけでなく，「電離現象」と判断する人間もいると考えられる．このように，人間が一意に判断できないことは，判断する手法が存在しないと考え，多義的な要素を持つ固有名詞については扱わないものとしている．また，節で述べる未知語の概念化では，未知語の属性とその重みの獲得をWebから行う．そのため検索にヒットしない，つまり，Webに存在しない未知語は扱わないものとしている．</section>
  <section title="構成技術">本章では，本研究を構成する技術であるシソーラス，連想メカニズム，および，属性の重み付け手法について述べる．</section>
  <subsection title="シソーラス">シソーラスとは，単語を意味的に分類した分類体系である．シソーラスの多くは木構造を持ち，名詞の集合を分類した名詞シソーラスや用言の集合を分類した用言シソーラスなどがある．また，木構造の葉（以下，リーフと呼ぶ）のみに単語が所属する分類シソーラスと根及び中間ノードにも単語が所属する上位下位シソーラスがある．本論文では，木構造を持つ名詞シソーラスであり，上位下位シソーラスの1つであるNTTシソーラスを用いる．NTTシソーラスは一般名詞の意味的用法を表す2710個のノードの上位—下位関係，全体—部分関係が木構造で示されたものである．ノードに所属する名詞として約13万語のリーフが分類されている．図にNTTシソーラスの木構造の一部を示す．本論文では，未知語を最も詳しく説明するノードに分類するという考えから，未知語を分類するノードを最下位ノード（1926個）に限定している．さらにその中で，固有名詞である未知語が分類されることはないと判断できるノードを人手で削除している．なお判断基準としては，3名の被験者に各最下位ノードに未知語が分類されるノードか否かを判断してもらい，そのうち3名全員が未知語は分類されないと判断したノードを削除している．結果，使用するノード数は385個となっている．表に選別したノードの一例を示す．</subsection>
  <subsection title="連想メカニズム">連想メカニズムは概念ベースと関連度計算により構成されており，概念ベースは，ある単語から語意の展開を行い，関連度計算は，語意の展開結果を利用し，単語の間にある関連性の強さを数値として表す手法である．</subsection>
  <subsubsection title="概念ベース">概念ベースとは複数の国語辞書や新聞などから機械的に構築した単語（概念）とその意味特徴を表す単語（属性）の集合からなる知識ベースである．概念には属性とその重要性を表す重みが付与されている．概念ベースには約9万語の概念が収録されており，1つの概念に平均約30個の属性が存在する．ある概念Aは属性a_iとその重みw_iの対の集合として，式で表される．任意の一次属性a_iは，その概念ベース中の概念表記の集合に含まれている単語で構成されている．したがって，一次属性は必ずある概念表記に一致するため，さらにその一次属性を抽出することができる．これを二次属性と呼ぶ．概念ベースにおいて，「概念」はn次までの属性の連鎖集合により定義されている（図）．本論文では，節で述べる未知語の概念化，および，節で述べるシソーラスのノードの概念化に概念ベースを用いている．</subsubsection>
  <subsubsection title="関連度計算">関連度とは，概念と概念の関連の強さを定量的に評価するものである．概念と概念の間にある関連性を定量的に評価する手法として，ベクトル空間モデルが広く用いられている．しかし，本論文では，概念を定義する属性集合とその重みを含めた一致度に基づいた関連度計算方式を利用している．これは，関連度計算方式が有限ベクトル空間によるベクトル空間モデルよりも良好な結果が得られるという報告がなされているためである．本論文では重み比率付き関連度計算方式を使用し，実験を行う．任意の概念A，Bについて，それぞれ一次属性をa_i，b_jとし，対応する重みをu_i，v_jとする．また，概念A，Bの属性数をL個，M個(L&lt;M)とする．A=(a_i,u_i)i=1〜L=(b_j,v_j)j=1〜Mgather*このとき，概念A，Bの重み比率付き一致度MatchWR(A,B)を以下の式，で定義する．MatchWR(A,B)=_a_i=b_j(u_i,v_j)(,)=		&amp;(&gt;)	&amp;()	cases	gather概念A，Bの属性a_i，b_jに対し，a_i=b_jとなる属性（概念A，Bに共通する属性）があった場合，共通する属性の重みの共通部分，つまり，小さい重み分のみ一致するとの考えに基づいている．定義から明らかなように，両概念の属性と重みが完全に一致する場合に，一致度は1.0となる．次に，属性の少ない方の概念をAとし(LM)，概念Aの属性を基準とする．[A=(a_1,u_1),(a_2,u_2),,(a_i,u_i),,(a_L,u_L)]そして概念Bの属性を，概念Aの各属性との重み比率付一致度MatchWR(a_i,b_xi)の和が最大になるように並び替える．[B_x=(b_x1,v_x1),(b_x2,v_x2),,(b_xi,v_xi),,(b_xL,v_xL)]これによって，概念Aの一次属性と概念Bの一次属性の対応する組を決める．対応にあふれた概念Bの属性は無視する（この時点では組み合わせはL個）．ただし，一次属性同士が一致する（概念表記が同じ）ものがある場合(a_i=b_j)は，別扱いにする．これは概念ベースには約9万の概念が存在し，属性が一致することは稀であるという考えに基づく．従って，属性の一致の扱いを別にすることにより，属性が一致した場合を大きく評価する．具体的には，対応する属性の重みu_i，v_jの大きさを重みの小さい方にそろえる．このとき，重みの大きい方はその値から小さい方の重みを引き，もう一度，他の属性と対応をとることにする．例えば，a_i=b_jでu_i=v_j+とすれば，対応が決定するのは(a_i,v_j)と(b_j,v_j)であり，(a_i,)はもう一度他の属性と対応させる．このように対応を決めて，対応の取れた属性の組み合わせ数をT個とする．重み比率付き関連度とは，重み比率付き一致度を比較する概念の各属性間で算出し，その和の最大値を求めることで計算する．これを以下の式により定義する．以下，重み比率付き関連度を関連度と略し，この関連度を用いる．関連度の値は概念間の関連の強さを0〜1の間の連続値で表す．1に近づくほど関連が強い．概念AとBに対して関連度計算を行った例を表に挙げる．最後に，概念「机」と「椅子」を例に用いて，関連度の計算例を説明する．概念「机」と「椅子」の一次属性および二次属性を表，表に示す．まず，概念「机」と「椅子」の一致度の計算を行う．例えば，概念「机」の一次属性「学校」と概念「椅子」の一次属性「木」は，「木造」という共通する属性を持っているため，一致度は以下のように計算される．[MatchWR(学校,木)=(0.2,0.4)=0.2]同様に全ての一次属性の組み合わせについて一致度を計算した結果を表に示す．次に，関連度の計算を行う．関連度の計算は，まず属性が完全に一致している部分から行われる．続いて，一致度の大きい部分から順に対応を決める．この場合，表から一次属性「勉強」と「勉強」，「学校」と「教室」，「本棚」と「勉強」の順に対応が決まることになる．結果，関連度は次式のように計算される．DoA(机,椅子)&amp;=1.0(0.3+0.3)(0.3/0.3)/0.2+0.4(0.6+0.3)(0.3/0.6)/2		&amp;+0.1(0.1+0.2)(0.1/0.2)/2		&amp;=0.3975align*本論文では，節で述べる未知語とシソーラスのノードとの関連の強さの判断に関連度計算を用いる．</subsubsection>
  <subsection title="属性の重み付け手法">本節では，本論文が提案する手法で用いる，対象としている文書に出現する単語の重み付け手法であるTF・IDFとSWeb-idfについて述べる．</subsection>
  <subsubsection title="TF・IDF">TF・IDFによる重み付けとは，対象としている単語の頻度と網羅性に基づいた重み付け手法である．文書dにおける索引語tの重みw(t,d)は以下の式によって得られる．tf(t,d)は文書dにおける索引語tの出現頻度である．また，idf(t)は検索対象文書数Nと索引語tが出現する文書の数df(t)によって決まり，式によって定義される．本論文では，節で述べるシソーラスのノード属性の概念化，および，節で述べるノード動詞の構築にTF・IDFを用いている．</subsubsection>
  <subsubsection title="SWeb-idf">SWeb-idf(StaticsWeb-InverseDocumentFrequency)とは，Web上の単語のIDFを統計的に調べたIDF値である．まず，無作為に選んだ固有名詞1000語を作成する．表に無作為に選択した固有名詞の一部を示す．この作成した1000語に対して個々に検索エンジンで検索を行い，1語につき検索上位10件の検索結果ページの内容を取得する．よって，得られた検索結果ページ数は10000ページとなる．この10000ページから，複数の国語辞書や新聞などから概念（単語）を抽出した知識ベースである概念ベースの収録語数である約9万語とほぼ同等の単語数が得られたことから，獲得した10000ページをWebの全情報情報空間とみなしている．そして，その中での単語のIDF値を表すSWeb-idfは，式で求められる．これらにより得られた単語とそのIDF値をデータベースに登録した．なおdf(t)項は，全文書空間（10000ページ）に出現する概念tの頻度である．獲得したSWeb-idfの値の例を表に挙げる．なお，固有名詞の選び方を変えてもSWeb-idfの値に大きな変化は見られないという報告がなされている．本論文では，節で述べる未知語の概念化にSWeb-idfを用いている．</subsubsection>
  <section title="未知語分類手法">本論文が提案する手法では，未知語を入力した後に，未知語とシソーラスのノードに対して関連度計算を行うために，未知語の概念化およびシソーラスのノードの概念化を行う．そして，概念化された未知語およびノードを用いて未知語が所属するシソーラスのノード決定を行う．処理の流れとしては，まず，未知語を入力した後に，未知語とノードに対して関連度計算を行うために，未知語とノードの概念化を行う．次に，概念化された未知語およびノードに対して関連度計算を行い，所属候補ノードを絞り込む．さらに，ノード動詞および共起ヒットを用いて未知語が所属するべきノードを決定する．図に未知語をシソーラスのノードへ分類する流れを示す．</section>
  <subsection title="未知語の概念化">以下の手順により，未知語の概念化を行うために，未知語の属性とその重みをWebから獲得する．入力された未知語をキーワードとして検索エンジンを用いて検索を行い，検索上位100件の検索結果ページの内容を取得する．HTMLタグなど不要な情報を取り除いた文書群に対して，形態素解析ソフト「茶筌」を用いて形態素解析を行い，自立語を抽出する．得られた自立語の中から概念ベースに存在する単語のみを未知語の属性として抜き出す．得られた属性の頻度にSWeb-idf（節参照）の値を掛け合わせたものを属性の重みとし，得られた重み順に並び替える．なお，SWeb-idfのDBに存在しない属性については，Web上にあまり存在しない単語と考え，SWeb-idf値の最大値を掛け合わせている．表に未知語を概念化した例を示す．</subsection>
  <subsection title="シソーラスのノードの概念化">入力された未知語の属性とその重みはWebの検索を用いて獲得したが（節参照），比較対象であるシソーラスのノードは概念ではないため，関連度計算による比較を行うことができない．そのため，シソーラスのノードの概念化を以下の手順で行う．ノードに所属する全てのリーフに対して概念ベースを参照し，リーフを概念とみなすことでその一次属性を取得する（図）．(1)の作業を全てのノードに対して行う．リーフを概念とみなすことで取得した一次属性に対して，TF・IDFを利用（節参照）して各属性の重みを求める．具体的には，取得した一次属性の重みをTFとみなし，また，全てのノードの数を式のN，取得した一次属性が出現するノードの数を式のdf(t)とみなしてIDFを求める．そして，得られた重み順に属性を並び替える．表にシソーラスのノードの1つである「時計」を概念化した例を示す．</subsection>
  <subsection title="シソーラスのノードの絞込み">以下の手順により，処理回数を少なくするためにシソーラスのノードの絞込みを行う．節で説明した手法を用いて，概念化を行った未知語queryを式で定義する．なお，q_iが属性，w_iがその重みである．シソーラスのノード集合NODEを式で定義する．また，節で説明した手法を用いて，概念化を行ったシソーラスのノードnode_iを式で定義する．なお，n_ijが属性，w_ijがその重みである．概念化を行った未知語queryとシソーラスの各ノードnode_iに対して関連度計算を行い，関連度DoA(query,node_i)を求める．そして，0.02以上の関連度を持つノードを所属候補ノードとする．よって，所属候補ノード集合NODE'は以下の式で定義される．なお，関連度の閾値0.02は，0.0から0.05まで0.001毎に変化させて実験を行った結果，最も高い精度を得られた値を閾値として採用したものである．この実験については，節で述べる．また，閾値によりノード数を385個から10個程度に絞り込むことができ，節で述べるノード動詞や共起ヒットを用いる処理において，処理回数を20分に1以下にすることに成功している．</subsection>
  <subsection title="所属ノードの決定">節の処理により求めた所属候補ノード集合NODE'に対してノード動詞や共起ヒットを用いたノード決定を行う．</subsection>
  <subsubsection title="ノード動詞">NTTシソーラスは作成者がある分類基準に従って単語を体系的に分類したものである．そのため，NTTシソーラスには「あるノードに所属するリーフは，そのリーフの直後に現れる助詞を伴う動詞が同じである」という関係が存在する．例えば，ノード「茶」に属するリーフ「番茶」や「麦茶」などには，「番茶を飲む」や「麦茶を飲む」など直後に現れる助詞を伴う動詞が共に「を飲む」であることが分かる．ノード動詞とはこの関係を利用して，ノードに設定したキーワードのことであり，ノード決定に利用する．具体的には，入力された未知語にノードごとに対応する助詞を伴う動詞（ノード動詞）を連結したキーワードを検索エンジンに入力し，HIT数を獲得する．そして，獲得したHIT数を節で述べるノード得点の算出に利用する．例えば，未知語が「マイルドセブン」，所属候補ノードが「たばこ」である場合，ノード「たばこ」のノード動詞である「を吸う」を連結した「マイルドセブンを吸う」というキーワードの検索を検索エンジンで行ったときのHIT数を求める．以下にノード動詞の構築方法を示す．ノードに属しているリーフをすべて抜き出す．それぞれのリーフをキーワードとして検索エンジンで検索し，各リーフについて検索上位1000件の検索結果ページを取得する．そして，その文書内でキーワードの直後に出現する「格助詞+動詞（サ変名詞を含む）」部分を全て抜き出す．(2)の操作を全てのノードに対して行う．(3)で得られた「格助詞＋動詞（サ変名詞を含む）」に対して，TF・IDF（節参照）を利用して，重みを求める．具体的には，取得した「格助詞+動詞（サ変名詞を含む）」の数をTFとみなし，また，全てのノードの数を式のN，「格助詞+動詞（サ変名詞を含む）」が出現するノードの数を式のdf(t)とみなしてIDFを求める．そして，最も大きな重みを持つ「格助詞＋動詞（サ変名詞を含む）」をノード動詞に決定する．表に構築したノード動詞の例を示す．</subsubsection>
  <subsubsection title="共起ヒット">「単語の意味は，どのような単語と共起するかという観点から特徴付けられる」というHarrisの分布仮説から，関係のある2語は，ある文書に共に出現すると考えられる．そこで，未知語とノード名のAnd検索を検索エンジンを行い，HIT数を獲得する．そして，獲得したHIT数を節で述べるノード得点の算出に利用する．例えば，未知語が「マイルドセブン」，所属候補ノードが「たばこ」である場合，「マイルドセブン」と「たばこ」のAnd検索を検索エンジンで行ったときのHIT数を求める．</subsubsection>
  <subsection title="所属ノード決定手法">未知語の所属ノードを決定する計算式を式に示す．所属候補ノードnode_iの中でノード得点NodeValue(node_i)が最も高いノードを所属ノードとする．DoA(query,node_i)は未知語queryとnode_iの関連度，VerbHit(node_i)は未知語にノード動詞を連結したキーワードの検索を検索エンジンで行ったときのHIT数，CoincidenceHit(node_i)は未知語とノード名のAnd検索を検索エンジンで行ったときのHIT数を表す．以下に未知語「Gショック」および「クイニーアマン」を例に，所属ノード決定手法における式の結果をノード得点上位5個まで例示したものを表，，，に示す．表が未知語とノード得点上位5個のノードとの関連度，表が未知語のノード得点上位5個のノードが持つノード動詞とノード動詞を用いたときのHIT数，表が共起ヒットを用いたときのHIT数，表が未知語のノード得点上位5個のノードに与えられたノード得点を表している．</subsection>
  <section title="評価">本論文で提案している手法の評価を行うために，20人から各10個ずつシソーラスに存在しない固有名詞とその固有名詞に対する正解ノードを重複することのないように記入してもらうことで，合計200語の未知語を持つテストセットを作成した．なお，テストセットに用いる固有名詞は，章で述べたように一意にその固有名詞の意味を判断できる，つまり，多義的な要素を持たない固有名詞に限定している．評価に使用したテストセットの一部を表に示す．テストセットの各未知語の入力に対して，本論文が提案する手法で出力した結果として，正解ノードを得た未知語を正解，得られなかった未知語を不正解として精度を算出する．</section>
  <subsection title="閾値調査の評価">節で述べたシソーラスのノードの絞込みにおいて関連度の閾値を決定するために，閾値を0.0から0.05まで0.001毎に変化させて未知語の所属ノードの決定を行ったときの実験結果を図に示す．図より，関連度の閾値が0.014から0.02の間で，最も高い66.0%の精度が得られている．そこで，その間で最もノードを絞り込むことができる関連度の0.02が閾値として適当であると考えられる．これをシソーラスのノードの絞込みを行う際に用いる閾値とした．</subsection>
  <subsection title="提案手法の評価">提案手法を用いて，各未知語に対して分類するノードを出力する．なお，式では，ノード得点NodeValue(node_i)が最大となる第1位の候補のみ出力しているが，この実験では第1位の候補から第10位の候補まで出力している．評価結果を図に示す．なお，横軸は考慮した累積のノードの数を表している．また，縦軸は考慮しているノードの中に1つでも正解ノードを得た未知語を正解，1つも正解ノードを得られなかった未知語を不正解として算出した精度を表している．図より，第10位の候補まで出力することで9割を超える高い精度が得られていることから判断できるように，結果として全体的に未知語と関連があると考えられるノードを獲得することができた．特に，第1位に関連が強いと考えられるノードが得られた場合，第2位から第5位までに正解ノードが得られる傾向にあった．例えば，正解ノードが「教師」である未知語「新島襄」を入力した場合，第1位に正解ノードである「教師」と関連が強い「教育」が得られ，第2位に正解ノードである「教師」が得られた．</subsection>
  <section title="既存手法との比較">ここでは既存手法として，ベクトル空間法に基づく手法について説明する．この手法では，シソーラスにはNTTシソーラス，学習データ及び未知語データにはEDRコーパスの共起辞書を用いている．EDRコーパスは22万文からなる文章のデータベースであり，係り受け関係にある単語対を抽出した共起辞書を用いている．</section>
  <subsection title="ベクトル空間法に基づく手法">ベクトル空間法に基づく手法は，シソーラスの各ノードの特徴ベクトルと未知語の特徴ベクトルの類似度をベクトル間の余弦を用いて算出し，類似度の高いノードに未知語を分類する．最も単純なベクトル空間法では，特徴ベクトルは名詞と動詞の共起頻度によるベクトルである．ノードの特徴ベクトルの各要素は，そのノードに属する名詞と動詞との共起頻度を足し合わせたものであり，未知語の特徴ベクトルの各要素は，未知語と動詞の共起頻度そのものとなっている．以下に，ベクトル空間法を詳しく説明する．ベクトル空間法では，式，，によって未知語unknownを分類するノードが決定される．式よりベクトル空間法では，未知語の特徴ベクトルvec(unknown)と余弦の値が最高になる特徴ベクトルvec(node_i)に対応するノードnode_iに未知語unknownを分類する．式，，についての説明を行う．まず，シソーラスに既に分類されている名詞（リーフ）noun_iの集合NOUN，シソーラスのノードnode_iの集合NODE，共起を考慮する動詞verb_iの集合VERBを以下に定義する．また，unknownは未知語を表している．NOUN&amp;=noun_1,noun_2,,noun_i,,noun_noun_numNODE&amp;=node_1,node_2,,node_i,,node_node_numVERB&amp;=verb_1,verb_2,,verb_i,,node_verb_numalign*次に，ノードwと動詞zが共起したことを表す1つの学習データを以下に定義する．[(w,z)wNODE,zVERB](w,z)^NはN個の学習データからなる系列である．学習データを生成するために用いる元々の文章の中では，名詞noun_iと動詞verb_iが共起しているが，学習データを生成する時点で名詞と動詞の二項組(noun_i,verb_j)をノードと動詞の二項組(node_k,verb_j)に変換する．なお，ノードnode_kは名詞noun_iが属するノードであり，複数のノードに属する場合は複数の二項組に変換する．したがって，未知語unknownが属するノードnode^*と未知語unknownと共起した動詞yの系列y^Mは，以下のように表すことができる．[(node^*,y^M)node^*NODE,yVERB]しかし，node^*は未知であり，実際に観測される未知語データは未知語unknownと共起した動詞yの系列y^Mの二項組(unknown,y^M)である．よって，未知語分類問題は学習データ(w,z)^Nと未知語データ(unknown,y^M)を観測したもとで未知語unknownが属するノードnode^*を推定する問題となる．d_(w,z)^N,(unknown,y^M)は，学習データ(w,z)^Nと未知語データ(unknown,y^M)を引数に取り，未知語unknownを分類するべきノードを決定する関数を表す．vec(node_i)はノードnode_iの特徴ベクトル，vec(unknown)は未知語unknownの特徴ベクトルである．また，co((node_i,verb_i)(w,z)^Z)は学習データ(w,z)^N中の(node_i,verb_j)の数でノードnode_iと動詞verb_jが共起した回数，co(verb_iy^M)は未知語データ(unknown,y^M)のy^M中のverb_iの数で未知語unknownと動詞verb_iが共起した回数を表す．はベクトル間の余弦の値を求める関数，vec_Avec_Bはベクトルvec_A,vec_B間の内積，vecはベクトルvecのノルムである．[b]d_(w,z)^N,(unknown,y^M)	&amp;=_node_i(vec(node_i),	vec(unknown))	&amp;=_node_ivec(node_i)	vec(unknown)		vec(node_i)	vec(unknown)	aligned[b]vec(node_i)=	&amp;co((node_i,verb_1)(w,z)^Z),	co((node_i,verb_2)	(w,z)^Z),	,	&amp;co((node_i,verb_i)(w,z)^Z),	,co((node_i,verb_verb_num)	(w,z)^Z)	aligned[b]vec(node_i)=	&amp;co(verb_1y^M),co(verb_2y^M)),	,	&amp;co(verb_iy^M),co	(verb_verb_numy^M)	alignedgatherなお，上記のような単純に共起頻度を用いるベクトル空間法以外に，各共起頻度に重み付けを行うTF・IDF法を導入したベクトル空間法も提案されており，情報検索などの分野において実用化されている手法は，TF・IDF法を導入したベクトル空間法である．TF・IDF法を導入したベクトル空間法では，式および式において，特徴ベクトルの第i要素にnode_numa(verb_i)を掛け合わせたものを特徴ベクトルとして採用し，その上で式を用いて未知語の分類を行う．ただし，a(verb_i)は動詞verb_iとの共起頻度が1以上のノードの数である．</subsection>
  <subsection title="比較評価">比較実験の方法を以下に示す．NTTシソーラスに既に分類されている名詞（リーフ）の中で概念ベース（節参照）に存在する単語から1000語を未知語と仮定して抽出する．NTTシソーラスに属している残りのリーフとEDRコーパス頻出動詞上位500語との共起回数を算出し，学習データを作成する．さらに，NTTシソーラスから取り出しておいた1000語の未知語について，学習データと同様にEDRコーパス頻出動詞上位500語との共起回数を共起辞書から算出し，1000個の未知語データを作成する．学習データと未知語データをもとにベクトル空間法（式）を用いて，各未知語に対する所属ノードを出力する．また，本論文で提案する手法（式）を用いて，各未知語に対する所属ノードを出力する．抽出された未知語とその未知語が所属するノードの例を表に示す．図に実験結果を示す．図のCosは共起頻度のみによるベクトル空間法，TF・IDFはTF・IDF法を導入したベクトル空間法，提案手法が本論文で提案している手法に対応する．本実験において，未知語が元のNTTシソーラスにおいて分類されていたノードに分類できた場合を正解とする．また，未知語が複数のノードに所属していた場合には，出力したノードがその中のどれか1つと一致すれば，正解とみなしている．なお，図と同様に，横軸は考慮した累積のノードの数を表している．また，縦軸は考慮しているノードの中に1つでも正解ノードを得た未知語を正解，1つも正解ノードを得られなかった未知語を不正解として算出した精度を表している．図より，提案手法の精度は共起頻度によるベクトル空間法(Cos)より13〜30%高く，TF・IDF法を導入したベクトル空間法(TF・IDF)に対しても10〜20%高くなっており，提案手法がベクトル空間法に基づく手法よりも優れた結果を示している．本来，本論文で提案している手法は，固有名詞を中心とする既存のシソーラスに分類されていない未知語に対して有効な手法である．その一方で，本実験で用いた既存のシソーラス（NTTシソーラス）から抽出した仮想的な未知語の実体は一般的な単語である．一般的な単語は多くの文書で使用されるため，節で説明した手法を用いると，広範囲にわたるページから属性を獲得することになる．その結果，獲得できる属性にばらつきが生じ，適切な属性を獲得することが困難である．そのため，本論文で提案している手法は，本実験に対しては不利な部分があるといえる．この点を踏まえると，本実験において不利な部分を持っているにも関わらず，提案手法は良好な結果が得られたといえる．したがって，本論文で提案する手法が未知語に限らず，一般的な単語に対しても柔軟に機能することを示しているといえる．</subsection>
  <section title="おわりに">本論文では，ある概念から様々な概念を連想できる連想メカニズムを基に，シソーラスに定義されてない単語（未知語）が大局的に見てどういうものであるかを，シソーラスのノードに分類して提示する手法を提案した．さらに，連想メカニズムに未知語とシソーラスの体系的特徴を利用した共起頻度を組み合わせることで精度向上を図る手法を考え，その有効性を実験によって検証した．結果として，第10位の候補まで出力することで未知語を9割を超える精度で正しいシソーラスのノードに分類することに成功し，未知語を分類するべきシソーラス上の最適なノードを提示できることを示した．さらに，第1位の候補のみを出力した場合，66.0%の精度が得られたことから，未知語をシソーラスに自動的に分類でき，シソーラスの自動構築にもつながると考えられる．今後の研究課題としては，得られた10個の候補から正解ノードを絞り込む方法について検討する．さらに，未知語を分類するべきノードを絞り込んだ後，前後の文脈から正解ノードを決定する方法を検討していきたい．また，未知語により適切な属性を与えるために，検索キーワードに対して適切なキーワードを追加するなど，より適切な検索結果ページを獲得する方法についても検討する必要がある．これにより，文中に多義的な要素を持つ未知語が含まれる場合でも，未知語をノード名に正しく置き換えることで，円滑な自然言語処理を行うことができると期待される．</section>
</root>
