<?xml version="1.0" ?>
<root>
  <jtitle>コーパスからの形容詞概念階層の構築と評価	—実データによる形容詞オントロジーの構築にむけて—</jtitle>
  <jauthor>神崎享子馬青山本英子白土保井佐原均</jauthor>
  <jabstract>本研究は，実データに基づいた形容詞の観点からみた概念体系の自動構築をめざし，その一環として，形容詞概念の階層関係構築に焦点を当てたものである．包含関係の尺度によって上位下位関係を求め，その単語間の上位下位関係に基づき概念階層を自動構築した．結果については，カバー率などの表層的な面と，階層の作られ方についての質的な面での評価を行った．階層の質的な面での評価にあたって，概念の継承関係と事例（形容詞）の各概念の成員としての連続性という観点から心理実験を行い，既存の人手によって作られたEDR辞書の階層と比較した．実験手法はScheffeの一対比較法を用いた．その結果，自動構築がよい，あるいは既存の辞書と有意差がないと判断された階層は，全体の43%となった．抽出した概念数の不足や階層構築の際の問題点など課題も抱えているが，自動生成の階層が既存辞書の階層に対して，その結果の半分弱の階層で問題を提起するという意味で，ベースラインとなる数値と考える．</jabstract>
  <jkeywords>オントロジー，概念，形容詞，自己組織化マップ，階層関係，シェッフェ法</jkeywords>
  <section title="はじめに">計算機科学でいう「オントロジー」とは，ある行為者や行為者のコミュニティーに対して存在しうる概念と関係の記述であり「概念」というのは，何らかの目的のために表現したいと思う抽象的で単純化した世界観である(Gruber1992)．認知科学では，「概念」について外延的意味（事例集合で定義された意味）と内包的意味（属性の集合から定義された意味）の見方があるとする．我々の認知活動の中で，概念化は，語，文，文脈，動作の仕方，事柄，場面など，様々なレベルで行われている．では，なぜ対象の概念化が必要かというと，河原では，MedinandGoldstonebook_24を引用して「概念」の機能を次のように述べている(MedinandGoldstone1990;河原2001)「現在の経験を，あるカテゴリの成員とみなす（分類）ことで，その経験を意味のあるまとまりとして解釈し（理解と説明），そこから将来に何がおきるか（予測）や関連する別の知識（推論）を引き出すことが可能になる（コミュニケーション）．その他，複数の概念を表す語を組み合わせて新たな概念を生成したり，新たな概念の記述を生成してから，その記述にあう事例を検索することもできる」．つまり，人間や計算機が効率的に柔軟な活動をするために，概念と，（言語化する・しないにかかわらず）概念の具体化された表現（あるいは事例）の総体である「オントロジー」は重要な役割を担っているといえる．我々が対象とする言語的オントロジー，特に，語彙の概念を体系化したオントロジーは，概念体系や意味体系と呼ばれ10年以上前から人手で構築されてきた（EDR電子化辞書（日本電子化辞書研究所1995）や分類語彙表など）．その目的は，ある特定のアプリケーションでの利用ではなく，我々の言語知識を体系化することであり，その知識体系を利用して計算機に予測・推論・事例の検索・新たな概念の理解など，深い意味処理をさせることを目的としている．本研究がめざす「形容詞のオントロジー」の目的も，従来の語彙的なオントロジーの目的と同様に，計算機や人間が，形容詞を使って表現する知識の体系化をはかるものである．ここで本研究の「形容詞」とは，形容詞と形容動詞を含むものとする．従来のものと異なる点は，実データからの獲得を図るため，運用の実態を反映したオントロジーを得ようとすることである．人間の内省による分析の場合，概念記述を行う個々人の言語的経験から，概念体系の粒度や概念記述に差異がでてくる．心理実験のように，複数の人が同じタスクをすれば共通の傾向もとれるが，通常のプロジェクトでは同じ個所に多くの人を投入することは不可能である．自動獲得の目的は，できるだけ実際の言語データから言語事実を反映した結果を得ることである．一つ一つのテキストは個々人の記述だが，それを量的に集めれば，複数の人のバリエーションを拾うことができ，結果的に多くの人の言語運用の実態をとることができる．言語データから意味関係を反映した概念体系を捉えられれば，人間の内省によって作られたオントロジーや言語学的知見，意味分類などと比較することは意義があるのではないかと考える．ところで，コーパスからの語彙のクラスタリングや上位下位関係の自動構築などについては，Webの自動アノテーションやインデックス，情報検索など，その目的は様々であるが，そのほとんどが，名詞や動詞を対象にした分類や関係抽出である．形容詞や副詞に関する研究はまだ少ない．しかし，形容詞や副詞が語彙のオントロジーにとって重要でないわけではなく，たとえば，WordNetで形容詞の意味情報が手薄であることを指摘し，イタリア語形容詞の意味情報を導入することで，ヨーロッパの複数言語で共同開発しているEuroWordNetの抽象レベルの高い概念体系(EuroWordNetTopOntology)に変更を加えることを試みている研究がある．オントロジーの主要な関係の一つに，類義関係と階層関係がある．形容詞概念を表すような抽象的な名詞の類義関係については，馬らなどの研究がある．しかし，形容詞概念の階層関係については，まだ研究が進んでいない．本研究では，形容詞概念の階層関係に着目し，コーパスから取得した概念から階層を構築する方法と，妥当そうな階層を得るための評価について述べる．本研究で扱う概念数は約365概念であり，それに対しEDR電子化辞書の形容詞の概念数が約2000概念ほどと考えると取り扱うべき概念はさらに増える可能性があるが，本研究は，現時点よりも多くの概念数を扱うために，まず，現段階での概念数で，階層構築とその評価方法について実験および考察を行ったものである．我々は，第2節でオントロジーのタイプの中で本研究がめざすオントロジーについて述べ，第3節で先行研究の言語学的考察から，形容詞の概念を語彙化したような表現があることを述べ，形容詞の概念をコーパスから抽出する．第4節では第3節で抽出したデータをもとに複数の尺度での階層構築と，得られた階層のうち，妥当そうな階層を判別するための条件を述べ，第5節で心理実験によってEDRの形容詞概念階層と比較評価を行う．第6節でオントロジー構築に向けての今後の展望をのべ，第7節でまとめを行う</section>
  <section title="オントロジーのタイプ">「オントロジー」という用語が喚起する定義や種類，目的などは多様化しているため，本研究がどのようなオントロジーで，何を目的として作るのかを明らかにする必要がある．Sowaは，主なオントロジーのタイプとして，terminologicalontology，prototype-basedontology，formalontologyなどをあげている(Sowa2003)．Terminologicalontologyは，概念の上位下位関係や部分全体関係などの関係が特定され，他の概念との相対的な関係が決められているタイプのものである．このタイプのオントロジーは概念を完全に定義するものではない．意味公理や論理的な定義よりも，プロトタイプや事例によって弁別されるオントロジーが，prototype-basedontologyである．つまりプロトタイプ集合や事例集合が相対的な関係をもって分類されているタイプのものである．また，論理形式で書かれる意味公理や定義によって概念が弁別されるオントロジーがformalontologyである．論理の複雑さの制限はない．一般的なterminologicalontologyとformalontologyの違いは，種類というより，概念間の関係の深さが異なり，formalontologyは規模が概して小さいが，深い記述がされるため推論をサポートするのに用いられる．Biemannはそれぞれのタイプを図示し（図1），長所と短所を述べている．このうち，formalontologyは直接推論に使えるものの，コード化に労力がかかり，大規模になると不整合もおきる危険性がある．一方，terminologicalontologyやprototype-basedontologyは自動化がしやすく作りやすい．しかし，prototype-basedontologyは，概念ラベルがないので，QAシステムなどには使いにくい．このオントロジーは語のクラスタリングによってすぐに導出されるのでterminologicalontologyより構築しやすいが，利用しにくい．その他の種類として，シソーラスがあげられる．シソーラスは関連語のまとまりをもち，prototype-basedontologyに似ている．しかし，関連語などの中には互いに異なった関係も含まれている場合がある．テキストからオントロジーを学習するのに利用できる手法として，分布特性によるクラスタリングをはじめ，表層的な統語情報や特定の言語表現パタンなどを利用して，階層関係や部分全体関係などの単語間の関係を獲得する研究などがある．これらの研究と関係が深いが，Semanticlexiconの構築としてのオントロジーの学習という観点もある．Semanticlexiconは，カテゴリと事例のセットという形であるが，オントロジーのように内部的に構造化されていない．そのアルゴリズムのほとんどがbootstrappingのアプローチである．以上，Sowa，BiemannArticle_03に従ってオントロジーのタイプを概観したが，我々が目的とする形容詞のオントロジーは，形容詞が事例となり，その事例が共通してもつ概念がラベルとなり，その概念ラベルが構造化されたオントロジーという形である．上記でいえば，Semanticlexiconのように形容詞の事例とそれらが共通にもつ概念を一つのユニットとして，それが，ラベルつきprototype-basedontologyのように構造化されたものである．これは，EDR電子化辞書や分類語彙表などの語彙の概念体系／意味体系と同様の形である．ただし，概念名については，EDR電子化辞書は説明的記述を使い，『分類語彙表』の項目では抽象的な語句あるいは代表的な形容詞を使っているが，本研究では，概念ラベルを抽象的な名詞で表現している．オントロジーは柔軟に概念と表現を結びつける必要があるので，概念間の関係は一種類ではなく複数想定され，木構造よりネットワーク的な形態の可能性もある．しかしまずは，概念の類義関係と階層関係をとらえていきたいと考える．本稿では，その一環として，特に，形容詞の概念の上位・下位関係について焦点をあてる</section>
  <section title="言語表現に現れる「概念とその具体事例」という関係"/>
  <subsection title="言語現象">日本語では，高橋が，以下のような例を言語学的に観察している．(1)やぎは性質がおとなしい(2)ぞうは鼻が長い(1)の「性質」は，主体「やぎ」からみると主体のある一面を表すので「側面語」であり，(2)は，主体「ぞう」からみると身体の一部であるので「部分語」と呼び分けて，統語的には同じ構造でも，語の文中での役割の違いを指摘した．そして，側面語については，主語が示すものの側面を表すとともに，述語が示す属性の類概念（上位概念）を表す単語であると考察している．また根本は，「色が白い」「速さがはやい」「年が若い」「背が高い」などは，同義反復的な性格が強いと述べている．このように，我々の言語活動の中でも，形容詞の上位概念を語彙化した表現がみられる．本研究では，(1)の「性質—おとなしい」や「色—白い」「速さ—はやい」などの関係を，「概念とその具体事例」という関係と捉え，このような抽象的な名詞と形容詞の共起をコーパスから抽出する．本稿では，このような抽象的な名詞を「概念」とよび，共起する形容詞を「事例」と考える</subsection>
  <subsection title="コーパスからの抽出方法">次に抽出方法であるが，上記の例のような「NはXがAdj」というパタンは今回は利用していない．この構文のNとX，Adjの意味関係は様々である．それは，3.1節の(1)と(2)が構文上同じ形をしているにもかかわらず，NやAdjに対するXの意味関係が違っていることからもわかる．従って，コーパスから「NはXがAdj」の文型を集めると，量は多いが，「概念とその具体事例」という関係を雑多な関係の中から取捨選択することが難しい．これにはなんらかの基準が必要である．（なるべくある程度のノイズがあっても自動化したり，あるいは人間が簡単に判別できる基準を求める必要があろうが，それは今後の課題とする．）I)は直接的な属性—属性値の関係であり，II-1)は被修飾名詞の意味の一部を形容詞で顕在化し重ねることで強調する関係，II-2)は被修飾名詞の指示対象の内容を具体化する関係となっている．どれも被修飾名詞の意味を含意しつつ形容詞表現で具体化する関係であるため，これら3つのパタンを採用した．以上のように，上記プロセスの2のステップでは，最終的に人間の内省で取捨選択しており，やはり労力がかかるが，1のステップで，被修飾名詞を「何かを範疇化する可能性のある語」に限定することで，抽出対象とする形容詞と概念の共起対を多く含んだデータを得ようとした．人間の取捨選択で得られた形容詞とY（名詞）共起対の総数は36,023共起対，異なりが10,524共起対である．概念数は365で，最大共起形容詞数は，「こと」の1,594語である．出現する共起形容詞数に対する各概念の例は以下のようになる．そして，抽出した概念と形容詞グループを最終的に以下のようなリストにまとめた．概念名となる抽象名詞と形容詞集合のリストを作る際，同じ抽象名詞であっても，明らかに指示対象が異なる場合は，番号をつけて区別した．たとえば，物理的な「形」（たとえば「丸い形」）と，形式的な意味の「形」（たとえば「おだやかな形で〜」）では，「形」の指すものが異なるので，「形1」「形2」のように区別し，形容詞集合をわけた．一方，形容詞についてはどのような名詞と共起しているか，だけをみており，ここで形容詞の多義は区別していない</subsection>
  <section title="概念の階層関係の構築—階層構築の手法と閾値の選定基準—">本節では，包含関係を求める尺度を使い，第3節で抽出した形容詞の概念の階層構築を行う．概念間の包含関係を求める尺度として，HagitaandSawakiが開発し山本・梅村が言語データへ応用した補完類似度(ComplementarySimilarityMeasure,CSM)と，頻度を考慮したCSM(Freq)，そして，CSM以外の尺度としてオーバーラップ相関係数(OverlapCoefficient，Ovlp)を使う．2つの概念間の包含関係を計算したのち階層構築を行うが，予備実験を行った結果，全ての包含関係の概念ペアを使うと明らかにランダムな長い階層ができた．そこで，包含関係が希薄な概念ペアが階層関係の精度を低くすることを阻止するため，包含関係の値に閾値を設定することにした．しかし，閾値設定の問題点として，ゴールドスタンダードがないこのタスクで，複数の尺度や閾値の組み合わせから構築された階層の明らかな差異を，一見して判定できない場合，どのように妥当そうな階層を特定したらよいのだろうか．第5節では心理実験によって階層評価を行うが，事前に明らかに不適当な尺度と閾値の組み合わせを除外するために，緩やかな階層の評価方法が必要になる．本節では，包含関係の尺度を用いて階層構築を述べた後，包含関係の尺度と閾値の組み合わせの妥当性をいくつかの観点から眺め，妥当そうな類似尺度と閾値をある程度特定する方法を述べる</section>
  <subsection title="包含関係の尺度">包含関係の尺度として，3種類の方法を用いた．まず，補完類似度(CSM)について述べる．補完類似度は一対多関係を推定する尺度として提案されたが，事象間の一対多関係は，包含関係（あるいは上位下位関係）を表すので，包含関係を推定する尺度とも考えられる．山本，梅村では，｛沖縄県，那覇市｝のような一対多関係を推定するタスクを行っており，そのタスクでは，コーパスからの関係抽出に用いられた他の類似尺度や連想規則の抽出に用いられる類似尺度など（たとえば相互情報量，コサイン関数，ダイス相関係数など）よりもよい結果を示したことが報告されている．この補完類似度を用いて，対象としている概念の包含関係，つまり上位下位関係を推定する．補完類似度は以下のようになる．今，共起形容詞のセットで定義した抽象名詞FとTがあるとする．我々のデータでは，FとTの特徴ベクトルは，双方の共起形容詞の出現状況を0または1で表現したものに相当する．それを以下のように表す．&amp;F=(f_1,f_2,...,f_i,...,f_n)(f_i=0または1)&amp;T=(t_1,t_2,...,t_i,...,t_n)(t_i=0または1)align*そして，補完類似度の式は以下のようになる．CSM(F,T)=ad-bc(a+c)(b+d)&amp;a=_i=1^nf_it_i,&amp;&amp;b=_i=1^nf_i(1-t_i),&amp;c=_i=1^n(1-f_i)t_i,&amp;&amp;d=_i=1^n(1-f_i)(1-t_i),&amp;n=a+b+c+d&amp;&amp;alignedgather``a''はFとTで共通する共起形容詞の数である．``b''はFとは共起するがTとは共起しない形容詞の数である．``c''はFとは共起しないがTとは共起する形容詞の数である．``d''はFともTとも共起しない形容詞の数である．``n''は，ベクトルの次元数となる．FがTを完全に包含する場合，c=0となり，TがFを包含する場合，b=0となるため，bc=0となる．補完類似度では，一致情報(ad)と不一致情報(bc)の差分をとるので，包含関係にある二語間の類似度は高くなる．さらに，補完類似度はFからTの類似度とTからFの類似度が非対称であることも特徴の一つである．FからTをみた補完類似度では，bはFだけに出現する形容詞の数，cはTだけに出現する形容詞の数である．逆に，TからFをみた補完類似度では，bはTだけに出現する形容詞の数となり，cはFだけに出現する形容詞の数となる．計算式の分母をみると，FとTがどちらの方向の類似度を計算するかで，bとcに代入される数値の大小が逆転し，それに伴って，類似度も非対称になる．次にCSMと比較する手法として，オーバーラップ相関係数(Ovlp)と頻度つきCSM(Freq)の階層を用いる．オーバーラップ相関係数について，ManningandSh&quot;utzeは包含関係を求める尺度として述べている．これは，二値ベクトル間の類似尺度で，計算式は以下のようになる．&amp;F=(f_1,f_2,...,f_i,...,f_n)&amp;(f_i=0または1)&amp;T=(t_1,t_2,...,t_i,...,t_n)&amp;(t_i=0または1)aligned[b]Ovlp(F,T)&amp;=|FT|min(|F|,|T|)	&amp;=amin(a+b,a+c)aligned&amp;a=_i=1^nf_it_i,&amp;b=_i=1^nf_i(1-t_i),&amp;c=_i=1^n(1-f_i)t_i&amp;alignedgathera，b，cなどのパラメータは，CSMでの定義と同様である．次に頻度を考慮した補完類似度について計算式を示す．これは，Sawaki,Hagiga,andIshiiが二値画像のための補完類似度を，多値画像解析のために拡張したものである．Yamamoto,Kanzaki,andIsaharaではこれを言語データに応用している．これは，多値ベクトル間の類似尺度で，計算式は以下のようになる．&amp;F_g=(f_g1,f_g2,...,f_gi,...,f_gn)&amp;(0f_gi&lt;1)&amp;T_g=(t_g1,t_g2,...,t_gi,...,t_gn)&amp;(0t_gi&lt;1)aligned_g(F_g,T_g)=a_gd_g-b_gc_gnT_g2-T_g^2&amp;a_g=_i=1^nf_git_gi,&amp;&amp;b_g=_i=1^nf_gi(1-t_gi),&amp;c_g=_i=1^n(1-f_gi)t_gi,&amp;&amp;d_g=_i=1^n(1-f_gi)(1-t_gi),&amp;T_g=_i=1^nT_gi,&amp;&amp;T_g2=_i=1^nt_gi^2alignedgatherこの定義式において，各要素は，には，抽象名詞（概念に相当）がi番目の形容詞と頻繁に共起するかどうかの状況を表す，共起頻度に基づく重みを用いる．重みは以下のように求める．Weight(noun,adj)=Freq(noun,adj)Freq(noun,adj)+1重みの値域は0Weight(noun,adj)&lt;1である．gatherベクトルF_gを持つ抽象名詞をnoun_FとT_gを持つ抽象名詞をnoun_Tとし，上式の重みでf_giとt_giを表すと，ベクトルは以下のように表される．F_g&amp;=(f_gi,f_g2,...,f_gn)&amp;=(Weight(noun_F,adj_1),	Weight(noun_F,adj_2),,	Weight(noun_F.adj_n))T_g&amp;=(t_gi,t_g2,,t_gn)&amp;=(Weight(noun_T,adj_1),	Weight(noun_T,adj_2),,	Weight(noun_T.adj_n))align</subsection>
  <subsection title="概念階層の構築方法">CSMなどによって包含関係を計算し，値を正規化して得られたリストの一部を示すと以下のようになる．単語Aから単語Bを見たときのCSM値が，単語Bから単語Aを見たときのCSM値より大きければ，単語Aが上位語，単語Bが下位語となる．たとえば，本稿では概念とは第3節で抽出した抽象的な名詞で定義しており，上記の概念の並びは，左の概念からみた右の概念の包含関係を表している．たとえば，左の概念が「印象」で右の概念が「感じ」の場合は，「印象」からみた「感じ」を示し，上記ではCSM値は0.936となる．逆に，方向が逆転し，左の概念が「感じ」で右の概念が「印象」の場合は，「感じ」からみた「印象」の包含関係を表し，0.778となる．この場合「印象」から「感じ」を見るほうが，CSM値が高いので，「印象」は「感じ」の上位概念となる．ただし，この場合は両方向からのCSM値が高いので，かなり事例に重なりがあると考えられる．上記のような二単語間の包含関係を求めた後，これを利用して階層を構築する．階層構築方法は次のようになる．初期階層として，CSM値の高い順に二単語をつなげる．ここでは，仮に単語Aが上位語，単語Bが下位語という関係とする．階層(0):A-B（``-''は上位下位関係を示す記号とする）まず，階層(0):A-Bの下位語を探索する．二単語間のCSM値のリストから，単語Bを上位語として，Bの下位語として最大値をとる単語Xを探して，単語Bの後ろに連結し，次に，その単語Xを上位語として，Xの下位語として最大値をとる単語Yを探して，単語Xの後ろに連結する．この操作を下位語がなくなるまで繰り返す．これによって以下のような階層ができる．階層(1)：A-B-X-Y次に，階層(0):A-Bの上位語を探索する．二単語間のCSM値のリストから，単語Aを下位語として，Aの上位語として最大値をとる単語Wを探して，単語Aの前に連結し，次に，その単語Wを下位語として，Wの上位語として最大値をとる単語Vを探す．この操作を上位語がなくなるまで繰り返す．階層(1)と連結することで以下のような階層ができる．階層(2):V-W-A-B-X-Yただし，上位下位関係は必ず保存する．もし上位下位関係が逆転した場合はその関係は連結しない．長い階層に完全に含まれる短い階層はマージし，二つの階層のうち一単語ずつ異なる場合は，各階層の差異となる二単語の補完類似度の値を測り，上位下位関係があれば結合した．A-B-C-D-EとA-B-Dという階層があるとき-B-Dは，順序を保存した状態で長い階層に完全に含まれるのでマージし，短い階層は削除する．-B-C-D-EA-B-C-D-EとA-B-X-D-EがあるときとXの補完類似度の値を求め，CとXに上位下位関係があれば結合した．-B-C-X-D-E最後に各階層のトップに「こと」を結合する．「こと」は全ての形容詞と共起するとして，計算時間の便宜上，「こと」は最後に各階層のトップに結合させることとした．最終階層:こと-V-W-A-B-X-Y</subsection>
  <subsection title="妥当そうな手法と閾値の選定">4.2節で求めた概念間の包含関係を全て使って階層を構築すると，冗長な意味のない概念階層（つまり単語の羅列）になり，閾値があまりに高いと，概念階層は非常に短くなる（つまり，連結される名詞があまりにも少なくなる）．そこで，包含関係が希薄な概念ペアが階層関係構築時に悪影響を及ぼすことを阻止するため，包含関係の値に閾値を設定することにした．CSMについては0.3と0.2，Ovlpについては0.3と0.2，Freqについては0.2と0.1の閾値を設定し，その閾値以上の概念間の包含関係を用いて階層を構築した．これらの閾値による階層は，概念を連結したある程度の長さの階層であり，かつ，明らかにおかしい概念の羅列ではない．この閾値以上でも以下でも，前述の弊害が出る．逆にいえば，前述の閾値からできた階層は，一見して妥当なのか，妥当ではないのか，すぐにはわからないともいえる．手法ごとに多くの階層が生成され，閾値をいくつか設定すれば，その分だけ，また階層が増えるので，心理実験などで既存辞書との比較評価を行おうと思えば，妥当そうな階層を事前に選定した方が効率的である．そこで，次のような観点から，階層を分析した．形容詞の階層としてできた階層の割合第2節で述べたprototype-basedontologyで構造化された事例集合（図1）をみるとわかるように，最下位レベルで出現している「チーズ」は，最上位レベルの事例集合にも出現している．通常，上位概念の特徴は下位概念の特徴に「継承」される．概念の特徴を定義するのが事例集合である場合，下位レベルで出現する事例は，上位レベルの概念の事例にもなる（「すずめ」は，鳥の事例でもあり，動物の事例でもあり，生物の事例である）．この認知科学的ルールから，自動構築した階層の，最下位概念の事例集合（形容詞の集合）が，最上位概念までの各概念の事例集合に含まれているかを調べ，連続して出現していれば，その階層は，当該形容詞の階層と考える．本稿のデータで考えると，「形容詞の階層としてできた階層」とは，ある形容詞が，最下位から最上位に位置するすべての概念の形容詞集合に出現している場合，その階層を「形容詞の階層としてできた階層」と呼ぶ．もし，ある形容詞が，階層のどこかの概念の形容詞集合の成員でなければ，形容詞の階層とはよばず，手法によって得られた「階層」とよぶ．この考えに則って，手法ごとに，得られた階層の中で，形容詞の階層として得られた階層が何割あるか，計算した．分母は，ある手法に基づいて構築された全階層であり，分子は「形容詞の階層としてできた階層」である．事例としてコーパスから抽出された全形容詞のうち，何語の形容詞に「形容詞の階層」が得られたか．階層を構成する概念の割合概念としてコーパスから抽出した抽象名詞は全部で365語あるが，そのうち何割が階層を構成しているか．階層を構成する概念の割合は次のように計算した．上記3つの観点から各手法の結果を求めると，表4のようになる．表中で，高い数値の第一位から第三位に「○」，そのうち極端に数値が高い場合は「◎」を数字の前に付与した．また，極端に数値が低いものには「＊」を付与した．表1から，総合的にみるとCSM0.2とOvlp0.3が，形容詞の階層としてできた階層の割合も，階層ができた形容詞数や365の概念のうちで階層を構成する概念の割合もよいとわかる．CSM0.3は，6種類の階層の中で形容詞の階層を最も多く作っているが，階層を構成している概念の数が最も低い．これは同じ階層をもつ形容詞のグループが，未分化である可能性がある．また，Ovlp0.2の階層は，形容詞の階層はあまり作られていないが，対象にしている365の概念をほとんど使って，階層を作っている．これは，冗長に階層を作っている可能性がある．程度の差こそあれ同様の傾向がみられるのはFreq0.1である．形容詞をカバーする階層は少ないが，階層を構成している概念が多いことがわかる．Freq0.2は，形容詞をカバーする階層は多めであるが，それより顕著な特徴は，階層を構成する概念の種類が少ないことである．程度の差こそあれ，その点では，CSM0.3に似た傾向がみられる．上記の結果より，CSM0.2とOvlp0.3は，外見的に妥当そうな階層となっているので，EDRと比較する階層としてこの二者を選択する．また，頻度を考慮したCSM(Freq)については，両者の閾値とも外見上それほど適当ではないが，異なる種類を比較するということで，形容詞の階層が比較的得られているFreq0.2を，EDRとの比較実験に加えることとする</subsection>
  <section title="自動構築の階層とEDR辞書の概念階層との比較評価">本節では，本研究の提案手法によって自動構築した階層と，EDR階層の優劣を心理実験によって定量的に比較する．EDR電子化辞書は，10年ほどの年月をかけ，言語学者や辞書編纂者などが携わった大規模な計算機用辞書である．この電子化辞書は概念体系をもち，各語彙は概念IDによって概念体系とリンクしており，概念IDから上位概念や下位概念などを辿ることができる．EDRの概念体系には局所的な不整合性や冗長性などの問題はあるものの，概念分類と概念間の関係を細かく記述した全品詞にわたる大規模シソーラスである．本研究が対象とする形容詞概念についても，EDRは広範囲にカバーしているため，本実験ではEDRを比較対象とした．EDRの概念記述は単語で定義されている場合もあれば，文で説明していることもある．たとえば，EDRの「肯定的な」という形容詞の概念階層の例を示すと次のようになる．一方，自動生成の階層は，各ノードの概念が抽象名詞で表現されている．たとえば以下のような階層である．階層中，「面1」のような名詞の横の番号は，「面」の意味を区別した際に付与した番号である．（ここでは，「やさしい面がある」のような形式的な意味の「面」と「丸い面」のような物理的な面とを区別し，前者の形式的な意味の「面」を「面1」とした．）二つの異なる形式の階層比較をした研究としては，概念記述間の単語の一致度によって表層的に評価した研究がある．しかし上記の通り，本研究で自動抽出された階層とEDR階層の構造は異なり，また概念の比較評価という抽象的な対象を扱うタスクであるため，我々は，表層的な比較ではなく，心理実験による優劣の比較を行った．4.3節(1)でも触れたが，階層関係が成立する重要な条件として，上位概念の下位概念への継承性事例（本稿では形容詞）が，事例集合の成員として最下位概念から最上位概念まで出現する連続性という二つの条件がある．本実験の目的は，上記二つの観点から，自動構築の階層とEDR階層の優劣の程度に関する人間の判断を数値化することにより，これら二つの階層間の優劣を統計的に比較することである．数値化手法としてはScheffeの一対比較法を用いた．Scheffeの一対比較法で得られる値は相対的な値であるため，各々の階層の絶対的な優劣の程度は数値化できないが，異なる階層間の優劣の相対的な程度を数値化することができる．そしてこのような数値化によって，階層間の優劣の判断に関する被験者間のばらつきを考慮した上で，階層間の優劣を統計的に検定することができる．なお，言語データの評価にScheffeの一対比較法を用いた他の研究として，丸元らの研究があるが，この研究は敬語表現の丁寧さの程度の数値化にScheffe法を用いたものである</section>
  <subsection title="実験データについて">実験には，下記に示す三種類のデータを用いた．30語の形容詞に対して，CSM0.2，Ovlp0.3，Freq0.2の三手法の全て，あるいは，三手法のうち少なくともいずれか二手法で共通して生成された階層（以下，COMMONと呼ぶ）と，EDRの階層のペア．(COMMON-EDR)10語の形容詞に対して，CSM0.2だけで生成された階層とEDRの階層のペア．(CSM-EDR)10語の形容詞に対して，Ovlp0.3だけで生成された階層とEDRの階層のペア．(Ovlp-EDR)Freq0.2の階層はCSM0.2の階層と殆ど同じであったので，本実験では，Freq0.2の手法だけで生成された階層は対象外にし，CSM0.2の階層のみをとりあげた．1)(COMMON-EDR)で対象となる30語の形容詞のリスト，2)(CSM0.2-EDR)で対象となる10語の形容詞のリスト，3)(Ovlp0.3-EDR)で対象となる10語の形容詞のリストをそれぞれ表5，表6，表7に示す．4</subsection>
</root>
