<?xml version="1.0" ?>
<root>
  <jtitle>複数の分類スコアを用いたクラス所属確率の推定</jtitle>
  <jauthor>高橋和子高村大也	奥村学</jauthor>
  <jabstract>文書分類の多くのアプリケーションにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用で，正確な推定値が必要とされる．これまでに提案された推定方法はいずれも2値分類を想定し，推定したいクラスの分類スコア（分類器が出力するスコア）のみを用いている.しかし，文書分類では多値分類が適用されることが多く，その場合は，予測されるクラスはクラスごとに出力された分類スコアの絶対的な大きさではなく相対的な大きさにより決定される.したがって，クラス所属確率は，推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられるため，推定したいクラス以外の分類スコアも用いて推定する必要があると思われる．本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第1位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．提案手法を多値分類に拡張したサポートベクターマシンに適用し，性質の異なる2つのデータセットを用いて実験した結果，有効性が示された.また，本稿では，クラス所属確率を推定する別の方法として，各分類スコアを軸として等間隔に区切ってセルを作成する「正解率表」を利用する方法も提案したが，この方法においても複数の分類スコアを用いることは有効であった．提案手法は，分類スコアの組み合わせや分類器の変更に対しても容易に対応できる.</jabstract>
  <jkeywords>クラス所属確率，ロジスティック回帰，複数の分類スコア，多値分類，	文書分類，正解率表，平滑化</jkeywords>
  <section title="序論">自然言語処理においては，タグ付けや文書分類をはじめとするさまざまな分類タスクにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用である．例えば，自動分類システムがより大きなシステムの一部を構成し，自動分類結果が別のシステムに自動入力されるような場合に，クラス所属確率は重要な役割を果たす．この例として，ブログ記事に対してさまざまな観点から付けられたタグ（複数）をユーザに表示するシステムにおいて，タグを自動的に付与する際に，クラス所属確率が閾値より低いタグについては排除することが有効な場合がある~.同様に，手書き文字認識システムによる分類結果が，言語モデルのようなドメイン知識を組み込んだシステムの入力である場合も，クラス所属確率が用いられている~.また，自動的にタグ付けされた事例のうち誤分類されたものを人手により訂正したい場合に，すべての事例をチェックするのは大きなコストがかかるが，クラス所属確率が低いものほど不正解である可能性が高いと仮定し，クラス所属確率が閾値を下回る事例のみを訂正することにすれば，効率的な作業が行える．さらに，自動分類結果が人間の意思決定を支援する場合においては，クラス所属確率は判断の根拠を与える．例えば，高橋らは，社会調査において自由回答で収集される職業データを該当する職業コードに自動分類し~,上位5位までに予測されたクラスを候補として画面に提示するシステム（NANACOシステム）を開発した~.NANACOシステムは，我が国の主要な社会調査であるJGSS（JapaneseGeneralSocialSurveys;日本版総合的社会調査）-0.5zwや，SSM調査（SocialStratificationandSocialMobilitySurvey;社会階層と社会移動調査）-0.5zwなどに利用されているが，システムを利用したコーダから，提示された各クラスについてどの程度確からしいかを示すクラス所属確率を付与してほしいという要望が出されている．最後に，クラス所属確率はEMアルゴリズムにおいても有用である．例えば，語の曖昧性解消において，あるドメインで訓練された分類器を，別のドメインのコーパス用に調整するために用いられたEMアルゴリズムにおいて，クラス所属確率は精度の向上に役立つことが報告されている~.事例xがあるクラスcに所属するクラス所属確率Pは，2値分類，多値分類のいずれにおいてもP(xc|x)で表される_i,X_iC_j|V_j,T_j,S,I)	で表される場合もある．	ただし，X_iは事例X_iを記述する属性のベクトル，	C_jはクラスj,V_jは確率密度関数を具体化する	パラメータ集合，	T_jは確率密度関数の数式，Sは許容される確率密度関数	V_j,Tの空間，Iは明確には表現されない暗黙の情報を	表す~.．このようなクラス所属確率の意味からは，1つの事例が複数のクラスに所属するマルチラベル分類の可能性があってもよく~,またある事例の全クラスに対するクラス所属確率の推定値の総和が1である必要もない~.しかし，もし，シングルラベル分類で，全クラスに対するクラス所属確率の推定値を求めることができれば，その総和が1になるように正規化することが可能である．このようなクラス所属確率は「正規化されたクラス所属確率」とよばれ~,事後確率と考えることができる．対象とする分類問題をシングルラベルとして扱う場合，本来は正規化されたクラス所属確率を用いる必要があると考えられる．しかし，本稿においては，事例が注目するクラスに所属するか否かという問題に対する関心により，それぞれのクラスを独立に扱うため，一部の実験を除き基本的には正規化されたクラス所属確率を用いない．実際には，今回の実験では，正規化を行わないクラス所属確率の推定値の総和の平均はほぼ1に等しく，また限定された実験の結果ではあるが，本稿における提案手法に関しては，正規化を行わない場合は正規化された場合とほぼ同様かやや劣る結果であるため，本稿における結論は，正規化されたクラス所属確率を用いた場合には，さらなる説得性をもつと考えられる．クラス所属確率の推定は，分類器が出力するスコア（分類スコア）に基づいて行われる．非常に単純には，例えばナイーブベイズ分類器や決定木では分類スコアが[0,1]の値をとるために，分類スコアをそのまま用いることができる．また，サポートベクターマシン(SVM)のように分類スコアが[0,1]の値をとらない場合でも，最大値や最小値を利用して確率値に変換することは容易である.しかし，このようにして得られた推定値は実際の値から乖離することが多い．この理由は，例えば，ナイーブベイズ分類器が出力する確率値は，0または1に近い極端な値をとることが多いために，この値をそのままクラス所属確率とすると不正確になるためである~.また，決定木においては，少なくとも，ナイーブベイズ分類器の場合と同様の確率値の偏りおよび，リーフに関連する訓練事例数が少ない場合に分散が大きいという2つの問題があるが，刈り込みによっても確率値の改善は期待できないため，クラス所属確率の推定値としては使えない~.SVMにおいても，分類スコアとして用いられる分離平面からの距離が，事例がクラスに所属する程度に正確には比例しない~ために，単純な変換では正確な値を推定しにくい．したがって，クラス所属確率の正確な値を推定する方法についての研究が必要である.これまでにいくつかの方法が提案されているが，代表的なものに，Plattの方法~やZadroznyらにより提案された方法~がある．Plattの方法では，SVMにおける分離平面からの距離を分類スコアとし，この値をシグモイド関数を利用して[0,1]区間の値に変換してクラス所属確率値の推定値とする（図~における実線）．例えば，訓練事例により図~の実線で表されるような変換式が得られている場合に，ある事例の分類スコアが1.5であれば，この事例のクラス所属確率は0.9であると計算される．しかし，Plattの方法では分類器やデータセットによってはうまく推定できない場合があるとして~,Zadroznyらは決定木やナイーブベイズ分類器に対していくつかの方法を提案した~.このうち，ナイーブベイズ分類器に適用した「ビニングによる方法」は注目に値する．ビニングによる方法は，訓練事例を分類スコアの順にソートして等サンプルごとに「ビン」にまとめ，各ビンごとに正解率を計算しておいたものをクラス所属確率として利用する（表~を参照のこと．表の上段の数値（斜体）は各ビンにおける分類スコアの範囲，下段の数値は各ビンの正解率を表す）．すなわち，評価事例の分類スコアから該当するビンを参照し，そのビンの正解率を評価事例のクラス所属確率の推定値とする．例えば，訓練事例により表~が作成されている場合に，未知の事例の分類スコアが0.6であれば，この事例のクラス所属確率は0.46であると推定される．Zadroznyらは，ビニングによる方法には最適なビンの個数を決定するのが困難であるという問題があるとして，次にIsotonic回帰による方法を提案した~.Isotonic回帰による方法もビニングによる方法と同様に，訓練事例を分類スコアの順にソートすることが前提条件であるが，ビンとしてまとめずに事例ごとに確率（正解の場合1,不正解の場合0）を付ける点が異なる．確率値は初期値1または0で開始されるが，分類スコアと単調関係を保つようになるまで修正が繰り返され，最終的に定まった値を正解率とする（表~を参照のこと．表の上段の数値（斜体）は各事例の分類スコア，下段の数値は各事例の正解率を表す）．評価事例のクラス所属確率は，評価事例の分類スコアと等しい分類スコアをもつ事例の正解率を参照し，この値を推定値とする．例えば，訓練事例により表~が作成されている場合に，未知の事例の分類スコアが0.8であれば，この事例のクラス所属確率は0.5であると推定される.これまでに提案された方法はいずれも2値分類を想定しているために，クラス所属確率の推定には推定したいクラスの分類スコアのみを用いる．したがって，文書分類でしばしば用いられる多値分類に対しても，分類スコアを単独に用いて推定する2値分類に分解する方法が検討された~.すなわち，多値分類をいったん2値分類の組に分解し，それぞれの組で2値分類として推定したクラス所属確率の値を最後に統合（調整）する．多値分類を2値分類に分解するには，all-pairs(one-versus-one)およびone-against-all(one-versus-rest)の2つの方法があるが，Zadroznyらは，分解する方法そのものに精度の違いがないことを実験により示した上で，実験においてはいずれの場合もone-against-allを用いた．各組の2値分類における推定値を統合する方法としては，one-against-allにより分解した各組（クラスの数と等しい）において推定した値の合計が1になるようにそれぞれの推定値を正規化する方法がよい結果を示したことを報告した~.また，Zadroznyらによる最新の統合方法はさらに単純で，one-against-allにより分解した2値分類の各組において推定したクラス所属確率をそのままそのクラスについての推定値とする）個に対して行い，	残りの1クラスについては，これらの推定値を合計したものを1から	引いた値を推定値とする．~.多値分類についての推定方法についてはZadroznyらの研究以外になく，例えば，Caruanaらによるクラス所属確率の推定方法の比較~においても，2値分類を対象としており，多値分類に対しては，Zadroznyらの文献~の紹介にとどまっている．しかし，多値分類は2値分類の場合と異なり，予測されるクラスは分類スコアの絶対的な大きさではなく相対的な大きさにより決定されるために，クラス所属確率は推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられる．したがって，多値分類においては，推定したいクラス以外のクラスの分類スコアも用いることが有効であると思われる．本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第1位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．本稿ではまた，複数の分類スコアを用いてクラス所属確率を推定する別の方法として，「正解率表」（表~を参照のこと．表の最左列と最上段の数値（斜体）はそれぞれ第1位と第2位に予測されたクラスに対する分類スコアの範囲，それ以外の数値は、第1位のクラスについての正解率を表す．）を利用する方法も提案する．正解率表を利用する方法とは，各分類スコアのなす空間を等区間（例えば0.5）に区切って「セル」を作成し，各セルについて正解率を計算した表を用意して参照する方法である．例えば，「正解率表」を利用する方法において，訓練事例により表~が作成されている場合，未知の事例において第1位に予測されたクラスの分類スコアが0.8,第2位に予測されたクラスの分類スコアが-0.6であれば，この事例の第1位のクラスに対するクラス所属確率は0.67であると推定される．しかし，もし第2位に予測されたクラスの分類スコアが-0.2または0.3であれば，第1位のクラスについてのクラス所属確率の推定値は，それぞれ0.53または0.38のようにより小さな値になる．このように，提案手法は既存の方法と異なり，推定したいクラス所属確率に関連すると思われる別のクラス（例えば第2位のクラス）の分類スコアを直接利用することで，より正確な推定を行うことが可能になる．以下，次節で関連研究について述べた後，3節では，まず第1位に予測されたクラスのクラス所属確率を複数の分類スコアを用いて推定する方法を提案し，実験を行う．4節では3節で得られた結論を第2位以下の任意のクラスに対して拡張する方法を提案し，実験を行う．最後にまとめと今後の課題について述べる．</section>
  <section title="関連研究">ここでは，本稿の基礎として，クラス所属確率を推定する代表的な方法であるPlattの方法および，Zadroznyらにより提案されたビニングによる方法とIsotonic回帰による方法について述べる．これらはいずれも2値分類を想定しているが，Isotonic回帰による方法においては，2値分類を多値分類に対応させる方法についても述べる．最後に，Plattの方法とIsotonic回帰による方法について，多種類の分類器とデータセットによる実験を行って比較したCaruanaらによる研究~について述べる．</section>
  <subsection title="Platt の方法">Platt~は，分類器をSVMに限定し，分類スコアを事例に対してクラスが予測された際の分離平面からの距離fとして，シグモイド関数P(f)=1/1+(Af+B)により[0,1]区間に変換される値P(f)をクラス所属確率の推定値として用いることを提案した．ただし，パラメータAおよびBは，あらかじめ最尤法により推定しておく必要がある．シグモイド関数による方法の利点は，分類スコアから直接，クラス所属確率の推定値を求めることができるため，パラメータAおよびBが推定されていれば，手続きが容易であることである．Plattは，シグモイド関数の過学習を避けるために，out-of-sampleモデルを用いて，Reuters~を含む5種類のデータセットを用いて実験を行い，この方法の有効性を示した．データセットがAdultの場合における結果を図~に示す．図~において，X軸は分類スコア，Y軸はクラス所属確率を表し，+印は分類スコアを0.1の区間に分けた場合に対応するクラス所属確率の実測値，実線は推定値を表す．しかし，Bennett~は，Plattの方法は分類器がナイーブベイズの場合にうまくいかないことをReuters21,578データセットにより示した.また，Zadroznyら~も，この方法がデータセットによっては適合しない場合があることを示し，以下に述べる方法を提案した．</subsection>
  <subsection title="ビニングによる方法">Zadroznyらは，分類器としてナイーブベイズを想定し，ビニングによる方法（ヒストグラム法）を提案した~.ビニングによる方法は，未知の事例のクラス所属確率を直接推定せずに，あらかじめ作成しておいた「ビン」を参照し，そのビンにある正解率を用いて間接的に推定を行う方法である．ビニングによる方法における処理手順は次の通りである．まず，訓練事例を分類スコアの値順に並べ，各区間に属する事例数が等しくなるように区切ってビンを決める．このとき，各ビンに属する事例の分類スコアから，そのビンに所属する事例における分類スコアの最大値と最小値を調査しておく．ここまでの処理を図~に示す．図~はナイーブベイズ分類器の例で，数値（斜体）は分類スコアを表す．次に，各ビンごとに正解の事例を数えてそのビンに属す全事例数で割り，正解率を計算する（表~を参照のこと）．最後に，未知の事例の分類スコアから該当するビンを見つけ，そのビンの正解率を未知の事例のクラス所属確率値とする．実験はKDD'98データセットを用いて行われ，平均二乗誤差や平均対数損失による評価の結果，有効性が示された（ビンの数が10個の場合）．ビニングによる方法は処理が単純であるという利点があるが，最適なビンの個数をどのようにして決めればよいか（各ビンに含まれる事例数をいくつにするか）という問題がある．なお，Zadroznyらは，この後に，誤分類に対するコストを考慮した方法として，ビニングによる方法を改良した「Probing」という方法を提案したが，実験の結果，有効性を示さない場合も多かった~.</subsection>
  <subsection title="Isotonic 回帰による方法">Zadroznyらは，ビニングによる方法の問題点を解決する方法として，次には，分類スコアと正解率が単調非減少な関係にあるという観察に基づくIsotonic回帰による方法を提案した~.ここで，Isotonic回帰問題とは，実数の有限集合Y=y_1,y_2,,y_nが与えられたとき，制約条件x_1x_nの下で目的関数_i=1^nw_i(x_i-y_i)^2を最小化する2次計画問題である~.ただし，w_iは正値重みを表す．Isotonic回帰問題の解法としては，PAV(pool-adjacentviolatorsまたはpair-adjacentviolators)アルゴリズム（以下では，PAVと略す）が最も代表的であり~,Zadroznyらが提案したIsotonic回帰による方法もPAVが適用されている．ここで，PAVとは，単調非減少ではないブロックがある場合に，そのブロック内に存在する値のすべてをブロック内の値の平均値で置き換える処理を繰り返すことにより，全体の単調非減少性を保つ方法である．例えば，前述の目的関数において重みがすべて1のとき，1,3,2,4,5,7,6,8において，まず3,2のブロックが単調非減少ではないために，ブロック内のすべての値を平均値2.5で置き換えて1,2.5,2.5,4,5,7,6,8に修正する．次に，7,6のブロックが単調非減少ではないために，同様に平均値6.5で置き換えて1,2.5,2.5,4,5,6.5,6.5,8に修正する方法である~.PAVを用いたIsotonic回帰による方法も，ビニングによる方法と同様に，最初に訓練事例を分類スコア順にソートする必要があるが，事例をまとめて扱わずに，各事例に対して正解率（正例の場合は1,負例の場合は0となる）を付ける点が異なる（図~における開始時点の表を参照のこと）．正解率が分類スコアと単調非減少な関係になるまで正解率の修正を繰り返し，最終的に定まった値を正解率とする（図~における終了時点の表を参照のこと）．図~では1回修正された値が再度修正されることはなかったが，値の並び方によっては再修正される可能性が高く，一般的には何度も修正が繰り返される場合が多い~.実験は，ナイーブベイズ分類器とSVMにおいてKDD'98データセットなどを用い，ビニングによる方法やシグモイド関数による方法と比較された（ビニングの数は5個から50個まで変えて行われた）．平均二乗誤差による評価の結果，PAVによる方法はビニングによる方法を常に上回ったが，シグモイド関数による方法との差は少しであった．Zadroznyらは，次に，多値分類においては，分類器は各々の予測クラスに対して分類スコアを1つずつ出力すると仮定し，多値分類におけるPAVの効果を調査した．すなわち，2値分類においてPAVにより推定したクラス所属確率値を統合した場合と，PAVを用いずに推定した値を統合した場合との比較を行った~.Zadroznyらは，この実験の前に，あらかじめ，ナイーブベイズ分類器とブーステッドナイーブベイズにおいて20Newsgroupsデータセットなどを用いた実験を行って，2値分類への分解法であるall-pairsとone-against-allの間で精度の差がないことを確認し，実験ではすべてone-against-allを用いた．2値分類における推定値を統合する方法としては，one-against-allに対応した正規化の方法の他に，どちらの分解方法にも対応可能な最小2乗法による方法や対数損失を最小化するカップリングの方法が用いられたが，正規化の方法が最もよい結果を示した．PAVの有効性については，まず，ナイーブベイズ分類器とブーステッドナイーブベイズによりデータセットPendigitを用いた実験の結果，分類器や統合する方法に関係なく，平均二乗誤差による評価では改善がみられたが，エラー率による評価ではほとんど改善されなかった．次に，ナイーブベイズ分類器によりデータセット20Newsgroupsを用いた実験結果も，多値分類への統合方法に関係なく，平均二乗誤差による評価では改善がみられたが，エラー率による評価ではほとんど改善されなかった．ここで，2値分類における推定値の3種類の統合方法を比較すると，ナイーブベイズ分類器による値をPAVにより修正した値を正規化する方法がよかったが（平均二乗誤差により評価した場合），他の分類器や評価法においては差がなかった．なお，Zadroznyらは，この後さらに提案したProbingとよばれるクラス所属確率の推定方法を多値分類へ拡張する場合には，ここで述べた統合方法を用いずに，one-against-allにより分解した各組において2値分類として推定した値をそのまま用いるという非常に単純な方法を示した~.ただし，この方法に対する評価実験は行っていない．</subsection>
  <subsection title="方法の比較">Caruanaら~は，アンサンブル学習を含めた10種類の分類器（SVM,ニューラルネット，決定木，k近傍法，baggedtrees,randomforests,boostedtrees,boostedstumps,ナイーブベイズ分類器，ロジスティック回帰）を，8種類のデータセット（UCIRepositoryから4種類，医療分野から2種類選んだデータセット，IndianPine92データセット~,StanfordLinearAccelerator）に適用し，Plattの方法とIsotonic回帰による方法(PAV)の比較を行った．その結果，Plattの方法はデータが少ないとき（約1,000サンプル未満）に効果的であり，Isotonic回帰による方法は過学習しない程度に十分なデータがあるときによかった．Jonesら~は，検索を成功させるために，ユーザが入力したクエリから新しくクエリを生成して置き換えるというタスクにおいて，置き換えられたクエリの正確さの程度を予測するために確信度スコアが必要であると考え，Isotonic回帰による方法(PAV)とシグモイド関数による方法についての簡単な比較実験を行った．その結果，Isotonic回帰による方法は過学習の問題があり，平均二乗誤差および対数損失のいずれにおいてもシグモイド関数による方法の方が上回ったため，彼らのタスクではシグモイド関数による方法が採用された．</subsection>
  <section title="第 1 位のクラスについてのクラス所属確率推定">本稿においても，Zadroznyらと同様に，多値分類においては，分類器は各々の予測クラスに対して分類スコアを1つずつ出力すると仮定する．例えば，k値分類の場合は分類スコアをk個出力するものとする．このとき，第1位に予測されるクラスはすべての分類スコアの中で最大の分類スコアをもつクラスで，分類スコアの絶対的な大きさではなく分類スコア間の相対的な大きさにより決定される．したがって，例えば第1位の分類スコアが大きな値であっても，第2位の分類スコアも同じ程度に大きな値の場合には第1位のクラスが不正解であったり，逆に，第1位の分類スコアがたとえ小さな値であっても，第2位の分類スコアがさらに小さな値の場合には第1位のクラスが正解であるケースも観察される．以上より，多値分類において第1位のクラスのクラス所属確率は，第1位のクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられるために，正確な推定値を得るためには，第1位のクラス以外の分類スコアも考慮に入れた複数の分類スコアを用いる必要があると思われる．ここで，既存のビニングによる方法やIsotonic回帰による方法は，いずれも前提条件として，事例を分類スコアの順にソートする必要があるために，複数の分類スコアを用いることが困難である．したがって，複数の分類スコアを扱える方法を検討する必要がある．本稿は，パラメトリックな方法としてPlattの方法を，またノンパラメトリックな方法としてZadorznyらのビニングによる方法をそれぞれ参考にしながら，複数の分類スコアを有効に用いる方法を検討する．その際，対象とするクラスを，クラス所属確率の必要性が最も高い第1位に予測されたクラスと，それ以外のクラス（第2位以下に予測されたクラス）の2つの場合に分けて検討することにする．以下では，まず，本節において，第1位の予測クラスについてクラス所属確率の推定方法を検討し，有効な方法を提案する．次に，4節で，本節において提案された推定方法を第2位以下の任意のクラスに対して拡張する方法を提案する．</section>
  <subsection title="提案手法">本稿では，第1位のクラス所属確率を複数の分類スコアを用いて推定することを提案する．クラス所属確率を推定する方法としては，ロジスティック回帰により直接推定する方法と，正解率表を利用して間接推定する方法の2つを提案する．</subsection>
  <subsubsection title="ロジスティック回帰による方法">第1位のクラスから第r位のクラスまでr個の分類スコアを用いる場合，ロジスティック回帰による方法は（1）式により直接，クラス所属確率を推定する．用いる分類スコアの数に制限はない．ここで，f_iは第i位の分類スコアを表す．このとき，パラメータA_i(i)およびBは訓練事例を用い，最尤法によりあらかじめ推定しておく必要がある．ロジスティック回帰による方法の手順を次に示す．STEP1全訓練事例を，パラメータを推定するための訓練事例と評価事例に分割し，各評価事例についての分類スコアと正解の状態（正解か不正解か）のペアデータから，パラメータA_iとBの最尤推定を行う．このとき，訓練事例と評価事例の分割は交差検定による．STEP2未知の事例に対するクラス所属確率の推定は，未知の事例において用いるクラスの分類スコアf_iをロジスティック回帰式（（1）式）に代入し，クラス所属確率を直接推定する．</subsubsection>
  <subsubsection title="正解率表を利用する方法">本稿においては，正解率表とは，各分類スコアを軸として等区間に区切ってセルを作成し，各セルについて正解率（＝セル内の正解事例数／セル内の全事例数）を計算した表をいう（表3参照のこと）．正解率表は用いる分類スコアの数により次元が決まる．すなわち，k個の分類スコアを用いる場合にはk次元の正解率表になる．例えば，分類スコアを1つしか利用しない場合は等幅の区切りをもつ線分，2個利用する場合は同様の長方形，3個利用する場合は同様の直方体となる．正解率表を利用する方法の手順を次に示す．STEP1まず，正解率表を作成するためには，事例ごとに分類スコアと正誤状況のペアデータが必要である．これは，ロジスティック回帰による方法と全く同様に，全訓練事例を交差検定により，正解率表作成のための訓練事例と評価事例に分割して学習を行って得ることができる．次に，用いる分類スコアを軸とし，各軸とも等間隔（例えば，SVMの場合には0.1など）に区切ってセルを作成し，各セルごとに該当する事例をまとめて正解率を計算する．例えば，第1位のクラスと第2位のクラスの分類スコアの2つを用いて区間幅0.1とする場合，縦横ともに0.1間隔で区切られたセルをもつ長方形の正解率表となるが，訓練事例中の各評価事例における2つのクラスの分類スコアから，どのセルに属するかが決まる．すべての訓練事例の所属先セルが決定された時点で，各セルごとに所属する事例数と正解の事例数により正解率が計算できる．提案手法は，ビニングによる方法やIsotonic回帰による方法のように，事例を分類スコア順にソートしておく必要がないために，利用する分類スコアの数（次元）が複数であっても正解率表の作成を行うことが可能である．ただし，実際には，正解率表の次元が上がるに連れてセル数の爆発が起こるというノンパラメトリックな方法に特有の問題があるために，分類スコアの数を無制限に大きくすることはできない．また，訓練事例数に比較してセル数が多すぎる場合や，区間幅の決め方（セルの作り方）によっては，セルに含まれる事例数がゼロになる（ゼロ頻度問題）可能性があり，正解率が計算できないという問題もある．さらに，セルに属する事例数が等しくない可能性があるために，正解率における信頼性に違いが生じるという問題もある．ゼロ頻度問題や信頼性の問題については，STEP2で対応する．STEP2正解率表の精度を高めるために，STEP1で計算された正解率に対して平滑化を行う．まず，ゼロ頻度問題に対応する手法とし，ラプラス法やリッドストーン法がある~.分類スコアfが与えられたとき，ラプラス法P_Lap(f)およびリッドストーン法P_Lid(f)により平滑化された正解率は，次式により計算される:ただし，c(f)は平滑化を行うセル，N(c(f))は平滑化を行うセル中の訓練事例の数，N_p(c(f))は平滑化を行うセル中の正しく分類された訓練事例の数を表す.また，は擬似的に加える数であり，=1の場合がラプラス法である．ここで，正解率表におけるセルの位置と正解率の関係を観察すると，各セルとも正解率は周囲のセルの正解率と値が類似しており，各軸ごとに分類スコアの変化に伴う正解率の状況は，ほぼ単調な関係がみられる．例えば，第1位の分類スコアは正解率と正の相関があり，第2位の分類スコアでは正解率と負の相関が観察される．したがって，平滑化を行うセルに対して，そのセルの周囲に位置するセルの情報も用いることが有効であると考えられる．このような平滑化を可能にする手法としては，移動平均法やメディアン法~がある．分類スコアfが与えられたとき，移動平均法P_MA(f)およびメディアン法P_Median(f)により平滑化された正解率は，次式により計算される:P_MA(f)&amp;=N_p(c(f))N(c(f))+_sNb(c(f))	N_p(s)N(s)n,P_Median(f)&amp;=median_sNb(c(f))(N_p(c(f))N(c(f)),	N_p(s)N(s)).alignただし，Nb(c(f))は平滑化を行うセルc(f)の周囲に位置するセル，nは|Nb(c(f))|+1を表す．さらに，セルごとに正解率の信頼性が異なる問題を解決する方法としては，各セルのカバレッジを重み付けとして調整する方法が考えられる．移動平均法にカバレッジによる重み付けを行う方法P_MA_covにより平滑化された正解率は，次式により計算される:ただし，C(c(f))は各セルのカバレッジで，セルc(f)における事例数をすべての事例数で割った数を表す．周囲の情報も利用した平滑化手法においては，どこまでの範囲を周囲とするかという問題があるが，今回は，最も単純に，平滑化を行うセルに隣接するセルまでとする．例えば，分類スコアを1つ利用する場合には平滑化を行うセルを含めて計3個，分類スコアを2個利用する場合には，平滑化を行うセルを中心に斜めに位置するセルも含め計9個のセルを用いる.STEP3未知の事例に対するクラス所属確率の推定は，未知の事例において用いる分類スコアにより正解率表の中から該当するセルを見つけ，そのセルの正解率を推定値とする．</subsubsection>
  <subsection title="実験">実験の目的は，多値分類における第1位のクラスのクラス所属確率について有効な推定方法を調査し，複数の分類スコアを用いることが有効であることを示すこと（実験1），および実験1で最も有効であった方法の性能を評価すること（実験2）である．</subsection>
  <subsubsection title="実験設定">分類器分類器はSVMを用いたが，提案手法の汎用性を調査するため，一部の実験についてはナイーブベイズ分類器も用いた．SVMを選択した理由は，SVMは文書分類においてきわめて高い分類性能を示す分類器として認識され~,適用される場合が多いために，分類器を特定しても有用性が高いと思われたためである．ただし，SVMは本来は2値分類器であるために，one-versus-rest法~により多値分類器に拡張した.高橋ら(2005a)およびTakahashietal.(2005)にしたがって，SVMにおけるカーネル関数は線形カーネルを用いた．データセットデータセットは，日本語の調査データであるJGSSデータセットおよびZadroznyらの実験~において用いられた英文のネットニュース記事であるUseNetnewsarticles(20Newsgroups)データセットの2つを用いた．JGSSデータセットは，2000年から2003年までの4年間に毎年実施された調査により収集されたデータのうちの職業データ（サンプル数23,838）で，自由回答である「仕事の内容」「従業先事業の種類」の他に，選択回答である「従業上の地位」「役職」「従業先事業の規模」など複数の回答群から構成されている．すべての職業データに195個ある職業コードのいずれか1つのコードが付与されており，本稿ではこの職業コードを正解とした．例えば，次のような職業データには正解として職業コード「563」が付与されている．JGSSデータセットにおいては，先に開発した自動コーディングシステム~の設定を踏襲し，「仕事の内容」と「従業先事業の種類」に出現する単語unigramおよび「従業上の地位」と「役職」を表す選択肢を素性として用いた．訓練事例と評価事例の分割は，実際の職業コーディングの状況に似せて，すでに正解が付けられた過去のデータを訓練事例とし，これからコーディングを行う予定のデータを評価事例とした．今回は，訓練事例として2000年から2002年までの3年間分のデータ（20,066サンプル），評価事例として2003年のデータ（3,772サンプル）に分割した．さらに，訓練事例は正解率表を作成するため，5分割交差検定により訓練事例と評価事例に分割した．すなわち，正解率表を作成するために，データを変えて訓練事例16,053サンプル，評価事例4,013サンプルに分割し，計5回の学習を行った．20Newsgroupsデータセット（サンプル数18,828）は，さまざまなUseNetのディスカッショングループに対応する20個のカテゴリのいずれかに分類されており，本稿ではこれを正解とした．用いた素性は，ネットニュース記事に出現する単語unigramで，JGSSデータセットにおける自由回答の場合と同様である．20Newsgroupsデータセットでは，訓練事例と評価事例の分割は5分割交差検定により行った．すなわち，データを変えて，例えば，訓練事例15,063サンプル，評価事例3,765サンプルとし，計5回の学習を行った．正解率表の作成は，JGSSデータセットの場合と全く同様に，全訓練事例を5分割交差検定により，訓練事例（例えば12,053サンプル）と評価事例（例えば3,013サンプル）に分割し計5回の学習を行った．セルの区間幅最適なセルの区間幅は自動的に決めることができないために，実験を行って決める必要がある．今回は，区間幅を0.05,0.1,0.2,0.3,0.5の5通りに設定した．このとき，1つの正解率表においては，どの次元の軸も同一の区間幅で区切った．第1位のクラスの分類スコア軸における区間幅とセルの数との関係は，表~に示す通りであった．評価尺度実験1では，各手法の評価を行うために，Zadroznyら~にしたがい，次式で計算されるクロスエントロピーを用いた．ただし，Nは評価事例数，p_iはi番目の事例におけるクラス所属確率の推定値，y_iはi番目の事例における正誤状況で，正解の場合は1,不正解の場合は0を表す．クロスエントロピーの値が小さいほどよい手法であるとする．実験2では，提案手法の評価を行うために，Caruanaら~にしたがい，予測値がどの程度実測値と重なるかを表す信頼度曲線を用いた．予測値と実測値が重なる程度が高いほどよい手法であるとする．また，Zadroznyら~にしたがい，ROC(receiveroperatingcharacteristic)曲線に基づいて計算されるAUC(AreaUndertheCurve)を用いた評価も行った．AUCの値が大きいほどよい手法であるとする．提案手法の性能評価としては，誤分類検出能力により従来の検出手法との比較を行った．誤分類検出能力は，誤分類の事例を対象となる事例数のカバレッジが低い時点で多く検出できるほどよい手法であるとする．</subsubsection>
  <subsubsection title="実験 1：有効な方法の調査">セルの作成法実験1を行う前の予備実験として，正解率表におけるセルの作成法について，分類スコアを等間隔に区切る方法（提案手法）を各ビンの事例数を等しくする方法（Zadoroznyらによるビニングの方法）と比較し，提案手法の有効性を確認した．ここでは，Zadoroznyらによるビニングの方法との比較を可能にするために，提案手法においても用いる分類スコアを第1位のクラスに対するもののみとし，正解率の平滑化を行わない値を用いた．ここで，提案手法における定義域は[-,+]であるが，今回用いたデータセットにおける第1位のクラスの分類スコアの範囲は，分類器がSVMの場合，JGSSデータセットでは[-0.99,5.48],20Newsgroupsデータセットでは[-2.92,19.636]であった．表~は，2つの方法により作成されたセルからなる正解率表の有効性を，データセットや分類器を変えてクロスエントロピーにより比較した結果である．表中，等間隔は我々の提案する方法（セルの区間幅を等間隔にする方法），等事例はZadroznyらの提案する方法（セルに含まれる事例数を等しくする方法）を表す．表の値は，等間隔の方法では区間幅を0.1から0.5まで4通り，等事例の方法においても，この区間幅に対応させてセルの個数を30個から7個まで4通りに変化させた中のそれぞれ最もよかった場合の値である．太字の数字は，2つの方法のうちよい方の値を示す．表~において，セルを等間隔に区切る方法は，ナイーブベイズ分類器ではセルに含まれる事例を等しくする方法にやや劣るものの，SVMではどちらのデータセットでも大きく上回る結果を示した．この傾向は，最もよかった値同士の比較だけではなく，セルの区間幅（セルの個数）が異なっても全く同様であった．この理由としては，一般に，データを各区間の度数が等しくなるように分割する方法は各区間幅が等しくなるように分割する方法より推定効率が高いことが知られているが，一方で，密度関数推定の観点から大きなバイアスを引き起こす可能性があることが指摘されており~,今回用いたデータセットの分類スコアの分布において，特にSVMを適用した場合にこのバイアス問題が生じたのではないかと考えられる．その結果，セルを等事例で区切る方法において作成された正解率表は，セルに属する事例の分類スコアと正解率の関係を適切に反映したものにならなかったのではないかと思われる．表~より，「分類スコアを等間隔に区切ってセルを作成する方法」により正解率表を作成する方法が有効であることが確認できたため，以下の実験では，セルの作成は分類スコアを等間隔に区切る方法を用いた．なお，今回，等事例に区切る方法において最もよかったのは，セルの個数が12個または7個の場合であったが，Zadroznyらのビニングによる方法においてもビンの個数が10個の場合が最もよかったとの報告があり~,第1位のクラスの分類スコアのみを用いる場合には，分類器やデータセットが異なっていても最適なセルの個数が類似していることは興味深い．クロスエントロピーによる評価表~は，SVMを適用しJGSSデータセットを用いた場合のクロスエントロピーの値を，用いた分類スコア別，クラス所属確率を推定する方法別にまとめたものである．表において，重み付け移動平均法はカバレッジを重みとする移動平均法を表す．リッドストーン法においては最もよい場合の値を示す．表の縦方向はセルの区間幅を0.05から0.5まで5通りに変化させたことを示しており，各区間幅の上段は利用した分類スコアが第1位のクラスのみの場合，下段は利用した分類スコアが第1位と第2位のクラスの場合の結果を示す．表中の記号「---」はクロスエントロピーが計算できなかったセルがあったことを示す．また，太字の数字は，表中のすべての値の中で最もよい値であることを示す．表では省略したが，正解率表を利用する方法において，第1位から第3位まで3つのクラスの分類スコアを用いた場合のクロスエントロピーは，いずれも第1位のクラスのみの場合よりははるかによく第1位と第2位のクラスの場合よりやや悪かった．なお，1節で述べた2種類の単純な変換~によるクロスエントロピーは，Nicllescu-Mizilらによる変換では1.4563であり，Zadroznyらによる変換では0.8332であった．同様に，SVMを適用し20Newsgroupsデータセットを用いた結果を表~に示す．表の形式や記号の意味などは表~と同様である．ここでも，正解率表を利用する方法においては，第1位から第3位まで3つのクラスの分類スコアを用いた場合のクロスエントロピーはJGSSデータセットを用いた場合と全く同様で，いずれも第1位のクラスのみの場合よりははるかによく，第1位と第2位のクラスの場合よりやや悪かった．なお，1節で述べた単純な変換によるクロスエントロピーは，Nicllescu-Mizilらによる変換では計算できず，Zadroznyらによる変換では0.9199であった．表~および表~より，次のことが明らかになった．まず，SVMを適用した場合は，クラス所属確率を推定する方法やデータセットに関係なく，第1位のクラスの分類スコアのみ用いるより他のクラスの分類スコアも含めた複数の分類スコアを用いることが有効であった．分類スコアの有効な組み合わせ方については，ロジスティック回帰による方法と正解率表を利用する方法で異なっており，ロジスティック回帰による方法は，第1位のクラスから第3位のクラスまで3つの分類スコアを用いた場合，正解率表を利用する方法は，第1位のクラスと第2位のクラスの2つの分類スコアを用いた場合が最もよかった．ただし，いずれの方法においても，分類スコアの組み合わせ方の違いによる差は小さかった．次に，ロジスティック回帰による方法も含めてすべての場合の中で最もよい結果を示したのは，最適な正解率表を利用した場合，すなわち「第1位と第2位のクラスの分類スコアを用いてカバレッジを重みとする移動平均法による平滑化を行った正解率表を利用する方法」（セルの区間幅0.1）であった．ただし，正解率表を利用する方法は，セルの区間幅の決め方により結果に大きな差があった．特にセルの区間幅を非常に小さく（0.05）設定した場合は，複数の分類スコアを用いることは有効ではなかった．この理由は，セルの個数が増えることにより各セルごとに含まれる事例数が少なくなり，場合によっては事例が存在しないセルが出現したために，正解率における信頼性が低くなったことが原因であると考えられる．正解率表を利用する方法においてはロジスティック回帰による方法と異なり，分類スコアを3つ用いた方が2つ用いた場合より結果が悪かった理由も，同様であると考えられる．今回は，最適なセルの区間幅は，どちらのデータセットにおいても0.1であった．これに対して，ロジスティック回帰による方法は，どちらのデータセットにおいても安定してよい結果を示した．さらに，正解率表における平滑化の手法は，いずれもデータセットに関係なく有効であった．特に，平滑化を行うセルの周囲にあるセルの情報も利用する方法である（カバレッジを重みとする）移動平均法は，セルの区間幅が適切であった場合によい結果を示した．注目するセルの情報のみで平滑化を行うラプラス法やリッドストーン法は，クロスエントロピーにおいては大きな効果はなかったが，ゼロ頻度問題に対応できる点で評価できる．ここで，正解率表を利用する方法における結論をより一般化させるために，分類器をナイーブベイズ分類器に変え，20Newsgroupsデータセットによる実験を行った．結果は表~に示すように，SVMの場合と同様に，第1位のクラスの分類スコアのみを用いた場合より，第2位のクラスまで2つの分類スコアを用いた場合の方がよかった．また，平滑化手法は有効で，特にセルの区間幅が適切な場合に移動平均法はよい結果を示した．ナイーブベイズ分類器において最もよかったのはセルの個数が30個の場合であり，これはSVMにおいて最もよかったセルの区間幅0.1の場合に該当する．以上より，多値分類における第1位のクラスのクラス所属確率の推定は，複数の分類スコアを用いることが有効であった．特に，最適な正解率表である「第1位と第2位のクラスの分類スコアを用いて（カバレッジによる重み付き）移動平均法による平滑化を行い，セルの区間幅を0.1（セルの個数30個）に設定した正解率表」を利用する方法は最も有効であった．ただし，正解率表を利用する方法は設定されたセルの区間幅により結果が不安定であるという問題があったのに対して，ロジスティック回帰による方法は安定してよい結果を示した．また，今回は，正解率表を利用する方法における最適な正解率表がデータセットや分類器に関係なく一致したが，この結果をさらに一般化するには，データセットや分類器をより多様なものに変えた実験を行って確認する必要がある．したがって，現時点では，正解率表を利用する方法は，データセットや分類器が異なる場合に最適な正解率表を決定するための実験を行う必要があり，手間がかかるという欠点があるといえる．</subsubsection>
  <subsubsection title="実験 2：提案手法の評価">ここでは，SVMを適用して，実験1において最適であった方法（以後，提案手法とよぶ）の評価を行った．信頼度曲線およびROC曲線信頼度曲線は，予測値（推定値）（X軸）と実際の値（Y軸）の関係をプロットしたもので，予測値と実際の値が等しい場合には対角線上にプロットされ，対角線から離れるほど予測の精度が悪いことを示す．ここでは，提案手法を，分類スコアを1つ用いた方法のうち，平滑化を行わない正解率表を利用する方法（以後，平滑化を行わない方法とよぶ）およびシグモイド関数による方法と比較した．このとき，平滑化を行わない方法は，等事例ではなく等間隔に区切ったビニングによる方法であると考えることができ，シグモイド関数による方法はPlattの方法を簡略化したものであると考えられる．今回は，予測値を0.1ずつ区切り10区間を作成し，予測値と真の値としていずれも区間内（例えば，[0,0.1]）に含まれる事例の平均を用いた．JGSSデータセットによる結果を図~に，20Newsgroupsデータセットによる結果を図~に示す．図~および図~において，提案手法はどちらのデータセットにおいても対角線の近くにプロットされており，クラス所属確率を全体的にうまく推定することがわかった．ROC曲線は，X軸がFPF（FalsePositiveFraction;偽陽性率），Y軸がTPF（TruePositiveFraction;真陽性率）を表す座標上に，正解率の程度により分類された各グループごとのFPFとTPFの値をプロットしたものである．ここで，FPF＝注目するグループ内の不正解事例数／全不正解事例数，TPF＝注目するグループ内の正解事例数／全正解事例数である．今回は，正解率を10点刻みに分類してFPFとTPFの値を求めた．すなわち，最上位のグループ（正解率が91%〜100%の範囲にある事例）から始めて，上限を固定し下限を10%ずつ下げたグループ（例えば2番目のグループは，正解率の範囲が81%〜100%である事例の集合）を計10個作成し，各グループにおけるFPFとTPFを計算した．ROC曲線においては，ROC曲線が左上方に位置するほど正確な推定が行われていることを示すが，より正確には，ROC曲線の下方にある領域であるAUC(AreaUndertheCurve)を計算し，その値が大きいほどよい手法であるとされる．図~に，JGSSデータセットおよび20Newsgroupsデータセットによる提案手法，平滑化を行わない方法，シグモイド関数による方法におけるROC曲線を示す．また，3つの手法におけるAUCの値を表~に示す．図~および表~より明らかなように，提案手法はいずれのデータセットにおいても他の2つの方法より正確な推定を行えることがわかった．誤分類検出能力事例をクラス所属確率の推定値の小さい順に並べたとき，カバレッジの値が小さいときにできるだけ多くの誤分類事例が検出されることが望ましい．カバレッジをこのように考えた場合に，各カバレッジごとにどのくらい誤分類された事例を検出できるかを，本稿では誤分類検出能力とよぶ．提案手法の誤分類検出能力を，JGSSデータセットおよび20Newsgroupsデータセットを用いて評価した．評価の方法は，提案手法によるクラス所属確率の推定値を値の小さい順に事例を並べ，カバレッジを10%ずつ増やしてできた区間ごとに，誤分類された事例数を調査した．比較のため，既存の手法であるSchohnにより提案された単純な方法~による結果も示した．単純な方法では，分類スコアの値の小さい順に並べ，同様にカバレッジを10%ずつ増やしてできた区間ごとに，誤分類された事例数を調査した．それぞれのデータセットによる結果を図~に示す．図~において，提案手法はどちらのデータセットにおいても常に単純な方法を上回った．特に，20Newsgroupsデータセットにおいては，カバレッジが小さい場合に大きく上回る点が評価できる．その理由は，我々が実際に人手により分類誤りを検出する必要がある場合，チェックをするデータセットの量はできる限り少量の方が作業が楽であるからである．JGSSデータセットでは，全体の40%をチェックすれば誤分類事例の80%を検出することができるが，20Newsgroupsデータセットで同じ量をチェックすると，誤分類事例の90%を検出できる．両者のデータセットにおける傾向の違いを説明する理由は明確ではないが，JGSSデータセットには非常に短く有効な素性が少ししか含まれない事例が多いため，正確な推定を行うために十分な情報がないことが原因であると考えられる．以上をまとめると，多値分類において第1位に予測されたクラスのクラス所属確率の推定は，複数の分類スコアを用いることが有効であることがわかった．特に，第1位と第2位に予測されたクラスの分類スコアを用いて作成した最適な正解率表を利用する方法が最もよい結果を示した．ここで，最適な正解率表とは，セルの区間幅を0.1（セルの個数が30）として作成した正解率表を（カバレッジによる重み付き）移動平均法による平滑化を行ったものである．ただし，正解率表を利用する方法は正解率表の作成法により結果が不安定であるという欠点があった．この点において，ロジスティック回帰による方法は安定してよい結果を示した．また，ロジスティック回帰による方法は，最適な正解率表を見つけるために実験を重ねる手間が不要であるという利点もある．</subsubsection>
  <section title="第 2 位以下の任意のクラスについてのクラス所属確率推定">3節で，多値分類における第1位の予測クラスについてのクラス所属確率は，複数の分類スコアを用いた推定が有効であることが明らかになった．本節では，3節で得られた結論を第2位以下の任意のクラスに対して拡張する方法を検討する．この場合，どのクラスの分類スコアを組み合わせることが有効であるかを検討することが重要である．</section>
  <subsubsection title="実験 1：分類スコアの有効な組み合わせ方">分類スコアの候補実験1を行う前の予備実験として，推定したいクラスのクラス所属確率と関連の深いクラスを発見するために，第2位以下のすべてのクラスについて，注目するクラスの正誤状況（正解の場合1，不正解の場合0）と全クラスの分類スコアとの相関関係を調査した．これは，注目するクラスの正誤状況と相関係数の絶対値が大きい分類スコアのクラスほど注目するクラスとの関連が強いと仮定したためである．したがって，相関係数の絶対値の大きな分類スコアが多い順位のクラスを候補として用いることを検討した．JGSSデータセットと20Newsgroupsデータセットを用いて第2位から第20位のクラスにおいて，各クラスごとに関連の強かったクラスを表~にまとめる．表~より，注目するクラス（推定したいクラス）自身より第1位のクラスの方が多かったため，用いるクラスの候補として第1位のクラスを候補とした．また，注目するクラスの直前や直後のクラスも候補とした．次に，これらの3つのクラスの分類スコアを推定したいクラスとそれぞれ単純に組み合わせた場合におけるクロスエントロピーを，JGSSデータセットと20newsgroupsデータセットを用いて調査した．その結果，どちらのデータセットにおいても，第1位のクラスの分類スコアを組み合わせた場合以外は有効性が認められなかったため，実験1では，複数の分類スコアとして次の3つの組み合わせ方を考え，「推定したいクラスの分類スコアのみを用いる」場合と比較を行った（（）内は用いる分類スコアの数を表す）．このとき，分類スコアを3個以上用いた場合のクラス所属確率の推定には，3節で述べた（1）式を適宜修正した式を用いた．［提案手法］「推定したいクラスと第1位のクラスの分類スコア」（2個）「第1位のクラスから推定したいクラス（第k位のクラス）までのすべてのクラスの分類スコア」（k個）「推定したいクラスとその直前および直後のクラスの分類スコア」（3個）提案手法の有効性図~は，JGSSデータセットと20Newsgroupsデータセットにより，用いた分類スコアの組み合わせを変えた場合のクロスエントロピーを，推定したいクラスの順位別（X軸）に示したものである．ただし，どちらのデータセットにおいても，13位以下のクラスにおいては12位と同様の傾向であったために省略した．図~から明らかなように，どちらのデータセットにおいても，推定したいクラスが上位の場合には，推定したいクラスの分類スコアのみを用いるより，クラスの組み合わせ方に関係なく複数の分類スコアを用いた方がよかった．特に提案手法である「推定したいクラスと第1位のクラスの分類スコア」を用いた場合は，どの順位においても最もよかった．ただし，推定したいクラスの順位が下がるにつれて，どの方法もクロスエントロピーの値が小さくなり，方法間の違いの差がみられなくなった．この理由は，クラスの順位が下がるにつれてどの方法であってもクラス所属確率の推定値が小さくなり，また予測されたクラスも不正解である場合が多くなるために，クロスエントロピーも小さくなったためだと考えられる．次に，提案手法を含めた4つの方法におけるROC曲線を，第2位のクラスと第3位のクラスに注目した場合についてそれぞれ図~および図~に示す．ただし，第2位のクラスにおいては，「第1位から推定したいクラスまでのすべてのクラスの分類スコアを用いる方法」は提案手法と同じ方法であるために，図~では省略した．また，図~9，図~10におけるAUCを表~に示す．表中，太字の数字は，各ケースにおいて最もよい値であることを示す．図~,図~,表~より，注目するクラスやデータセットが異なっても，複数の分類スコアを用いる方法は，注目するクラスの分類スコアだけを用いる方法よりよかった．AUCによる評価において最もよかった方法は，JGSSデータセットの場合は提案手法であり，20Newsgroupsデータセットの場合は，注目するクラスと直前および直後のクラスの分類スコアを用いる方法（第2位のクラスの場合）や，第1位から推定したいクラスまでのすべてのクラスの分類スコアを用いる方法（第3位のクラスの場合）であった．ただし，提案手法は20Newsgroupsデータセットの場合も安定してよかった．以上より，第2位以下の任意のクラスについてのクラス所属確率を推定する場合も，複数の分類スコアを用いることは有効であり，特に推定したいクラスと第1位のクラスの分類スコアを用いる方法は有効であることが示された．最後に，ロジスティック回帰式におけるパラメータを最尤推定するために用いる訓練事例数を変化させたときのクロスエントロピーを調査した．図~は，JGSSデータセットにより，推定したいクラスの分類スコアのみ用いる方法と提案手法を比較したものである．X軸は訓練事例数を表しており，右端はこれまでの実験において訓練事例として用いられてきた20,066サンプルの場合，左端は1,000サンプルにまで減らした場合を表す．図~より，まず，訓練事例の数に関係なく提案手法が有効であることがわかった．また，訓練事例が1,000サンプルと比較的少ない場合でも，ロジスティック回帰による方法は安定してよい結果を示すこともわかった．</subsubsection>
  <subsubsection title="実験 2：ロジスティック回帰による方法の有効性">ここでは，提案手法による分類スコアの組み合わせにおいて，ロジスティック回帰による方法を最適な正解率表を利用する方法と比較した．このとき，最適な正解率表としては次の2つを検討した．1つは第1位のクラスについて推定する場合に最も有効であった正解率表（セルの区間幅を0.1に設定）で，推定したいクラスごとに新たな正解率表を作成する手間を省略する目的で用いた．もう1つは，第2位以下の各クラスにおける分類スコアのとる値の状況に合わせて，セルの区間幅を適宜（例えば0.2など）変えたもので，「正解率表（改良版）」とよぶことにする．いずれの正解率表も，3節で最も有効であった平滑化手法すなわちカバレッジを重みとする移動平均法による平滑化を行った．図~に，ロジスティック回帰による方法と正解率表を利用する方法におけるクロスエントロピーを示す．図~より，注目するクラスが第2位から第5位までの場合の平均において，ロジスティック回帰による方法が最も有効であることが示された．正解率表（改良版）を利用する方法は，JGSSデータセットにおいて第2位のクラスに注目する場合や，20Newsgroupsデータセットにおいて第3位のクラスに注目する場合のみ，ロジスティック回帰による方法よりわずかによい結果であったが，注目するクラスに対して毎回，最適な正解率表を作成する手間がかかるという欠点がある．3つの方法におけるROC曲線の例として，JGSSデータセットを用いて第2位のクラスに注目する場合を図~に示す．このとき，3つの方法におけるAUCは，それぞれロジスティック回帰による方法（0.7443），第1位のクラスに対する最適な正解率表を利用する方法（0.7260），正解率表（改良版）を利用する方法（0.7449）で，JGSSデータセットにおいて第2位のクラスを推定する場合に限り，正解率表（改良版）を利用する方法がロジスティック回帰による方法をやや上回った．今回，第6位以下のクラスについては比較実験を行っていないが，先に述べたように，下位のクラスになるにしたがって最適な正解率表の作成は困難になることが予想されるため，第6位以下のクラスにおいてもロジスティック回帰による方法が有効であると考えられる．以上より，第2位以下の任意のクラスにおいても，ロジスティック回帰による方法の方が正解率表を利用する方法より有効であると判断できた．</subsubsection>
  <section title="結論">本稿では，文書分類で適用されることの多い多値分類における任意のクラスのクラス所属確率を，複数の分類スコアを用いて高精度に推定する方法を提案した．提案手法は，複数個の分類スコア，特に推定したいクラスと第1位のクラスの分類スコアを用いてロジスティック回帰によりクラス所属確率を推定する．ここで，第1位のクラスについては，第1位と第2位のクラスの分類スコアのなす空間を等間隔（0.1）に区切って作成した各セルにおいて正解率を計算し，カバレッジを重みとする移動平均法により平滑化を行った正解率表を参照する方法も有効であった．提案手法は，SVMを適用し，性質の異なる2種類のデータセット（社会調査データである日本語自由回答や英文の自由投稿ネットニュース記事）を用いて実験した結果，どちらのデータセットにおいても有効性を示した．また，誤分類の検出において，従来の方法を上回った．今後の課題は，提案手法の有効性を理論的に裏付けることが必要であると考えられる．</section>
</root>
