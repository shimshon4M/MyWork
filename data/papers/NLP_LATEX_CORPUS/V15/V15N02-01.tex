    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.1}
\usepackage{amsmath}
\usepackage[dvips]{graphicx}
\usepackage{hangcaption_jnlp}

\Volume{15}
\Number{2}
\Month{Apr.}
\Year{2008}
\received{2007}{6}{10}
\revised{2007}{11}{20}
\accepted{2007}{12}{23}

\setcounter{page}{3}

\jtitle{複数の分類スコアを用いたクラス所属確率の推定}
\jauthor{高橋　和子\affiref{KEIAI} \and 高村　大也\affiref{PRECISION} 
	\and 奥村　　学\affiref{PRECISION}}
\jabstract{
文書分類の多くのアプリケーションにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用で，正確な推定値が必要とされる．これまでに提案された推定方法はいずれも 2 値分類を想定し，推定したいクラスの分類スコア（分類器が出力するスコア）のみを用いている. しかし，文書分類では多値分類が適用されることが多く，その場合は，予測されるクラスはクラスごとに出力された分類スコアの絶対的な大きさではなく相対的な大きさにより決定される. 
したがって，クラス所属確率は，推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられるため，推定したいクラス以外の分類スコアも用いて推定する必要があると思われる．本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第 1 位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．提案手法を多値分類に拡張したサポートベクターマシンに適用し，性質の異なる 2 つのデータセットを用いて実験した結果，有効性が示された. また，本稿では，クラス所属確率を推定する別の方法として，各分類スコアを軸として等間隔に区切ってセルを作成する「正解率表」を利用する方法も提案したが，この方法においても複数の分類スコアを用いることは有効であった．提案手法は，分類スコアの組み合わせや分類器の変更に対しても容易に対応できる.
}
\jkeywords{クラス所属確率，ロジスティック回帰，複数の分類スコア，多値分類，\\
	文書分類，正解率表，平滑化}

\etitle{Estimation of Class Membership Probabilities by Using Multiple Classification Scores}
\eauthor{Kazuko Takahashi\affiref{KEIAI}
	\and Hiroya Takamura\affiref{PRECISION} 
	\and Manabu Okumura\affiref{PRECISION}} 
\eabstract{
We propose a method for estimating class membership probabilities of a predicted class in multiclass classification, using scores outputted by a classifier (classification scores), not only for the predicted class but also for other classes in a document classification. Class membership probabilities are important in many applications of document classification, in which multiclass classification is often applied. As a method for estimating class membership probabilities by using multiple scores, we propose two kinds of methods. One is generating an accuracy table with smoothing methods such as the moving average or a moving average with coverage, which indirectly estimates class membership probabilities by referring the accuracy table. The other is applying a logistic regression estimated parameters beforehand, which directly estimate these probabilities. Through experiments on two different datasets with both Support Vector Machines and Naive Bayes classifiers, we show that the use of multiple classification scores is much effective in both methods. We also show that the proposed smoothing method for the accuracy table works quite well, and that the method applying a logistic regression is more stable. Moreover, the estimated class membership probabilities by the proposed method are useful in the detection of the misclassified samples. 
}
\ekeywords{Class membership probability, Logistic regression, 
	Multiple classificaion scores, Multiclass classification, Document classification, 
	Accuracy table, Smoothing}

\headauthor{高橋，高村，奥村}
\headtitle{複数の分類スコアを用いたクラス所属確率の推定}

\affilabel{KEIAI}{敬愛大学国際学部}{Faculty of International Studies, Keiai University}
\affilabel{PRECISION}{東京工業大学精密工学研究所}{Precision and Intelligence Laboratory, Tokyo Institute of Technology}



\begin{document}
\maketitle


\section{序論}\label{sec:hajime}

自然言語処理においては，タグ付けや文書分類をはじめとするさまざまな分類タスクにおいて，分類器が出力するクラスに確信度すなわちクラス所属確率を付与することは有用である．
例えば，自動分類システムがより大きなシステムの一部を構成し，自動分類結果が別のシステムに自動入力されるような場合に，クラス所属確率は重要な役割を果たす．
この例として，ブログ記事に対してさまざまな観点から付けられたタグ（複数）をユーザに表示するシステムにおいて，タグを自動的に付与する際に，クラス所属確率が閾値より低いタグについては排除することが有効な場合がある~\cite{Ohkura06}.  同様に，手書き文字認識システムによる分類結果が，言語モデルのようなドメイン知識を組み込んだシステムの入力である場合も，クラス所属確率が用いられている~\cite{Zadrozny02}. 
また，自動的にタグ付けされた事例のうち誤分類されたものを人手により訂正したい場合に，すべての事例をチェックするのは大きなコストがかかるが，
クラス所属確率が低いものほど不正解である可能性が高いと仮定し，
クラス所属確率が閾値を下回る事例のみを訂正することにすれば，効率的な作業が行える．
さらに，自動分類結果が人間の意思決定を支援する場合においては，クラス所属確率は判断の根拠を与える．
例えば，高橋らは，
社会調査において自由回答で収集される職業データを該当する職業コードに自動分類し~\cite{Takahashi05a,Takahashi05c}, 
上位 5 位までに予測されたクラスを候補として画面に提示するシステム（NANACO システム）を開発した~\cite{Takahashi05b}.  
NANACO システムは，我が国の主要な社会調査である JGSS（Japanese General Social Surveys; 日本版総合的社会調査）\kern-0.5zw\footnote{
	\texttt{http://jgss.daishodai.ac.jp/}. JGSS プロジェクトは，シカゴ大学 NORC 
	(the National Opinion Research Center) における GSS プロジェクトの日本版であり，
	国際比較分析を可能にするために，日本の社会や態度，行動に関する調査項目を有する．
} や，
SSM 調査（Social Stratification and Social Mobility Survey; 
社会階層と社会移動調査）\kern-0.5zw\footnote{
	\texttt{http://www.sal.tohoku.ac.jp/coe/ssm/index.html}.  1995 年から 10 年ごとに
	実施されている「仕事と暮らしに関する」全国調査である．
} などに利用されているが，
システムを利用したコーダから，
提示された各クラスについてどの程度確からしいかを示すクラス所属確率を付与してほしいという要望が出されている\footnote{
	NANACO システムが適用されるたびに，コーダによるシステム評価を行っている．
}．
最後に，クラス所属確率は EM アルゴリズムにおいても有用である．
例えば，語の曖昧性解消において，あるドメインで訓練された分類器を，別のドメインのコーパス用に調整するために用いられた EM アルゴリズムにおいて，クラス所属確率は精度の向上に役立つことが報告されている~\cite{Chan06}.  

事例 $x$ があるクラス $c$ に所属するクラス所属確率 $P$ は，2 値分類，多値分類のいずれにおいても $P(x \in{c}|x)$ で表される\footnote{
	クラス所属確率 $P$ の別の定義として，
	$P(\overrightarrow{\rm X}_{i},X_{i}\in{C_{j}}|\overrightarrow{\rm V}_{j},T_{j},S,I)$ 
	で表される場合もある．
	ただし，$\overrightarrow{\rm X}_{i}$ は事例 $X_{i}$ を記述する属性のベクトル，
	$C_{j}$ はクラス $j$, $\overrightarrow{\rm V}_{j}$ は確率密度関数を具体化する
	パラメータ集合，
	$T_{j}$ は確率密度関数の数式，$S$ は許容される確率密度関数 
	$\overrightarrow{\rm V}_{j}$, $T$ の空間，$I$ は明確には表現されない暗黙の情報を
	表す~\cite{Cheeseman96}.
}．
このようなクラス所属確率の意味からは，1 つの事例が複数のクラスに所属するマルチラベル分類の可能性があってもよく~\cite{erosheva05}, 
またある事例の全クラスに対するクラス所属確率の推定値の総和が $1$ 
である必要もない~\cite{Canters02}\footnote{
	さらに，Carreiras (2005) らにおいては，$n$ 個の分類器のバギングにより生成された分類器に
	おいて，クラス所属確率の推定値として，それぞれのクラスごとに各分類器におけるクラス
	所属確率の推定値の平均をそのまま用いている~\cite{Carreiras05}.
}. 
しかし，もし，シングルラベル分類で，全クラスに対するクラス所属確率の推定値を求めることができれば，その総和が $1$ になるように正規化することが可能である．このようなクラス所属確率は「正規化されたクラス所属確率」とよばれ~\cite{Cheeseman96}, 
事後確率と考えることができる．
対象とする分類問題をシングルラベルとして扱う場合，本来は正規化されたクラス所属確率を用いる必要があると考えられる．しかし，本稿においては，事例が注目するクラスに所属するか否かという問題に対する関心により，それぞれのクラスを独立に扱うため，一部の実験を除き基本的には正規化されたクラス所属確率を用いない．
実際には，
今回の実験では，正規化を行わないクラス所属確率の推定値の総和の平均はほぼ 1 に等しく，
また限定された実験の結果ではあるが\footnote{
	3.2.2 節および 4.2.2 節において報告を行う．
}，
本稿における提案手法に関しては，正規化を行わない場合は正規化された場合とほぼ同様かやや劣る結果であるため，本稿における結論は，正規化されたクラス所属確率を用いた場合には，さらなる説得性をもつと考えられる\footnote{
	この理由は，既存の方法に関しては，正規化を行う場合の方が正規化を行わない
	場合より結果が悪いためである．ただし，一般化するにはさらなる実験が必要である．
}．

クラス所属確率の推定は，分類器が出力するスコア（分類スコア）に基づいて行われる．非常に単純には，例えばナイーブベイズ分類器や決定木では分類スコアが $[0,1]$ の値をとるために，
分類スコアをそのまま用いることができる． 
また，サポートベクターマシン (SVM) のように分類スコアが $[0,1]$ の値をとらない場合でも，
最大値や最小値を利用して確率値に変換することは容易である\footnote{
	例えば分類スコアが $f$ の場合，$(f-min)/(max-min)$~\cite{Mizil05} または 
	$(f+max)/2*max$~\cite{Zadrozny02} により $[0,1]$ の値に変換することが可能である．
	ここで，$max$, $min$ はそれぞれ分類スコアの最大値，最小値を表す．
}. 
しかし，このようにして得られた推定値は実際の値から乖離することが多い．
この理由は，例えば，ナイーブベイズ分類器が出力する確率値は，0 または 1 に近い極端な値をとることが多いために，この値をそのままクラス所属確率とすると不正確になるためである\footnote{
	Zadrozny らによれば，ナイーブベイズ分類器が出力する確率は，
	その大小関係を用いた事例のランキングをうまく行うことはできる．
}~\cite{Zadrozny02}. 
また，決定木においては，少なくとも，ナイーブベイズ分類器の場合と同様の確率値の偏りおよび，
リーフに関連する訓練事例数が少ない場合に分散が大きいという 2 つの問題\footnote{
	度数が少ないことによる信頼性の低さが原因である．
}があるが，刈り込みによっても確率値の改善は期待できないため，クラス所属確率の推定値としては使えない~\cite{Zadrozny01b}.   
SVM においても，分類スコアとして用いられる分離平面からの距離が，事例がクラスに所属する程度に正確には比例しない~\cite{Zadrozny02} ために，
単純な変換では正確な値を推定しにくい．
したがって，クラス所属確率の正確な値を推定する方法についての研究が必要である.


\begin{table}[b]
\begin{center}
\caption{ビニングによる方法において参照される正解率の例}
\raisebox{1zw}[0pt][0pt]{（ナイーブベイズ分類器を利用しビンが 3 個の場合）}
\par
\label{bining1}
\input{01table01.txt}
\end{center}
\end{table}

これまでにいくつかの方法が提案されているが，代表的なものに，
Platt の方法~\cite{Platt99} や Zadrozny らにより提案された方法~\cite{Zadrozny01a,Zadrozny01b,Zadrozny02,Zadrozny05} がある． 
Platt の方法では，SVM における分離平面からの距離を分類スコアとし，
この値をシグモイド関数を利用して $[0,1]$ 区間の値に変換してクラス所属確率値の推定値とする（図~\ref{Platt} における実線）．
例えば，訓練事例により図~\ref{Platt} の実線で表されるような変換式が得られている場合に，ある事例の分類スコアが 1.5 であれば，この事例のクラス所属確率は 0.9 であると計算される．
しかし，Platt の方法では分類器やデータセットによってはうまく推定できない場合があるとして~\cite{Bennett00,Zadrozny01b}, 
Zadrozny らは決定木やナイーブベイズ分類器に対していくつかの方法を提案した~\cite{Zadrozny01a,Zadrozny01b}. 
このうち，
ナイーブベイズ分類器に適用した「ビニングによる方法」は注目に値する．
ビニングによる方法は，
訓練事例を分類スコアの順にソートして等サンプルごとに「ビン」にまとめ，各ビンごとに正解率を計算しておいたものをクラス所属確率として利用する（表~\ref{bining1} を参照のこと．表の上段の数値（斜体）は各ビンにおける分類スコアの範囲，下段の数値は各ビンの正解率を表す）． 
すなわち，評価事例の分類スコアから該当するビンを参照し，そのビンの正解率を評価事例のクラス所属確率の推定値とする．
例えば，訓練事例により表~\ref{bining1} が作成されている場合に，未知の事例の分類スコアが 0.6 であれば，この事例のクラス所属確率は 0.46 であると推定される．
Zadrozny らは，ビニングによる方法には最適なビンの個数を決定するのが困難であるという問題があるとして，
次に Isotonic 回帰による方法を提案した~\cite{Zadrozny02}. 
Isotonic 回帰による方法もビニングによる方法と同様に，訓練事例を分類スコアの順にソートすることが前提条件であるが，
ビンとしてまとめずに事例ごとに確率（正解の場合 1, 不正解の場合 0）を付ける点が異なる．
確率値は初期値 1 または 0 で開始されるが，分類スコアと単調関係を保つようになるまで修正が繰り返され，最終的に定まった値を正解率とする（表~\ref{Isotonic1} を参照のこと．表の上段の数値（斜体）は各事例の分類スコア，下段の数値は各事例の正解率を表す）．
評価事例のクラス所属確率は，評価事例の分類スコアと等しい分類スコアをもつ事例の正解率を参照し，この値を推定値とする．
例えば，訓練事例により表~\ref{Isotonic1} が作成されている場合に，未知の事例の分類スコアが 0.8 であれば，この事例のクラス所属確率は 0.5 であると推定される.

\begin{table}[b]
\begin{center}
\caption{Isotonic 回帰による方法において参照される正解率の例（SVM を利用し事例数が 10 の場合）}
\label{Isotonic1}
\input{01table02.txt}
\end{center}
\end{table}

これまでに提案された方法\footnote{
	これらの方法についての詳しい解説はこの後 2 節で行う．
}はいずれも 2 値分類を想定しているために，
クラス所属確率の推定には推定したいクラスの分類スコアのみを用いる．
したがって，文書分類でしばしば用いられる多値分類に対しても，分類スコアを単独に用いて推定する 2 値分類に分解する方法が検討された~\cite{Zadrozny02,Zadrozny05}.  
すなわち，
多値分類をいったん 2 値分類の組に分解し，それぞれの組で 2 値分類として推定したクラス所属確率の値を最後に統合（調整）する．
多値分類を 2 値分類に分解するには，all-pairs (one-versus-one) および one-against-all (one-versus-rest) の 2 つの方法があるが，
Zadrozny らは，
分解する方法そのものに精度の違いがないことを実験により示した上で，
実験においてはいずれの場合も one-against-all を用いた．
各組の 2 値分類における推定値を統合する方法としては，
one-against-all により分解した各組（クラスの数と等しい）において推定した値の合計が 1 になるようにそれぞれの推定値を正規化する方法がよい結果を示したことを報告した\footnote{
	Zadrozny らが推定値を統合する方法として提案した他の方法については，
	2.3 節で述べる．
}~\cite{Zadrozny02}. 
また，Zadrozny らによる最新の統合方法はさらに単純で，
one-against-all により分解した 2 値分類の各組において推定したクラス所属確率をそのままそのクラスについての推定値とする\footnote{
	ただし，この推定は（$\text{分類クラスの数}-{1}$）個に対して行い，
	残りの 1 クラスについては，これらの推定値を合計したものを 1 から
	引いた値を推定値とする．
}~\cite{Zadrozny05}. 
多値分類についての推定方法については Zadrozny らの研究以外になく，
例えば，Caruana らによるクラス所属確率の推定方法の比較~\cite{Mizil05} においても，2 値分類を対象としており，多値分類に対しては，Zadrozny らの文献~\cite{Zadrozny02} の紹介にとどまっている．

しかし，多値分類は 2 値分類の場合と異なり，予測されるクラスは分類スコアの絶対的な大きさではなく相対的な大きさにより決定されるために，クラス所属確率は推定したいクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられる．したがって，多値分類においては，推定したいクラス以外のクラスの分類スコアも用いることが有効であると思われる．

本稿は，多値分類における任意のクラスについてのクラス所属確率を，複数の分類スコア，特に推定したいクラスと第 1 位のクラスの分類スコアを用いて，ロジスティック回帰により高精度に推定する方法を提案する．
本稿ではまた，複数の分類スコアを用いてクラス所属確率を推定する別の方法として，「正解率表」（表~\ref{accuracy_table1} を参照のこと．表の最左列と最上段の数値（斜体）はそれぞれ第 1 位と第 2 位に予測されたクラスに対する分類スコアの範囲，それ以外の数値は、第 1 位のクラスについての正解率を表す．）を利用する方法も提案する．
正解率表を利用する方法とは，各分類スコアのなす空間を等区間（例えば 0.5）に区切って
「セル」\footnote{
	正解率表は多次元を想定するために，
	ビンではなくセルの語を用いることにする．
}を作成し，各セルについて正解率を計算した表を用意して参照する方法である．
例えば，「正解率表」を利用する方法において，
訓練事例により表~\ref{accuracy_table1} が作成されている場合，未知の事例において第 1 位に予測されたクラスの分類スコアが 0.8, 第 2 位に予測されたクラスの分類スコアが $-0.6$ であれば，この事例の第 1 位のクラスに対するクラス所属確率は 0.67 であると推定される．
しかし，もし第 2 位に予測されたクラスの分類スコアが $-0.2$ または 0.3 であれば，第 1 位のクラスについてのクラス所属確率の推定値は，それぞれ 0.53 または 0.38 のようにより小さな値になる．
このように，提案手法は既存の方法と異なり，推定したいクラス所属確率に関連すると思われる別のクラス（例えば第 2 位のクラス）の分類スコアを直接利用することで，より正確な推定を行うことが可能になる．


\begin{table}[b]
\begin{center}
\hangcaption{複数の分類スコアを用いた正解率表の例（SVM を利用し，第 1 位と第 2 位のクラスの分類スコアを用いた場合）}
\label{accuracy_table1}
\input{01table03.txt}
\end{center}
\end{table}

以下，次節で関連研究について述べた後，
3 節では，まず第 1 位に予測されたクラスのクラス所属確率を複数の分類スコアを用いて推定する方法を提案し，実験を行う．
4 節では 3 節で得られた結論を第 2 位以下の任意のクラスに対して拡張する方法を提案し，実験を行う．
最後にまとめと今後の課題について述べる．

\section{関連研究}\label{sec:kanren}

ここでは，
本稿の基礎として，
クラス所属確率を推定する代表的な方法である Platt の方法および，Zadrozny らにより提案されたビニングによる方法と Isotonic 回帰による方法について述べる．
これらはいずれも 2 値分類を想定しているが，
Isotonic 回帰による方法においては，2 値分類を多値分類に対応させる方法についても述べる．
最後に，
Platt の 方法と Isotonic 回帰による方法について，多種類の分類器とデータセットによる実験を行って比較した Caruana らによる研究~\cite{Caruana04,Mizil05} について述べる．

\subsection{Platt の方法}

Platt~\cite{Platt99} は，分類器を SVM に限定し，
分類スコアを事例に対してクラスが予測された際の分離平面からの距離 $f$ として，
シグモイド関数 $P( f ) = 1/\{1+\exp(Af+B)\}$ により [0,1] 区間に変換される値 $P (f)$ をクラス所属確率の推定値として用いることを提案した．
ただし，パラメータ $A$ および $B$ は，あらかじめ最尤法により推定しておく必要がある．
シグモイド関数による方法の利点は，
分類スコアから直接，クラス所属確率の推定値を求めることができるため，
パラメータ $A$ および $B$ が推定されていれば，手続きが容易であることである．
Platt は，シグモイド関数の過学習を避けるために，out-of-sample モデルを用いて，
Reuters~\cite{Joachims98} を含む 5 種類のデータセットを用いて実験を行い，
この方法の有効性を示した．
データセットが Adult の場合における結果を図\ref{Platt}~\cite{Platt99} に示す．
図~\ref{Platt} において，$X$ 軸は分類スコア，$Y$ 軸はクラス所属確率を表し，$+$ 印は分類スコアを 0.1 の区間に分けた場合に対応するクラス所属確率の実測値，実線は推定値を表す．


\begin{figure}[b]
  \begin{center}
\includegraphics{15-2ia1f1.eps}
\caption{Platt の方法による推定値と実測値の例}
\label{Platt}
  \end{center}
\end{figure}


しかし，Bennett~\cite{Bennett00} は，Platt の方法は分類器がナイーブベイズの場合にうまくいかないことを Reuters 21,578 データセット\footnote{
	\texttt{http://www.daviddlewis.com/resources/testcollections/reuters21578/}
}により示した\footnote{
	Bennett~\cite{Bennett00} の実験では，特に，出現頻度が少ないクラス（例えば $Corn$ など）
	において信頼度曲線（3.2.1 節を参照のこと）による評価が悪かった．
}. 
また，Zadrozny ら~\cite{Zadrozny02} も，この方法がデータセットによっては適合しない場合があることを示し\footnote{
	Zadrozny ら~\cite{Zadrozny02} の実験では，Adult データセットと 
	TIC (The Insurance Company Benchmark) データセットにナイーブベイズ分類器を適用した場合は，
	スコアの変換がうまくいかなかった．
}，以下に述べる方法を提案した．

\subsection{ビニングによる方法}

Zadrozny らは，分類器としてナイーブベイズを想定し，ビニングによる方法（ヒストグラム法）を提案した~\cite{Zadrozny01a,Zadrozny01b}. 
ビニングによる方法は，未知の事例のクラス所属確率を直接推定せずに，
あらかじめ作成しておいた「ビン」を参照し，そのビンにある正解率を用いて間接的に推定を行う方法である．
ビニングによる方法における処理手順は次の通りである．

まず，訓練事例を分類スコアの値順に並べ，
各区間に属する事例数が等しくなるように区切ってビンを決める．
このとき，各ビンに属する事例の分類スコアから，そのビンに所属する事例における分類スコアの最大値と最小値を調査しておく．
ここまでの処理を図~\ref{bining} に示す．
図~\ref{bining} はナイーブベイズ分類器の例で，数値（斜体）は分類スコアを表す．


\begin{figure}[b]
  \begin{center}
\includegraphics{15-2ia1f2.eps}
\caption{ビンの作成例（訓練事例数が 12 でビンの数が 3 個の場合）}
\label{bining}
  \end{center}
\end{figure}


次に，各ビンごとに正解の事例を数えてそのビンに属す全事例数で割り，正解率を計算する（表~\ref{bining1} を参照のこと）．
最後に，未知の事例の分類スコアから該当するビンを見つけ，そのビンの正解率を未知の事例のクラス所属確率値とする．

実験は KDD'98 データセット\footnote{
	\texttt{http://kdd.ics.uci.edu/}
}を用いて行われ，
平均二乗誤差や平均対数損失による評価の結果，有効性が示された（ビンの数が 10 個の場合）．
ビニングによる方法は処理が単純であるという利点があるが，
最適なビンの個数をどのようにして決めればよいか（各ビンに含まれる事例数をいくつにするか）という問題がある．

なお，Zadrozny らは，この後に，誤分類に対するコストを考慮した方法として，ビニングによる方法を改良した「Probing」という方法を提案したが，
実験の結果，有効性を示さない場合も多かった\footnote{
	決定木，バギングされた決定木，SVM, ナイーブベイズ，ロジスティック回帰において，
	UCI machine learning repository や UCI KDD archive, 2004 KDD における
	計 15 種類のデータセットを用いて実験し，二乗誤差，クロスエントロピー，
	AUC (Area under the ROC curve) によりを評価を行った．
}~\cite{Zadrozny05}. 

\subsection{Isotonic 回帰による方法}

Zadrozny らは，ビニングによる方法の問題点を解決する方法として，
次には，分類スコアと正解率が単調非減少な関係にあるという観察に基づく Isotonic 回帰による方法\footnote{
	Chanらは，語の曖昧性解消タスクにおける EM アルゴリズムで，Isotonic 回帰による方法を
	用いてクラス所属確率の推定を行った~\cite{Chan06}.
}を提案した~\cite{Zadrozny02}. 
ここで，Isotonic 回帰問題とは，
実数の有限集合 $Y=\{y_{1}, y_{2}, \cdots, y_{n}\}$ が与えられたとき，
制約条件 $x_{1}\le \cdots \le x_{n}$ の下で目的関数 $\sum_{i = 1}^{n} w_i(x_i - y_i)^{2}$ を最小化する 2 次計画問題である~\cite{Kearsley96}. 
ただし，$w_i$ は正値重みを表す．

Isotonic 回帰問題の解法としては，PAV (pool-adjacent violators または pair-adjacent violators) アルゴリズム（以下では，PAV と略す）が最も代表的であり~\cite{Kearsley96,Ahuja01,Mizil05,Fawcett06}, Zadrozny らが提案した Isotonic 回帰による方法も PAV が適用されている．
ここで，PAV とは，単調非減少ではないブロックがある場合に，そのブロック内に存在する値のすべてをブロック内の値の平均値で置き換える処理を繰り返すことにより，全体の単調非減少性を保つ方法である．
例えば，
前述の目的関数において重みがすべて 1 のとき，
\{1, 3, 2, 4, 5, 7, 6, 8\} において，まず \{3, 2\} 
のブロックが単調非減少ではないために，ブロック内のすべての値を平均値 2.5 で置き換えて \{1, 2.5, 2.5, 4, 5, 7, 6, 8\} に修正する．
次に，\{7, 6\} のブロックが単調非減少ではないために，同様に平均値 6.5 で置き換えて \{1, 2.5, 2.5, 4, 5, 6.5, 6.5, 8\} に修正する方法である~\cite{Kearsley96}. 

PAV を用いた Isotonic 回帰による方法も，ビニングによる方法と同様に，最初に訓練事例を分類スコア順にソートする必要があるが，
事例をまとめて扱わずに，各事例に対して正解率（正例の場合は 1, 負例の場合は 0 となる）を付ける点が異なる（図~\ref{Isotonic} における開始時点の表を参照のこと）．
正解率が分類スコアと単調非減少な関係になるまで正解率の修正を繰り返し，最終的に定まった値を正解率とする（図~\ref{Isotonic} における終了時点の表を参照のこと）．
図~\ref{Isotonic} では 1 回修正された値が再度修正されることはなかったが，値の並び方によっては再修正される可能性が高く，一般的には何度も修正が繰り返される場合が多い~\cite{Kearsley96,Ahuja01,Mizil05,Fawcett06}. 


\begin{figure}[t]
  \begin{center}
\includegraphics{15-2ia1f3.eps}
\caption{Isotonic 回帰による方法における正解率の修正例（SVM を利用し事例数が 10 の場合）}
\label{Isotonic}
  \end{center}
\end{figure}

実験は，
ナイーブベイズ分類器と SVM において KDD'98 データセットなどを用い，
ビニングによる方法やシグモイド関数による方法と比較された（ビニングの数は 5 個から 50 個まで変えて行われた）．
平均二乗誤差による評価の結果，PAV による方法はビニングによる方法を常に上回ったが，
シグモイド関数による方法との差は少しであった．

Zadrozny らは，次に，多値分類においては，分類器は各々の予測クラスに対して分類スコアを 1 つずつ出力すると仮定し，多値分類における PAV の効果を調査した．すなわち，2 値分類において PAV により推定したクラス所属確率値を統合した場合と，PAV を用いずに推定した値を統合した場合との比較を行った~\cite{Zadrozny02}. 
Zadrozny らは，この実験の前に，あらかじめ，ナイーブベイズ分類器とブーステッドナイーブベイズにおいて 20 Newsgroups データセット\footnote{
	\texttt{http://people.csail.mit.edu/jrennie/20Newsgroups/}
}などを用いた実験を行って，2 値分類への分解法である all-pairs と one-against-all の間で精度の差がないことを確認し，実験ではすべて one-against-all を用いた．
2 値分類における推定値を統合する方法としては，
one-against-all に対応した正規化の方法の他に，
どちらの分解方法にも対応可能な最小 2 乗法による方法や対数損失を最小化するカップリングの方法が用いられたが，正規化の方法が最もよい結果を示した．


PAV の有効性については，まず，ナイーブベイズ分類器とブーステッドナイーブベイズによりデータセット Pendigit を用いた実験の結果，
分類器や統合する方法に関係なく，平均二乗誤差による評価では改善がみられたが，
エラー率による評価ではほとんど改善されなかった．
次に，ナイーブベイズ分類器によりデータセット 20 Newsgroups を用いた実験結果も，
多値分類への統合方法に関係なく，平均二乗誤差による評価では改善がみられたが，
エラー率による評価ではほとんど改善されなかった．
ここで，2 値分類における推定値の 3 種類の統合方法を比較すると，
ナイーブベイズ分類器による値を PAV により修正した値を正規化する方法がよかったが（平均二乗誤差により評価した場合），他の分類器や評価法においては差がなかった．

なお，Zadrozny らは，この後さらに提案した Probing とよばれるクラス所属確率の推定方法を多値分類へ拡張する場合には，ここで述べた統合方法を用いずに，
one-against-all により分解した各組において 2 値分類として推定した値をそのまま用いるという非常に単純な方法を示した~\cite{Zadrozny05}. 
ただし，この方法に対する評価実験は行っていない．

\subsection{方法の比較}

Caruana ら~\cite{Caruana04,Mizil05} は，
アンサンブル学習を含めた 10 種類の分類器（SVM, ニューラルネット，決定木，k 近傍法，
bagged trees, random forests, boosted trees, boosted stumps,  ナイーブベイズ分類器，
ロジスティック回帰）を，
8 種類のデータセット（UCI Repository から 4 種類，医療分野から 2 種類選んだデータセット，IndianPine92 データセット~\cite{Gualtieri99}, Stanford Linear Accelerator）に適用し，
Platt の方法と Isotonic 回帰による方法 (PAV) の比較を行った．
その結果，
Platt の方法はデータが少ないとき（約 1,000 サンプル未満）に効果的であり，
Isotonic 回帰による方法は過学習しない程度に十分なデータがあるときによかった．

Jones ら~\cite{Jones06} は，検索を成功させるために，ユーザが入力したクエリから新しくクエリを生成して置き換えるというタスクにおいて，置き換えられたクエリの正確さの程度を予測するために確信度スコアが必要であると考え，Isotonic 回帰による方法 (PAV) とシグモイド関数による方法についての簡単な比較実験を行った． 
その結果，
Isotonic 回帰による方法は過学習の問題があり，
平均二乗誤差および対数損失のいずれにおいてもシグモイド関数による方法の方が上回ったため，
彼らのタスクではシグモイド関数による方法が採用された．

\section{第 1 位のクラスについてのクラス所属確率推定}

本稿においても，Zadrozny らと同様に，多値分類においては，分類器は各々の予測クラスに対して分類スコアを 1 つずつ出力すると仮定する．
例えば，$k$ 値分類の場合は分類スコアを $k$ 個出力するものとする．
このとき，第 1 位に予測されるクラスはすべての分類スコアの中で最大の分類スコアをもつクラスで，分類スコアの絶対的な大きさではなく分類スコア間の相対的な大きさにより決定される．
したがって，例えば第 1 位の分類スコアが大きな値であっても，第 2 位の分類スコアも同じ程度に大きな値の場合には第 1 位のクラスが不正解であったり，
逆に，第 1 位の分類スコアがたとえ小さな値であっても，第 2 位の分類スコアがさらに小さな値の場合には第 1 位のクラスが正解であるケースも観察される．
以上より，多値分類において第 1 位のクラスのクラス所属確率は，第 1 位のクラスの分類スコアだけでなく他のクラスの分類スコアにも依存すると考えられるために，正確な推定値を得るためには，第 1 位のクラス以外の分類スコアも考慮に入れた複数の分類スコアを用いる必要があると思われる．

ここで，
既存のビニングによる方法や Isotonic 回帰による方法は，
いずれも前提条件として，事例を分類スコアの順にソートする必要があるために，
複数の分類スコアを用いることが困難である．
したがって，複数の分類スコアを扱える方法を検討する必要がある．
本稿は，パラメトリックな方法として Platt の方法を，またノンパラメトリックな方法として Zadorzny らのビニングによる方法をそれぞれ参考にしながら，複数の分類スコアを有効に用いる方法を検討する．
その際，対象とするクラスを，クラス所属確率の必要性が最も高い第 1 位に予測されたクラスと，それ以外のクラス（第 2 位以下に予測されたクラス）の 2 つの場合に分けて検討することにする．

以下では，まず，本節において，第 1 位の予測クラスについてクラス所属確率の推定方法を検討し，有効な方法を提案する．
次に，4 節で，本節において提案された推定方法を第 2 位以下の任意のクラスに対して拡張する方法を提案する．

\subsection{提案手法}\label{method}

本稿では，第 1 位のクラス所属確率を複数の分類スコアを用いて推定することを提案する．
クラス所属確率を推定する方法としては，
ロジスティック回帰により直接推定する方法と，
正解率表を利用して間接推定する方法の 2 つを提案する．

\subsubsection{ロジスティック回帰による方法}

第 1 位のクラスから第 $r$ 位のクラスまで $r$ 個の分類スコアを用いる場合，
ロジスティック回帰による方法は（1）式により直接，クラス所属確率を推定する．
用いる分類スコアの数に制限はない．
\begin{equation}
P_{Log}( f_{1},\cdots , f_{r} ) = \frac{1}{1+\exp (\sum_{i=1}^r A_{i}f_{i}+B)},
\end{equation}
ここで，
$f_{i}$ は第 $i$ 位の分類スコアを表す．
このとき，
パラメータ $A_{i}$ ($\forall i$) および $B$ は訓練事例を用い，
最尤法によりあらかじめ推定しておく必要がある．

ロジスティック回帰による方法の手順を次に示す．
\vspace{0.5\baselineskip}
\begin{description}
\item[STEP 1]
ロジスティック回帰式におけるパラメータの推定

\item[STEP 2]
クラス所属確率の推定
\end{description}
\vspace{0.5\baselineskip}
\noindent
{\bf STEP 1}
\par
全訓練事例を，パラメータを推定するための訓練事例と評価事例に分割し，
各評価事例についての分類スコアと正解の状態（正解か不正解か）のペアデータから，パラメータ $A_{i}$ と $B$ の最尤推定を行う．
このとき，訓練事例と評価事例の分割は交差検定による．
\vspace{1\baselineskip}\par
\noindent
{\bf STEP 2}

未知の事例に対するクラス所属確率の推定は，未知の事例において用いるクラスの分類スコア $f_{i}$ をロジスティック回帰式（（1）式）に代入し，クラス所属確率を直接推定する．


\subsubsection{正解率表を利用する方法}

本稿においては，正解率表とは，各分類スコアを軸として等区間に区切ってセルを作成し，各セルについて正解率（＝セル内の正解事例数／セル内の全事例数）を計算した表をいう（表 3 参照のこと）．
正解率表は用いる分類スコアの数により次元が決まる．
すなわち，$k$ 個の分類スコアを用いる場合には $k$ 次元の正解率表になる．
例えば，分類スコアを 1 つしか利用しない場合は等幅の区切りをもつ線分，
2 個利用する場合は同様の長方形，
3 個利用する場合は同様の直方体となる．

正解率表を利用する方法の手順を次に示す．\\

\begin{description}
\item[STEP 1]
正解率表のためのセルの作成と正解率の計算 

\item[STEP 2]
正解率の平滑化

\item[STEP 3]
クラス所属確率の推定
\end{description}

\vspace{1\baselineskip}
\noindent
{\bf STEP 1}

まず，正解率表を作成するためには，
事例ごとに分類スコアと正誤状況のペアデータが必要である．
これは，ロジスティック回帰による方法と全く同様に，全訓練事例を交差検定により，正解率表作成のための訓練事例と評価事例に分割して学習を行って得ることができる．
次に，用いる分類スコアを軸とし，各軸とも等間隔（例えば，SVM の場合には 0.1 など）に区切ってセルを作成し，各セルごとに該当する事例をまとめて正解率を計算する．
例えば，第 1 位のクラスと第 2 位のクラスの分類スコアの 2 つを用いて区間幅 0.1 とする場合，縦横ともに 0.1 間隔で区切られたセルをもつ長方形の正解率表となるが，
訓練事例中の各評価事例における 2 つのクラスの分類スコアから，どのセルに属するかが決まる．
すべての訓練事例の所属先セルが決定された時点で，
各セルごとに所属する事例数と正解の事例数により正解率が計算できる．

提案手法は，ビニングによる方法や Isotonic 回帰による方法のように，事例を分類スコア順にソートしておく必要がないために，
利用する分類スコアの数（次元）が複数であっても正解率表の作成を行うことが可能である．ただし，実際には，正解率表の次元が上がるに連れてセル数の爆発が起こるというノンパラメトリックな方法に特有の問題があるために，分類スコアの数を無制限に大きくすることはできない．
また，訓練事例数に比較してセル数が多すぎる場合や，区間幅の決め方（セルの作り方）によっては，セルに含まれる事例数がゼロになる（ゼロ頻度問題）可能性があり，
正解率が計算できないという問題もある．
さらに，
セルに属する事例数が等しくない可能性があるために，
正解率における信頼性に違いが生じるという問題もある．
ゼロ頻度問題や信頼性の問題については，STEP 2 で対応する．
\vspace{1\baselineskip}\par
\noindent
{\bf STEP2}

正解率表の精度を高めるために，STEP 1 で計算された正解率に対して平滑化を行う．
まず，ゼロ頻度問題に対応する手法とし，
ラプラス法やリッドストーン法がある~\cite{Kita99_j}. 
分類スコア $f$ が与えられたとき，
ラプラス法 $P_{Lap}(f)$ およびリッドストーン法 $P_{Lid}(f)$ により平滑化された正解率は，
次式により計算される: 
\begin{equation}
P_{LapLid}(f)=\frac{N_{p}(c(f))+\delta} {N(c(f))+2\delta}.
\end{equation} 
ただし，
 $c(f)$ は平滑化を行うセル，
$N(c(f))$ は平滑化を行うセル中の訓練事例の数，
$N_{p}(c(f))$ は平滑化を行うセル中の正しく分類された訓練事例の数を表す.
また，$\delta$ は擬似的に加える数\footnote{
	本稿では，$\delta$ の最適な値を実験により決定する．
}であり，$\delta=1$ の場合がラプラス法である．

ここで，正解率表におけるセルの位置と正解率の関係を観察すると，
各セルとも正解率は周囲のセルの正解率と値が類似しており，
各軸ごとに分類スコアの変化に伴う正解率の状況は，
ほぼ単調な関係がみられる．
例えば，
第 1 位の分類スコアは正解率と正の相関があり，
第 2 位の分類スコアでは正解率と負の相関が観察される．
したがって，平滑化を行うセルに対して，
そのセルの周囲に位置するセルの情報も用いることが有効であると考えられる．
このような平滑化を可能にする手法としては，
移動平均法やメディアン法~\cite{Agui91_j} がある．
分類スコア $f$ が与えられたとき，
移動平均法 $P_{MA}(f)$ およびメディアン法 $P_{Median}(f)$ により平滑化された正解率は，
次式により計算される:
\begin{align}
 P_{\mathit{MA}}(f) & = \frac{\frac{N_p(c(f))}{N(c(f))} + \sum_{s\in Nb(c(f))}
	 \frac{N_p(s)}{N(s)}}{n},\\
 P_{\mathit{Median}}(f) & = \mathit{median}_{s\in Nb(c(f))} \Bigg( \frac{N_p(c(f))}{N(c(f))} , 
	\frac{N_p(s)}{N(s)} \Biggr).
\end{align}
ただし，
$Nb(c(f))$ は平滑化を行うセル $c(f)$ の周囲に位置するセル，
$n$ は $|Nb(c(f))|+1$ を表す．

さらに，
セルごとに正解率の信頼性が異なる問題を解決する方法としては，
各セルのカバレッジを重み付けとして調整する方法が考えられる．
移動平均法にカバレッジによる重み付けを行う方法 $P_{MA\_cov}$ により平滑化された正解率は，
次式により計算される: 
\begin{equation}
P_{\mathit{MA}\_cov}(f)=\frac{\frac{N_p(c(f))}{N(c(f))}C(c(f))
 + \sum_{s\in Nb(c(f))} \frac{N_p(s)}{N(s)}C(s)}{C(c(f))+\sum_{s\in Nb(c(f))}C(s)}.
\end{equation}
ただし，
 $C(c(f))$ は各セルのカバレッジで，
セル $c(f)$ における事例数をすべての事例数で割った数を表す．

周囲の情報も利用した平滑化手法においては，どこまでの範囲を周囲とするかという問題があるが，
今回は，最も単純に，平滑化を行うセルに隣接するセルまでとする．
例えば，
分類スコアを 1 つ利用する場合には平滑化を行うセルを含めて計 3 個，
分類スコアを 2 個利用する場合には，平滑化を行うセルを中心に斜めに位置するセルも含め計 9 個のセルを用いる\footnote{
	ただし，端や端の列（行）に位置するセルで用いられるセルは，この数より少ない．
}. \\\\ 
{\bf STEP3}
 
未知の事例に対するクラス所属確率の推定は，
未知の事例において用いる分類スコアにより正解率表の中から該当するセルを見つけ，そのセルの正解率を推定値とする．

\subsection{実験}

実験の目的は，
多値分類における第 1 位のクラスのクラス所属確率について有効な推定方法を調査し，複数の分類スコアを用いることが有効であることを示すこと（実験 1），
および実験 1 で最も有効であった方法の性能を評価すること（実験 2）である．

\subsubsection{実験設定} 
\noindent{\bf 分類器}

分類器は SVM を用いたが，提案手法の汎用性を調査するため，一部の実験についてはナイーブベイズ分類器も用いた．
SVM を選択した理由は，
SVM は文書分類においてきわめて高い分類性能を示す分類器として認識され~\cite{Joachims98,Dumais_et_al98,Taira00,Sebastiani02}, 
適用される場合が多いために，
分類器を特定しても有用性が高いと思われたためである．
ただし，SVM は本来は 2 値分類器であるために，
one-versus-rest 法~\cite{kressel99} により多値分類器に拡張した\footnote{
	\texttt{http://chasen.org/\textasciitilde taku/software/TinySVM/}
}. 
高橋ら (2005a) および Takahashi et al. (2005) にしたがって，SVM におけるカーネル関数は線形カーネルを用いた．
\vspace{1\baselineskip}\par
\noindent
{\bf データセット} 

データセットは，日本語の調査データである JGSS データセット
\pagebreak
および Zadrozny らの実験~\cite{Zadrozny02} において用いられた英文のネットニュース記事である UseNet news articles (20 Newsgroups) データセットの 2 つを用いた．

JGSS データセットは，
2000 年から 2003 年までの 4 年間に毎年実施された調査により収集されたデータのうちの職業データ（サンプル数 23,838）で，
自由回答である「仕事の内容」「従業先事業の種類」の他に，
選択回答である「従業上の地位」「役職」「従業先事業の規模」など複数の回答群から構成されている． すべての職業データに 195 個ある職業コードのいずれか 1 つのコードが付与されており\footnote{
	過去のデータには人手による職業コーディングが行われて職業コードが付与されている．
}，本稿ではこの職業コードを正解とした．
例えば，次のような職業データには正解として職業コード「563」が付与されている．
    \vspace{0.5\baselineskip}\par
\begin{tabular}{lll}
「仕事の内容」&：&配車等を手配（自由回答）\\
「従業先事業の種類」&：&荷物をつみおろす業務他（自由回答）\\  
「従業上の地位」&：&2　常時雇用の一般従事者（選択肢）\\
「役職」&：&1　役職なし（選択肢）\\
「従業先事業の規模」&：&8　500〜999 人（選択肢）
\end{tabular}
    \vspace{0.5\baselineskip}

JGSS データセットにおいては，
先に開発した自動コーディングシステム~\cite{Takahashi05a} の設定を踏襲し，
「仕事の内容」と「従業先事業の種類」に出現する単語 unigram および「従業上の地位」と「役職」を表す選択肢を素性として用いた．
訓練事例と評価事例の分割は，実際の職業コーディングの状況に似せて，
すでに正解が付けられた過去のデータを訓練事例とし，
これからコーディングを行う予定のデータを評価事例とした．
今回は，
訓練事例として 2000 年から 2002 年までの 3 年間分のデータ（20,066 サンプル），
評価事例として 2003 年のデータ（3,772 サンプル）に分割した．
さらに，訓練事例は正解率表を作成するため，5 分割交差検定により訓練事例と評価事例に分割した．
すなわち，
正解率表を作成するために，データを変えて訓練事例 16,053 サンプル，
評価事例 4,013 サンプルに分割し，計 5 回の学習を行った．

20 Newsgroups データセット（サンプル数 18,828）は，さまざまな UseNet のディスカッショングループに対応する 20 個のカテゴリのいずれかに分類されており，本稿ではこれを正解とした．
用いた素性は，ネットニュース記事に出現する単語 unigram で，JGSS データセットにおける自由回答の場合と同様である．
20 Newsgroups データセットでは，訓練事例と評価事例の分割は 5 分割交差検定により行った．
すなわち，
データを変えて，例えば，訓練事例 15,063 サンプル，評価事例 3,765 サンプルとし，計 5 回の学習を行った．
正解率表の作成は，
JGSS データセットの場合と全く同様に，全訓練事例を 5 分割交差検定により，訓練事例（例えば 12,053 サンプル）と評価事例（例えば 3,013 サンプル）に分割し計 5 回の学習を行った．
    \clearpage
\noindent
{\bf セルの区間幅}

最適なセルの区間幅は自動的に決めることができないために，
実験を行って決める必要がある．
今回は，区間幅を 0.05, 0.1, 0.2, 0.3, 0.5 の 5 通りに設定した．
このとき，1 つの正解率表においては，どの次元の軸も同一の区間幅で区切った．
第 1 位のクラスの分類スコア軸における区間幅とセルの数との関係は，
表~\ref{cell_interval} に示す通りであった．


\begin{table}[t]
\begin{center}
\caption{SVM におけるセルの区間幅と個数の関係 }
\label{cell_interval}
\input{01table04.txt}
\end{center}
\end{table}


\vspace{1\baselineskip}
\noindent
{\bf 評価尺度}

実験 1 では，各手法の評価を行うために，Zadrozny ら~\cite{Zadrozny05} にしたがい，次式で計算されるクロスエントロピーを用いた．
\begin{equation}
 H(y,p) = \frac{1}{N}\sum_{i=1}^N\{-y_{i}\log(p_{i}) - (1-y_{i})\log(1-p_{i})\}, 
\end{equation}
ただし，
$N$ は評価事例数，
$p_{i}$ は $i$ 番目の事例におけるクラス所属確率の推定値，
$y_{i}$ は $i$ 番目の事例における正誤状況で，正解の場合は $1$, 不正解の場合は $0$ を表す．
クロスエントロピーの値が小さいほどよい手法であるとする．

実験 2 では，提案手法の評価を行うために，Caruana ら~\cite{Caruana04,Mizil05} にしたがい，予測値がどの程度実測値と重なるかを表す信頼度曲線を用いた．
予測値と実測値が重なる程度が高いほどよい手法であるとする．
また，Zadrozny ら~\cite{Zadrozny05} にしたがい，ROC (receiver operating characteristic) 曲線に基づいて計算される AUC (Area Under the Curve) を用いた評価も行った．
AUC の値が大きいほどよい手法であるとする．
提案手法の性能評価としては，誤分類検出能力により従来の検出手法との比較を行った．
誤分類検出能力は，誤分類の事例を対象となる事例数のカバレッジが低い時点で多く検出できるほどよい手法であるとする．

\subsubsection{実験 1：有効な方法の調査}

\noindent{\bf セルの作成法}

実験 1 を行う前の予備実験として，正解率表におけるセルの作成法について，
分類スコアを等間隔に区切る方法（提案手法）を各ビンの事例数を等しくする方法（Zadorozny らによるビニングの方法）と比較し，
提案手法の有効性を確認した．
ここでは，
Zadorozny らによるビニングの方法との比較を可能にするために，
提案手法においても用いる分類スコアを第 1 位のクラスに対するもののみとし，正解率の平滑化を行わない値を用いた．
ここで，提案手法における定義域は $[-\infty,+\infty]$ であるが，今回用いたデータセットにおける第 1 位のクラスの分類スコアの範囲は，分類器が SVM の場合，JGSS データセットでは $[-0.99,5.48]$, 20 Newsgroups データセットでは $[-2.92,19.636]$ であった．

表~\ref{equal} は，
2 つの方法により作成されたセルからなる正解率表の有効性を，
データセットや分類器を変えてクロスエントロピーにより比較した結果である．
表中，等間隔は我々の提案する方法（セルの区間幅を等間隔にする方法），
等事例は Zadrozny らの提案する方法（セルに含まれる事例数を等しくする方法）を表す．
表の値は，等間隔の方法では区間幅を 0.1 から 0.5 まで 4 通り，
等事例の方法においても，この区間幅に対応させてセルの個数を 30 個から 7 個まで 4 通りに変化させた中のそれぞれ最もよかった場合の値である\footnote{
	セル個数 30, 16 に対応するセルの区間幅はそれぞれ 0.1, 0.2 である
	（表~\ref{cell_interval} 参照のこと）．
}．
太字の数字は，2 つの方法のうちよい方の値を示す．

\begin{table}[b]
\begin{center}
\caption{セルの作成法別クロスエントロピー}
\label{equal}
\input{01table05.txt}
\end{center}
\end{table}

表~\ref{equal} において，
セルを等間隔に区切る方法は，
ナイーブベイズ分類器ではセルに含まれる事例を等しくする方法にやや劣るものの，
SVM ではどちらのデータセットでも大きく上回る結果を示した．
この傾向は，
最もよかった値同士の比較だけではなく，セルの区間幅（セルの個数）が異なっても全く同様であった．
この理由としては，一般に，データを各区間の度数が等しくなるように分割する方法は各区間幅が等しくなるように分割する方法より推定効率が高いことが知られているが，一方で，密度関数推定の観点から大きなバイアスを引き起こす可能性があることが指摘されており~\cite{Kogure05},  
今回用いたデータセットの分類スコアの分布において，特に SVM を適用した場合にこのバイアス問題が生じたのではないかと考えられる．
その結果，
セルを等事例で区切る方法において作成された正解率表は，セルに属する事例の分類スコアと正解率の関係を適切に反映したものにならなかったのではないかと思われる．
表~\ref{equal} より，
「分類スコアを等間隔に区切ってセルを作成する方法」により正解率表を作成する方法が有効であることが確認できたため，
以下の実験では，セルの作成は分類スコアを等間隔に区切る方法を用いた．

なお，今回，等事例に区切る方法において最もよかったのは，セルの個数が 12 個または 7 個の場合であったが，
Zadrozny らのビニングによる方法においてもビンの個数が 10 個の場合が最もよかったとの報告があり~\cite{Zadrozny02}, 
第 1 位のクラスの分類スコアのみを用いる場合には，分類器やデータセットが異なっていても最適なセルの個数が類似していることは興味深い．
    \vspace{1\baselineskip}\par
    \noindent
{\bf クロスエントロピーによる評価}

表~\ref{loglikelihoodJGSS} は，
SVM を適用し JGSS データセットを用いた場合のクロスエントロピーの値を，
用いた分類スコア別，クラス所属確率を推定する方法別にまとめたものである．
表において，
重み付け移動平均法はカバレッジを重みとする移動平均法を表す．
リッドストーン法においては最もよい場合の値を示す．
表の縦方向はセルの区間幅を 0.05 から 0.5 まで 5 通りに変化させたことを示しており，
各区間幅の上段は利用した分類スコアが第 1 位のクラスのみの場合，
下段は利用した分類スコアが第 1 位と第 2 位のクラスの場合の結果を示す．
表中の記号「---」は クロスエントロピーが計算できなかったセルがあったことを示す\footnote{
	セル内の事例数が 0 であったり，正解の場合に確率値が 0 であった場合に生じた．
}．
また，太字の数字は，表中のすべての値の中で最もよい値であることを示す．

\begin{table}[b]
\begin{center}
\hangcaption{用いた分類スコア別 SVM におけるクロスエントロピー（JGSS データセット）．正解率表を利用する方法（上）およびロジスティック回帰による方法（下）}
\label{loglikelihoodJGSS}
\input{01table06.txt}
\end{center}
\end{table}

表では省略したが，正解率表を利用する方法において，第 1 位から第 3 位まで 3 つのクラスの分類スコアを用いた場合のクロスエントロピーは，
いずれも第 1 位のクラスのみの場合よりははるかによく第 1 位と第 2 位のクラスの場合よりやや悪かった．
なお，1 節で述べた 2 種類の単純な変換~\cite{Mizil05,Zadrozny02} によるクロスエントロピーは，
Nicllescu-Mizil らによる変換では 1.4563 であり，Zadrozny らによる変換では 0.8332 であった．

同様に，
SVM を適用し 20 Newsgroups データセットを用いた結果を表~\ref{loglikelihoodNS} に示す．
表の形式や記号の意味などは表~\ref{loglikelihoodJGSS} と同様である．
ここでも，正解率表を利用する方法においては，第 1 位から第 3 位まで 3 つのクラスの分類スコアを用いた場合のクロスエントロピーは JGSS データセットを用いた場合と全く同様で，いずれも第 1 位のクラスのみの場合よりははるかによく，第 1 位と第 2 位のクラスの場合よりやや悪かった．
なお，1 節で述べた単純な変換によるクロスエントロピーは，Nicllescu-Mizil らによる変換では計算できず，Zadrozny らによる変換では 0.9199 であった．




\begin{table}[b]
\begin{center}
\hangcaption{用いた分類スコア別 SVM におけるクロスエントロピー（20 Newsgroups データセット）．正解率表を利用する方法（上）およびロジスティック回帰による方法（下）}
\label{loglikelihoodNS}
\input{01table07.txt}
\end{center}
\end{table}

表~\ref{loglikelihoodJGSS} および表~\ref{loglikelihoodNS} より，次のことが明らかになった．
まず，SVM を適用した場合は，クラス所属確率を推定する方法やデータセットに関係なく，
第 1 位のクラスの分類スコアのみ用いるより他のクラスの分類スコアも含めた複数の分類スコアを用いることが有効であった．
分類スコアの有効な組み合わせ方については，ロジスティック回帰による方法と正解率表を利用する方法で異なっており，
ロジスティック回帰による方法は，第 1 位のクラスから第 3 位のクラスまで 3 つの分類スコアを用いた場合，
正解率表を利用する方法は，第 1 位のクラスと第 2 位のクラスの 2 つの分類スコアを用いた場合が最もよかった．
ただし，いずれの方法においても，分類スコアの組み合わせ方の違いによる差は小さかった．
 
次に，ロジスティック回帰による方法も含めてすべての場合の中で最もよい結果を示したのは，最適な正解率表を利用した場合，すなわち「第 1 位と第 2 位のクラスの分類スコアを用いてカバレッジを重みとする移動平均法による平滑化を行った正解率表を利用する方法」（セルの区間幅 0.1）であった．
ただし，正解率表を利用する方法は，セルの区間幅の決め方により結果に大きな差があった．
特にセルの区間幅を非常に小さく（0.05）設定した場合は，複数の分類スコアを用いることは有効ではなかった．
この理由は，
セルの個数が増えることにより各セルごとに含まれる事例数が少なくなり，場合によっては事例が存在しないセルが出現したために，正解率における信頼性が低くなったことが原因であると考えられる．
正解率表を利用する方法においてはロジスティック回帰による方法と異なり，分類スコアを 3 つ用いた方が 2 つ用いた場合より結果が悪かった理由も，同様であると考えられる．
今回は，最適なセルの区間幅は，どちらのデータセットにおいても 0.1 であった．
これに対して，ロジスティック回帰による方法は，どちらのデータセットにおいても安定してよい結果を示した\footnote{
	なお，第 2 位以下のクラスについて，注目するクラスのスコアのみを用いて推定した場合における
	全クラスの総和は，平均 1.0035, 標準偏差 0.1625 であり，4.2.2 節で提案するように
	注目するクラスと第 1 位のクラスのスコアを用いて推定した場合における全クラスの総和は，
	平均 0.9998, 標準偏差 0.0478 であった．
	これらの値から，正規化されたクラス所属確率を計算して用いた場合のクロスエントロピーは，
	第 1 位のスコアしか用いない場合は 0.4449 で表~\ref{loglikelihoodNS} における
	すべてのケースの中で最も悪く，
	第 1 位\&第 2 位のスコアを用いた場合は 0.3634 で正規化しない場合よりややよかった．
	一方，JGSS データセットの場合は，クラスの総数が約 200 個と多いため第 20 位までのクラス
	に対する推定値の総和の計算を試みた．その結果，注目するクラスのスコアのみを用いた場合は，
	平均 0.9217, 標準偏差 0.2711 で，注目するクラスと第 1 位のクラスのスコアを用いた場合の
	総和は，平均 0.9039, 標準偏差 0.1141 であった．
}．

さらに，正解率表における平滑化の手法は，いずれもデータセットに関係なく有効であった．
特に，平滑化を行うセルの周囲にあるセルの情報も利用する方法である（カバレッジを重みとする）移動平均法は，セルの区間幅が適切であった場合によい結果を示した．
注目するセルの情報のみで平滑化を行うラプラス法やリッドストーン法は，クロスエントロピーにおいては大きな効果はなかったが，ゼロ頻度問題に対応できる点で評価できる．

ここで，正解率表を利用する方法における結論をより一般化させるために，分類器をナイーブベイズ分類器に変え，20 Newsgroups データセットによる実験を行った\footnote{
	ただし，正解率の信頼性が低下することが明らかな場合，すなわち 分類スコアを第 3 位のクラス
	まで用いた場合やセルの個数が 60 個の場合についての実験は行わなかった．
	また，表~\ref{loglikelihoodJGSS} および表~\ref{loglikelihoodNS} に示すように，
	周囲の情報を用いない平滑化手法の 2 つの手法は違いがみられなかったため，
	ラプラス法のみを用いた．
}．
結果は表~\ref{loglikelihoodNS_NB} に示すように，
SVM の場合と同様に，
第 1 位のクラスの分類スコアのみを用いた場合より，第 2 位のクラスまで 2 つの分類スコアを用いた場合の方がよかった．
また，平滑化手法は有効で，特にセルの区間幅が適切な場合に移動平均法はよい結果を示した．
ナイーブベイズ分類器において最もよかったのはセルの個数が 30 個の場合であり，これは SVM において最もよかったセルの区間幅 0.1 の場合に該当する．

\begin{table}[t]
\begin{center}
\hangcaption{用いた分類スコア別ナイーブベイズ分類器におけるクロスエントロピー（20 Newsgroups データセット）}
\label{loglikelihoodNS_NB}
\input{01table08.txt}
\end{center}
\end{table}

以上より，
多値分類における第 1 位のクラスのクラス所属確率の推定は，複数の分類スコアを用いることが有効であった．
特に，最適な正解率表である「第 1 位と第 2 位のクラスの分類スコアを用いて（カバレッジによる重み付き）移動平均法による平滑化を行い，セルの区間幅を 0.1（セルの個数 30 個）に設定した正解率表」を利用する方法は最も有効であった．
ただし，正解率表を利用する方法は設定されたセルの区間幅により結果が不安定であるという問題があったのに対して，ロジスティック回帰による方法は安定してよい結果を示した．
また，今回は，正解率表を利用する方法における最適な正解率表がデータセットや分類器に関係なく一致したが，
この結果をさらに一般化するには，データセットや分類器をより多様なものに変えた実験を行って確認する必要がある．  
したがって，現時点では，正解率表を利用する方法は，データセットや分類器が異なる場合に最適な正解率表を決定するための実験を行う必要があり，手間がかかるという欠点があるといえる\footnote{
	今回は，$\delta$ を最適にしたリッドストーン法のラプラス法に対する優位性が
	認められなかったが，
	この点についても一般化するためにはさらなる実験が必要である．
}．

\subsubsection{実験 2：提案手法の評価}

ここでは，SVM を適用して，実験 1 において最適であった方法（以後，提案手法とよぶ）の評価を行った．\\\\
\noindent{\bf 信頼度曲線および ROC 曲線}

信頼度曲線は，予測値（推定値）（$X$ 軸）と実際の値（$Y$ 軸）の関係をプロットしたもので，
予測値と実際の値が等しい場合には対角線上にプロットされ，
対角線から離れるほど予測の精度が悪いことを示す．
ここでは，提案手法を，分類スコアを 1 つ用いた方法のうち，平滑化を行わない正解率表を利用する方法（以後，平滑化を行わない方法とよぶ）
およびシグモイド関数による方法と比較した．
このとき，平滑化を行わない方法は，等事例ではなく等間隔に区切ったビニングによる方法であると考えることができ，シグモイド関数による方法は Platt の方法を簡略化したものであると考えられる．
今回は，予測値を 0.1 ずつ区切り 10 区間を作成し，予測値と真の値としていずれも区間内（例えば，$[0,0.1]$）に含まれる事例の平均を用いた．
JGSS データセットによる結果を図~\ref{reliability_JGSS} に，20 Newsgroups データセットによる結果を図~\ref{reliability_20ng} に示す．
図~\ref{reliability_JGSS} および図~\ref{reliability_20ng} において，
提案手法はどちらのデータセットにおいても対角線の近くにプロットされており，クラス所属確率を全体的にうまく推定することがわかった．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f4.eps}
\hangcaption{JGSS データセットにおける信頼度曲線．左から順に提案手法，平滑化を行わない方法，シグモイド関数による方法の結果を示す．}
\label{reliability_JGSS}
\end{center}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f5.eps}
\hangcaption{20 Newsgroups データセットにおける信頼度曲線．左から順に提案手法，平滑化を行わない方法，シグモイド関数による方法の結果を示す．}
\label{reliability_20ng}
\end{center}
\end{figure}

ROC 曲線は，$X$ 軸が FPF（False Positive Fraction; 偽陽性率），$Y$ 軸が TPF（True Positive Fraction; 真陽性率）を表す座標上に，正解率の程度により分類された各グループごとの FPF と TPF の値をプロットしたものである．
ここで，FPF＝注目するグループ内の不正解事例数／全不正解事例数，TPF＝注目するグループ内の正解事例数／全正解事例数である．
今回は，正解率を 10 点刻みに分類して FPF と TPF の値を求めた．
すなわち，最上位のグループ（正解率が 91\%〜100\% の範囲にある事例）から始めて，上限を固定し下限を 10\% ずつ下げたグループ（例えば 2 番目のグループは，正解率の範囲が 81\%〜100\% である事例の集合）を計 10 個作成し，各グループにおける FPF と TPF を計算した．
ROC 曲線においては，ROC 曲線が左上方に位置するほど正確な推定が行われていることを示すが，
より正確には，ROC 曲線の下方にある領域である AUC (Area Under the Curve) を計算し，その値が大きいほどよい手法であるとされる．
図~\ref{ROC_JGSS_20ns} に，JGSS データセットおよび 20 Newsgroups データセットによる提案手法，平滑化を行わない方法，シグモイド関数による方法における ROC 曲線を示す．
また，3 つの手法における AUC の値を表~\ref{AUC_rank1} に示す．
図~\ref{ROC_JGSS_20ns} および表~\ref{AUC_rank1} より明らかなように，提案手法はいずれのデータセットにおいても他の 2 つの方法より正確な推定を行えることがわかった．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f6.eps}
\hangcaption{クラス所属確率の推定方法別 ROC 曲線（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{ROC_JGSS_20ns}
\end{center}
\end{figure}
\begin{table}[b]
\begin{center}
\caption{クラス所属確率の推定方法別 AUC (Area Under the Curve)}
\label{AUC_rank1}
\input{01table09.txt}
\end{center}
\end{table}



\vspace{1\baselineskip}
\noindent
{\bf 誤分類検出能力} 

事例をクラス所属確率の推定値の小さい順に並べたとき，
カバレッジの値が小さいときにできるだけ多くの誤分類事例が検出されることが望ましい．
カバレッジをこのように考えた場合に，各カバレッジごとにどのくらい誤分類された事例を検出できるかを，本稿では誤分類検出能力とよぶ．
提案手法の誤分類検出能力を，
JGSS データセットおよび 20 Newsgroups データセットを用いて評価した．
評価の方法は，
提案手法によるクラス所属確率の推定値を値の小さい順に事例を並べ，
カバレッジを 10\% ずつ増やしてできた区間ごとに，誤分類された事例数を調査した．
比較のため，既存の手法である Schohn により提案された単純な方法~\cite{Schohn00} による結果も示した．
単純な方法では，
分類スコアの値の小さい順に並べ，同様にカバレッジを 10\% ずつ増やしてできた区間ごとに，
誤分類された事例数を調査した．
それぞれのデータセットによる結果を図~\ref{Lap-RawJGSS_ns} に示す．
 
図~\ref{Lap-RawJGSS_ns} において，
提案手法はどちらのデータセットにおいても常に単純な方法を上回った．
特に，20 Newsgroups データセットにおいては，
カバレッジが小さい場合に大きく上回る点が評価できる．
その理由は，我々が実際に人手により分類誤りを検出する必要がある場合，
チェックをするデータセットの量はできる限り少量の方が作業が楽であるからである．
JGSS データセットでは，全体の 40\% をチェックすれば誤分類事例の 80\% を検出することができるが，
20 Newsgroups データセットで同じ量をチェックすると，誤分類事例の 90\% を検出できる．
両者のデータセットにおける傾向の違いを説明する理由は明確ではないが，
JGSS データセットには非常に短く有効な素性が少ししか含まれない事例が多いため，
正確な推定を行うために十分な情報がないことが原因であると考えられる\footnote{
	表~\ref{equal}，表~\ref{loglikelihoodJGSS}, 表~\ref{loglikelihoodNS} における
	クロスエントロピーの値からも，JGSS データセットの方が推定が困難な
	タスクであることが予想される．
}．

\begin{figure}[t]
\begin{center}
\includegraphics{15-2ia1f7.eps}
\hangcaption{SVM における提案手法の誤分類検出能力（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{Lap-RawJGSS_ns}
\end{center}
\end{figure}

以上をまとめると，
多値分類において第 1 位に予測されたクラスのクラス所属確率の推定は，
複数の分類スコアを用いることが有効であることがわかった．
特に，第 1 位と第 2 位に予測されたクラスの分類スコアを用いて作成した最適な正解率表を利用する方法が最もよい結果を示した．
ここで，最適な正解率表とは，
セルの区間幅を 0.1（セルの個数が 30）として作成した正解率表を（カバレッジによる重み付き）移動平均法による平滑化を行ったものである．
ただし，正解率表を利用する方法は正解率表の作成法により結果が不安定であるという欠点があった．
この点において，ロジスティック回帰による方法は安定してよい結果を示した．
また，ロジスティック回帰による方法は，最適な正解率表を見つけるために実験を重ねる手間が不要であるという利点もある．

\section{第 2 位以下の任意のクラスについてのクラス所属確率推定}\

3 節で，多値分類における第 1 位の予測クラスについてのクラス所属確率は，
複数の分類スコアを用いた推定が有効であることが明らかになった．
本節では，3 節で得られた結論を第 2 位以下の任意のクラスに対して拡張する方法を検討する．
この場合，どのクラスの分類スコアを組み合わせることが有効であるかを検討することが重要である．

\subsection{提案手法}

本稿では，多値分類における第 2 位以下の任意のクラスについてのクラス所属確率を高精度に推定するために，
推定したいクラス（第 $k$ 位のクラス）と第 1 位のクラスの分類スコアを用いてロジスティック回帰により推定する方法を提案する．
すなわち，次式\footnote{
	3 節で示した（1）式を第 1 位と第 $k$ 位のクラスのみ用いるように修正したものである．
}によりクラス所属確率の推定を行うことを提案する．
\begin{equation}
 P_{Log}( f_{1},f_{k}) = \frac{1}{1+\exp (A_{1}f_{1}+A_{k}f_{k}+B)}.
\end{equation}
ここで，
$f_{k}$ は第 $k$ 位の分類スコアを表す．
このとき，
パラメータ $A_{1}$, $A_{k}$ および $B$ は訓練事例を用い，
最尤法によりあらかじめ推定しておく必要がある.

ここで，
推定したいクラスの他に用いるクラスとして第 1 位のクラスを選択した理由は，
3 節でも述べたように，
多値分類においては，第 1 位のクラスの分類スコアが最も大きく，
どのクラスの分類スコアも第 1 位のクラスの分類スコアの値以上にはならないため，
推定したいクラスの分類スコアの値を第 1 位のクラスの分類スコアとの相対的な関係で捉えることが有効であると考えたためである．
これを実現するための方法はいくつか存在するが\footnote{
	例えば，2 つのスコア間の差や相関係数などが考えられる．
}，ここでは，3 節と同様に最も単純に第 1 位のクラスの分類スコアをそのまま用いることにした．
また，クラス所属確率の推定方法については，第 2 位以下のクラスにおいては，
第 1 位のクラスよりも分類スコアの傾向をさらに把握しにくくなるために，
最適な正解率表を作成することが困難であると考えられる．
したがって，第 1 位のクラスの場合において安定した結果を示したロジスティック回帰による方法の方が有効であると考えた．この 2 つの仮定を以下の実験により確認する．

\subsection{実験}

実験の目的は，
多値分類における第 2 位以下の任意のクラスのクラス所属確率の推定に用いる分類スコアは，提案手法による組み合わせ方が最も有効であることを示すこと（実験 1），
および第 2 位以下のクラスにおいては，ロジスティック回帰による方法が正解率表を利用する方法より有効であることを示すこと（実験 2）である．

実験設定は 3 節と同様で，分類器は SVM を適用した．実験 1 では第 2 位から
第 20 位までのクラス\footnote{
	JGSS データセットにおいては 10\%, 20 Newsgroups データセットにおいてはすべてのクラスを
	カバーする．
}，実験 2 では第 2 位から第 5 位までのクラスについて調査した．


\subsubsection{実験 1：分類スコアの有効な組み合わせ方}

\noindent{\bf 分類スコアの候補}

実験 1 を行う前の予備実験として，推定したいクラスのクラス所属確率と関連の深いクラスを発見するために，
第 2 位以下のすべてのクラスについて，注目するクラスの正誤状況（正解の場合 1，不正解の場合 0）と全クラスの分類スコアとの相関関係を調査した．
これは，注目するクラスの正誤状況と相関係数の絶対値が大きい分類スコアのクラスほど注目するクラスとの関連が強いと仮定したためである．
したがって，相関係数の絶対値の大きな分類スコアが多い順位のクラスを候補として用いることを検討した．

JGSS データセットと 20 Newsgroups データセットを用いて第 2 位から第 20 位のクラスにおいて，各クラスごとに関連の強かったクラスを表~\ref{correlation} にまとめる．
表~\ref{correlation} より，注目するクラス（推定したいクラス）自身より第 1 位のクラスの方が多かったため，
用いるクラスの候補として第 1 位のクラスを候補とした．
また，注目するクラスの直前や直後のクラスも候補とした．

\begin{table}[b]
\begin{center}
\caption{注目するクラスの正誤状況と関連の強いクラス}
\label{correlation}
\input{01table10.txt}
\end{center}
\end{table}

次に，これらの 3 つのクラスの分類スコアを推定したいクラスとそれぞれ単純に組み合わせた場合におけるクロスエントロピーを， JGSS データセットと 20 newsgroups データセットを用いて調査した．
その結果，どちらのデータセットにおいても，
第 1 位のクラスの分類スコアを組み合わせた場合以外は有効性が認められなかったため，実験 1 では，複数の分類スコアとして次の 3 つの組み合わせ方を考え，「推定したいクラスの分類スコアのみを用いる」場合と比較を行った（（　）内は用いる分類スコアの数を表す）．
このとき，分類スコアを 3 個以上用いた場合のクラス所属確率の推定には，3 節で述べた（1）式を適宜修正した式を用いた．
\begin{itemize}
\item ［提案手法］「推定したいクラスと第 1 位のクラスの分類スコア」（2 個） 

\item 「第 1 位のクラスから推定したいクラス（第 $k$ 位のクラス）までのすべてのクラスの分類スコア」（$k$ 個）

\item 「推定したいクラスとその直前および直後のクラスの分類スコア」（3 個）
\end{itemize}


\vspace{1\baselineskip}
\noindent
{\bf 提案手法の有効性}

図~\ref{rank2-12_JGSS_20ns} は，
JGSS データセットと 20 Newsgroups データセットにより，用いた分類スコアの組み合わせを変えた場合のクロスエントロピーを，推定したいクラスの順位別（$X$ 軸）に示したものである．
ただし，どちらのデータセットにおいても，13 位以下のクラスにおいては 12 位と同様の傾向であったために省略した．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f8.eps}
\caption{分類スコアの組み合わせ方別クロスエントロピー}
\label{rank2-12_JGSS_20ns}
\end{center}
\end{figure}



図~\ref{rank2-12_JGSS_20ns} から明らかなように，どちらのデータセットにおいても，推定したいクラスが上位の場合には，推定したいクラスの分類スコアのみを用いるより，クラスの組み合わせ方に関係なく複数の分類スコアを用いた方がよかった．
特に提案手法である「推定したいクラスと第 1 位のクラスの分類スコア」を用いた場合は，どの順位においても最もよかった．
ただし，推定したいクラスの順位が下がるにつれて，どの方法もクロスエントロピーの値が小さくなり，方法間の違いの差がみられなくなった．
この理由は，クラスの順位が下がるにつれてどの方法であってもクラス所属確率の推定値が小さくなり，また予測されたクラスも不正解である場合が多くなるために\footnote{
	例えば，JGSS データセットにおいて第 2 位から第 5 位に予測されたクラスの正解率は，
	それぞれ 7.7\%, 2.2\%, 0.9\%, 0.6\% であり，20 newsgroups データセットにおいては
	それぞれ 6.4\%, 2.3\%, 1.2\%, 0.8\% であった．
}，クロスエントロピーも小さくなったためだと考えられる．

次に，提案手法を含めた 4 つの方法における ROC 曲線を，第 2 位のクラスと第 3 位のクラスに注目した場合についてそれぞれ図~\ref{ROC2} および図~\ref{ROC3} に示す\footnote{
	第 4 位以下のクラスについては，いずれのデータセットにおいても第 3 位の場合と
	同様の傾向であったために省略した．
}．
ただし，第 2 位のクラスにおいては，
「第 1 位から推定したいクラスまでのすべてのクラスの分類スコアを用いる方法」は提案手法と同じ方法であるために，図~\ref{ROC2} では省略した．
また，図~9，図~10 における AUC を表~\ref{AUC_rank23} に示す．
表中，太字の数字は，各ケースにおいて最もよい値であることを示す．
図~\ref{ROC2}, 図~\ref{ROC3}, 表~\ref{AUC_rank23} より，注目するクラスやデータセットが異なっても，
複数の分類スコアを用いる方法は，注目するクラスの分類スコアだけを用いる方法よりよかった．
AUC による評価において最もよかった方法は，
JGSS データセットの場合は提案手法であり，
20 Newsgroups データセットの場合は，注目するクラスと直前および直後のクラスの分類スコアを用いる方法（第 2 位のクラスの場合）や，第 1 位から推定したいクラスまでのすべてのクラスの分類スコアを用いる方法（第 3 位のクラスの場合）であった．
ただし，提案手法は 20 Newsgroups データセットの場合も安定してよかった．

\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f9.eps}
\hangcaption{第 2 位のクラスについての分類スコアの組み合わせ方別 ROC 曲線（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{ROC2}
\end{center}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f10.eps}
\hangcaption{第 3 位のクラスについての分類スコアの組み合わせ方別 ROC 曲線（JGSS データセット（左）および 20 Newsgroups データセット（右））}
\label{ROC3}
\end{center}
\end{figure}

以上より，第 2 位以下の任意のクラスについてのクラス所属確率を推定する場合も，複数の分類スコアを用いることは有効であり，特に推定したいクラスと第 1 位のクラスの分類スコアを用いる方法は有効であることが示された．

最後に，ロジスティック回帰式におけるパラメータを最尤推定するために用いる訓練事例数を変化させたときのクロスエントロピーを調査した．
図~\ref{JGSS_train_size} は，JGSS データセットにより，推定したいクラスの分類スコアのみ用いる方法と提案手法を比較したものである．
$X$ 軸は訓練事例数を表しており，右端はこれまでの実験において訓練事例として用いられてきた 20,066 サンプルの場合，左端は 1,000 サンプルにまで減らした場合を表す．
図~\ref{JGSS_train_size} より，まず，
訓練事例の数に関係なく提案手法が有効であることがわかった．
また，訓練事例が 1,000 サンプルと比較的少ない場合でも，ロジスティック回帰による方法は安定してよい結果を示すこともわかった．

\begin{table}[t]
\begin{center}
\caption{分類スコアを利用したクラス別 AUC}
\label{AUC_rank23}
\input{01table11.txt}
\end{center}
\end{table}
\begin{figure}[t]
  \begin{center}
\includegraphics{15-2ia1f11.eps}
\hangcaption{パラメータ推定に用いる訓練事例数の変化によるクロスエントロピー（ロジスティック回帰による方法）}
\label{JGSS_train_size}
  \end{center}
\end{figure}



\subsubsection{実験 2：ロジスティック回帰による方法の有効性}

ここでは，
提案手法による分類スコアの組み合わせにおいて，ロジスティック回帰による方法を最適な正解率表を利用する方法と比較した．
このとき，
最適な正解率表としては次の 2 つを検討した．
1 つは第 1 位のクラスについて推定する場合に
最も有効であった正解率表（セルの区間幅を 0.1 に設定）で，
推定したいクラスごとに新たな正解率表を作成する手間を省略する目的で用いた．
もう 1 つは，第 2 位以下の各クラスにおける分類スコアのとる値の状況に合わせて，セルの区間幅を適宜（例えば 0.2 など）変えたもので，「正解率表（改良版）」とよぶことにする．
いずれの正解率表も，
3 節で最も有効であった平滑化手法すなわちカバレッジを重みとする移動平均法による平滑化を行った．



\begin{figure}[b]
\begin{center}
\includegraphics{15-2ia1f12.eps}
\caption{クラス所属確率の推定方法別クロスエントロピー}
\label{JGSS_20ns_seikai_hikaku}
\end{center}
\end{figure}


図~\ref{JGSS_20ns_seikai_hikaku} に，ロジスティック回帰による方法と正解率表を利用する方法におけるクロスエントロピーを示す．
図~\ref{JGSS_20ns_seikai_hikaku} より，
注目するクラスが第 2 位から第 5 位までの場合の平均において，ロジスティック回帰による方法が最も有効であることが示された\footnote{
	なお，20 Newsgroups データセットを用いた場合，ロジスティック回帰による方法において
	正規化されたクラス所属確率を用いた場合の第 2 位から第 5 位までのクロスエントロピーと
	その平均はそれぞれ 0.2386, 0.1246, 0.0694, 0.0483, 0.1202 で，正規化しない場合の値
	（0.2450, 0.1161, 0.0697, 0.0556, 0.1216）とほぼ同様であった．
}．
正解率表（改良版）を利用する方法は，JGSS データセットにおいて第 2 位のクラスに注目する場合や，20 Newsgroups データセットにおいて第 3 位のクラスに注目する場合のみ，
ロジスティック回帰による方法よりわずかによい結果であったが，
注目するクラスに対して毎回，最適な正解率表を作成する手間がかかるという欠点がある． 
3 つの方法における ROC 曲線の例として，JGSS データセットを用いて第 2 位のクラスに注目する場合を図~\ref{ROC_JGSS_seikai_hikaku} に示す．
このとき，3 つの方法における AUC は，それぞれロジスティック回帰による方法（0.7443），第 1 位のクラスに対する最適な正解率表を利用する方法（0.7260），正解率表（改良版）を利用する方法（0.7449）で，JGSS データセットにおいて第 2 位のクラスを推定する場合に限り，正解率表（改良版）を利用する方法がロジスティック回帰による方法をやや上回った．

\begin{figure}[t]
  \begin{center}
\includegraphics{15-2ia1f13.eps}
  \caption{クラス所属確率の推定方法別 ROC 曲線（JGSS データセットにおける第 2 位のクラス）}
  \label{ROC_JGSS_seikai_hikaku}
 \end{center}
\end{figure}


今回，第 6 位以下のクラスについては比較実験を行っていないが，
先に述べたように，下位のクラスになるにしたがって最適な正解率表の作成は困難になることが予想されるため，第 6 位以下のクラスにおいてもロジスティック回帰による方法が有効であると考えられる．


以上より，第 2 位以下の任意のクラスにおいても，
ロジスティック回帰による方法の方が正解率表を利用する方法より有効であると判断できた．

\section{結論}

本稿では，文書分類で適用されることの多い多値分類における任意のクラスのクラス所属確率を，複数の分類スコアを用いて高精度に推定する方法を提案した．
提案手法は，複数個の分類スコア，特に推定したいクラスと第 1 位のクラスの分類スコアを用いてロジスティック回帰によりクラス所属確率を推定する．
ここで，第 1 位のクラスについては，第 1 位と第 2 位のクラスの分類スコアのなす空間を等間隔（0.1）に区切って作成した各セルにおいて正解率を計算し，カバレッジを重みとする移動平均法により平滑化を行った正解率表を参照する方法も有効であった．
提案手法は，SVM を適用し，性質の異なる 2 種類のデータセット（社会調査データである日本語自由回答や英文の自由投稿ネットニュース記事）を用いて実験した結果，
どちらのデータセットにおいても有効性を示した．
また，誤分類の検出において，
従来の方法を上回った．
今後の課題は，
提案手法の有効性を理論的に裏付けることが必要であると考えられる．



\acknowledgment

日本版 General Social Surveys (JGSS) は，大阪商業大学比較地域研
究所が，文部科学省から学術フロンティア推進拠点としての指定を受けて（1999--2003 年
度），東京大学社会科学研究所と共同で実施している研究プロジェクトである（研究代表
：谷岡一郎・仁田道夫，代表幹事：佐藤博樹・岩井紀子，事務局長：大澤美苗）．データ
の入手先は，東京大学社会科学研究所附属日本社会研究情報センター SSJ データ・アーカ
イブである.

本稿に対して貴重なコメントを下さいました査読者の皆さまに深く感謝いたします．



\bibliographystyle{jnlpbbl_1.3}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Ahuja \BBA\ Orlin}{Ahuja \BBA\ Orlin}{2001}]{Ahuja01}
Ahuja, R.~K.\BBACOMMA\ \BBA\ Orlin, J.~B. \BBOP 2001\BBCP.
\newblock \BBOQ A Fast Scaling Algorithm for Minimizing Separable Convex
  Functions Subject to Chain Constraints\BBCQ\
\newblock {\Bem Operations Research}, {\Bbf 49}, \mbox{\BPGS\ 784--789}.

\bibitem[\protect\BCAY{Bennett}{Bennett}{2000}]{Bennett00}
Bennett, P.~N. \BBOP 2000\BBCP.
\newblock \BBOQ Assessing the Calibration of Naive Bayes' Posterior Estimates
  {CMU}-{CS}-00-155\BBCQ\
\newblock \BTR, School of Computer Science, Carnegie Mellon University.

\bibitem[\protect\BCAY{Canters, Genst, \BBA\ Dufourmont}{Canters
  et~al.}{2002}]{Canters02}
Canters, F., Genst, W.~D., \BBA\ Dufourmont, H. \BBOP 2002\BBCP.
\newblock \BBOQ Assessing effects of input uncertainty in structural landscape
  classification\BBCQ\
\newblock {\Bem International {J}ournal of {G}eographical {I}nformation
  {S}cience}, {\Bbf 16}  (2), \mbox{\BPGS\ 129--149}.

\bibitem[\protect\BCAY{Carreiras, Pereira, Campagnolo, \BBA\
  Shimabukuro}{Carreiras et~al.}{2005}]{Carreiras05}
Carreiras, J.~M.~B., Pereira, J.~M.~C., Campagnolo, M.~L., \BBA\ Shimabukuro,
  Y.~E. \BBOP 2005\BBCP.
\newblock \BBOQ A land cover map for the {B}razilian {L}egal {A}mazon using
  {SPOT\-4} {VEGETATION} data and machine learning algorithms\BBCQ\
\newblock In {\Bem Anais X{I}{I} {S}inposio {B}rasileiro de {S}ensoriamento
  {R}emoto}, \mbox{\BPGS\ 457--464}.

\bibitem[\protect\BCAY{Caruana \BBA\ Niculescu-Mizil}{Caruana \BBA\
  Niculescu-Mizil}{2004}]{Caruana04}
Caruana, R.\BBACOMMA\ \BBA\ Niculescu-Mizil, A. \BBOP 2004\BBCP.
\newblock \BBOQ Predicting Good Probabilities With Supervised Learning\BBCQ\
\newblock In {\Bem Proceedings of NIPS 2004 Workshop on Calibration and
  Probabilistic Prediction in Supervised Learning}.

\bibitem[\protect\BCAY{Chan \BBA\ Ng}{Chan \BBA\ Ng}{2006}]{Chan06}
Chan, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2006\BBCP.
\newblock \BBOQ Estimating Class Priors in Domain Adaptation for Word Sense
  Disambiguation\BBCQ\
\newblock In {\Bem Proceedings of the 21st International Conference on
  Computational Linguistics and 44th Annual Meeting of the ACL}, \mbox{\BPGS\
  89--96}.

\bibitem[\protect\BCAY{Cheeseman \BBA\ Stutz}{Cheeseman \BBA\
  Stutz}{1996}]{Cheeseman96}
Cheeseman, P.\BBACOMMA\ \BBA\ Stutz, J. \BBOP 1996\BBCP.
\newblock \BBOQ B{AYESIAN CLASSIFICATION (AUTO CLASS): \mbox{THEORY} AND
  RESULTS}\BBCQ\
\newblock In {\Bem Advances in knowledge discovery and data mining},
  \mbox{\BPGS\ 153--180}. American Association for Artficial Intelligence.

\bibitem[\protect\BCAY{Dumais, Platt, Hecherman, \BBA\ Sahami}{Dumais
  et~al.}{1998}]{Dumais_et_al98}
Dumais, S., Platt, J., Hecherman, D., \BBA\ Sahami, M. \BBOP 1998\BBCP.
\newblock \BBOQ Inductive Learning Algorithms and Representations for Text
  Categorization\BBCQ\
\newblock In {\Bem Proceedings of the ACM-CIKM98}, \mbox{\BPGS\ 145--155}.

\bibitem[\protect\BCAY{Erosheva}{Erosheva}{2005}]{erosheva05}
Erosheva, E. \BBOP 2005\BBCP.
\newblock \BBOQ Latent class representation of the {G}rade of {M}embership
  model\BBCQ\
\newblock \BTR, Department of {S}tatistics, University of Washington.

\bibitem[\protect\BCAY{Fawcett \BBA\ Niculescu-Mizil}{Fawcett \BBA\
  Niculescu-Mizil}{2006}]{Fawcett06}
Fawcett, T.\BBACOMMA\ \BBA\ Niculescu-Mizil, A. \BBOP 2006\BBCP.
\newblock \BBOQ PAV and the ROC Convex Hull\BBCQ\
\newblock \BTR, Kluwer Academic Publishers.

\bibitem[\protect\BCAY{Gualtieri, Chettri, Cromp, \BBA\ Johnson}{Gualtieri
  et~al.}{1999}]{Gualtieri99}
Gualtieri, A., Chettri, S.~R., Cromp, R., \BBA\ Johnson, L. \BBOP 1999\BBCP.
\newblock \BBOQ Support vector machine classifiers as applied to aviris
  data\BBCQ\
\newblock In {\Bem Proceedings of the 6th JPL Airborne Geoscience Workshop}.

\bibitem[\protect\BCAY{Joachims}{Joachims}{1998}]{Joachims98}
Joachims, T. \BBOP 1998\BBCP.
\newblock \BBOQ Text Categorization with Support Vector Machines: Learning with
  Many Relevant Features\BBCQ\
\newblock In {\Bem Proceedings of the European Conference on Machine Learning},
  \mbox{\BPGS\ 137--142}.

\bibitem[\protect\BCAY{Jones, Rey, Madani, \BBA\ Greiner}{Jones
  et~al.}{2006}]{Jones06}
Jones, R., Rey, B., Madani, O., \BBA\ Greiner, W. \BBOP 2006\BBCP.
\newblock \BBOQ Generating Query Substitutions\BBCQ\
\newblock In {\Bem Proceedings of the 15th International World Wide Web
  Conference (WWW'06)}, \mbox{\BPGS\ 387--396}.

\bibitem[\protect\BCAY{Kearsley, Tapia, \BBA\ Trosset}{Kearsley
  et~al.}{1996}]{Kearsley96}
Kearsley, A.~J., Tapia, R.~A., \BBA\ Trosset, M.~W. \BBOP 1996\BBCP.
\newblock \BBOQ An Approach to Parallelizing Isotonic Regression\BBCQ\
\newblock \BTR, CRPC-TR98840.

\bibitem[\protect\BCAY{Kressel}{Kressel}{1999}]{kressel99}
Kressel, U. \BBOP 1999\BBCP.
\newblock \BBOQ Pairwise classification and support vector machines\BBCQ\
\newblock In Sch{\" o}lkopf, B., Burgesa, C. J.~C., \BBA\ Smola, A.~J.\BEDS,
  {\Bem Advances in Kernel Methods Support Vector Learning}, \mbox{\BPGS\
  255--268}. The MIT Press.

\bibitem[\protect\BCAY{Langford \BBA\ Zadrozny}{Langford \BBA\
  Zadrozny}{2005}]{Zadrozny05}
Langford, J.\BBACOMMA\ \BBA\ Zadrozny, B. \BBOP 2005\BBCP.
\newblock \BBOQ Estimating Class Membership Probabilities using Classifier
  Learners\BBCQ\
\newblock In {\Bem Proceedings of the 10th International Conference on
  Artificial Intelligence and Statistics ('06)}.

\bibitem[\protect\BCAY{Niculescu-Mizil \BBA\ Caruana}{Niculescu-Mizil \BBA\
  Caruana}{2005}]{Mizil05}
Niculescu-Mizil, A.\BBACOMMA\ \BBA\ Caruana, R. \BBOP 2005\BBCP.
\newblock \BBOQ Predicting Good Probabilities With Supervised Learning\BBCQ\
\newblock In {\Bem Proceedings of the 22nd International Conference on Machine
  Learning (ICML'05)}, \mbox{\BPGS\ 625--632}.

\bibitem[\protect\BCAY{Ohkura, Kiyota, \BBA\ Nakagawa}{Ohkura
  et~al.}{2006}]{Ohkura06}
Ohkura, T., Kiyota, Y., \BBA\ Nakagawa, H. \BBOP 2006\BBCP.
\newblock \BBOQ Browsing System for Weblog Articles based on Automated
  Folksonomy\BBCQ\
\newblock In {\Bem Workshop on the Weblogging Ecosystem (WWW2006)}.

\bibitem[\protect\BCAY{Platt}{Platt}{1999}]{Platt99}
Platt, J.~C. \BBOP 1999\BBCP.
\newblock \BBOQ Probabilistic Outputs for Support Vector Machines and
  Comparisons to Regularized Likelihood Methods\BBCQ\
\newblock In Sch{\" o}lkopf, B., Burgesa, C. J.~C., \BBA\ Smola, A.~J.\BEDS,
  {\Bem Advances in Large Margin Classifiers}, \mbox{\BPGS\ 255--268}. The MIT
  Press.

\bibitem[\protect\BCAY{Schohn \BBA\ Cohn}{Schohn \BBA\ Cohn}{2002}]{Schohn00}
Schohn, G.\BBACOMMA\ \BBA\ Cohn, D. \BBOP 2002\BBCP.
\newblock \BBOQ Less is More: Active Learning with Support Vector
  Machines\BBCQ\
\newblock In {\Bem Proceedings of the 17th International Conference on Machine
  Learning (ICML'00)}, \mbox{\BPGS\ 839--846}.

\bibitem[\protect\BCAY{Sebastiani}{Sebastiani}{2002}]{Sebastiani02}
Sebastiani, F. \BBOP 2002\BBCP.
\newblock \BBOQ Machine Learning Automated Text Categorization\BBCQ\
\newblock {\Bem ACM Computing Surveys}, {\Bbf 34}  (1), \mbox{\BPGS\ 1--47}.

\bibitem[\protect\BCAY{Takahashi, Takamura, \BBA\ Okumura}{Takahashi
  et~al.}{2005}]{Takahashi05c}
Takahashi, K., Takamura, H., \BBA\ Okumura, M. \BBOP 2005\BBCP.
\newblock \BBOQ Automatic Occupation Coding with Combination of Machine
  Learning and Hand-Crafted Rules\BBCQ\
\newblock In {\Bem Proceedings of the 9th International Conference on
  Pacific-Asia Knowledge Discovery and Data Mining (PAKDD'05)}, \mbox{\BPGS\
  269--279}.

\bibitem[\protect\BCAY{Zadrozny \BBA\ Elkan}{Zadrozny \BBA\
  Elkan}{2001a}]{Zadrozny01a}
Zadrozny, B.\BBACOMMA\ \BBA\ Elkan, C. \BBOP 2001a\BBCP.
\newblock \BBOQ Learning and Making Decisions When Costs and Probabilities are
  Both Unknown\BBCQ\
\newblock In {\Bem Proceedings of the 7th International Conference on Knowledge
  Discovery and Data Mining (KDD'01)}, \mbox{\BPGS\ 204--213}.

\bibitem[\protect\BCAY{Zadrozny \BBA\ Elkan}{Zadrozny \BBA\
  Elkan}{2001b}]{Zadrozny01b}
Zadrozny, B.\BBACOMMA\ \BBA\ Elkan, C. \BBOP 2001b\BBCP.
\newblock \BBOQ Obtaining calibrated probability estimates from decision trees
  and naive Bayesian classifiers\BBCQ\
\newblock In {\Bem Proceedings of the 18th International Conference on Machine
  Learning (ICML'01)}, \mbox{\BPGS\ 609--616}.

\bibitem[\protect\BCAY{Zadrozny \BBA\ Elkan}{Zadrozny \BBA\
  Elkan}{2002}]{Zadrozny02}
Zadrozny, B.\BBACOMMA\ \BBA\ Elkan, C. \BBOP 2002\BBCP.
\newblock \BBOQ Transforming Classifier Scores into Accurate Multiclass
  Probability Estimates\BBCQ\
\newblock In {\Bem Proceedings of the 8th International Conference on Knowledge
  Discovery and Data Mining (KDD'02)}, \mbox{\BPGS\ 694--699}.

\bibitem[\protect\BCAY{安居院\JBA 中嶋}{安居院\JBA 中嶋}{1991}]{Agui91_j}
安居院猛\JBA 中嶋正之 \BBOP 1991\BBCP.
\newblock \Jem{画像情報処理}.
\newblock 森北出版.

\bibitem[\protect\BCAY{北}{北}{1999}]{Kita99_j}
北研二 \BBOP 1999\BBCP.
\newblock \Jem{言語と計算（4）確率的言語モデル}.
\newblock 東大出版会.

\bibitem[\protect\BCAY{小暮\JBA 寒河江}{小暮\JBA 寒河江}{2005}]{Kogure05}
小暮厚之\JBA 寒河江雅彦 \BBOP 2005\BBCP.
\newblock \JBOQ
  パーセント点に集計されたデータからの密度関数の推定—バイアス・パズルの考察—
\JBCQ\
\newblock \Jem{統計数理}, {\Bbf 53}  (2), \mbox{\BPGS\ 376--389}.

\bibitem[\protect\BCAY{平\JBA 春野}{平\JBA 春野}{2000}]{Taira00}
平博順\JBA 春野雅彦 \BBOP 2000\BBCP.
\newblock \JBOQ Support Vector Machine によるテキスト分類における属性選択\JBCQ\
\newblock \Jem{情報処理}, {\Bbf 41}  (4), \mbox{\BPGS\ 1113--1123}.

\bibitem[\protect\BCAY{高橋\JBA 高村\JBA 奥村}{高橋\Jetal
  }{2005a}]{Takahashi05a}
高橋和子\JBA 高村大也\JBA 奥村学 \BBOP 2005a\BBCP.
\newblock \JBOQ
  機械学習とルールベース手法の組み合わせによる自動職業コーディング\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (2), \mbox{\BPGS\ 3--24}.

\bibitem[\protect\BCAY{高橋\JBA 須山\JBA 村山\JBA 高村\JBA 奥村}{高橋\Jetal
  }{2005b}]{Takahashi05b}
高橋和子\JBA 須山敦\JBA 村山紀文\JBA 高村大也\JBA 奥村学 \BBOP 2005b\BBCP.
\newblock \JBOQ 職業コーディング支援システム（{NANACO}）の開発と {JGSS}-2003
  における適用\JBCQ\
\newblock \Jem{日本版 General Social Surveys 研究論文集 [4] JGSS
  で見た日本人の意識と行動〈JGSS Research Series No.1〉{\kern-0.5zw}},
  \mbox{\BPGS\ 225--242}.

\end{thebibliography}

\begin{biography}
\bioauthor{高橋　和子（正会員）}{
東京女子大学文理学部数理学科卒.
茨城大学人文学部社会科学科助手，千葉敬愛短期大学専任講師を経て
1997 年敬愛大学国際学部国際協力学科専任講師．
1998 年産能大学大学院経営情報学研究科修了．
2007 年東京工業大学大学院総合理工学研究科博士課程修了．
2008 年敬愛大学国際学部国際学科教授，現在に至る．
修士（経営情報学）．博士（工学）．
社会調査で収集されるテキスト型データの処理・分析方法に興味をもつ．
日本オペレーションズ・リサーチ学会，数理社会学会，情報処理学会，言語処理学会，人工知能学会各会員．}

\bioauthor{高村　大也（正会員）}{
1974 年生．
1997 年東京大学工学部計数工学科卒．2000 年同大大学院工学系研究科計数工学専
攻修了（1999 年はオーストリアウィーン工科大学にて研究）．
2003 年奈良先端科学技術大学院大学博士後期課程修了．
同年東京工業大学精密工学研究所助手（現在，助教），現在に至る．
博士（工学）．自然言語処理，特に学習理論等の応用に興味を持つ．
情報処理学会，言語処理学会，ACL 各会員．}

\bioauthor{奥村　　学（正会員）}{
1962 年生．1984 年東京工業大学工学部情報工学科卒業．1989 年同大学院博士課
程修了．同年，東京工業大学工学部情報工学科助手．1992 年北陸先端科学技術
大学院大学情報科学研究科助教授，2000 年東京工業大学精密工学研究所助教授，
現在に至る．工学博士．自然言語処理，知的情報提示技術，語学学習支援，テ
キストマイニングに関する研究に従事．
情報処理学会，人工知能学会，AAAI, 言語処理学会，ACL, 認知科学会，計量国
 語学会各会員．}

\end{biography}


\biodate


\end{document}
