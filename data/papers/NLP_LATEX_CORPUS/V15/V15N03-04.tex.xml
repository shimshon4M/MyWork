<?xml version="1.0" ?>
<root>
  <jtitle>HTML文書集合からの評価文の自動収集</jtitle>
  <jauthor>鍜治伸裕喜連川優</jauthor>
  <jabstract>本論文では大規模なHTML文書集合から評価文を自動収集する手法を提案する．基本的なアイデアは「定型文」「箇条書き」「表」といった記述形式を利用するというものである．本手法に必要なのは少数の規則だけであるため，人手をほとんどかけずに評価文を収集することが可能である．また，任意のHTML文書に適用できる手法であるため，様々なドメインの評価文を収集できることが期待される．実験では，提案手法を約10億件のHTML文書に適用したところ，約65万の評価文を獲得することができた．</jabstract>
  <jkeywords>評価情報分析，評価極性</jkeywords>
  <section title="はじめに">近年，自然言語処理において評価情報処理が注目を集めている．評価情報処理とは，物事に対する評価が記述されたテキストを検索，分類，要約，構造化するような処理の総称であり，国家政治に対する意見集約やマーケティングといった幅広い応用を持っている．具体的な研究事例としては，テキストから特定の商品やサービスに対する評価情報を抽出する処理や，文書や文を評価極性（好評と不評）に応じて分類する処理などが議論されている．評価情報処理を行うためには様々な言語資源が必要となる．例えば，評価情報を抽出するためには「良い」「素晴しい」「ひどい」といった評価表現を登録した辞書が不可欠である．また，文書や文を評価極性に応じて分類するためには，評価極性がタグ付けされたコーパスが教師あり学習のトレーニングデータとして使われる．我々は，評価情報処理のために利用する言語資源の一つとして，評価文コーパスの構築に取り組んでいる．ここで言う評価文コーパスとは，何かの評価を述べている文（評価文）とその評価極性を示すタグが対になったデータのことである（表）．タグは好評と不評の2種類を想定している．大規模な評価文コーパスがあれば，それを評価文分類器のトレーニングデータとして利用することや，そのコーパスから評価表現を獲得することが可能になると考えられる．評価文コーパスを構築するには，単純に考えると以下の2つの方法がある．人手でコーパスを作成する方法と，ウェブ上のレビューデータを活用する方法である．後者は，例えばアマゾンのようなサイトを利用するというものである．アマゾンに投稿されているレビューには，そのレビューの評価極性を表すメタデータが付与されている．そのため，メタデータを利用することによって，好評内容のレビューと不評内容のレビューを自動的に収集することができる．しかしながら，このような方法には問題がある．まず，人手でコーパスを作るという方法は，大規模なコーパスを作ることを考えるとコストが問題となる．また，レビューデータを利用する方法には，文単位の評価極性情報を取得しにくいという問題がある．後者の具体例として図に示すレビュー文書を考える．これは文書全体としては不評内容を述べているが，その中には好評文がいくつも出現している例である．このような文書を扱う場合，文書単位の評価極性だけでなく，文単位の評価極性も把握しておくことが望ましい．しかし，一般的にレビューのメタデータは文書に対して与えられるので，文単位の評価極性の獲得は難しい．さらに，レビューデータを利用した場合には，内容が特定ドメインに偏ってしまうという問題もある．こうした問題を踏まえて，本論文では大規模なHTML文書集合から評価文を自動収集する手法を提案する．基本的なアイデアは「定型文」「箇条書き」「表」といった記述形式を利用するというものである．本手法に必要なのは少数の規則だけであるため，人手をほとんどかけずに大量の評価文を収集することが可能となる．また，評価文書ではなく評価文を収集対象としているため，図のような問題は緩和される．さらに任意のHTML文書に適用できる方法であるため，様々なドメインの評価文を収集できることが期待される．実験では，提案手法を約10億件のHTML文書に適用したところ，約65万の評価文を獲得することができた．</section>
  <section title="アイデア">提案手法は「定型文」「箇条書き」「表」という3つの記述形式を利用して評価文を自動抽出する．本節では，これら3つの形式で記述された評価文の例を概観して，基本的な考え方を説明する．手法の詳細は次節で述べる．</section>
  <subsection title="定型文">まず我々が着目したのは定型的な評価文である．これの良いところは計算が速いことです．悪い点は，慣れるまで時間がかかること．lingexampleいずれの評価文も「良いところ／悪い点は〜なこと」という定型的な表現を使って記述されている．そのため，下線部にマッチするような語彙統語パターンを用意すれば，四角で囲まれたテキストを評価文として抽出することができる．以下では「良いところ」「悪い点」のように，評価文の存在を示唆する表現のことを手がかり句と呼ぶ．特に好評文の存在を示す手がかり句を「好評手がかり句」と呼ぶ．例えば「良いところ」は好評手がかり句である．同様に，不評文の存在を示す手がかり句を「不評手がかり句」と呼ぶ．</subsection>
  <subsection title="箇条書き">次に着目したのは，図のように箇条書き形式で列挙された評価文である．この箇条書きは手がかり句（良い点，悪い点）を見出しに持つため，各項目に評価文が含まれていることが分かる．</subsection>
  <subsection title="表">箇条書きと同様に，図のような表形式からも評価文を自動収集することができる．この表は左側の列が見出しの働きをしているが，ここにも手がかり句（気に入った点，イヤな点）が使われているので，表中に評価文が記述されていることが分かる．</subsection>
  <section title="評価文の自動収集">HTML文書から評価文を収集する手続きは次のようになる．手がかり句のリストを作成する．HTML文書をタグとテキストに分割する．一部の箇条書きと見出しはHTMLタグを使わないで記述されているので，ルールでタグを補完する．手がかり句のリストを利用して「定型文」「箇条書き」「表」から評価文を抽出する．以下では，まず実験で用いた手がかり句について説明する．そして「定型文」「箇条書き」「表」から評価文を抽出する方法を順に説明する．</section>
  <subsection title="手がかり句">実験で用いた手がかり句の一覧を表に示す．これらは予備実験を通して人手で選定した．表中の動詞，形容詞，形容動詞（「良い」など）は「所」「点」「面」という3つの名詞と組み合わせて使う．例えば「良い」は「良い所」「良い点」「良い面」の3つを手がかり句として使うことを意味する．「長所」や「メリット」のような名詞は，単語そのものを手がかり句として使う．なお，詳細は省略しているが「駄目な所」と「ダメな所」または「良い所」と「良いところ」のような表記揺れも網羅的に人手で記述している．</subsection>
  <subsection title="定型文からの抽出">定型文から評価文を抽出するために，3種類の語彙統語パターンを人手で作成した．各パターンとそれにマッチする定型文の具体例を表に示す．最初のパターン（表上）は，主部が手がかり句（良いところ）で述部が評価文であるような定型文にマッチする．パターン中の矢印は文節間の依存関係，手がかり句は手がかり句をそれぞれ表している．また評価文は，この部分にマッチしたテキストが評価文として抽出されることを意味する．表の右側に評価文が抽出される様子を示す．残り2つのパターンも同様である．それぞれ，主部が評価文で述部が手がかり句である定型文にマッチするパターン（表中）と，評価文と手がかり句が同格になっている定型文にマッチするパターン（表下）である．</subsection>
  <subsection title="箇条書きからの抽出">箇条書きからの評価文抽出は，手がかり句リストとHTMLタグを利用すれば容易に実現できる．すなわち，手がかり句が見出しになっている箇条書きを見つけて，その箇条書きの項目を順に取り出していけばよい．例えば，前節の図からは「変に加工しない素直な音を出す」「曲の検索が簡単にでる」が好評文として，「リモコンに液晶表示がない」「ボディに傷や指紋がつきやすい」が不評文として取り出される．ここで問題となるのは，1つの項目に複数文が記述されている場合の処理である（図の3番目の項目）．このような場合は1項目に好評文と不評文が混在している可能性がある．各文の評価極性を自動判定することは難しいので，1つの項目に複数文が存在した場合，その項目は抽出に使わないことにした．例えば図からは「発色がものすごくよい．」と「撮っていくうちに楽しくなる．」「カメラ背面の液晶画面が大きく，見やすい．」が好評文として抽出される．</subsection>
  <subsection title="表からの抽出">最後に，表から評価文を抽出する方法を述べる．基本的には手がかり表現と&lt;table&gt;タグを利用すればよいのだが，HTML文書には多種多様な表が出現するので，あらゆる表に対応した抽出規則を作成することは難しい．そこで2種類の表だけを考えることにした（図）．図中のC_+とC_-は好評手がかり句と不評手がかり句を表し，＋と−は好評文と不評文を表す．タイプAは，1列目に手がかり句があって，その横に評価文があるタイプである．前節で紹介した図はこのタイプに相当する．タイプBは，1行目に手がかり句があって，その下に評価文があるタイプである．与えられた表のタイプは，1列目（1行目）を調べて，好評手がかり句と不評手がかり句の両方が出現していればタイプA（タイプB）であると判定する．表のタイプが決まれば，あとは図の＋と−に対応するマスから評価文を抽出すればよい．ただし，1つのマスに複数文が記述されている場合は抽出対象としない．これは箇条書きの1項目に複数文が記述されている場合と同様の理由からである．</subsection>
  <section title="実験">約10億件のHTML文書集合を用いて評価文の収集実験を行った結果，約65万の評価文を獲得することができた．ただし，使用したHTML文書にはミラーサイトなどの重複文書も含まれているため，同一の評価文が複数回抽出された場合は集計に入れていないようにした．表に収集された評価文数の詳細を示す．定型文は，3種類の語彙統語パターン（表）から抽出された評価文数を分けて示している．定型文1，2，3というのは，それぞれ表の上，中，下に記述されたパターンに相当する．表に自動収集された評価文の一例を示す．収集された評価文コーパスから250文（各抽出法ごとに50文ずつ）を無作為に取り出し，妥当な評価文が集められているかどうかを2人の評価者が人手で調査した．評価者には収集された文のみを提示して，それを好評，不評，曖昧の3つに分類するように指示した．曖昧というカテゴリは，好評文か不評文かを決めるのが困難な場合に使用するものとした．評価の結果を表に示す．抽出に利用した記述形式によって精度にややばらつきが見られるものの，おおよそ80%から90%の収集精度で評価文が収集できたことが分かる．ただし，評価者が曖昧と判断した文は不正解としている．さらに表に，評価者が曖昧と判断した文を除いた場合の精度を示す．表の結果と比べて，精度は大きく向上している．この結果から，表で不正解に数えられている事例は，ほとんどが人間でも判断に迷う（=評価者が「曖昧」に分類していた）ケースであったことが分かる．曖昧に分類された文の典型例は文脈情報が欠如している文であった．これについては次節で詳しく議論する．なお，調査で用いた250文のうち，2人の評価者の分類結果が一致したものは208文であった（Kappa値は0.748）．次に，自動構築した評価文コーパスをトレーニングデータに使って評価文分類器を構築し，その分類精度を調べた（表）．テストデータは，レストラン，コンピュータ，自動車の3ドメインのレビューサイトから収集したものを用いた．分類器はナイーブベイズ，素性は形容詞の原形を用いた．「良くない」などの言い回しに対応するため，形容詞と同一文節内に「ない」「ぬ」がある場合には，形容詞の原形に否定を示すタグを付与したものを素性に使った．また，自動収集した好評文と不評文の数に偏りがあったため，クラスの事前分布は好評，不評ともに0.5に設定した．比較のため，上記3種類のレビューデータを，それぞれトレーニング／テストデータとして使ったときの分類精度も調査した（表）．ただし，トレーニングとテストで同一データを用いた場合には，10分割の交差検定を行った．この表から，トレーニングとテストに同一データを使った場合は，本コーパスを用いた場合と同等の精度であることが分かる．その一方で，異なるデータを用いた場合には精度が大きく低下していることが確認できる．この実験結果から，レビューデータよりも本コーパスの方がドメインの変化に頑健であると言うことができる．これは，大量のHTML文書から評価文を収集しているため，幅広いドメインの表現を網羅しているからであると考えられる．</section>
  <section title="議論">実験の結果から，提案手法は80%から90%という精度で評価文を獲得できることが分かった．また，収集した評価文が分類タスクに対して有効であることも確認することができた．今後の課題としては，定型文から収集された評価文が多かったことから，新しい語彙統語パターンを利用して収集量をさらに拡大させることを検討している．また，収集した評価文からの評価表現辞書の構築にも取り組んでいる．評価者が「曖昧」と分類した評価文を分析したところ，評価極性を決定するために十分な文脈情報が与えられていない場合が大半であることが分かった．それ以外のものとしては，文分割と構文解析の誤りに起因するものが3例だけ見つかった．3例とも定型文から抽出されていた．文脈情報が欠落している例として「何しろ情報量が多い」という文が好評文として獲得されていた．この文の評価極性は文脈に依存するため，この文単独で評価極性を決定することは困難である．したがって，この評価文を人手で評価した場合には「曖昧」に分類される可能性が高い．しかし，実際にこの文が抽出された元テキストを調べてみると，次のようなものであった．このガイドブックのいいところは何しろ情報量が多いところです．lingexampleこれを見ると「何しろ情報量が多い」という文は，少なくとも原文では好評文として使われていたことが分かる．このことから，表で不正解に数えられている評価文の中には，完全な間違いとは言いきれないものが含まれていると考えている．利用した記述形式によって，収集される好評文と不評文の割合に大きな差が見られた．特に定型文2の内訳を見ると，不評文の数が圧倒的に多いことが分かる（表の定型文2）．この理由を調べたところ「〜なのが難点」という言い回しが頻出していることが原因であった．このような好不評の偏りは，例えば本コーパスを評価文分類器のトレーニングデータとして使うときには考慮しておく必要があると考えられる．本実験ではHTML文書から評価文の収集を行ったが，提案手法自体はHTML文書に特化したものではないと考えている．たしかに，箇条書きと表形式を利用した抽出処理は，HTML文書の特性を利用している．しかし，表から分かるように，抽出された評価文のうち80%以上が定型文から抽出されている．このことから，提案手法はHTML文書以外のコーパスに対しても有効に働くと考えられる．</section>
  <section title="関連研究">我々の知る限り，評価文の自動収集を行ったという研究はこれまでに報告されていない．最も関連が深いのは，評価語や評価句の自動獲得に関する研究である．これには主に2つのアプローチがあり，1つはシソーラスや国語辞典のような言語資源を利用して評価語を獲得する手法である．Kampsらは，類義語／反義語は同一／逆極性を持ちやすいという仮定にもとづき，WordNetを利用して評価語を獲得する手法を提案した．同様の考え方にもとづく手法はこれまでに多数提案されている．一方で，Esuliらは語の評価極性の判定を定義文の分類問題として解いている．評価語や評価句を獲得するためのもう1つのアプローチは，評価表現同士の共起関係を利用する方法である．Turneyは，評価表現は同一ウィンドウ内に共起しやすいとことに着目し，語句の評価極性を判定する手法を提案した．共起頻度を求めるときに既存のコーパスを利用するのではなく，検索エンジンを利用してウェブという大規模コーパスでの頻度を見積もり，データスパースネスの問題に対処している点が特徴である．Hatzivassiloglouらは，コーパス中で2つの形容詞がandなどの順接を表す接続詞で結ばれていれば同一評価極性を持ちやすく，逆にbutのような逆接で結ばれていれば逆極性を持ちやすいという観察にもとづき，コーパスから評価語を獲得する手法を提案した．この考え方はKanayamaらによってさらに拡張されている．語句の評価極性ではなく主観性に着目した研究報告も存在する．Wiebeは，人手でタグ付けされたトレーニングデータ利用して，主観的形容詞を学習する手法を提案している．Riloffらは主観的名詞の獲得を行っている．Riloffらの手法では，主観的名詞とその抽出パターンが交互に学習される．まずシステムには少数の主観的名詞が入力として与えられる．そして，それを利用して主観的名詞の抽出パターンを学習する，学習されたパターンで新たな主観的名詞を獲得する，という処理が繰り返される．これにより大量の主観的名詞の獲得が行われる．では名詞が対象とされていたが，では名詞以外の句も獲得対象となっている．同様のブートストラップ的な手法はでも議論されている．提案手法のように語彙統語パターンやレイアウト（箇条書きや表）パターンを用いて知識獲得を行う手法は古くから研究されてきている．Hearstは，suchasのようなパターンに着目して，単語間の上位下位関係をコーパスから獲得する手法を提案した．Hearstの手法は英語を対象としているが，日本語においても安藤らが同様の手法を試している．一方，新里らは，同一箇条書きに出現する単語は共通の上位語を持ちやすいという仮説にもとづき，上位下位関係を獲得する手法を提案している．これ以外にも，全体部分関係にある単語対の獲得や，属性と属性値の獲得といったタスクにも，同様の手法が用いられている．我々の知る限り，評価情報処理に同様の手法を適用したという報告はない．HuらやKimらの手法ではレイアウトパターンが利用されているが，これらの研究では，レイアウトは特定サイトに固有の手がかりとして議論されているため意味合いが異なる．</section>
  <section title="おわりに">本論文では大規模なHTML文書集合から評価文を自動収集する手法を提案した．提案手法を約10億件のHTML文書に適用したところ，約65万の評価文を獲得することができた．収集精度はおおよそ80%から90%であったが，文脈依存する評価文の存在を考慮すると，良好な結果であると考えている．今後は，このコーパスからの評価表現の収集に取り組む予定である．</section>
</root>
