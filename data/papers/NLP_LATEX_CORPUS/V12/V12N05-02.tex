\newif\ifdraft \draftfalse
\documentstyle[epsf,jnlpbbl]
{ jnlp_j}
\setcounter{page}{1}
\setcounter{巻数}{12}
\setcounter{号数}{4}
\setcounter{年}{2005}
\setcounter{月}{10}
\受付{2004}{12}{2}
\再受付{2005}{2}{14}
\再々受付{2005}{5}{5}
\採録{2005}{7}{19}


\headauthor{宇津呂・日野・堀内・中川}
\headtitle{日英関連報道記事を用いた訳語対応推定}

\author{宇津呂 武仁\affiref{KU} \and 日野 浩平\affiref{NTT} \and 堀内 貴司\affiref{Hitachi} \and 中川 聖一\affiref{TUT}}
\eauthor{Takehito Utsuro\affiref{KU} \and Kohei Hino\affiref{NTT} \and
Takashi Horiuchi\affiref{Hitachi} \and Seiichi Nakagawa\affiref{TUT}} 

\affilabel{KU}{
京都大学 情報学研究科 知能情報学専攻}
{Department of Intelligence Science and Technology,
  Graduate School of Informatics, Kyoto University}
\affilabel{NTT}{NTTデータテクノロジー株式会社}
{NTT Data Technology Corporation}
\affilabel{Hitachi}{日立製作所}
{Hitachi Ltd.}
\affilabel{TUT}{
豊橋技術科学大学 工学部 情報工学系}
{Department of Information and Computer Sciences, 
Toyohashi University of Technology}

\title{日英関連報道記事を用いた訳語対応推定}

\jabstract{
   近年，ウェブ上の日本国内の新聞社などのサイトにおいては，日本語だけでなく英語で書
   かれた報道記事も掲載しており，これらの英語記事においては，同一時期の日本
   語記事とほぼ同じ内容の報道が含まれている．
   本論文では，これらの報道記事のページから，
   日本語で書かれた文書および英語で書かれた文書を収集し，
   多種多様な分野について，
   分野固有の
   固有名詞(固有表現)や事象・言い回しなどの
   翻訳知識を獲得する手法を提案する．
   本論文の手法には，
   情報源となるコーパスを用意するコストについては，
   コンパラブルコーパスを用いた翻訳知識獲得のアプローチと同等に小さく，しかも
   同時期の報道記事を用いるため，
   片方の言語におけるタームや表現の訳が
   もう一方の言語の記事の方に出現する可能性が高く，
   翻訳知識の獲得が相対的に容易になるという大きな利点がある．
   翻訳知識獲得においては，まず，
   報道内容がほぼ同一もしくは密接に関連した日本語記事および英語記事を
   検索する．
   そして，関連記事組を用いて二言語間の訳語対応を推定する．
   訳語対応を推定する尺度としては，
   関連記事組における訳語候補の共起を利用する方法を適用し，
   評価実験において文脈ベクトルを用いる方法と比較し，
   この方法が有効であることを示す．
}
\jkeywords{機械翻訳，訳語対応推定，対訳コーパス，
            コンパラブルコーパス，言語横断情報検索，対訳辞書
}

\etitle{Estimating Bilingual Term Correspondences\\ from Relevant
       Japanese-English News Articles}

\eabstract{
  This paper focuses on bilingual news articles on WWW news sites
  as a source for translation knowledge acquisition.
  We take an approach 
  of acquiring translation knowledge
  of domain specific named entities, event expressions, 
  and collocational expressions
  from the collection of bilingual news articles on WWW news sites.
  In this framework, pairs of Japanese and English news articles
  which report identical contents or at least closely related
  contents are retrieved.
  Then, a statistical measure is employed for the task of estimating
  bilingual term correspondences 
  based on co-occurrence of Japanese and
  English terms across relevant Japanese and English news articles.
  We experimentally show that 
  the proposed method is effective in estimating
  bilingual term correspondences from cross-lingually relevant news articles.
}
\ekeywords{machine translation, estimating bilingual term correspondences, 
           parallel corpus, comparable corpus, cross-language IR, 
           bilingual lexicon
}


\def\argmax{}

\setcounter{topnumber}{2}
\def\topfraction{}
\setcounter{bottomnumber}{1}
\def\bottomfraction{}
\setcounter{totalnumber}{3}
\def\textfraction{}
\def\floatpagefraction{}

\def\argmax{}

\def\sekine_encoding{}

\begin{document}
\maketitle


\section{はじめに}

近年，コーパスを利用した機械翻訳の研究においては，
翻訳システムに不足している翻訳知識を人手で増強していく際のコストを
軽減する目的で，対訳コーパスやコンパラブルコーパス等の多言語コーパスから
様々な翻訳知識を獲得する手法の研究が行なわれてきた~\cite{Matsumoto00a}．
これまでに研究されてきた翻訳知識獲得の手法は，
大きく，対訳コーパスからの獲得手法とコンパラブルコーパスからの
獲得手法に分けられる．
通常，対訳コーパスからの獲得
(例えば，\cite{Gale91a})
においては，文の対応の情報を利用することにより，
片方の言語におけるタームや表現について，
もう一方の言語における訳の候補が比較的少数に絞られるため，
翻訳知識の獲得は相対的には容易といえる．
ただし，そのような対訳コーパスを人手で整備する必要がある点が短所である．
一方，コンパラブルコーパスからの獲得
(例えば，\cite{Rapp95a,Fung98a})では，
各タームの周囲の文脈の類似性を言語横断して測定することにより，
訳語対応の推定が行われる．
情報源となるコーパスを用意するコストは小さくて済むが，
対訳コーパスと比較すると，
片方の言語のコーパス中のタームや表現の訳がもう一方の言語のコーパスに
出現する可能性が相対的に低いため，
翻訳知識の獲得は相対的に難しく，
高性能に翻訳知識獲得を行うのは容易ではない．

そこで，本論文では，翻訳知識獲得の目的において，
人手で整備された対訳コーパスよりも利用可能性が高く，
一般のコンパラブルコーパスよりも翻訳知識の獲得が容易である情報源として，
日英二言語で書かれた報道記事に着目する．
近年，ウェブ上の日本国内の新聞社などのサイトには，
日本語だけでなく英語で書かれた報道記事も掲載されて
おり，これらの英語記事においては，同一時期の日本
語記事とほぼ同じ内容の報道が含まれている．
これらの日本語および英語の報道記事のページにおいては，
最新の情報が日々刻々と更新されており，分野特有の新出語(造語)や
言い回しなどの翻訳知識を得るための情報源として，非常に有用である．
そこで，本論文では，これらの報道記事のページから日本語および英語など，
異なった言語で書かれた文書を収集し，多種多様な分野について，
分野固有の人名・地名・組織名などの固有名詞(固有表現)や事象・言い回しなどの
翻訳知識を自動または半自動で獲得するというアプローチをとる．
本論文のアプローチは，
情報源となるコーパスを用意するコストについては，
コンパラブルコーパスを用いるアプローチと同等に小さく，しかも
同時期の報道記事を用いるため，
片方の言語におけるタームや表現の訳が
もう一方の言語の記事の方に出現する可能性が高く，
翻訳知識の獲得が相対的に容易になるという大きな利点がある．

\begin{figure}
\begin{center}
\epsfile{file=FIG/pic01.ai,scale=0.6} 
\end{center}
\vspace*{-.0cm}
\caption{日英関連報道記事からの翻訳知識獲得のプロセス}
\label{fig:pic01}
\end{figure}

本論文の翻訳知識獲得のアプローチにおいて，
日英関連報道記事から翻訳知識を獲得するプロセスの一般的な流れを
図~\ref{fig:pic01}に示す．
まず，翻訳知識獲得のための情報源収集を目的と
して，同時期に日英二言語で書かれたウェブ上の新聞社やテレビ局のサイトから，
報道内容がほぼ同一もしくは密接に関連した日本語記事および英語記事を
検索する．
この際には，既存の対訳辞書，翻訳ソフトの翻訳知識を利用することにより，
日本語記事と英語記事の間の関連性を測定する．
そして，取得された関連記事対に対し，内容的に対応する翻訳部分の推定を行い，
その推定範囲から二言語間の訳語対応を推定し，訳語対の獲得を行う．
ここで，  
  従来のコンパラブルコーパスからの
  訳語対獲得のアプローチにおいては，原理的には，
  コンパラブルコーパスに出現する全ての日本語タームおよび英語タームの組を
  訳語対応の候補としていた．
  一方，本論文のアプローチでは，
  予備調査の結果~\cite{Utsuro03b,Horiuchi03aj}をふまえて，
  関連報道記事の組において共起した日本語ターム，
  および，英語タームの組を収集し，これを訳語対応の候補としており，
  この点が特徴的である
  \footnote{
  予備調査の結果~\cite{Utsuro03b,Horiuchi03aj}においては，
  関連報道記事の組において共起した日本語ターム，
  および，英語タームの組を訳語対応の候補とすることにより，
  不要な訳語対応の候補を大幅に削減できることが分かっており，
  本論文のアプローチが適切であることの裏付けとなっている．
}．
ただし，本論文で述べる手法の範囲では，現在のところ，関連記事中で
内容的に対応する翻訳部分の推定は行なっておらず，
関連記事対全体から訳語対応を推定している．
また，
訳語対応を推定する尺度としては，
関連記事組における訳語候補の共起を利用する方法を適用し，
評価実験を通して，この方法が有効であることを示す．
特に，評価実験においては，
訳語対応を推定すべき英語タームの出現頻度の分布に応じて，
訳語対応推定性能がどのように変化するかを調査し，その相関を評価する．


以下，\ref{sec:clir}~節では，
翻訳知識獲得のための情報源収集を目的として，
言語を横断して，
報道内容がほぼ同一もしくは密接に関連した日本語記事および英語記事を
検索する処理について述べる．
次に，\ref{sec:msr}~節では，
関連記事組の集合から訳語対応を推定する手法について述べる．
\ref{sec:eval}~節において，実験を通して提案手法の評価を行ない，
\ref{sec:related}~節において，関連研究について詳細に述べる．


\section{言語横断関連報道記事検索}
\label{sec:clir}

\begin{figure}
\begin{center}

  \epsfile{file=FIG/clir.ai,scale=0.5} 

\caption{日英関連報道記事検索のプロセス}
\label{fig:clir}
\end{center}
\end{figure}

本論文の翻訳知識獲得のアプローチにおける
言語横断関連報道記事検索の流れを図~\ref{fig:clir}に示す．
言語横断関連報道記事検索においては，
まず，新聞社やテレビ局のサイトから英語記事$d_E$と日本語記事$d_J$を取得する．
次に，内容的にほぼ同一の日英記事対は，お互いの日付が前後数日程度の範囲に
あるという調査結果~\cite{Horiuchi02aj,Horiuchi02bj}に基づいて，
日付の情報を用いて検索対象の記事を絞りこむ
(実際に，評価実験において用いた日英記事間の日付の幅の詳細については，
\ref{subsec:expr_sb}~節で述べる．)．
そして，取得した英語記事$d_E$と日本語記事$d_J$の間の類似性を測るために，
翻訳ソフト・対訳辞書・数値表現翻訳規則などの情報源を利用して
英語記事$d_E$を日本語訳に変換する．
ここで，言語横断関連報道記事検索の性能において，
翻訳ソフト(オムロン社製「翻訳魂」)，対訳辞書(英辞郎Ver.37，85万語)，
および，数値表現翻訳規則
(規則数約300)
の三種類の情報源の性能を比較した結果においては，
翻訳ソフトが最も高い検索性能を達成した~\cite{Hamamoto03aj}．
そこで，本論文の評価実験においても，
翻訳ソフトを用いて英語記事の日本語訳を行った後，
関連記事検索を行った結果を用いる
\footnote{
   \cite{Hino04aj}においては，
   訳語対応推定の性能において，
   翻訳ソフトを用いて日英関連報道記事を検索した結果，および，
   対訳辞書を用いて日英関連報道記事を検索した結果を比較しているが，
   ここでも，翻訳ソフトを用いた方が高い性能となっている．
}．

次に，英語記事$d_E$の日本語訳から日本語訳頻度ベクトル$v_{trJ}(d_E)$を，
また，日本語記事$d_J$から日本語頻度ベクトル$v(d_J)$を，それぞれ作成する．
ここでは，日本語形態素解析システム「茶筌」
\footnote{
  {\tt http://chasen.naist.jp/hiki/ChaSen/}
}
を用いてテキストを形態素列に分割し，
平仮名語の高頻度機能的表現26語を不要語として削除した．
また，頻度ベクトルにおいては，
接頭詞，名詞，動詞によって構成され，
形態素長が5以内の形態素列を次元とした
\footnote{
   各記事の頻度ベクトルの次元としては，
   \ref{subsec:estm-cv}~節で述べる文単位の文脈頻度ベクトルの次元と同じも
   のを用いている．
   予備調査の結果，
   文脈頻度ベクトルを用いた訳語対応推定においては，
   一形態素のみを次元とした文脈頻度ベクトルでは不十分であるが，
   5形態素長以内の形態素列を次元としておけば，周囲の文脈として必要な表現が
   ほぼ含まれることが分かっている．
   これは，5形態素を越える長さの形態素列を用いないと，
   周囲の文脈の特性を表現しきれない，ということが極めて稀であるからであ
   る．
   一方，関連記事検索の性能を評価した予備調査の結果においては，
   名詞および動詞の一形態素のみを次元とした場合と，
   5形態素長以内の形態素列を次元とした場合との間の性能差はわずかであった．
   以上をふまえて，本論文では，頻度ベクトルの次元としては，
   形態素長が5以内の形態素列を用いる．
}．
最後に，頻度ベクトル間で余弦類似度を計算し，
余弦類似度が下限値以上の記事を関連記事検索結果とする．

ここで，この検索結果から，日英関連記事組を作成する場合には，
英語記事を検索質問として関連日本語記事を収集する場合と，
逆に，日本語記事を検索質問として関連英語記事を収集する場合の二通りが
考えられる．
詳細については\ref{subsec:expr_sb}~節で述べるが，
本論文の評価実験において対象とした新聞社・テレビ局のサイトは
日本国内のもので，掲載される報道記事数は，
日本語記事数が英語記事数の4$\sim$6倍となっている．
したがって，検索質問として日本語記事を用いる場合よりも，
検索質問として英語記事を用いた場合の方が，
関連記事組が収集できる割合が大きい．
実際に，検索質問として英語記事を用いた場合には，
検索質問の約半数に対して関連記事組が収集できることが
分かっている~\cite{Horiuchi02aj,Horiuchi02bj}．
これらの調査結果をふまえて，本論文では，
英語記事を検索質問として関連日本語記事を収集することにより，
日英関連記事組を作成する．
ここで，検索質問となる英語記事
$d_E$の日本語訳頻度ベクトル$v_{trJ}(d_E)$との間で余弦類似度の値が下限値$L_d$以上となる日本語記事の集合を
$D_J$とする．
{
\begin{eqnarray*}
D_J & = & \Bigl\{d_J\mid \cos(v_{trJ}(d_E),v(d_J))\geq L_d \Bigr\}
\end{eqnarray*}
}
そして，$D_J$中の記事を結合することにより一つの日本語記事$D'_J$を構成し，
このような英日関連記事組$\langle d_E,D'_J\rangle$を集めた集合を$RC_{EJ}$
とする
(
ここで，
$D_J$中の記事を結合して一つの日本語記事$D'_J$を構成するのは，
\ref{subsec:estm-cont}~節において，関連記事組の集合$RC_{EJ}$を疑似的な対訳コーパスとみなして
訳語対応の推定を行なうためである．
)．
{
\begin{eqnarray}\label{eqn:RCej}
RC_{EJ} & = & \Bigl\{\langle d_E,D'_J\rangle\mid D_J\neq \emptyset\Bigr\}
\end{eqnarray}
}

\begin{table}
\begin{center}
 \caption{$2\times 2$分割表}
 \label{tab:2t2}
{
\begin{center}
\begin{tabular}{c|cccc} \hline
               & $t_J$ & && $\neg t_J$ \\ \hline
$t_E$ &          $df(t_E,t_J)=a$ & && $df(t_E,\neg t_J)=b$  \\
$\neg t_E$    &  $df(\neg t_E,t_J)=c$ & && $df(\neg t_E,\neg t_J)=d$
 \\ \hline
\end{tabular}
\end{center}
}
\end{center}
\end{table}




\section{日英関連報道記事における訳語対応の推定}
\label{sec:msr}
\vspace*{-.0cm}

本論文では，関連記事組の集合$RC_{EJ}$から訳語対応を推定する方法として，
関連記事組の集合を疑似的な対訳コーパスとみなして，
対訳コーパスにおける共起頻度を用いた訳語対応推定尺度を適用する方法，
および，関連記事組の集合をコンパラブルコーパスとみなして，
コンパラブルコーパスからの訳語対応推定手法を適用する方法の二種類を
比較する．
本節では，関連記事組の集合を疑似的な対訳コーパスとみなす場合の方法を
\ref{subsec:estm-cont}~節で，
関連記事組の集合をコンパラブルコーパスとみなす場合の方法を
\ref{subsec:estm-cv}~節で，それぞれ説明する．
以下，訳語対応推定の対象となる英語ターム(連語または単語)を$t_E$，
日本語ターム(連語または単語)を$t_J$として，
$t_E$と$t_J$の間の訳語対応推定値を$corr_{EJ}(t_E,t_J)$とする．

\subsection{関連記事組における訳語候補の共起および分割表を用いた推定}
\label{subsec:estm-cont}

関連記事組の集合$RC_{EJ}$を疑似的な対訳コーパスとみなして訳語対応の推定
を行う場合は，
対訳コーパスからの訳語対応推定の場合と同様に，
一般に共起推定でよく用いられる相互情報量，
$\phi^2$統計，dice係数，対数尤度比などの尺度\cite{Matsumoto00a}
が適用可能である．
これらの尺度を比較したところ，
訳語対応推定の性能としては，
$\phi^2$統計，dice係数，対数尤度比が
ほぼ同程度の性能となり，
相互情報量はやや劣るという結果が得られた．
そこで，本論文では，$t_E$と$t_J$の統計的相関を測定する尺度としては，
$\phi^2$統計を用いることとし，
これを訳語対応推定値$corr_{EJ}(t_E,t_J)$とする．
具体的には，
$RC_{EJ}$中の関連記事組$\langle d_E,D'_J\rangle$において
$t_E$と$t_J$が共起する記事組数$df(t_E,t_J)(=aとする)$，
$t_E$のみが含まれ$t_J$が含まれない記事組数$df(t_E,\neg t_J)(=bとする)$，
$t_J$のみが含まれ$t_E$が含まれない記事組数$df(\neg t_E,t_J)(=cとする)$，
$t_E$も$t_J$も含まれない記事組数$df(\neg t_E,\neg t_J)(=dとする)$を用いて
表1の$2\times 2$分割表を構成する．
この$2\times 2$分割表を用いると，
$t_E$と$t_J$の$\phi^2$統計は以下で与えられる．
{
\begin{eqnarray*}
\phi^2(t_E,t_J) 
 & =& \frac{(ad - bc)^2}{(a + b)(a + c)(b + d)(c + d)}
\end{eqnarray*}
}

\subsection{文脈の類似性を用いた推定}
\label{subsec:estm-cv}

関連記事組の集合$RC_{EJ}$をコンパラブルコーパスとみなして訳語対応の推定を行う場合は，
$t_E$および$t_J$についての文単位の文脈頻度ベクトルを求め，
これらの文脈頻度ベクトル間の類似性を用いて$t_E$と$t_J$の
訳語対応を推定する．
具体的には，前節で述べたように，
英語記事$d_E$に対する日本語訳頻度ベクトルを$v_{trJ}(d_E)$として，
$d_E$において$t_E$が出現する文の日本語訳の頻度ベクトルを
$v_{trJ}(d_E)$から求め，これを加算して，
$t_E$に対する文単位の文脈頻度ベクトル$cv_{trJ}(t_E)$を構成する．
同様に，日本語記事$d_J$を集めた記事集合において$t_J$が出現する文について，
それらの頻度ベクトルを加算することにより，
$t_J$に対する文単位の文脈頻度ベクトル$cv(t_J)$を構成する．
そして，この文脈頻度ベクトル間の余弦$\cos(cv_{trJ}(t_E),cv(t_J))$を
$corr_{EJ}(t_E,t_J)$とする．

\section{実験および評価}
\label{sec:eval}

\subsection{言語横断関連報道記事検索}
\label{subsec:expr_sb}

国内の新聞社等三社のウェブサイトから，
表~\ref{tab:01}に示す日数・記事数・記事長の
英語および日本語の報道記事を収集した．
また，表~\ref{tab:01}には，
言語横断関連報道記事検索の性能の評価のために用いる
評価用日英記事対数も示す．
ここで，本論文では，
報道内容がほぼ同一の日英記事対のことを「同一内容」の記事対とよび，
報道内容は同一ではないが，記事として密接に関連している
日英記事対(例えば，事件発生に関する報道記事に対して，
犯人逮捕に関する続報記事など)のことを「関連話題」の記事対とよぶ．

次に，\ref{sec:clir}~節で述べたように，
英語の記事に対してほぼ同一の内容の日本語記事が存在する日付の幅を設定し，
その日付の幅の範囲で言語横断関連報道記事検索を行った．
評価用日英記事対のうちの英語記事を検索質問として，
日本語記事を検索した場合の適合率・再現率の変化をプロットしたものを
図~\ref{fig:recSim}に示す．
ここで，評価用(同一内容または関連話題)記事対の集合を$DP_{ref}$，
記事間類似度の下限値を$L_d$とすると，この場合の適合率・再現率の定義は，
{
\begin{eqnarray*}
 適合率 & = & \frac{|\{\langle d_E,d_J\rangle\mid \langle d_E,d_J\rangle\in DP_{ref}, \cos(d_E,d_J)\geq L_d\}|}
              {|\{d_E\mid \exists d'_J, \langle d_E,d'_J\rangle\in DP_{ref}, \exists d_J \cos(d_E,d_J)\geq L_d\}|}
\\
& & \\
 再現率 & = & \frac{|\{\langle d_E,d_J\rangle\mid \langle d_E,d_J\rangle\in DP_{ref}, \cos(d_E,d_J)\geq L_d\}|}
              {|\{\langle d_E,d_J\rangle\mid \langle d_E,d_J\rangle\in DP_{ref}\}|}
\end{eqnarray*}
}
となる．

また，表~\ref{tab:acq_art}には，
記事間類似度下限$L_d$を変化させた場合に検索される記事数の一覧を示す．
表~\ref{tab:acq_art}においては，
各サイトについて用いた日付の幅もともに示す．
ここで，「日本語記事数(重複あり)」の欄には，
二つ以上の英語記事に対して重複して検索された日本語記事を重複して
数えた記事数を示す．
この結果から，類似度下限$L_d$が0.4や0.5の場合は，
利用可能な記事数が著しく減少することが分かる．
また，図~\ref{fig:recSim}においても，類似度下限$L_d$が0.4や0.5の場合は，
再現率が大きく低下している．
ここで，予備実験において，訳語対応推定が安定して行えるためには，
一定規模以上の記事が必要であるという結果が得られていたため，
以降の訳語対応推定は，類似度下限$L_d=0.3$の条件のもとで行う．

\begin{table}
\begin{center}
 \caption{記事の日数・記事数・平均記事長}
 \label{tab:01}
  \newcommand{\lw}[1]{}
{
  \begin{tabular}{|c|c||c|c|c|c|c|c|}
   \hline
          &   &        &          & 一日の平 & 一記事の平均 
             &  \multicolumn{2}{|c|}{評価用記事対数} \\ \cline{7-8}
   新聞社 &   & 総日数 & 総記事数 & 均記事数 & 記事長(byte) &
                     同一内容 & 関連話題 \\ \hline\hline
          &   英語   & 935 & 23064 & 24.7 & 3228.9 & \lw{28} & \lw{31} \\ \cline{2-6} 
サイトA      &   日本語 & 941 & 96688 & 102.8 & 837.7 & & \\ \hline
          &   英語   & 935 & 14587 & 15.6 & 3302.6  & \lw{28} & \lw{82} \\ \cline{2-6} 
サイトB      &   日本語 & 941 & 81652 & 86.8 & 867.9 & & \\ \hline
          &   英語   & 935 & 1553  & 1.6 & 1368.6 & \lw{24} & \lw{33} \\ \cline{2-6} 
サイトC       &   日本語 & 941 & 9660  & 10.2 & 774.3 & & \\ \hline
  \end{tabular}
}
\vspace*{.5cm}

 \caption{記事間類似度の下限を満たす日英報道記事の数}
 \label{tab:acq_art}
{
   \begin{tabular}{|c|c||r|r|r|}                      \hline
   & \multicolumn{1}{|c||}{類似度下限$L_d$} 
           &  \multicolumn{1}{|c|}{0.3} & \multicolumn{1}{|c|}{0.4} 
    & \multicolumn{1}{|c|}{0.5}  \\ \hline\hline
   & \multicolumn{1}{|c||}{日付幅 (日)} 
    &\multicolumn{3}{|c|}{$\pm$ 2} \\ \cline{2-5}
   サイトA&    英語記事数 & 6073 &  2392 & 701 \\ \cline{2-5}
   &   日本語記事数 &  12367  & 3444 & 882 \\ \cline{2-2}\cline{3-5}
   &   日本語記事数(重複あり) & 16507  & 3840 & 918 \\ \hline
    \hline

   & \multicolumn{1}{|c||}{日付幅 (日)} 
    &\multicolumn{3}{|c|}{$\pm$ 2} \\ \cline{2-5}
   サイトB&    英語記事数 & 4316 & 1658  & 396 \\ \cline{2-5}
          &   日本語記事数 & 8108 & 2349 & 499 \\ \cline{2-2}\cline{3-5}
   &   日本語記事数(重複あり) & 11451  & 2694 & 523 \\ \hline
    \hline

   & \multicolumn{1}{|c||}{日付幅 (日)} 
    &\multicolumn{3}{|c|}{$\pm$ 4} \\ \cline{2-5}
   サイトC&    英語記事数 & 765 &  413 & 159 \\ \cline{2-5} 
          & 日本語記事数  &  1918&  673 & 192 \\ \cline{2-2}\cline{3-5}
   &   日本語記事数(重複あり) & 2406&  766 & 203 \\ \hline
   \end{tabular}
}
\end{center}
\end{table}

\begin{figure*}
 \begin{center}
\begin{tabular}{c}
   サイト A \\
  \epsfile{file=FIG/yom-pre+rec.eps,scale=0.3} \\
   サイト B \\
  \epsfile{file=FIG/asa-pre+rec.eps,scale=0.3} \\
   サイト C \\
  \epsfile{file=FIG/tbs-pre+rec.eps,scale=0.3}
\end{tabular}
  \caption{日英関連記事検索の適合率・再現率 (記事間類似度$\geq\ L_d$)}
  \label{fig:recSim}
 \end{center}
\end{figure*}

\subsection{英語・日本語訳語組候補の条件}

本論文では，実装の都合上，英語・日本語間で訳語組候補となるタームに対して，
タームを構成する単語もしくは形態素の数に上限を設け，
さらに，タームを構成する単語もしくは形態素の品詞にも制限を設ける．
まず，タームを構成する単語もしくは形態素の数については，上限を5とする．
この条件により，次節で選定される評価用英語ターム
(およびその正解日本語訳語)については，
構成単語数あるいは構成形態素数が5を越えるものは除外される．
また，英語タームとしては名詞句を対象とすることとし，
Charniak parser
\footnote{\tt
   http://www.cs.brown.edu/people/ec/
}
を用いて各英語単語の品詞付けを行い，
英語単語列として以下の表現を満たすものだけを対象とする
(
ただし，$*$は0回以上の繰り返し，$+$は1回以上の繰り返しを表す．
)．
\begin{itemize}
 \item $W_1=[形容詞|名詞|現在分詞|
          \hspace*{0cm}過去分詞|動名詞]* 名詞$
 \item $W_2=([形容詞|名詞|現在分詞|過去分詞|
          \hspace*{0cm}動名詞]+,)\ast \\
          \hspace*{2cm}[形容詞|名詞|現在分詞|過去分詞|
          \hspace*{0cm}動名詞]+ \hspace{1mm} and \hspace{2mm}\\
          \hspace*{2cm} [形容詞|名詞|現在分詞|過去分詞|
           \hspace*{0cm}動名詞]\ast 名詞$
\end{itemize}
日本語タームについても，
名詞句相当のものを対象とする．
具体的には，
接頭詞，名詞，動詞によって構成される形態素列を対象とする
(構成要素に動詞を含めたのは，
連用形の名詞用法に対応するためである．
ただし，現時点では，活用形の照合は行なっていないため，
日本語タームの候補として適切でないものも混入している．
)．

さらに，\ref{sec:clir}~節の(\ref{eqn:RCej})式において，
英日関連記事組を集めて構成した集合$RC_{EJ}$中の
関連記事組$\langle d_E,D'_J\rangle$において，
英語ターム$t_E$と日本語ターム$t_J$が共起する記事組数$df(t_E,t_J)$に
下限を設け，これを2以上とする．

\subsection{評価用英語タームの選定}
\label{subsec:perform}

本論文の訳語対応推定の評価実験の範囲では，
訳語対応推定の対象とする英語タームを自動抽出することは行わず，
訳語対応推定の評価用英語タームを人手で選定しておき
\footnote{
  既存のターム抽出技術を用いることにより，
  一定レベルの性能で英語タームを抽出することは可能である．
  本論文の訳語対応推定の枠組において，英語ターム自動抽出の技術を
  併用すれば，訳語組を全自動で獲得する一連の流れの性能を評価する
  ことができると考えられる．
}，
これらに対して日本語訳語候補を自動抽出し，
日本語訳語候補の順位付け性能の評価を行った．
特に，本論文では，
既存の翻訳ソフト
(オムロン社製「翻訳魂」)
によって翻訳することができず，
対訳辞書
(英辞郎Ver.37，85万語)
にも存在しない英語タームを評価用英語タームとして選定した．
ここで，英語ターム出現頻度の計算を効率よく行うために，
PrefixSpan~\cite{Pei01a}
\footnote{
    {\tt http://chasen.org/\~{}taku/software/prefixspan/}
}
を用いて頻度5以上の単語列の頻度を測定した．
そして，頻度5以上10未満，10以上20未満，20以上，の三種類の
出現頻度
分布
(
ただし，サイトCは，他のサイトに比較して記事数が少ないため，
頻度5以上10未満，および，10以上，の二種類の分布とした．
)
で単語列集合を分割し，
それぞれの集合に対して，以下の
手順によって評価用英語タームを選定した．


\begin{table*}
\begin{center}
 \caption{評価用英語ターム数の分布}
 \label{tb:03}
{\footnotesize
  \begin{tabular}{|c|c||c|c|c|}
    \multicolumn{5}{c}{(a)\ \  全体} \\ \hline
サイト &   頻度  & 5$\sim$10  & 10$\sim$20 & 20以上 \\ \hline\hline
&   MT    & 117   & 158   & 531   \\ \cline{2-5}
&   辞書  & 1391  & 1718  & 2507  \\ \cline{2-5}
A & その他    & 4423  & 3483  & 2786 \\ \cline{2-5}
&   総数  & 5931  & 5359  & 5824  \\ \hline\hline
   &   MT    & 104   & 214   & 791   \\ \cline{2-5}
&   辞書  & 1098  &  1367 & 1968  \\ \cline{2-5}
B &   その他    & 3105  & 2364  & 1868  \\ \cline{2-5}
&   総数  & 4292  & 3835  & 4167  \\ \hline\hline
   &   MT    & 103   & \multicolumn{2}{|c|}{164} \\ \cline{2-5}
&   辞書  &  226  &   \multicolumn{2}{|c|}{205} \\ \cline{2-5}
C &その他  &  313  &  \multicolumn{2}{|c|}{152} \\ \cline{2-5}
&   総数 &  585  &  \multicolumn{2}{|c|}{424} \\ \hline
  \end{tabular}

\vspace*{.3cm}

  \begin{tabular}{|c|c||c|c|c||c|c|c||c|c|c|c|c|}
\multicolumn{11}{c}{(b)\ \ $\phi^2統計値$ごとの分布} \\
   \hline
&    & \multicolumn{3}{|c||}{$\phi^2統計値$ 1$\sim$0.15}
   & \multicolumn{3}{|c||}{$\phi^2統計値$ 0.15$\sim$0.07}
   & \multicolumn{3}{|c|}{$\phi^2統計値$ 上位100} \\ \cline{2-11}

サイト &   頻度  & 5$\sim$10  & 10$\sim$20 & 20以上 &
   5$\sim$10  & 10$\sim$20 & 20以上 & 5$\sim$10  & 10$\sim$20 & 20以上 \\ \hline\hline
&    MT  & 58 & 82 & 289 & 32 &37 & 147 
    & 38 & 110 & 103 \\ \cline{2-11}
&    辞書  & 285 & 407 & 727 & 229
   & 304 & 570 
   & 73 & 166 & 157 \\ \cline{2-11}
A &  評価用  & 148  &  116  & 131 &51 & 48 &56
  & 100 & 100  & 100  \\ \cline{2-11}
& 除外  & 866 & 671 & 687& 800 &
   684 & 618
 & 199 & 75 & 66  \\ \cline{2-11} 
&   総数 & 1357 & 1276 & 1834 & 1112 &
   1073 & 1391
   & 397 & 381 & 360 \\ \hline\hline
   & MT  & 87 & 124& 377 & 28 & 57& 226 
    & 87 & 128 & 95 \\ \cline{2-11}
&  辞書  & 216 & 321 & 590 & 203
   & 236 & 452 
   & 216 & 333 & 218 \\ \cline{2-11}
B &   評価用  & 104  &  71  & 102 &25 & 45 &26
  & 100 & 100 &  100 \\ \cline{2-11}
&    除外  & 669 &  476  & 462 & 570 &
   432 & 418
 & 673 & 487  & 306  \\ \cline{2-11} 
&   総数 & 1048 &  922 & 1298 &  808 &
   740  &  995
   & 1048 & 977 & 668 \\ \hline
   & MT  & 75 & \multicolumn{2}{|c||}{114} & 22 & \multicolumn{2}{|c||}{43} 
    & 103 & \multicolumn{2}{|c|}{164} \\ \cline{2-11}
&   辞書  & 147 & \multicolumn{2}{|c||}{125} &  46
   &  \multicolumn{2}{|c||}{60} 
   & 226 & \multicolumn{2}{|c|}{205}  \\ \cline{2-11}
C &  評価用  &  43  &  \multicolumn{2}{|c||}{35}
   & 10 &  \multicolumn{2}{|c||}{4}
    & 57 & \multicolumn{2}{|c|}{40}
   \\ \cline{2-11}
& 除外   & 158 &
   \multicolumn{2}{|c||}{68}  
     & 54&  \multicolumn{2}{|c||}{33} & 256 & \multicolumn{2}{|c|}{112}
 \\ \cline{2-11} 
& 総数    &  379 &
   \multicolumn{2}{|c||}{275}
    &123& \multicolumn{2}{|c||}{115} & 585 & \multicolumn{2}{|c|}{424}
 \\ \hline
  \end{tabular}

}


\end{center}
\end{table*}

\begin{enumerate}
\item 英語タームグループの作成
\item $\phi^2$統計値を用いた英語タームグループの整列
\item 評価用英語タームの選定
\end{enumerate}
以下，これらの手順の詳細について順に述べる．

\subsubsection{英語タームグループの作成}

前節で述べた通り，本論文では，英語タームとしては名詞句を対象とする．
そこで，まず，前節の制限を満たす英語単語列を抽出する．
次に，単語列の上で包含関係にある単語列同士をグルーピングし，
英語タームグループを作成した．
このとき，多くの場合，一つの英語タームグループ中において，
適切な英語タームとして認定すべき単語列は高々一つ程度であるので，
実質的なターム数はタームグループ数とほぼ等しい．
このことをふまえて，
頻度5以上10未満，10以上20未満，20以上，の三種類の出現頻度分布ごとの
英語タームの内訳を表~\ref{tb:03}(a)に示す
(ただし，サイトCについては，頻度5以上10未満，および，10以上，
の二種類の出現頻度分布とする)．
英語タームの内訳は，
翻訳ソフトで翻訳に成功した英語ターム数(「MT」の欄)，
対訳辞書に存在する英語ターム数(「辞書」の欄)，
および，
翻訳ソフトによって翻訳することができず，
対訳辞書にも存在しない英語ターム数(「その他」の欄)によって示す．
ただし，翻訳ソフトで翻訳できる英語タームおよび
対訳辞書に存在する英語タームの間には重複があり得る．

\subsubsection{$\phi^2$統計値を用いた英語タームグループの整列}

次に，ある英語タームグループについて，その要素となる英語ターム
$t_E$が任意の日本語訳語候補に対して持つ$\phi^2$統計値
$\phi^2(t_E,t_J)$の最大値を，そのグループの持つ$\phi^2$統計値と
みなして，英語タームグループを$\phi^2$統計値の降順に整列した．
なお，詳細は\ref{subsec:estm-eval}~節で述べるが，
予備実験\cite{Hino04aj}において，\ref{subsec:estm-cont}~節の
$\phi^2$統計を用いる方法と，\ref{subsec:estm-cv}~節の文脈ベクトルを
用いる方法を比較した結果では，$\phi^2$統計を用いた方法の方が
高い性能であった．
そこで，本論文では，$\phi^2$統計値の降順に整列した
英語タームグループを用いて評価用英語タームを選定することとした．

\subsubsection{評価用英語タームの選定}

この整列済み英語タームグループのうち，
「その他」に分類される英語タームグループを人手で選別し，
以下の個数の評価用英語タームを選定して，
合計三種類の評価用英語タームセットを作成した．
\begin{enumerate}
\item[(i)] $\phi^2$統計値の決められた範囲($1\sim0.15$および
	   \hspace*{0cm}
	   $0.15\sim0.07$)から，
	   無作為に評価用英語ターム
	   \hspace*{0cm}を100個ずつ選定した．
	   ただし，100個に満たない場合は可能な限り選定する．
\item[(ii)] 上位の英語タームグループに含まれる英語タームから順に
	   評価用英語タームを100個選定した．
\end{enumerate}
ただし，選別の際には，
各新聞記事を参照しながら，冗長部分を持つもの，別の単語列の断片であるもの，
一般的で訳語が一意に定まらないようなもの，
および，人名と地名を除外した．
その上で，日本語関連記事から収集した日本語訳語候補に
正解訳語が含まれている，いないに関わらず，
英語タームが妥当であると判断したものを選定した
\footnote{
  この条件により，本論文の訳語対応推定の評価は，
  各サイトから収集した日英関連記事組において，正解の日本語訳語が
  どの程度の割合で含まれているかを考慮した評価となっていると言える．
  実際に，正解の日本語訳語が含まれる度合はサイトによって異なっており，
  その詳細については，次節で考察する．
}
\footnote{
  厳密には，正解である日本語訳語が前節の日本語タームの条件
  (接頭詞，名詞，動詞によって構成され，形態素長が5以内の形態素列)
  を満たさない場合には，訳語候補の日本語タームとすることができない．
  このような場合には，
  正解日本語訳語との間の訳語対応推定が不可能である
  ため，評価用英語タームとしては選定しなかった．
}．
この手順から分かるように，「その他」に分類される英語タームは，
人手による選定の際に，訳語対応推定対象としては適切でないと判断して
除外したもの，訳語対応推定対象として適切であり，評価用英語タームとして
選定されたもの，および，人手による選別を受けないまま残されたものの
三種類のタームから構成される．

この結果，サイトA，および，サイトBについては，
頻度5以上10未満，10以上20未満，20以上の三通りの頻度分布ごとに
これらの評価用英語タームセットを作成したため，
合計で9個のタームセットとなった．
また，サイトCについては，
頻度5以上10未満，10以上の二通りの頻度分布ごとに
これらの評価用英語タームセットを作成したため，
合計で6個のタームセットとなった．
これらのタームセットにおける英語ターム数の内訳を
表~\ref{tb:03}(b)に示す
\footnote{
  実際は，英語タームグループ数だが，上述の通り，英語ターム数と
  英語タームグループ数はほぼ等しい．
}．
英語ターム数の内訳は，各タームセットについて，
翻訳ソフトで翻訳に成功した英語ターム数(「MT」の欄)，
対訳辞書に存在する英語ターム数(「辞書」の欄)，
人手で選定した英語ターム数
(「評価用」の欄 --- ただし，100個を超える場合には，
実際の評価実験において使用したのは100個のみ)，
および，上記の理由により除外した英語ターム数(「除外」の欄)によって示す~\footnote{
  具体的には，「$\phi^2統計値 1\sim0.15$」および
  「$\phi^2統計値 0.15\sim0.07$」の「評価用」の欄には，
  英語タームの$\phi^2統計値$について，
  それぞれの範囲内で無作為に評価用英語タームを選定した場合のターム数を示し，
  「$\phi^2$統計値 上位100」の「評価用」の欄には，
  $\phi^2統計値$の降順に，評価用英語タームを100個選定した場合のターム数を示す．
}．
ただし，翻訳ソフトで翻訳できる英語タームおよび
対訳辞書に存在する英語タームの間には重複があり得る．
実際に選定した評価用ターム組の例を表~\ref{tab:ex}に示す．


表~\ref{tb:03}(b)において，
例えば，サイトAに対して$\phi^2$統計値が1$\sim$0.15，
頻度分布が5以上10未満の英語タームに注目すると，
総数は1,357個，対訳辞書のエントリに含まれたものが285個，
翻訳ソフトで訳せたものが58個，
対訳辞書のエントリに含まれず翻訳ソフトでも訳せず，
訳語対応の獲得対象として判定したターム数は148個，
対訳辞書のエントリに含まれず翻訳ソフトでも訳せないが，
訳語対応の獲得対象とは判定されなかったターム数が866個となっている．
表~\ref{tb:03}から分かるように，
本論文における評価用英語タームの選定においては，
「除外」と判定されるタームの割合が大きくなっている．





{
\begin{table}
\begin{center}
 \caption{評価用日英ターム組の例}
 \label{tab:ex}
 \begin{tabular}{|c|c|} \hline
  英語ターム & 日本語ターム \\
  \hline\hline
  High Public Prosecutors Office & 高検 \\ \hline
  Environment Ministry & 環境省 \\ \hline
  Japanese Consulate General & 日本総領事館 \\ \hline
  diesel-powered vehicles & ディーゼル車 \\ \hline
  Japan Coast Guard & 海上保安庁 \\ \hline
  fertilized eggs & 受精卵 \\ \hline
  Tokyo District Public Prosecutors Office & 東京地検 \\ \hline
  Aum Supreme Truth & オウム真理教 \\ \hline
  intellectual property rights & 知的財産権 \\ \hline
  special structural reform zones & 構造改革特区 \\ \hline
 \end{tabular}
\end{center}
\end{table}
}


\begin{figure}
\begin{minipage}{1\hsize}
\begin{center}
(1) 評価用英語タームのうち$\phi^2$統計値の上位100ターム\\[-.3cm]
\epsfile{file=FIG/set1_context_phi2.ai,scale=1.0} \\

(2) $\phi^2$統計値の上位1000タームグループから無作為に評価用英語タームを
 100ターム選定\\[-.3cm]
\epsfile{file=FIG/set2_context_phi2.ai,scale=1.0} 
\end{center}
\caption{訳語対応推定手法の比較(サイトA，頻度10以上の評価用英語ターム)}
\label{fig:graph-cv-phi}
\end{minipage}
\end{figure}



\begin{figure}[t]
\begin{minipage}{1\hsize}
\begin{center}
\epsfile{file=FIG/yom_top100.ai,hscale=1.35,vscale=1.4} 

\epsfile{file=FIG/yom_1-015.ai,hscale=1.35,vscale=1.4} 

\epsfile{file=FIG/yom_015-007.ai,hscale=1.35,vscale=1.4} 
\end{center}
\caption{英語タームの頻度分布 及び $\phi^2統計値の分布$ごとの
        訳語対応推定性能(サイトA)}
\label{fig:graph-A}
\end{minipage}
\end{figure}

\begin{figure}[t]
\begin{minipage}{1\hsize}
\begin{center}
\epsfile{file=FIG/asahi_top100.ai,hscale=1.35,vscale=1.4} 

\epsfile{file=FIG/asahi_1-015.ai,hscale=1.35,vscale=1.4} 

\epsfile{file=FIG/asahi_015-007.ai,hscale=1.35,vscale=1.4} 
\end{center}
\caption{英語タームの頻度分布 及び $\phi^2統計値の分布$ごとの
        訳語対応推定性能(サイトB)}
\label{fig:graph-B}
\end{minipage}
\end{figure}

\begin{figure}[t]
\begin{minipage}{1\hsize}
\begin{center}
\epsfile{file=FIG/tbs_top100.ai,hscale=1.35,vscale=1.4} 

\epsfile{file=FIG/tbs_1-015.ai,hscale=1.35,vscale=1.4} 

\epsfile{file=FIG/tbs_015-007.ai,hscale=1.35,vscale=1.4} 
\end{center}
\caption{英語タームの頻度分布 及び $\phi^2統計値の分布$ごとの
        訳語対応推定性能(サイトC)}
\label{fig:graph-C}
\end{minipage}
\end{figure}




\subsection{訳語対応推定の性能}
\label{subsec:estm-eval}

\begin{table}

\begin{center}

 \caption{訳語対応推定例 ({\bf 太字: 正解訳語})}
 \label{tab:est}
\hspace*{.001cm}
{
  \begin{tabular}{|c||c|c|c|}
   \hline
   英語ターム & 順位  & 日本語訳語候補 & 訳語対応推定値 \\ \hline\hline
& 1 & 大阪高検 &       0.640 \\ \cline{2-4}
& 2 & 公安部長 &      0.450  \\ \cline{2-4}
  High Public Prosecutors Office 
& 2 & 三井環   &       0.450 \\ \cline{2-4}
& 4 & 登録免許税 &      0.360 \\ \cline{2-4}
& {\bf 5} & {\bf 高検} & {\bf 0.290} \\ \hline\hline
& {\bf 1} & {\bf 環境省} &   {\bf 0.542} \\ \cline{2-4}
  Environment Ministry 
& 2 & 国定公園 &  0.099 \\ \cline{2-4}
& 3 & 鳥獣保護 &  0.079 \\ \hline\hline
& 1 & 連行事件   &   0.521 \\ \cline{2-4}
& 2 & 中国・瀋陽 &       0.507 \\ \cline{2-4}
  Japanese Consulate General 
& 3 & 亡命者連行事件 &       0.497 \\ \cline{2-4}
& 4 & 亡命者 &   0.482 \\ \cline{2-4}
& 5 & 瀋陽 &     0.393 \\ \cline{2-4}
& {\bf 6} & {\bf 日本総領事館} &   {\bf 0.389} \\ \hline\hline
& 1 & 浄化装置 & 0.520 \\ \cline{2-4}
  diesel-powered vehicles 
& 2 & 粒子状物質 &  0.408 \\ \cline{2-4}
& {\bf 3} & {\bf ディーゼル車} &  {\bf 0.382} \\ \hline\hline
& {\bf 1} & {\bf 海上保安庁} & {\bf 0.503} \\ \cline{2-4}
  Japan Coast Guard 
& 2 & 巡視 & 0.394 \\ \cline{2-4}
& 3 & 海保 & 0.382 \\ \hline\hline
& 1 & ES細胞 &  0.500 \\ \cline{2-4}
  fertilized eggs 
& {\bf 2} & {\bf 受精卵} &  {\bf 0.333} \\ \cline{2-4}
& 2 & 不妊治療 & 0.333 \\ \hline\hline
& {\bf 1} & {\bf 東京地検} & 0.443 \\ \cline{2-4}
  Tokyo District Public Prosecutors Office 
& 2 & 東京地検特捜部 & 0.378 \\ \cline{2-4}
& 3 & 地検特捜部 & 0.343 \\ \hline\hline
& {\bf 1} & {\bf オウム真理教} & {\bf 0.467} \\ \cline{2-4}
  Aum Supreme Truth 
& 2 & 松本被告 & 0.432 \\ \cline{2-4}
& 3 & こと松本智津夫 & 0.410 \\ \hline\hline
& 1 & 知的財産 & 0.095 \\ \cline{2-4}
  intellectual property rights 
& {\bf 2} & {\bf 知的財産権} & {\bf 0.080} \\ \cline{2-4}
& 3 & 財産権 & 0.073 \\ \hline\hline
& 1 & 構造改革特区推進 & 0.457 \\ \cline{2-4}
  special structural reform zones 
& {\bf 2} & {\bf 構造改革特区} & {\bf 0.349} \\ \cline{2-4}
& 3 & 構造改革特区推進本部 & 0.321 \\ \hline
  \end{tabular}
}
\end{center}
\end{table}

\begin{table}
\begin{center}
 \caption{訳語候補順位付けの誤り原因の分析}
 \label{tab:wrong}
{
  \begin{tabular}{|c|c|c|c|c|c|}
   \hline
       &  &   & \multicolumn{3}{|c|}{誤り原因の内訳 (\%)}     \\ \cline{4-6}
サイト & 頻度  & 誤り数 &  \hspace*{.25cm}(1)\hspace*{.25cm}     
              & \hspace*{.25cm}(2)\hspace*{.25cm}  & \hspace*{.25cm}(3)\hspace*{.25cm}    \\ \hline\hline
       & 5$\sim$10  & 81 & 30       & 27    & 43       \\ \cline{2-6} 
A      & 10$\sim$20 & 78 & 37       & 47    & 16     \\ \cline{2-6} 
       & 20以上& 57 & 44            & 56    & 0       \\ \hline
       & 5$\sim$10  & 84 & 33       & 44    & 23      \\ \cline{2-6} 
B       & 10$\sim$20 & 78 & 23      & 59    & 18      \\ \cline{2-6} 
      & 20以上& 75 & 24             & 61    & 15       \\ \hline
  \end{tabular}
}
\end{center}
\end{table}

本節では，
前節で選定した各サイトの評価用英語タームについて，
訳語対応推定値の
上位$n$位以内に正解訳語(本論文の実験では，各英語タームにつき一つだけ)が
含まれる英語タームの割合をプロットすることにより，
訳語対応推定の性能を評価する．

まず，サイトAについて，頻度10以上の評価用英語タームを用いて
以下の二種類のタームセットを作成し，
\ref{subsec:estm-cont}~節の$\phi^2$統計を用いる方法と，
\ref{subsec:estm-cv}~節の文脈ベクトルを用いる方法を比較した．
\begin{enumerate}
\item[i)] 評価用英語タームのうち$\phi^2$統計値の上位100タームを
   集めたタームセット，
\item[ii)] $\phi^2$統計値の上位1000タームグループから無作為に評価用英語タームを
      100ターム選定して作成したタームセット．
\end{enumerate} 
セットi)の選定方法では$\phi^2$統計を用いる方法に有利になる
可能性があるため，別途，セットii)を用いた評価も行なった．
この結果を図~\ref{fig:graph-cv-phi}に示す．
この結果から分かるように，いずれのセットにおいても，
$\phi^2$統計を用いる方法の方が高い性能を示すことが分かる．

次に，サイトA，B，および，Cの各サイトについて，
表~\ref{tb:03}(b)の各タームセットに対する訳語対応推定性能を
評価した結果を図~\ref{fig:graph-A}$\sim$図~\ref{fig:graph-C}に示す．
ただし，「$\phi^2$統計値上位100」，
「$\phi^2統計値 1\sim0.15$」，
「$\phi^2統計値 0.15\sim0.07$」の各々の英語タームセットごとにプロットを
まとめた．
また，表~\ref{tab:ex}の評価用英語タームに対する
訳語対応推定結果の抜粋を表~\ref{tab:est}に示す．
表内の太字部分が正解日本語訳語である．

全体としては，英語タームの頻度が大きい方が，訳語対応推定の性能が高い．
ただし，「$\phi^2統計値 0.15\sim0.07$」では，英語タームの頻度分布の
違いの影響はかなり小さくなっている．
つまり，訳語対応推定値
($\phi^2統計値$)
が十分大きくなければ，
訳語対応推定の性能は，英語タームの頻度によらず，
ほぼ同等となると言える．

次に，訳語対応推定性能をサイト間で比較すると，
特に，サイトCは，サイトAおよびサイトBと比較して，
低頻度ターム(頻度5以上10未満)に対する訳語対応推定性能が低くなっている．
サイトCの場合，サイトAおよびサイトBと比較して，
報道記事の数が約10分の1と少ないために，英語記事に対応する関連日本語記事を
十分収集することができず，
結果的に正解訳語との共起頻度が小さくなってしまっていると考えられる．
また，サイトAとサイトBを比べると，$\phi^2$統計値の上位において，
頻度20以上のタームに対する訳語対応推定性能の差が顕著である．
この原因を分析するために，
次に，訳語対応推定値の一位が正解訳語とならない場合の誤りの内訳を調査した．
誤りの原因は主に次の三種類に分類される．
\begin{enumerate}
\item[(1)] 単語列として，正解訳語との間で包含関係にあるタームが同等もしくはそれ以上の
      
      訳語対応推定値を持つ．
      
\item[(2)] 報道記事中における関連タームが同等もしくは
      
      それ以上の訳語対応推定値を持つ．
\item[(3)] 正解訳語との共起頻度が小さい．
      
\end{enumerate}
(1)の例としては，表~\ref{tab:est}の
``High Public Prosecutors Office''の
「大阪高検」と{\bf 「高検」}，
``intellectual property rights''の「知的財産」
   と{\bf 「知的財産権」}，
``special structural reform zones''の
「構造改革特区推進」と{\bf 「構造改革特区」}
などがある．
(2)の例としては，
``Japanese Consulate General''の「連行事件」と
   {\bf 「日本総領事館」}，
``diesel-powered vehicles''の「浄化装置」と
{\bf 「ディーゼル車」}，
``fertilized eggs ''の「ES細胞」と{\bf 「受精卵」}
などがある．
また(3)は，関連記事対検索が失敗した場合や，
もともと日本語関連記事において正解訳語が出現しない場合に起こる．

さらに，サイトAおよびサイトBにおいて，
「$\phi^2$統計値上位100」のタームセットにおける頻度分布ごとに
誤り原因の内訳を求めた結果を表~\ref{tab:wrong}に示す．
両サイト間の最も顕著な違いとしては，
頻度20以上のタームセットにおいて，
「正解訳語との共起頻度が小さい」が占める割合の違いが挙げられる．
サイトAではこの割合が0\%となるのに対して，
サイトBではこの割合が15\%と大きい．
これは，サイトAとサイトBでは，特に，
日本語記事の文体等の特性が異なっており，
サイトBでは
日本語関連記事において正解訳語が出現しないということが
一定の割合で起こるためであると考えられる．




\section{関連研究}
\label{sec:related}

本節では，コーパスを用いて訳語対応等の翻訳知識を獲得する手法に関連する
研究のうち，
言語横断関連報道記事検索に関する関連研究，および，
訳語対応推定に関する関連研究について述べる．

\subsection{言語横断関連報道記事検索}

\ref{sec:clir}~節で述べた言語横断関連報道記事検索の手法に
関連する研究として，内容的に対応した二言語文書を収集する
手法に関する研究がいくつか行なわれている．
二言語文書の種類としては，同一の期間の報道記事を対象として，
内容が対応した二言語の記事を収集するという手法が
いくつか提案されている．
言語を横断して記事の内容の類似性を測定する手法を分類する観点としては，
主として，
i) 言語を横断する際に用いる対訳情報の情報源の種類，
ii) 記事間の類似度を測定する際に，文レベルの対応まで考慮するか否か，
という二点が挙げられる．
i)に関しては，
翻訳ソフト，既存の対訳辞書，あるいは，内容的に対応する既知の
二言語文書から学習した翻訳モデル，等の情報が用いられる．
また，ii)に関しては，
既存の多くの研究においては，文レベルの対応までは考慮せず，
文書全体での類似性を測定している．
そのような事例としては，
例えば，数値表現や名前等の訳語対応を情報源として
用いるもの~\cite{Takahashi97a,Xu99a}，
翻訳システムおよび会社名の対訳辞書を情報源として用いる
もの~\cite{KMatsumoto02a}，
翻訳システムおよび既存の対訳辞書を情報源として用い，
両者の性能比較を行なったもの~\cite{Collier98a}などがある．
また，\cite{Masuichi00a}は，特許文書を対象として，
小規模な対訳文書を初期データとして，
ブートストラップにより言語横断情報検索モデルを学習しながら，
内容的に対応する二言語文書を収集する手法を提案している．
一方，\cite{Hasan01a}は，日中二言語間で内容的に対応する
文書を収集するタスクにおいて，翻訳ソフトおよび漢字を利用した
いくつかの統計量を情報源として用いている．
以上の事例においては，いずれも，文レベルの対応までは考慮せず，
記事全体で類似性を測定している．
それに対して，
\cite{Uchiyama03aj}は，読売新聞およびThe Daily Yomiuriという，
完全な対訳に近い二言語文書対の収集がある程度期待できる文書集合を
対象として，既存の対訳辞書を情報源として，
記事中の文の対応まで考慮した日英記事間の類似度を用いて，
内容的に対応する記事を収集する手法を提案している．

これらの関連研究と比較すると，本論文で述べた
言語横断関連報道記事検索の手法は，
i)の，言語を横断する際に用いる対訳情報の情報源の種類に関しては，
\ref{sec:clir}~節で述べたように，翻訳ソフト，対訳辞書，
数値表現翻訳規則の三種類のうち，単独の情報源としては翻訳ソフトを
用いている．
また，ii)に関しては，文レベルの対応までは考慮せず，
記事全体で類似性を測定している．
したがって，本論文の言語横断関連報道記事検索の手法は，
既存の研究事例で用いられた手法と比較すると，
相対的に簡便な手法であると言える．
本論文における評価実験は，
言語横断関連報道記事検索の手法として，最も簡便な手法を採用した場合に，
どの程度の記事検索性能，および，訳語対応推定性能が達成できるかを
示しているということができる．
本論文の評価実験において，
関連研究で用いられた技術を導入すれば，
言語横断関連報道記事検索の性能が向上することが期待できる．
具体的には，
i)の，言語を横断する際に用いる対訳情報の情報源の種類に関しては，
複数の情報源を併用すること，
また，ii)に関しては，文レベルの対応まで考慮して記事間の類似度を
測定することが考えられる．
ただし，本論文の手法は，
厳密な文対応付けが困難であるような
粗い関連記事群に対しても有効であるという点が長所の一つであると言えるので，
ii)の点に関しては，綿密な分析が必要であると思われる．

また，その他の関連研究として，ウェブ上の二言語文書を対象として，
URLおよびHTML文書の構造における手がかりを利用することにより，
対訳で書かれた文書対を収集する手法も
提案されている~\cite{Resnik03a,Nie99a}．

\subsection{訳語対応推定}

二言語コーパスからの訳語対応推定の手法の研究においては，
これまでに，様々な手法が提案されている．
本節では，いくつかの観点からそれらの手法を整理するとともに，
同一内容の記事組を抽出した後，何らかの形で訳語の対応を推定するという
本論文の問題設定に比較的近い研究事例について，
本論文の手法との比較を行なう．
また，この本論文の問題設定とは独立な観点として，
訳語対応を推定する際にどのような情報を用いるかという観点のもとでの
整理を行ない，関連研究，および，本論文の手法の間の関係について述べる．

まず，訳語対応推定において用いる要素技術は，
大きく分けて，
文対応がつけられた対訳コーパスからの訳語対応推定手法，
および，
コンパラブルコーパスからの訳語対応推定手法という
二種類の技術に分けることができる．
文対応がつけられた対訳コーパスからの訳語対応推定においては，
訳語候補となる語の組に対して，分割表を用いて統計的な相関を測定する
という手法がよく知られている
\cite{Gale91a,Kumano94b,Haruno98dj,Smadja96a,Kitamura96a,Melamed00a}．
一方，コンパラブルコーパスからの訳語対応推定においては，
一般に，訳語候補となる語の組に対して，何らかの方法で文脈の類似性を測定し，
訳語候補の順位付けを行なう．
特に，初期の研究~\cite{Fung95b,Rapp95a}においては，
基本的な語についての既存の対訳辞書を用いずに，
文脈の類似性を測定することが試みられたが，
以後の研究
\cite{KTanaka96a,Fung98a,Rapp99a,Kaji01aj,Chiao02a,TTanaka02a,Gaussier04a}
では，基本的な語についての既存の対訳辞書を用いて，
文脈の類似性を測定している．
また，訳語対応推定の研究に関連した研究としては，
コンパラブルコーパスを用いて，複数の訳語を持つ語の訳語選択を
行なう手法を提案しているものもある~\cite{Dagan94c,HNakagawa01a}．

一方，比較的最近の研究においては，
要素技術としては，特に，コンパラブルコーパスからの訳語対応推定に
おいて用いられた，文脈の類似性に基づく手法を用いるものが多いが，
問題設定そのものとして，
1) ウェブ上のテキストを利用する，
2) 訳語候補の順位付けにおいて，複数の情報源・推定尺度を併用する，
といった点に重点を置いた研究事例がいくつかみられる．
例えば，ウェブ上のテキストを利用する研究事例としては，
ウェブ上で，他言語への翻訳が専門用語に併記されているページを利用して，
訳語対応を推定するもの~\cite{Nagata01a,Cheng04a}がある．
特に，\cite{Cheng04a}では，
英語タームを検索質問として，ウェブ上の中国語ページを収集した
結果から中国語訳語候補を生成し，
中国語訳語候補と英語タームとの間の統計的相関，および，
文脈ベクトルの類似性を併用して，英語・中国語間の訳語対応を
推定する手法を提案している．
また，\cite{Cao02a}では，基本語対訳辞書中の訳語の組合せにより，
複合語の訳語候補を生成し，
ウェブから訳語候補を検索したページから文脈ベクトルを生成して，
訳語対応を推定する手法を提案している．
また，通常の報道記事をコンパラブルコーパスとして訳語対応を推定する
手法の研究においても，
英語・中国語間の翻字の情報と文脈ベクトルの類似性を併用して訳語対応を
推定するもの\cite{Shao04a,Huang04a}などがある．

これらの最近の研究の他に，
本論文の問題設定に比較的近い研究事例としては，
\cite{Fung04a,Munteanu04a}がある．
これらにおいては，まず，
同時期の報道記事をコンパラブルコーパスとして，
同一内容の記事組を抽出し，その記事組から対訳文を抽出する．
そして，その結果から，統計的機械翻訳モデルを用いて訳語対応を推定する\cite{Fung04a}，
あるいは，統計的機械翻訳モデルの性能により，
対訳文の質を評価する\cite{Munteanu04a}，
といったことが行なわれる．
本論文の問題設定と比較すると，
これらの研究事例の問題設定は，
同一内容の記事組を抽出した後，何らかの形で訳語の対応を推定するという
処理を行なう点が類似していると言える．
ただし，最も重要な違いとして，これらの研究事例においては，
対訳文を抽出する過程を経る必要があるのに対して，
本論文の手法においては，
記事対応を粗く推定するだけで，訳語対応の推定が可能である点が
挙げられる．
したがって，本論文の手法は，厳密な文対応付けが困難であるような
粗い関連記事群に対しても有効であるという点が特徴であると言える．

また，上で述べた本論文の問題設定とは独立な観点として，
訳語対応を推定する際に用いる情報という観点から，
関連研究，および，本論文の手法の間の関係を整理することができる．
まず，本論文では，
訳語対応を推定する際に用いる情報としては，
「関連記事組における訳語候補の共起および分割表」
(\ref{subsec:estm-cont}~節)を用いた場合，
および，
「文脈の類似性」(\ref{subsec:estm-cv}~節)を用いた場合の
比較を行なった．
一方，本論文の評価実験で用いなかった情報としては，その他には，
複合語の構成要素の訳語対応~\cite{Cao02a,Yoshimi04aj}，
読み等を利用した翻字の情報~\cite{Shao04a,Huang04a,Yoshimi04aj}等がある．
さらに，これらの複数の情報を併用することにより，
訳語対応推定の性能が改善することが期待できる~\cite{Hino04aj,Yoshimi04aj}．


\section{おわりに}

本論文では，ウェブ上の報道記事のページから，
日本語で書かれた文書および英語で書かれた文書を収集し，
多種多様な分野について，
分野固有の
固有名詞(固有表現)や事象・言い回しなどの
翻訳知識を獲得する手法を提案した．
翻訳知識獲得においては，まず，
報道内容がほぼ同一もしくは密接に関連した日本語記事および英語記事を
検索する．
そして，関連記事組を用いて二言語間の訳語対応を推定する．
訳語対応を推定する尺度としては，
関連記事組における訳語候補の共起を利用する方法を適用し，
評価実験において文脈ベクトルを用いる方法と比較し，
この方法が有効であることを示した．
本論文では，特に，
日英関連報道記事からの訳語対応推定のタスクにおいて，
英語タームの出現頻度と，訳語対応推定性能の相関を評価し，
英語タームの頻度が大きいほど，
高い訳語対応推定性能が達成できることが分かった．

一方，この評価結果に関連して，特に，報道記事において
低頻度であるタームに対しては，
訳語対応推定の性能が低下することが分かっている~\cite{Hino04bj}．
本論文の評価実験において対象としたタームの種類数は高々数百個程度であるが，
報道記事に出現するターム全体で言えば，
出現頻度が数回程度のタームが相当数あると考えられる．
特に，実用的観点から言えば，これらの低頻度タームの訳語を
どのようにして獲得するか，という問題を解決することが重要である．
この点に関しては，報道記事における出現頻度が小さいタームについては，
ウェブ検索エンジンを用いて，ウェブ上での出現文書を収集し，
この文書を用いて訳語候補を順位付けることにより，
訳語対応推定の性能が改善できることが
分かっている~\cite{Utsuro04d,Kida04bj}．
また，訳語候補の順位付けにおいて，正解訳語を必ずしも一位に
順位付けすることができなくても，上位10位以内程度に正解訳語を含める
ことができれば，人間が訳語対応を発見する過程を比較的効率的に
支援できると考えられる．
この点に関しては，訳語対応推定の結果，および，各タームが出現する文書を
閲覧する機能を備えた訳語対応獲得支援
インタフェース~\cite{Utsuro02gs,Hino03aj}を援用できると考えている．
本論文で提案した技術を利用する局面としては，
直接的には，機械翻訳用の対訳辞書を強化することが挙げられるが，
その他に，例えば，言語横断情報検索において，
既存の対訳辞書や機械翻訳システムに未登録の訳語組を収集する場合や，
人間の翻訳者が必要とする翻訳知識を収集する場合などが考えられる．










\bibliographystyle{jnlpbbl}
\newcommand{\gengoshori}{}\newcommand{\kokuken}{}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Cao \BBA\ Li}{Cao \BBA\ Li}{2002}]{Cao02a}
Cao, Y.\BBACOMMA\  \BBA\ Li, H. \BBOP 2002\BBCP.
\newblock \BBOQ Base Noun Phrase Translation Using {Web} Data and the {EM}
  Algorithm\BBCQ\
\newblock In {\Bem Proceedings of the 19th {COLING}}, \BPGS\ 127--133.

\bibitem[\protect\BCAY{Cheng\JBA Lu\JBA Teng \BBA\ Chien}{Cheng
  et~al.}{2004}]{Cheng04a}
Cheng, P.-J.\JBA Lu, W.-H.\JBA Teng, J.-W.\JBA  \BBA\ Chien, L.-F. \BBOP
  2004\BBCP.
\newblock \BBOQ Creating Multilingual Translation Lexicons with Regional
  Variations Using {Web} Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 42nd {ACL}}, \BPGS\ 534--541.

\bibitem[\protect\BCAY{Chiao \BBA\ Zweigenbaum}{Chiao \BBA\
  Zweigenbaum}{2002}]{Chiao02a}
Chiao, Y.-C.\BBACOMMA\  \BBA\ Zweigenbaum, P. \BBOP 2002\BBCP.
\newblock \BBOQ Looking for Candidate Translational Equivalents in Specialized,
  Comparable Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 19th {COLING}}, \BPGS\ 1208--1212.

\bibitem[\protect\BCAY{Collier\JBA Hirakawa \BBA\ Kumano}{Collier
  et~al.}{1998}]{Collier98a}
Collier, N.\JBA Hirakawa, H.\JBA  \BBA\ Kumano, A. \BBOP 1998\BBCP.
\newblock \BBOQ Machine Translation vs. Dictionary Term Translation --- A
  Comparison for {English-Japanese} News Article Alignment\BBCQ\
\newblock In {\Bem Proceedings of the 17th {COLING} and the 36th Annual Meeting
  of {ACL}}, \BPGS\ 263--267.

\bibitem[\protect\BCAY{Dagan \BBA\ Itai}{Dagan \BBA\ Itai}{1994}]{Dagan94c}
Dagan, I.\BBACOMMA\  \BBA\ Itai, A. \BBOP 1994\BBCP.
\newblock \BBOQ Word Sense Disambiguation Using a Second Language Monolingual
  Corpus\BBCQ\
\newblock {\Bem {Computational Linguistics}}, {\Bbf 20}  (4), 563--596.

\bibitem[\protect\BCAY{Fung}{Fung}{1995}]{Fung95b}
Fung, P. \BBOP 1995\BBCP.
\newblock \BBOQ Compiling Bilingual Lexicon Entries From a Non-Parallel
  {English-Chinese} Corpus\BBCQ\
\newblock In {\Bem Proceedings of 3rd Workshop on Very Large Corpora}, \BPGS\
  173--183.

\bibitem[\protect\BCAY{Fung \BBA\ Cheung}{Fung \BBA\ Cheung}{2004}]{Fung04a}
Fung, P.\BBACOMMA\  \BBA\ Cheung, P. \BBOP 2004\BBCP.
\newblock \BBOQ Mining Very-Non-Parallel Corpora: Parallel Sentence and Lexicon
  Extraction via Bootstrapping and {EM}\BBCQ\
\newblock In {\Bem Proceedings of EMNLP}, \BPGS\ 57--63.

\bibitem[\protect\BCAY{Fung \BBA\ Yee}{Fung \BBA\ Yee}{1998}]{Fung98a}
Fung, P.\BBACOMMA\  \BBA\ Yee, L.~Y. \BBOP 1998\BBCP.
\newblock \BBOQ An {IR} Approach for Translating New Words from Nonparallel,
  Comparable Texts\BBCQ\
\newblock In {\Bem Proceedings of the 17th {COLING} and the 36th Annual Meeting
  of {ACL}}, \BPGS\ 414--420.

\bibitem[\protect\BCAY{Gale \BBA\ Church}{Gale \BBA\ Church}{1991}]{Gale91a}
Gale, W.\BBACOMMA\  \BBA\ Church, K. \BBOP 1991\BBCP.
\newblock \BBOQ Identifying Word Correspondences in Parallel Texts\BBCQ\
\newblock In {\Bem Proceedings of the 4th {DARPA Speech and Natural Language
  Workshop}}, \BPGS\ 152--157.

\bibitem[\protect\BCAY{Gaussier\JBA Renders\JBA Matveeva\JBA Goutte \BBA\
  Dejean}{Gaussier et~al.}{2004}]{Gaussier04a}
Gaussier, E.\JBA Renders, J.\JBA Matveeva, I.\JBA Goutte, C.\JBA  \BBA\ Dejean,
  H. \BBOP 2004\BBCP.
\newblock \BBOQ A Geometric View on Bilingual Lexicon Extraction from
  Comparable Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 42nd {ACL}}, \BPGS\ 526--533.

\bibitem[\protect\BCAY{浜本\JBA 中山\JBA 日野\JBA 堀内\JBA 宇津呂}{浜本\Jetal
  }{2003}]{Hamamoto03aj}
浜本武\JBA 中山健明\JBA 日野浩平\JBA 堀内貴司\JBA  宇津呂武仁 \BBOP 2003\BBCP.
\newblock \JBOQ 言語横断関連報道記事検索における
  翻訳ソフト・対訳辞書・数値表現翻訳規則の性能比較\JBCQ\
\newblock \Jem{言語処理学会第9回年次大会論文集}, \BPGS\ 425--428.

\bibitem[\protect\BCAY{Haruno \BBA\ Ikehara}{Haruno \BBA\
  Ikehara}{1998}]{Haruno98dj}
Haruno, M.\BBACOMMA\  \BBA\ Ikehara, S. \BBOP 1998\BBCP.
\newblock \BBOQ Two-Step Extraction of Bilingual Collocations by Using
  Word-Level Sorting\BBCQ\
\newblock \Jem{電子情報通信学会論文誌}, {\Bbf E81-D}  (10), 1103--1110.

\bibitem[\protect\BCAY{Hasan \BBA\ Matsumoto}{Hasan \BBA\
  Matsumoto}{2001}]{Hasan01a}
Hasan, M.~M.\BBACOMMA\  \BBA\ Matsumoto, Y. \BBOP 2001\BBCP.
\newblock \BBOQ Multilingual Document Alignment --- A Study with {Chinese} and
  {Japanese}\BBCQ\
\newblock In {\Bem Proceedings of the 6th NLPRS}, \BPGS\ 617--623.

\bibitem[\protect\BCAY{日野\JBA 堀内\JBA 浜本\JBA 中山\JBA 宇津呂}{日野\Jetal
  }{2003}]{Hino03aj}
日野浩平\JBA 堀内貴司\JBA 浜本武\JBA 中山健明\JBA  宇津呂武仁 \BBOP 2003\BBCP.
\newblock \JBOQ
  日英関連報道記事からの翻訳知識獲得のためのユーザインタフェースの作成\JBCQ\
\newblock \Jem{言語処理学会第9回年次大会論文集}, \BPGS\ 421--424.

\bibitem[\protect\BCAY{日野\JBA 宇津呂\JBA 中川}{日野\Jetal }{2004a}]{Hino04bj}
日野浩平\JBA 宇津呂武仁\JBA  中川聖一 \BBOP 2004a\BBCP.
\newblock \JBOQ
  日英報道記事からの訳語対応推定：ターム頻度と訳語対応推定性能の相関の評価\JBCQ\
\newblock \Jem{情報処理学会研究報告}, {\Bbf 2004}  ((2004--NL--162)), 57--63.

\bibitem[\protect\BCAY{日野\JBA 宇津呂\JBA 中川}{日野\Jetal }{2004b}]{Hino04aj}
日野浩平\JBA 宇津呂武仁\JBA  中川聖一 \BBOP 2004b\BBCP.
\newblock \JBOQ
  日英報道記事からの訳語対応推定における複数の推定尺度の利用\JBCQ\
\newblock \Jem{言語処理学会第10回年次大会論文集}, \BPGS\ 249--252.

\bibitem[\protect\BCAY{堀内\JBA 千葉\JBA 浜本\JBA 宇津呂}{堀内\Jetal
  }{2002a}]{Horiuchi02bj}
堀内貴司\JBA 千葉靖伸\JBA 浜本武\JBA  宇津呂武仁 \BBOP 2002a\BBCP.
\newblock \JBOQ
  言語横断検索により自動収集された日英関連報道記事からの訳語対応の獲得\JBCQ\
\newblock \Jem{情報処理学会研究報告}, {\Bbf 2002}  ((2002--NL--150)), 191--198.

\bibitem[\protect\BCAY{堀内\JBA 千葉\JBA 浜本\JBA 宇津呂}{堀内\Jetal
  }{2002b}]{Horiuchi02aj}
堀内貴司\JBA 千葉靖伸\JBA 浜本武\JBA  宇津呂武仁 \BBOP 2002b\BBCP.
\newblock \JBOQ 翻訳知識獲得のための言語横断関連報道記事検索\JBCQ\
\newblock \Jem{言語処理学会第8回年次大会論文集}, \BPGS\ 303--306.

\bibitem[\protect\BCAY{堀内\JBA 日野\JBA 浜本\JBA 中山\JBA 宇津呂}{堀内\Jetal
  }{2003}]{Horiuchi03aj}
堀内貴司\JBA 日野浩平\JBA 浜本武\JBA 中山健明\JBA  宇津呂武仁 \BBOP 2003\BBCP.
\newblock \JBOQ
  日英報道記事からの訳語対獲得における言語横断情報検索の有効性の評価\JBCQ\
\newblock \Jem{言語処理学会第9回年次大会論文集}, \BPGS\ 341--344.

\bibitem[\protect\BCAY{Huang\JBA Vogel \BBA\ Waibel}{Huang
  et~al.}{2004}]{Huang04a}
Huang, F.\JBA Vogel, S.\JBA  \BBA\ Waibel, A. \BBOP 2004\BBCP.
\newblock \BBOQ Improving Named Entity Translation Combining Phonetic and
  Semantic Similarities\BBCQ\
\newblock In {\Bem Proceedings of HLT-NAACL}, \BPGS\ 281--288.

\bibitem[\protect\BCAY{梶\JBA 相薗}{梶\JBA 相薗}{2001}]{Kaji01aj}
梶博行\JBA  相薗敏子 \BBOP 2001\BBCP.
\newblock \JBOQ 共起集合の類似度に基づく対訳コーパスからの対訳語抽出\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 42}  (9), 2248--2258.

\bibitem[\protect\BCAY{木田\JBA 宇津呂\JBA 日野\JBA 佐藤}{木田\Jetal
  }{2004}]{Kida04bj}
木田充洋\JBA 宇津呂武仁\JBA 日野浩平\JBA  佐藤理史 \BBOP 2004\BBCP.
\newblock \JBOQ 日英二言語文書を用いた訳語対応推定:
  ウェブ上の非対訳文書を用いた訳語候補順位付け\JBCQ\
\newblock \Jem{情報処理学会研究報告}, {\Bbf 2004}  ((2004--NL--162)), 65--70.

\bibitem[\protect\BCAY{Kitamura \BBA\ Matsumoto}{Kitamura \BBA\
  Matsumoto}{1996}]{Kitamura96a}
Kitamura, M.\BBACOMMA\  \BBA\ Matsumoto, Y. \BBOP 1996\BBCP.
\newblock \BBOQ Automatic Extraction of Word Sequence Correspondences in
  Parallel Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 4th Workshop on Very Large Corpora},
  \BPGS\ 79--87.

\bibitem[\protect\BCAY{Kumano \BBA\ Hirakawa}{Kumano \BBA\
  Hirakawa}{1994}]{Kumano94b}
Kumano, A.\BBACOMMA\  \BBA\ Hirakawa, H. \BBOP 1994\BBCP.
\newblock \BBOQ Building an {MT} Dictionary from Parallel Texts based on
  Linguistic and Statistical Information\BBCQ\
\newblock In {\Bem Proceedings of the 15th {COLING}}, \BPGS\ 76--81.

\bibitem[\protect\BCAY{Masuichi\JBA Flournoy\JBA Kaufmann \BBA\
  Peters}{Masuichi et~al.}{2000}]{Masuichi00a}
Masuichi, H.\JBA Flournoy, R.\JBA Kaufmann, S.\JBA  \BBA\ Peters, S. \BBOP
  2000\BBCP.
\newblock \BBOQ A Bootstrapping Method for Extracting Bilingual Text
  Pairs\BBCQ\
\newblock In {\Bem Proceedings of the 18th {COLING}}, \BPGS\ 1066--1070.

\bibitem[\protect\BCAY{Matsumoto \BBA\ Tanaka}{Matsumoto \BBA\
  Tanaka}{2002}]{KMatsumoto02a}
Matsumoto, K.\BBACOMMA\  \BBA\ Tanaka, H. \BBOP 2002\BBCP.
\newblock \BBOQ Automatic Alignment of {Japanese} and {English} Newspaper
  Articles using an {MT} System and a Bilingual Company Name Dictionary\BBCQ\
\newblock In {\Bem Proceedings of the 3rd International Conference on Language
  Resources and Evaluation}, \lowercase{\BVOL}~2, \BPGS\ 480--484.

\bibitem[\protect\BCAY{Matsumoto \BBA\ Utsuro}{Matsumoto \BBA\
  Utsuro}{2000}]{Matsumoto00a}
Matsumoto, Y.\BBACOMMA\  \BBA\ Utsuro, T. \BBOP 2000\BBCP.
\newblock \BBOQ Lexical Knowledge Acquisition\BBCQ\
\newblock In Dale, R.\JBA Moisl, H.\JBA  \BBA\ Somers, H.\BEDS, {\Bem {\em
  Handbook of Natural Language Processing}}, \BCH~24, \BPGS\ 563--610. Marcel
  Dekker Inc.

\bibitem[\protect\BCAY{Melamed}{Melamed}{2000}]{Melamed00a}
Melamed, I.~D. \BBOP 2000\BBCP.
\newblock \BBOQ Models of Translational Equivalence among Words\BBCQ\
\newblock {\Bem {Computational Linguistics}}, {\Bbf 26}  (2), 221--249.

\bibitem[\protect\BCAY{Munteanu\JBA Fraser \BBA\ Marcu}{Munteanu
  et~al.}{2004}]{Munteanu04a}
Munteanu, D.~S.\JBA Fraser, A.\JBA  \BBA\ Marcu, D. \BBOP 2004\BBCP.
\newblock \BBOQ Improved Machine Translation Performance via Parallel Sentence
  Extraction from Comparable Corpora\BBCQ\
\newblock In {\Bem Proceedings of HLT-NAACL}, \BPGS\ 265--272.

\bibitem[\protect\BCAY{Nagata\JBA Saito \BBA\ Suzuki}{Nagata
  et~al.}{2001}]{Nagata01a}
Nagata, M.\JBA Saito, T.\JBA  \BBA\ Suzuki, K. \BBOP 2001\BBCP.
\newblock \BBOQ Using the {Web} as a Bilingual Dictionary\BBCQ\
\newblock In {\Bem Proceedings of the ACL-2001 Workshop on Data-driven Methods
  in Machine Translation}, \BPGS\ 95--102.

\bibitem[\protect\BCAY{Nakagawa}{Nakagawa}{2001}]{HNakagawa01a}
Nakagawa, H. \BBOP 2001\BBCP.
\newblock \BBOQ Disambiguation of Single Noun Translations Extracted from
  Bilingual Comparable Corpora\BBCQ\
\newblock {\Bem Terminology}, {\Bbf 7}  (1), 63--83.

\bibitem[\protect\BCAY{Nie\JBA Simard\JBA Isabelle \BBA\ Durand}{Nie
  et~al.}{1999}]{Nie99a}
Nie, J.-Y.\JBA Simard, M.\JBA Isabelle, P.\JBA  \BBA\ Durand, R. \BBOP
  1999\BBCP.
\newblock \BBOQ Cross-Language Information Retrieval based on Parallel Texts
  and Automatic Mining of Parallel Texts from the {Web}\BBCQ\
\newblock In {\Bem Proceedings of the 22nd SIGIR}, \BPGS\ 74--81.

\bibitem[\protect\BCAY{Pei\JBA Han\JBA Mortazavi-Asl \BBA\ Pinto}{Pei
  et~al.}{2001}]{Pei01a}
Pei, J.\JBA Han, J.\JBA Mortazavi-Asl, B.\JBA  \BBA\ Pinto, H. \BBOP 2001\BBCP.
\newblock \BBOQ PrefixSpan: Mining Sequential Patterns Efficiently by
  Prefix-Projected Pattern Growth\BBCQ\
\newblock In {\Bem Proceedings of the 17th International Conference on Data
  Mining}, \BPGS\ 215--224.

\bibitem[\protect\BCAY{Rapp}{Rapp}{1995}]{Rapp95a}
Rapp, R. \BBOP 1995\BBCP.
\newblock \BBOQ Identifying Word Translations in Non-Parallel Texts\BBCQ\
\newblock In {\Bem Proceedings of the 33rd Annual Meeting of {ACL}}, \BPGS\
  320--322.

\bibitem[\protect\BCAY{Rapp}{Rapp}{1999}]{Rapp99a}
Rapp, R. \BBOP 1999\BBCP.
\newblock \BBOQ Automatic Identification of Word Translations from Unrelated
  {English} and {German} Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 37th Annual Meeting of {ACL}}, \BPGS\
  519--526.

\bibitem[\protect\BCAY{Resnik \BBA\ Smith}{Resnik \BBA\
  Smith}{2003}]{Resnik03a}
Resnik, P.\BBACOMMA\  \BBA\ Smith, N. \BBOP 2003\BBCP.
\newblock \BBOQ The {Web} as a Parallel Corpus\BBCQ\
\newblock {\Bem {Computational Linguistics}}, {\Bbf 29}  (3), 349--380.

\bibitem[\protect\BCAY{Shao \BBA\ Ng}{Shao \BBA\ Ng}{2004}]{Shao04a}
Shao, L.\BBACOMMA\  \BBA\ Ng, H.~T. \BBOP 2004\BBCP.
\newblock \BBOQ Mining New Word Translations from Comparable Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 20th {COLING}}, \BPGS\ 618--624.

\bibitem[\protect\BCAY{Smadja\JBA McKeown \BBA\ Hatzivassiloglou}{Smadja
  et~al.}{1996}]{Smadja96a}
Smadja, F.\JBA McKeown, K.~R.\JBA  \BBA\ Hatzivassiloglou, V. \BBOP 1996\BBCP.
\newblock \BBOQ Translating Collocations for Bilingual Lexicons: A Statistical
  Approach\BBCQ\
\newblock {\Bem {Computational Linguistics}}, {\Bbf 22}  (1), 1--38.

\bibitem[\protect\BCAY{Takahashi\JBA Shirai \BBA\ Bond}{Takahashi
  et~al.}{1997}]{Takahashi97a}
Takahashi, Y.\JBA Shirai, S.\JBA  \BBA\ Bond, F. \BBOP 1997\BBCP.
\newblock \BBOQ A Method of Automatically Aligning {Japanese} and {English}
  Newspaper Articles\BBCQ\
\newblock In {\Bem Proceedings of the 4th NLPRS}, \BPGS\ 657--660.

\bibitem[\protect\BCAY{Tanaka \BBA\ Iwasaki}{Tanaka \BBA\
  Iwasaki}{1996}]{KTanaka96a}
Tanaka, K.\BBACOMMA\  \BBA\ Iwasaki, H. \BBOP 1996\BBCP.
\newblock \BBOQ Extraction of Lexical Translations from Non-Aligned
  Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 16th {COLING}}, \BPGS\ 580--585.

\bibitem[\protect\BCAY{Tanaka}{Tanaka}{2002}]{TTanaka02a}
Tanaka, T. \BBOP 2002\BBCP.
\newblock \BBOQ Measuring the Similarity between Compound Nouns in Different
  Languages Using Non-Parallel Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 19th {COLING}}, \BPGS\ 981--987.

\bibitem[\protect\BCAY{内山\JBA 井佐原}{内山\JBA 井佐原}{2003}]{Uchiyama03aj}
内山将夫\JBA  井佐原均 \BBOP 2003\BBCP.
\newblock \JBOQ 日英新聞の記事および文を対応付けるための高信頼性尺度\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 10}  (4), 201--220.

\bibitem[\protect\BCAY{Utsuro\JBA Horiuchi\JBA Chiba \BBA\ Hamamoto}{Utsuro
  et~al.}{2002}]{Utsuro02gs}
Utsuro, T.\JBA Horiuchi, T.\JBA Chiba, Y.\JBA  \BBA\ Hamamoto, T. \BBOP
  2002\BBCP.
\newblock \BBOQ Semi-automatic Compilation of Bilingual Lexicon Entries from
  Cross-Lingually Relevant News Articles on {WWW} News Sites\BBCQ\
\newblock In Richardson, S.~D.\BED, {\Bem Machine Translation: From Research to
  Real Users}, Lecture Notes in Artificial Intelligence: Vol. 2499, \BPGS\
  165--176. Springer.

\bibitem[\protect\BCAY{Utsuro\JBA Horiuchi\JBA Hamamoto\JBA Hino \BBA\
  Nakayama}{Utsuro et~al.}{2003}]{Utsuro03b}
Utsuro, T.\JBA Horiuchi, T.\JBA Hamamoto, T.\JBA Hino, K.\JBA  \BBA\ Nakayama,
  T. \BBOP 2003\BBCP.
\newblock \BBOQ Effect of Cross-Language {IR} in Bilingual Lexicon Acquisition
  from Comparable Corpora\BBCQ\
\newblock In {\Bem Proceedings of the 10th {EACL}}, \BPGS\ 355--362.

\bibitem[\protect\BCAY{Utsuro\JBA Hino\JBA Kida\JBA Nakagawa \BBA\ Sato}{Utsuro
  et~al.}{2004}]{Utsuro04d}
Utsuro, T.\JBA Hino, K.\JBA Kida, M.\JBA Nakagawa, S.\JBA  \BBA\ Sato, S. \BBOP
  2004\BBCP.
\newblock \BBOQ Integrating Cross-Lingually Relevant News Articles and
  Monolingual {Web} Documents in Bilingual Lexicon Acquisition\BBCQ\
\newblock In {\Bem Proceedings of the 20th {COLING}}, \BPGS\ 1036--1042.

\bibitem[\protect\BCAY{Xu \BBA\ Tan}{Xu \BBA\ Tan}{1999}]{Xu99a}
Xu, D.\BBACOMMA\  \BBA\ Tan, C.~L. \BBOP 1999\BBCP.
\newblock \BBOQ Alignment and Matching of Bilingual {English-Chinese} News
  Texts\BBCQ\
\newblock {\Bem Machine Translation}, {\Bbf 14}, 1--33.

\bibitem[\protect\BCAY{吉見\JBA 九津見\JBA 小谷\JBA 佐田\JBA 井佐原}{吉見\Jetal
  }{2004}]{Yoshimi04aj}
吉見毅彦\JBA 九津見毅\JBA 小谷克則\JBA 佐田いち子\JBA  井佐原均 \BBOP
  2004\BBCP.
\newblock \JBOQ 複合語の内部情報・外部情報を統合的に利用した訳語対の抽出\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 11}  (4), 89--103.

\end{thebibliography}


\begin{biography}
\biotitle{略歴}
\bioauthor{宇津呂 武仁}
{1989年京都大学工学部 電気工学第二学科 卒業．
1994年同大学大学院工学研究科 博士課程電気工学第二専攻 修了．
京都大学博士(工学)．
奈良先端科学技術大学院大学情報科学研究科助手，
豊橋技術科学大学工学部情報工学系講師を経て，
2003年より 京都大学 情報学研究科 知能情報学専攻 講師．
自然言語処理の研究に従事．
}
\bioauthor{日野 浩平}
{2003年豊橋技術科学大学 工学部 情報工学系卒業．
2005年 同大学大学院工学研究科修士課程 情報工学専攻修了．
現在，NTTデータテクノロジー株式会社に勤務．
在学中は自然言語処理に関する研究に従事．
}
\bioauthor{堀内 貴司}
{2001年豊橋技術科学大学 工学部 情報工学系卒業．
2003年 同大学大学院工学研究科修士課程 情報工学専攻修了．
現在，日立製作所に勤務．
在学中は自然言語処理に関する研究に従事．
}
\bioauthor{中川 聖一}
{
1976年 京都大学大学院工学研究科博士課程修了．
同年京都大学工学部 情報工学科 助手．
1980年 豊橋技術科学大学工学部情報工学系講師．
1990年 同教授．
1985$\sim$1986年 カーネギーメロン大学客員研究員．
音声言語情報処理，自然言語処理，人工知能の研究に従事．工学博士．
1977年 電子通信学会論文賞，1998年度IETE最優秀論文賞，
2001年 電子情報通信学会論文賞受賞．
著書「確率モデルによる音声認識」（電子情報通信学会編），
「音声・聴覚と神経回路網モデル」（共著，オーム社），
「情報理論の基礎と応用」（近代科学社），「パターン情報処理 」（丸善）など．
}

\bioreceived{受付}
\biorevised{再受付}
\biorevised{再々受付}
\bioaccepted{採録}

\end{biography}

\end{document}
