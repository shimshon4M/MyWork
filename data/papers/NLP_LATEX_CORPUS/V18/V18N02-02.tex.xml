<?xml version="1.0" ?>
<root>
  <jtitle>集合間類似度に対する簡潔かつ高速な	類似文字列検索アルゴリズム</jtitle>
  <jauthor>岡崎直観辻井潤一</jauthor>
  <jabstract>本論文では，コサイン係数，ダイス係数，ジャッカード係数，オーバーラップ係数に対し，簡潔かつ高速な類似文字列検索アルゴリズムを提案する．本論文では，文字列を任意の特徴（tri-gramなど）の集合で表現し，類似文字列検索における必要十分条件及び必要条件を導出する．そして，類似文字列検索が転置リストにおけるオーバーラップ問題として正確に解けることを示す．次に，オーバーラップ問題の効率的な解法として，CPMergeアルゴリズムを提案する．CPMergeは，検索クエリ文字列中のシグニチャと呼ばれる特徴と，解候補が枝刈りできる条件に着目し，オーバーラップ問題の解候補を絞り込む．さらに，CPMergeアルゴリズムの実装上の工夫について言及する．英語の人名，日本語の単語，生命医学分野の固有表現の3つの大規模文字列データセットを用い，類似文字列検索の性能を評価する．実験では，類似文字列検索の最近の手法であるLocalitySensitiveHashingやDivideSkip等と提案手法を比較し，提案手法が全てのデータセットにおいて，最も高速かつ正確に文字列を検索できることを実証する．また，提案手法による類似文字列検索が高速になる要因について，分析を行う．なお，提案手法をライブラリとして実装したものは，SimStringとしてオープンソースライセンスで公開している．</jabstract>
  <jkeywords>類似文字列検索，集合間類似度，転置リスト，オーバーラップ問題</jkeywords>
  <subsection title="オーバーラップ問題のアルゴリズム">節では，特徴をキーとして，その特徴を含む文字列(SID)のリストを返す転置インデックスを構築した．特徴qの転置リストに含まれている文字列は，特徴qを含むことが保証されている．したがって，特徴qXに対応する|X|個の転置リストの中で，ある文字列yがc個の転置リスト2回出現するならば，|XY|=cである．ゆえに，転置リスト上において回以上出現するSIDを見つけることで，オーバーラップ問題を解くことができる．図に，このアイディアに基づくオーバーラップ問題の解法（AllScanアルゴリズム）を示した．4行目の関数(d,q)は，転置インデックスdの中で特徴qに対応する転置リスト（SIDのリスト）を返す関数である．この擬似コードは，転置インデックスd，特徴集合X，最小オーバーラップ数を受け取り，SIDの出現頻度，すなわち|XY|を連想配列Mに格納し，その値がに到達したSIDをリストRに入れて返すものである．表は，検索クエリ文字列x=に対して，Web日本語Nグラムコーパスのユニグラムの中で，文字数が7（つまり|Y|=9）の文字列を実際に検索するとき，|XY|の高い文字列10件を示したものである（文字列の特徴はtri-gramで表現）．コサイン係数が0.7以上の文字列を探すには，=|X||Y|=6であるから，類似文字列検索の解は「スパッゲティー」「スパゲティーニ」「スパゲティー・」「スパゲッティー」の4つである．AllScanアルゴリズムの実装は簡単であるが，検索に用いる特徴が数多くの文字列に出現するとき，走査するSIDの数が非常に大きくなるという欠点がある．例えば，`ティー'（「ティー」を含む）や`ー＄＄'（「ー」で終わる）などの文字tri-gramは，日本語の多くの語で出現するため，転置リストが大きくなる傾向にある．表に，Web日本語Nグラムコーパスにおいて，「スパゲティー」の各tri-gramの転置リストのサイズ（すなわち，各tri-gramを含む文字列の数）を示した．この表によると，AllScanアルゴリズムは30,584種類，35,964個のSIDを走査することになるが，その中でたった4個(0.013%)しか解にならない．走査すべきSIDの数を減らすため，オーバーラップ問題に関する次の性質に着目する~．要素数がkの集合Xと，要素数が任意の集合Yがある．要素数が(k-+1)となる任意の部分集合ZXを考える．もし，|XY|ならば，ZYである．propertyこの性質は，その対偶を考えれば明白である．すなわち，ZY=ならば，Zの定義から|XZ|=k-(k-+1)=-1であるので，|XY|=|(XZ)ZY|=|(XZ)Y|+|ZY|-1．ゆえに，|XY|&lt;が示される．性質の利用例を，先の類似文字列検索を用いて説明する．検索クエリ文字列x=「スパゲティー」に対し，|Y|=9かつ，=6|XY|という条件を満たす文字列yを検索している．検索される文字列yが|XY|6を満たすならば，特徴集合X中の任意の(8-6+1)=3要素で構成された任意の部分集合ZXに対し，ZYである．言い換えれば，特徴集合X中の任意の3要素を選ぶと，対応する転置リストに，類似文字列検索の解が（あるとすれば）必ず含まれている．この性質を用いると，類似文字列検索の解の候補を絞り込むことができる．解候補を生成するために用いる要素は，シグニチャ~と呼ばれる．では，検索文字列の特徴集合の中で，どの要素をシグニチャとして採用すれば良いのだろうか？シグニチャの特徴数は性質から決定されるが，その選び方は任意である．したがって，転置リストのサイズが小さい特徴をシグニチャとして採用すれば，解候補生成時に走査するSIDの数を減らすことができる．すなわち，文字列データベース中で稀に出現するtri-gramを優先的にシグニチャとして採用し，解の候補を絞り込めばよい．表の例では，「パゲテ」「ゲティ」「スパゲ」をシグニチャとして選択することになる．シグニチャによる解候補生成を採用したアルゴリズムを，図に示す．性質より，特徴集合Xを，要素数(|X|-+1)のシグニチャSと，残りL(=XS)に分解する．このアルゴリズムは，2から7行目で類似文字列検索の解候補をシグニチャSから獲得し，8行目から21行目で解候補の検証と枝刈りをLで行う．このアルゴリズムは，解候補の生成と枝刈りをしながら転置リストをマージしていくので，CPMergeアルゴリズムと命名した．1行目で，検索文字列の特徴集合の要素を，転置リストのサイズ（要素数）の昇順に並び替える．このとき，X[k]の転置リストの内容をすべてメモリに読み込まなくても，|(d,X[k])|の値を取得し，Xの要素を並び替えられるようにしておくことは，実用上重要である（この理由は節で明らかになる）．特徴集合Xの要素を並び替えたとき，稀な特徴の順番にX[0],,X[|X|-1]とアクセスできるものとする．シグニチャSとして採用されるのは，X[0],,X[|X|-+1]である．アルゴリズムの2から7行目では，シグニチャの特徴を持つ文字列をデータベースdから検索し，その転置リストにおける出現回数を連想配列Mに記録する．先の例と同じ類似文字列検索（x=，|Y|=9，=6|XY|）に対して，CPMergeアルゴリズムの動作例を表に示した．候補生成フェーズでは，「パゲテ」「ゲティ」「スパゲ」のtri-gramを含む文字列を検索し，検索された文字列を解候補とするとともに，該当する箇所に「○」を記している．シグニチャから獲得される解候補の数は32で，AllScanアルゴリズムと比べると，解候補数を0.105%まで絞り込んだことになる．アルゴリズムの9行目から21行目では，それぞれの候補文字列が，残りの特徴Lを持っているかどうかを調べる．それぞれの解候補iMが（10行目），特徴X[k]を持っているかどうかを，転置リスト(d,X[k])上における二分探索で調べ（11行目），転置リストがiを含んでいれば，頻度カウンタをインクリメントする（12行目）．もし，頻度カウントがに到達したら（14行目），iを結果リストRに追加し（15行目），候補Mから削除する（16行目）．もし，頻度カウントがに到達していない場合は，以下の性質を利用して枝刈りの可能性を調べる．要素数がgの集合Xと，要素数が任意の集合Yがある．要素数がhのある部分集合ZXを考える．もし，|ZY|=ならば，|XY|+g-hである．propertyZの定義により|XZ|=g-hであるから，|(XZ)Y|g-h．したがって，この性質は|XY|の上限値が(+g-h)になることを表現している．図のアルゴリズムでは，=M[i]，g=|X|，h=(k+1)とおき，|XY|の上限値を(M[i]-|X|-k-1)と計算し，この値がを下回っているならば（17行目），候補iを枝刈りする（18行目）．表は，検証フェーズ(3k7)の動作例も示している．k=3では，32個の候補文字列のそれぞれに対して，414個のSIDを含む転置リスト上で二分探索を行い，「＄スパ」というtri-gramを含むかどうか調べている．候補文字列が特徴を含む場合は「○」，含まない場合は「×」が記される．もし，候補文字列が「＄スパ」というtri-gramを含んでおらず，これまでの出現頻度が1回だった場合は，今後4k7の全ての転置リストに出現しても，出現頻度の最大値は5に留まる．つまり，|XY|&lt;6となることが確定しているので，「アニスパゲス」「イカスバゲティ」などの文字列は，k=3において枝刈りする．表では，枝刈りされる候補に「×.」を記している．枝刈りにより，k=3において15個の解候補が枝刈りされ，候補は17文字列に減る．k=4,5でも同様の処理を行い，解の候補はそれぞれ8個，5個まで絞り込まれる．k=6では，「スパゲティー・」と「スパゲティーニ」の出現回数が6に到達するので，候補集合から解集合に移動させる（1.7.で表示）．k=7では，「スパゲッティー」と「スパッゲティー」の出現回数が6に到達し，全ての候補の検証が終了したことになる．CPMergeアルゴリズムにおいて，X[k]の転置リストを処理した後に残る解候補の数をC_k，X[k]の転置リストの要素数をP_k=|(d,X[k])|とする．CPMergeの検証フェーズでは，それぞれの候補に対して二分探索を行うため，9行目の各kに対して，10〜20行目の計算量はO(C_k-1P_k)である．X[k]の並び順の定義から，kが大きくなるとP_kも増加するが，枝刈りが有効に働けば，C_kが小さくなる．表の例では，各kに対してC_k-1P_kの値は，193(k=3)，115(k=4)，57.5(k=5)，45.1(k=6)，20.2(k=7)であり，9〜21行目のループが進むにつれて，計算量の見積りが減少する．検索クエリ文字列やデータベースの文字列集合のtri-gramの分布により，C_kやP_kの傾向が異なるので，計算量の見積りを一般的に行うことは難しい．そこで，第節では，CPMergeアルゴリズムが実際のデータセットに対して動作する際の，解の候補数，転置リストに含まれるSIDの数などの統計情報を報告する．</subsection>
  <section title="はじめに">知的で高度な言語処理を実現するには，辞書，シソーラス，コーパスなどの言語資源の整備・構築が欠かせない．一方，実際のテキストに対して，言語資源を活用するときにボトルネックとなるのが，表層表現が実テキストと言語資源では一致しない問題である．例えば，「スパゲティー」には，「スパゲッティ」「スパゲティ」「スパゲッテー」などの異表記があるが，完全一致の文字列マッチングでは，これらの異表記から言語資源に含まれるエントリ（例えば「スパゲティー」）を引き出すことができない．ウェブなどの大規模かつ統制されていないテキストには，大量の異表記や表記誤りが含まれると考えられ，これらの実テキストに対して言語処理を頑健に適用するには，言語資源とテキストを柔軟にマッチングさせる技術が必要である．文字列を標準的な表記に変換してからマッチングさせる手法として，ステミング~，レマタイゼーション~，スペル訂正~，人名表記の照合~，カタカナ異表記の生成及び統一~，等が代表的である．これらの研究に共通するのは，与えられた文字列から標準形に変換するための文字列書き換え規則を，人手，マイニング，もしくは機械学習で獲得していることである．これらの研究では，語幹やカタカナ異表記など，異表記のタイプに特化した文字列書き換え規則を獲得することに，重点が置かれる．本論文では，より一般的なタスク設定として，与えられた文字列に似ている文字列を，データベースの中から見つけ出すタスク（類似文字列検索）を考える．本論文では，「文字列の集合Vの中で，検索クエリ文字列xと類似度が以上の文字列を全て見つけ出す操作」を，類似文字列検索と定義する．この操作は，Vの部分集合Y_x,を求める問題として記述できる．ただし，sim(x,y)は文字列xとyの類似度を与える関数（類似度関数）である．この問題の単純な解法は，検索クエリ文字列xが与えられる度に，文字列の類似度を総当たりで|V|回計算することである．文字列集合の要素数|V|が小さいときには，総当たりで解を求めることも可能だが，文字列集合が膨大（例えば数百万オーダー以上の要素数）になると，実用的な時間で解けなくなる．本論文では，自然言語処理でよく用いられる類似度関数であるコサイン係数，ジャッカード係数，ダイス係数，オーバーラップ係数に対して，式の簡潔かつ高速なアルゴリズムを提案する．本論文の貢献は，以下の2点に集約される．まず，類似文字列検索における必要十分条件及び必要条件を導出し，式が転置リストにおける$\tau$オーバーラップ問題~として正確に解けることを示す．次に，オーバーラップ問題の効率的な解法として，CPMergeアルゴリズムを提案する．このアルゴリズムは，オーバーラップ問題の解となり得る文字列の数をできるだけコンパクトに保つ特徴がある．提案手法の実装は非常に容易であり，C++で実装したライブラリを公開している．提案手法の優位性を示すため，英語の人名，日本語の単語，生命医学分野の固有表現を文字列データとして，類似文字列検索の性能を評価する．実験では，類似文字列検索の最近の手法であるLocalitySensitiveHashing(LSH)~，SkipMerge,DivideSkip~等と提案手法を比較する．実験結果では，提案手法が全てのデータセットにおいて，最も高速かつ正確に文字列を検索できることが示される．本論文の構成は以下の通りである．次節では，類似文字列検索の必要十分条件，必要条件を導出し，式がオーバーラップ問題として正確に解けることを示す．第節では，本論文が提案するデータ構造，及びオーバーラップ問題の効率的なアルゴリズムを説明する．第節で，評価実験とその結果を報告する．第節では，類似文字列検索の関連研究をまとめる．第節で，本論文の結論を述べる．</section>
  <section title="類似文字列検索の定式化">本研究では，文字列は特徴の集合で表現されると仮定する．文字列の特徴の捉え方は，提案手法に依らず任意であるが，本論文では一貫して文字tri-gramを具体例として用いる．例えば，文字列x=は，9要素の文字tri-gramから構成される集合Xで表現される．ここで，文字列の先頭と末尾に`＄'を挿入し，文字列の開始と終了を表現している．一般に，文字数が|x|の文字列xを文字n-gramの集合Xで表現したとき，|X|=|x|+n-1という関係が成り立つ．本論文では，文字列を小文字の変数（xなど）で表し，文字列を特徴の集合に変換したものを特徴集合と呼び，対応する大文字の変数（Xなど）で表す．|x|を文字列xの長さ，|X|を文字列xのサイズと呼び，これらを区別する．なお，特徴に頻度などの重みが付くときは，特徴の識別子を分割することで，重み付きの集合を模擬する．例えば，文字列「トラトラトラ」を文字tri-gramで表現するとき，`トラト'と`ラトラ'が2回ずつ出現する．これを集合で表現するには，tri-gramの末尾に出現回数を表す番号を付加すれば良い．これにより「トラトラトラ」は，,,,,,,,という集合で表現できる．特徴に出現回数を付与することは実用上重要であるが，説明が冗長になるため，以降では省略する．本論文では，ダイス係数，ジャッカード係数，コサイン係数，オーバーラップ係数など，集合間のオーバーラップに基づく類似度（集合間類似度）に対して，類似文字列検索アルゴリズムを導出する．文字列の特徴と類似度関数は，類似文字列検索の精度を左右するので，アプリケーションに応じて慎重に選択する必要がある．しかし，どのくらいの精度の類似度関数が必要になるかはアプリケーション依存であるため，文字列の特徴や類似度関数の選び方は本論文の対象外とし，与えられた特徴空間と類似度関数に対して，出来るだけ効率よくY_x,を求めるアルゴリズムを提案することに注力する．精細な類似度が必要な場合は，適当な類似度関数に対して緩い閾値を用い，提案手法で再現率が高くなるように類似文字列を検索し，関連研究（第節）で紹介する手法などで精査することで，適合率を改善すればよい．さて，文字列xとyを，それぞれ特徴集合XとYで表すとき，xとyのコサイン係数は，この定義式を式に代入すると，類似文字列のための必要十分条件が得られる．ここで，vはvの整数値への切り上げを表す．また，式には，|XY|の上限値|X|,|Y|を不等式として組み込んだ．式は，特徴集合XとYのコサイン係数が以上になるためには，少なくても|X||Y|個の要素を共通に持つ必要があることを示している．必要十分条件において，|XY|が取るべき最小の値を，XとYの最小オーバーラップ数と呼び，以降この数を$\tau$で表す．は，|X|，|Y|，に依存して計算される値である．ところで，式において|XY|を無視すると，|X|と|Y|に関する不等式を得る．この不等式を|Y|について解くと，類似文字列の必要条件が得られる．ここで，vはvの整数値への切り捨てを表す．この不等式は，Xに対して類似文字列検索を行う際の，Yに関する探索範囲を表現している．言い換えれば，特徴集合の要素数がこの範囲外の文字列は，無視できる．なお，同様の導出は，ダイス係数，ジャッカード係数，オーバーラップ係数などの類似度関数に対しても可能である．表に，それぞれの類似度関数の条件式をまとめた．これらの条件式の大元の出典は不明であるが，本論文で導出した条件式は，いくつかの先行研究でも用いられている~．ここで，導出した不等式の利用例を説明する．検索クエリ文字列x=とし，コサイン類似度の閾値=0.7で類似文字列検索を行う．また，文字列の特徴を文字tri-gramで表現することとする（したがって，|X|=6+3-1=8である）．式から，Yの要素数に関する探索範囲は4|Y|16である．この範囲内で，例えば|Y|=9となる文字列を考慮しているとき，式から，類似文字列の必要十分条件，6|XY|が得られる．この必要十分条件は，Xのtri-gramのうち，少なくても6個はYにも出現しなければならないことを表す．例えば，y=を考えると，|XY|=6である．したがって，yは類似文字列検索の解の1つである．実際，xとyのコサイン類似度は，6/89=0.707()である．以上のことをまとめると，種々の類似度関数を用いた類似文字列検索は，次のような一般的な手順で実装することができる．与えられた検索文字列Xと類似度閾値から，|Y|の範囲を求めるその範囲内で，|XY|の条件を満たすYを見つける次節では，これらの手順を効率良く実装するデータ構造とアルゴリズムを議論する．</section>
  <section title="データ構造とアルゴリズム"/>
  <subsection title="データ構造">前節までの議論により，類似文字列検索は次の部分問題を解くことに帰着される．[オーバーラップ問題]検索クエリ文字列の特徴集合Xが与えられたとき，その特徴を個以上共有する文字列Yを全て見つける．definitionここで，はXとYの最小オーバーラップ数で，コサイン係数を類似度関数として用いる場合は，=|X||Y|である．この部分問題を効率的に解くため，特徴をキーとして，その特徴を含む文字列のリストを値とする連想配列（転置インデックス）を構築する．式から，探索すべき文字列のサイズ|Y|の範囲が絞り込まれること，式から，|Y|に依存して最小オーバーラップ数が決まることを考慮し，文字列のサイズl毎に転置インデックスD_lを構築する．また，アルゴリズムを効率よく実行するため，文字列をユニークな文字列識別番号(SID)で表現し，転置リストは特徴を含む文字列のSIDを昇順に並べたものを格納することとする．図に，データ構造の実現例を示した．例えば，`＄＄ス'を特徴に持つ文字列のSIDは，#267,#452,#743,#2389,...であり，「スパゲッティー」のSIDは#452である．図では，文字列のサイズ毎にハッシュ表を構築しているが，SQLなどの関係データベースを用いても，同様のデータ構造が実現できる．図に，類似文字列検索の擬似コードを示す．文字列のサイズl毎に構成された転置インデックスの配列D=D_lに対して，検索文字列x，類似度閾値が与えられると，この擬似コードはxとの類似度が以上の文字列のSIDのリストRを返す．1〜3行目で，クエリ文字列xを特徴集合Xに変換し，考慮すべき文字列のサイズの範囲を表から求める．探索範囲内のそれぞれの長さl[n,N]に対し（5行目），最小オーバーラップ数を求め（6行目），overlap_join関数でオーバーラップ問題を解き，解集合Rを更新する（7行目）．</subsection>
  <subsection title="実装上の工夫">図のアルゴリズムでは，SIDをキーとして頻度を格納する連想配列Mを用いていた．実は，転置リストが整列済みのSIDで構成されるという性質を利用すれば，情報検索における転置リストのマージ~と同様に，連想配列をリスト構造（可変長配列）で代用できる．主要なプログラミング言語では連想配列を容易に扱えるが，アクセスのコストがリスト構造よりも大きいので，連想配列をリスト構造で置き換えることで，検索処理の高速化が期待できる．図は，図から連想配列を排除し，リスト構造のみでCPMergeアルゴリズムを実装するもの(CPMerge-opt)である．図の2〜21行目は，図の2〜7行目に対応し，解の候補生成を行う．2行目では，解候補の頻度を計測する変数Mを初期化しているが，その型は連想配列()から，可変長配列([])に変更されている．CPMerge-optでは，Mの要素は(,)のタプルであり，要素はSIDの昇順に並べる．3〜21行目の基本的な流れは，(k-1)における解候補リストMと，P=(d,X[k])の転置リストを，先頭から順に比較していき，一時変数Wにkにおける解候補リストを作成する．最後に，MをWで上書きし（20行目），k+1のステップへと進む．各kにおいて，Wを空のリストで初期化し（4行目），MとPでこれから処理する要素の位置（インデックス）を管理する変数mとpを，それぞれ0で初期化する（6行目）．7行目から19行目までは，MとPの全ての要素を処理し終わるまで，以下の処理を繰り返す．もし転置リストPのSID(P[p])が，(k-1)における解候補リストMに含まれていない場合（8行目），P[p]を新しい候補としてWに登録し（9行目），pをインクリメントする（10行目）．もし，(k-1)における解候補リストM中のSID(M[m].id)が，転置リストPに含まれていない場合（11行目），M[m]をWにそのまま追加し（12行目），mをインクリメントする（13行目）．それ以外の場合，すなわち転置リストPの要素P[p]と解候補リストM中のM[m].idが等しい場合（14行目），M[m]の頻度をインクリメントしたものをWに追加し（15行目），pとmの両方をインクリメントする（16行目）．図の22〜36行目は，図の8〜21行目に対応し，解の候補の検証と枝刈りを行っている．CPMerge-optでは，(k-1)における解候補リストMに対して，転置リスト(d,X[k])で検証を行い，枝刈りされなかった候補を一時変数Wに待避し，kにおける処理が終わったらMをWで上書きしている．図と図のその他の箇所は，ほとんど同じである．</subsection>
  <section title="実験"/>
  <subsection title="比較したシステム">本節では，大規模な文字列データセットに対して，種々の類似文字列検索アルゴリズムの性能を比較し，提案手法の有用性を示す．実験に用いたシステムは，以下の通りである．なお，先行研究の詳細については，節を参照されたい．	提案手法：オーバーラップ問題をCPMerge（図）で解くもの	提案手法-opt:CPMergeを図の擬似コードで高速化したもの	総当たり法：検索クエリが与えられる毎に，データベース内の全ての文字列と類似度を計算し，閾値以上の文字列を見つけ出す方法	AllScan:オーバーラップ問題をAllScanアルゴリズム（図）で解くもの	Signature:オーバーラップ問題をCPMerge（図）で解くが，解候補の枝刈りを行わないもの（図の17〜18行目を削除）	SkipMerge:オーバーラップ問題をSkipMergeアルゴリズム~で解く	DivideSkip:オーバーラップ問題をDivideSkipアルゴリズム~で解くを試し，最も検索レスポンスが速かった=40を採用した．	MergeOpt:オーバーラップ問題をMergeOptアルゴリズム~で解く．ただし，MergeOptは重み付きの類似度を用いた類似文字列検索アルゴリズムであり，本論文と実験設定を揃えるため，次のような修正を行った．(1)文字列の特徴の重みはすべて等しいこととする．(2)提案手法と同様に，転置リストはサイズの昇順でソートする．(3)転置リストを候補生成用Sと検証用Lに分割するときは，提案手法と同様にSをシグニチャの転置リストとする．	LocalitySensitiveHashing(LSH)~:	文字列のtri-gramを特徴とし，64ビットの局所鋭敏ハッシュ(LSH)値を計算する関数をh(x)とする．2つのハッシュ値v_1とv_2の，ビット単位でのハミング距離（ビットの異なり数）を，hdist(v_1,v_2)と書く．	このシステムは，クエリ文字列xが与えられると，そのハッシュ値h(x)とのハミング距離が以内の文字列をVから探し，解候補となる文字列集合C(|C||V|)を求める．		解候補のそれぞれの文字列yCに対して，実際にxとの類似度を計算し，閾値以上の文字列を解とする．	式の正確な解を求めることは難しいため，Ravichandranら~の手順を参考に，近似解を求める．	基本的なアイディアは，データベース中の文字列のハッシュ値のビット列を並び替え，検索クエリの（ビット列を並び替えられた）ハッシュ値の近傍を探すという試行を繰り返せば，式の近似解が求まるというものである．	ある文字列のハッシュ値h(y)のビット列を，置換_pで並び替えたものを_p(h(y))で表し，そのような置換をランダムにP種類用意し，=_pとする．	置換_pを用いて，データベースに含まれている全ての文字列yVのハッシュ値のビット列を並び替え，辞書順にソートしたハッシュ値リストをa_pとする．	置換をP種類別々に適用すると，ハッシュ値のリストもP種類作られる．	すると，a_pの中でクエリの（置換が適用された）ハッシュ値_p(h(x))に近い要素を二分探索で求め，その近傍のW個の文字列の中でハミング距離が以内のものを見つけ出すことで，式を近似的に求めることができる．	この処理を，準備しておいたP個の置換と，対応するP個のハッシュ値リストに対して行い，式の近似解の精度を向上させる．		LSHは，類似文字列検索の解の近似解を高速に求める手法であるため，検索漏れ（類似文字列が検索されない状況）が生じることがある．	LSHでは，ハミング距離の閾値()，並び替えハッシュ値リストの数(P)，近傍探索の幅(W)の3つのパラメータで検索速度と再現率のトレードオフを調整する．	今回の実験では，実験的に=24，P=24と決定しを試し，検索速度と再現率のバランスが良かった24を採用した．，WをW16,32,64と変えながら性能を測定した．総当たり法とLSH以外のすべてのシステムは，図の実装を共有しており，オーバーラップ問題の解法が性能差となって現れる．ハッシュ・データベースとしては，CDB++を用い，提案手法をC++で実装したライブラリとして，SimStringを公開している．すべての実験は，IntelXeon5140CPU(2.33~GHz)と8~GBの主記憶を搭載したDebianGNU/Linux4.0のアプリケーション・サーバー上で行った．転置インデックスはファイル上に構築し，実験時には必要に応じて主記憶に読み込んでいる．</subsection>
  <subsection title="実験に用いたデータセット">実験に用いたデータセットは，以下の3つである．	IMDB:	IMDBデータベースのファイルactors.list.gzから抜き出した	すべての俳優名（1,098,022文字列，18~MB）．	1つの文字列当たりの文字tri-gramの特徴数は17.2，	データセット全体における文字tri-gramの種類数は42,180である．	SimString	は，このデータセットから83~MBのインデックスファイル群を，56.6秒で構築した．	日本語ユニグラム：Web日本語Nグラム第1版に収録されている単語ユニグラム	（2,565,424文字列，49~MB）．	1つの文字列当たりの文字tri-gramの特徴数は20.8，	データセット全体における文字tri-gramの種類数は137,675である．	SimStringは，このデータセットから220~Mのインデックスファイル群を，134.0秒で構築した．	UMLS:	UnifiedMedicalLanguageSystem(UMLS)に収録されている生命医学分野の英語の概念や記述（5,216,323文字列，212~MB）．	評価に用いる文字列は，UMLSRelease2009AA(April6,2009)のMRCONSO.RRF.aa.gz及びMRCONSO.RRF.ab.gzというファイルに含まれる全ての英語の概念名である．	一つの文字列当たりの文字tri-gramの特徴数は43.6，	データセット全体における文字tri-gramの種類数は171,596である．	SimString	は，このデータセットから1.1~GBのインデックスファイル群を，1216.8秒で構築した．それぞれのデータセットにおいて，1,000個の文字列をランダムに選び，テスト用のクエリ文字列とした．完全には一致しない文字列で検索する状況をシミュレートするため，1,000個の文字列のうち，1/3の文字列はそのまま，1/3の文字列には1文字をランダムな文字に置換，残りの1/3の文字列には2文字をランダムな文字に置換している．</subsection>
  <subsection title="1 クエリあたりの平均レスポンス時間">図に，各データセットでコサイン係数が0.7以上の類似文字列を検索するときの，1クエリあたりの平均レスポンス時間を示した．グラフの横軸は，データベースに登録する文字列の数(|V|)で，データセット全体の10%から100%まで変化させた．また，表に，各データセットをすべて(100%)利用したときのシステム性能として，検索の再現率(Recall)，1クエリあたりの平均レスポンス時間(Mean)，1クエリに対する最遅レスポンス時間(Max)をまとめた．実験したシステムの中ではLSH(W=16)が最も高速に文字列を検索でき，データサイズが100%の時の平均レスポンス時間は，0.53~ms(IMDB)，1.61~ms（日本語ユニグラム），2.11~ms(UMLS)であった．また，平均レスポンス時間に対して最遅レスポンス時間がどのくらい遅くなるのかに着目すると，LSHは入力クエリの影響を受けにくいことが分かる．これは，LSHでは探索範囲が，P，Wなどのパラメータで一定に保たれるからである．一方，LSH以外の手法（総当たり法を除く）は，クエリ文字列に応じて|Y|の探索範囲が変化し，さらに，クエリ文字列に応じて転置リストのサイズが異なる（つまり，処理すべきSIDの数が変化する）ため，レスポンス時間のばらつきが大きくなる．しかし，LSH(W=16)は検索漏れが非常に多い．総当たり法で検索される類似文字列を正解とみなし，そのどのくらいをカバーできているか（再現率）を測定すると，LSH(W=16)の再現率は，15.4%(IMDB)，7.5%（日本語ユニグラム），4.0%(UMLS)であった．これは，式の近似解の精度が悪いためである．LSHの再現率を改善するには，周辺探索の幅(W)を大きくすればよいが，レスポンス時間を犠牲にしなければならない．例えば，LSH(W=64)では，再現率は25.8%(IMDB)，15.4%（日本語ユニグラム），11.1%(UMLS)に改善されるが，レスポンス時間は29.72~ms(IMDB9，38.07~ms（日本語ユニグラム），79.73~ms(UMLS)まで遅くなる．これに対し，提案手法では調整するパラメータもなく，正確な解（100%の再現率）が保証されている．したがって，類似文字列検索の再現率を重視する場合は，提案手法の方が優れている．提案手法-optは，正確な解が得られるシステムの中で最もレスポンスが速く，データサイズが100%の時の平均レスポンス時間は，1.07~ms(IMDB)，26.99~ms（日本語ユニグラム），20.37~ms(UMLS)であった．提案手法と提案手法-optを比較すると，図の実装上の工夫を利用することで，レスポンス時間が1.7〜2.1倍高速になった．そこで，以降の説明では単に「提案手法」というと，図の工夫を適用した「提案手法-opt」を指すこととする．総当たり法のレスポンス時間は図にプロットできないくらい遅く，32.8~s(IMDB)，92.7~s（日本語ユニグラム），416.3~s(UMLS)であった．提案手法は，総当たり法よりも3,400〜20,000倍高速に動作し，類似文字列検索を実用的な速度で実現している．提案手法は，AllScanアルゴリズムよりもかなり高速に動作し，検索速度は65.3倍(IMDB)，24.8倍（日本語ユニグラム），19.2倍(UMLS)高速であった．提案手法とSignatureシステムを比較すると，提案手法の方がSignatureよりも115.9倍(IMDB)，237.0倍（日本語ユニグラム），2323倍(UMLS)高速であった．Signatureシステムと提案手法の差は，解候補の枝刈り（図の17〜18行目）のみであるが，この処理を省くと大幅にレスポンスが低下し，AllScanアルゴリズムよりも遅くなる．これらのシステムの比較から，オーバーラップ問題を解く際に解候補を絞り込んでおくこと，二分探索の回数を減らすために解候補の枝刈りをすることが，非常に重要であることが伺える．先行研究であるMergeOpt，SkipMerge，DivideSkipは，各転置リストの先頭（SIDの小さい方）からSIDを優先順位付きキューに挿入するアルゴリズムを採用しており，オーバーラップ問題の解き方が提案手法と全く異なる．このため，レスポンス時間の差の要因を分析することは難しいが，提案手法はMergeOptよりも6.47〜9.68倍，SkipMergeよりも5.14〜6.15倍，DivideSkipよりも11.1〜24.1倍高速であった．IMDBデータセットにおいて，提案手法が検索に最も時間を要したクエリ文字列は，``Morales,Michael(VIII)''で，11.8~msを要した．以下，``Reiner,Robert(I)''(9.2~ms)，``Dore,Michael(I)''(9.2~ms)，``Dow,Christopher(III)''(8.6~ms)，``Cain,William(II)''(8.0~ms)と続く．これらのクエリが遅いのは，データセット中に似ている文字列（例えば``Morales,Michael(III)''や``Morales,Rafael(VIII)''など）が多く，-オーバーラップ問題を解くときに多くの解候補を抱えるためである．例えば，``Morales,Michael(VIII)''というクエリに対し，データセット中の72,375個の文字列が解候補となり，最終的に解になったのは42文字列であった．一方，提案手法とSkipMergeアルゴリズムのレスポンス時間の差を計算したとき，提案手法の改善が最も顕著に表れたクエリの上位3件は，``Morales,Michael(VIII)''(-44.4~ms)，``Pittman,Robert(III)''(-39.0~ms)，``Richards,Jon(VII)''(-36.6~ms)であった．ここでも，``Morales,Michael(VIII)''というクエリが登場し，その他の2つのクエリも解候補が非常に多い（40,000個以上）ことから，データセット中にクエリ文字列と似ている文字列が多く存在するとき，提案手法の優位性が際立つと考えられる．逆に，提案手法がSkipMergeアルゴリズムよりも遅くなったクエリは無かったものの，改善が全く見られなかったクエリとして，``Zhao,lSh@nqiu''(0~ms)，``Peral9a,dStacy''(0~ms)，``Sen]g[renqing''(0~ms)などが見つかった．これらのクエリは，元々``Zhao,Shenqiu'',``Peralta,Stacy'',``Senggerenqing''の文字列にノイズが加わったものと考えられるが，転置リストに含まれる文字列の種類数が非常に少なく，それぞれ3個，108個，18個であった．したがって，転置リストにおいて処理すべき文字列の数が圧倒的に少ないため，アルゴリズム間の差が出にくくなったと考えられる．このような場合でも，提案手法はSkipMergeアルゴリズムよりも遅くならず，同程度のレスポンス時間を出していた．図は，異なる類似度関数と閾値を用いたときの，提案手法のレスポンス時間を示している．類似度の閾値を低く設定すると，類似文字列検索の解となる文字列の数|Y|が大きくなるので，提案手法のレスポンス時間が遅くなる．類似度関数の良さはタスク依存で決めることであるが，同じ閾値を用いた場合はジャッカード係数が最も速く，ダイス係数とコサイン係数が同程度，オーバーラップ係数が最も遅いという傾向が見られる．この傾向は，類似度関数の性質（どの程度文字列を類似していると見なすか）によって，類似文字列検索の解の数が異なることから説明できる．例えば，日本語ユニグラムコーパスにおいて閾値0.7で類似文字列検索を行った場合，ジャッカード係数，ダイス係数，コサイン係数，オーバーラップ係数が返す解文字列数の平均は，それぞれ，1.2個，14.8個，16.2個，1036.4個であった．したがって，類似文字列検索では，最も多い解を返すオーバーラップ係数が遅く，最も少ない解を返すジャッカード係数が速くなる．また，表の必要条件から求まる|Y|の探索範囲が，ジャッカード係数では最も狭く2-|X||X|が成立する．|Y|の探索範囲の上限に関しても，|X|/|X|/^2，|X|/2-|X|であり，ダイス係数やコサイン係数よりもジャッカード係数の方が，同じ閾値を用いたとき，|Y|の探索範囲が狭くなる．，オーバーラップ係数では|Y|の探索範囲に制約が付かないことから，類似度関数による検索速度の違いを推察できる．</subsection>
  <subsection title="提案手法の動作統計">表は，提案手法が各データセットにおいて類似文字列検索を行うときの，様々な統計情報をまとめたものである（類似度にコサイン係数を用い，閾値は0.7とした）．この表の見方をIMDBデータセットで説明すると，提案手法はサイズが8.74から34.06までの文字列を検索対象とし，1クエリあたり4.63文字列を解として返した．提案手法の候補生成フェーズでは，平均4.6個の転置リストに含まれる279.7個のSIDを走査し，232.5個の解候補を得た．提案手法の候補検証フェーズでは，平均4.3個の転置リストに対して二分探索を行い，7,561.8個のSIDが二分探索の対象となった．これに対し，AllScanアルゴリズムは，17.7個の転置リストに含まれる16,155.1個のSIDを走査しなければならず，平均4.63個の解を求めるのに，9,788.7個の文字列を候補として考慮する必要があった．この表は，提案手法の3つの特筆すべき特徴を表している．提案手法はAllScanアルゴリズムと比較すると，走査するSIDの数を格段に減らしている．例えば，IMDBデータセットにおいて解候補を得るために，AllScanアルゴリズムは16,155.1個のSIDを走査する必要があったが，提案手法は279.7個のSIDを走査するだけで済んだ．別の言い方をすれば，提案手法はAllScanアルゴリズムと比較すると，1.1%〜3.5%の文字列を走査すれば，解候補が得られることを示している．提案手法はAllScanアルゴリズムと比較すると，解候補の数を9,788.7から232.5に減らしている．すなわち，解候補の数は提案手法により1.2%〜6.6%まで削減された．提案手法はAllScanアルゴリズムと比較すると，主記憶上に展開すべき転置リストの数を減らすことができる．提案手法は，オーバーラップ問題を解くために，8.9(IMDB)，18.8（日本語ユニグラム），31.7(UMLS)個の転置リストを使っている．AllScanアルゴリズムが用いる転置リストの数と比べると，提案手法は50.3%(IMDB)，53.6%（日本語ユニグラム），51.9%(UMLS)の転置リストしかアクセスしないことを意味する．これは，図のアルゴリズムで，k0.5|X|付近で解候補の検証・枝刈りが完了し，解の候補が0になっているからである．提案手法では，kが大きくなるにつれ，転置リストのサイズが大きくなるが，サイズの大きい転置リストをメモリ上に展開することなく，オーバーラップ問題を解けるのは，提案手法の大きなアドバンテージである．</subsection>
  <section title="関連研究">類似文字列検索は，データベースやデータマイニングの分野で，盛んに研究が行われている．その中で最も多い研究は，文字列の編集距離を距離尺度として用いるものである．Gravanoら~は，n-gramで文字列のインデックスを作り，オーバーラップの個数，位置，文字列のサイズなどで編集距離の制約を満たす解を絞り込む方法を提案した．Kimら~は，n-gramが出現した場所をインデックスに効率よく格納するため，2階層のn-gramインデックスを提案した．Liら~は，クエリの処理速度を向上させるため，可変長のnを用いたn-gramインデックスを用いた．Leeら~は，ワイルドカードを含むn-gramでインデックスを作り，編集距離制約の類似文字列を効率よく検索する手法を考案した．Xiaoら~は，検索クエリとマッチングできなかったn-gramを活用する，Ed-Joinアルゴリズムを提案した．文字列をn-gramなどで表現することなく，編集距離に基づく類似文字列検索を実現する方式も，いくつか提案されている．Bocekら~は，データベースに文字列を格納するときに，元の文字列に近い複数の隣接文字列を格納するアプローチ（隣接文字列生成）として，FastSimilaritySearch(FastSS)を提案した．Wangら~は，隣接文字列生成手法を改善するため，文字列を分割したり，接頭辞で枝刈りを行う方法を紹介した．Huynhら~は，圧縮された接尾辞配列上で類似文字列検索を行うアルゴリズムを提案した．Liuら~は，文字列をトライに格納し，類似文字列検索を行う枠組みを提案した．これまでに紹介した研究は，編集距離を類似度関数として採用した場合に特化している．Chaudhuriら~は，編集距離とジャッカード係数に対する類似文字列検索に向けて，SSJoin演算を提案した．このアルゴリズムは，検索クエリ文字列からシグニチャを作成し，シグニチャの特徴を含む全ての文字列を解候補として検索し，編集距離やジャッカード係数の制約を満たす文字列を選び出すものである．Chaudhuriらは，関係データベースの等結合(equi-join)を用いてSSJoin演算を実装する方法を示した．本論文では，SSJoin演算を関係データベース上で実装していないが，これは第節のSignatureシステムと同等である．Sarawagiら~は，オーバーラップ問題を解くアルゴリズムとして，MergeOptを提案した．このアルゴリズムは，転置リストをSとLという2つのグループに分け，Sで解の候補生成を行い，Lで解の検証を行う．提案手法と異なる点は，Sで解の候補生成を行うときにヒープを用いる点，Lで解の検証を行うときに，枝刈りを行わない点である．Liら~は，Sarawagiらの手法を改良し，SkipMergeとDivideSkipというアルゴリズムを提案した．SkipMergeアルゴリズムは，全ての転置リストの先頭から順にSIDをヒープに挿入し，ヒープの先頭から同じSIDの要素を取り出したとき，取り出された個数がを超えたら，そのSIDを解とするものである．ただし，ヒープに転置リストからSIDを挿入するときに，オーバーラップ問題の解となり得ない要素をスキップするメカニズムが組み込まれており，転置リスト中の全てのSIDをヒープに挿入しなくても，オーバーラップ問題が解けるように工夫されている．DivideSkipアルゴリズムは，MergeOptアルゴリズムと同様，転置リストをSとLという2つのグループに分け，SkipMergeアルゴリズムをSに適用して解の候補生成を行い，Lで解の検証を行うものである．しかしながら，DivideSkipアルゴリズムでは解の枝刈り方法については，述べられていない．これらの手法と提案手法を解析的に比較するのは難しいが，第節では，SkipMergeとDivideSkipアルゴリズムによる類似文字列検索の性能を測定し，提案手法の方が高速に検索できることを実験的に示した．続いて，提案手法とMergeOpt，SkipMerge，DivideSkipを空間計算量に関して比較する．ここに挙げた全てのアルゴリズムは，転置リスト上で二分探索を行うため，特殊な工夫をしない限り，転置リストの内容を主記憶に読み込む必要がある．最悪の場合を考えると，どのアルゴリズムも与えられたクエリ文字列に対して，最もサイズの大きい転置リストを主記憶に読み込む必要が生じる．これに加え，各アルゴリズムとも解文字列の候補を主記憶上に保持しておく必要がある．MergeOpt，SkipMerge，DivideSkipアルゴリズムは，解候補をヒープに格納するアルゴリズムであり，ヒープに格納される解候補の数は，クエリに対する転置リストの数（すなわち，クエリの特徴集合Xの要素数|X|）を超えない．これに対し，提案手法は，いったん解候補の列挙を行うため，おおよそ(|X|-+1)程度の解候補を主記憶に保持することになる．したがって，提案手法はMergeOpt，SkipMerge，DivideSkipアルゴリズムよりも空間計算量が大きくなる．表には，提案手法の各データセットにおける解候補数（#候補）が示されている．これによると，途中で保持した解候補数は数百〜数千程度のオーダーであり，提案手法の空間計算量は実用上は問題にならないと考えられる．最後に，類似文字列検索に近いタスクとして，類似文字列照合との関係を説明する．このタスクでは，与えられた2つの文字列の表記が近いかどうかを精密に検出するため，文字列の類似度関数を改良したり~，機械学習で獲得するアプローチ~が取られる．これらの研究成果を用いると，2つの文字列の類似性を高精度に判別できるが，判別する2つの文字列があらかじめ与えられることを前提としている．このような精細な類似度で類似文字列検索を行いたい場合は，適当な類似度関数に対して緩い閾値を用い，提案手法で類似文字列の候補を獲得してから，類似文字列照合を適用すればよい．</section>
  <section title="まとめ">本論文では，コサイン係数，ダイス係数，ジャッカード係数，オーバーラップ係数を用いた類似文字列検索のための，新しいアルゴリズムを提案した．類似文字列検索を，オーバーラップ問題に帰着させ，その簡潔かつ高速なアルゴリズムとしてCPMergeを提案した．このアルゴリズムは，オーバーラップ問題の解候補をできるだけコンパクトに保ち，解を効率よく求めるものである．英語の人名，日本語の単語，生命医学分野の固有表現を文字列データとして，類似文字列検索の性能を評価した．CPMergeアルゴリズムは非常にシンプルであるが，類似文字列検索の最近の手法であるLocalitySensitiveHashing(LSH)~やDivideSkip~と比べ，高速かつ正確に文字列を検索できることを実証した．自然言語処理を実テキストに適用するときの基礎的な技術として，本研究の成果が活用されることを期待している．CPMergeアルゴリズムが従来手法（例えばMergeSkip）に対して特に有利なのは，全ての転置リストを主記憶に読み込まなくても，類似文字列検索の解を求めることができる点である．表に示した通り，CPMergeアルゴリズムはクエリに対して約50%の転置リストを読み込むだけで，類似文字列検索の解を求めることができた（コサイン類似度で閾値が0.7の場合）．提案手法と従来手法は，アルゴリズム中で二分探索を用いるため，転置リスト上におけるランダムアクセスを，（暗黙的に）仮定している．したがって，読み込む転置リストの数を減らすことができるという提案手法の特徴は，転置リストを圧縮する際に有利であると考えられる．転置リストの圧縮に関する最近の研究成果~を参考に，圧縮された転置リストを用いた類似文字列検索を今後検討したいと考えている．</section>
</root>
