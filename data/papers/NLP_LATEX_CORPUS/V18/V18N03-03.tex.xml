<?xml version="1.0" ?>
<root>
  <jtitle>日本語語義曖昧性解消のための訓練データの自動拡張</jtitle>
  <jauthor>藤田早苗KevinDuh藤野昭典平博順進藤裕之</jauthor>
  <jabstract>本稿では，訓練データの自動拡張による語義曖昧性解消の精度向上方法について述べる．評価対象として，SemEval-2010日本語語義曖昧性解消タスクを利用した．本稿では，まず，配布された訓練データのみを利用して学習した場合の結果を紹介する．更に，辞書の例文，配布データ以外のセンスバンク，ラベルなしコーパスなど，さまざまなコーパスを利用して，訓練データの自動拡張を試みた結果を紹介する．本稿では，訓練データの自動獲得により79.5%の精度を得ることができた．更に，対象語の難易度に基づき，追加する訓練データの上限を制御したところ，最高80.0%の精度を得ることができた．</jabstract>
  <jkeywords>SemEval-2010，例文，コーパス，難易度</jkeywords>
  <section title="はじめに">SemEval-2010において，日本語の語義曖昧性解消タスクが行われた．本タスクは，コーパス中に出現する対象語に対し，辞書で定義された語義のうち適切な語義を推定することが課題である．日本語を対象とした類似のタスクとしては，2001年に開催されたSENSEVAL-2の日本語辞書タスクがあげられる．ただし，SENSEVAL-2における日本語辞書タスクとは，2つの点で大きく異なっている．すなわち，対象コーパスの分野が多岐にわたる点，および，辞書に定義されていない語義が出現することもあるという点で異なっている．語義曖昧性解消は，非常に古くから取り組まれてきている課題であり，さまざまな手法が提案されてきている．教師なし学習法も，クラスタリングに基づく手法や，辞書定義文を利用した手法などが提案されているが，一般に訓練データが存在する場合には，教師あり学習法による精度の方が高い．SENSEVAL-2，および，SemEval-2010での日本語語義曖昧性解消タスクでも，教師あり学習法による手法が最も高い精度を出している．そこで，本稿でも，教師あり学習法をベースとした実験を行った．しかし，本タスクにおいて，訓練データとして与えられたのは，各対象語につき50例ずつであり，十分な量とはいい難い．実際，評価データにしか出現しない語義（未知語義）も存在する．そのような未知語義は，訓練データのみを用いた学習では推測できない．また，コンテストに参加したチームで，ドメイン適合性に着目した実験を行ったチームもあるが，ドメイン適合性はいずれのチームでもあまり有効に機能していない．我々は，その原因が，訓練データの少なさにあると考え，訓練データの自動獲得による精度向上を試みた．本稿ではその報告を行う．訓練データを自動的に増やす方法としては，まず，Bootstrapping法があげられる．Bootstrapping法では，まずラベル（語義）の付与された訓練データで学習し，ラベルなしデータのラベルを推定し，ある基準において最も信頼できるものをラベルありデータに追加する．ここで，ラベルなしデータのラベル推定を決定木で行う研究もある．しかしこれらの方法の場合，ラベルなしデータから，いくら訓練データを追加したところで，もともとの訓練データに出現しないような語義を推測することはできない，という問題がある．そのため，この方法でも未知語義には対応できない．また，訓練データを自動的に増やす他の方法として，単義の同義語を利用する方法も提案されている．彼らは，WordNetの同義語(synset)のうち，単義語（例えば，``remember_1''に対して``recollect''など）や，定義文(gloss)の中のユニークな表現（例えば，``produce_5''に対して，glossの一部である``bringontothemarket''など）を検索語としてWeb検索を行い，獲得したスニペット中の対象語に語義を付与し，訓練データに追加している．この方法であれば，未知語義の訓練データを得て，推定できる可能性がある．そこで，本稿では，基本的に後者の方法に近い方法を導入する．ただし，らは，WordNetから同義語等を得ることができたが，本タスクの語義は岩波国語辞典によるため，WordNetのsynsetのような同義語を直接獲得することは難しい．そこで，定義文中から比較的抽出しやすい例文に着目し，例文を利用した訓練データの獲得を行う．また，本稿では，既存のコーパスの利用も考える．本稿では，まず章で，本タスクで配布されたデータ，および，それ以外に本稿で利用したデータについて紹介する．次に章では，本稿で利用する素性，学習方法について述べる．章では実験の結果とそれに基づく議論，章では自動獲得した訓練データの評価について，章では結論を述べる．</section>
  <section title="データ"/>
  <subsection title="SemEval-2010: Japanese WSD タスク配布データ">章で述べたように，SemEval-2010:JapaneseWSDタスクは，対象コーパスの分野が多岐にわたるという特徴がある．訓練データは，白書（以下，），新聞()，本や雑誌()の分野から成り，評価データは，更に，Web上のQ&amp;Aサイトである，Yahoo!知恵袋（以下，）のデータも含んでいる．これらのデータは，現代日本語書き言葉均衡コーパス()のうち，形態素解析の誤りを人手で修正したコアデータと呼ばれる部分から抽出されている．なお，形態素解析は，に基づいて行われている．また，本データには，岩波国語辞典の語義を元に，語義IDが付与されている．岩波国語辞典に定義されていない新語義（以下，）も付与されている場合があり，それらの新語義を推定することも，課題の一つである．対象語は50語で，辞典に定義された語義数は219だった．訓練データでは，2種類の新語義()が出現している．訓練データと評価データは，各語50文ずつ与えられた．図~は，本タスクで配布された岩波国語辞典の例である．図~に示すように，各エントリは，表記，品詞，定義文や例文などの情報を含んでいる．図~は，訓練データの例である．ここで，sense=&quot;&quot;で示される部分が，付与されている語義IDを示している．例えば，図~，6行めの形態素「取っ」の場合，語義ID'37713-0-0-1-1'が付与されている．但し，図~において，lemma=&quot;&quot;の部分は，配布データには存在していなかった．これは，各形態素の基本形を示しており，カタカナによる基本形(bfm)や，出現形から推測し，我々がほぼ自動的に付与したものである．また，図~において，各行頭に付与した番号は，参照用に便宜的に付与したものである．</subsection>
  <subsection title="岩波国語辞典の例文">本稿では，まず，岩波国語辞典の例文を抽出する．図~の例のように，「」で囲まれた部分は，各語義の例文になっている．そこで，「」で囲まれた部分を例文として抽出する．ここで，``—''の部分は，見出し語を補完することができる．それにより，例えば，図~に示した見出し語「とる」の場合，37713-0-0-1-1の例文として()，37713-0-0-3-1の例文として()，37713-0-0-6-3の例文として()などが獲得できる．また，岩波国語辞典の場合，例文の前方や後方が，``…''という記号によって省略される場合がある．例えば，「…に—って」のような形（図~の37713-0-0-3-3）である．こうした``…''は，取り除き，()のような形にした．手を取って導く(37713-0-0-1-1)責任を取る(37713-0-0-3-1)数を取る(37713-0-0-6-3)にとって(37713-0-0-3-3)exeこうして抽出した例文は，形態素解析器Mecabのバージョンで解析する．また，例文()--()において,``—''によって見出し語を補完した部分（下線部）には，例文を抽出した語義のIDを付与する．但し，本タスクで推定する語義の粒度は，中語義（-で区切られた数字の，最後の部分を除いたもの．37713-0-0-1,37713-0-0-3等）なので，実際には，中語義に集約して抽出している．つまり，例文()は37713-0-0-1，(),()は37713-0-0-3，()は37713-0-0-6の例文として利用する．</subsection>
  <subsection title="センスバンク：檜">本稿では，更に数種類の言語資源を利用した．まず，基本語意味データベース，および，センスバンク「檜」を利用する．は，日本人にとって最も馴染みの深い28,270語を収録した辞書である．収録語は，心理実験によって選定されており，語義毎に語義文と例文がある．また，各語義文と例文の内容語には，自身の語義が付与されている．更に，京都大学テキストコーパスの内容語に対しても，の語義が付与されている．これらの，によって語義付与されたセンスバンクを「檜」と呼んでいる．檜のサイズを表~に示す．なお，檜には構文情報も付与されているが，本稿では利用していない．ここで，と岩波国語辞典の語義は，語義文の類似度の高いもの同士がリンクされている．そのため，リンクが存在する語義なら，檜で付与されているの語義を岩波国語辞典の語義に置き換えて，訓練データとして利用することができる．例えば，岩波国語辞典の「とる」37713-0-0-6-3の語義文は「数える．測る．」であり，の19036420-49の語義文「数える．測定する．」と，非常に類似しており，リンクされている．このリンクを用いることで，例えば，の19036420-49の例文()を，岩波国語辞典の37713-0-0-6(-3)の訓練データに追加できる．但し，檜はIPA品詞体系に基づいた形態素解析が行われているため，によって形態素解析をやりなおし，語義IDのみを対応箇所に付与しなおした．そこで、医者は患者の顔色を診ながら脈を取った。exe</subsection>
  <subsection title="現代日本語書き言葉均衡コーパス">章で述べたように，本タスクのデータは，現代日本語書き言葉均衡コーパス()のコアデータから抽出されている．のデータは，モニター公開データとして利用可能である．但し，コアデータには，人手修正された形態素解析結果が付与されているが，コアデータ以外のには形態素解析結果は付与されていない．本稿では，の2009年度版モニター公開データを利用する．Readmeによると，2009年度版モニター公開データには4,300万語が含まれている．このデータから，章で抽出した岩波国語辞典の例文を利用し，訓練データを獲得する．まず，章で獲得した例文を文字の列として完全に含む文を抽出し，形態素解析を行う．更に，対象例文の見出し語と，基本形，および，品詞大分類が一致する形態素に，該当する例文の語義IDを付与する．例えば，37713-0-0-3-3の例文「にとって」（図~参照）を含む文として，Yahoo!知恵袋()から，文()を獲得できる．文()の下線部は，章で抽出した例文()と一致した部分である．また，これを形態素解析したものが，図~である．地運の相性を見ても彼はあなたにとって最高の相手ですが、exeこのように，本手法によって獲得した文はラベルあり訓練データとして追加する．但し，には，評価対象文が含まれるので，評価対象文と同一の文は利用しないという制限を設けた．また，新聞データ2年分（日本経済新聞（以下，），毎日新聞()）からも，同様に訓練データを抽出した．</subsection>
  <subsection title="未知語義数，および，獲得データサイズ">表~に，評価データに出現する語義のうち，訓練データにも出現する語義と，評価データにのみ出現する語義の数を示す．辞書に定義された全語義は219語義だが，評価データに出現する語義は，新語義()を除くと，142語義(=150-8)であり，辞書に定義された全語義の64.8%だった．また，評価データにのみ出現する語義は9語義(=15-6)，18例(=34-16)だった．また，章から章で紹介した方法で獲得した訓練データのサイズを，表~に示す．表~から，評価データにのみ出現する9語義に対しても，例文()，檜の両方から訓練データが獲得できることがわかる．また，表~には，参考のため，訓練データの数値も表示している．本提案手法では，新語義()の訓練データは獲得できない．また，それ以外の語義に対しても，評価データに出現する語義の異なりに対して，訓練データほどのカバー率はない．但し，すべてのコーパスを利用すれば，ほぼ，訓練データに近いカバー率を得ることができている．なお，表~は，獲得傾向を確認するために，評価データに出現する語義かどうかを分けて表示しているが，実験では当然，評価データに出現しない語義の例文であっても区別せずに利用している．</subsection>
  <section title="実験"/>
  <subsection title="学習器">学習には，代表的な識別モデルの一つであり，ラベルありデータを用いて教師あり学習を行う最大エントロピーモデル(MaximumEntropyMethod:,)を用いた．これは，Fujitaら(2010)によると，SupportVectorMachine(,)より，の精度がはるかに良かったためである．</subsection>
  <subsection title="素性">[基本素性]まず，語義曖昧性解消タスクで一般的に利用される素性を，基本素性として利用する．各対象語wに対し，出現形，基本形，品詞，品詞大分類（名詞，動詞，形容詞など）を利用する．また，対象語がi番目の語だとすると，前後2語(i-2,i-1,i+1,i+2)の同じ情報も利用する．更に，前後3語以内のbigrams,trigrams,skipbigramsも利用する．これらの素性を利用したモデルをとする．[Bag-of-Words]各対象語wに対し，同一文内に出現する全内容語の基本形を素性として利用する．これらの素性を利用したモデルをとする．[トピック素性]SemEval-2007EnglishWSDタスクでは，トピック情報を利用したシステムが，最も高い精度を得ている．Caiら(2007)の研究を参考に，トピック情報を利用した素性を導入した．Caiらは，Bayesiantopicmodels(LatentDirichletAllocation:LDA)を用いて教師なし状態でトピック分類を行い，推定したトピックを素性として利用している．本稿では，訓練データと評価データにgibbslda++を適用し，文書（ファイル）単位でトピック分類を行った．但し，新聞()の場合のみ，記事毎に分類した．これは，新聞の場合は，記事毎に，内容ががらりと変わることがあるが，それ以外の文書（書籍やYahoo!知恵袋，白書など）では，がらりと変わると思われなかったためである．また，一つの文書，あるいは記事は，複数のトピックに含まれることがある．本稿では，対象語が属する文書，あるいは記事の含まれるトピック分類を素性として利用し，これらの素性を利用したモデルをXとする．ここで，Xは，トピック数であり，Xが多ければ多いほど，分類が細かいことになる．</subsection>
  <section title="結果と議論"/>
  <subsection title="配布データのみを利用">Fujitaら(2010)によると，対象語毎に訓練データの分野の組合せを変えて学習するより，分野に関係なくすべての訓練データを学習に用いる方が精度が良い．学習器は，前述のようにを用いる．表~に，すべての訓練データを学習に用い，素性の組合せを変えた場合の結果を示す．パラメータは，訓練データにおける対象語毎の交差検定で最も良い精度を出したものを用いている．また，表~には，参考として，SemEval-2010でのBestresult(RALI-2)も掲載している．更に，対象語を難易度毎に分けて傾向を分析する．そのため，SENSEVAL-2の日本語辞書タスクと同様に，訓練データにおける語義の頻度分布のエントロピーE(w)（式()）を，単語の難易度の目安として利用し，対象語を，高難易度(D_diff,E(w)1)，中難易度(D_mid,0.5E(w)&lt;1)，低難易度(D_easy,E(w)&lt;0.5)の3つにわけた．式()において，p(s_i|w)は，単語wの語義がs_iとなる確率を表している．各難易度に含まれる対象語の数は，それぞれ，D_diffで9語，D_midで20語，D_easyで21語だった．対象語の詳細を，表~に示す．表~によると，基本素性()だけを利用した場合でも，SemEval-2010のBestresult(76.4%)より高い精度(77.7%)が得られた．最も精度が高かったのは，トピック素性を利用した場合(+200)(78.0%)だった．を素性として利用する場合は，精度はかえって低下する傾向にある．なお，+200で最も精度が高かった対象語は，「外」（精度100%），「経済」(98%)，「考える」(98%)，「大きい」(98%)，「文化」(98%)などである．一方，最も精度の低かった語は，「取る」(36%)，「良い」(48%)，「上げる」(48%)，「出す」(50%)，「立つ」(54%)などである．</subsection>
  <subsection title="自動獲得した訓練データも利用">本節では，自動獲得した訓練データ（表~参照）を利用した場合の結果について紹介する（表~）．表~では，素性は基本素性()のみ利用し，学習器はを利用した．基本素性()を用いて，配布された訓練データのみで学習した場合の精度を基準とすると，難易度別に傾向が非常に異なることがわかる．低難易語の場合，訓練データを追加すると，ほとんどの場合で精度が低下している．それどころか，精度が最も高いのは，最頻語義を利用したBaseLineである．しかし，中難易語では，精度向上する場合の方が多くなり，高難易語では，すべての場合で，精度が向上している．特に，自動獲得したすべての訓練データを追加した場合，低難易語では最も精度が低くなり，高難易語では最も精度が高くなっている．これはつまり，そもそも低難易語の場合には，誤りを含むかもしれない訓練データの追加は，むしろマイナスに働く可能性が高いが，中・高難易語の場合，訓練データに含まれる誤りによる悪影響より，訓練データが増えることによる好影響の方が強いことが伺える．また，表~には，配布訓練データを用いず，自動獲得したすべての訓練データだけを用いた場合の実験結果も載せている．それによると，低・中難易度では，配布訓練データを用いた精度に及ばないが，高難易度では，配布訓練データのみを用いる場合より高い精度を得ることができた．このように，自動獲得した訓練データのみを利用した場合も善戦はしているが，配布訓練データも利用した場合の方が相当精度が高い（最大11.1ポイント差）．この原因は，(1)特にと新聞データは，岩波の例文を含む文のみを抽出しているため，訓練データのバリエーションに乏しい，(2)例文によって，獲得できる訓練データ数に非常にばらつきがあり，自然な分布にならない，(3)自動獲得しているため誤りが含まれる，などが考えられる．また，岩波の例文そのものを追加した場合，精度は若干低下する．しかし，例文を用いて訓練データを追加した，も新聞も，を除いて，精度向上が見られる．これは，例文そのものは非常に短いものが多く，切れ切れになってしまうが，例文を含む文全体を追加することで，もう少し広い前後の語などの情報も利用できるために，精度が向上したのだと考えられる．また，本手法の利点の一つに，訓練データで出現しない語義に対しても，訓練データを追加できることがある．そこで，評価データにしか出現しなかった未知語義（9語義18例，節参照）に対する精度のみを確認した．訓練データに出現しない語義なので，訓練データのみ利用した場合，精度は0%である．表~に，改良があった結果のみ表示する．表~によると，すべて追加した場合でも，2例正解しただけであるが，訓練データだけでは絶対に正解できなかった部分であり，意義は大きい．</subsection>
  <subsection title="学習曲線">前節では，各コーパスから追加可能な文はすべて追加して学習した．本節では，過学習していないか調べるため，追加する文数と精度との関連を調べた．や新聞データの場合，岩波の例文を完全に含む文を追加するため，例文毎に追加できる最大の文数を設定し，精度との関係を調べた．つまり例えば，最大追加文数を5文と設定する場合，例文()--()のそれぞれに対し，条件を満たす文のうち，最初に出てきた5文までを訓練データとして追加する．但し，当然，最大の文数まで獲得できない場合もある．表~は，表~で最も良い精度を出したを用いた場合の結果である．また，参考までに，図~に学習曲線を示した．表~および図~から，難易度によって，学習曲線が大きく異なることがわかる．低難易語の場合，10文追加までは，かろうじて精度が向上している．しかし，その後は，訓練データを追加すればするほど，精度が低下している．一方で，中・高難易語に対しては，訓練データを追加した方が精度は向上する．特に，高難易語での精度向上が大きい．この結果から，低難易語には訓練データをほとんど追加せず，中・高難易語には訓練データを追加する方がいいことがわかる．表~の「参考」に，中・高難易語にのみ，300文を上限に訓練データを追加した場合の結果を示す．但し，本稿の手法の利点の一つは，訓練データに出現しなかった語義にも訓練データを獲得できることであるため，訓練データに出現していない語義に対しては，低難易語であっても訓練データを5文を上限として追加している．この場合，低難易語の精度は下がらず，全体精度は80.0%を達成，未知語義も1例正解できた．</subsection>
  <section title="自動獲得した訓練データの評価">本節では，章の訓練データの自動獲得方法で獲得した訓練データに正しい語義が付与されているかどうかを評価した．評価対象には，前節（節）で利用したにおいて，追加できる最大文数を5文とした場合に獲得されたデータを用いた．この条件では，47語，114語義に対し，1,038文が獲得されている．人手評価の結果，正しい訓練データだったものは979文(94.3%)，誤っていたものは59文(5.7%)だった．このように5.7%の誤りを含んでいたものの，表~によると，全体で1.4%の精度の向上が見られており追加の効果は高い．誤った訓練データを獲得した原因で最も多かったのは，慣用表現である．例えば，語義ID20676-0-0-1「ある時刻と他の時刻との間（の長さ）．」の例文「時間の問題」は慣用的な表現である．しかし，獲得された5文のうち，1文は，文()であり，語義ID20676-0-0-3「空間と共に，物体界を成り立たせる基礎形式と考えるもの．」の方がふさわしいだろう．この本はむずかしい時間の問題を、抽象的な時間論というかたちではなく、...exe慣用表現かどうかの判定は非常に難しく，本稿の手法で，慣用表現による誤りを取り除くことは困難である．すべての誤りを取り除くには，慣用表現辞書などを利用し，慣用表現と思しき表現を利用しないことにするか，最終的に人手による判断が必要だろう．次に多かった誤りは，対象語以外の形態素区切りの不一致によるものだった．例えば，37713-0-0-6の例文「数を取る」の場合，文()が獲得されている．しかし，37713-0-0-6は「数える」という意味なので，文()は誤りである．ペーパーテストではいい点数を取るのかもしれませんがね。exe節で述べたように，訓練データの追加条件は，例文を完全に含むこと以外にも，「対象例文の見出し語と，基本形，および，品詞大分類が一致する形態素に，該当する例文の語義IDを付与する．」という条件がある．しかし，見出し語以外は，形態素解析結果が一致するかは確認していない．だが，文()の場合，動詞「取る」の目的語部分（「数」と「点数」）は異なっているため，例文側も形態素解析し，前後の形態素も含めて一致する文だけを訓練データに追加すれば，排除できる誤りである．ここまで述べたように，自動獲得した訓練データには誤りが含まれる．しかし，1,038文の正誤評価には1日とかからなかったので，慣用表現のような，人手判断が必要な表現であっても，1日の人手作業で，正しい訓練データを4割近く増やすことができることになる．また，自動獲得では間違いやすい部分のみ，人手作業を行うことも可能である．そのようにして，効率的に正確な訓練データを増やすことも，今後，選択肢の一つになると考えられる．</section>
  <section title="おわりに">本稿では，訓練データの自動拡張による語義曖昧性解消の精度向上方法について述べた．評価対象として，SemEval-2010日本語語義曖昧性解消タスクを利用した．本稿では，辞書の例文，配布データ以外のセンスバンク（檜），ラベルなしコーパス(),新聞データなど，さまざまなコーパスを利用して，訓練データの自動拡張を試みた．配布データ以外のセンスバンク（檜）を利用する場合，語義が定義された辞書同士のリンクを経由して，訓練データを獲得した．辞書同士のリンクは，定義文同士の類似度によって構築されている．檜を追加した場合，78.8%の精度を得ることができた．これは，配布データのみを利用した場合の結果(77.7%)より，+1.2%の改良である．このように，異なる品詞体系，異なる辞書（語義）に基づいて構築されたセンスバンクであっても，自動的に訓練データに追加し，精度向上に寄与できることを示した．人手で構築する言語資源は，構築のための時間と費用が非常にかかるため，こうした既存言語資源の有効利用は，ますます重要になると考えれられる．また，センスバンク以外のラベルなしデータを用いる場合，辞書の例文を文字の列として完全に含み，かつ，形態素解析の結果，対象語と，基本形，および，品詞大分類が一致するものを訓練データとして追加した．最も良い精度を出したラベルなしデータは，書籍（の）であり，79.5%(+1.8%)の精度を得た．ここで，追加した例文のうち，1,038文をサンプリング評価したところ，94.3%に正しい語義が付与されていた．このように，自動獲得した訓練データには誤りも含まれるものの，例文そのものを追加するより，本稿の提案手法のように，例文を完全に含む，より自然な文を利用する方が効果が高いことを示した．難易度に基づいて傾向を分析した結果，低難易語には訓練データを追加せず，中・高難易語には訓練データを追加する方がいいことがわかった．そのため，中・高難易語と未知語義にのみ訓練データを追加した場合，最高80.0%の精度を得た．このように，本稿で紹介したような訓練データの追加は，非常に有効であると言える．最後に，今後の課題として以下の3点を挙げる．訓練データを追加する場合（章参照）も，トピック素性を利用して実験を行う．配布データのみを利用した場合には，トピック素性を利用した場合がもっとも良かった（章参照）ためである．辞書定義文から同義語を獲得し，らと同様に，同義語を用いた訓練データの拡張も行う．本稿では，辞書の例文に完全一致する語を訓練データとして追加したが，本手法の場合，そもそも辞書に全く例文がない場合には，新しい訓練データは獲得できない．同義語も利用すれば，例文のみでは訓練データを新たに獲得できなかった語義についても新しい訓練データを追加できるかもしれない．また，例文に完全一致する文のみの追加では，訓練データに偏りが出る恐れがあるが，その点を補完できると期待できる．ラベルなしデータを利用した半教師あり学習法による精度向上を図る．半教師あり学習を適用する場合でも，始めに与える訓練データにない語義は，ラベルなしデータをいくら与えたところで推定できない．そのため，本稿のようにあらかじめ低頻度語の訓練データを追加しておくことは重要だと思われる．-2010JapaneseWSDtaskに関しまして，データ整備，運営，開催等にご尽力された皆様に感謝いたします．また，「『現代日本語書き言葉均衡コーパス』モニター公開データ（2009年度版）」に関しまして，使用を許可して下さった独立行政法人国立国語研究所に感謝いたします．document</section>
</root>
