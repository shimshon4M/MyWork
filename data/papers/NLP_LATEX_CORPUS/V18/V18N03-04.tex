    \documentclass[english]{jnlp_1.4}

\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\newcommand{\url}[1]{}

\Volume{18}
\Number{3}
\Month{June}
\Year{2011}

\received{2010}{10}{7}
\revised{2011}{1}{11}
\accepted{2011}{2}{20}

\setcounter{page}{293}


\etitle{On SemEval-2010 Japanese WSD Task}
\eauthor{Manabu Okumura\affiref{TITech} \and Kiyoaki Shirai\affiref{JAIST} \and Kanako Komiya\affiref{TUAT} \and Hikaru Yokono\affiref{TITech}} 
\eabstract{
  An overview of the SemEval-2 Japanese WSD task is
  presented. The new
  characteristics of our task are (1) the task will use the first
  balanced Japanese sense-tagged corpus, and (2) the task will take into
  account not only the instances that have a sense in the given set
  but also the instances that have a sense that cannot be found in the
  set. It is a lexical sample task, and word senses are defined
  according to a Japanese dictionary, the Iwanami Kokugo Jiten. This dictionary
  and a training corpus were distributed to participants. The
  number of target words was 50, with 22 nouns, 23 verbs, and 5
  adjectives. Fifty instances of each target word were provided,
  consisting of a total of 2,500 instances for the evaluation. Nine systems
  from four organizations participated in the task.
}
\ekeywords{Word Sense Disambiguation, Balanced Corpus, Text Genre, New Word Sense}

\headauthor{Okumura et al.}
\headtitle{On SemEval-2010 Japanese WSD Task}

\affilabel{TITech}{}{Precision and Intelligence Laboratory, Tokyo Institute of Technology}
\affilabel{JAIST}{}{School of Information Science, Japan Advanced Institute of Science and Technology}
\affilabel{TUAT}{}{Institute of Engineering, Tokyo University of Agriculture and Technology}


\begin{document}
\maketitle


\section{Introduction}

This paper reports an overview of the SemEval-2 Japanese Word Sense
Disambiguation (WSD) task. It is an extension of the SENSEVAL-2 Japanese monolingual
dictionary-based task \cite{shirai:01:a}, and is a lexical sample
task\footnote{In the lexical sample task, a pre-selected set of
    target words is used for evaluating WSD systems.}. In the usual
WSD task, participants received a dictionary as a sense
  inventory and training data, and they are requested to annotate senses
  from the dictionary for target words in test data.

Our task has the following two new characteristics:
\begin{enumerate}
\item All previous Japanese sense-tagged corpora were from newspaper
   articles, while sense-tagged corpora were constructed in
   English on balanced corpora, such as the Brown corpus and the BNC
   corpus. The first balanced corpus of contemporary written Japanese
   (BCCWJ corpus) is now being constructed as part of a government
   funded project in Japan \cite{maekawa:08:a}, and we are now
   constructing a sense-tagged corpus based on it. Therefore, the task will use the first
   balanced Japanese sense-tagged corpus.

Because a balanced corpus consists of documents from multiple genres, the
corpus can be divided into multiple sub-corpora of a genre. 
In supervised learning approaches on word sense disambiguation, because
word sense distribution might vary across different sub-corpora, we
need to take into account the genres of training and test
data. Therefore, word sense disambiguation on a balanced corpus
requires tackling a kind of domain (genre) adaptation
problem \cite{chang:06:a,agirre:08:a}.
\item In previous WSD tasks, systems have been required to select a sense
   from a given set of senses in a dictionary for a word in one
   context (an instance). However, the set of senses in the dictionary
   is not always complete. New word senses sometimes appear after the
   dictionary has been compiled. Therefore, some instances might have
   a sense that cannot be found in the dictionary's set. The task
   will take into account not only the instances that have a sense in the
   given set but also the instances that have a sense that cannot be
   found in the set. In the latter case, systems should output that
   the instances have a sense that is not in the set.
\end{enumerate}

Word senses are defined according to the Iwanami Kokugo 
Jiten \cite{nishio:94:a}, a Japanese dictionary published by Iwanami
Shoten.
The training data consists of three genres (books, newspaper
articles, and white papers) and is manually annotated with sense IDs.
For the evaluation, we distributed a
corpus that consists of four genres (books, newspaper articles, white
papers, and documents from a Q\&A site on the
WWW\footnote{Yahoo!知恵袋(\url{http://chiebukuro.yahoo.co.jp/})}) with marked target
words as the test data. Participants were requested to assign one or more
sense IDs to each target word, optionally with associated
probabilities. The number of target words was 50, with 22 nouns, 23 verbs,
and 5 adjectives. Fifty instances of each target word were provided,
consisting of a total of 2,500 instances for the evaluation.

In what follows, section two describes the details of the data used in
the Japanese WSD task. Section three describes the process to
construct the sense tagged data, including the analysis of an
inter-annotator agreement. Section four explains two
evaluation methodologies in our task. Section five briefly introduces
participating systems, and section six describes their
results. Finally, section seven concludes the paper.



\section{Data}

For the task, we prepared three types of data: a sense
  inventory, training data, and test data. In the following
  subsections, we describe detailed statistics and specifications of
  the sense inventory and the data.


\subsection{Sense inventory}

As described in section one, word senses are defined according to a
Japanese dictionary, the Iwanami Kokugo Jiten. The total number of
headwords and the word senses in the Iwanami Kokugo Jiten is 60,321 and
85,870, respectively. For ambiguous words that have multiple
word senses, the number of headwords and the average number of word
senses for them is 12,360 and 3.067, respectively.

As described in the task description of SENSEVAL-2 Japanese
dictionary task \cite{shirai:01:a}, the Iwanami Kokugo Jiten has
hierarchical structures in word sense descriptions. The Iwanami Kokugo
Jiten has at most three hierarchical
levels. Figure~1 shows a sample entry of the Iwanami Kokugo Jiten.

\begin{figure}[b]
\begin{center}
\includegraphics{18-3ia5f1.eps}
\end{center}
\caption{Entry of 「合う」 in the Iwanami Kokugo Jiten}
\end{figure}


\subsection{BCCWJ corpus}

BCCWJ corpus is the first balanced corpus of contemporary written
Japanese, that is now being constructed. We are now constructing a
sense-tagged corpus based on it. In this subsection, we briefly outline
BCCWJ corpus before we explain our sense-tagged corpus.

The volume of the corpus will be 100 million words in total. The BCCWJ
consists of the following 3 sub-corpora \cite{maekawa:08:a}:
\begin{enumerate}
\item Publication sub-corpus\\
This sub-corpus represents the production, as opposed to the reception
aspect of contemporary Japanese. It consists of 35 million words from
books, magazines, and newspapers.
\item Library sub-corpus\\
The sampling for this sub-corpus was from the books in at least 13
public libraries in Tokyo. It consists of 30 million words.
\item Special-purpose sub-corpus\\
This corpus is the aggregate of various mini corpora. The mini corpora
include texts of governmental white papers, Web texts, and so on. The
whole corpus consists of 35 million words.
\end{enumerate}

The subset of the BCCWJ corpus was annotated with morphological
information for all words, as explained in the next subsection, and
the subset data was named `core data'. We manually annotated word
sense IDs for all ambiguous words in the core data. The core data
consists of 200 thousand words from books, 200 thousand words from
white papers, 300 thousand words from newspaper articles, and 100
thousand words from a Q\&A site on the WWW.


\subsection{Annotation for the data}

The annotated information both for the training and test data is as
follows:
\begin{itemize}
\item Morphological information\\
The document was annotated with morphological information (word
boundaries, a part-of-speech (POS) tag, a base form, and a reading) for
all words. All the morphological information was automatically annotated
using a morphological analyzer ChaSen\footnote{\url{http://chasen-legacy.sourceforge.jp/}} with
a short-unit dictionary named UniDic\footnote{\url{http://www.tokuteicorpus.jp/dist/}} and was manually
post-edited.
\item Genre code\\
Each document was assigned a code indicating its genre from the
aforementioned list.
\item Word sense IDs\\
Word sense IDs were manually annotated\footnote{They were hidden from
  the participants in the test data during the formal
  run.}. The details are described in section three.
\end{itemize}


\subsection{Training and test data}

The training data consists of 240 documents of three genres (books,
newspaper articles, and white papers) from the BCCWJ corpus.
3,437 word tokens were annotated for sense IDs, and the data
contain 31,611 sense-tagged instances that include 2,500 instances for
the 50 target words. Words assigned with sense IDs satisfied the
following conditions:
\begin{enumerate}
\item The Iwanami Kokugo Jiten gave their sense description.
\item Their POSs were either a noun, a verb, or an adjective.
\item They were ambiguous, that is, there were more than two word
  senses for them in the dictionary.
\end{enumerate}

The test data consists of 695 documents of four genres (books, newspaper
articles, white papers, and documents from a Q\&A site on the WWW) from
the BCCWJ corpus, with marked target words.
The documents used for the training and test data are not mutually
exclusive. The number of overlapping documents between the training and
test data is 185. 
The instances used for the evaluation were not provided as the
training data\footnote{The word sense IDs for them were hidden from
the participants.}.

The number of target words was 50, with 22 nouns, 23 verbs, and 5
adjectives. Fifty instances of each target word were provided,
consisting of a total of 2,500 instances for the evaluation.


\subsection{Statistics of training/test data}

First, we listed 50 target words in the appendix. In the list, we
also showed their POSs and their word classes by the entropy of the
word sense distribution, that we will mention in section seven. `N', `v',
and `a' are an abbreviation of noun, verb, and adjective, respectively.

The number of instances for a new word sense in the training and test
data is 15 and 38, respectively\footnote{
Due to space limits, we unfortunately cannot present the
Jensen Shannon (JS)
divergence \cite{lin:91:a,dagan:97:a} between the word sense
distributions of two different genres.}.


\section{Word sense tagging}

Except for the word sense IDs, the data described in section two was
developed by the National Institute of Japanese Language and Linguistics. However, the
word sense IDs were newly annotated on the data. This
section presents the process of annotating the word sense IDs, and the
analysis of the inter-annotator agreement.


\subsection{Sampling target words}

When we chose target words, we set the following conditions:
\begin{itemize}
\item The POSs of target words were either a noun, a verb, or an adjective.
\item We chose words that occurred more than 50 times in the
training data.
\item The relative ``difficulty'' in disambiguating the sense of words
      was taken into account. 
\pagebreak
 The difficulty of the word {\it w} was defined by the
      entropy of the word sense distribution $E(w)$ in the test
      data \cite{kilgarriff:00:a}. Obviously, the higher $E(w)$ is, the
      more difficult the WSD for {\it w} is.
\item The number of instances for a new sense was also taken into account.
\end{itemize}


\subsection{Manual annotation}

Nine annotators assigned the word sense IDs for the training and
test data. All of them majored in linguistics and had a certain level of linguistic knowledge. The
process of manual annotation was as follows:
\begin{enumerate}
\item An annotator chose a sense ID for each word separately in
accordance with the following guidelines:
\begin{itemize}
\item One sense ID was to be chosen for each word.
\item Sense IDs at any layers in the hierarchical structures were
      assignable.
\item The ``new word sense'' tag was to be chosen only when all sense
      IDs were not absolutely applicable.
\end{itemize}
\item For the instances that had a `new word sense' tag, another
      annotator reexamined them carefully and judged whether those instances really had
      a new sense.
\end{enumerate}
The inter-annotator agreement between the two annotators
  in step (1) was calculated with Kappa statistics for a fragment of the
  corpus tagged by multiple annotators in a preliminary annotation, and it was 0.678.


\section{Evaluation methodology}

The evaluation was returned in the following two ways:
\begin{enumerate}
\item The sense IDs outputted by a system were evaluated, assuming the `new sense' as
   another sense ID. The outputted sense IDs were compared to the
   given gold standard word senses, and the usual precision measure
   for supervised word sense disambiguation systems was computed
   using the scorer. The Iwanami Kokugo Jiten has
   three levels for sense IDs, and we used the middle-level sense in
   the task. Therefore, the scoring in the task was
   `middle-grained scoring'.
\item The ability of finding the instances of new senses was evaluated,
   assuming the task as classifying each instance into a `known sense'
   or `new sense' class. The outputted sense IDs (same as in (1)) were
   compared to the given gold standard word senses, and the usual
   accuracy for binary classification was computed, assuming all
   sense IDs in the dictionary were in the `known sense' class.
\end{enumerate}


\section{Participating systems}

In the Japanese WSD task, 10 organizations registered for
participation. However, only the nine systems from four
organizations submitted the results. In what follows, we outline them
on the basis of the following six aspects:
\begin{enumerate}
\item learning algorithm used,
\item features used,
\item language resources used,
\item level of analysis performed in the system,
\item whether and how the difference in the text genre was taken into account,
\item method to detect new senses of words, if any.
\end{enumerate}
Note that most of the systems used supervised learning techniques.
\begin{itemize}
\item HIT-1\\
(1) Naive Bayes, (2) Word form/POS of the target word, word form/POS before or
after the target word, content words in the context, classes in a
thesaurus for those words in the context, the text genre,
(3) `Bunrui-Goi-Hyou', a Japanese thesaurus \cite{NIJL:64:a},
(4) Morphological analysis, (5) A genre is included in the
features. (6) Assuming that the posterior probability has a normal distribution, 
the system judges those instances deviating from the distribution at
the 0.05 significance level as a new word sense.
\item JAIST-1\\
(1) Agglomerative clustering, (2) Bag-of-words in context, etc. (3) None,
(4) Morphological analysis, (5) The system does not merge example sentences
in different genre sub-corpus into a cluster. (6) First, the system makes
clusters of example sentences, then measures the similarity between a
cluster and a sense in the dictionary, finally regarding the cluster as a
collection of new senses when the similarity is small. For WSD, the
system chooses the most similar sense for each cluster, then it
considers all the instances in the cluster to have that sense.
\item JAIST-2\\
(1) SVM, (2) Word form/POS before or after the target word, content words in
the context, etc. (3) None, (4) Morphological analysis, (5) The system was
trained with the feature set where features are distinguished whether
or not they are derived from only one genre sub-corpus. (6) `New sense'
is treated as one of the sense classes.
\item JAIST-3\\
The system is an ensemble of JAIST-1 and JAIST-2. The judgment of a new
sense is performed by JAIST-1. The output of JAIST-1 is chosen when the
similarity between a cluster and a sense in the dictionary is
sufficiently high. Otherwise, the output of JAIST-2 is used.
\item MSS-1,2,3\\
(1) Maximum entropy, (2) Three word forms/lemmas/POSs
  before or after the target word, bigrams, and skip bigrams in the
  context, bag-of-words in the document, a class of the document
  categorized by a topic classifier, etc. (3) None, (4) None, (5) For each
  target word, the system selected the genre and dictionary examples
  combinations for training data, which got the best results in
  cross-validation. (6) The system calculated the entropy for each target word
  given by the Maximum Entropy Model (MEM). It assumed that high
  entropy (when probabilities of classes are uniformly dispersed) was
  indicative of a new sense. The threshold was tuned by using the
  words with a new sense tag in the training data. Three official
  submissions correspond to different thresholds.
\item RALI-1,2\\
(1) Naive Bayes, (2) Only the `writing' of the words (inside of $<$mor$>$
tag), (3) The Mainichi 2005 corpus of NTCIR, parsed with ChaSen+UniDic,
(4) None, (5) Not taken into account, (6) `New sense' is
  outputted only for the words that have instances for a new word
  sense in the training data.
\end{itemize}
For more details, please refer to their description papers in the
SemEval-2010 workshop \cite{brosseau:10:a,shirai:10:a,fujita:10:a}.


\section{Results}
\label{sec:length}

The evaluation results of all the systems are shown in Tables~1 and
2. ``MFS'' for WSD indicates the results of the baseline that outputed
the `most frequent sense' in the training data.
``Baseline'' for WSD indicates the results of the baseline system
that used SVM with the following features:
\begin{itemize}
\item Morphological features\\
Bag-of-words (BOW), Part-of-speech (POS), and detailed POS
classification. We extract these features from the target word itself
and the two words to the right and left of it.
\item Syntactic features
\begin{itemize}
\item If the POS of a target word is a noun, extract the verb in a grammatical dependency
relation with the noun.
\item If the POS of a target word is a verb, extract the noun in a grammatical dependency
relation with the verb.
\end{itemize}
\item Figures in Bunrui-Goi-Hyou\\
4 and 5 digits regarding the content word to the right and left of the target
word. 
\end{itemize}
The baseline system did not take into account any information on the
text genre. ``Baseline'' for new sense detection (NSD) indicates the
results of the baseline system, which outputs a sense in the
dictionary and never outputs the new sense tag. Precision and recall
for NSD are shown just for reference.
Because relatively few instances for a new word sense were found (38 out of
2500), the task of the new sense detection was found to be rather difficult.

\begin{table}[t]
\begin{minipage}[t]{156pt}
\setlength{\captionwidth}{156pt}
\hangcaption{Results (Precision): Word sense disambiguation.}
\input{04table01.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{244pt}
\setlength{\captionwidth}{244pt}
\hangcaption{Results (Accuracy): New sense detection.}
\input{04table02.txt}
\end{minipage}
\end{table}

Tables~3 and 4 show the results for nouns, verbs, and adjectives.
In our comparison of the baseline system scores for WSD, the score for nouns was the
biggest, and the score for verbs was the smallest (Table~3). However, the
average entropy of nouns was the second biggest (0.7257), and that of
verbs was the biggest (1.194)\footnote{The average entropy of adjectives
was 0.6326.}.

We set up three word classes, $D_{\mathit{diff}} (E(w) \geq 1)$, $D_{mid} (0.5 \leq E(w) <
1)$, and $D_{easy} (E(w) < 0.5)$, based on the relative ``difficulty''
in disambiguating the sense of words that we mentioned in section 3.1.
$D_{\mathit{diff}}$, $D_{mid}$, and $D_{easy}$ consist of 20, 19
and 11 words, respectively. Tables~5 and 6 show the results for each
word class. The results of WSD are quite natural in that the higher $E(w)$
is, the more difficult WSD is, and the more the performance degrades.

\begin{table}[t]
\setlength{\captionwidth}{200pt}
\begin{minipage}[t]{200pt}
  \hangcaption{Results for each POS (Precision): Word sense disambiguation.}
\input{04table03.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{200pt}
  \hangcaption{Results for each POS (Accuracy): New sense detection.}
\input{04table04.txt}
\end{minipage}
\end{table}

\begin{table}[t]
\setlength{\captionwidth}{200pt}
\begin{minipage}[t]{200pt}
  \hangcaption{Results for entropy classes (Precision): Word sense disambiguation.}
\input{04table05.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{200pt}
  \hangcaption{Results for Entropy classes (Accuracy): New sense detection.}
\input{04table06.txt}
\end{minipage}
\end{table}

Lastly, Tables~7 and 8 show the results for each genre of
instances. Test data consists of four genres of instances: books (PB),
newspaper articles (PN), white papers (OW), and documents from a Q\&A
site on the WWW (OC).

The results of WSD are quite natural in that the performance for OC
sharply degrades compared with other genres, since training data does
not contain any instances from the documents from a Q\&A site on the
WWW (OC).

\begin{table}[t]
\setlength{\captionwidth}{200pt}
\begin{minipage}[t]{200pt}
  \hangcaption{Results for each genre (Precision): Word sense disambiguation.}
\input{04table07.txt}
\end{minipage}
\hfill
\begin{minipage}[t]{200pt}
  \hangcaption{Results for each genre (Accuracy): New sense detection.}
\input{04table08.txt}
\end{minipage}
\end{table}



\section{Conclusion}

This paper reported an overview of the SemEval-2 Japanese WSD
task. The number of target words was 50, with 22 nouns, 23 verbs, and
5 adjectives. Fifty instances of each target word were provided,
consisting of a total of 2,500 instances for the evaluation. Nine
systems from four organizations participated in the task.
The data used in this task will be available when you contact the
task organizer and sign a copyright agreement form. We hope this
valuable data helps many researchers improve their WSD systems.



\section*{Appendix}

\begin{enumerate}
\item 「相手」(n, $D_{mid}$)，
\item 「合う」(v, $D_{\mathit{diff}}$)，
\item 「上げる」(v, $D_{\mathit{diff}}$)，
\item 「与える」(v, $D_{\mathit{diff}}$)，
\item 「生きる」(v, $D_{easy}$)，
\item 「意味」(n, $D_{\mathit{diff}}$)，
\item 「入れる」(v, $D_{\mathit{diff}}$)，
\item 「大きい」(a, $D_{easy}$)，
\item 「教える」(v, $D_{mid}$)，
\item 「可能」(n, $D_{mid}$)，
\item 「考える」(v, $D_{easy}$)，
\item 「関係」(n, $D_{mid}$)，
\item 「技術」(n, $D_{mid}$)，
\item 「経済」(n, $D_{easy}$)，
\item 「現場」(n, $D_{mid}$)，
\item 「子供」(n, $D_{mid}$)，
\item 「時間」(n, $D_{mid}$)，
\item 「市場」(n, $D_{\mathit{diff}}$)，
\item 「社会」(n, $D_{mid}$)，
\item 「情報」(n, $D_{mid}$)，
\item 「進める」(v, $D_{\mathit{diff}}$)，
\item 「する」(v, $D_{\mathit{diff}}$)，
\item 「高い」(a, $D_{mid}$)，
\item 「出す」(v, $D_{\mathit{diff}}$)，
\item 「立つ」(v, $D_{\mathit{diff}}$)，
\item 「強い」(a, $D_{easy}$)，
\item 「手」(n, $D_{\mathit{diff}}$)，
\item 「出る」(v, $D_{\mathit{diff}}$)，
\item 「電話」(n, $D_{mid}$)，
\item 「取る」(v, $D_{\mathit{diff}}$)，
\item 「乗る」(v, $D_{\mathit{diff}}$)，
\item 「場合」(n, $D_{mid}$)，
\item 「入る」(v, $D_{\mathit{diff}}$)，
\item 「初め」(n, $D_{mid}$)，
\item 「始める」(v, $D_{mid}$)，
\item 「場所」(n, $D_{easy}$)，
\item 「早い」(a, $D_{mid}$)，
\item 「一つ」(n, $D_{easy}$)，
\item 「開く」(v, $D_{easy}$)，
\item 「文化」(n, $D_{easy}$)，
\item 「外」(n, $D_{easy}$)，
\item 「前」(n, $D_{\mathit{diff}}$)，
\item 「見える」(v, $D_{\mathit{diff}}$)，
\item 「認める」(v, $D_{\mathit{diff}}$)，
\item 「見る」(v, $D_{\mathit{diff}}$)，
\item 「持つ」(v, $D_{\mathit{diff}}$)，
\item 「求める」(v, $D_{mid}$)，
\item 「もの」(n, $D_{mid}$)，
\item 「やる」(v, $D_{easy}$)，
\item 「良い」(a, $D_{mid}$)
\end{enumerate}



\acknowledgment

We would like to thank all the participants and the annotators for
constructing this sense tagged corpus.

\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Agirre \BBA\ de~Lacalle}{Agirre \BBA\
  de~Lacalle}{2008}]{agirre:08:a}
Agirre, E.\BBACOMMA\ \BBA\ de~Lacalle, O.~L. \BBOP 2008\BBCP.
\newblock \BBOQ On Robustness and Domain Adaptation using SVD for Word Sense
  Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of COLING'08}.

\bibitem[\protect\BCAY{Brosseau-Villeneuve, Kando, \BBA\
  Nie}{Brosseau-Villeneuve et~al.}{2010}]{brosseau:10:a}
Brosseau-Villeneuve, B., Kando, N., \BBA\ Nie, J.-Y. \BBOP 2010\BBCP.
\newblock \BBOQ RALI: Automatic Weighting of Text Window Distances.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation}, \mbox{\BPGS\ 375--378}.

\bibitem[\protect\BCAY{Chang \BBA\ Ng}{Chang \BBA\ Ng}{2006}]{chang:06:a}
Chang, Y.~S.\BBACOMMA\ \BBA\ Ng, H.~T. \BBOP 2006\BBCP.
\newblock \BBOQ Estimating Class Priors in Domain Adaptation for WSD.\BBCQ\
\newblock In {\Bem Proceedings of ACL'06}.

\bibitem[\protect\BCAY{Dagan, Lee, \BBA\ Pereira}{Dagan
  et~al.}{1997}]{dagan:97:a}
Dagan, I., Lee, L., \BBA\ Pereira, F. \BBOP 1997\BBCP.
\newblock \BBOQ Similarity-Based Methods For Word Sense Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of the Thirty-Fifth Annual Meeting of the
  Association for Computational Linguistics and Eighth Conference of the
  European Chapter of the Association for Computational Linguistics},
  \mbox{\BPGS\ 56--63}.

\bibitem[\protect\BCAY{Fujita, Duh, Fujino, Taira, \BBA\ Shindo}{Fujita
  et~al.}{2010}]{fujita:10:a}
Fujita, S., Duh, K., Fujino, A., Taira, H., \BBA\ Shindo, H. \BBOP 2010\BBCP.
\newblock \BBOQ MSS: Investigating the Effectiveness of Domain Combinations and
  Topic Features for Word Sense Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation}, \mbox{\BPGS\ 383--386}.

\bibitem[\protect\BCAY{Kilgarriff \BBA\ Rosenzweig}{Kilgarriff \BBA\
  Rosenzweig}{2000}]{kilgarriff:00:a}
Kilgarriff, A.\BBACOMMA\ \BBA\ Rosenzweig, J. \BBOP 2000\BBCP.
\newblock \BBOQ English SENSEVAL: Report and Results.\BBCQ\
\newblock In {\Bem Proceedings LREC'00}.

\bibitem[\protect\BCAY{Lin}{Lin}{1991}]{lin:91:a}
Lin, J. \BBOP 1991\BBCP.
\newblock \BBOQ Divergence measures based on the shannon entropy.\BBCQ\
\newblock {\Bem IEEE Transactions on Information Theory}, {\Bbf 37}  (1),
  \mbox{\BPGS\ 145--151}.

\bibitem[\protect\BCAY{Maekawa}{Maekawa}{2008}]{maekawa:08:a}
Maekawa, K. \BBOP 2008\BBCP.
\newblock \BBOQ Balanced Corpus of Contemporary Written Japanese.\BBCQ\
\newblock In {\Bem Proceedings of the 6th Workshop on Asian Language Resources
  (ALR)}, \mbox{\BPGS\ 101--102}.

\bibitem[\protect\BCAY{{National Institute of Japanese Language}}{{National
  Institute of Japanese Language}}{1964}]{NIJL:64:a}
{National Institute of Japanese Language} \BBOP 1964\BBCP.
\newblock {\Bem Bunruigoihyou}.
\newblock Shuuei Shuppan.
\newblock In Japanese.

\bibitem[\protect\BCAY{Nishio, Iwabuchi, \BBA\ Mizutani}{Nishio
  et~al.}{1994}]{nishio:94:a}
Nishio, M., Iwabuchi, E., \BBA\ Mizutani, S. \BBOP 1994\BBCP.
\newblock {\Bem Iwanami Kokugo Jiten Dai Go Han}.
\newblock Iwanami Publisher.
\newblock In Japanese.

\bibitem[\protect\BCAY{Shirai}{Shirai}{2001}]{shirai:01:a}
Shirai, K. \BBOP 2001\BBCP.
\newblock \BBOQ SENSEVAL-2 Japanese Dictionary Task.\BBCQ\
\newblock In {\Bem Proceedings of SENSEVAL-2: Second International Workshop on
  Evaluating Word Sense Disambiguation Systems}, \mbox{\BPGS\ 33--36}.

\bibitem[\protect\BCAY{Shirai \BBA\ Nakamura}{Shirai \BBA\
  Nakamura}{2010}]{shirai:10:a}
Shirai, K.\BBACOMMA\ \BBA\ Nakamura, M. \BBOP 2010\BBCP.
\newblock \BBOQ JAIST: Clustering and Classification Based Approaches for
  Japanese WSD.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation}, \mbox{\BPGS\ 379--382}.

\end{thebibliography}


\begin{biography}
\bioauthor{奥村　　学}{
1962年生．1984年東京工業大学工学部情報工学科卒業．1989年同大学院博士課
程修了．同年，東京工業大学工学部情報工学科助手．1992年北陸先端科学技術
大学院大学情報科学研究科助教授，2000年東京工業大学精密工学研究所助教授，
2009年同教授，現在に至る．工学博士．自然言語処理，知的情報提示技術，語
学学習支援，テキスト評価分析，テキストマイニングに関する研究に従事．
情報処理学会，電子情報通信学会，人工知能学会, 
AAAI，言語処理学会，
ACL, 認知科学会，計量国語学会各会員．
}
\bioauthor{白井　清昭}{
1993年東京工業大学工学部情報工学科卒業．
1998年同大学院情報理工学研究科博士後期課程修了．
同年同大学院情報理工学研究科計算工学専攻助手．
2001年北陸先端科学技術大学院大学情報科学研究科助教授．
現在同准教授．
博士（工学）．
自然言語処理に関する研究に従事．
言語処理学会，情報処理学会，人工知能学会，ACL各会員．
}

\bioauthor{古宮嘉那子}{
2005年東京農工大学工学部情報コミュニケーション工学科卒．2009年同大大学院
博士後期課程電子情報工学専攻修了．博士（工学）．同年東京工業大学精密工学研究所研究員，
2010年東京農工大学工学研究院特任助教，現在に至る．自然言語処理の研究に従事．
情報処理学会，人工知能学会，言語処理学会各会員．
}

\bioauthor{横野　　光}{
2003年岡山大学工学部情報工学科卒．2008年同大大学院自然科学研究科産業創成
工学専攻単位取得退学．同年東京工業大学精密工学研究所研究員，現在に至る．
博士（工学）．自然言語処理の研究に従事．情報処理学会，言語処理学会各会員．
}
\end{biography}

\biodate




\end{document}
