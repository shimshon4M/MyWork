    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}

\usepackage{mygb4e} 
\usepackage{xspace}
    \newcommand{\blue}[1]{}

\newcommand{\OW}{}
\newcommand{\OC}{}
\newcommand{\PN}{}
\newcommand{\PB}{}
\newcommand{\BK}{}
\newcommand{\WEB}{}
\newcommand{\EX}{}
\newcommand{\LD}{}
\newcommand{\LEX}{}
\newcommand{\KC}{}

\newcommand{\MAI}{}
\newcommand{\NIK}{}

\newcommand{\NEWS}{}

\newcommand{\bl}{}
\newcommand{\bow}{}
\newcommand{\bows}{}
\newcommand{\tp}[1]{}
\newcommand{\tpdist}[1]{}
\newcommand{\twd}[1]{}

\newcommand{\X}{}

\newcommand{\MEM}{}
\newcommand{\SVM}{}
\newcommand{\chasen}{}
\newcommand{\unidic}{}
\newcommand{\bccwj}{}
\newcommand{\lxd}{}

\usepackage[e,j]{mtg2e}


\Volume{18}
\Number{3}
\Month{June}
\Year{2011}

\received{2011}{9}{30}
\accepted{2011}{2}{26}

\setcounter{page}{273}

\jtitle{日本語語義曖昧性解消のための訓練データの自動拡張}
\jauthor{藤田　早苗\affiref{Author_1} \and Kevin Duh\affiref{Author_1} \and 藤野　昭典\affiref{Author_1} \and 平　　博順\affiref{Author_1} \and 進藤　裕之\affiref{Author_1}}
\jabstract{
本稿では，訓練データの自動拡張による語義曖昧性解消の精度向上方法について
述べる．評価対象として，SemEval-2010 日本語語義曖昧性解消タスクを利用した．
本稿では，まず，配布された訓練データのみを利用して学習した場合の結果を紹
介する．更に，辞書の例文，配布データ以外のセンスバンク，ラベルなしコーパ
スなど，
さまざまなコーパスを利用して，訓練データの自動拡張を試
みた結果を紹介する．本稿では，訓練データの自動獲得により 79.5\% 
の精度を得ることができた．
更に，対象語の難易度に基づき，追加する訓練データの上限を制御したところ，
最高 80.0\% 
の精度を得ることができた．
}
\jkeywords{SemEval-2010，例文，コーパス，難易度}

\etitle{Effectiveness of Automatic Expansion of Training Data for Japanese Word Sense Disambiguation}
\eauthor{Sanae Fujita\affiref{Author_1} \and  Kevin Duh\affiref{Author_1} \and Akinori Fujino\affiref{Author_1} \and  \\
	Hirotoshi Taira\affiref{Author_1} \and Hiroyuki Shindo\affiref{Author_1}} 
\eabstract{
In this paper, 
we propose a method to 
expand training data automatically, 
using example sentences of a dictionary, other sensebank and 
unlabelled corpus. 
We tested on the data of SemEval-2010 Japanese WSD task and achieved 
79.5\% accuracy in our experiments. 
Then, we limited the number of used training data and 
achieved 80.0\% accuracy.
}
\ekeywords{SemEval-2010, Example sentences, Corpus, Difficulty Analysis}

\headauthor{藤田，Duh, 藤野，平，進藤}
\headtitle{日本語語義曖昧性解消のための訓練データの自動拡張}

\affilabel{Author_1}{日本電信電話株式会社 NTT コミュニケーション科学基礎研究所}{NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation}



\begin{document}
\maketitle


\section{はじめに} \label{sec:intro}

SemEval-2010 において，日本語の語義曖昧性解消タスクが行われた
\cite{SemEval2:JWSD}．
本タスクは，コーパス中に出現する対象語に対し，辞書で定義された語義のうち
適切な語義を推定することが課題である．
日本語を対象とした類似のタスクとしては，2001年に開催されたSENSEVAL-2の日
本語辞書タスクがあげられる．
ただし，SENSEVAL-2における日本語辞書タスクとは，2 つの点で大きく異なって
いる．すなわち，
対象コーパスの分野が多岐にわたる点，および，
辞書に定義されていない語義が出現することもあるという点で異なっている．

語義曖昧性解消は，非常に古くから取り組まれてきている課題であり，さまざま
な手法が提案されてきている\cite{Navigli:2009}．教師なし学習法も，クラスタ
リングに基づく手法\cite{Pedersen:2006}や，辞書定義文を利用した手法
\cite{Lesk:1986,Baldwin:Kim:Bond:Fujita:Martinez:Tanaka:2010}などが提案さ
れているが，一般に訓練データが存在する場合には，教師あり学習法による精度
の方が高い\cite{Tanaka:Bond:Baldwin:Fujita:Hashimoto:2007}．SENSEVAL-2，
および，SemEval-2010での日本語語義曖昧性解消タスクでも，教師あり学習法に
よる手法が最も高い精度を出している
\cite{SemEval2:JWSD,Murata:Utiyama:Uchimoto:Ma:Isahara:2003j}．そこで，本
稿でも，教師あり学習法をベースとした実験を行った．


しかし，本タスクにおいて，訓練データとして与えられたのは，
各対象語につき50例ずつであり，十分な量とはいい難い．
実際，評価データにしか出現しない語義（未知語義）も存在する．
そのような未知語義は，訓練データのみを用いた学習では推測できない．
また，コンテストに参加したチームで，ドメイン適合性に着目した実験を行っ
たチームもあるが，ドメイン適合性はいずれのチームでもあまり有効に機能して
いない\cite{Shirai:Nakamura:2010,Fujita:Duh:Fujino:Taira:Shindo:2010}．我々
は，その原因が，訓練データの少なさにあると考え，訓練データの自動獲得によ
る精度向上を試みた．本稿ではその報告を行う．



訓練データを自動的に増やす方法としては，まず，Bootstrapping法があげられる．
Bootstrapping法では，まずラベル（語義）の付与された訓練データで学習し，ラベ
ルなしデータのラベルを推定し，ある基準において最も信頼できるものをラベル
ありデータに追加する\cite{Mihalcea:2002,Mihalcea:2004}．ここで，ラベルなしデータ
のラベル推定を決定木で行う研究もある\cite{Yarowsky:1995}．

しかしこれらの方法の場合，ラベルなしデータから，いくら訓練データを追加し
たところで，もともとの訓練データに出現しないような語義を推測することはで
きない，という問題がある．そのため，この方法でも未知語義には対応できない．

また，訓練データを自動的に増やす他の方法として，単義の同義語を利用する方
法も提案されている\cite{Mihalcea:Moldovan:1999,Agirre:Martinez:2000}．彼
らは，
WordNetの同義語(synset)のうち，単義語（例えば，
\eng{``$remember_1$''}に対して\eng{``recollect''}など）や，
定義文(gloss)の中のユニークな表現（例えば，
\eng{``$produce_5$''}に対して，gloss の一部である\eng{``bring onto the
market''}など）を検索語としてWeb検索を行
い，獲得したスニペット中の対象語に語義を付与し，訓練データに追加している．
この方法であれば，未知語義の訓練データを得て，推定できる可能性がある．


そこで，本稿では，基本的に後者の方法に近い方法を導入する．ただし，
\cite{Mihalcea:Moldovan:1999,Agirre:Martinez:2000}らは，WordNetから同義語
等を得ることができたが，本タスクの語義は岩波国語辞典によるため，WordNetの
synsetのような同義語を直接獲得することは難しい．
そこで，定義文中から比較的抽出しやすい例文に着目し，例文を利用した訓練デー
タの獲得を行う．
また，本稿では，既存のコーパスの利用も考える．

本稿では，まず\ref{sec:data}章で，本タスクで配布されたデータ，および，そ
れ以外に本稿で利用したデータについて紹介する．次に\ref{sec:system}章では，
本稿で利用する素性，学習方法について述べる．\ref{sec:result}章では実験
の結果とそれに基づく議論，
\ref{sec:eva-addex}章では自動獲得した訓練データの評価について，
\ref{sec:conclusion}章では結論を述べる．


\section{データ} 
\label{sec:data} 

\subsection{SemEval-2010: Japanese WSD タスク配布データ} 
\label{sec:jwsd}


\ref{sec:intro}章で述べたように，
SemEval-2010: Japanese WSD タスクは，
対象コーパスの分野が多岐にわたるという特徴がある．
訓練データは，白書（以下，\OW{}），新聞(\PN)，本や雑誌(\PB)の分野から成り，
評価データは，更に，Web上のQ\&Aサイトである，Yahoo! 知恵袋（以下，\OC{}）のデータも含んでいる．
これらのデータは，
現代日本語書き言葉均衡コーパス(\bccwj)\footnote{http://www.ninjal.ac.jp/kotonoha/}
のうち，形態素解析の誤りを人手で修正したコアデータと呼ばれる部分から抽出
されている．
なお，形態素解析は，\unidic\footnote{http://www.tokuteicorpus.jp/dist/} に基づいて行われている．

また，本データには，
岩波国語辞典\cite{Nishio:Iwabuchi:Mizutani:1994j}
の語義を元に，語義IDが付与されている．
岩波国語辞典に定義されていない新語義（以下，\X{}）も付与されている場合があり，
それらの新語義を推定することも，課題の一つである．
対象語は50語で，辞典に定義された語義数は219だった．訓練データでは，2
種類の新語義(\X)が出現している．
訓練データと評価データは，各語50文ずつ与えられた．

図~\ref{fig:iwanami}は，本タスクで配布された岩波国語辞典の例である．
図~\ref{fig:iwanami}に示すように，各エントリは，表記，品詞，定義文や例文
などの情報を含んでいる．

図~\ref{fig:trnORG} は，訓練データの例である．ここで，sense=""
で示される部分が，付与されている語義IDを示している．例えば，
図~\ref{fig:trnORG}，6行めの形態素「取っ」の場合，語義ID '37713-0-0-1-1'が
付与されている．但し，図~\ref{fig:trnORG} において，lemma="" の部分は，配
布データには存在していなかった．これは，各形態素の基本形を示しており，カ
タカナによる基本形(bfm)や，出現形
から推測し，我々がほぼ自動的に付与したも
のである．また，図~\ref{fig:trnORG} において，各行頭に付与した番号は，
参照用に便宜的に付与したものである．

\begin{figure}[t]
\includegraphics{18-3ia3f1.eps}
\caption{岩波国語辞典の例：「とる」から抜粋}
\label{fig:iwanami}
\end{figure}
\begin{figure}[t]
\includegraphics{18-3ia3f2.eps}
\caption{訓練データの例} \label{fig:trnORG}
\end{figure}


\subsection{岩波国語辞典の例文} 
\label{sec:iwanami-ex}

本稿では，まず，岩波国語辞典の例文を抽出す
る．図~\ref{fig:iwanami}の例のように，「」で囲ま
れた部分は，各語義の例文になっている．そこで，「」で囲ま
れた部分を例文として抽出する．ここで，``—''の部分は，見出し語を
補完することができる．それにより，
例えば，図~\ref{fig:iwanami}に示した見出し語「とる」の場合，
37713-0-0-1-1の例文として(\ref{s:toru:ex1})，
37713-0-0-3-1の例文として(\ref{s:toru:ex3})，
37713-0-0-6-3の例文として(\ref{s:toru:ex6})などが獲得できる．
また，岩波国語辞典の場合，
例文の前方や後方が，``…''という記号によって省略される場合がある．
例えば，「…に—って」のような形（図~\ref{fig:iwanami}の37713-0-0-3-3）で
ある．こうした``…''は，取り除き，(\ref{s:toru:ex3-3})のような形にした
\footnote{Fujitaら (2010)では，岩波国語辞典の例文をその
まま追加した場合，精度はむしろ低下する傾向にあった．この原因は，``…''等で表
される省略記号などを取り除かず，そのまま利用したこと，
例文そのものは非常に短いものが多く，切れ切れになってしまうことなどが考え
られる．
}．

\begin{exe}
\ex \label{s:toru:ex1}
手を\ul{取}って導く (37713-0-0-1-1)
\ex \label{s:toru:ex3}
責任を\ul{取る} (37713-0-0-3-1)
\ex \label{s:toru:ex6}
数を\ul{取る} (37713-0-0-6-3)
\ex \label{s:toru:ex3-3}
に\ul{とっ}て (37713-0-0-3-3)
\end{exe}


こうして抽出した例文は，形態素解析器
Mecab\footnote{http://mecab.sourceforge.net/}の \unidic{}バージョンで解析
する．
また，例文(\ref{s:toru:ex1})--(\ref{s:toru:ex6})において, ``—''によって
見出し語を補完した部分（\ul{下線部}）には，例文を抽出した語義のIDを付与す
る．
但し，本タスクで推定する語義の粒度は，中語義（ - で区切られた数字の，最後
の部分を除いたもの．37713-0-0-1, 37713-0-0-3等）なので，
実際には，中語義に集約して抽出している．
つまり，例文(\ref{s:toru:ex1})は37713-0-0-1，
(\ref{s:toru:ex3}), (\ref{s:toru:ex3-3})は
37713-0-0-3，(\ref{s:toru:ex6})は37713-0-0-6 の例文として利用する．


\subsection{センスバンク：檜} 
\label{sec:hinoki}


本稿では，更に数種類の言語資源を利用した．

\begin{table}[b]
\caption{「檜」に付与された語義数}
\label{tab:words-counts}
\input{03table01.txt}
\end{table}

まず，基本語意味データベース\lxd
\cite{Lexeed:2004j}，および，センスバンク「檜」
\cite{Bond:Fujita:Tanaka:2006}を利用する．
\lxd{}は，日本人にとって最も馴染みの深い28,270語を収録した辞書である．
収録語は，心理実験によって選定されており，語義毎に語義文と例文がある．
また，各語義文と例文の内容語には，\lxd{}自身の語義が付与されている．
更に，京都大学テキストコーパス
\footnote{http://www-lab25.kuee.kyoto-u.ac.jp/nl-resource/corpus.html}
の内容語に対しても，\lxd{}の語義が付与されている．これらの，\lxd{}によって
語義付与されたセンスバンクを「檜」\cite{Bond:Fujita:Tanaka:2006}と呼んでいる．
檜のサイズを表~\ref{tab:words-counts}に示す．
なお，檜には構文情報も付与されているが，本稿では利用していない．


ここで，\lxd{}と岩波国語辞典の語義は，
語義文の類似度の高いもの同士がリンクされている
\cite{Dridan:Bond:2006}．
そのため，リンクが存在する語義なら，檜で付与されている\lxd{}の語義を
岩波国語辞典の語義に置き換えて，
訓練データとして利用することができる．

例えば，岩波国語辞典の「とる」37713-0-0-6-3の語義文は「数える．測る．」
であり，\lxd{}の19036420-49 の語義文「数える．測定する．」と，非常に類似しており，
リンクされている．このリンクを用いることで，例えば，\lxd{}の19036420-49
の例文(\ref{s:toru:lxd})を，岩波国語辞典の 37713-0-0-6(-3)の訓練データに
追加できる．但し，檜はIPA品詞体系に基づいた形態素解析が行われているため，
\unidic{}によって形態素解析をやりなおし，語義IDのみを\ul{対応箇所}に付与
しなおした．


\begin{exe}
\ex \label{s:toru:lxd}
そこで、医者は患者の顔色を診ながら脈を\ul{取っ}た 。 
\end{exe}



\subsection{現代日本語書き言葉均衡コーパス} 
\label{sec:bccwj}

\ref{sec:jwsd}章で述べたように，本タスクのデータは，
現代日本語書き言葉均衡コーパス(\bccwj)のコアデータから抽出されている．
\bccwj のデータは，モニター公開データとして利用可能である．
但し，コアデータには，人手修正された形態素解析結果が付与されているが，
コアデータ以外の\bccwj には形態素解析結果は付与されていない．
本稿では，\bccwj の2009年度版モニター公開データを利用する．
Readme によると，\bccwj 2009年度版モニター公開データには4,300万語が含ま
れている．

このデータから，\ref{sec:iwanami-ex}章で抽出した岩波国語辞典の例文を利
用し，訓練データを獲得する．まず，\ref{sec:iwanami-ex}章で獲得した例文を
文字の列として完全に含む文を抽出し，形態素解析を行う．更に，対象例文の見出し語と，
基本形，および，品詞大分類が一致する形態素に，該当する例文の語義IDを付与
する．

例えば，37713-0-0-3-3の例文
「にとって」（図~\ref{fig:iwanami}参照）を含む文
として，Yahoo! 知恵袋(\OC{})から，文(\ref{s:toru:oc})を獲得できる．
文(\ref{s:toru:oc})の\ul{下線部}は，\ref{sec:iwanami-ex}章で抽出した例文
(\ref{s:toru:ex3-3})
と一致した部分である．
また，これを形態素解析したものが，図~\ref{fig:getOC}である．


\begin{exe}
\ex \label{s:toru:oc}
 地運の相性を見ても彼はあなた\ul{にとって}最高の相手ですが、
\end{exe}


このように，本手法によって獲得した文はラベルあり訓練データとして追加する．
但し，\bccwj{}には，評価対象文が含まれ
るので，評価対象文と同一の文は利用しないという制限を設けた．

また，新聞データ2年分（日本経済新聞（以下，\NIK{}），毎日新聞(\MAI)）からも，同様に訓練データを抽出し
た．


\subsection{未知語義数，および，獲得データサイズ} 
\label{sec:get-size}

表~\ref{tb:wsnum-test} に，評価データに出現する語義のうち，訓練データにも
出現する語義と，評価データにのみ出現する語義の数を示す．辞書に定義された
全語義は 219語義だが，評価データに出現する語義は，新語義 (\X)を除くと，
142語義($=150-8$)であり，辞書に定義された全語義の64.8\%だった．
また，評価データにのみ出現する語義は9 語義($=15-6$)，18例($=34-16$)だった．


\begin{figure}[t]
\includegraphics{18-3ia3f3.eps}
\caption{新たに獲得した訓練データの例} 
\label{fig:getOC}
\vspace{1\baselineskip}
\end{figure}
\begin{table}[t]
\caption{評価データに出現する語義の種類と出現回数}
\label{tb:wsnum-test}
\input{03table02.txt}
\vspace{1\baselineskip}
\end{table}

また，\ref{sec:iwanami-ex}章から\ref{sec:bccwj}章
で紹介した方法で獲得した訓練データのサイズを，表~\ref{tb:get:size}に示す．
表~\ref{tb:get:size}から，
評価データにのみ出現する9 語義に対しても，
例文(\EX)，檜の両方から  訓練データが獲得できることがわかる．
また，表~\ref{tb:get:size}には，参考のため，訓練データの数値も表示している．

本提案手法では，新語義 (\X)の訓練データは獲得できない．また，
それ以外の語義に対しても，評価データに出現する語義の異なりに対して，訓練データほ
どのカバー率はない．
但し，すべてのコーパスを利用すれば，ほぼ，訓練データに近いカバー率を
得ることができている．


なお，表~\ref{tb:get:size}は，獲得傾向を確認するために，評価データに出現する語
義かどうかを分けて表示しているが，
実験では当然，評価データに出現しない語義の例文であっても区別せずに利用
している．

\begin{table}[t]
\caption{新たに獲得した訓練データの数} 
\label{tb:get:size}
\input{03table03.txt}
\end{table}



\section{実験} 
\label{sec:system}


\subsection{学習器} 
\label{sec:exp}

学習には，代表的な識別モデルの一つであり，ラベルありデータを用いて教師
あり学習を行う最大エントロピーモデル(Maximum Entropy Method: \MEM, 
\cite{Nigam:Lafferty:McCallum:1999}) を用いた．
これは，
Fujitaら (2010)によると，Support Vector
Machine (\SVM, \cite{libsvm})より，
\MEM{}
の精度がはるかに良かったためである．


\subsection{素性} 
\label{sec:fea}

{\bf [基本素性]}
まず，語義曖昧性解消タスクで一般的に利用される素性を，基本素性として利用
する．

各対象語 $w$ に対し，出現形，基本形，品詞，品詞大分類（名詞，動詞，形容詞
など）を利用する．また，対象語が$i$番目の語だとすると，前後2語(
$i - 2$, $i - 1$, $i + 1$, $i + 2$)の同じ情報も利用する．更に，前後3語以内の
bigrams, trigrams, skipbigramsも利用する．これらの素性を利用したモデルを
\bl{}とする．

{\bf [Bag-of-Words]}
各対象語 $w$ に対し，同一文内に出現する全内容語の基本形を素性として利用する．
これらの素性を利用したモデルを\bows{}とする．


{\bf [トピック素性]}
SemEval-2007 English WSD タスクでは，トピック情報を利用したシステムが，最
も高い精度を得ている\cite{Cai:Lee:Teh:2007}．Caiら(2007)の研
究を参考に，トピック情報を利用した素性を導入した．
Caiらは，Bayesian topic models (Latent Dirichlet Allocation: LDA) を用い
て教師なし状態でトピック分類を行い，
推定したトピックを素性として利用している．

本稿では，訓練データと評価データに
gibbslda++\footnote{http://gibbslda.sourceforge.net/} を適用し，文書（ファ
イル）単位でトピック分類を行った．但し，新聞(\PN)の場合のみ，記事毎に分
類した．これは，新聞の場合は，記事毎に，内容ががらりと変わることがあるが，
それ以外の文書（書籍やYahoo! 知恵袋，白書など）では，がらりと変わると思わ
れなかったためである．また，一つの文書，あるいは記事は，複数のトピック
に含まれることがある．

本稿では，対象語が属する文書，あるいは記事の含まれるトピック分類を素性と
して利用し，これらの素性を利用したモデルを\tp{X}とする．ここで，Xは，トピッ
ク数であり，Xが多ければ多いほど，分類が細かいことになる．


\section{結果と議論}
\label{sec:result}


\subsection{配布データのみを利用} 
\label{sec:result-given}

Fujitaら (2010) によると，対象語毎に訓練データの分野の組合せを変えて学習する
より，分野に関係なくすべての訓練データを学習に用いる方が精度が良い．学習
器は，前述のように\MEM{}を用いる．
表~\ref{tb:result-given}に，すべての訓練データを学習に用い，素性の組合せ
を変えた場合の結果を示す．パラメータは，訓練データにおける対象語
毎の交差検定で最も良い精度を出したものを用いている．
また，表~\ref{tb:result-given}には，参考として，SemEval-2010でのBest result
(RALI-2 \cite{Brosseauvilleneuve:Kando:Nie:2010})も掲載している．

更に，対象語を難易度毎に分けて傾向を分析する．
そのため，SENSEVAL-2 の日本語辞書タスクと同様に，
訓練データにおける語義の頻度分布のエントロピー$E(w)$
（式(\ref{s:entropy})）を，単語の難易度の目安として利用し，対象語を，
高難易度($D_{diff}$, $E(w) \geq 1 $)，
中難易度($D_{mid}$, $0.5 \leq E(w) < 1 $)，
低難易度($D_{easy}$, $E(w) < 0.5 $)の
3つにわけた\cite{Shirai:2003j}．
式(\ref{s:entropy})において，$p(s_{i}|w)$ は，単語$w$の語義が$s_i$となる
確率を表している．
\begin{equation}
\label{s:entropy}
E(w) = - \sum_{i}^{} p(s_{i}|w) \log {p(s_{i}|w)}
\end{equation}



各難易度に含まれる対象語の数は，それぞれ，
$D_{diff}$で9語，
$D_{mid}$で20語，
$D_{easy}$で21語だった．対象語の詳細を，表~\ref{tb:wd-diff}に示す．


\begin{table}[t]
\caption{難易度毎の対象語} 
\label{tb:wd-diff}
\input{03table04.txt}
\end{table}
\begin{table}[t]
\caption{素性毎の精度 (Precision, \%)} 
\label{tb:result-given}
\input{03table05.txt}
\end{table}

表~\ref{tb:result-given}によると，基本素性(\bl)だけを利用した場合でも，
SemEval-2010のBest result (76.4\%)より高い精度(77.7\%)が得られた．
最も精度が高かったのは，トピック素性を利用した場合(\bl +\tp{200})
(78.0\%)だった．
\bow{}を素性として利用する場合は，精度はかえって低下する傾向にある
\footnote{但し，
有意水準 5\% のt-検定を行ったところ，いずれも有意差は
なかった．}．


なお，\bl+\tp{200} で最も精度が高かった対象語は，
「外」（精度 100\%），「経済」(98\%)，「考える」(98\%)，
「大きい」(98\%)，「文化」(98\%)などである．
一方，最も精度の低かった語は，「取る」(36\%)，「良い」(48\%)，
「上げる」(48\%)，「出す」(50\%)，「立つ」(54\%)などである．




\subsection{自動獲得した訓練データも利用} 
\label{sec:result-add}


本節では，自動獲得した訓練データ（表~\ref{tb:get:size}参照）を利用した場合の
結果について紹介する（表~\ref{tb:result-add}）．表~\ref{tb:result-add}では，
素性は基本素性(\bl)のみ利用し，学習器は\MEM{}を利用した．

基本素性(\bl)を用いて，配布された訓練データのみで学習した場合の精度
を基準とすると，
難易度別に傾向が非常に異なることがわかる．
低難易語の場合，訓練データを追加すると，ほとんどの場合で
精度が低下している．
それどころか，精度が最も高いのは，最頻語義を利用したBase Lineである．
しかし，中難易語では，精度向上する場合の方が多くなり，高難易語では，
すべての場合で，精度が向上している．
特に，自動獲得したすべての訓練データを追加した場合，
低難易語では最も精度が低くなり，高難易語では最も精度が高くなっている．

\begin{table}[t]
\caption{自動獲得した訓練データも利用した場合の精度(\%) （基本素性(\bl)のみ利用）} 
\label{tb:result-add}
\input{03table06.txt}
\end{table}

これはつまり，そもそも低難易語の場合には，誤りを含むかもしれない訓練デー
タの追加は，むしろマイナスに働く可能性が高いが，
中・高難易語の場合，
訓練データに含まれる誤りによる悪影響より，
訓練データが増えることによる好影響の方が
強いことが伺える．


また，表~\ref{tb:result-add}には，
配布訓練データを用いず，自動獲得したすべての訓練データだけを用いた場合
の実験結果も載せている．それによると，低・中難易度では，
配布訓練データを用いた精度に及ばないが，高難易度では，配布訓練データのみ
を用いる場合より高い精度を得ることができた．このように，自動獲得した訓練
データのみを利用した場合も善戦はしているが，配布訓練データも利用した場合
の方が相当精度が高い（最大11.1ポイント差）．この原因は，(1) 特に\bccwj と新聞デー
タは，岩波の例文を含む文のみを抽出しているため，訓練データのバリエーショ
ンに乏しい，(2) 例文によって，獲得できる訓練データ数に非常にばらつきがあ
り，自然な分布にならない，(3) 自動獲得しているため誤りが含まれる，などが
考えられる．


また，岩波の例文そのものを追加した場合，精度は若干低下する．しかし，例文
を用いて訓練データを追加した，\bccwj{}も新聞も，\OW{}を除いて，精度向上が見ら
れる．

これは，例文そのものは非常に短いものが多く，切れ切れになってしまうが，
例文を含む文全体を追加することで，もう少し広い前後の語などの情報も利用
できるために，精度が向上したのだと考えられる\footnote{ 但し，
有意水準 5\% のt-検定を行ったところ，いずれも有意差は
なかった．}．


また，本手法の利点の一つに，訓練データで出現しない語義に対しても，訓練データを
追加できることがある．
そこで，評価データにしか出現しなかった未知語義（9 語義 18 例，\ref{sec:get-size}
節参照）に対する精度のみを確認した．
訓練データに出現しない語義なので，訓練データのみ利用した場合，精度は0\%である．
表~\ref{tb:result-unseen}に，改良があった結果のみ表示する．
表~\ref{tb:result-unseen}によると，すべて追加した場合でも，2例正解しただ
けであるが，訓練データだけでは絶対に正解できなかった部分であり，
意義は大きい．


\begin{table}[b]
\caption{未知語義（18 例）に対する精度（基本素性）} 
\label{tb:result-unseen}
\input{03table07.txt}
\end{table}



\subsection{学習曲線} 
\label{sec:result-lc}

前節では，各コーパスから追加可能な文はすべて追加して学習した．
本節では，過学習していないか調べるため，追加する文数と精度との関連を調べた．
\bccwj{}や新聞データの場合，岩波の例文を完全に含む文を追加するため，
例文毎に追加できる最大の文数を設定し，精度との関係を調べた．
つまり例えば，最大追加文数を5文と設定する場合，
例文(\ref{s:toru:ex1})--(\ref{s:toru:ex3-3})のそれぞれに対し，
条件を満たす文のうち，最初に出てきた5文までを訓
練データとして追加する．但し，当然，最大の文数まで獲得できない場合もある．

表~\ref{tb:result-lc-BK}は，表~\ref{tb:result-add} で最も良い精度を出した
\PB{}を用いた場合の結果である．また，参考までに，
図~\ref{fig:result-lc-BK}に学習曲線を示した．

表~\ref{tb:result-lc-BK} および 図~\ref{fig:result-lc-BK} から，
難易度によって，学習曲線が大きく異なることがわかる．
低難易語の場合，10文追加までは，かろうじて精度が向上している．
しかし，その後は，訓練データを追加すればするほど，精度が低下している．
一方で，中・高難易語に対しては，
訓練データを追加した方が精度は向上する．
特に，高難易語での精度向上が大きい
\footnote{有意水準 5\% のt-検定を行ったところ，追加文数を制御したすべての
場合で配布訓練データのみを利用する場合に対して有意差があった．}．


\begin{table}[t]
\caption{岩波例文毎に追加する最大文数を制限する場合（難易度別, 基本素性利用, \BK）(\%)} 
\label{tb:result-lc-BK}
\input{03table08.txt}
\end{table}
\begin{figure}[t]
\begin{center}
\includegraphics{18-3ia3f4.eps}
\end{center}
\caption{岩波例文毎に追加する最大文数を制限する場合（基本素性, \BK）}
\label{fig:result-lc-BK}
\end{figure}

この結果から，
低難易語には訓練データをほとんど追加せず，中・高難易語には
訓練データを追加する方がいいことがわかる．
表~\ref{tb:result-lc-BK}の「参考」に，中・高難易語にのみ，300文を上限に訓練
データを追加した場合の結果を示す．但し，本稿の手法の利点の一つは，訓練デー
タに出現しなかった語義にも訓練データを獲得できることであるため，訓練
データに出現していない語義に対しては，低難易語であっても訓練データを5文
を上限として追加している．この場合，低難易語の精度は下がらず，全体精度は
80.0\%を達成，未知語義も1例正解できた．




\section{自動獲得した訓練データの評価} 
\label{sec:eva-addex}


本節では，\ref{sec:bccwj}章の訓練データの自動獲得方法で
獲得した訓練データに正しい語義が付与されているかどうかを評価した．

評価対象には，前節（\ref{sec:result-lc}節）で
利用した\BK{}において，追加できる最大文数を5文とした場合に
獲得されたデータを用いた．
この条件では，47語，114語義に対し，1,038文が獲得されている．
人手評価の結果，正しい訓練データだったものは979文 (94.3\%) ，
誤っていたものは59文 (5.7\%)だった．
このように5.7\%の誤りを含んでいたものの，表~\ref{tb:result-lc-BK}による
と，全体で1.4\%の精度の向上が見られており追加の効果は高い．


誤った訓練データを獲得した原因で最も多かったのは，慣用表現である．
例えば，語義ID 20676-0-0-1 「ある時刻と他の時刻との間（の長さ）．」の例文「時間の問題」は慣用的な表現である\footnote{（その物事の結着まで長くはかかるまいという情況にまで立ち至った
こと）との注釈がある}．しかし，
獲得された5文のうち，1文は，文(\ref{s:toru:error3})であり，
語義ID 20676-0-0-3 「空間と共に，物体界を成り立たせる基礎形式と考えるも
の．」の方がふさわしいだろう．


\begin{exe}
\ex \label{s:toru:error3}
この本はむずかしい\ul{時間の問題}を、抽象的な時間論というかたちではなく、...
\end{exe}


慣用表現かどうかの判定は非常に難しく\cite{Hashimoto:2008j}，
本稿の手法で，慣用表現による誤りを取り除くことは困難である．
すべての誤りを取り除くには，慣用表現辞書\cite{Hashimoto:2008bj}
などを利用し，慣用表現と思しき表現を利用しないことにするか，
最終的に人手による判断が必要だろう．

次に多かった誤りは，対象語以外の形態素区切りの不一致によるものだった．

例えば，37713-0-0-6の例文「数を取る」の場合，文(\ref{s:toru:error1})が獲
得されている．しかし，37713-0-0-6 は「数える」という意味なので，文
(\ref{s:toru:error1})は誤りである．

\begin{exe}
\ex \label{s:toru:error1}
ペーパーテストではいい点\ul{数を取る}のかもしれませんがね。
\end{exe}


\ref{sec:bccwj}節で述べたように，訓練データの追加条件は，例文を完全に含む
こと以外にも，「対象例文の見出し語と，基本形，および，品詞大分類が一致す
る形態素に，該当する例文の語義IDを付与する．」という条件がある．
しかし，見出し語以外は，形態素解析結果が一致するかは確認していない．
だが，文(\ref{s:toru:error1})の場合，動詞「取る」の目的語部分（「数」と「点数」）は異なっているため，
例文側も形態素解析し，前後の形態素も含めて一致する文だけを訓練デー
タに追加すれば，排除できる誤りである．



ここまで述べたように，自動獲得した訓練データには誤りが含まれる．
しかし，1,038文の正誤評価には1日とかからなかったので
\footnote{正誤評価のときには，対象語と定義文，例文を提示し，例文毎に，自動獲得したデータ
をまとめて表示した．また，例文に一致した部分にはマークをつけ，わかりやすく表示した．}，
慣用表現のような，人手判断が必要な表現であっても，
1日の人手作業で，正しい訓練データを4割近く増やすことができること
になる．また，自動獲得では間違いやすい部分のみ，人手作業を行うことも
可能である．
そのようにして，効率的に正確な訓練データを増やすことも，今後，選択肢の一つにな
ると考えられる．


\section{おわりに} 
\label{sec:conclusion}

本稿では，訓練データの自動拡張による語義曖昧性解消の精度向上方法について
述べた．評価対象として，SemEval-2010 日本語語義曖昧性解
消タスクを利用した．

本稿では，辞書の例文，配布データ以外のセンスバンク（檜），ラベルなしコーパ
ス(\bccwj), 新聞データなど，
さまざまなコーパスを利用して，訓練データの自動拡張を試みた．

配布データ以外のセンスバンク（檜）を利用する場合，語義が定義された辞書同士
のリンクを経由して，訓練データを獲得した．辞書同士のリンクは，定義文同士
の類似度によって構築されている．
檜を追加した場合，78.8\%の精度を得ることができた．
これは，配布データのみを利用した場合の結果(77.7\%)より，+1.2\%の改良で
ある．

このように，異なる品詞体系，異なる辞書（語義）に基づいて構築されたセンスバ
ンクであっても，自動的に訓練データに追加し，精度向上に寄与できることを示
した．人手で構築する言語資源は，構築のための時間と費用が非常にかかるため，
こうした既存言語資源の有効利用は，ますます重要になると考えれられる．


また，センスバンク以外のラベルなしデータを用いる場合，辞書の例文を
文字の列として
完全に含み，かつ，形態素解析の結果，対象語と，基本形，および，品詞大分類が一致
するものを訓練データとして追加した．

最も良い精度を出したラベルなしデータは，書籍（\bccwj{}の\BK{}）であり，
79.5\% (+1.8\%) の精度を得た．
ここで，追加した例文のうち，1,038文をサンプリング評価したところ，94.3\%に正しい語義が付与されていた．
このように，自動獲得した訓練データには誤りも含まれるものの，
例文そのものを追加するより，本稿の提案手法のように，
例文を完全に含む，より自然な文を利用する方が効果が高いことを示した．


難易度に基づいて傾向を分析した結果，
低難易語には訓練データを追加せず，中・高難易語には
訓練データを追加する方がいいことがわかった．
そのため，中・高難易語と未知語義にのみ訓練データを追加した場合，
最高80.0\% の精度を得た．



このように，本稿で紹介したような訓練データの追加は，非常に有効であると言
える．

最後に，今後の課題として以下の3点を挙げる．

\begin{enumerate}
  \item 訓練データを追加する場合（\ref{sec:result-add}章参照）も，トピック素
性を利用して実験を行う．配布データのみを利用した場合には，トピック
素性を利用した場合がもっとも良かった（\ref{sec:result-given}章参照）ためで
ある．

  \item 辞書定義文から同義語を獲得し，
\cite{Mihalcea:Moldovan:1999,Agirre:Martinez:2000}らと同様に，同義語を用
いた訓練データの拡張も行う．本稿では，辞書の例文に完全一致する語を訓練
データとして追加したが，本手法の場合，そもそも辞書に全く例文がない場合に
は，新しい訓練データは獲得できない．
同義語も利用すれば，例文のみでは訓練データを新たに獲得できなかった語義について
も新しい訓練データを追加できるかもしれない．
また，例文に完全一致する文のみの追加では，訓練データに偏りが出る恐れがあるが，
その点を補完できると期待できる．

\item 
ラベルなしデータを利用した半教師あり学習法\cite{Fujino:Ueda:Saito:2008}に
よる精度向上を図る．半教師あり学習を適用する場合
でも，始めに与える訓練データにない語義は，ラベルなしデータをいくら与えた
ところで推定できない．そのため，本稿のようにあらかじめ低頻度語の訓練デー
タを追加しておくことは重要だと思われる．
\end{enumerate}




\acknowledgment

SemEval-2010 Japanese WSD task に関しまして，データ整備，運営，開催
等にご尽力された皆様に感謝いたします．また，「『現代日本語書き言葉均衡コー
パス』モニター公開データ（2009年度版）」に関しまして，使用を許可して下さっ
た独立行政法人国立国語研究所に感謝いたします．



\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Agirre \BBA\ Martinez}{Agirre \BBA\
  Martinez}{2000}]{Agirre:Martinez:2000}
Agirre, E.\BBACOMMA\ \BBA\ Martinez, D. \BBOP 2000\BBCP.
\newblock \BBOQ {Exploring Automatic Word Sense Disambiguation with Decision
  Lists and the Web.}\BBCQ\
\newblock {\Bem CoRR}, \mbox{\BPGS\ 11--19}.

\bibitem[\protect\BCAY{Baldwin, Kim, Bond, Fujita, Martinez, \BBA\
  Tanaka}{Baldwin et~al.}{2010}]{Baldwin:Kim:Bond:Fujita:Martinez:Tanaka:2010}
Baldwin, T., Kim, S.~N., Bond, F., Fujita, S., Martinez, D., \BBA\ Tanaka, T.
  \BBOP 2010\BBCP.
\newblock \BBOQ {A reexamination of MRD-based word sense disambiguation.}\BBCQ\
\newblock {\Bem Transactions on Asian Language Information Process, Association
  for Computing Machinery (ACM)}, \textbf{9} (1), \mbox{\BPGS\ 1--21}.

\bibitem[\protect\BCAY{Bond, Fujita, \BBA\ Tanaka}{Bond
  et~al.}{2006}]{Bond:Fujita:Tanaka:2006}
Bond, F., Fujita, S., \BBA\ Tanaka, T. \BBOP 2006\BBCP.
\newblock \BBOQ {The hinoki syntactic and semantic treebank of Japanese.}\BBCQ\
\newblock {\Bem Language Resources and Evaluation}, \textbf{40} (3/4),
  \mbox{\BPGS\ 253--261}.
\newblock (Special issue on Asian language technology).

\bibitem[\protect\BCAY{Brosseau-Villeneuve, Kando, \BBA\
  Nie}{Brosseau-Villeneuve et~al.}{2010}]{Brosseauvilleneuve:Kando:Nie:2010}
Brosseau-Villeneuve, B., Kando, N., \BBA\ Nie, J.-Y. \BBOP 2010\BBCP.
\newblock \BBOQ {RALI: Automatic Weighting of Text Window Distances.}\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation (SemEval-2010)}, \mbox{\BPGS\ 375--378}.

\bibitem[\protect\BCAY{Cai, Lee, \BBA\ Teh}{Cai
  et~al.}{2007}]{Cai:Lee:Teh:2007}
Cai, J.~F., Lee, W.~S., \BBA\ Teh, Y.~W. \BBOP 2007\BBCP.
\newblock \BBOQ NUS-ML: Improving Word Sense Disambiguation Using Topic
  Features.\BBCQ\
\newblock In {\Bem Proceedings of the Fourth International Workshop on Semantic
  Evaluations (SemEval-2007)}, \mbox{\BPGS\ 249--252}.

\bibitem[\protect\BCAY{Chang \BBA\ Lin}{Chang \BBA\ Lin}{2001}]{libsvm}
Chang, C.-C.\BBACOMMA\ \BBA\ Lin, C.-J. \BBOP 2001\BBCP.
\newblock {\Bem {LIBSVM}: a library for support vector machines}.
\newblock Software available at http://www.csie.ntu.edu.tw/{\textasciitilde}cjlin/libsvm.

\bibitem[\protect\BCAY{Dridan \BBA\ Bond}{Dridan \BBA\
  Bond}{2006}]{Dridan:Bond:2006}
Dridan, R.\BBACOMMA\ \BBA\ Bond, F. \BBOP 2006\BBCP.
\newblock \BBOQ {Sentence Comparison using Robust Minimal Recursion Semantics
  and an Ontology}\BBCQ\
\newblock In {\Bem Workshop on Linguistic Distances}, \mbox{\BPGS\ 35--42}.

\bibitem[\protect\BCAY{Fujino, Ueda, \BBA\ Saito}{Fujino
  et~al.}{2008}]{Fujino:Ueda:Saito:2008}
Fujino, A., Ueda, N., \BBA\ Saito, K. \BBOP 2008\BBCP.
\newblock \BBOQ Semi-supervised learning for a hybrid generative/discriminative
  classifier based on the maximum entropy principle\BBCQ\
\newblock {\Bem IEEE Transactions on Pattern Analysis and Machine Intelligence
  (TPAMI)}, \textbf{30} (3), \mbox{\BPGS\ 424--437}.

\bibitem[\protect\BCAY{Fujita, Duh, Fujino, Taira, \BBA\ Shindo}{Fujita
  et~al.}{2010}]{Fujita:Duh:Fujino:Taira:Shindo:2010}
Fujita, S., Duh, K., Fujino, A., Taira, H., \BBA\ Shindo, H. \BBOP 2010\BBCP.
\newblock \BBOQ MSS: Investigating the Effectiveness of Domain Combinations and
  Topic Features for Word Sense Disambiguation.\BBCQ\
\newblock In {\Bem the 5th International Workshop on Semantic Evaluation
		(SemEval-2010)},
  \mbox{\BPGS\ 383--386}. 

\bibitem[\protect\BCAY{橋本\JBA 河原}{橋本\JBA 河原}{2008a}]{Hashimoto:2008bj}
橋本力\JBA 河原大輔 \BBOP 2008a\BBCP.
\newblock 慣用句の検出と格解析のための言語資源の構築.\ 
\newblock \Jem{言語処理学会第14回年次大会発表論文集}, \mbox{\BPGS\ 1148--1151}.

\bibitem[\protect\BCAY{橋本\JBA 河原}{橋本\JBA 河原}{2008b}]{Hashimoto:2008j}
橋本力\JBA 河原大輔 \BBOP 2008b\BBCP.
\newblock 日本語慣用句コーパスの構築と慣用句曖昧性解消の試み.\ 
\newblock \Jem{電子情報通信学会 言語理解とコミュニケーション研
  究会}, \mbox{\BPGS\ 1--6}.

\bibitem[\protect\BCAY{笠原\JBA 佐藤\JBA Francis\JBA 田中\JBA 藤田\JBA 金杉\JBA
  天野}{笠原\Jetal }{2004}]{Lexeed:2004j}
笠原要\JBA 佐藤浩史\JBA Francis Bond\JBA 田中貴秋\JBA 藤田早苗\JBA 金杉友子\JBA
  天野昭成 \BBOP 2004\BBCP.
\newblock 「基本語意味データベース：Lexeed」の構築\
\newblock \Jem{情報処理学会 自然言語処理研究会 (2004-NLC-159)}, \mbox{\BPGS\
  75--82}.

\bibitem[\protect\BCAY{Lesk}{Lesk}{1986}]{Lesk:1986}
Lesk, M. \BBOP 1986\BBCP.
\newblock \BBOQ Automatic Sense Disambiguation using Machine Readable
  Dictionaries: How to Tell a Pine Cone from an Ice Cream Cone.\BBCQ\
\newblock In {\Bem Proceedings of the 5th Annual International Conference on
  Systems Documentation}, \mbox{\BPGS\ 24--26}.

\bibitem[\protect\BCAY{Mihalcea}{Mihalcea}{2002}]{Mihalcea:2002}
Mihalcea, R. \BBOP 2002\BBCP.
\newblock \BBOQ Bootstrapping Large Sense Tagged Corpora.\BBCQ\
\newblock In {\Bem Proceedings of the 3rd International Conference on Language
  Resources and Evaluation (LREC-2002)}, \mbox{\BPGS\ 1407--1411}.

\bibitem[\protect\BCAY{Mihalcea}{Mihalcea}{2004}]{Mihalcea:2004}
Mihalcea, R. \BBOP 2004\BBCP.
\newblock \BBOQ Co-training and Self-training for Word Sense
  Disambiguation.\BBCQ\
\newblock In {\Bem Proceedings of the Conference on Natural Language Learning
  (CoNLL-2004)}, \mbox{\BPGS\ 33--40}.

\bibitem[\protect\BCAY{Mihalcea \BBA\ Moldovan}{Mihalcea \BBA\
  Moldovan}{1999}]{Mihalcea:Moldovan:1999}
Mihalcea, R.\BBACOMMA\ \BBA\ Moldovan, D. \BBOP 1999\BBCP.
\newblock \BBOQ An Automatic Method for Generating Sense Tagged Corpora.\BBCQ\
\newblock In {\Bem Proceedings of the American Association for Artificial
  Intelligence (AAAI-1999)}, \mbox{\BPGS\ 461--466}.

\bibitem[\protect\BCAY{村田\JBA 内山\JBA 内元\JBA 馬\JBA 井佐原}{村田\Jetal
  }{2003}]{Murata:Utiyama:Uchimoto:Ma:Isahara:2003j}
村田真樹\JBA 内山将夫\JBA 内元清貴\JBA 馬青\JBA 井佐原均 \BBOP 2003\BBCP.
\newblock 技術資料 {SENSEVAL-2J}辞書タスクでの{CRL}の取り組み—
  日本語単語多義性解消における種々の機械学習手法と素性 の比較. 
\newblock \Jem{自然言語処理}, \textbf{10} (3), \mbox{\BPGS\ 115--134}.

\bibitem[\protect\BCAY{Navigli}{Navigli}{2009}]{Navigli:2009}
Navigli, R. \BBOP 2009\BBCP.
\newblock \BBOQ Word sense disambiguation: A survey.\BBCQ\
\newblock {\Bem ACM Comput. Surv.}, \textbf{41} (2), \mbox{\BPGS\ 1--69}.

\bibitem[\protect\BCAY{Nigam, Lafferty, \BBA\ McCallum}{Nigam
  et~al.}{1999}]{Nigam:Lafferty:McCallum:1999}
Nigam, K., Lafferty, J., \BBA\ McCallum, A. \BBOP 1999\BBCP.
\newblock \BBOQ Using Maximum Entropy for Text Classification.\BBCQ\
\newblock In {\Bem IJCAI-99 Workshop on Machine Learning for Information
  Filtering}, \mbox{\BPGS\ 61--67}.

\bibitem[\protect\BCAY{西尾\JBA 岩淵\JBA 水谷}{西尾\Jetal
  }{1994}]{Nishio:Iwabuchi:Mizutani:1994j}
西尾実\JBA 岩淵悦太郎\JBA 水谷静夫 \BBOP 1994\BBCP.
\newblock \Jem{岩波国語辞典}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{Okumura, Shirai, Komiya, \BBA\ Yokono}{Okumura
  et~al.}{2010}]{SemEval2:JWSD}
Okumura, M., Shirai, K., Komiya, K., \BBA\ Yokono, H. \BBOP 2010\BBCP.
\newblock \BBOQ SemEval-2010 Task: Japanese WSD.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation (SemEval-2010)}, \mbox{\BPGS\ 69--74}.

\bibitem[\protect\BCAY{Pedersen}{Pedersen}{2006}]{Pedersen:2006}
Pedersen, T. \BBOP 2006\BBCP.
\newblock {\Bem Word Sense Disambiguation: Algorithms and Applications}, 
  \textbf{33}, \BCH~6, \mbox{\BPGS\ 133--166}.
\newblock Springer.

\bibitem[\protect\BCAY{Shirai \BBA\ Nakamura}{Shirai \BBA\
  Nakamura}{2010}]{Shirai:Nakamura:2010}
Shirai, K.\BBACOMMA\ \BBA\ Nakamura, M. \BBOP 2010\BBCP.
\newblock \BBOQ {JAIST: Clustering and Classification Based Approaches for
  Japanese WSD.}\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Workshop on Semantic
  Evaluation (SemEval-2010)}, \mbox{\BPGS\ 379--382}.

\bibitem[\protect\BCAY{白井}{白井}{2003}]{Shirai:2003j}
白井清昭 \BBOP 2003\BBCP.
\newblock {SENSEVAL-2} 日本語辞書タスク.\
\newblock \Jem{自然言語処理}, \textbf{10} (3), \mbox{\BPGS\ 3--24}.

\bibitem[\protect\BCAY{Tanaka, Bond, Baldwin, Fujita, \BBA\ Hashimoto}{Tanaka
  et~al.}{2007}]{Tanaka:Bond:Baldwin:Fujita:Hashimoto:2007}
Tanaka, T., Bond, F., Baldwin, T., Fujita, S., \BBA\ Hashimoto, C. \BBOP
  2007\BBCP.
\newblock \BBOQ {Word Sense Disambiguation Incorporating Lexical and Structural
  Semantic Information}.\BBCQ\
\newblock In {\Bem Proceedings of the 2007 Joint Conference on Empirical
  Methods in Natural Language Processing and Computational Natural Language
  Learning (EMNLP-CoNLL-2007)}, \mbox{\BPGS\ 477--485}.

\bibitem[\protect\BCAY{Yarowsky}{Yarowsky}{1995}]{Yarowsky:1995}
Yarowsky, D. \BBOP 1995\BBCP.
\newblock \BBOQ Unsupervised Word Sense Disambiguation Rivaling Supervised
  Methods.\BBCQ\
\newblock In {\Bem Proceedings of the 33rd Annual Meeting of the Association
  for Computational Linguistics (ACL-93)}, \mbox{\BPGS\ 189--196}.

\end{thebibliography}



\begin{biography}
\bioauthor{藤田　早苗}{
1997年大阪府立大学工学部航空宇宙工学科卒業．
1999年奈良先端科学技術大学院大学情報科学研究科博士前期課程修了．
同年4月よりNTT日本電信電話株式会社コミュニケーション科学基礎研究勤務．
以来，自然言語処理の研究に従事．
また，2009年3月奈良先端科学技術大学院大学にて博士号（工学）取得．
ACL，言語処理学会各会員．
}

\bioauthor[:]{Kevin Duh}{
Kevin has been a research associate at NTT CS Labs since 2009/09. He
received his B.S. from Rice University (USA) in 2003, and PhD from the
University of Washington (USA) in 2009, both in Electrical Engineering. 
He is interested in natural language processing, information retrieval, and machine learning
research.
}


\bioauthor{藤野　昭典}{
1995年京都大学工学部精密工学科卒業．
1997年同大学大学院修士課程修了．
2009年同大学大学院博士課程修了．
博士（情報学）．
1997年NTT入社．
機械学習，テキスト処理などの研究に従事．
現在，NTTコミュニケーション科学基礎研究所 研究主任．
電子情報通信学会PRMU研究奨励賞（2004年度），
FIT論文賞（2005年）等受賞．
電子情報通信学会，情報処理学会，IEEE各会員．
}

\bioauthor{平　　博順}{
1994年東京大学大学理学部化学科卒業．
1996年同大学院理学系研究科化学専攻修士課程修了．
同年，日本電信電話株式会社，NTT コミュニケーション科学研究所入所．
意味理解，文書自動分類，バイオインフォマティクスの研究に従事．
2002年 奈良先端大学院大学 情報学専攻 博士後期課程修了．
博士（工学）．
2005年〜2007年 株式会社NTTデータ 技術開発本部 研究主任．
2007年よりNTT コミュニケーション科学基礎研究所 研究員，現在に至る．
自然言語処理の研究に従事．情報処理学会，人工知能学会，ACL各会員．
人工知能学会編集委員．
}


\bioauthor{進藤　裕之}{
2009年早稲田大学大学院先進理工学研究科修士課程修了．同年NTT入社．
統計的自然言語処理の研究に従事．
現在，NTTコミュニケーション科学基礎研究所研究員．ACL会員．
}


\end{biography}


\biodate



\end{document}

