<?xml version="1.0" ?>
<root>
  <jtitle>点予測による形態素解析</jtitle>
  <jauthor>森信介中田陽介	NeubigGraham河原達也</jauthor>
  <jabstract>本論文では，形態素解析の問題を単語分割と品詞推定に分解し，それぞれの処理で点予測を用いる手法を提案する．点予測とは，分類器の素性として，周囲の単語境界や品詞等の推定値を利用せずに，周囲の文字列の情報のみを利用する方法である．点予測を用いることで，柔軟に言語資源を利用することができる．特に分野適応において，低い人的コストで，高い分野適応性を実現できる．提案手法の評価として，言語資源が豊富な一般分野において，既存手法である条件付き確率場と形態素n-gramモデルとの解析精度の比較を行い，同程度の精度を得た．さらに，提案手法の分野適応性を評価するための評価実験を行い，高い分野適応性を示す結果を得た．</jabstract>
  <jkeywords>形態素解析，単語分割，品詞付与，点予測，系列予測</jkeywords>
  <section title="はじめに">形態素解析は，日本語における自然言語処理の基礎であり，非常に重要な処理である．形態素解析の入力は文字列であり，出力は単語と品詞の組（形態素）の列である．形態素解析の出力は，固有表現抽出や構文解析などの後段の言語処理の入力となるばかりでなく，情報検索システムやテキストマイニング等の自然言語処理の応用の入力として直接利用される．そのため，形態素解析の精度は自然言語処理やその応用に大きな影響を与える．昨今，自然言語処理の応用は医療や法律からWeb文書まで多岐に渡る．したがって，様々な分野のテキストに対して，高い形態素解析解析精度を短時間かつ低コストで実現する手法が望まれている．現在の形態素解析器の主流は，コーパスに基づく方法である．この方法では，統計的なモデルを仮定し，そのパラメータをコーパスから推定する．代表的な手法は，品詞n-gramモデル，全ての品詞を語彙化した形態素n-gramモデル，条件付き確率場(CRF)などを用いている．これらの統計的手法は，パラメータをコーパスから推定することで，際限なきコスト調整という規則に基づく方法の問題を解決し，コーパス作成の作業量に応じて精度が確実に向上するようになった．一方，これらの既存の統計的手法による形態素解析器で，医療や法律などの学習コーパスに含まれない分野のテキストを解析すると実用に耐えない解析精度となる．この問題に対して，分野特有の単語を辞書に追加するという簡便な方法が採られるが，問題を軽減するに過ぎない．論文等で報告されている程度の精度を実現するには，解析対象の分野のフルアノテーションコーパスを準備しなければならない．すなわち，解析対象の分野のテキストを用意し，すべての文字間に単語境界情報を付与し，すべての単語に品詞を付与する必要がある．この結果，ある分野のテキストに自然言語処理を適用するのに要する時間は長くなり，コストは高くなる．本論文では，上述の形態素解析の現状と要求を背景として，大量の学習コーパスがある分野で既存手法と同程度の解析精度を実現すると同時に，高い分野適応性を実現する形態素解析器の設計を提案する．具体的には，形態素解析を単語分割と品詞推定に分解し，それぞれを点予測を用いて解決することを提案する．点予測とは，推定時の素性として，周囲の単語境界や品詞情報等の推定値を参照せずに，周辺の文字列の情報のみを参照する方法である．提案する設計により，単語境界や品詞が文の一部にのみ付与された部分的アノテーションコーパスや，品詞が付与されていない単語や単語列からなる辞書などの言語資源を利用することが可能となる．この結果，従来手法に比して格段に高い分野適応性を実現できる．</section>
  <section title="点予測を用いた形態素解析">本論文では，形態素解析を単語分割と品詞推定に分けて段階的に処理する手法を提案する（figure:flow参照）．それぞれの処理において，単語境界や品詞の推定時に，推定結果しか存在しない動的な情報を用いず，周辺の文字列情報のみを素性とする点予測を用いる．</section>
  <subsection title="点予測を用いた単語分割">点予測による単語分割には先行研究がある．提案手法での単語分割にはこれを採用する．以下では，この点予測による単語分割を概説する．点予測による単語分割の入力は文字列x=xnであり，各文字間に単語境界の有無を示す単語境界タグt=tn-1を出力する．単語境界タグt_iがとりうる値は，文字x_iとx_i+1の間に単語境界が「存在する」か「存在しない」の2種類である．したがって，単語境界タグの推定は，2値分類問題として定式化される．点予測による単語分割では，以下の3種類の素性を参照する線形サポートベクトルマシン(LinearSVM)による分類を行っている．参照する素性は以下の通りである（figure:KyWS参照）．文字n-gram:判別するタグ位置iの周辺の部分文字列である．窓幅mと長さnのパラメータがあり，長さ2mの文字列x_i-m+1,,x_i-1,x_i,x_i+1,,x_i+mの長さn以下のすべての部分文字列である．文字種n-gram:文字を文字種に変換した記号列を対象とする点以外は文字n-gramと同じである．文字種は，漢字(K)，片仮名(k)，平仮名(H)，ローマ字(R)，数字(N)，その他(O)の6つである．単語辞書素性:判別するタグ位置iを始点とする単語，終点とする単語，内包する単語が辞書にあるか否かのフラグと，その単語の長さである．</subsection>
  <subsection title="点予測を用いた品詞推定">様々な言語資源を有効活用するために，点予測による単語分割の考え方を拡張し，点予測を用いた品詞推定手法を提案する．提案手法による品詞推定の入力は単語列であるが，品詞推定対象の単語以外の単語境界情報を参照しない．この設計により，一部の単語にのみ単語境界や品詞情報が付与された部分的アノテーションコーパスが容易に利用可能となる．この点が，英語などの単語に分かち書きされた言語に対する品詞推定の既存手法との相違点である．提案手法における品詞推定は，注目する単語に応じて以下の4つの種類の処理を行う．学習コーパスに出現し，複数の品詞が付与されている単語は，後述する単語毎の分類器で品詞を推定する．学習コーパスに出現し，唯一の品詞が付与されている単語には，その品詞を付与する．学習コーパスに出現せず，辞書に出現する単語には，辞書に最初に現れる品詞を付与する．学習コーパスに出現せず，辞書にも出現しない単語は，その品詞を名詞とする．分類器で品詞を推定する(1)の場合は，点予測を用いることとする．点予測による品詞推定は，品詞を推定する単語wとその直前の文字列x_-と直後の文字列x_+を入力とし，これらのみを参照して単語wの品詞を推定する多値分類問題として定式化される．参照する文字列の窓幅をm'とすると，入力において参照される文脈情報はx_-,w,x_+=x_-m'x_-2x_-1,w,xm'となる．すなわち，この文字列とwの前後に単語境界があり内部には単語境界がないという情報のみからwの品詞を推定する．換言すれば，推定対象の単語以外の単語境界情報や周囲の単語の品詞などの推定結果を一切参照しない．この設計により，パラメータ推定時に様々な言語資源の柔軟な活用が可能となる．分類器品詞推定に利用する素性は以下の通りである（figure:KyPT参照）．x_-x_+に含まれる文字n-gramx_-x_+に含まれる文字種n-gram単語分割とは異なり，品詞推定は多値分類である．したがって，各単語の品詞候補毎の分類器を作る．つまり，ある単語に品詞候補が3つ存在すれば分類器はその単語に対して3つ作り，推定には1対多方式(one-versus-rest)を用いて多値分類を行う．なお，全単語に対して1つの多値分類器を作るという方法も考えられる．予備実験で，この手法を能動学習で用いたところ，能動学習に対して頑健性が低く，偏ったデータを学習データに利用すると解析精度が大幅に下がる現象が起きたので本論文では利用しないこととした．</subsection>
  <subsection title="点予測による柔軟な言語資源利用">点予測を用いた単語分割，および品詞推定は，入力から計算される素性のみを参照し，周囲の推定値を参照しない．この設計により，様々な言語資源を柔軟に利用することが可能となる．系列ラベリングとして定式化する既存手法による形態素解析器のパラメータ推定には，一般的に次の2つの言語資源のみが利用可能である．これらは提案手法でも利用可能である．フルアノテーションコーパスを作成する作業者は，対象分野の知識に加えて，単語分割基準と品詞体系の両方を熟知している必要がある．現実にはこのような人材の確保は困難であり，比較的短時間の訓練の後に実作業にあたることになる．その結果，不明な箇所や判断に自信のない箇所が含まれる文に対しては，その文すべてを棄却するか，確信の持てない情報付与をすることとなる．また，形態素辞書を作成する際にも，単語であることのみに確信があり，品詞の判断に自信がない場合，その単語を辞書に加えないか，確信の持てない品詞を付与するかのいずれかしかない．このような問題は，言語資源作成の現場では非常に深刻であり，確信の持てる箇所で確信の持てる情報のみのアノテーションを許容する枠組みが渇望されている．提案する枠組みでは，以下のような部分的な情報付与の結果得られる言語資源も有効に活用することができる（figure:LR参照）．フルアノテーションコーパスは，各分野で十分な量を確保することは難しいが，上記の言語資源は比較的簡単に用意することができる．本手法では，これらの様々な言語資源を有効活用することにより，高い分野適応性を実現する．</subsection>
  <subsection title="分野適応戦略">本項は，分野適応戦略について述べる．最も効果が高い分野適応の戦略は，適応分野のフルアノテーションコーパスを用意することであるが，作成に必要な人的コストが膨大であるという問題がある．低い人的コストで高い効果を得るためには，推定の信頼度が低い箇所に優先的にアノテーションを行うことが望ましい．単語境界や品詞の推定の信頼度は，文内の各箇所で異なるので，アノテーションは文単位ではなく，推定対象となる最小の単位であるべきである．このようなアノテーションの結果，部分的アノテーションコーパスが得られる．既存手法の形態素解析器では，部分的アノテーションコーパスの利用は困難であるが，提案手法では周囲の文字列の情報のみを用いて形態素解析を行うので，部分的アノテーションコーパスの利用が容易である．そこで，分野適応戦略として，形態素解析器の学習と部分的アノテーションを交互に繰り返し行う能動学習を採択する．手順は以下の通りである（figure:AL参照）．一般分野のフルアノテーションコーパスで分類器の学習を行う．適応分野の学習コーパス（初期状態は生コーパス）に対して形態素解析を行い，後述する方法で推定の信頼度が低い100箇所を選択する．選択した箇所を作業者に提示し，単語境界と品詞を付与してもらう．その結果，適応分野の部分的アノテーションコーパスが得られる．一般分野のフルアノテーションコーパスと適応分野の部分的アノテーションコーパスを用いて分類器の再学習を行う．上記の(2)〜(4)の手順を繰り返す．アノテーション箇所の候補は，分類器の判断の信頼度が低い単語分割箇所と品詞推定対象の単語である．信頼度の尺度は，SVMの分離平面からの距離であり，単語分割箇所と品詞推定の単語を一括して比較する．実際のアノテーションは，選択された箇所（選択箇所）に応じて以下のように行う．選択箇所が単語分割箇所（文字間）の場合:以下の2通りに分類する．選択箇所が単語内の場合:その単語の内部と前後の単語境界情報および品詞情報を付与する．選択箇所が単語境界の場合:その前後の単語の内部と前後の単語境界情報および品詞情報を付与する．選択箇所が品詞推定箇所（単語）の場合:その単語の内部と前後の単語境界情報および品詞情報を付与する．</subsection>
  <section title="評価">提案手法の評価を行うために2つの評価実験を行った．1つ目の実験では，自然言語処理の適応対象を医薬品情報のテキストと想定し，言語資源が豊富な一般分野のコーパスで学習を行い，医薬品情報のテキストに対する形態素解析精度を既存手法と比較する．2つ目の実験は，能動学習による提案手法の分野適応性の定量的評価である．比較的大きなコーパスが存在する分野のテキストを対象に，一部をテストコーパスとし，残りを能動学習を模擬するための学習コーパスとして利用し，アノテーション数と精度の関係を評価する．</section>
  <subsection title="コーパス">実験には「現代日本語書き言葉均衡コーパス」モニター公開データ（2009年度版）のコアデータ（以下BCCWJと呼ぶ）と医薬品情報のテキスト（以下JAPICと呼ぶ）を用いた．これらのコーパスは，単語分割と品詞付与が人手で行われている．コーパスの諸元をtable:corpusに示す．また，219,583形態素を収めたUniDicを辞書として用いた．本論文で提案するのは，分野適応性の高い形態素解析器であり，1つ目の実験では，一般分野とJAPIC（適応分野）をテストコーパスとする評価を行う．この実験では，コーパスと同じ基準の辞書がある場合とない場合も比較した．それぞれの場合のカバー率はtable:coverageの通りである．2つ目の実験では，提案手法と既存手法の代表であるCRFの能動学習を行ない，分野適応性を評価する．この実験でもJAPICを適応分野とするのが理想的であるが，我々は能動学習の実験に必要なアノテーションを模擬する学習コーパスを有していない．したがって，性質に応じてBCCWJを2つに分割し，能動学習の実験を行った．分割においては，文献Design.Compilation.and.Preliminary.Analyses.of.Balanced.Corpus.of.Contemporary.Written.Japaneseを参考に，他の出典のデータと大きく性質が異なるYahoo!知恵袋を適応分野とし，白書と書籍と新聞を一般分野とした．分野適応性の評価のための実験で，UniDicを利用することも考えられるが，table:coverageから分かるように，これを語彙に加えた場合のYahoo!知恵袋のカバー率は99.80%とJAPICを対象とした場合の95.99%に比べて非常に高く，実際の分野適応を模擬していることにはならない．したがって，分野適応性の評価実験においては，UniDicを使用しないこととした．なお，この場合のカバー率は96.29%であり，この判断はおおむね妥当である．</subsection>
  <subsection title="評価基準">本論文で用いた評価基準は，文献で用いられている再現率と適合率であり，次のように定義される．正解コーパスに含まれる形態素数をN_REF，解析結果に含まれる形態素数をN_SYS，単語分割と品詞の両方が一致した形態素数をN_CORとすると，再現率はN_COR/N_REFと定義され，適合率はN_COR/N_SYSと定義される．例として，コーパスの内容と解析結果が以下のような場合を考える．この場合，分割と品詞の両方が一致した形態素は「は/助詞」と「な/形容詞」と「い/形容詞語尾」であるので，N_COR=3となる．また，コーパスには6つの形態素が含まれ，解析結果には5つの形態素が含まれているので，N_REF=6,,N_SYS=5である．よって，再現率はN_COR/N_REF=3/6となり，適合率はN_COR/N_SYS=3/5となる．また，再現率と適合率の調和平均であるF値も評価の対象とした．</subsection>
  <subsection title="各手法の詳細">提案手法においては，学習コーパスのみを用いた予備実験により，文字n-gram長のnの上限値，文字種n-gram長のnの上限値，窓幅m,;m'をすべて3とした．なお，分類器には，精度と学習効率を考慮して線形SVMを用いた．比較対象とした既存手法は，品詞2-gramモデル(HMM)と，形態素n-gramモデル(n=2,;3)と，CRFに基づく方法(MeCab-0.98)である．予備実験の結果，CRFに基づく方法において素性とする語彙は，学習コーパスに出現する全単語のうちの低頻度語500語以外とした．また，学習コーパスの出現頻度上位5,000語を語彙化した．素性は，品詞，文字種，表記2-gram，品詞2-gram，形態素2-gramである．素性列から内部状態素性列に変換するマッピング定義の1-gramには，品詞と表記を用い，右文脈2-gramと左文脈2-gramには，品詞2-gramと語彙化された単語を用いた．</subsection>
  <subsection title="既存手法との比較">まず，一定量の言語資源がある状況での精度を既存手法と比較した．table:L1T1とtable:L1T3は，各手法において学習コーパスのみを用いる場合の一般分野と適応分野のテストコーパスに対する精度である．また，table:L2T1とtable:L2T3は，言語資源として辞書も用いる場合の結果である．まず，全体の傾向としては，多くの場合に表の上から順に精度が良くなっていく．品詞2-gramモデルと形態素2-gramモデルと形態素3-gramモデルの精度は，いずれの場合もこの順に向上する．これは，文献に報告されている通りである．唯一の例外は，JAPICに対する単語分割精度である．これは，過学習が原因であると考えられる．次に，CRFに基づく方法と品詞2-gramモデルとの比較である．ある程度大きな辞書が利用可能でカバー率が高いという条件下ではCRFに基づく方法は品詞2-gramモデルより精度が高いことがわかる．これは，文献に述べられている結果と同じである．しかしながら，利用可能な辞書がなくカバー率が低い場合には，学習コーパスと異なる分野のテキストに対してほぼ同じ形態素解析精度になっている．この原因は，CRFに基づく方法の未知語処理が不十分で，単語分割精度が著しく低いことである．形態素n-gramモデルは，いずれの条件でも品詞2-gramモデルよりも高い精度となっている．これは，文献の結果を追認し，品詞列のみならず，表記列の情報をモデル化することの重要性を強く示唆する．形態素n-gramモデルとCRFに基づく方法との比較では，単語分割においては形態素n-gramモデルがCRFを用いる方法よりも優れているが，品詞の一致も評価に含めた場合，CRFに基づく方法がより優れている．唯一の例外は，カバー率が最も低いtable:L1T3の場合で，CRFに基づく方法の単語分割精度が低すぎて，形態素解析精度においても形態素n-gramモデルよりも低い精度となっている．最後に，本論文で提案する点予測に基づく方法と既存手法の比較についてである．品詞2-gramモデルや形態素n-gramモデルとの比較においては，唯一の例外（table:L2T1の単語分割の再現率）を除いて，提案手法が高い精度となっている．CRFに基づく方法との比較では，辞書を用いて学習コーパスと同一の分野のテストコーパスを解析対象とするtable:L2T1の場合を除いて，提案手法が高い精度となっている．現実的な応用を想定したJAPICを対象とする場合（table:L1T3とtable:L2T3参照）において，提案手法がいずれの既存手法よりも高い精度となっている点は注目に値する．特筆すべきは，コーパスと同じ基準で作成された辞書がないtable:L1T3の場合に，提案手法が他の手法と比べて圧倒的に高い精度となっている点である．以上の結果から，点予測に基づく方法は，ある単語分割および品詞付与の基準に基づく言語資源作成の初期や，同じ分野の学習コーパスの存在が望めない実際の言語処理において非常に有効であることがわかる．</subsection>
  <subsection title="分野適応性の評価">提案手法の分野適応性を評価するために，以下の4つの手法を比較した．部分的アノテーションコーパスの作成手順はsubsection:戦略の通りである．なお，前述の通り，カバー率の観点から初期の言語資源として一般分野の学習コーパスのみを用い，適応分野をYahoo!知恵袋とする．以上のそれぞれで学習したモデルで適応分野のテストコーパスに対して形態素解析を行い，その精度を測定した．その結果をfigure:res2に示す．まず，各形態素解析器において，フルアノテーションと部分的アノテーションでは，部分的アノテーションの方が解析精度の向上に貢献していることがわかる．また，フルアノテーションによる解析精度向上に対する効果は，いずれの手法においてもほぼ同じであることがわかる．最後に，部分的アノテーションによる解析精度向上に対する効果は，提案手法においてより大きいことがわかる．このことから，点予測による形態素解析手法と部分的アノテーションによる能動学習は，非常に良い組み合わせであり，本論文の提案により既存手法に比べて高い分野適応性が実現できることが分かる．このことは，ある分野のテキストに対して言語処理がどの程度有効かを迅速に示す必要があるようなプロジェクトの初期や，形態素解析がプロジェクトの一部に過ぎず，投資額が限られるような実際の言語処理において非常に大きな意味を持つ．</subsection>
  <section title="おわりに">本論文では，点予測による形態素解析手法を提案した．言語資源が豊富な一般分野のコーパスで学習を行い，一般分野と適応分野において提案手法と既存手法の解析精度の比較を行った．その結果，提案手法を用いた形態素解析は，実際の言語処理において非常に有効であることが示された．さらに，部分的アノテーションを用いる能動学習と提案手法を組み合わせることで，既存手法と比較して高い分野適応性が実現できることが示された．</section>
</root>
