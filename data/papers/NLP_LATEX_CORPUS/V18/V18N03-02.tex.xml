<?xml version="1.0" ?>
<root>
  <jtitle>ラベルなしデータの二段階分類とアンサンブル学習に基づく	半教師あり日本語語義曖昧性解消</jtitle>
  <jauthor>井上裁都斎藤博昭</jauthor>
  <jabstract>本稿では，パラメータ調整を簡略化したブートストラッピング的手法による日本語語義曖昧性解消を提案する．本稿で取り上げるブートストラッピングとは，ラベルなしデータを既存の教師あり学習手法を用いて分類し，その中で信頼度の高いデータをラベル付きデータに加え，この手順を反復することによって分類の性能を向上させる半教師あり学習手法である．従来のブートストラッピングによる語義曖昧性解消においては，プールサイズ，ラベル付きデータに追加するラベルなしデータの事例数，手順の反復回数といったパラメータをタスクに合わせ調整する必要があった．本稿にて提案する手法はヒューリスティックと教師あり学習（最大エントロピー法）によるラベルなしデータの二段階の分類，および学習に用いるラベルなしデータの条件を変えた複数の分類器のアンサンブルに基づく．これにより必要なパラメータ数は一つになり，かつパラメータの変化に対し頑健な語義曖昧性解消を実現する．SemEval-2日本語タスクのデータセットを用いたベースラインの教師あり手法との比較実験の結果，パラメータの変化に対し最高で1.8ポイント，最低でも1.56ポイントの向上が見られ，提案手法の有効性を示せた．</jabstract>
  <jkeywords>語義曖昧性解消，半教師あり学習，ブートストラッピング，最大エントロピー法，アンサンブル学習，頑健性</jkeywords>
  <section title="はじめに">語義曖昧性解消は古典的な自然言語処理の課題の一つであり，先行研究の多くは教師あり学習により成果を挙げてきた．しかし，教師あり学習による語義曖昧性解消においてはデータスパースネスが大きな問題となる．多義語の語義がその共起語より定まるという仮定に基づけば，一つの多義語と共起し得る単語の種類が数万を超えることは珍しくなく，この数万種類のパターンに対応するために充分な語義ラベル付きデータを人手で確保し，教師あり手法を適用するのは現実的でない．一方で語義ラベルが付与されていない，いわゆるラベルなしのデータを大量に用意することは，ウェブの発展，学術研究用のコーパスの整備などにより比較的容易である．このような背景から，訓練データと大量のラベルなしデータを併用してクラス分類精度を向上させる半教師あり学習，または訓練データを必要としない教師なし学習による効果的な語義曖昧性解消手法の確立は重要であると言える．本稿では半教師あり手法の一つであるブートストラッピング法を取り上げ，従来のブートストラッピング法による語義曖昧性解消手法の欠点に対処した手法を提案する．ブートストラッピング法による語義曖昧性解消においては主にSelf-training（自己訓練）とCo-training（共訓練）の二つのアプローチがある．まずこれらの手法に共通する手順を述べると次のようになる．Self-trainingとCo-trainingの違いは，前者はStep2で用いる分類器は一つであるのに対し，後者は二つ用いる点にある．またCo-trainingにおいては二つの独立した素性集合を設定し，各分類器を一方の素性集合のみを用いて作成する．Co-trainingにおいてこのように設定するのは，Step3において追加する事例を一方の素性のみから決定することから，追加事例のもう一方の素性を見たとき新しい規則の獲得が期待できるためである．Self-trainingとCo-trainingの欠点はいずれも性能に影響するパラメータが多数存在し，かつこれらのパラメータを最適化する手段がないことである．具体的にはStep1のプールサイズP,Step3のLに加える事例の個数G,手順の反復回数Rは全てパラメータであり，タスクに合わせた調整を必要とする．本稿では，ラベル付きデータとラベルなしデータを同時に活用しつつも，パラメータ設定をほとんど不要とする新しい手法を提案する．本手法はまずヒューリスティックと教師あり学習で構築した分類器によるラベルなしデータの二段階の「分類」を行う．ここで「分類」とは語義曖昧性解消を行い，語義ラベルを付与することを意味する．本稿では以後特に断りがない限り，分類とはこの語義ラベル付与のことを指す．二段階分類したラベルなしデータの中で条件を満たすデータはオリジナルのラベル付きデータに加えられる．その結果，パラメータ設定がほぼ不要なブートストラッピング的半教師あり手法による語義曖昧性解消を実現する．さらに追加するラベルなしデータの条件を変えることで複数の分類器を作成し，アンサンブル学習することで，パラメータの変化に頑健な分類器を生成する．本稿の構成は以下の通りである．節にて関連研究および本研究の位置付けを述べる．節にて提案手法およびその原理を並行して述べる．節にてSemEval-2日本語タスクのデータセットに提案手法を適用した実験の結果を示す．節にて結論を述べる．</section>
  <section title="関連研究">本節ではまず節でブートストラッピング手法として挙げたSelf-trainingおよびCo-trainingを用いた語義曖昧性解消の先行研究を概観する．また，アンサンブル学習に基づく語義曖昧性解消には教師あり学習のアンサンブル，教師なし学習のアンサンブル，半教師あり学習のアンサンブルに基づいた手法が提案されており，これら先行研究を併せて概説する．</section>
  <subsection title="ブートストラッピングに基づく研究">Self-trainingに基づいた語義曖昧性解消の先駆けとしてはYarowskyの研究が挙げられる．Yarowskyは「語義はその語の連語より定まる(onesensepercollocation)」「語義はその語を含む談話より定まる(onesenseperdiscourse)」という二つのヒューリスティックに基づき，ラベルなしデータに反復的にラベル付けするアルゴリズムを提案した．この手法は二つの観点からラベル付けをするため，Co-trainingの一種であると見ることもできる．また，このヒューリスティックに基づいたYarowskyのアルゴリズムはAbneyにより，目的関数の最適化問題として定式化されている．Co-trainingを用いた語義曖昧性解消の早期の例としては新納の報告がある．新納はCo-trainingを適用するにあたり，二組の素性集合の独立性を高めるため，ラベル付きデータに追加するラベルなしデータを素性間の共起性に基づいて選択する手法を提案した．結果，日本語の語義曖昧性解消において通常のCo-trainingよりも性能が向上したと報告した．MihalceaはCo-trainingとSelf-trainingの両方を語義曖昧性解消に適用し，節にて述べたパラメータの影響について調査した．この報告ではパラメータの自動での最適化はできず，最適な設定と自動による設定に大きな差があったと報告している．また，Mihalceaは同じ報告の中でスムージングしたCo-trainingおよびSelf-trainingを提案した．これは手順の反復のたびに生成される各分類器の多数決より語義判定しブートストラッピングするという方式であり，ブートストラッピングとアンサンブル学習の組合せの一種と見ることができる．この方式は通常のブートストラッピングよりも性能が向上したと報告された．以上の手法は節で述べたようなパラメータをタスク（データセット）に合わせ調整しなければならないという大きな課題がある．NiuらはZhuらの提案したラベル伝播手法に基づいた半教師あり手法による語義曖昧性解消について調査した．ラベル伝播は事例を節点とする連結グラフを考え，重み付きの辺を通してラベルありの事例からラベルなしの事例へとラベル情報を反復的に伝播させる．そして伝播の収束結果よりラベルを推定する．この手法はSenseval-3Englishlexicalsampleタスクのデータセットに適用した結果，従来の教師あり学習と比較して著しい成果は得られなかったとしている．PhamらはCo-trainingとSmoothedCo-trainingに加え，SpectralGraphTransduction(SGT)およびSGTとCo-trainingを組合せたCo-trainingの語義曖昧性解消への適用を調査した．Transductionとは訓練データから分類器を生成せず，直接テストデータにラベル付けする推論方法である．SGTはk近傍法のTransductive版であるとされる．SGTはk近傍法の応用であるため，kがパラメータとなり，かつkは性能に与える影響が大きいと報告されている．よってPhamらの調査した手法全てにはパラメータ設定の問題が存在していることになる．手法のアンサンブルを含まないブートストラッピングによる語義曖昧性解消の研究の最後として小町らの報告を挙げる．小町らはブートストラッピング手法の一つであるEspressoに対しグラフ理論に基づいて意味ドリフトの解析を行った．意味ドリフトは，語義曖昧性解消の観点から考えると，どのような語義の語も持つ素性をジェネリックパターンと考え，ジェネリックパターンを持つ（信頼性が低いとされるべき）ラベルなしデータに対し手順の反復過程においてラベルが与えられることにより，反復終了後に生成される分類器の性能が低下してしまう現象と解釈できる．この問題への対処のため小町らは二つのリンク解析的関連度算出法を適用した．この手法は意味ドリフトに頑健かつパラメータ数が一つでさらにその調整が比較的容易という利点を持つ．Senseval-3Englishlexicalsampleタスクのデータセットに手法を適用した実験の結果，小町らの手法は類似したグラフ理論的手法であるHyperLexやPageRankと比較して高い性能が得られたと報告している．</subsection>
  <subsection title="アンサンブル学習に基づく研究">教師あり学習のアンサンブルに基づく研究としては，AdaBoostを用いた，素性として用いる文脈の大きさを変えて複数のNaiveBayes分類器をアンサンブルした，六種の分類器の組合せによる，二段階の分類器の出力の選択に基づいた，複数のNaiveBayes分類器の出力の比較に基づいたが挙げられる．ここではWangらの手法をより詳しくみる．WangらはまずPedersonと同様に素性として用いる文脈の大きさ，つまり目標の多義語前後k語以内の語を素性として用いるとして，kを変えることで複数のNaiveBayes分類器を作成する．次にラベル付きデータを各分類器にて分類する．各要素がこの各分類器による分類結果であるベクトルをdecisiontrajectoryと呼ぶ．最後に各ラベル付きデータから得たdecisiontrajectoryの集合を訓練データとし，これらと入力から得たdecisiontrajectoryの類似度に基づいて入力の語義を判定する．Wangらの手法は中国語の語義曖昧性解消実験の結果，Pedersonの手法などと比較して最も良い結果が得られたと報告した．教師なし手法のアンサンブルの例としてはBrodyらの研究が挙げられる．Brodyらは過去に語義曖昧性解消において有効と報告された教師なし手法であるExtendedGlossOverlap，DistributionalandWordNetSimilarity，LexicalChainsおよびStructuralSemanticInterconnectionsを組合せた手法を提案した．この手法は組合せに用いた各手法と比較し，より良い結果が得られたと報告されている．最後に本稿で提案する手法に最も関連の深いブートストラッピング手法のアンサンブルを行ったLeらの研究について述べる．Leらは我々と同様に従来のブートストラッピングによる語義曖昧性解消の問題点に対する解決法を提案した．Leらが解決法を提案した問題点は，(1)ラベル付きデータのラベル毎のデータ数の偏り，(2)ラベル付きデータに追加するラベルなしデータ決定の基準，(3)手順の反復の停止条件および最終分類器の作成法の三つである．ここで問題(2)は節にて述べたパラメータGの決定法，問題(3)はパラメータRの決定法とも換言できる．Leらはこれらの解決のため，追加するラベルなしデータのリサイズ，複数のデータ追加条件の閾値の設定および対応する複数の追加データ集合の設定，訓練データを用いた追加データの評価および手順反復停止条件の設定，そして追加データと教師あり学習手法別の各分類器のいくつかの組合せ法を提案した．ここで追加データの評価と手順反復停止条件の設定の手法は，Zhouらが提案したTri-training法で用いられた手法を参考に設定している．Tri-trainingはCo-trainingを発展させた手法であり，Co-trainingと異なりパラメータ設定を不要とする特徴がある．実験はSenseval-2およびSenseval-3のEnglishlexicalsampleタスクのデータセットを用いて行われ，従来の教師あり手法と比較し最大で1.51ポイントの精度向上が見られたとLeらは報告した．</subsection>
  <subsection title="本研究の位置付け">節と節を踏まえた上での本研究の位置付けは以下の通りである．まず，小町らの手法はパラメータ設定が容易という利点があるが，他の教師あり手法と組合せるのが困難なのが問題点である．高性能な教師あり手法を用いず，さらに性能を向上させるのは難しい．また，Leらの手法の難点として手順の反復停止条件の設定が挙げられる．これは，教師あり学習を用い追加データを訓練データとして分類器を作成しオリジナルのラベル付きデータを分類して得られるエラー率，および追加データの総数に基づき設定される．具体的には次の式を用い追加データの評価値qを求める．ここで，mは追加データの総数，はエラー率を示す．このqが前回の値よりも小さければ反復は停止する．しかし反復の停止にこの条件が用いられる具体的根拠は示されていない．単に反復を自動的に停止するためと述べられているだけである．このためこの停止条件が最適であるかどうか疑問が残る．そこで本研究の立場だが，まず本稿ではこの停止条件の追究はしない方針とする．しかし，節にて目標としたようにブートストラッピングにおけるパラメータの削減は達成を目指す．そこで本研究では手順の反復回数（パラメータR）を一回に留めるという方針を採る．この方針には次の利点が考えられる．手順の回数が固定され計算時間の予測が立てやすい．ラベル付きデータへのラベルなしデータの追加が一度のみとなるため，追加されたデータに対し分析，考察を加えやすい．反復1回目の精度を向上させることで，手法を複数反復できるように拡張したとき更なる精度向上が見込める．以上の検討に基づき，本研究では反復を伴わず，かつ教師あり学習手法を併用した高性能なブートストラッピング的手法を確立する．また反復回数を一回にすることは，反復回数以外のパラメータを削減することにもつながる．詳しくは節にて述べる</subsection>
  <section title="提案手法">提案手法は節で述べたラベルなしデータの二段階の分類とその結果を用いたアンサンブル学習による最終分類器作成の全三段階からなる．手法の流れを次に，また本手法に基づくシステム全体像を図に示す．まず図の見方を述べる．長方形の囲みは各種処理，楕円の囲みは各処理の出力を示す．各種処理の中には語義分類の処理が三回登場するが，これらの括弧内の分類器はそれぞれの分類処理のために作成し使用する分類器を示している．実線の矢印は各処理において入出力されるデータの流れを示す．点線は入出力するデータへの処理に利用するデータであり，分類器作成のために訓練データとして用いるデータも含まれる．図における訓練データとはオリジナルのラベル付きデータを指す．本システムにおける最終的な語義曖昧性解消の対象は，テストデータとして図のように入力し，その結果は語義分類最終結果として出力される．図に基づく本システムの概観は次のようになる．まず本システムの最初の手順は手掛り語の獲得である．手掛り語は訓練データから抽出する形で獲得する．第二の手順はラベルなしデータからの手掛り付き事例の獲得である．手掛り付き事例の獲得は，手掛り語を用いたラベルなしデータからの手掛り付き事例の抽出・分類（1回目），訓練データを用いて作成された一次分類器による手掛り付き事例の語義分類，一次分類器による分類結果に基づく手掛り付き事例の分類（2回目）といった多段の手順により実現される．最後の手順はテストデータの語義曖昧性解消である．これは獲得した手掛り付き事例と訓練データを用いた二次分類器の作成，および異なる条件で作成された複数の二次分類器によるテストデータの分類結果に基づく最終分類器の判定より構成される．本節では，以後本手法を全三段階に区切り，詳述していく．ここで一つ注意点がある．それは今，本システムを上述のように手掛り語，手掛り付き事例，語義分類最終結果と出力されるデータに着目し，手順を三つに区切ったが，これは以後に述べる三段階の手順と対応関係にないということである．具体的には，手法第一段階は図の手掛り語獲得から手掛り付き事例抽出・分類1回目まで，手法第二段階は一次分類器による手掛り付き事例の分類から二次分類器によるテストデータの語義分類まで，手法第三段階は最終分類器によるテストデータの語義分類のみと対応する．手法第一段階はヒューリスティックによるラベルなしデータの分類として一括りし，手掛り語ならびに手掛り付き事例の詳細と併せて節にて詳述する．手法第二段階はラベルなしデータから抽出した手掛り付き事例の教師あり学習手法による分類とその結果に基づく二次分類器の作成として括り出し，詳細を節にて述べる．手法第三段階はアンサンブル学習による最終分類器の作成として括り，節にて詳述する．節では本手法のまとめをする．このような手法の全三段階の区切りは，節にて述べる実験結果の考察において意味を持つことになる．なお本稿では，訓練データ，テストデータおよびラベルなしデータはいずれもUniDicを用いて形態素解析済みであり，訓練データにおいてラベルは各形態素に付与されているものとする．また本稿では便宜上，形態素を単語または語とも呼ぶことにする．</section>
  <subsection title="Stage 1：ヒューリスティックによる分類">分類第一段階は訓練データからの手掛り語の獲得ならびにヒューリスティックによるラベルなしデータからの手掛り付き事例の抽出・分類（1回目）からなる．</subsection>
  <subsubsection title="手掛り語の獲得">本手法で獲得する手掛り語W_tsとは，訓練データLにおいて語義ラベルが付与された対象語tの前後n_w語以内において共起する内容語の表層形であり，かつ与えられた訓練データ内で共起するtに付与された語義ラベルが必ずある一つの語義ラベルsに定まる語の集合とする．後者の条件は，sが付与されたtをt_sとすると，形態素w_j共起の下でtがt_sである確率をp(t_s|w_j)とすると，を満たすw_jであることとも書き換えることができる．前者の条件にある窓幅n_wについては節で詳述する．このような条件を満たすw_tsW_tsが語義ラベルが付与されていないtと共起したとき，このtは単純に式()よりt_sである可能性が高いと考え，以後W_tsはtの語義曖昧性解消の手掛りとして利用する．また表層形を条件としたのは，基本形，品詞といった情報は表層形と比べ情報の粒度が荒く，表層形の方が手掛りとしての信頼性が高いと考えたことによる．もし式()を満たすw_jがL全体で一度だけ出現する語である場合，tがt_sに決定付けられる可能性は低いとも考えられるが，これは二度以上出現する語の場合も大差はないと筆者は考える．p(t_s|w_j)は語義曖昧性解消において単純ベイズや決定リストのルールの信頼度などにしばしば用いられ，その中でp(t_s|w_j)をスムージングして用いる例もいくつかある．しかしこの場合は最適な閾値を求める必要があり，問題がかえって難しくなってしまう．このため，今回は単純な式()をw_tsの条件とした．なお上述のw_tsは添え字が示すように共起するt_sに付与されていたsの情報を含む．よって実際の手掛り語獲得では，例えば対象語が「相手」，n_w=2，訓練データの一つに「相手に取って不足はない」があり，この文中の「相手」に``117-0-0-3''という語義IDが付与されていたとする．このとき「取っ」という語が訓練データにおいて``117-0-0-3''の語義の「相手」とのみ共起するのであれば，この訓練データからは《取っ,117-0-0-3》という二つ組一つを抽出する．</subsubsection>
  <subsubsection title="手掛り付き事例抽出・分類（1回目）">ここでは，まず手掛り付き事例抽出の手順を述べる前にSemEval-2日本語タスクにおける対象語tの表記ゆれへの対処について述べる．SemEval-2においてはtについて与えられる情報は訓練データLを除くと与えられた辞書に記述された見出し語H_tと語義の語釈文D_tのみであり，tの表記に関する情報は充分には与えられない．例えば，tの一つに「子供」があるが，これは他にも「子ども」「こども」といった表記があるのに対し，H_tにない「子ども」という表記の情報は与えられていない．この問題に対処しない場合，ラベルなしデータからtの事例を充分な数獲得できないだけでなく，tの表記により語義の傾向が変わる場合も考えられ，抽出する事例の語義に偏りが生まれる可能性も考えられる．このため，UniDicの辞書を用いて，以下の手順でtの取り得る表記（表層形）E_tの獲得を行った．なお下記のStep2では実際にはE_t0からひらがなのみで構成される表層形を除外してV_tを抽出している．これはこのような語は語彙素の同定が困難であり表層形獲得精度の低下を招くためである．またe_tE_tは品詞細分類の情報も合わせて獲得し，以後tの事例としてこの二つ組の情報が一致するものを獲得する．続いて，獲得した手掛り語W_tsおよび対象語の表層形E_tを用いてラベルなしデータUより手掛り付き事例の抽出および1回目の分類を行う．手順を以下に示す．手掛り付き事例I_ts1とは対象語tの前後に手掛り語w_tsが共起する事例を指し，上記手順より抽出される．また，ここで抽出されるI_ts1のsはw_tsの添え字のsであり，i_t0にsを付与することで分類したとみなすことができる．よって上記手順では，手掛り付き事例の抽出と分類を同時に行っていると解釈できる．一方で，i_t0の集合I_t0と_sI_ts1の差集合は語義ラベルが付与されないということで，語義判定不可に分類されたと考えることもできる．上記手順を具体例を挙げ説明すると次のようになる．E_tに「相手」，W_tsに《取っ,117-0-0-3》が含まれているとし，Uより「ゼネコン三十一社を相手取って一人あたり三千三百万円の損害賠償を求めた」という文に対し上記手順を適用するとする．また，n_w'=2とする．この場合，文中の「相手」がi_t0となり，tの前後2語以内に「取っ」が共起するため，s=``117-0-0-3''とし，i_t0を手掛り付き事例i_ts1として抽出する．さて，ここでパラメータn_w'についてであるが，これはW_ts獲得に用いるパラメータn_wとは区別する．さらにn_w'の値は上述の例と同様に``2''と固定する．この2という数は節で述べる教師あり学習による分類の素性として対象語前後``2''語以内の形態素を用いることと対応するのだが，その理由を列挙すると以下のようになる．W_ts獲得に用いる訓練データLは本タスクにおいて数少ない信頼できるデータである．したがって，Lからは出来る限り多くの特徴を抽出したい．一方，ラベルなしデータUは多量に存在するが，これを自動的に分類したデータは当然ながら必ずしも信頼できるわけではない．反復回数一回でなるべく信頼性が高くかつ充分な数のデータの獲得が望ましい．n_w'を教師あり学習の素性抽出の範囲と一致させた場合，抽出した手掛り付き事例i_ts1の素性に必ずw_tsが含まれる．このため，i_ts1を教師あり手法で再分類したとき高精度の分類が期待できる．w_tsはn_wに関わらず式()を満たす．つまりある程度の範囲まではn_wを大きくすることで信頼性を維持しつつ多数のw_tsを獲得できる．w_tsが充分な数あれば，一度の処理で多数のUを分類しやはり充分な数のデータをLに加えることができる．上述の理由には従来法の欠点と提案法の利点の両方が含まれている．その対応関係は，理由(4)は(2)への対処であり，(5)は(4)の補足かつ(1)への対処であり，(6)は(5)を踏まえた(3)への対処となる．またここに述べた理由は，節にて述べる手掛り付き事例分類2回目において，節で述べたパラメータP,G,Rが削減可能となる理由にもなる．詳しくは節にて改めて述べる．以上のアルゴリズムをもって，本手法の第一段階とする．節題の通り，本処理は経験則に基づく部分が多い．しかし，本処理は以降の処理においても必要とされる性質を備えている．これらは節および節にて詳述する．</subsubsection>
  <subsection title="Stage 2：教師あり学習手法による分類">分類第二段階では節で抽出・分類した手掛り付き事例に対し，オリジナルの訓練データから得られる一次分類器を用いて2回目の分類を行う．そして，その結果得られる手掛り付き事例を用いて二次分類器を作成する．</subsection>
  <subsubsection title="教師あり学習手法">本手法で用いる教師あり学習手法は最適化にL-BFGSを用いた最大エントロピー法とした．この理由はSemEval-2日本語タスクフォーマルラン参加チームの一つの報告に最大エントロピー法が有効というものがあったためである．また学習の素性もFujitaらの報告を参考に次のように設定した．範囲対象語前後2語以内1グラム素性形態素の表層形形態素の基本形2グラム・3グラム・対象語を含むスキップ2グラム素性形態素の表層形形態素の基本形形態素の品詞と対象語との相対位置の組合せ形態素の品詞細分類と対象語との相対位置の組合せ具体的には，対象語「相手」の事例「相手に取って不足はない」に対しては次の素性が獲得できる．下記例中の``*''を含む素性はスキップ2グラムを示す．また品詞に付与されている番号は対象語との相対位置である．</subsubsection>
  <subsubsection title="手掛り付き事例分類（2回目）">前述の学習手法，素性，そして訓練データLを用いて一次分類器C_1を作成し，C_1を用いて節で抽出・分類した手掛り付き事例I_ts1を再分類する．この分類2回目の結果が分類1回目の結果と一致する，つまりC_1のi_ts1I_ts1の分類結果をc_1(i_ts1)としたとき，c_1(i_ts1)=sである場合，i_ts1をi_ts2I_ts2としLに加え，これを用いてC_1同様に二次分類器C_2を作成する．節で述べたようにi_ts1はその素性に必ず手掛り語w_tsを含む．そのためc_1(i_ts1)はsと一致する可能性が高いが，実際に一致を確認し，一致しなければC_2作成においてこの手掛り付き事例は使わない．この結果，C_2作成に用いられるI_ts2のラベルsは信頼性の高いものとなる．このシステムの重要な点は単に二種類の分類手法の結果が合致するものを選択することではない．そうだとすれば，分類1回目は一般的な教師あり学習手法を用いても良いことになってしまう．重要なのは分類2回目にてC_1が高い精度で分類可能な事例I_ts1を分類1回目において選択していることにある．つまり，分類1回目が分類2回目の精度向上を明確に支援していることがポイントである．これによりI_ts2全てをLに加えても信頼性は保持され，同時に充分な数のブートストラッピングが可能になる．これは従来法において必要だった節に挙げたパラメータ，ラベル付きデータLに加える事例の個数Gおよび手順の反復回数Rを決めることなしに適切な事例をLに加えられることも意味する．なぜなら，Gを定めずとも全事例をLに加えればよく，Rを定めずとも一度の実行で充分な数の事例の獲得が可能だからである．またプールサイズPについては，Blumらの考察から考えるとブートストラッピングの反復において意味を持つ値であると思われる．よって，反復回数1の本手法は単にプールを設定する必要がなく，事例を全てのラベルなしデータUから抽出することで処理できる．また，W_tsはn_w&gt;2であればLの素性にない語（つまり対象語から3語以上離れた位置にある語）を含むことから，I_ts1の素性はやはりLの素性にない語を含む．するとI_ts1が分類2回目の結果，Lに追加されれば，上述の通り分類2回目の信頼性は高いと言えるため，C_2はC_1と比べ正しく分類できるUが増える可能性が高い．したがって，本手法はUのLへの追加における効率性が高い手法であるとも言うことができる．上述の性質はCo-trainingとの類似性を指摘することもできる．Co-trainingは節で述べたように二つの素性集合のうち一方のみに基づいて分類することで他方の素性について新しい規則の獲得が期待できるのが特徴である．本手法では，W_tsとC_1に用いる素性の二種類の素性を実質的に両方考慮して手掛り付き事例を分類している．しかし，C_2に用いる素性は後者の素性のみである．つまり，一方は他方の一部ということになるが，一方の素性で分類した結果を他方の素性を用いる分類器の訓練データに加えるという点ではCo-trainingと共通する．その一方で，提案手法はLに追加するUの分類に二種類，つまり全ての素性を用いており，一方のみを使う場合と比較すると分類結果の信頼性が高いという利点がある．このような変則的なCo-trainingと通常のCo-trainingの間にどのような差異が生まれるかは未調査だが，ここに述べた性質は性能の向上に結び付くと期待される．本処理の直感的な意味としては，C_1にまず簡単な問題を解かせ，その結果をC_2の学習に利用していると解釈できる．一方で従来のブートストラッピングは，難易度がランダムな問題を複数解かせ，その中でシステムが自信を持って答えられるものから学習すると考えられる．しかし後者の場合，回答に対し「間違った自信」を持ってしまい，結果として不適切な学習をしてしまう危険性があり得る．前者の，つまり提案した手法は，確実ではないがC_1が解くのが簡単であろう問題を選択しており，この危険性はいくらか低減していると推測される．この推測が正しいとすれば，C_1に提示する問題を選択する分類1回目の処理は重要な意味を持つことになる．また，ここで提示するのは勿論ラベルなしの文章であるが，見方を変えると「良い文章」をシステムに提示することでより良い学習が可能になると考えられ，興味深い．</subsubsection>
  <subsection title="Stage 3：アンサンブル学習による最終分類器作成">本節では節で作成した二次分類器C_2をアンサンブルして最終分類器C_3を作成する方法を述べる．アンサンブルには節の手掛り語抽出において決定法を保留していた窓幅n_wを利用する．すなわち，n_wをパラメータとする二次分類器をC_2(n_w)とし，n_wを変化させたC_2(n_w)を複数組合せC_3とする．組合せの方法は各最大エントロピー分類器が出力する各ラベルの推定確率の中で最高値を出力した分類器の判定を採用する方式とする．つまり入力をx，C_2(n_w)がxに対し出力する語義sである推定確率をp(s|x,n_w)とすると，より求まるs_*(x)をC_3の出力とする．式()の方式で良い結果が得られる根拠は手掛り語W_tsの条件の一つである式()にある．式()の制約の下でn_wの値を大きくしたとき，得られるW_tsに以下の二つの変化が見られる．n_w変化前になくかつn_w変化後に式()を満たす語が追加される．n_w変化前にはあるがn_w変化後に式()を満たさなくなる語が削除される．ここで重要なのは後者の性質である．式()の性質上，後者の変化よりW_tsから削除された語はn_wをどんなに大きくしても再度W_tsに追加されることは絶対にない．n_w変化後に削除される語は必ずしも重要度が高い語とも低い語とも言えないが，少なくとも一度はW_tsの条件を満たすため重要度が高い語を含む可能性は高い．よって，n_wの変化によって変わる各W_tsの集合には他の集合にはない重要度の高いW_tsが含まれている可能性が少なからずあるということになる．したがって，n_wの差異により各分類器に長所・短所が生まれ，アンサンブル学習の効果が生まれやすいということができる．逆に，C_2をアンサンブルしない場合，n_wの差異により性能に大きく差がつくと考えられ，n_wをパラメータとした調整は難しいと考えられる．またn_wを増やせば，それだけ対象語から離れた位置にある語を特徴とすることになるため，少しずつW_tsの信頼性が落ちていくものと考えられるが，これに伴い任意のsに対しC_2(n_w)のsの推定確率p(s|x,n_w)も落ちていくと予想される．すると，C_3の出力を式()を満たすs_*(x)としたが，n_wの増大に従いC_2(n_w)の判定が採用される確率も減少していくと考えられる．よって，n_wの増大はW_tsの信頼性の減少を意味するが，同時にC_2(n_w)の判定の採用確率も減ぜられる．このため本手法はn_wの増大に対し頑健なアンサンブル手法であるとも言うことができる．本手法はMihalceaのSmoothedCo-trainingおよびWangらTrajectoryBasedの手法と類似性を持つ．まずWangらは文脈の大きさを変えながら複数のNaiveBayes分類器を作成しているが，提案手法の処理はこれとよく似ている．Wangらの手法は文脈の大きさというパラメータの影響の差による性能差が小さくなることで性能が上がると見られるが，本手法でも同様の効果が期待できる．またMihalceaはCo-trainingの反復過程にて分類器の多数決を適用した結果，反復回数の差による性能差が小さくなりかつ全体的な性能も向上したと報告したが，本手法における分類器の組合せにおいても同様の効果が期待できる．なお，分類器の組合せのもう一つの単純な方式として推定確率を重みとした重み付き多数決方式，つまりが考えられる．ここで記号の意味は式()と同じである．しかし，式()の方式は事前実験の結果，式()の方式ほどは良くないことがわかった．これは，n_wの増大に伴いC_2(n_w)の推定確率が低くなることに変わりはないが，式()と比べn_wの大きなC_2(n_w)の判定がより重めに考慮されていることが原因と思われる．最後に本手法唯一のパラメータであるn_wの変化の範囲について述べる．一つの方法としては範囲を設けない，つまり任意のn_wを許すことが考えられるが，当然ながらn_wを増やすことで計算時間が増加する．また，n_wの増大に伴う分類器の信頼性の減少に対しある程度は頑健であるとはいえ，限度の存在があり得る．このためn_wの変化の範囲には何らかの閾値を定めるのが妥当と考えられる．節で述べる実験ではパラメータn_を定め，1n_wn_の範囲でn_wを1刻みで変化させるとし，n_の変化により語義曖昧性解消の性能がどのように変化していくか見ていく．</subsection>
  <subsection title="まとめ">提案手法を一つのアルゴリズムとして表現すると次のようになる．まず着目すべきは本手法はStep8に示したn_以外にパラメータが存在しないことである．そして節で示すようにこのパラメータの設定は比較的容易である．次に留意すべきは節で述べたP,G,Iといったパラメータがないにも関わらず，ブートストラッピングの効果が充分に見込めるという点である．このメカニズムは，上記Step2に示した手掛り語W_tsの条件，Step4のI_ts1の抽出の条件，Step6のI_ts2抽出の条件，さらにStep8,9が巧妙に作用しあっていることに基づいている．最後に注意すべきは，本手法はStep0から9までの1度の実行だけで，充分なブートストラッピングが可能であり，2回以上の反復を必要としない点である．しかし，Step4のI_ts1の抽出は必然的に再現率を犠牲にするため，本手法1回の実行で完全な学習ができる訳ではない．本手法の反復による更なる精度の向上は今後の課題である．</subsection>
  <section title="実験">今回実験に使用したデータセットはSemEval-2日本語タスクにおいて配布された訓練データ（語義ラベル），テストデータを含む形態素解析済みコーパス，および語義の定義に用いられた岩波国語辞典のデータのみである．ラベルなしデータとしては上述の形態素解析済みコーパス全てを利用した．本研究では形態素の基本形の情報も利用するが，SemEval-2日本語タスクにおいてはデータセットに漢字表記の基本形の情報は付与されていない．しかし，用言については基本形のカナ表記（bfm;語形）の情報が付与されているため，本研究ではこれを基本形として扱った．また本研究では，配布されたコーパスの形態素に付与されている品詞が名詞，動詞，形容詞，形状詞，副詞，接尾辞，接頭辞のいずれかであるものを内容語とした．本研究では，訓練データに対する前処理として，SemEval-2日本語タスクにおいて語義の定義に用いられた岩波国語辞典の語釈文に含まれる用例の訓練データへの追加を行った．まず岩波国語辞典の用例中の対象語は``—''に置きかえられているため，``—''を人手で対象語に置換し直し，用例を自動と人手による修正により抽出した．用例の形態素解析にはSemEval-2のデータセットの形態素解析に用いられたのと同様に辞書としてUniDicを用い，MeCabを用いて形態素解析した．形態素解析結果に対する対象語の語義の付与は，用例の抽出同様，自動と人手による修正の組合せより行った．ここで追加した用例の総数は788であり，追加後の訓練データ全体の約24%を占める．上記の辞書中の用例とオリジナルのデータセットの間には性質に相違がある．オリジナルのデータセットはまとまった文章で与えられ，対象語周辺から多くの文脈情報が得られる．対して，辞書の用例は短い文で与えられ，得られる文脈情報は少なく，また用例自体は通常の文章に現れにくい表現の場合がある．節にて述べた手掛り語獲得の手法は，対象語から離れた位置からも手掛り語を獲得することを想定した手法であり，上述のような性質の異なるデータを併用すると不具合が生じる可能性が考えられる．このため実験では，手掛り語獲得において，上記の辞書用例からの追加データを使用する場合と使用しない場合の二通りの実験を行った．実験はn_を変化させつつ，節で述べた通りにn_wを1n_wn_の範囲で1刻みで変化させ最終分類器を作成し，最終分類器の性能を前述のテストデータを用いて評価した．n_の値は1n_100の範囲で1刻みで変化させた．まず手掛り語獲得において辞書用例データを使用しない場合の実験結果を図に示す．ここでFinalclassifierが提案手法の分類精度であり，1stclassifierの結果は節にて述べた一次分類器によるテストデータの分類精度を示す．なお一次分類器はベースラインの教師あり手法であることに注意されたい．また，最終分類器と二次分類器の性能比較のため，n_wを1n_w100の範囲で変化させ二次分類器単体でテストデータを分類したときの評価結果を図に示す．図と図の共通点としては，どのn_，n_wにおいても最終分類器，二次分類器ともに一次分類器の結果を上回っていることがわかる．これより本手法の第二段階の時点で信頼性の高いブートストラッピングができていたことが確認できる．一方で図を見て明らかな通り，二次分類器は最終分類器と比較してパラメータ(n_w)による精度のバラつきがかなり大きいことがわかる．また最終分類器はn_=50付近から，二次分類器はn_w=60付近からn_，n_wの増加に伴い明白に精度が落ちていくことがわかるが，二次分類器の精度の落ち方は最終分類器と比べ明らかに大きい．これより節で述べたように提案手法がn_wの増大に対し実際に頑健であることもわかる．二次分類器の最高値は最終分類器と比べると有意に高いと言えるが，そのときのn_w=23のすぐ近くに大きな谷(n_w=27)があり，これより二次分類器のパラメータ調整の難しさがうかがえる．一方で，最終分類器は特に35n_50の範囲で性能が安定しており，パラメータ調整は比較的容易と言える．次に手掛り語獲得において辞書用例データを使用した場合の最終分類器の評価結果を図，二次分類器の評価結果を図に示す．始めに図と図を比較すると，やはり最終分類器の方がパラメータの変化に対し性能が頑健であることがわかる．しかし図と図で最終分類器同士を比較すると，n_=10周辺では辞書用例使用の方がわずかに性能が良いが，n_がこれより大きくなると辞書用例不使用と比べ性能がやや落ちる．5n_50の範囲における性能の安定性を比較すると，これは明確に辞書用例不使用の方が高いと言える．また図と図で二次分類器同士を比較すると，辞書用例使用の方はn_w=20周辺においてやや安定性が高いが，有意差があるとは言いにくく，いずれにせよこれらは最終分類器より性能の安定性が低い．結論としては，辞書用例使用の有無ではっきりと有意差があるとは言えないが，今回の実験では性能の安定性は辞書用例不使用の方が比較的高いとみることにする．以後は辞書用例不使用の場合の実験結果のみを示す．続いて5n_w20，20n_w35，35n_w50，5n_w50の四つの範囲別（n_も同様）の二次分類器・最終分類器の精度の最高値・最低値・平均値，および最頻出語義選択，一次分類器の精度を表に示す．ここで最高値，最低値の右括弧内の値はそのときのn_w，n_を示す．最高値，最低値のn_w，n_が複数ある場合はその中で最も小さい値を示した．表において特筆すべきはやはり最終分類器の最低値と平均値の高さである．以下全て5n_50（n_wも同じ）の範囲について述べる．まず最低値は0.44ポイント二次分類器を上回り，一次分類器を常に1.56ポイント上回ることになる．これは二次分類器の平均値よりも高い値である．また最終分類器の平均値は一次分類器を1.69ポイント上回る．一方，最高値は二次分類器の方が最終分類器を0.44ポイント上回り，最大で一次分類器を2.24ポイント上回ることになる．しかし，最高値と最低値の差は二次分類器は1.12ポイントあるのに対し，最終分類器はわずか0.24ポイントである．よって，パラメータの調整を考えると最終分類器の方が手法として扱いやすい．最後に一次分類器の精度，n_が表に示した5n_50の範囲における最高値・最低値の精度のときの値の最終分類器の精度，および5n_50の範囲での最終分類器の精度の平均値のそれぞれについて，SemEval-2日本語タスクの語義曖昧性解消対象語別に求めた結果を表に示す．なお表に示した最高値・最低値はn_を対象語別に精度が最高値・最低値になるように変化させたときの値ではないため，表の「子供」の結果のように，最低値の精度が最高値より高い場合も存在する．また対象語右の括弧内の数字はSemEval-2における判別すべき語義の総数であり，この数字に付記された``+''はテストデータに新語義の語が含まれていたことを示す．ただし本稿では特に新語義判別を考慮した処理はしておらず，本実験での一次，二次，最終の各分類器の比較に新語義の有無は関係しない．表において強調してある一次分類器の精度は最終分類器の平均値を上回るもの，強調してある最終分類器の平均値は一次分類器の精度を5ポイント以上上回るものを示している．まず最終分類器の平均値を上回る一次分類器の結果を見てみると，その差は最大で「始める」の3.7ポイントと比較的小さい．一方，一次分類器の結果を上回る最終分類器の結果を見てみると，最大で「教える」が14.3ポイント向上しているとわかる．対象語の語義数と精度の変化の関係を見てみると，例外的に「もの」は比較的語義数が多くて精度の向上もやや大きいが，語義数の多い語は一次分類器と比べ最終分類器の精度が落ちる傾向がある．これは，手掛り語の条件である式()の存在により，語義数が多いと有益な手掛り語の獲得が難しくなるためと考えられる．対処方法の一つとしては語義数により手掛り語の条件を変えることが考えられるが，どのように条件を変えるべきかは難しい問題である．最後に全体を見てみると，結局一次分類器と最終分類器の間に差がないものが多いことに気付く．よって提案手法は一部の単語に対し高い効果を持つ手法であるということになる．この原因としては，本手法で手掛り語として用いたのが内容語の表層形の1グラムのみと，手掛り語が素性としては非常に狭い範囲内に位置するものだったこと，そして手掛り付き事例抽出の条件が対象語前後2語以内に手掛り語を含むという厳しい制約であったことが考えられる．ここで後者の原因は手掛り付き事例抽出の条件のn_w'=2を可変にし，さらに多くの二次分類器を作成してアンサンブルすることで取り除ける可能性がある．一方，前者の原因は単に素性の粒度を荒くしただけでは精度が低下する恐れがある．以上を踏まえると節にて述べたヒューリスティックは部分的に有効と言えるが，汎用性に不安が残る．節の手法第一段階を他の段階と切り離すとすると，第二段階，第三段階に変更を加えない場合，第一段階の要件は手掛り付き事例を（仮の）ラベルを付与して抽出すること抽出事例は第二段階の分類を助ける手掛りを持つこと第三段階にて二次分類器を複数作成するためのパラメータを持つこと要件(2)の手掛りの信頼性と要件(3)のパラメータの間に相関があることの四つである．この中で特に難しいと思われるのは要件(2)であるが，これを実現する方法の一つとしては特徴選択がある．第一段階は狭い意味での特徴選択をしているとも見ることができ，効果的な特徴選択法を利用することで上述の問題への対処，つまりより多くの単語の語義曖昧性解消を実現できる可能性がある．特徴選択を応用した語義曖昧性解消の研究の一つとしてはMihalceaによるものが挙げられる．Mihalceaは手法はSenseval-2Englishallwordstaskにおいて二位の成績から5.4ポイント引き離し最高の成績を得た実績がある．よって，Mihalceaの手法を本手法に応用することで更なる性能の向上を見込める可能性がある．</section>
  <section title="おわりに">本稿では，従来のブートストラッピング法による語義曖昧性解消手法の欠点であるパラメータ調整の難しさに対処するため，パラメータ設定をほぼ不要とするブートストラッピング的半教師あり語義曖昧性解消手法を提案した．この手法は二段階の分類をラベルなしデータに適用するものであり，反復回数を一回に留めるにも関わらず充分な効果があるブートストラッピングを実現した．またラベル付きデータに追加するラベルなしデータの条件を変え，複数の分類器を作成しアンサンブル学習することで唯一のパラメータの調整も容易とする手法を確立した．本手法の改良の方針としては次の二つが考えられる．本手法を通常のブートストラッピング同様に訓練データの反復追加を可能にし，性能が向上するように拡張する．節にて述べたヒューリスティックによる分類をより多くの語の語義曖昧性解消に有効な汎用的手法に改良する．これらはいずれも重要度の高い課題であり，並行して取り組むべき課題であると言える．また，提案した手法は語義曖昧性解消に特化しているが，節と節で述べたような半教師ありのアンサンブル学習の枠組みを異なる問題に適用することも興味深い課題である．最後に，実現可能性は未知数だが本手法の発展の可能性として，語義曖昧性解消のような分類問題において機械学習を用い人間にとって理解しやすい規則を獲得できるようになれば面白いのではないかと筆者は考えている．これは本稿にて提示したヒューリスティックに基づいた手法そのものを訓練事例とみなし，機械が自動でこの訓練事例に類似し，かつ人間に理解しやすい規則を獲得するというものである．これを実現するには「理解しやすさ」という尺度を定義することから始めなければならないと思われるが，もし実現できれば，従来の機械学習において困難だった獲得した規則の解釈が容易になることが予想される．そうすれば機械学習，またはこれを応用した自然言語処理などの研究の進展が加速するのではないかと期待できる．</section>
</root>
