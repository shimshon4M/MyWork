    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{boxedminipage}


\Volume{19}
\Number{4}
\Month{December}
\Year{2012}

\received{2012}{2}{6}
\revised{2012}{6}{8}
\rerevised{2012}{7}{18}
\accepted{2012}{9}{20}

\setcounter{page}{303}

\jtitle{外れ値検出手法を利用した新語義の検出}
\jauthor{新納　浩幸\affiref{Author_1} \and 佐々木　稔\affiref{Author_1}}
\jabstract{
本論文では対象単語の用例集合から，その単語の語義が新語義（辞書に未記載の語義）となっている
用例を検出する手法を提案する．
ここでのアプローチの基本は，新語義の用例が用例集合中の外れ値になると考え，
データマイニング分野の外れ値検出の手法を利用することである．
ただし外れ値検出のタスクは教師なしの枠組みになるが，
新語義検出という本タスクの性質を考慮すると，一部のデータ（用例）にラベル（対象単語の語義）
が付与されているという枠組みで考える方が適切である．
そのため本論文では一部のデータにラベルがついているという教師付きの枠組みで外れ値検出を行う．
具体的には 2 つの手法（教師付き LOF と生成モデル）を用い，それら出力の共通部分（積集合）を最終的な出力とする．
この教師付き LOF と生成モデルの積集合を出力する手法を提案手法とする．
実験では SemEval-2 日本語 WSD タスクのデータを用いて，提案手法の有効性を示した．
また WSD のアプローチを単独で利用しただけでは，本タスクの解決が困難であることも示した．
}
\jkeywords{新語義，外れ値検出，LOF，生成モデル，One Class SVM，SemEval-2 日本語 WSD タスク}

\etitle{Detection of New Word Senses by the Outlier \\Detection Method}
\eauthor{Hiroyuki Shinnou\affiref{Author_1} \and Minoru Sasaki\affiref{Author_1}} 
\eabstract{
In this paper, we propose a method to detect new word senses of a target word 
from sentences that contain it.
To achieve this, we assume a new word sense sentence as an outlier of a data set
constructed by sentences that contain the target word.
Then using outlier detection methods in the data mining domain, we detect the new word senses.
Generally, outlier detection methods are considered to be unsupervised.
However, our method utilises data sets including some sentences with the labelled target word.
Therefore, our outlier detection method is classified under the supervised framework.
We propose an ensemble method of two methods to detect new word sense sentences:
the supervised LOF (Local Outlier Factor) and the supervised generative model.
The final output is the intersection of outputs of both methods.
We demonstrate the effectiveness of our method using SemEval-2 Japanese WSD task data. 
Moreover we show that  word sense disambiguation systems cannot solve our task by themselves.
}
\ekeywords{new word sense, outlier detection, LOF, generative model, One Class SVM, SemEval-2 Japanese WSD task}

\headauthor{新納，佐々木}
\headtitle{外れ値検出手法を利用した新語義の検出}

\affilabel{Author_1}{茨城大学工学部情報工学科}{Department of Computer and Information Sciences, Ibaraki University}



\begin{document}
\maketitle


\section{はじめに}

本論文では対象単語の用例集合から，その単語の語義が新語義（辞書に未記載の語義）となっている
用例を検出する手法を提案する．

新語義の検出は語義曖昧性解消の問題に対する訓練データを作成したり，辞書を構築する際に有用である．
また新語義の検出は意味解析の精度を向上させる\cite{erk}．
また新語義の用例はしばしば書き誤りとなっているので，誤り検出としても利用できる．
新語義検出は一般に Word Sense Disambiguation (WSD) の一種として行う方法，
新語義の用例をクラスターとして集める Word Sense Induction (WSI) のアプローチで行う方法\cite{denkowski}，
及び新語義の用例を用例集合中の外れ値とみなし，外れ値検出の手法を用いる方法\cite{erk}がある．
ここでは外れ値検出の手法のアプローチを取る．
ただしデータマイニングで用いられる外れ値検出の手法は教師なしであるが，
本タスクの場合，少量の用例に語義のラベルが付いているという
教師付きの枠組みで行う方が自然であり，ここでは教師付き外れ値検出の手法を提案する．

提案手法は 2つの検出手法を組み合わせたものである．
第1の手法は代表的な外れ値検出手法である
Local Outlier Factor (LOF) \cite{lof} を教師付きの枠組みに拡張したものである．
第2の手法は，対象単語の用例（データ）の生成モデルを用いたものである．
一般に外れ値検出はデータの生成モデルを構築することで解決できる．
提案手法では第1の手法と第2の手法の出力の積集合を取ることで，
最終の出力を行う．

提案手法の有効性を確認するために，SemEval-2 の 日本語 WSD タスク\cite{semeval-2010}のデータを利用した．
従来の外れ値検出の手法と比較することで提案手法の有効性を示す．
実験を通して，外れ値検出に教師データを利用する効果も確認する．
また SVM による WSD の信頼度を利用した外れ値検出も行い，
WSD システム単独では新語義の検出は困難であることも示す．


\section{従来の新語義検出手法}

\subsection{WSD の信頼度の利用}

WSD は語義を識別するタスクなので，WSD システムを利用すれば新語義を検出できると考えるのは自然である．
WSD の対象単語\( w \)の語義のクラスを\( C \)とする．
関数\( f(x,c) \) はある WSD システムが出力する用例\( x \)中の\( w \)の
語義が\( c \in C\)となる信頼度とする．
この WSD システムは\( argmax_{c \in C} f(x,c) \)により語義を識別する．
新語義の検出はある閾値\( \alpha \)を定め，
\begin{equation}
\forall c \in C\ \ \ \  f(x,c) < \alpha
  \label{eq:1}
\end{equation}
のときに\( x \)を新語義の用例と判定することで，新語義を検出できる．

ただし適切な\( \alpha \)の値は単語毎に異なるはずであり，その設定は困難である．
また WSD は識別のタスクであり，一般に WSD システムは SVM のような識別モデルをもとに構築される．
そのためシステムは語義の識別精度が上がるように最適化されており，
\( f(x,c_i) \)の値は\( f(x,c_j) \)との相対的なものである．つまり\mbox{式(\ref{eq:1})}により
新語義が検出できる保証はない．
例えば図\ref{fig1} のような状況を考えてみる．図\ref{fig1} のクラス1とクラス2 を分離する直線が，
分類器に対応する識別境界とする．データがクラスに属する信頼度は，一般に，識別境界までの
距離で測るので，図\ref{fig1} のデータa とデータb はクラス1 と識別され，その信頼度は等しくなる．
識別の場合はデータが識別境界のどちら側に属するかだけが重要なので，それで十分であるが，
データa とデータb を比べると，明らかにデータb の方がクラス1 に属する信頼度が低い\footnote{分類器が SVM の場合，
データを高次元に写すので図\ref{fig1}の例は特殊であるが，SVM でも同じ問題は内在する．
また査読者から図\ref{fig1}の例には問題があり削除するよう指示があったが，
何が問題かが理解できなかったので，あえて本例は削除していない．}．

\begin{figure}[t]
\begin{center}
\includegraphics{19-4ia3f1.eps}
\end{center}
\caption{識別の信頼度と外れ値の度合い}
\label{fig1}
\end{figure} 


\subsection{WSI による検出}

従来，新語義の検出は Word Sense Induction (WSI) というタスクの一部として行われてきた\cite{shutze,stefan,kuoka}．
WSI は本質的には対象単語の用例を語義に基づいてクラスタリングするタスクである\cite{denkowski}．
用例集合中に新語義の用例があれば，それらも語義のクラスターとして出現するために
新語義の検出として利用できる．

ただし陽に新語義を検出するには，得られたクラスターに語義のラベルを付与する必要がある\cite{tanaka-h}．
Shirai は辞書に記述された語義の定義文を利用して，得られたクラスターに語義のラベルを付けることで
新語義を検出しようとしている\cite{shirai-semeval2}．また Sugiyama は既存語義の用例を種用例として，
用例集合を半教師なしクラスタリングによりクラスタリングした\cite{sugiyama}．
種用例のないクラスターが新語義のクラスターとなる．
ただしどちらもクラスタリング自体の精度が悪く，新語義の検出までには至っていない．

本来，クラスターに語義のラベルを付けるためには，語義のラベル集合が必要である．
語義のラベル集合を定めた場合に，WSI と WSD との違いはほとんどなくなる．
WSD を行う前に教師なし学習であるクラスタリングを行うアプローチが，
新語義の検出に有効かどうかは不明である．
また用例を語義に基づいてクラスタリングする場合，
クラスターの数の決め方が大きな問題になる\cite{agirre}．
また新語義がクラスターを形成するという仮定は，多くの新語義に対して当てはまらない．
クラスターを形成するくらいに，その語義の用例が存在するのであれば，
その語義は新語義ではなく既に一般的な語義と考えられる．



\subsection{外れ値検出による検出}

新語義の用例を用例集合内の外れ値と見なし，外れ値検出の手法を利用して
新語義を検出するアプローチがある．

\begin{figure}[b]
\begin{center}
\includegraphics{19-4ia3f2.eps}
\end{center}
\caption{外れ値検出手法の最近傍法}
\label{fig-erk}
\end{figure} 

Erk は外れ値検出手法の最近傍法を利用して新語義の検出を試みた\cite{erk}．
対象単語\( w \)の語義が付与された用例集を\( D \)とし，
用例\( x \)の外れ値の度合い\( out(x) \)を\mbox{式(\ref{eq:siki1})}で測り，
この値が 1 以上の\( x \)を新語義の用例とした．ここで\( d(x,y) \)は
用例\( x \)と用例\( y \)間の距離である．
\begin{equation}
out(x) = \frac{d(x,y)}{\min_{z \in D} d(y,z)} \qquad
  \text{where} \quad  y = argmin_{y' \in D} d(x,y')   \label{eq:siki1}
\end{equation}

この式は\( D \)の中で\( x \)と最も距離が近いデータ\( y \)を選び，
更にその\( y \)と最も距離が近い\( D \)内のデータ\( z \)を選んで，
\( d(x,y) \)と\( d(y,z) \)の比を取ったものである（図\ref{fig-erk} 参照）．

ただし最近傍法が妥当な精度を出すには，大量の訓練データを必要とするという問題がある．


\section{外れ値検出手法}

データマイニング分野の外れ値検出手法は非常に多岐にわたるが，その多くは変化点検出の手法
に位置づけられる\cite{yamanishi}．つまり時系列的にデータが生起するオンラインでのタスクに対する手法が中心である．
新語義検出のようなバッチ的なタスクに対する手法としては，
密度ベースの手法，One Class SVM，生成モデルによる手法が代表的な手法である．
ここではこの3つの手法を本論文の提案手法との比較手法とする．



\subsection{密度ベースの手法}

外れ値検出は古典的にはマハラノビス距離を用いた距離ベースの手法が中心だが，
それを改良したのが密度ベースの手法であり，密度ベースの代表的な手法が
LOF である．LOF は，データの近傍の密度を利用することで，そのデータの外れ値の度合いを測り，
その値によって外れ値を検出する．

LOF におけるデータ\( x \in D\)における外れ値の度合いを\( LOF(x) \)と表記する．
ここで\( D \)はデータ全体の集合である．
\( LOF(x) \)を定義するために，いくつかの式を定義しておく．
まず\( kdist(x)\)は\( x \)に対する\( k \)距離と呼ばれる値で，
以下の条件を満たすデータ\( o \in D\)との距離\( d(x,o) \)として定義される．

\begin{enumerate}
\item 少なくとも\( k \) 個のデータ\(o' \in D\setminus\{x\}\) に対して \( d(x,o') \leq d(x,o)\) が成立する．
\item 高々\( k - 1 \)個のデータ\( o' \in D\setminus\{x\}\)に対してのみ \( d(x,o') < d(x,o)\) が成立する．
\end{enumerate}

直感的には，上記のデータ\( o \)はデータ\( x\)からの\( k\)番目に近いデータとなる．
データ\( x\)から同じ距離を持つデータが複数存在する場合を考慮して，
上記のようなテクニカルな定義になっている．

次に\( kdist(x) \)を利用して，\( N_{k}(x) \)，\( rd_{k}(x,y) \)及び\( lrd_{k}(x) \) を
定義してゆく．
\[
N_{k}(x) = \{ y \in D\setminus\{x\}| d(x,y) \leq kdist(x) \}
\]

これは\( x \)の \( k \)近傍と呼ばれる集合であり，\( x \)との距離が\( kdist(x) \)以下になるような
データの集合である．
\[
rd_{k}(x,y) = \max \{ d(x,y), kdist(y) \}
\]

これは\( x \)から\( y \)への距離を表すが，\( x \)が\( y \)の \( k \)近傍内に入る場合に，
その距離を\( kdist(y) \)で置き換えている．直感的にはデータ間の距離が近い場合に，
\( k \)距離で補正している．
\[
lrd_{k}(x) = \frac{|N_{k}(x)|}{\sum_{y \in N_{k}(x)} rd_{k}(x,y)}.
\]

これは\( x \)の \( k \)近傍内のデータ\( y \)の\( rd_{k}(x,y) \)の平均の逆数であり，
これが\( x \)の密度を表している．

これらの式を用いて，\( LOF(x) \)は以下で定義される．
\[
LOF(x) = \frac{1}{|N_{k}(x)|} \sum_{y \in N_{k}(x)} \frac{lrd_{k}(y)}{lrd_{k}(x)}
\]

つまり\( x \)の \( k \)近傍内のデータの密度と\( x \)の密度の比の平均を外れ値の度合いとしている．
直感的には近くのデータの密度は高く，自身の密度が低い場合に外れ値の度合いが高くなる．
また「近くのデータの密度は高く，自身の密度が低い」というのは，
ある密度の高いクラスターがあり，そこから離れている独立のデータであるような場合である．

例えば図\ref{lof-ex} では，データa とデータb が外れ値である． 
距離ベースの手法では，データb は外れ値として検出できるが，
データa はクラスターA との距離が近いために検出できない．
一方 LOF では，クラスターA の密度が高く，データa の近辺にはデータがなく孤立しているので，
外れ値として検出できる．

\begin{figure}[t]
\begin{center}
\includegraphics{19-4ia3f3.eps}
\end{center}
\caption{LOF による外れ値検出}
\label{lof-ex}
\end{figure} 

また LOF ではパラメータとして\( k \)が存在する．本論文では\( k = 5\)としている．


\subsection{One Class SVM}

One Class SVM は\(\nu-\)SVM \cite{oc-svm}を利用した外れ値検出の手法である\cite{akaho}．
すべてのデータは\( +1 \)のクラスに属し，原点のみが\( -1 \)のクラスに属するとして，
\(\nu-\)SVM を使って 2 つのクラスを分離する超平面を求める．
原点はすべての点に対して類似度が 0 となるために，外れ値とみなせる．
また\(\nu-\)SVM はソフトマージンを利用するので，
\( -1 \)のクラス側に属するデータを外れ値と判定する．

\begin{figure}[t]
\begin{center}
\includegraphics{19-4ia3f4.eps}
\end{center}
\caption{One Class SVM による外れ値の検出}
\label{ocs-ex}
\end{figure} 

図\ref{ocs-ex} で概略を説明する．図の星形の点が外れ値である．
原点は全ての点と内積が 0 となる，つまり類似度が 0 であるために
外れ値と考える．図の星形の点（外れ値）も含め，原点以外のすべての点を正常値と考え，
外れ値と正常値を分離する超平面を \(\nu-\)SVM で求める．
\(\nu-\)SVMはソフト SVM であり，教師データのすべての点を正確に分離するわけではなく，少数の誤りを認める．
図では原点付近に超平面（この場合，直線）を近づければ，識別の精度は向上するが，
その場合，最大マージンが小さくなる．最大マージンを大きくしようとすると，
識別の精度は下がる．このバランスをうまくとるような超平面を求めるのが \(\nu-\)SVM である．
最終的に原点側に属するデータが外れ値と判断される．

One Class SVM を利用する際には，用いるカーネル関数やどの程度のマージンの誤りを認めるかの
パラメータの設定が結果に大きく影響する．
本論文の実験では One Class SVM のプログラムとして 
LIBSVM\footnote{http://www.csie.ntu.edu.tw/\~{}cjlin/libsvm/} を用いた．
カーネルは線形カーネルを利用し，マージンの誤りはパラメータ\( n \)に対応するが，
\( n = 0.02 \)で固定した．


\subsection{生成モデルによる手法}

データ\( x \)の生成過程を確率モデル\( P(x) \)でモデル化したものを生成モデルと呼ぶ．
一般に潜在変数\( z_i \)を導入し，ある確率モデル\( P_i(x) \) の
混合分布により\( P(x) \)をモデル化する．
\[
P(x) = \sum_{i} z_i P_i(x) \ \ \ \ s.t.\ \ \  0 \le z_i \le 1,\ \ \sum_i z_i = 1
\]
モデル化の後に，与えられたデータから EM 法などを利用して，
\( z_i \)と\( P_i(x) \)のパラメータを推定することで\( P(x) \)を構成する．

データ\( x \)の外れ値の度合いとしては\( - \log P(x) \)が用いられる．
この値が大きいほど外れ値と見なせる．



\section{提案手法}

\subsection{教師付き外れ値検出}

一般に外れ値検出のタスクでは外れ値の定義が不可能である
\footnote{もし定義できるのであれば，その定義にあったデータを取り出せばよいだけなので，
タスクとしての意味はなくなる．}．
これは外れ値にラベルをつける意味がないことを示している．
なぜなら仮にあるデータが外れ値であり，その外れ値にラベルをつけることができたとしても，
他の外れ値がそのラベル付きの外れ値と類似している保証がないからである．
また検出元となるデータ集合は，ほぼすべて正常値である．
仮にデータにラベルをつけるとすれば，正常値のラベルだけになり，教師データに意味はない．
これらのことから外れ値検出の手法は教師なしの枠組みにならざるをえない．

しかし新語義の用例を外れ値と見なした新語義検出のタスクの場合，
一般の外れ値検出とは異なった2つの特徴がある．
1つは外れ値の定義が明確という点である．ここでの外れ値は新語義の用例であるが，
新語義とは「辞書に記載されていない語義」というように明確に定義できる．
もう 1つは正常値のデータは語義のクラスターに分割されるという点である．
しかもクラスターの数も明確である．一方，通常の外れ値検出では正常値の
集合がクラスターに分割されるのか，されるとしてもいくつのクラスターに分割されるのかは
不明である．

ここではこれらの特徴を利用して外れ値検出を行う．
つまり，検出元となる対象単語の用例集の一部に，対象単語の語義のラベルを付与し，
その設定のもとで外れ値検出を行う．


\subsection{教師付き LOF}

教師データを LOF で利用するには単純に教師データをテストデータに加えればよい．
しかしその場合，教師データからも外れ値が検出される可能性がある．
ここでは教師データを\( k + 1 \)倍してからテストデータに加えてデータセットを作り，
そのデータセットに対して LOF を適用する．
ただし\( k \)は LOF における\( kdist \)で使われる\( k \)である．
LOF の場合，教師データ\( x \)を\( k + 1 \)倍すると\( kdist(x) = 0 \)
となり，教師データ\( x \)が外れ値として検出されることはなくなる．

教師データを\( k + 1 \)倍することで，テストデータに対して，外れ値検出の精度が
高まるという保証はないが，いくつかの予備実験により経験的に精度が向上することは確認している．
一般に教師データを増やせば検出の精度は高まる．また，教師データを増やせば既存の教師データ
に対する密度が高まるはずなので，教師データを\( k + 1 \)倍することは
精度を高める方向に作用する．
また LOF は確率的な手法ではないので，明確には教師データの独立同一性分布を仮定していない．
この点で同じデータを増やしても精度を落とす方向へ作用しないと考える．
また注記として，教師なしの LOFも教師付き LOFも\( k \)の値が特に精度に影響を与えている．
この点は考察の章で述べる．
本論文では教師なしの LOF において\( k = 5 \)としたが，教師付きの LOFでも
\( k = 5\)とする．


\subsection{教師データを利用した生成モデルの構築}

対象単語\( w \)の用例\( x \)に対する生成モデル\( P(x) \)を教師データを利用して構成する．
\( w \)の語義を\( z_i \)(\(i=1 \sim K\))としたとき，
全確率の公式から以下が成立する．
\[
P(x) = \sum_{i=1}^K P(z_i) P(x|z_i)
\]
\( w \)の教師データが\( N \)個あり，その中で語義\( z_i \)のデータが\( n_i \)個あれば，
\( \sum_{i=1}^K n_i = N \)であり，
\begin{equation}
P(z_i) = \frac{n_i}{N}
  \label{eq:seisei1}
\end{equation}
と推定できる．

問題は\( P(x|z_i) \)の推定である．\( x \)は以下のような素性リストで表現されている．
\[
x = \{ f_1, f_2, \cdots, f_m \}
\]
ここでは Naive Bayes で使われる素性間の独立性を仮定して，
\[
P(x|z_i) \approx \prod_{j = 1}^m P(f_j | z_i)
\]
と近似する．教師データの中の語義が\( z_i \)となっているデータの中で
\( f_j \)が出現した個数を\( n(z_i,f_j) \)と書くことにする．このとき，
\begin{equation}
P(f_j | z_i) = \frac{n(z_i,f_j)}{n_i}
  \label{eq:seisei2}
\end{equation}
と推定できる．ただし式(\ref{eq:seisei1})や式(\ref{eq:seisei2})は
頻度が 0 の部分があると不具合が生じる．
そこで MAP 推定でスムージングを行い，以下の補正式を用いる\cite{takamura}．
\begin{gather}
P(z_i) = \frac{n_i + 1}{N + K} \\[0.5em]
P(f_j | z_i) = \frac{n(z_i,f_j) + 1}{n_i + 2}
\end{gather}

以上より\( P(x) \)の値が求まる．外れ値の度合いは\( - \log P(x) \)で測り，
この値の大きなものを外れ値の候補とする．

ここである閾値を定めて外れ値を検出することも考えられるが，
単語毎に\( - \log P(x) \)の値は大きく異なるために，固定した閾値を定めることはできない．
そこでここでは単語毎に，検出対象のデータ（テストデータ）に対して\( - \log P(x) \)を計算し，
それらの値に対する平均\( \mu \)と分散\( \sigma^2 \)を求める．
\( - \log P(x) \)の分布を正規分布と考え，
以下の式の値（正規化した値）に対して閾値\( \theta \)を設けることにした．
\begin{equation}
\frac{- \log P(x) - \mu}{\sigma}  \label{gtheta}
\end{equation}
上記の正規化した値が\( \theta \)以上の\( x \)を外れ値とする．

ここでは予備実験を行い\( \theta = 1.1 \)とした．


\subsection{教師付き LOF と生成モデルの積集合}

本論文の提案手法は，前述した教師付き LOF による出力と，
教師データを利用して構築した生成モデルの出力の共通部分（積集合）を出力するものである．

一般に外れ値検出のタスクは難しく，単一の手法ではなかなか高い検出能力が得られない．
その 1 つの原因は誤検出が多いことである．
提案手法の狙いは，異なったタイプの手法の出力の積集合を取ることで，
誤検出を減らし，全体の検出能力を向上させることである．
LOF と生成モデルは外れ値の捉え方が異なるために，出力の積集合を取る効果が期待できる．



\section{実験}

\subsection{実験データ}

SemEval-2 は語義曖昧性解消に関する評価型の国際会議であり，いくつかのタスクが設定されている．
日本語 WSD はその中の 1 つである．通常の日本語の語義曖昧性解消のタスクであるが，
最も特徴的な点は識別結果に新語義というカテゴリを含めている点である．
つまりテストデータの中には設定された語義のどれでもないという答えがありえる．
そのため，このタスクで用意された教師データとテストデータを用いることで，
教師付きの枠組みでの新語義の検出手法の評価が可能である．

日本語 WSD の対象単語は 50 単語である．
この中で「可能」「入る」は教師データ内に新語義の用例があるので，
それらを外して残り 48 単語を実験対象とした．
各単語を以下に示す．

\vspace{1\Cvs}

\small
\begin{boxedminipage}{140mm}
\begin{verbatim}

名詞   21 単語
相手，意味，関係，技術，経済，現場，子供，時間，市場，社会，情報，手，電話，場合，
はじめ，場所，一，文化，ほか，前，もの

動詞   22単語
会う，あげる，与える，生きる，入れる，教える，考える，勧める，する，出す，立つ，
出る，とる，乗る，始める，開く，見える，認める，見る，持つ，求める，やる

形容詞  5 単語
大きい，高い，強い，早い，良い

\end{verbatim}
\end{boxedminipage}
\normalsize

\vspace{1\Cvs}

新語義は「意味」で 1用例，「手」で 3用例，「前」で 7用例，
「求める」で 1用例，「あげる」で 2 用例，「はじめる」で 2用例の計 16用例存在する．
これらが検出の正解となる．正解の用例を以下に示す．下線の単語が対象単語である．

\small
\noindent
\hspace{10mm}1. …の開きが，ある\underline{意味}で，科学技術と社会に…\\
\hspace{10mm}2. …医業収益等は\underline{手}入力…\\
\hspace{10mm}3. …本部での集約も\underline{手}入力，…\\
\hspace{10mm}4. …経理コンピュータへの予算入力も\underline{手}入力で…\\
\hspace{10mm}5. …ランチ＝\underline{前}十一時半〜後 3 時．\\
\hspace{10mm}6. …二十四日火，\underline{前}十時〜後 7 時…\\
\hspace{10mm}7. …来年 3 月二十日木までの\underline{前}十時〜後十時，…\\
\hspace{10mm}8. …ゆうゆうワイド（TBS＝\underline{前}8・三十）…\\
\hspace{10mm}9. …三十日水までの\underline{前}十一時半〜後 2 時半，…\\
\hspace{10mm}10. …，\underline{前}十一時半〜後 2 時半，…\\
\hspace{10mm}11. …\underline{前}十時半と後 6 時，本館 1 階正面口で…\\
\hspace{10mm}12. …インフラ不安に要因を\underline{求め}，その強化対策を…\\
\hspace{10mm}13. …国を\underline{挙げて}緑化を進めた．\\
\hspace{10mm}14. …国を\underline{あげて}緑化に取り組んだシンガポールは，…\\
\hspace{10mm}15. 16. …「\underline{はじめる}・はじまる」は「初」でなく，「\underline{始める}・始まる」と書きます． \\
\normalsize


\subsection{素性の設定}

本手法を利用するためには，用例を素性ベクトルで表現しなくてはならない．そのために
以下の 8種類の素性を利用した．基本的 WSD で利用する素性である．
なお対象単語の直前の単語を\( w_{-1}\)，直後の単語を\( w_1 \)としている．

{\setlength{\leftskip}{4zw}
\noindent
e0　\( w \) の表記\\
e1　\( w \) の品詞\\
e2　\( w_{-1} \) の表記\\
e3　\( w_{-1} \) の品詞\\
e4　\( w_1 \) の表記\\
e5　\( w_1 \) の品詞\\
e6　\( w \) の前後 3 つまでの自立語の表記\\
e7　e6 の分類語彙表の番号の4桁と5桁\par
}

例えば以下は WSD の対象単語が 16単語目の \mbox{``経済''} である文の形態素解析結果である\footnote{SemEval-2 の
日本語 WSD タスクのデータはこの例のように，形態素解析済みのデータである．}．

\small
\begin{verbatim}
    <sentence>
    <mor pos="名詞-固有名詞-組織名" rd="デンツー">電通</mor>
    <mor pos="補助記号-読点" rd="，">，</mor>
    <mor pos="名詞-固有名詞-組織名" rd="ハクホー">博報</mor>
    <mor pos="接尾辞-名詞的-一般" rd="ドー">堂</mor>
    <mor pos="助詞-格助詞" rd="オ">を</mor>
    <mor pos="名詞-普通名詞-副詞可能" rd="ハジメ">はじめ</mor>
    <mor pos="名詞-普通名詞-一般" rd="ジョーイ">上位</mor>
    <mor pos="名詞-数詞" rd="ゴ">五</mor>
    <mor pos="接尾辞-名詞的-助数詞" rd="シャ">社</mor>
    <mor pos="助詞-副助詞" rd="クライ">くらい</mor>
    <mor pos="助動詞" rd="ナラ" bfm="ダ">なら</mor>
    <mor pos="名詞-普通名詞-一般" rd="エイチピー">HP</mor>
    <mor pos="助詞-格助詞" rd="オ">を</mor>
    <mor pos="動詞-一般" rd="ツクル" bfm="ツクル" >作る</mor>
    <mor pos="形状詞-一般" rd="ジンテキ">人的</mor>
    <mor pos="名詞-普通名詞-一般" rd="ケーザイ" sense="X">経済</mor>
    <mor pos="接尾辞-形状詞的" rd="テキ">的</mor>
    <mor pos="名詞-普通名詞-一般" rd="ヨユー">余裕</mor>
    <mor pos="助詞-係助詞" rd="モ">も</mor>
    <mor pos="動詞-非自立可能" rd="アル" bfm="アル" >ある</mor>
    <mor pos="助動詞" rd="デショー" bfm="デス">でしょう</mor>
    <mor pos="助詞-接続助詞" rd="ガ">が</mor>
    <mor pos="補助記号-読点" rd="，">，</mor>
    <mor pos="名詞-普通名詞-一般" rd="チューショー">中小</mor>
    <mor pos="助詞-格助詞" rd="ノ">の</mor>
    <mor pos="名詞-普通名詞-サ変可能" rd="ダイリ">代理</mor>
    <mor pos="接尾辞-名詞的-一般" rd="テン">店</mor>
    <mor pos="助詞-格助詞" rd="デ">で</mor>
    <mor pos="助詞-係助詞" rd="ワ">は</mor>
    <mor pos="連体詞" rd="ソンナ">そんな</mor>
    <mor pos="名詞-普通名詞-一般" rd="ヨユー">余裕</mor>
    <mor pos="助詞-係助詞" rd="ワ">は</mor>
    <mor pos="動詞-非自立可能" rd="アリ" bfm="アル" >あり</mor>
    <mor pos="助動詞" rd="マセ" bfm="マス">ませ</mor>
    <mor pos="助動詞" rd="ン" bfm="ヌ">ん</mor>
    <mor pos="補助記号-句点" rd="．">．</mor>
    </sentence>
\end{verbatim}

\normalsize
上記の用例から以下の素性リストが作成される．全体の素性リストが得られれば，
全リストの各要素（素性）=（素性値）を各次元に設定することで，
素性リストを素性ベクトル（実数値ベクトル）に変換できる．
またここでは作成した素性ベクトルの
大きさを 1 に正規化した．

\begin{verbatim}
    e0=経済，e1=名詞-普通名詞-一般，e2=人的，e3=形状詞，
    e4=的，e5=接尾辞，e6=人的，e6=作る，e6=HP，e6=余裕，
    e6=ある，e6=中小，e7=2386，e7=1197，e7=11972

\end{verbatim}

素性 e7 について注記しておく．上記例の場合，素性 e6 の値としては，
「人的」「作る」「HP」「余裕」「ある」「中小」の 6つ存在する．
各々の分類語彙表の番号を調べると，以下のようになっている\footnote{下位分類の番号は省略している．}．

\begin{verbatim}
        作る  ==>  2.386
        余裕  ==>  1.1972
        ある  ==>  2.120  3.100
\end{verbatim}

「人的」「HP」「中小」については分類語彙表に記載はない．
「作る」の \verb|2.386| から上位4桁を取り\verb|e7=2386|が作成される．
また「余裕」の \verb|1.1972| から上位4桁と5桁を取り\verb|e7=1197|と\verb|e7=11972|が作成される．
最後に「ある」に関してだが，この単語からは素性 e7 は作成しない．
本論文では全てひらがな文字からなる単語は多義語になっている場合が多い．
そのため分類語彙表の番号を素性リストに含めてもノイズの方が多いと考え，
そのような処理をしている．


\subsection{実験結果}

\subsubsection{F値による評価} 

まず F値による評価実験の結果を表\ref{tab:jikken2} に示す．
LOF では LOF 値の大きなもの上位 3つを取り出すことにする．
3つというのは，上位1つ，上位2つ，…，上位5つと各実験を行い，
最も検出能力が高かった（F値が高かった）ものである．
OCS は One Class SVM の意味である．
$\text{OCS}\cap\text{LOF}$は LOF の出力と OCS の出力の積集合をとったものである\cite{shinnou-lrec2010}．
この 3つが教師なしの外れ値検出に相当する．
LOF-e は教師データを除いて LOF 値の高い上位3つをとったたもの，
OCS-e は OCS の出力から教師データを除いたもの，
$\text{OCS}\cap\text{LOF-e}$ は LOF-e と OCS-e の出力の積集合を取ったものである．
またNN は \cite{erk} で用いられた最近傍法であり式(\ref{eq:siki1}) が 1.12 以上の
ものを取り出している．
1.12 という閾値は出力結果から F値が最も高くなるように
設定した値である\footnote{論文\cite{erk}で用いられている閾値は 1 である．}．
S-LOF は本論文で提案した教師付き LOFを指す．
S-LOF では，LOF と同様，LOF 値の高い上位3つを取り出すことにする．
また G-model は本論文で説明した生成モデルによるものである．
この 6つと S-LOF と G-model の出力の積集合を出力とする本手法の 
7つが教師付きの外れ値検出に相当する．


\begin{table}[t]
\caption{実験結果（F値）}
\label{tab:jikken2}
\input{03table01.txt}
\end{table}

教師ラベルを全く使わない場合，教師データからも外れ値が検出されるので，F値は低くなる．
また単純に通常の検出を行った後に教師データを除く方法（表\ref{tab:jikken2}の *-e の手法）よりも，
積極的に教師データを利用した S-LOF の方が F 値が高い．

また S-LOF と G-model は検出の手法が異なるために，検出結果の重なりが少なく，
結果的に両者の積集合を取る本手法の F値が最も高かった．

\subsubsection{平均適合率による評価} 

前節では手法の評価を F値で行った．本節では全データに対して外れ値の度合いの順位を出力し，
平均適合率を求めることで手法の評価を行う．

NN と G-model では出力の値（外れ値の度合い）をソートすることで，
全データに対する外れ値の度合いの順位が得られる．
LOF や S-LOF の場合は，単語毎に出力の値のスケールが異なるために，まず G-model で
行ったような正規化を行い，単語毎の出力値のスケールを揃える．
次に単語毎の出力値の上位 3位までの出力値に 100 を加えた後に，
全体をソートすることで，全データに対する外れ値の度合いの順位を得る．
「上位 3位までの出力値に 100 を加える」意味は，単語毎の出力値の上位 3位までを
優先して出力することに対応する\footnote{理論的には順位1位の出力値 + 1 で十分だが，
本論文で扱う手法は全て順位1位の出力値が 100 よりもかなり小さいので，100を加えるという
単純な処理にしている．}．これは本来 LOF や S-LOF は単語毎に上位数件を
外れ値として出力する手法であり，取り出さないデータの順位に意味があるかどうかは
不明であるために導入した処理である．実際，この処理を行った方が，行わなかった場合よりも
平均適合率は高かった．OCS の場合は，外れ値と判定したデータ群の重心を求め，
その重心との距離によって，全データに対する外れ値の度合いの順位を得た．
本手法 $(\text{G-model}\cap\text{S-LOF})$ の場合，基本的に G-model の出力の値を外れ値の度合いとするが，
本来の S-LOF における出力のデータ（単語毎の LOF値の上位 3件）に対しては，
G-model での出力の値に 100 を加えた後に，全体をソートした．
$\text{OCS}\cap\text{LOF}$ などの LOF類と積集合を取る手法も本手法と同様に，
LOF と組み合わせる方の手法のみで，まず外れ値の度合いを得て，
次に本来の LOF における出力のデータ（単語毎の LOF値の上位 3件）に対して 100 を加えた後に全体をソートした．

\begin{table}[b]
\caption{実験結果（平均適合率）}
\label{tab:ap}
\input{03table02.txt}
\end{table}

実験の結果を表\ref{tab:ap} に示す．表の1行目は手法名である．
紙面の都合上 $\text{OCS}\cap\text{LOF}$, $\text{OCS}\cap\text{LOF-e}$, G-model は，それぞれ
$\text{O}\cap\text{L}$, $\text{O}\cap\text{L-e}$, G-mdl と略記している．
表の1列目は新語義の現れた個数，表内の数値はその個数の時点での適合率である．
例えば，本手法の場合，1番目に新語義の現れた順位は 7 であり，その時点での
適合率は $1/7 = 0.14286$ であり，2番目に新語義の現れた順位は 13 であり，その時点での
適合率は $2/13 = 0.15385$ である．これを全ての新語義の個数 16個まで調べ，
各適合率の平均が平均適合率(Average Presision = AP) である．
そして各手法に対する平均適合率をグラフ化したものが図\ref{fig-ap} である．

\begin{figure}[t]
\begin{center}
\includegraphics{19-4ia3f5.eps}
\end{center}
\caption{平均適合率}
\label{fig-ap}
\end{figure} 

表\ref{tab:ap} 及び図\ref{fig-ap} より，本手法が最も平均適合率が高いことが確認できる．
また教師なしの手法にあたる LOF, OCS, $\text{OCS}\cap\text{LOF}$
の3つは 0.005 前後の値となり，教師ラベルを使わずに単純に
出力結果から教師データを除く手法 LOF-e, OCS-e, $\text{OCS}\cap\text{LOF-e}$ の3つは
0.010 弱の値になり，教師付き外れ値検出手法にあたる NN, S-LOF, G-model の3つは
0.010 強の値になる．これらのことから教師データを外れ値検出に積極的に利用する効果も確認できる．



\section{考察}

\subsection{教師データを $k+1$ 倍する効果} 

S-LOF は教師データを\( k+1 \)倍した LOF であるが，この倍率を 1 から\( k+1 \)まで変化させた結果を表\ref{tab:jikken2-tuika} に示す．なお倍率 1 倍は通常の LOF である．
正解の検出数及び教師データからの検出（誤検出）は\( k \)倍まではほぼ変化ないが，
\( k+1 \)倍することで急激に改善される．これにより教師データを\( k+1 \)倍する効果が確認できる．

\begin{table}[b]
\caption{S-LOF における教師データの倍率の変化}
\label{tab:jikken2-tuika}
\input{03table03.txt}
\end{table}

\subsection{WSD による新語義検出}

WSD の教師データが利用できるのであれば，WSD の分類器を学習し，
その識別の信頼度を利用して新語義が検出できると考えるのは自然である．
ただし単純にそのアプローチだけでは新語義の検出は困難である．

前述した素性を使い SVM を学習し，SemEval-2 日本語 WSD タスクの
テストデータ 50単語全てを対象に語義の曖昧性解消を行ったところ，
平均正解率は 0.7664 であった．上記タスクの参加システム中最高の
正解率は RALI-2 の 0.7636 であり\cite{semeval-2010}，
ここで学習できた SVM は十分能力が高いことがわかる．
上記 SVM の学習には LIBSVM を用いたが，そこでは\verb|-b|のオプションで
識別の信頼度（その語義に属する確率値）を求めることができる．
このオプションを用いて，閾値\( \theta \)以下の信頼度のときに，
その用例を新語義の用例とすることで新語義の検出を試みた．

\begin{figure}[b]
\begin{center}
\includegraphics{19-4ia3f6.eps}
\end{center}
\caption{閾値とF値}
\label{k-zettai}
\end{figure} 

閾値\( \theta \)の設定であるが，まず単純に 0.51 から 0.99 までの値を 0.01 刻みで設定し，
その値を用いた場合の検出結果に対する F値を求めた．そのグラフを図\ref{k-zettai} に示す．
\( \theta = 0.73\) のときに検出数 388 正解数 4 となり F値 が最大の 0.0198 を取る．
また語義数が\( K \)の場合，SVM が出力する識別の信頼度は
明らかに\( 1/K \)以上の値になるので，語義数の影響を受けている可能性がある．
そこで閾値を\( \theta = (1 + \alpha)/K \)と設定し，
\( \alpha \)を 0.01 刻みで 0.99 まで試したときのグラフを図\ref{k-soutai}に示す．
\( \alpha = 0.17\) のときに検出数 39 正解数 2 となり F値 が最大の 0.0727 を取る．

\begin{figure}[b]
\begin{center}
\includegraphics{19-4ia3f7.eps}
\end{center}
\caption{語義数を考慮した閾値とF値}
\label{k-soutai}
\end{figure} 

F値 0.0727 は表\ref{tab:jikken2} で示された外れ値検出手法と比較すると，
それほど悪いとも言えないが，WSD システム単独では新語義の検出が困難であることがわかる．

また平均適合率の評価も行っておく．システムが識別した語義の信頼度によって，
全体のデータを（昇順に）ソートすることで，平均適合率を調べたところ 0.00638 となった．
この値は表\ref{tab:ap} に示した外れ値検出手法による平均適合率と比べると
高い値とは言えない．平均適合率の観点からも，
WSD システム単独では新語義の検出が困難であることがわかる．

上記では語義の識別の信頼度により新語義を検出するアプローチであったが，
ここでは SVM を利用しているので，one-vs-rest 法を利用して，
語義毎に SVM を学習し，すべての語義について否と判定されたものを
新語義とするアプローチも考えられる．このアプローチによる評価も行っておく．

語義毎に SVM を学習する際にも LIBSVM の\verb|-b|のオプションを用いる．
語義毎の各 SVM が否と識別した信頼度を集め，その最小値\( \gamma \)をそのデータの新語義の度合いとする．
\( \gamma \)が閾値\( \theta \)よりも大きい場合に，新語義と判定する．
\( \theta = 0.5 \)は語義毎の SVM 全てが否と判定したものを新語義と判定することを意味する．
出力結果の分析から\(\theta = 0.6996\)のときに検出数 33 正解数 1 となり F値 が最大の 0.0408 を取る．
また one-vs-rest 法を利用した場合の平均適合率も調べた．\( \gamma \)の値を新語義の度合いとし，
全データに対して新語義の度合いの順位を出力することで平均適合率が求まる．
結果，平均適合率は 0.0132 であった．

F値にしても平均適合率にしても，表\ref{tab:jikken2} や図\ref{fig-ap} と比較すると，
通常の教師付きの外れ値検出手法と同程度である．one-vs-rest 法を利用した場合でも，
WSD システム単独では新語義の検出が困難であることがわかる．


\subsection{未出現語義を含めた評価}

SemEval-2 日本語 WSD タスクでは，教師データ中には現れないが，
テストデータには出現する語義が存在する．このような教師データ中の未出現語義は，
新語義と見なすこともできる．このような用例は
「あう」で 1用例，「すすめる」で 1用例，「出す」で 3用例，「立つ」で 1用例，
「とる」で 3用例，「ひとつ」で 1用例，「見る」で 6用例，「持つ」で 1用例，
「大きい」で 2用例，「与える」で 1用例の合計 20用例存在する．
これらも新語義の用例と見なした場合の検出結果を表\ref{tab:jikken3} に示す．
F値の括弧内の数値は正解を新語義のみにした場合の正解数とF値（表\ref{tab:jikken2} の値）である．

\begin{table}[b]
\caption{未出現語義を含めた評価（F値）}
\label{tab:jikken3}
\input{03table04.txt}
\end{table}
\begin{table}[b]
\caption{未出現語義を含めた評価（平均適合率）}
\label{tab:ap2}
\input{03table05.txt}
\end{table}


また平均適合率の評価も行っておく．各手法の平均適合率の求め方は前述した方法で行う．
結果を表\ref{tab:ap2} に示す．表\ref{tab:ap2} の「新語義のみ」の列は
正解を新語義のみにした場合であり，「未出現語義を含む」の列は
正解を新語義と未出現語義を合わせたものにした場合である．


F値の評価でも平均適合率の評価でも本手法が最も高い値を出しており，
本手法の効果は確認できる．
ただし全体的な傾向として，未出現語義を正解に含めた場合の方が，
F値も平均適合率も若干高くなるが，本手法に関しては値が下がっている．
S-LOF や G-model は未出現語義を正解に含めると，検出できる正解数は増えるが，
共通して検出できる部分がなかったために，このような結果になった．
この対策としては，後述するアンサンブル手法の導入により改良していきたい．

また，前節の WSD システムを用いた場合の評価を表\ref{tab:wsd+} に示す．
F 値と平均適合率の括弧内の数値は正解を「新語義のみ」にしたものである．

\begin{table}[t]
\caption{未出現語義を含めた WSD の評価}
\label{tab:wsd+}
\input{03table06.txt}
\end{table}

未出現語義を正解に含めた場合でも，前節同様，
WSD システム単独では新語義の検出が困難であるといえる．


\subsection{誤検出・未検出の原因}

本手法の誤検出の原因について述べる．1つは固有表現や熟語内の単語である．
例えば以下のような表現が検出されている．

\begin{itemize}
\item[(a)] 未来科学\underline{技術}共同研究センターの中の研究施設
\item[(b)] 昔話の「千代ごこ\underline{出}やっせ」のように
\item[(c)] 中小零細企業の取材は数多く\underline{手}がかかる割りに
\end{itemize}

固有表現や熟語内の単語に通常の意味があるとは考えづらく，
新語義の検出という観点では，このような表現を抽出しても
完全に誤りとは言えない．
本来，新語義の検出するためには，固有表現や熟語を予め抽出しておくことが
必要だと考える．

また誤検出のその他の原因は多様であるが，全体として，対象単語の直前や直後に自立語が現れる
複合語の用法や動詞の連体形の用法などが目立った．

\begin{itemize}
\item[(d)] わが国が最も重要な貿易\underline{相手}国の一つ
\item[(e)] 人間性を疑ってしまう人とは男女\underline{関係}なく，
\item[(f)] 夏休み等に行って来た時の経験＝古き\underline{良き}時代を，
\end{itemize}

複合語が専門性の高い用語である場合は意味のある検出とも見なせるが，
ここでは複合語を単なる名詞連続で認識しているために，専門用語との区別は付けられない．
新語義の検出に関しては，熟語や固有表現と同様，専門用語も通常の表現とは，
区別した方がよいと考える．

本手法の未検出の原因としては，突き詰めれば，用例間の距離の測定方法に帰着される．
ある新語義の用例と他の正常値の用例との距離がある程度，離れていたとしても，
正常値の用例間の距離も同程度は離れているという状況である．
これは動詞や形容詞における検出では顕著である．
この問題に注目して距離学習を新語義発見に応用した研究も存在する\cite{msasaki}．
ただしこの問題は本質的に語義曖昧性解消の場合と同じであり，語義曖昧性解消の精度向上の試みが
本研究に応用できる．



\subsection{教師付き LOF とパラメータ\( k \)}

オリジナルの LOF ではパラメータ\( k \)が存在し，
この値が精度に大きく影響することが指摘されている．
ここで提案した教師付き LOF では更に\( k \)の設定はシビアである．

教師付き LOF では，テストデータ\( y \)と最も近い点が教師データ\( x \)であった場合，
\( x \)の密度が非常に高いために\( LOF(y) \)の値も高くなり，一見，不都合に感じる．
ただしテストデータ\( z \)の場合も，最も近い点が教師データ\( x \)であり，
\( d(x,y) < d(x,z) \)となっている場合は，\( LOF(y) < LOF(z) \)となるために，
\( y \)の外れ値の程度は\( z \)よりも下がる（図\ref{kou1} 参照）．

\begin{figure}[b]
\begin{center}
\includegraphics{19-4ia3f8.eps}
\end{center}
\caption{教師データとの位置関係による外れ値の度合い1}
\label{kou1}
\end{figure} 

つまり極端に言えば，教師付き LOF は，最も近い点が教師データであり，
しかもその点までの距離が大きい場合に外れ値の程度が大きくなる．
これは外れ値の性質としては妥当である．
現実的にはテストデータ\( y \)の \( k \)近傍\( N_{k}(y) \)の中に教師データ\( x \)が入るかどうか，
\( y \)から\( x \)までの距離\( d(x,y)\)，\( N_{k}(y) \)の中にテストデータがいくつ入るか及び
それらの位置関係が\( LOF(y) \)の値に影響している．
もしも\( N_{k}(y) \)の中に教師データが入らない場合は，
入る場合と比較して極端に\( LOF(y) \)の値は小さいので，\( y \)が外れ値として
検出されることはない（図\ref{kou2} 参照）．

\begin{figure}[t]
\begin{center}
\includegraphics{19-4ia3f9.eps}
\end{center}
\caption{教師データとの位置関係による外れ値の度合い2}
\label{kou2}
\vspace{-1\Cvs}
\end{figure} 

「\( k \)近傍内に教師データが入らない場合は外れ値ではない」という設定が妥当かどうかは不明である．
当然，そうではない場合も想定することは可能だが，
実験結果をみると本タスクにおいては上記設定が有効に機能していた．
おそらく\( k \)近傍内に教師データが入らない場合は，そのデータ近辺の密度が低いためだと考えられる．

ここで提案した教師付き LOF では，\( k \)近傍内に教師データが入るかどうかで，
外れ値かどうかの最初の判定がされていると見なすこともできるので，
パラメータ\( k \)の値は，通常の LOF よりも更に精度に影響を与えていると言える．


\subsection{外れ値検出手法のアンサンブル}

外れ値検出手法は数多く提案されており，本論文で利用した LOF についても
いくつかの改良手法が提案されている\cite{jin,papadimitriou}．
これらの手法をどのようにして教師付きの枠組みへ拡張するかは不明であるが，
これらを利用することで本手法の改善も可能である．

また，新たに外れ値検出手法を考案するのではなく，既存の手法を組み合わせる戦略も有効である．
Lazavic は複数の外れ値検出の手法を適用して，それら出力結果を総合的に
判断して最終的に外れ値候補を出力するという外れ値検出手法のアンサンブル(ensemble)を提案した\cite{lazavic}．
ここで提案した LOF と生成モデルの組み合わせも，外れ値検出手法のアンサンブルの一種と考えられる．
ここでは単純に出力の積により最終の出力を決めたが，重みを付けて判断するなどの
工夫も考えられる．あるいは他の外れ値検出の手法の組み合わせることも有効であろう．
表\ref{tab:jikken3} からもわかるとおり，LOF の出力と生成モデルの出力は
かなり異なる．単純に出力の和を取ると，検出数が多くなりすぎて F値の評価は下がってしまうが，
第 1 段目の候補としては取り出せているので，そこからの選別に工夫することで
改善が可能である．ここらが今後の課題である．

また，本論文では S-LOF と G-model のアンサンブルを提案したが，実験の結果をみると
NN と G-model のアンサンブルや S-LOF と NN のアンサンブルも有望に見える．
それらの実験結果を表7に示す\footnote{$\text{G-model}\cap\text{NN}$ の平均適合率の
測り方は $\text{G-model}\cap\text{S-LOF}$（本手法）と同様である．
つまり，G-model の出力の値を外れ値の度合いとし，
本来の NN における出力のデータに対しては，G-model での出力の値に 100 を加えた後に，全体をソートした．} ．

\begin{table}[t]
\caption{手法の組み合わせの評価}
\label{tab:nncombi}
\input{03table07.txt}
\end{table}


表7が示すとおり，
提案手法の S-LOF と G-model のアンサンブルが最も優れている．
また組み合わせる手法によっては，個々の手法よりも精度が劣化することもありえるので，
アンサンブルに用いる手法の選択も重要であることがわかる．


\section{おわりに}

本論文では対象単語の用例集合から，その単語の語義が新語義となっている
用例を検出する手法を提案した．
基本的に新語義の用例を用例集合中の外れ値と考え，外れ値検出の手法を利用する．
ただし従来の外れ値検出では教師なしの枠組みであるが，
ここではタスクの性質を考慮し，教師付きの枠組みで行った．

まず LOF を教師データを利用する形に改良した教師付き LOF を提案し，
次に教師データを利用することで生成モデルを構築した．
提案手法は上記2つの手法それぞれの出力の共通部分（積集合）を取るものである．
これは 2 つの異なったタイプの外れ値検出の手法の積集合を取ることで
誤検出を減らし，結果的に検出能力を高めることを狙いとしている．

タスクの一部として新語義識別を含む SemEval-2 の 日本語 WSD タスクのデータを利用して，
LOF, One Class SVM, 最近傍法，教師付き LOF，生成モデルおよび提案手法による新語義の
検出実験を行った．それぞれの手法の F値と平均適合率を求めることで，提案手法の有効性を示した．
また教師なしの手法 (LOF, OCS, $\text{OCS}\cap\text{LOF}$)，
単純に教師データを検出結果から除く手法 (LOF-e, OCS-e, $\text{OCS}\cap\text{LOF-e}$) 及び教師付きの
手法 (NN, S-LOF, G-model) の F値と平均適合率を比較することで，
新語義検出を目的とした外れ値検出では，教師データを積極的に利用することが精度向上に
効果があることが確認できた．
また WSD システムの識別の信頼度を利用した新語義を検出実験も行った．
十分なパフォーマンスを示す WSD システムを用いても，WSD システム単独では新語義の検出が困難であることも示した．

提案手法は外れ値検出手法のアンサンブルの手法と位置づけられる．
提案手法における出力結果のアンサンブルは，積集合をとるという単純なものであるため，
この部分に工夫を入れることで更に検出能力が高まると予想している．
出力結果の統合方法を工夫することが今後の課題である．





\begin{thebibliography}{}

\bibitem[\protect\BCAY{Agirre \BBA\ Soroa}{Agirre \BBA\ Soroa}{2007}]{agirre}
Agirre, E.\BBACOMMA\ \BBA\ Soroa, A. \BBOP 2007\BBCP.
\newblock \BBOQ {Semeval-2007 task 02: Evaluating word sense induction and
  discrimination systems}.\BBCQ\
\newblock In {\Bem SemEval-2007}.

\bibitem[\protect\BCAY{赤穂}{赤穂}{2008}]{akaho}
赤穂昭太郎 \BBOP 2008\BBCP.
\newblock \Jem{カーネル多変量解析}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{Bordag}{Bordag}{2006}]{stefan}
Bordag, S. \BBOP 2006\BBCP.
\newblock \BBOQ {Word sense induction: Triplet-based clustering and automatic
  evaluation}.\BBCQ\
\newblock In {\Bem {EACL-2006}}, \mbox{\BPGS\ 137--144}.

\bibitem[\protect\BCAY{Breuning, Kriegel, Ng, \BBA\ Sander}{Breuning
  et~al.}{2000}]{lof}
Breuning, M.~M., Kriegel, H.-P., Ng, R.~T., \BBA\ Sander, J. \BBOP 2000\BBCP.
\newblock \BBOQ {LOF: Identifying Density-Based Local Outliers}.\BBCQ\
\newblock In {\Bem {ACM SIGMOD 2000}}, \mbox{\BPGS\ 93--104}.

\bibitem[\protect\BCAY{Denkowski}{Denkowski}{2009}]{denkowski}
Denkowski, M. \BBOP 2009\BBCP.
\newblock \BBOQ {Survey of Techniques for Unsupervised Word Sense
      Induction}.\BBCQ

\bibitem[\protect\BCAY{Erk}{Erk}{2006}]{erk}
Erk, K. \BBOP 2006\BBCP.
\newblock \BBOQ {Unknown word sense detection as outlier detection}.\BBCQ\
\newblock In {\Bem {NAACL-2006}}, \mbox{\BPGS\ 128--135}.

\bibitem[\protect\BCAY{Jin, Tung, Han, \BBA\ Wang}{Jin et~al.}{2006}]{jin}
Jin, W., Tung, A. K.~H., Han, J., \BBA\ Wang, W. \BBOP 2006\BBCP.
\newblock \BBOQ {Ranking outliers using symmetric neighborhood
  relationship}.\BBCQ\
\newblock In {\Bem The 10th Pacific-Asia conference on Advances in Knowledge
  Discovery and Data Mining (PAKDD '06)}, \mbox{\BPGS\ 577--593}.

\bibitem[\protect\BCAY{九岡\JBA 白井\JBA 中村}{九岡 \Jetal }{2008}]{kuoka}
九岡佑介\JBA 白井清昭\JBA 中村誠 \BBOP 2008\BBCP.
\newblock 複数の特徴ベクトルのクラスタリングに基づく単語の意味の弁別.\
\newblock \Jem{第14回言語処理学会年次大会}, \mbox{\BPGS\ 572--575}.

\bibitem[\protect\BCAY{Lazarevic \BBA\ Kumar}{Lazarevic \BBA\
  Kumar}{2005}]{lazavic}
Lazarevic, A.\BBACOMMA\ \BBA\ Kumar, V. \BBOP 2005\BBCP.
\newblock \BBOQ Feature bagging for outlier detection.\BBCQ\
\newblock In {\Bem The eleventh ACM SIGKDD international conference on
  Knowledge discovery in data mining (KDD '05)}, \mbox{\BPGS\ 157--166}.

\bibitem[\protect\BCAY{Okumura, Shirai, Komiya, \BBA\ Yokono}{Okumura
  et~al.}{2010}]{semeval-2010}
Okumura, M., Shirai, K., Komiya, K., \BBA\ Yokono, H. \BBOP 2010\BBCP.
\newblock \BBOQ {SemEval-2010 Task: Japanese WSD}.\BBCQ\
\newblock In {\Bem {The 5th International Workshop on Semantic Evaluation}},
  \mbox{\BPGS\ 69--74}.

\bibitem[\protect\BCAY{Papadimitriou, Kitagawa, Gibbons, \BBA\
  Faloutsos}{Papadimitriou et~al.}{2003}]{papadimitriou}
Papadimitriou, S., Kitagawa, H., Gibbons, P.~B., \BBA\ Faloutsos, C. \BBOP
  2003\BBCP.
\newblock \BBOQ {LOCI: Fast Outlier Detection Using the Local Correlation
  Integral}.\BBCQ\
\newblock In {\Bem ICDE-2003}, \mbox{\BPGS\ 315--326}.

\bibitem[\protect\BCAY{Sasaki \BBA\ Shinnou}{Sasaki \BBA\
  Shinnou}{2012}]{msasaki}
Sasaki, M.\BBACOMMA\ \BBA\ Shinnou, H. \BBOP 2012\BBCP.
\newblock \BBOQ {Detection of Peculiar Word Sense by Distance Metric Learning
  with Labeled Examples}.\BBCQ\
\newblock In {\Bem LREC-2012}, \mbox{\BPGS\ Session--P6}.

\bibitem[\protect\BCAY{Sch\"{o}lkopf, Platt, Shawe-Taylor, Smola, \BBA\
  Williamson}{Sch\"{o}lkopf et~al.}{2001}]{oc-svm}
Sch\"{o}lkopf, B., Platt, J.~C., Shawe-Taylor, J., Smola, A.~J., \BBA\
  Williamson, R.~C. \BBOP 2001\BBCP.
\newblock \BBOQ Estimating the support of a high-dimensional
  distribution.\BBCQ\
\newblock {\Bem Neural Computation}, {\Bbf 13}  (7), \mbox{\BPGS\ 1443--1471}.

\bibitem[\protect\BCAY{Sch\"{u}tze}{Sch\"{u}tze}{1998}]{shutze}
Sch\"{u}tze, H. \BBOP 1998\BBCP.
\newblock \BBOQ Automatic word sense discrimination.\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 24}  (1), \mbox{\BPGS\
  97--123}.

\bibitem[\protect\BCAY{Shinnou \BBA\ Sasaki}{Shinnou \BBA\
  Sasaki}{2010}]{shinnou-lrec2010}
Shinnou, H.\BBACOMMA\ \BBA\ Sasaki, M. \BBOP 2010\BBCP.
\newblock \BBOQ {Detection of Peculiar Examples using LOF and One Class
  SVM}.\BBCQ\
\newblock In {\Bem {LREC-2010}}.

\bibitem[\protect\BCAY{Shirai \BBA\ Nakamura}{Shirai \BBA\
  Nakamura}{2010}]{shirai-semeval2}
Shirai, K.\BBACOMMA\ \BBA\ Nakamura, M. \BBOP 2010\BBCP.
\newblock \BBOQ {JAIST: Clustering and Classification Based Approaches for
  Japanese WSD}.\BBCQ\
\newblock In {\Bem {The 5th International Workshop on Semantic Evaluation}},
  \mbox{\BPGS\ 379--382}.

\bibitem[\protect\BCAY{Sugiyama \BBA\ Okumura}{Sugiyama \BBA\
  Okumura}{2009}]{sugiyama}
Sugiyama, K.\BBACOMMA\ \BBA\ Okumura, M. \BBOP 2009\BBCP.
\newblock \BBOQ {Semi-supervised Clustering for Word Instances and Its Effect
  on Word Sense Disambiguation}.\BBCQ\
\newblock In {\Bem {The 10th International Conference on Intelligent Text
  Processing and Computational Linguistics (CICLing 2009)}}, \mbox{\BPGS\
  266--279}.

\bibitem[\protect\BCAY{高村}{高村}{2010}]{takamura}
高村大也 \BBOP 2010\BBCP.
\newblock \Jem{言語処理のための機械学習入門}.
\newblock コロナ社.

\bibitem[\protect\BCAY{田中\JBA 中村\JBA 白井}{田中 \Jetal }{2009}]{tanaka-h}
田中博貴\JBA 中村誠\JBA 白井清昭 \BBOP 2009\BBCP.
\newblock 新語義発見のための用例クラスタと辞書定義文の対応付け.\
\newblock \Jem{第15回言語処理学会年次大会}, \mbox{\BPGS\ 590--593}.

\bibitem[\protect\BCAY{山西}{山西}{2009}]{yamanishi}
山西健司 \BBOP 2009\BBCP.
\newblock \Jem{データマイニングによる異常検知}.
\newblock 共立出版.

\end{thebibliography}

\begin{biography}

\bioauthor{新納　浩幸}{
1985年東京工業大学理学部情報科学科卒業．
1987年同大学大学院理工学研究科情報科学専攻修士課程修了．
同年富士ゼロックス，翌年松下電器を経て，
1993年4月茨城大学工学部システム工学科助手．
1997年10月同学科講師，2001年4月同学科助教授，
現在，茨城大学工学部情報工学科准教授．博士（工学）．
機械学習や統計的手法による自然言語処理の研究に従事．
言語処理学会，情報処理学会，人工知能学会 各会員．
}
\bioauthor{佐々木　稔}{
1996年徳島大学工学部知能情報工学科卒業．
2001年同大学大学院博士後期課程修了．博士（工学）．
2001年12月茨城大学工学部情報工学科助手．
現在，茨城大学工学部情報工学科講師．
機械学習や統計的手法による情報検索，自然言語処理等に関する研究に従事．
言語処理学会，情報処理学会 各会員．
}

\end{biography}


\biodate


\end{document}

