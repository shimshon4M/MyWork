<?xml version="1.0" ?>
<root>
  <jtitle>外れ値検出手法を利用した新語義の検出</jtitle>
  <jauthor>新納浩幸佐々木稔</jauthor>
  <jabstract>本論文では対象単語の用例集合から，その単語の語義が新語義（辞書に未記載の語義）となっている用例を検出する手法を提案する．ここでのアプローチの基本は，新語義の用例が用例集合中の外れ値になると考え，データマイニング分野の外れ値検出の手法を利用することである．ただし外れ値検出のタスクは教師なしの枠組みになるが，新語義検出という本タスクの性質を考慮すると，一部のデータ（用例）にラベル（対象単語の語義）が付与されているという枠組みで考える方が適切である．そのため本論文では一部のデータにラベルがついているという教師付きの枠組みで外れ値検出を行う．具体的には2つの手法（教師付きLOFと生成モデル）を用い，それら出力の共通部分（積集合）を最終的な出力とする．この教師付きLOFと生成モデルの積集合を出力する手法を提案手法とする．実験ではSemEval-2日本語WSDタスクのデータを用いて，提案手法の有効性を示した．またWSDのアプローチを単独で利用しただけでは，本タスクの解決が困難であることも示した．</jabstract>
  <jkeywords>新語義，外れ値検出，LOF，生成モデル，OneClassSVM，SemEval-2日本語WSDタスク</jkeywords>
  <subsection title="教師データを k+1 倍する効果">S-LOFは教師データを(k+1)倍したLOFであるが，この倍率を1から(k+1)まで変化させた結果を表に示す．なお倍率1倍は通常のLOFである．正解の検出数及び教師データからの検出（誤検出）は(k)倍まではほぼ変化ないが，(k+1)倍することで急激に改善される．これにより教師データを(k+1)倍する効果が確認できる．</subsection>
  <section title="はじめに">本論文では対象単語の用例集合から，その単語の語義が新語義（辞書に未記載の語義）となっている用例を検出する手法を提案する．新語義の検出は語義曖昧性解消の問題に対する訓練データを作成したり，辞書を構築する際に有用である．また新語義の検出は意味解析の精度を向上させる．また新語義の用例はしばしば書き誤りとなっているので，誤り検出としても利用できる．新語義検出は一般にWordSenseDisambiguation(WSD)の一種として行う方法，新語義の用例をクラスターとして集めるWordSenseInduction(WSI)のアプローチで行う方法，及び新語義の用例を用例集合中の外れ値とみなし，外れ値検出の手法を用いる方法がある．ここでは外れ値検出の手法のアプローチを取る．ただしデータマイニングで用いられる外れ値検出の手法は教師なしであるが，本タスクの場合，少量の用例に語義のラベルが付いているという教師付きの枠組みで行う方が自然であり，ここでは教師付き外れ値検出の手法を提案する．提案手法は2つの検出手法を組み合わせたものである．第1の手法は代表的な外れ値検出手法であるLocalOutlierFactor(LOF)を教師付きの枠組みに拡張したものである．第2の手法は，対象単語の用例（データ）の生成モデルを用いたものである．一般に外れ値検出はデータの生成モデルを構築することで解決できる．提案手法では第1の手法と第2の手法の出力の積集合を取ることで，最終の出力を行う．提案手法の有効性を確認するために，SemEval-2の日本語WSDタスクのデータを利用した．従来の外れ値検出の手法と比較することで提案手法の有効性を示す．実験を通して，外れ値検出に教師データを利用する効果も確認する．またSVMによるWSDの信頼度を利用した外れ値検出も行い，WSDシステム単独では新語義の検出は困難であることも示す．</section>
  <section title="従来の新語義検出手法"/>
  <subsection title="WSD の信頼度の利用">WSDは語義を識別するタスクなので，WSDシステムを利用すれば新語義を検出できると考えるのは自然である．WSDの対象単語(w)の語義のクラスを(C)とする．関数(f(x,c))はあるWSDシステムが出力する用例(x)中の(w)の語義が(cC)となる信頼度とする．このWSDシステムは(argmax_cCf(x,c))により語義を識別する．新語義の検出はある閾値()を定め，のときに(x)を新語義の用例と判定することで，新語義を検出できる．ただし適切な()の値は単語毎に異なるはずであり，その設定は困難である．またWSDは識別のタスクであり，一般にWSDシステムはSVMのような識別モデルをもとに構築される．そのためシステムは語義の識別精度が上がるように最適化されており，(f(x,c_i))の値は(f(x,c_j))との相対的なものである．つまりにより新語義が検出できる保証はない．例えば図のような状況を考えてみる．図のクラス1とクラス2を分離する直線が，分類器に対応する識別境界とする．データがクラスに属する信頼度は，一般に，識別境界までの距離で測るので，図のデータaとデータbはクラス1と識別され，その信頼度は等しくなる．識別の場合はデータが識別境界のどちら側に属するかだけが重要なので，それで十分であるが，データaとデータbを比べると，明らかにデータbの方がクラス1に属する信頼度が低い．</subsection>
  <subsection title="WSI による検出">従来，新語義の検出はWordSenseInduction(WSI)というタスクの一部として行われてきた．WSIは本質的には対象単語の用例を語義に基づいてクラスタリングするタスクである．用例集合中に新語義の用例があれば，それらも語義のクラスターとして出現するために新語義の検出として利用できる．ただし陽に新語義を検出するには，得られたクラスターに語義のラベルを付与する必要がある．Shiraiは辞書に記述された語義の定義文を利用して，得られたクラスターに語義のラベルを付けることで新語義を検出しようとしている．またSugiyamaは既存語義の用例を種用例として，用例集合を半教師なしクラスタリングによりクラスタリングした．種用例のないクラスターが新語義のクラスターとなる．ただしどちらもクラスタリング自体の精度が悪く，新語義の検出までには至っていない．本来，クラスターに語義のラベルを付けるためには，語義のラベル集合が必要である．語義のラベル集合を定めた場合に，WSIとWSDとの違いはほとんどなくなる．WSDを行う前に教師なし学習であるクラスタリングを行うアプローチが，新語義の検出に有効かどうかは不明である．また用例を語義に基づいてクラスタリングする場合，クラスターの数の決め方が大きな問題になる．また新語義がクラスターを形成するという仮定は，多くの新語義に対して当てはまらない．クラスターを形成するくらいに，その語義の用例が存在するのであれば，その語義は新語義ではなく既に一般的な語義と考えられる．</subsection>
  <subsection title="外れ値検出による検出">新語義の用例を用例集合内の外れ値と見なし，外れ値検出の手法を利用して新語義を検出するアプローチがある．Erkは外れ値検出手法の最近傍法を利用して新語義の検出を試みた．対象単語(w)の語義が付与された用例集を(D)とし，用例(x)の外れ値の度合い(out(x))をで測り，この値が1以上の(x)を新語義の用例とした．ここで(d(x,y))は用例(x)と用例(y)間の距離である．この式は(D)の中で(x)と最も距離が近いデータ(y)を選び，更にその(y)と最も距離が近い(D)内のデータ(z)を選んで，(d(x,y))と(d(y,z))の比を取ったものである（図参照）．ただし最近傍法が妥当な精度を出すには，大量の訓練データを必要とするという問題がある．</subsection>
  <section title="外れ値検出手法">データマイニング分野の外れ値検出手法は非常に多岐にわたるが，その多くは変化点検出の手法に位置づけられる．つまり時系列的にデータが生起するオンラインでのタスクに対する手法が中心である．新語義検出のようなバッチ的なタスクに対する手法としては，密度ベースの手法，OneClassSVM，生成モデルによる手法が代表的な手法である．ここではこの3つの手法を本論文の提案手法との比較手法とする．</section>
  <subsection title="密度ベースの手法">外れ値検出は古典的にはマハラノビス距離を用いた距離ベースの手法が中心だが，それを改良したのが密度ベースの手法であり，密度ベースの代表的な手法がLOFである．LOFは，データの近傍の密度を利用することで，そのデータの外れ値の度合いを測り，その値によって外れ値を検出する．LOFにおけるデータ(xD)における外れ値の度合いを(LOF(x))と表記する．ここで(D)はデータ全体の集合である．(LOF(x))を定義するために，いくつかの式を定義しておく．まず(kdist(x))は(x)に対する(k)距離と呼ばれる値で，以下の条件を満たすデータ(oD)との距離(d(x,o))として定義される．少なくとも(k)個のデータ(o'Dx)に対して(d(x,o')d(x,o))が成立する．高々(k-1)個のデータ(o'Dx)に対してのみ(d(x,o')&lt;d(x,o))が成立する．直感的には，上記のデータ(o)はデータ(x)からの(k)番目に近いデータとなる．データ(x)から同じ距離を持つデータが複数存在する場合を考慮して，上記のようなテクニカルな定義になっている．次に(kdist(x))を利用して，(N_k(x))，(rd_k(x,y))及び(lrd_k(x))を定義してゆく．[N_k(x)=yDx|d(x,y)kdist(x)]これは(x)の(k)近傍と呼ばれる集合であり，(x)との距離が(kdist(x))以下になるようなデータの集合である．[rd_k(x,y)=d(x,y),kdist(y)]これは(x)から(y)への距離を表すが，(x)が(y)の(k)近傍内に入る場合に，その距離を(kdist(y))で置き換えている．直感的にはデータ間の距離が近い場合に，(k)距離で補正している．[lrd_k(x)=|N_k(x)|_yN_k(x)rd_k(x,y).]これは(x)の(k)近傍内のデータ(y)の(rd_k(x,y))の平均の逆数であり，これが(x)の密度を表している．これらの式を用いて，(LOF(x))は以下で定義される．[LOF(x)=1|N_k(x)|_yN_k(x)lrd_k(y)lrd_k(x)]つまり(x)の(k)近傍内のデータの密度と(x)の密度の比の平均を外れ値の度合いとしている．直感的には近くのデータの密度は高く，自身の密度が低い場合に外れ値の度合いが高くなる．また「近くのデータの密度は高く，自身の密度が低い」というのは，ある密度の高いクラスターがあり，そこから離れている独立のデータであるような場合である．例えば図では，データaとデータbが外れ値である．距離ベースの手法では，データbは外れ値として検出できるが，データaはクラスターAとの距離が近いために検出できない．一方LOFでは，クラスターAの密度が高く，データaの近辺にはデータがなく孤立しているので，外れ値として検出できる．またLOFではパラメータとして(k)が存在する．本論文では(k=5)としている．</subsection>
  <subsection title="One Class SVM">OneClassSVMは(-)SVMを利用した外れ値検出の手法である．すべてのデータは(+1)のクラスに属し，原点のみが(-1)のクラスに属するとして，(-)SVMを使って2つのクラスを分離する超平面を求める．原点はすべての点に対して類似度が0となるために，外れ値とみなせる．また(-)SVMはソフトマージンを利用するので，(-1)のクラス側に属するデータを外れ値と判定する．図で概略を説明する．図の星形の点が外れ値である．原点は全ての点と内積が0となる，つまり類似度が0であるために外れ値と考える．図の星形の点（外れ値）も含め，原点以外のすべての点を正常値と考え，外れ値と正常値を分離する超平面を(-)SVMで求める．(-)SVMはソフトSVMであり，教師データのすべての点を正確に分離するわけではなく，少数の誤りを認める．図では原点付近に超平面（この場合，直線）を近づければ，識別の精度は向上するが，その場合，最大マージンが小さくなる．最大マージンを大きくしようとすると，識別の精度は下がる．このバランスをうまくとるような超平面を求めるのが(-)SVMである．最終的に原点側に属するデータが外れ値と判断される．OneClassSVMを利用する際には，用いるカーネル関数やどの程度のマージンの誤りを認めるかのパラメータの設定が結果に大きく影響する．本論文の実験ではOneClassSVMのプログラムとしてLIBSVMcjlin/libsvm/を用いた．カーネルは線形カーネルを利用し，マージンの誤りはパラメータ(n)に対応するが，(n=0.02)で固定した．</subsection>
  <subsection title="生成モデルによる手法">データ(x)の生成過程を確率モデル(P(x))でモデル化したものを生成モデルと呼ぶ．一般に潜在変数(z_i)を導入し，ある確率モデル(P_i(x))の混合分布により(P(x))をモデル化する．[P(x)=_iz_iP_i(x)s.t.0z_i1,_iz_i=1]モデル化の後に，与えられたデータからEM法などを利用して，(z_i)と(P_i(x))のパラメータを推定することで(P(x))を構成する．データ(x)の外れ値の度合いとしては(-P(x))が用いられる．この値が大きいほど外れ値と見なせる．</subsection>
  <section title="提案手法"/>
  <subsection title="教師付き外れ値検出">一般に外れ値検出のタスクでは外れ値の定義が不可能である．これは外れ値にラベルをつける意味がないことを示している．なぜなら仮にあるデータが外れ値であり，その外れ値にラベルをつけることができたとしても，他の外れ値がそのラベル付きの外れ値と類似している保証がないからである．また検出元となるデータ集合は，ほぼすべて正常値である．仮にデータにラベルをつけるとすれば，正常値のラベルだけになり，教師データに意味はない．これらのことから外れ値検出の手法は教師なしの枠組みにならざるをえない．しかし新語義の用例を外れ値と見なした新語義検出のタスクの場合，一般の外れ値検出とは異なった2つの特徴がある．1つは外れ値の定義が明確という点である．ここでの外れ値は新語義の用例であるが，新語義とは「辞書に記載されていない語義」というように明確に定義できる．もう1つは正常値のデータは語義のクラスターに分割されるという点である．しかもクラスターの数も明確である．一方，通常の外れ値検出では正常値の集合がクラスターに分割されるのか，されるとしてもいくつのクラスターに分割されるのかは不明である．ここではこれらの特徴を利用して外れ値検出を行う．つまり，検出元となる対象単語の用例集の一部に，対象単語の語義のラベルを付与し，その設定のもとで外れ値検出を行う．</subsection>
  <subsection title="教師付き LOF">教師データをLOFで利用するには単純に教師データをテストデータに加えればよい．しかしその場合，教師データからも外れ値が検出される可能性がある．ここでは教師データを(k+1)倍してからテストデータに加えてデータセットを作り，そのデータセットに対してLOFを適用する．ただし(k)はLOFにおける(kdist)で使われる(k)である．LOFの場合，教師データ(x)を(k+1)倍すると(kdist(x)=0)となり，教師データ(x)が外れ値として検出されることはなくなる．教師データを(k+1)倍することで，テストデータに対して，外れ値検出の精度が高まるという保証はないが，いくつかの予備実験により経験的に精度が向上することは確認している．一般に教師データを増やせば検出の精度は高まる．また，教師データを増やせば既存の教師データに対する密度が高まるはずなので，教師データを(k+1)倍することは精度を高める方向に作用する．またLOFは確率的な手法ではないので，明確には教師データの独立同一性分布を仮定していない．この点で同じデータを増やしても精度を落とす方向へ作用しないと考える．また注記として，教師なしのLOFも教師付きLOFも(k)の値が特に精度に影響を与えている．この点は考察の章で述べる．本論文では教師なしのLOFにおいて(k=5)としたが，教師付きのLOFでも(k=5)とする．</subsection>
  <subsection title="教師データを利用した生成モデルの構築">対象単語(w)の用例(x)に対する生成モデル(P(x))を教師データを利用して構成する．(w)の語義を(z_i)((i=1K))としたとき，全確率の公式から以下が成立する．[P(x)=_i=1^KP(z_i)P(x|z_i)](w)の教師データが(N)個あり，その中で語義(z_i)のデータが(n_i)個あれば，(_i=1^Kn_i=N)であり，と推定できる．問題は(P(x|z_i))の推定である．(x)は以下のような素性リストで表現されている．[x=f_1,f_2,,f_m]ここではNaiveBayesで使われる素性間の独立性を仮定して，[P(x|z_i)_j=1^mP(f_j|z_i)]と近似する．教師データの中の語義が(z_i)となっているデータの中で(f_j)が出現した個数を(n(z_i,f_j))と書くことにする．このとき，と推定できる．ただし式()や式()は頻度が0の部分があると不具合が生じる．そこでMAP推定でスムージングを行い，以下の補正式を用いる．P(z_i)=n_i+1N+K[0.5em]P(f_j|z_i)=n(z_i,f_j)+1n_i+2gather以上より(P(x))の値が求まる．外れ値の度合いは(-P(x))で測り，この値の大きなものを外れ値の候補とする．ここである閾値を定めて外れ値を検出することも考えられるが，単語毎に(-P(x))の値は大きく異なるために，固定した閾値を定めることはできない．そこでここでは単語毎に，検出対象のデータ（テストデータ）に対して(-P(x))を計算し，それらの値に対する平均()と分散(^2)を求める．(-P(x))の分布を正規分布と考え，以下の式の値（正規化した値）に対して閾値()を設けることにした．上記の正規化した値が()以上の(x)を外れ値とする．ここでは予備実験を行い(=1.1)とした．</subsection>
  <subsection title="教師付き LOF と生成モデルの積集合">本論文の提案手法は，前述した教師付きLOFによる出力と，教師データを利用して構築した生成モデルの出力の共通部分（積集合）を出力するものである．一般に外れ値検出のタスクは難しく，単一の手法ではなかなか高い検出能力が得られない．その1つの原因は誤検出が多いことである．提案手法の狙いは，異なったタイプの手法の出力の積集合を取ることで，誤検出を減らし，全体の検出能力を向上させることである．LOFと生成モデルは外れ値の捉え方が異なるために，出力の積集合を取る効果が期待できる．</subsection>
  <section title="実験"/>
  <subsection title="実験データ">SemEval-2は語義曖昧性解消に関する評価型の国際会議であり，いくつかのタスクが設定されている．日本語WSDはその中の1つである．通常の日本語の語義曖昧性解消のタスクであるが，最も特徴的な点は識別結果に新語義というカテゴリを含めている点である．つまりテストデータの中には設定された語義のどれでもないという答えがありえる．そのため，このタスクで用意された教師データとテストデータを用いることで，教師付きの枠組みでの新語義の検出手法の評価が可能である．日本語WSDの対象単語は50単語である．この中で「可能」「入る」は教師データ内に新語義の用例があるので，それらを外して残り48単語を実験対象とした．各単語を以下に示す．140mm名詞21単語相手，意味，関係，技術，経済，現場，子供，時間，市場，社会，情報，手，電話，場合，はじめ，場所，一，文化，ほか，前，もの動詞22単語会う，あげる，与える，生きる，入れる，教える，考える，勧める，する，出す，立つ，出る，とる，乗る，始める，開く，見える，認める，見る，持つ，求める，やる形容詞5単語大きい，高い，強い，早い，良いverbatimboxedminipage新語義は「意味」で1用例，「手」で3用例，「前」で7用例，「求める」で1用例，「あげる」で2用例，「はじめる」で2用例の計16用例存在する．これらが検出の正解となる．正解の用例を以下に示す．下線の単語が対象単語である．1.…の開きが，ある意味で，科学技術と社会に…2.…医業収益等は手入力…3.…本部での集約も手入力，…4.…経理コンピュータへの予算入力も手入力で…5.…ランチ＝前十一時半〜後3時．6.…二十四日火，前十時〜後7時…7.…来年3月二十日木までの前十時〜後十時，…8.…ゆうゆうワイド（TBS＝前8・三十）…9.…三十日水までの前十一時半〜後2時半，…10.…，前十一時半〜後2時半，…11.…前十時半と後6時，本館1階正面口で…12.…インフラ不安に要因を求め，その強化対策を…13.…国を挙げて緑化を進めた．14.…国をあげて緑化に取り組んだシンガポールは，…15.16.…「はじめる・はじまる」は「初」でなく，「始める・始まる」と書きます．</subsection>
  <subsection title="素性の設定">本手法を利用するためには，用例を素性ベクトルで表現しなくてはならない．そのために以下の8種類の素性を利用した．基本的WSDで利用する素性である．なお対象単語の直前の単語を(w_-1)，直後の単語を(w_1)としている．4zw0(w)の表記1(w)の品詞2(w_-1)の表記3(w_-1)の品詞4(w_1)の表記5(w_1)の品詞6(w)の前後3つまでの自立語の表記7e6の分類語彙表の番号の4桁と5桁例えば以下はWSDの対象単語が16単語目のである文の形態素解析結果である．&lt;sentence&gt;&lt;morpos=&quot;名詞-固有名詞-組織名&quot;rd=&quot;デンツー&quot;&gt;電通&lt;/mor&gt;&lt;morpos=&quot;補助記号-読点&quot;rd=&quot;，&quot;&gt;，&lt;/mor&gt;&lt;morpos=&quot;名詞-固有名詞-組織名&quot;rd=&quot;ハクホー&quot;&gt;博報&lt;/mor&gt;&lt;morpos=&quot;接尾辞-名詞的-一般&quot;rd=&quot;ドー&quot;&gt;堂&lt;/mor&gt;&lt;morpos=&quot;助詞-格助詞&quot;rd=&quot;オ&quot;&gt;を&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-副詞可能&quot;rd=&quot;ハジメ&quot;&gt;はじめ&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-一般&quot;rd=&quot;ジョーイ&quot;&gt;上位&lt;/mor&gt;&lt;morpos=&quot;名詞-数詞&quot;rd=&quot;ゴ&quot;&gt;五&lt;/mor&gt;&lt;morpos=&quot;接尾辞-名詞的-助数詞&quot;rd=&quot;シャ&quot;&gt;社&lt;/mor&gt;&lt;morpos=&quot;助詞-副助詞&quot;rd=&quot;クライ&quot;&gt;くらい&lt;/mor&gt;&lt;morpos=&quot;助動詞&quot;rd=&quot;ナラ&quot;bfm=&quot;ダ&quot;&gt;なら&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-一般&quot;rd=&quot;エイチピー&quot;&gt;HP&lt;/mor&gt;&lt;morpos=&quot;助詞-格助詞&quot;rd=&quot;オ&quot;&gt;を&lt;/mor&gt;&lt;morpos=&quot;動詞-一般&quot;rd=&quot;ツクル&quot;bfm=&quot;ツクル&quot;&gt;作る&lt;/mor&gt;&lt;morpos=&quot;形状詞-一般&quot;rd=&quot;ジンテキ&quot;&gt;人的&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-一般&quot;rd=&quot;ケーザイ&quot;sense=&quot;X&quot;&gt;経済&lt;/mor&gt;&lt;morpos=&quot;接尾辞-形状詞的&quot;rd=&quot;テキ&quot;&gt;的&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-一般&quot;rd=&quot;ヨユー&quot;&gt;余裕&lt;/mor&gt;&lt;morpos=&quot;助詞-係助詞&quot;rd=&quot;モ&quot;&gt;も&lt;/mor&gt;&lt;morpos=&quot;動詞-非自立可能&quot;rd=&quot;アル&quot;bfm=&quot;アル&quot;&gt;ある&lt;/mor&gt;&lt;morpos=&quot;助動詞&quot;rd=&quot;デショー&quot;bfm=&quot;デス&quot;&gt;でしょう&lt;/mor&gt;&lt;morpos=&quot;助詞-接続助詞&quot;rd=&quot;ガ&quot;&gt;が&lt;/mor&gt;&lt;morpos=&quot;補助記号-読点&quot;rd=&quot;，&quot;&gt;，&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-一般&quot;rd=&quot;チューショー&quot;&gt;中小&lt;/mor&gt;&lt;morpos=&quot;助詞-格助詞&quot;rd=&quot;ノ&quot;&gt;の&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-サ変可能&quot;rd=&quot;ダイリ&quot;&gt;代理&lt;/mor&gt;&lt;morpos=&quot;接尾辞-名詞的-一般&quot;rd=&quot;テン&quot;&gt;店&lt;/mor&gt;&lt;morpos=&quot;助詞-格助詞&quot;rd=&quot;デ&quot;&gt;で&lt;/mor&gt;&lt;morpos=&quot;助詞-係助詞&quot;rd=&quot;ワ&quot;&gt;は&lt;/mor&gt;&lt;morpos=&quot;連体詞&quot;rd=&quot;ソンナ&quot;&gt;そんな&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-一般&quot;rd=&quot;ヨユー&quot;&gt;余裕&lt;/mor&gt;&lt;morpos=&quot;助詞-係助詞&quot;rd=&quot;ワ&quot;&gt;は&lt;/mor&gt;&lt;morpos=&quot;動詞-非自立可能&quot;rd=&quot;アリ&quot;bfm=&quot;アル&quot;&gt;あり&lt;/mor&gt;&lt;morpos=&quot;助動詞&quot;rd=&quot;マセ&quot;bfm=&quot;マス&quot;&gt;ませ&lt;/mor&gt;&lt;morpos=&quot;助動詞&quot;rd=&quot;ン&quot;bfm=&quot;ヌ&quot;&gt;ん&lt;/mor&gt;&lt;morpos=&quot;補助記号-句点&quot;rd=&quot;．&quot;&gt;．&lt;/mor&gt;&lt;/sentence&gt;verbatim上記の用例から以下の素性リストが作成される．全体の素性リストが得られれば，全リストの各要素（素性）=（素性値）を各次元に設定することで，素性リストを素性ベクトル（実数値ベクトル）に変換できる．またここでは作成した素性ベクトルの大きさを1に正規化した．e0=経済，e1=名詞-普通名詞-一般，e2=人的，e3=形状詞，e4=的，e5=接尾辞，e6=人的，e6=作る，e6=HP，e6=余裕，e6=ある，e6=中小，e7=2386，e7=1197，e7=11972verbatim素性e7について注記しておく．上記例の場合，素性e6の値としては，「人的」「作る」「HP」「余裕」「ある」「中小」の6つ存在する．各々の分類語彙表の番号を調べると，以下のようになっている．作る==&gt;2.386余裕==&gt;1.1972ある==&gt;2.1203.100verbatim「人的」「HP」「中小」については分類語彙表に記載はない．「作る」の|2.386|から上位4桁を取り|e7=2386|が作成される．また「余裕」の|1.1972|から上位4桁と5桁を取り|e7=1197|と|e7=11972|が作成される．最後に「ある」に関してだが，この単語からは素性e7は作成しない．本論文では全てひらがな文字からなる単語は多義語になっている場合が多い．そのため分類語彙表の番号を素性リストに含めてもノイズの方が多いと考え，そのような処理をしている．</subsection>
  <subsection title="実験結果"/>
  <subsubsection title="F値による評価">まずF値による評価実験の結果を表に示す．LOFではLOF値の大きなもの上位3つを取り出すことにする．3つというのは，上位1つ，上位2つ，…，上位5つと各実験を行い，最も検出能力が高かった（F値が高かった）ものである．OCSはOneClassSVMの意味である．OCSLOFはLOFの出力とOCSの出力の積集合をとったものである．この3つが教師なしの外れ値検出に相当する．LOF-eは教師データを除いてLOF値の高い上位3つをとったたもの，OCS-eはOCSの出力から教師データを除いたもの，OCSLOF-eはLOF-eとOCS-eの出力の積集合を取ったものである．またNNはで用いられた最近傍法であり式()が1.12以上のものを取り出している．1.12という閾値は出力結果からF値が最も高くなるように設定した値である．S-LOFは本論文で提案した教師付きLOFを指す．S-LOFでは，LOFと同様，LOF値の高い上位3つを取り出すことにする．またG-modelは本論文で説明した生成モデルによるものである．この6つとS-LOFとG-modelの出力の積集合を出力とする本手法の7つが教師付きの外れ値検出に相当する．教師ラベルを全く使わない場合，教師データからも外れ値が検出されるので，F値は低くなる．また単純に通常の検出を行った後に教師データを除く方法（表の*-eの手法）よりも，積極的に教師データを利用したS-LOFの方がF値が高い．またS-LOFとG-modelは検出の手法が異なるために，検出結果の重なりが少なく，結果的に両者の積集合を取る本手法のF値が最も高かった．</subsubsection>
  <subsubsection title="平均適合率による評価">前節では手法の評価をF値で行った．本節では全データに対して外れ値の度合いの順位を出力し，平均適合率を求めることで手法の評価を行う．NNとG-modelでは出力の値（外れ値の度合い）をソートすることで，全データに対する外れ値の度合いの順位が得られる．LOFやS-LOFの場合は，単語毎に出力の値のスケールが異なるために，まずG-modelで行ったような正規化を行い，単語毎の出力値のスケールを揃える．次に単語毎の出力値の上位3位までの出力値に100を加えた後に，全体をソートすることで，全データに対する外れ値の度合いの順位を得る．「上位3位までの出力値に100を加える」意味は，単語毎の出力値の上位3位までを優先して出力することに対応する．これは本来LOFやS-LOFは単語毎に上位数件を外れ値として出力する手法であり，取り出さないデータの順位に意味があるかどうかは不明であるために導入した処理である．実際，この処理を行った方が，行わなかった場合よりも平均適合率は高かった．OCSの場合は，外れ値と判定したデータ群の重心を求め，その重心との距離によって，全データに対する外れ値の度合いの順位を得た．本手法(G-modelS-LOF)の場合，基本的にG-modelの出力の値を外れ値の度合いとするが，本来のS-LOFにおける出力のデータ（単語毎のLOF値の上位3件）に対しては，G-modelでの出力の値に100を加えた後に，全体をソートした．OCSLOFなどのLOF類と積集合を取る手法も本手法と同様に，LOFと組み合わせる方の手法のみで，まず外れ値の度合いを得て，次に本来のLOFにおける出力のデータ（単語毎のLOF値の上位3件）に対して100を加えた後に全体をソートした．実験の結果を表に示す．表の1行目は手法名である．紙面の都合上OCSLOF,OCSLOF-e,G-modelは，それぞれOL,OL-e,G-mdlと略記している．表の1列目は新語義の現れた個数，表内の数値はその個数の時点での適合率である．例えば，本手法の場合，1番目に新語義の現れた順位は7であり，その時点での適合率は1/7=0.14286であり，2番目に新語義の現れた順位は13であり，その時点での適合率は2/13=0.15385である．これを全ての新語義の個数16個まで調べ，各適合率の平均が平均適合率(AveragePresision=AP)である．そして各手法に対する平均適合率をグラフ化したものが図である．表及び図より，本手法が最も平均適合率が高いことが確認できる．また教師なしの手法にあたるLOF,OCS,OCSLOFの3つは0.005前後の値となり，教師ラベルを使わずに単純に出力結果から教師データを除く手法LOF-e,OCS-e,OCSLOF-eの3つは0.010弱の値になり，教師付き外れ値検出手法にあたるNN,S-LOF,G-modelの3つは0.010強の値になる．これらのことから教師データを外れ値検出に積極的に利用する効果も確認できる．</subsubsection>
  <section title="考察"/>
  <subsection title="WSD による新語義検出">WSDの教師データが利用できるのであれば，WSDの分類器を学習し，その識別の信頼度を利用して新語義が検出できると考えるのは自然である．ただし単純にそのアプローチだけでは新語義の検出は困難である．前述した素性を使いSVMを学習し，SemEval-2日本語WSDタスクのテストデータ50単語全てを対象に語義の曖昧性解消を行ったところ，平均正解率は0.7664であった．上記タスクの参加システム中最高の正解率はRALI-2の0.7636であり，ここで学習できたSVMは十分能力が高いことがわかる．上記SVMの学習にはLIBSVMを用いたが，そこでは|-b|のオプションで識別の信頼度（その語義に属する確率値）を求めることができる．このオプションを用いて，閾値()以下の信頼度のときに，その用例を新語義の用例とすることで新語義の検出を試みた．閾値()の設定であるが，まず単純に0.51から0.99までの値を0.01刻みで設定し，その値を用いた場合の検出結果に対するF値を求めた．そのグラフを図に示す．(=0.73)のときに検出数388正解数4となりF値が最大の0.0198を取る．また語義数が(K)の場合，SVMが出力する識別の信頼度は明らかに(1/K)以上の値になるので，語義数の影響を受けている可能性がある．そこで閾値を(=(1+)/K)と設定し，()を0.01刻みで0.99まで試したときのグラフを図に示す．(=0.17)のときに検出数39正解数2となりF値が最大の0.0727を取る．F値0.0727は表で示された外れ値検出手法と比較すると，それほど悪いとも言えないが，WSDシステム単独では新語義の検出が困難であることがわかる．また平均適合率の評価も行っておく．システムが識別した語義の信頼度によって，全体のデータを（昇順に）ソートすることで，平均適合率を調べたところ0.00638となった．この値は表に示した外れ値検出手法による平均適合率と比べると高い値とは言えない．平均適合率の観点からも，WSDシステム単独では新語義の検出が困難であることがわかる．上記では語義の識別の信頼度により新語義を検出するアプローチであったが，ここではSVMを利用しているので，one-vs-rest法を利用して，語義毎にSVMを学習し，すべての語義について否と判定されたものを新語義とするアプローチも考えられる．このアプローチによる評価も行っておく．語義毎にSVMを学習する際にもLIBSVMの|-b|のオプションを用いる．語義毎の各SVMが否と識別した信頼度を集め，その最小値()をそのデータの新語義の度合いとする．()が閾値()よりも大きい場合に，新語義と判定する．(=0.5)は語義毎のSVM全てが否と判定したものを新語義と判定することを意味する．出力結果の分析から(=0.6996)のときに検出数33正解数1となりF値が最大の0.0408を取る．またone-vs-rest法を利用した場合の平均適合率も調べた．()の値を新語義の度合いとし，全データに対して新語義の度合いの順位を出力することで平均適合率が求まる．結果，平均適合率は0.0132であった．F値にしても平均適合率にしても，表や図と比較すると，通常の教師付きの外れ値検出手法と同程度である．one-vs-rest法を利用した場合でも，WSDシステム単独では新語義の検出が困難であることがわかる．</subsection>
  <subsection title="未出現語義を含めた評価">SemEval-2日本語WSDタスクでは，教師データ中には現れないが，テストデータには出現する語義が存在する．このような教師データ中の未出現語義は，新語義と見なすこともできる．このような用例は「あう」で1用例，「すすめる」で1用例，「出す」で3用例，「立つ」で1用例，「とる」で3用例，「ひとつ」で1用例，「見る」で6用例，「持つ」で1用例，「大きい」で2用例，「与える」で1用例の合計20用例存在する．これらも新語義の用例と見なした場合の検出結果を表に示す．F値の括弧内の数値は正解を新語義のみにした場合の正解数とF値（表の値）である．また平均適合率の評価も行っておく．各手法の平均適合率の求め方は前述した方法で行う．結果を表に示す．表の「新語義のみ」の列は正解を新語義のみにした場合であり，「未出現語義を含む」の列は正解を新語義と未出現語義を合わせたものにした場合である．F値の評価でも平均適合率の評価でも本手法が最も高い値を出しており，本手法の効果は確認できる．ただし全体的な傾向として，未出現語義を正解に含めた場合の方が，F値も平均適合率も若干高くなるが，本手法に関しては値が下がっている．S-LOFやG-modelは未出現語義を正解に含めると，検出できる正解数は増えるが，共通して検出できる部分がなかったために，このような結果になった．この対策としては，後述するアンサンブル手法の導入により改良していきたい．また，前節のWSDシステムを用いた場合の評価を表に示す．F値と平均適合率の括弧内の数値は正解を「新語義のみ」にしたものである．未出現語義を正解に含めた場合でも，前節同様，WSDシステム単独では新語義の検出が困難であるといえる．</subsection>
  <subsection title="誤検出・未検出の原因">本手法の誤検出の原因について述べる．1つは固有表現や熟語内の単語である．例えば以下のような表現が検出されている．未来科学技術共同研究センターの中の研究施設昔話の「千代ごこ出やっせ」のように中小零細企業の取材は数多く手がかかる割りに固有表現や熟語内の単語に通常の意味があるとは考えづらく，新語義の検出という観点では，このような表現を抽出しても完全に誤りとは言えない．本来，新語義の検出するためには，固有表現や熟語を予め抽出しておくことが必要だと考える．また誤検出のその他の原因は多様であるが，全体として，対象単語の直前や直後に自立語が現れる複合語の用法や動詞の連体形の用法などが目立った．わが国が最も重要な貿易相手国の一つ人間性を疑ってしまう人とは男女関係なく，夏休み等に行って来た時の経験＝古き良き時代を，複合語が専門性の高い用語である場合は意味のある検出とも見なせるが，ここでは複合語を単なる名詞連続で認識しているために，専門用語との区別は付けられない．新語義の検出に関しては，熟語や固有表現と同様，専門用語も通常の表現とは，区別した方がよいと考える．本手法の未検出の原因としては，突き詰めれば，用例間の距離の測定方法に帰着される．ある新語義の用例と他の正常値の用例との距離がある程度，離れていたとしても，正常値の用例間の距離も同程度は離れているという状況である．これは動詞や形容詞における検出では顕著である．この問題に注目して距離学習を新語義発見に応用した研究も存在する．ただしこの問題は本質的に語義曖昧性解消の場合と同じであり，語義曖昧性解消の精度向上の試みが本研究に応用できる．</subsection>
  <subsection title="外れ値検出手法のアンサンブル">外れ値検出手法は数多く提案されており，本論文で利用したLOFについてもいくつかの改良手法が提案されている．これらの手法をどのようにして教師付きの枠組みへ拡張するかは不明であるが，これらを利用することで本手法の改善も可能である．また，新たに外れ値検出手法を考案するのではなく，既存の手法を組み合わせる戦略も有効である．Lazavicは複数の外れ値検出の手法を適用して，それら出力結果を総合的に判断して最終的に外れ値候補を出力するという外れ値検出手法のアンサンブル(ensemble)を提案した．ここで提案したLOFと生成モデルの組み合わせも，外れ値検出手法のアンサンブルの一種と考えられる．ここでは単純に出力の積により最終の出力を決めたが，重みを付けて判断するなどの工夫も考えられる．あるいは他の外れ値検出の手法の組み合わせることも有効であろう．表からもわかるとおり，LOFの出力と生成モデルの出力はかなり異なる．単純に出力の和を取ると，検出数が多くなりすぎてF値の評価は下がってしまうが，第1段目の候補としては取り出せているので，そこからの選別に工夫することで改善が可能である．ここらが今後の課題である．また，本論文ではS-LOFとG-modelのアンサンブルを提案したが，実験の結果をみるとNNとG-modelのアンサンブルやS-LOFとNNのアンサンブルも有望に見える．それらの実験結果を表7に示す．表7が示すとおり，提案手法のS-LOFとG-modelのアンサンブルが最も優れている．また組み合わせる手法によっては，個々の手法よりも精度が劣化することもありえるので，アンサンブルに用いる手法の選択も重要であることがわかる．</subsection>
  <section title="おわりに">本論文では対象単語の用例集合から，その単語の語義が新語義となっている用例を検出する手法を提案した．基本的に新語義の用例を用例集合中の外れ値と考え，外れ値検出の手法を利用する．ただし従来の外れ値検出では教師なしの枠組みであるが，ここではタスクの性質を考慮し，教師付きの枠組みで行った．まずLOFを教師データを利用する形に改良した教師付きLOFを提案し，次に教師データを利用することで生成モデルを構築した．提案手法は上記2つの手法それぞれの出力の共通部分（積集合）を取るものである．これは2つの異なったタイプの外れ値検出の手法の積集合を取ることで誤検出を減らし，結果的に検出能力を高めることを狙いとしている．タスクの一部として新語義識別を含むSemEval-2の日本語WSDタスクのデータを利用して，LOF,OneClassSVM,最近傍法，教師付きLOF，生成モデルおよび提案手法による新語義の検出実験を行った．それぞれの手法のF値と平均適合率を求めることで，提案手法の有効性を示した．また教師なしの手法(LOF,OCS,OCSLOF)，単純に教師データを検出結果から除く手法(LOF-e,OCS-e,OCSLOF-e)及び教師付きの手法(NN,S-LOF,G-model)のF値と平均適合率を比較することで，新語義検出を目的とした外れ値検出では，教師データを積極的に利用することが精度向上に効果があることが確認できた．またWSDシステムの識別の信頼度を利用した新語義を検出実験も行った．十分なパフォーマンスを示すWSDシステムを用いても，WSDシステム単独では新語義の検出が困難であることも示した．提案手法は外れ値検出手法のアンサンブルの手法と位置づけられる．提案手法における出力結果のアンサンブルは，積集合をとるという単純なものであるため，この部分に工夫を入れることで更に検出能力が高まると予想している．出力結果の統合方法を工夫することが今後の課題である．document</section>
</root>
