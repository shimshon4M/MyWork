<?xml version="1.0" ?>
<root>
  <section title="Introduction">Thegrowthoftheinternetandthedecreaseofthestoragecostsareresultingintherapidincreaseofmultimediacontentstoday.Forretrievingthesecontents,availabletext-basedtaginformationislimited.SpokenDocumentRetrieval(SDR)andSpokenTermDetection(STD)arepromisingtechnologiesforretrievingthesecontentsusingthespeechdataincludedinthem.MostofgeneralwaystoperformSDRandSTDuseautomaticspeechrecognition(ASR).First,targetspeechesaretranslatedtotextsymbolsequencesthatareequaltowordorsub-wordsequencesinmanycases.Then,textinformationretrieval(IR)techniquesareadaptedtosearchspeechesorutteredtermsrelatedtoagivenqueryfromaspokendocumentscollection.AnyASRsystemcannotachieveperfectspeechrecognitionaccuracy.Therefore,textsymbolsequencesproducedbyASRhavealotofrecognitionerrors(noises).ItisthemostimportantprobleminSDRandSTDstudies.Therefore,manySDRandSTDresearchershavechallengedtoimproveIRperformanceforverynoisytextdocuments.SDRandSTDstudieshavebeenevolvingsincetestcollectionwasconstructed.Forexample,theTextRetrievalConference(TREC)hasdealtwithSDRsince1996.ThetaskofSDRistoidentifyatargetspokendocumentfromamongalargenumberofspokendocuments,wherethetargetisoftendefinedascontainingaparticulartopic,forexample,thecontentofanewsclip.However,SDRhaslimitations:evenifthetargetspokendocumentisidentified,theusermustbrowsetheentirespokendocumenttoconfirmitscontent,eveniftheuserwouldratherbrowseonlythesectioncontainingthekeywordofinterest.Therefore,STDfunctionalityisneeded.So,theNationalInstituteofStandardsandTechnology(NIST)hassetupSTDtestcollectionsandcollectedtheresultsofconferenceattendees.ResearchanddevelopmentofSDRandSTDhasbeenactivelycarriedout,owingtotheconstructionofthesetestcollections.InSDRandSTDresearch,astandardtestcollectionisindispensablebecausetheperformanceofSDRandSTDdependsonthequeryset,thesizeandcategoryofthespokendocuments,andthecorrectdocumentsorsections,andtheoccurrencesinspokendocumentsthatareincludedinsuchatestcollection.TestcollectionsforJapanesearehighlydesiredbythespokendocumentsprocessingcommunityinJapan.Therefore,theSpokenDocumentProcessingWorkingGroup,whichispartofthespecialinterestgroupofspokenlanguageprocessing(SIG-SLP)oftheInformationProcessingSocietyofJapan,developedprototypesofSDRtestcollections;theCSJSpokenTermDetectiontestcollectionandtheCSJSpokenDocumentRetrievaltestcollection.ThetargetdocumentsofboththetestcollectionsarespokenlecturesintheCorpusofSpontaneousJapanese(CSJ).Byusing(andextending)thesetestcollections,weperformedtwosub-taskswereconductedintheNTCIR-9.TheNTCIRWorkshopisaseriesofevaluationworkshopsdesignedtoenhanceresearchininformationaccesstechnologiesbyprovidinglarge-scaletestcollectionsandaforumforresearchers.Weproposedanewtaskcalled``IRforSpokenDocuments,''shortenedto``SpokenDoc,''anditwasacceptedasoneofthecoretasksintheninthNTCIRWorkshop(NTCIR-9).IntheNTCIR-9SpokenDoc,weevaluateSTDandSDR,especiallybasedonarealisticASRcondition,wherethetargetdocumentsarespontaneousspeechdatawithhighworderrorratesandhighOOVrates.Inthispaper,weespeciallyfocusontheSTDsub-taskattheNTCIR-9.ThispaperdescribesthetaskdesignandevaluationframeworkforSTDsutdiesattheNTCIR-9SpokenDoctask.InourSTDsub-task,wedistributedthereferencetranscriptionsproducedbyASRsystemstotaskparticipants.ThisaimsatancompetitionatwhichASRperformancedoesnotinfluencetheSTDevaluationofeachparticipant'sresult.ASRforaspontaneousspeechisdifficult.Therefore,itishardtoachievehighperformanceSTDintermsofthecurrentSTDstudies.ThedesignoftheSTDsub-taskatNTCIR-9isthechallengeforbreakthroughontheSTDresearches.Theorganizationofthispaperisasfollows.Section2describesanoutlineofSTDtaskandSection3introducesotherevaluationframeworksrelatedtoourSTDsub-task.InSection4,weexplainthetaskdefinitionoftheNTCIR-9SpokenDocSTDsub-task.Section5showstheevaluationresultsofthesub-taskparticipants,andfinally,wegiveourconclusioninSection6.</section>
  <section title="Outline of STD">ThegoalofanSTDtaskistorapidlydetectthepresenceofaterm,consistingofonewordorasequenceofwordsconsecutivelyspoken,fromaspokendocumentscollection.TheeffectivenessofanSTDsystemisevaluatedondetectionrate,detectionaccuracyofagivenqueryterm,retrievalspeed,andprocessingresourceswhichacomputerrequires.Therefore,ansystem,whichcanrapidlyidentifylocationsofagivenqueryterminaspokendocumentwithlesscomputerresources,mustbeagoodSTDsystem.However,thereisatrade-offbetweendetectionrateandaccuracy.TheSTDresearchisthechallengetobreakthroughthistread-offproblem.FigureshowsagenericprocessingflowdiagramofanSTDtask.First,targetspeechesaretranslatedtotextsymbol(wordorsub-word)sequencesbyusinganASRsystem.Next,indexiscreatedfromthesymbolsequences.Therearesomemethodsonhowtomakesymbolsequencesandanindexforrobustlysearchingqueryterms.Whenaquerytermisinputtoasearchengine,itdetectslocationsinwhichthequerytermexistsfromtheindexedspeeches.ItishardtodetecttermscorrespondingtoaquerytermbecauseanyASRsystemoftengeneratesspeechrecognitionerrors.Inaddition,words,whicharenotlistedonanASRdictionaryusedbyanASRsystem,arenevercorrectlytranslatedtotext.Thesewordsarecalledout-of-vocabulary(OOV).TheSTDstudyisalsothechallengetoovercomethespeechrecognitionerrorandOOVproblems.ItisnecessarytoconsiderthreekeypointstoputSTDapplicationsintopracticaluse:thefirstisdetectionperformances(detectionrateandaccuracy),thesecondissearchtimeandthethirdiscomputerresources.Forexample,evenifanSTDsystemhasgooddetectionperformances,itmaynotbeusefulifthesystemprocesslowerspeed.Therefore,theparticipants'STDsystemswereevaluatedintermsofthethreekeypoints.</section>
  <section title="Related evaluation frameworks">ThissectiondescribesotherevaluationframeworksrelatedtoourSTDevaluationframeworkandespeciallyclarifiesthedifferencesbetweenourproposing,theTRECandtheNISTframeworks.TheTREC-6SDRtrackheldin1997isthefirstsearchtasktargetedforspeechdata.Theknown-itemretrievaltaskattheTREC-6wassimilartoourSTDtask,inwhichspokendocumentsincludingkeywordscomposingaquerywereretrieved.Inthistask,however,theretrievaltechniquestacklingtheOOVandtranscriptionerrorproblemscausedbyASRwerenotcomperedbetweenthetaskparticipants.TheTREC-8SDRtrack,thefinalSDRevaluationframeworkintheTRECseries,hadthead-hocSDRtask.Thead-hocSDRtaskisdifferentfromtheSTDtask.However,thegoalofboththetasksisefficientIRfromthelargescalespeechdata.TheTREC-8usedthebroadcastingnewscorpuswhosedurationwas560hours.ThescaleofthespeechdatawasthesameasourSTDtargetspeech.Ontheotherhand,ourSTDsub-taskusedthelecturespeechcorpus,theCSJ.MostspeechesintheCSJwerehardtotranscribebyASR.ThisisbecausethespeechesintheCSJarespontaneous.Therefore,manyfalters,restatedwords,andfilledpausesareincludedinthespeeches.TheydamageASRperformance.Inadditiontothis,theCSJhasover1,400speakers.Weusedthespeechdatawhichismorevariedonspeakerindividualityandspeakingstyle.IncontrasttotheTREC-8SDRtrack,theNISTevaluationframeworkhasthesamegoalasourSTDevaluationframework.However,thereweresomeproblemsdescribedinfollowings:ThequerysetintheNISTtaskwascomposedofhighly-frequentwordN-gramsautomaticallyextractedfromthespeechcorpus.Itiseasytodetecthighly-frequentwordsfromthespeechdatabecauseofeasyspeechrecognitionofthem.TheNISTtaskwaseasy.TheNISTtaskdidnotdisinguishbetweenin-vocabulary(IV)termsandOOVtermsinthequerysetbecausethetaskorganizersdidnotprovideanyresourcesnecessaryforthedistinction.ThetaskparticipantswererequiredtoperformASRofthetargetspeechbythemselvesandhadtomaketheirowndistinctionbetweenIVandOOVterms.ItisidealtoclarifythedefinitionofIVandOOVtermsintheevaluationsetsforpreciselyexaminingtheapplicabilityofSTDmethodsintopracticalretrieval.Therefore,itwashardtocomparetheSTDperformancesbetweentheSTDmethodsintheNISTtaskbecausethedifferencesbetweentheASRsystemschangedtheleveloftaskdifficulty.TheNISTpreparedthreesortsoftargetspeechesintheEnglishtask.Thedurationsofallofthemwerejustafewhours.Therefore,theNISTtaskwastooeasy.IntheNISTtask,adetectionerrortrade-offcurvethatplotstermfalsealarmprobabilityversustermmissprobability,andtheopticalandactualpointsonthecurvewereusedforevaluatingtheSTDperformance.Theoptical/actualpointswerecalledMTWV(maximumtermweightedvalue)andATWV(actualtermweightedvalue),respectively.Theseevaluatingmeasurescalculatedbasedonheuristicparametersdependingonatargetspeech.ThisisspecializedtotheNISTtask.WehavesetuptheSpokenDocSTDsub-taskintheNTCIR-9basedontheproblemsoftheNISTtask.ComparingtheNISTtaskwithourSTDsub-task,ourshasfollowingadvantages:ThequerysetinourSTDsub-taskwasformedbyhuman-selectingkeywords(mostlypropernouns),whicharelikelytobeusedforIR.Furthermore,thefrequenciesofthequerytermsarewidelydistributedandthenumberofsyllablescomposingaquerytermisalsoconsidered.Therefore,ourtaskprovidedtheSTDevaluationatavarietyoflevelsofdetectiondifficulty.WeprovidedthetwosortsofreferencetranscriptionsproducedbythetwoASRsystemstothetaskparticipants.Theparticipantscouldusethem.Inadditiontothis,theASRdictionary,acousticandlanguagemodelswerealsodistributed.WeannouncedtheguidelinesofASRforparticipantswhowantstouseownanASRsystem,becausetheyperformtheirSTDunderthesameASRconditions(suchastrainingdataandvocabularyforASR)ofthereferencetranscriptions.Therefore,participantschallengedthesub-taskatthesamelevelofdetectiondifficultyfortheallparticipantsbecausethedefinitionofIVandOOVtermswerecommonalized.OurtargetspeechwasmuchlargerthantheNIST'sone.Thedurationswereabout602and44hoursforthetwoquerysets,respectively.Arecall-precisioncurveandF-measure,harmonicmeanofrecallandprecisionrates,wereusedfortheSTDevaluationinoursub-task.TheseevaluationvaluesallowedustocomparetheSTDperformancesbetweentheallparticipants'STDsystemsatamacroscopicperspective.Furthermore,wealsoevaluatedtheSTDperformancefrommicroscopicperspectivebasedonMAP(meanaverageprecision)metric.Falsedetection,oneofSTDerrors,wereadequatelyevaluated.</section>
  <section title="STD task design at the NTCIR-9"/>
  <subsection title="Target speech collection">OurtargetdocumentcollectionistheCSJreleasedbytheNationalInstituteforJapaneseLanguage.AmongtheCSJ,2,702lectures(about602hours)areusedasthetargetdocumentsforourSTDsub-task(referredtoasALL).Thesubset177lectures(about44hours)ofthem,calledCORE,isalsousedforthetargetforourSTDsub-task(referredtoasCORE).Theparticipantswererequiredtopurchasethedatabythemselves.EachlectureintheCSJissegmentedbythepausesthatarenoshorterthan200msec.EachsegmentiscalledInter-PausalUnit(IPU).AnIPUisshortenoughtobeusedasthealternatetothepositioninthelecture.Therefore,theIPUsareusedasthebasicunittobesearchedinourSTDsub-task.</subsection>
  <subsection title="Transcription of speech">AstandardSTDmethodfirsttranscribestheaudiosignalintoitstextualrepresentationbyusingASR,followedbytext-basedretrieval.Theparticipantscouldusethefollowingtwotypesoftranscriptions.ReferenceautomatictranscriptionsTheorganizerspreparedtworeferenceautomatictranscriptions.TheyenabledthosewhowereinterestedinSTDbutnotinASRtoparticipateinoursub-task.TheyalsoenabledcomparisonsoftheSTDmethodsbasedonthesameunderlyingASRperformance.Theparticipantscanalsousebothtranscriptionsatthesametimetoboosttheperformance.ThetextualrepresentationofthetranscriptionswillbetheN-bestlistofthewordorsyllablesequencedependingonthetwobackgroundASRsystems,alongwiththeirlatticeandconfusionnetworkrepresentations.Word-basedtranscription(denotedas``REF-WORD'')obtainedbyusingaword-basedASRsystem.Inotherwords,awordn-grammodelwasusedasthelanguagemodeloftheASRsystem.Withthetextualrepresentation,italsoprovidesthevocabularylistusedintheASR,whichdeterminesthedistinctionbetweentheIVquerytermsandtheOOVquerytermsusedinourSTDsub-task.Syllable-basedtranscription(denotedas``REF-SYLLABLE'')obtainedbyusingasyllable-basedASRsystem.Thesyllablen-grammodelwasusedforthelanguagemodel,wherethevocabularyisallJapanesesyllables.UsingthismodelcanavoidtheOOVproblemofthespokendocumentretrieval.Participantswhowanttofocusontheopen-vocabularySTDcanusethistranscription.Tableshowstheword-basedcorrectrate(``W.Corr.'')andaccuracy(``W.Acc.'')andthesyllable-basedcorrectrate(``S.Corr.'')andaccuracy(``S.Acc.'')forthesereferencetranscriptions.Participant'sowntranscriptionparticipantscouldusetheirownASRsystemsforthetranscription.ToenjoythesameIVandOOVconditions,werecommendedthattheirword-basedASRsystemsshouldusethesamevocabularylistasourreferencetranscription,butthiswasnotnecessary.Whenparticipatingwiththeirowntranscriptions,theparticipantswereencouragedtoprovidethemtotheorganizersforfutureSpokenDoctestcollections.</subsection>
  <subsection title="Speech recognition models">Torealizeopenspeechrecognition,weusedthefollowingacousticandlanguagemodels,whichweretrainedundertheconditiondescribedbelow.AllspeechesexcepttheCOREpartsweredividedintotwogroupsaccordingtothespeechIDnumber:anoddgroupandanevengroup.Weconstructedtwosetsofacousticmodelsandlanguagemodels,andperformedautomaticspeechrecognitionusingtheacousticandlanguagemodelstrainedbytheothergroup.Theacousticmodelsaretriphonebased,with48phonemes.Thefeaturevectorshave38dimensions:12-dimensionalMel-frequencycepstrumcoefficients(MFCCs);thecepstrumdifferencecoefficients(deltaMFCCs);theiracceleration(deltadeltaMFCCs);deltapower;anddeltadeltapower.Thecomponentswerecalculatedevery10ms.Thedistributionoftheacousticfeatureswasmodeledusing32mixturesofdiagonalcovarianceGaussianfortheHMMs.Thelanguagemodelsareword-basedtrigrammodelswithavocabularyof27~kwords.Ontheotherhand,syllable-basedtrigrammodels,whichweretrainedbythesyllablesequencesofeachtraininggroup,wereusedtomakethesyllable-basedtranscription.WeusedJuliusasadecoder,withtheASRdictionarycontainingtheabovevocabulary.Allwordsregisteredinthedictionaryappearedinbothtrainingsets.Theodd-grouplectureswererecognizedbyJuliususingtheeven-groupacousticmodelandlanguagemodel,whiletheeven-grouplectureswererecognizedusingtheodd-groupmodels.Finally,weobtainedN-bestspeechrecognitionresultsforallspokendocuments.ThefollowingsmodelsanddictionaryweremadeavailabletotheparticipantsoftheSpokenDoctask.OddacousticmodelsandlanguagemodelsEvenacousticmodelsandlanguagemodelsAdictionaryoftheASR</subsection>
  <subsection title="The task definition">OurSTDtaskistofindallIPUsthatincludeaspecifiedquerytermintheCSJ.Aterminthistaskisasequenceofoneormorewords.ThisisdifferentfromtheSTDtaskproducedbyNIST.ParticipantscanspecifyasuitablethresholdforascoreforanIPU;ifthescoreforaquerytermisgreaterthanorequaltothethreshold,theIPUisoutput.Oneoftheevaluationmetricsisbasedontheseoutputs.However,participantscanoutputupto1,000IPUsforeachquery.Therefore,IPUswithscoreslessthanthethresholdmaybesubmitted.</subsection>
  <subsection title="STD query set">Weprovidedtwosetsofquerytermlists,oneforALLlecturesandoneforCORElectures.Eachparticipant'ssubmission(calleda``run'')shouldchoosethelistcorrespondingtotheirtargetdocumentcollection,i.e.,eitherALLorCORE.Wepreparedthe50queriessetsfortheCOREandALLlecturessets.FortheCORE,31oftheall50queriesareOOVqueriesthatarenotincludedintheASRdictionaryandtheothersareIVqueries.Ontheotherhand,fortheALL,24oftheall50queriesareOOVqueries.Theaverageoccurrencesperatermis7.1timesand20.5timesfortheCOREandALLsets,respectively.Eachquerytermconsistsofoneormorewords.BecausetheSTDperformancedependsonthelengthofthequeryterms,weselectedqueriesofdifferinglength.Querylengthsrangefrom4to14morae.</subsection>
  <subsection title="System output requirement">WhenatermissuplliedtoanSTDsystem,alloftheoccurrencesoftheterminthespeechdataaretobefoundandscoreforeachoccurrenceofthegiventermaretobeoutput.AllSTDsystemsmustoutputfollowinginformation:document(lecture)IDoftheterm,IPUID,ascoreindicatinghowlikelythetermexistswithmorepositivevaluesindicatingmorelikelyoccurrence,abinarydecisionastowhetherthedetectioniscorrectornot.Thescoreforeachtermoccurrencecanbeofanyscale.However,arangeofthescoresmustbestandardizedforalltheterms.</subsection>
  <subsection title="Evaluation measures">Asdescribedbofore,ansystem,whichcanrapidlyidentifyIPUsincludingagivenquerytermwithlesscomputerresources,isgood.Therefore,weofficiallyuserecall-precisioncurves,F-measuresandmeanaverageprecision(MAP)forevaluatingdetectionperformance.Inaddition,wealsoevaluateSTDsystemsbyretrievaltimeandmemoryconsumptionofacomputer.Calculationofrecall,precision,F-measureandMAPisdescribedasfollows.IPUsdetectedbyeachsystemwerejudgedbywhetherornottheIPUsincludedthespecifiedterm.Thejudgmentwasbasedona``correctIPUslist''foreachspecifiedterm.ThedefinitionofcorrectIPUsforaspecifiedtermisbasedonperfectmatchingtothemanualtranscriptionsoftheCSJinJapaneserepresentation(Kanji,HiragataandKatakana).TheevaluationmeasureforeffectivenessistheF-measureatthedecisionpointspecifiedbytheparticipant,basedonrecallandprecisionaveragedoverqueries(describedas``F-measure(spec.)'').TheF-measureatthemaximumdecisionpoint(describedas``F-measure(max)''),recall-precisioncurvesandmeanaverageprecision(MAP)arealsousedforanalysispurposes.Theyaredefinedasfollows:Recall=N_corrN_true[1ex]Precision=N_corrN_corr+N_spurious[1ex]F-measure=2RecallPrecisionRecall+PrecisiongatherwhereN_corrandN_spuriousarethetotalnumberofcorrectandspurious(false)term(IPU)detectionswhosescoresaregreaterthanorequaltothethreshold,andN_trueisthetotalnumberoftruetermoccurrencesinthespeechdata.Recall-precisioncurvescanbeplottedbychangingthethresholdvalue.Intheevaluation,thethresholdvalueisvariedin100steps.F-measureatthemaximumdecisionpointiscalculatedattheoptimalbalanceofRecallandPrecisionvaluesfromtherecall-precisioncurve.MAPforthesetofqueriesisthemeanvalueoftheaverageprecisionvaluesforeachquery.Itcanbecalculateasfollows:whereQisthenumberofqueriesandAveP(i)meanstheaverageprecisionofthei-thqueryofthequeryset.Theaverageprecisioniscalculatedbyaveragingoftheprecisionvaluescomputedatthepointofeachoftherelevanttermsinthelistinwhichretrievedtermsarerankedbyarelevancemeasure.whereristherank,N_iistheranknumberatwhichtheallrelevancetermsofqueryiarefound,andRel_iisthenumberoftherelevancetermsofqueryi._risabinaryfunctionontherelevanceofagivenrankr.</subsection>
  <section title="NTCIR-9 SpokenDoc management"/>
  <subsection title="Schedule">TheNTCIR-9SpokenDoctaskwasworkedoutasfollowingschedule:Callforparticipation:Oct./2010Dec./2010Datadistribution:onMar./2011Dry-runworkandresultsrelease:onMay/2011Formal-runworkandresultsrelease:onJuly/2011Participants'draftpapersubmission:onSept./2011Participants'camera-readypapersubmission:onNov./2011Workshopmeeting:onDec./2011</subsection>
  <subsection title="Task participants of STD task">IntheNTCIR-9SpokenDocSTDsub-task,seventeamsparticipatedinthetaskwith18submissionruns.TheteamIDsarelistedinTable.AlltheseventeamssubmittedtheresultsfortheCOREqueryset.However,onlythetwoteamssubmittedtheresultsoftheALLqueryset.</subsection>
  <subsection title="Participants' techniques">Here,weprovideabriefoverviewofSTDtechniquesusedbytheparticipants.Themoredetailsofeachparticipant'stechniqueweredescribedontheirpapers.Tablesummarizesthenumberoftranscription(s)usedforeachrun.AKBLsubmittedtworunsfortheCOREset.Theirindexingmethod,calledMetricSubspaceIndexing,wasquitedifferentfromthoseusedintextindexing.ThetermdetectionwasperformedontheseindicesandbasedontheHoughTransformalgorithmusuallyusedinimageprocessing.Methodsforincorporatingthemultiplecandidatesfromspeechrecognitionintotheirindexingwerealsoinvestigated.TheyusedtheREF-SYLLABLEtranscription.ALPSsubmittedtworunsfortheCOREset.The10(includingREF-WORD,REF-SYLLABLE,andOWN)transcriptionsobtainedfromvariousrecognitionsystemswereincorporatedintoasausage-stylelattice,calledPTN,andthesearchwasperformedonitbyusingtheDTW(DynamicTimeWarping)algorithm.Toreducefalsedetections,twoadditionalscores,whichroughlycorrespondedtothedegreeofconsensusandambiguityinthecompetingsyllablesinthelattice,werealsoincorporatedintothedistancescoreusedintheDTWprocess.IWAPUsubmittedtworunsfortheCOREset.TheyusedmultipleOWNtranscriptionsofvarioussubwordunits,includingmonophone,triphone,syllable,demiphone,andSub-PhoneticSegment(SPS),byusingthemultiplespeechrecognitionsystemspreparedfortheseunits.Thequerywasalsoconvertedtothesesubwordsequences,andthenthedetectionwasperformedforeachsubwordrepresentationusingtheDTWalgorithm.ThesemultipledetectionresultswereintegratedintothefinalresultsbyinterpolatingtheirdetectionscoreslinearlytoimprovetheSTDperformance.NKGWsubmittedonerunfortheCOREset.TwoOWNtranscriptionswereusedatthesametime:theword-basedtranscriptionwasusedfortheIVsearchqueryandthesyllable-basedtranscriptionwasusedfortheIVandOOVquery.Forthesyllable-basedtranscription,aninvertedindexbasedonthesyllabletrigramwasusedforindexing,andthesubstitutionandinsertionerrorsweredealtwithbyintroducingextraerror-predictionindices,whilethedeletionerrorwasdealtwithbyremovingasyllablefromtheinputquerysequence.Theindexwasalsoaugmentedbythedistancescoreaccordingtotheerrorprediction,whichwasusedtoreducefalsedetectionswithoutapplyingtheexpensiveDTW-basedconfirmation.NKI11submittedtworunsfortheCOREsetandtworunsfortheALLset.Asuffixarraywasusedforindexing,whichwasconstructedfromthephonemesequencesobtainedfromthetranscriptionsofspokendocuments.Atdetectiontime,thesuffixarraywassearchedagainstthephonemesequenceofthequeryusingtheDTWalgorithm.Toimprovetheefficiencyofthesearchonthesuffixarray,thephonemesequenceofthelongquerytermwasdividedintosubsequences,eachofwhichwasthensearchedagainstthesuffixarray.Thedetectionresultsofthesubsequenceswerefurtherconfirmedtoformthefinaldetectionresults.ThetranscriptionusedwasREF-SYLLABLE.RYSDTsubmittedthreerunsfortheCOREsetandthreerunsfortheALLset.ThetermdetectionwasperformedbasedontheHoughTransform,alinedetectionalgorithmusuallyusedinimageprocessing.Severalfilteringmethodswereappliedtothequerydocumentimageplanetoimprovethelinedetectionperformance.ThetranscriptionusedwasREF-WORD.YLABsubmittedonerunfortheCOREset.TheyusedNOtranscriptionobtainedfromspeechrecognition,butusedthevectorquantization(VQ)codesequenceofthespokendocument.Foreachdocumentgroupconsistingoflecturesbythesamespeaker,theindividualVQcodesetwasproducedandusedonlyforit.TheV-Pscore,whichencodedthesimilaritybetweenaphonemeandaVQcode,wasobtainedfromthesamedocumentgroupandusedforthedetectionguidedbytheDTWalgorithm.</subsection>
  <subsection title="Formal-run evaluation results">TheevaluationresultsaresummarizedinFigureandTablefortheCOREquerysetofthe13submittedrunsandthebaseline.FigureandTablealsoshowtheSTDperformancefortheALLquerysetofthefivesubmittedrunsandthebaseline.Theofflineprocessingtimeandindexsize(memoryconsumption)arealsoshowninTableonlyfortherunsusingsomeindexingmethodforefficientsearch.Thebaselinesystemuseddynamicprogramming(DP)-basedwordspotting,whichcoulddecidewhetherornotaquerytermisincludedinanIPU.ThescorebetweenaquerytermandanIPUwascalculatedusingthephoneme-basededitdistance.Thephoneme-basedindexforthebaselinesystemwasmadeofthetranscriptionsofREF-SYLLABLE.ThedecisionpointforcalculatingF-measure(spec.)wasdecidedbytheresultofthedry-runqueryset.WeadjustedthethresholdtobethebestF-measurevalueonthedry-runset,whichwasusedasadevelopmentset.FortheCOREqueryset,mostoftherunsthatusedsubword-basedindexingandasimplematchingmethod(DPorexactmatching)outperformedthebaselineperformanceforF-measure(max)andF-measure(spec.).Ontheotherhand,therunsbasedontheHoughTransformalgorithm(teamsAKBLandRYSDT)andtheVQcodebook(teamYLAB)performedbelowthebaseline.ThebestSTDperformancewas``ALPS-1,''whichusesmuchmoreoftheinformationinthespeech.Itused10kindsoftranscriptionsofthespeech.However,theretrievaltimewastheworstamongallthesubmissions.``IWAPU-1''alsoobtainedgoodSTDperformancebyusingafewsubword-basedindices.Therefore,combinationsofmultipleindexesmaybeeffectiveinimprovingSTDperformance.TeamsNKGWandNKI11achievedperformancealittlebetterthanthebaseline.However,theirsearcheswerefasterthanthoseofteamsALPSandIWAPU.ThetasksusingtheALLquerysetmaybemoredifficultthanthoseusingtheCOREquerysetbecausethebaselineperformanceforALLislessthanthatforCORE.Nevertheless,theonlyrunsofteamRYSDToutperformedthebaselineforF-measure(max).TheseresultsarebetterthantheCOREqueryset.</subsection>
  <subsection title="Discussion">ThissectiondescribesthathowourSTDevaluationframeworkcontributestothenewfindingsthroughtheconductofthecompetition.AsdescribedinSection,theoneofcharacteristicinourSTDevaluationframeworkistodistributethereferencetranscriptions.Inadditiontothis,theASRdictionary,theacousticmodelsandthelanguagemodelswerealsoprovidedtothetaskparticipants.Thiscontributedgreatlytoevaluatetheparticipants'STDoutputs.AsshowninFigure,theASRperformanceforthetargetspeechdatadirectlyaffectstheSTDperformance.Therefore,itisveryimportanttocomparetheindexingandsearchmethodsbyprovidingthereferencetranscriptions,thedictionary,themodels,anditstrainingconditions.AsshowninTable,fourparticipantsusedthereferencetranscriptions.ThismadeuscomparetheSTDperformancesbetweentheparticipants'STDtechniques,suchasindexingandsearchmethods,underthesameASRaccuracyofthetargetspeechdata.Forexample,teamsNKI11andAKBLusedthesamereferencetranscription(REF-SYLLABLE),andfinally,NKI11gotbettertheSTDperformance.NKI11hadbetterindexingandsearchmethodsthanAKBL,however,AKBL'ssearchenginecouldfindthetermssoquickly.Ontheotherhand,teamsALPSandIWAPUusedowntranscriptionsobtainedbytheirASRsystemsunderthesameASRconditionsasthereferencetranscriptions.ALPSusednotonlythereferencetranscriptionsbutalsotheadditionaleightsortsoftranscriptions.CombiningthesetranscriptionsgotthebestSTDperformanceamongtheallparticipants.IWAPUachievedthegoodSTDperformancebyimprovingtheacousticmodels,whichmadethegoodASRunderthesameASRconditionsfortheallparticipants.AlthoughthesearchmethodsofALPS,IWAPU,andNKI11weresimilar,wecanfindthedifferencesbetweentheSTDperformances.ThisisattributabletothevarietyofASRsystemsandthemodelingtechniques.Providingthetranscriptions,thedictionary,andthemodelsenabledustocomparetheSTDalgorithmsanddiscusstheSTDperformanceswhensimilarSTDmethodswereusedonourSTDevaluationframework.ThismaybeveryusefulforSTDresearchersaroundtheworld.TheothercharacteristicinourSTDevaluationframeworkistoprovidetwotypesoftestsets:ALLandCOREqueryset,whichhaveadifferentsizeofthespeechdata.Inthesub-task,onlytwoteamsNKI11,RYSDT,andthebaselineusedboththequerysets.AsshowninTableandTable,thelargertargetspeechdata(theALLqueryset)degradedtheevaluationmeasuresrelatedtofalsedetections(precisionrateandMAP)definitely,however,therateofdeclinewasnotsolargeevenifthespeechdatafortheALLquerysetwasabout14timesasmuchassizeoftheCOREqueryset.Forexample,thebothresultsoftheALLandtheCOREquerysetsfromteamRYSDTwerealmostthesameperformanceonF-measure(max)andMAP.Forthebaseline,asshowninFiguresand,theprecisionratedecreaseto20%(fortheALLset)from55%(fortheCOREset)atthepointof50%ofrecallrate.However,thefalsedetectionsjustincreased2.3-foldintheALLqueryset,evenifthespeechdatasizewas14timeslargerthantheCOREsetspeechdata.Ontheotherhand,NKI11gotworsetheSTDperformancefromtheCOREqueryset.ThisfoundthattheRYSDT'sSTDtechniquewasrobustforspeechdatasizechanges.IntheNISTevaluationframework,falsedetectionerrorwasevaluatedbyfalsealarmprobabilitybasedondurationofthetargetspeechdata.Inotherwords,falsealarmprobabilitydeclinesinproportiontotargetspeechsize.Therefore,theNISTevaluationcannotcompletelyinvestigatethechangesofSTDperformancewhenspeechdatasetsinvarioussizesareused.Thisevaluationframeworkclarifiedthetwofindings:anSTDresearchercansufficientlyestimatetheSTDperformanceforabigscalespeechdatasetwithoutthesamescalespeechdataofthetargetspeech,andtheSTDperformancefromthespecificSTDmethoddidnotdependonthesizeoftargetspeechdata.ThesefindingsmayalsobeusefulforSTDresearchers.</subsection>
  <section title="Conclusions">Thispaperdescribedthedesignandevaluationframeworkforthespokentermdetectionstudywhichistheoneofinformationaccesstechnologies.WemanagedtheSTDsub-task,oneoftheSpokenDoctaskattheNTCIR-9workshop.Inthesub-task,wesuppliedthedata,includingrichtranscriptionsandsomemodelsforASR,andtestquerysetsfortheCOREandALLlectures.Finally,seventermsparticipatedintotheSTDsub-task,and18runsweresubmitted.Eachrunwasevaluatedinthedetectionperformances:recall-precisioncurve,F-measures,MAP,timeandcomputerresources(memoryconsumption).ThevarietyofmethodsforSTDhavebeenproposedintheSTDsub-task.UsingrichtranscriptionsfrommultipleASRsystemswasgottenthebestF-measureandMAPamongtheallsubmissions,butitsretrievingspeedwasverylow.Itisuselessonarealapplication.Ontheotherhand,usingtheefficientindexingmethodsachievedthehigh-speedretrieval.However,thedetectionperformancesweresignificantlylesseffectivethanthetopperformance.ItisimportanttoanalyzeadvantagesanddisadvantagesofeachSTDtechniqueandsharetheanalyseswiththetaskparticipants.WehopethattheNTCIR-9SpokenDocwillcontributetogeneratesomenewideasoftheSTDstudyandtodevelopinformationaccesstechnologiesforspokendocuments.authorswouldliketoacknowledgethelargecontributionsofthemembersofSpokenDocumentProcessingWorkingGroupforhavingdiscussionswiththeNTCIR-9SpokenDocSTDsub-task.Apartofthepaper'scontenthasbeenpresentedatthe9-thNTCIRWorkshopmeeting.document</section>
</root>
