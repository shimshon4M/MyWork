    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\newcommand{\thype}{}
\newcommand{\ghype}{}
\newcommand{\xmp}[1]{}
\newcommand{\xmpE}[1]{}
\newcommand{\isa}[2]{}
\newcommand{\isaE}[2]{}
\newcommand{\isaThree}[3]{}
\newcommand{\isaFour}[4]{}
\newcommand{\isaFourE}[4]{}
\newcommand{\attval}[3]{}
\newcommand{\attvalE}[3]{}
\newcommand{\bakuzen}[1]{}


\Volume{19}
\Number{1}
\Month{March}
\Year{2012}

\received{2011}{3}{22}
\revised{2011}{6}{21}
\accepted{2011}{8}{3}

\setcounter{page}{3}

\jtitle{Wikipedia を利用した上位下位関係の詳細化}
\jauthor{山田　一郎\affiref{Author_1} 
\and 橋本　　力\affiref{Author_2}
\and 呉　　鍾勲\affiref{Author_2}
\and 鳥澤健太郎\affiref{Author_2}
\and 黒田　　航\affiref{Author_3}\affiref{Author_4}
\and Stijn De Saeger\affiref{Author_2}
\and 土田　正明\affiref{Author_5}
\and 風間　淳一\affiref{Author_2}}
\jabstract{
単語の上位下位関係を自動獲得する研究はこれまで活発に行われてきたが，
上位概念の詳細さに関する議論はほとんどなされてこなかった．
自動獲得された上位下位関係の中には，
例えば\isa{作品}{七人の侍}や\isa{作品}{1Q84}のように，
より適切と考えられる上位概念「映画」や「小説」と比べて広範囲な概念をカバーする上位概念（「作品」）が含まれることがある．
このような上位概念を検索や質問応答などのタスクにおいて利用すると，より詳細な上位概念を利用する手法と比較して有用でないことが多い．
そこで本論文では，自動獲得した上位下位関係を，Wikipediaの情報を利用することでより詳
細にする手法を提案する．
例えば\isa{作品}{七人の侍}から，
\isaFour{作品}{映画監督の作品}{黒澤明の作品}{七人の侍}
のように，単語「七人の侍」の上位概念（かつ，単語「作品」の下位概念）として，2種類の中間ノード「黒澤明の作品」，
「映画監督の作品」を生成することにより，元の上位下位関係を詳細化する．
自動獲得した1,925,676ペアの上位下位関係を対象とした実験では，最も詳細な上位概念となる一つ目の中間ノード（\xmp{黒澤明の作品}など）
を重み付き適合率85.3\%で2,719,441個，
二つ目の中間ノード（\xmp{映画監督の作品}など）を重み付き適合率78.6\%で6,347,472個生成し，高精度に上位下位関係を詳細化できることを確認した．
さらに，生成した上位下位関係が
\attval{対象}{属性}{属性値}として解釈できることについても報告する．
}
\jkeywords{上位下位関係獲得，「対象--属性--属性値」抽出，Wikipedia}

\etitle{Generating Information-Rich Taxonomy Using Wikipedia}
\eauthor{Ichiro Yamada\affiref{Author_1}
\and Chikara Hashimoto\affiref{Author_2}
\and Jong-Hoon Oh\affiref{Author_2}
\and Kentaro Torisawa\affiref{Author_2}
\and Kow Kuroda\affiref{Author_3}\affiref{Author_4}
\and Stijn De Saeger\affiref{Author_2}
\and Masaaki Tsuchida\affiref{Author_5}
\and Jun'ichi Kazama\affiref{Author_2}}
\eabstract{
Hyponymy relation acquisition has been
 extensively studied. However,
the informativeness of acquired hypernyms
has not been sufficiently discussed.
We found that the hypernyms in automatically acquired hyponymy relations
are often too vague for their hyponyms.
For instance, \xmpE{work} is a vague hypernym for
\isaE{work}{Seven Samurai} and \isaE{work}{1Q84}.
These vague hypernyms 
sometimes cause the lower accuracy
for NLP applications such as information retrieval or question answering.
In this paper, we propose a method of making (vague) hypernyms more specific
exploting Wikipedia.
For instance, our method generates two intermediate nodes \xmpE{work by Akira Kurosawa} and \xmpE{work by film director} for 
a original hyponymy relation \isaE{work}{Seven Samurai}.
We show that our method acquires 2,719,441 hyponymy relations
with the first intermediate concepts
(such as \xmpE{work by Akira Kurosawa})
with 85.3\% weighted precision and
6,347,472 hyponymy relations
with the second intermediate concepts
(such as \xmpE{work by film director})
with 78.6\% weighted precision.
Furthermore, we confirm that hyponymy relaitons acquired by
our method can be interpreted as \attvalE{object}{attribute}{value}.
}
\ekeywords{Hyponymy relation acquisition, Object-attribute-value acquisition, Wikipedia}

\headauthor{山田，橋本，呉，鳥澤，黒田，Saeger, 土田，風間}
\headtitle{Wikipedia を利用した上位下位関係の詳細化}

\affilabel{Author_1}{NHK放送技術研究所}{Science ＆Technology Research Laboratory, Japan Broadcasting Corporation}
\affilabel{Author_2}{情報通信研究機構}{National Institute of Information and Communications Technology}
\affilabel{Author_3}{京都大学}{Kyoto University}
\affilabel{Author_4}{早稲田大学総合研究機構}{Conprehensive Research Organization, Waseda University}
\affilabel{Author_5}{日本電気株式会社}{NEC Corporation}



\begin{document}
\maketitle


\section{はじめに}

上位下位関係は自然言語処理の様々なタスクにおいて最も
重要な意味的関係の一つであり，それゆえ盛んに研究されてきた
\cite{hearst92,hovy09,oh09,ponzetto07,隅田:吉永:鳥澤:2009,suchanek07,nastase08,snow05}．
これらの過去の研究では，上位下位関係を，「AはBの一種あるいはインスタンスであるAとBの関係」と定義している．
本論文の上位下位関係もこの定義に従う．ただし，「概念」の詳細な表現を可能にするために，単一の語だけでなく，\xmp{黒澤明の映画作品}のような句や複合語も考慮する．
このように制限を緩めることで，上位概念をより詳細に表現することが可能となる．

上記の定義によれば，次のペアはいずれも上位下位関係にあると考えられる\footnote{
本稿では上位下位関係を\isa{A}{B}のように表す．
\xmp{A}が上位概念で\xmp{B}が下位概念である．
}．
\begin{enumerate}
\item \isa{黒澤明の映画作品}{七人の侍}
	\label{enum:Kurosawa}
\item \isa{映画作品}{七人の侍}
\item \isa{作品}{七人の侍}
	\label{enum:work}
\end{enumerate}


質問応答等のアプリケーションを考えた場合，
これらの上位下位関係の有用性は異なると考えられる．
例えば，「``七人の侍''とは何ですか？」という質問に対して，
上の3つの上位下位関係の上位概念のうち，答えとして適切なのは最も詳細な上位概念である
(\ref{enum:Kurosawa})の「黒澤明の映画作品」と考えられる．
一方，(\ref{enum:work})の上位概念「作品」は，「何の作品であるか」という必要な情報が欠落しているため「黒澤明の映画作品」という答えに比べて適切ではない．

本論文では，以下の2つの条件を満たす場合に「下位概念Cに対して，AはBより詳細な上位概念」と呼ぶ．
\begin{itemize}
\item AとBは同じ下位概念Cを持つ
\item BはAの上位概念である
\end{itemize}
上記の例では，全ての上位概念が「七人の侍」という同じ下位概念を持ち，かつ，上位概念間には，それぞれ上位下位関係が成り立つ．
「黒澤明の映画作品」の上位概念は「映画作品」，または「作品」，さらに「映画作品」の上位概念は「作品」と考えられる．
従って，下位概念「七人の侍」に対して「黒澤明の映画作品」は「映画作品」や「作品」より詳細な上位概念であり，「映画作品」は「作品」より詳細な上位概念と言うことができる．
また，ある上位概念をより詳細な上位概念に置き換える処理を「上位概念の詳細化」と呼ぶ．

本研究では，自動獲得した上位下位関係の上位概念と下位概念の間に，
より具体的な上位概念を中間ノードとして追加することで，元の上位下位関係を
詳細化する．
中間ノードとして追加されるより具体的な上位概念は，元の上位下位関係が
記述されているWikipedia記事のタイトルと元の上位概念を「AのB」
の形式で連結することで自動獲得する．

例として\isa{作品}{七人の侍}を挙げる．
この上位下位関係は，タイトルが「黒澤明」のWikipedia記事
の中に現れる．
具体的には，当該記事の\xmp{作品}というセクションに\xmp{七人の侍}が記載さ
れている．
本手法では，この情報から，\xmp{七人の侍}は黒澤明の\xmp{作品}であると推測
し，\isa{黒澤明の作品}{七人の侍}を新たに獲得する．
さらに，\xmp{黒澤明}の上位概念が\xmp{映画監督}であることが獲得済みの上位下位関係
から判明すれば，\isa{映画監督の作品}{七人の侍}も獲得できる．
最終的に，元の\isa{作品}{七人の侍}から，
\isaFour{作品}{映画監督の作品}{黒澤明の作品}{七人の侍}を得ることができる．


本稿ではさらに，本手法により獲得した上位下位関係（例えば
\isa{黒澤明の作品}{七人の侍}）が\attval{対象}{属性}{属性値}関係
（例えば\attval{黒澤明}{作品}{七人の侍}）として解釈できることについて議
論する．
この解釈では，Wikipedia記事のタイトルが対象に，
上位概念が属性に，下位概念が属性値に対応づけられる．
実験で生成した上位下位関係2,719,441ペアは，94.0\%の適合率で，
\attval{対象}{属性}{属性値}関係として解釈可能であることを確認した．

以下，\ref{sec:hh-problems}節では，既存の手法で獲得された上位概念の問題
点を例とともに述べる．
\ref{sec:Base-hh}節では，Wikipediaからの上位下位関係獲得手法\cite{隅田:吉永:鳥澤:2009}について説明する．
\ref{sec:proposed-method}節では，我々が開発した，
Wikipediaを用いた詳細な上位下位関係の獲得手法について説明する．
\ref{sec:evaluation}節では，提案手法の評価とエラー分析の結果について
述べる．
\ref{sec:discussion}節では，提案手法により獲得した詳細な上位概念を
より簡潔に言い換える試みと，詳細な上位下位関係の
\attval{対象}{属性}{属性値}関係としての解釈について議論する．
\ref{sec:related-word}節で関連研究について述べる．最後に
\ref{sec:conclusion}節で結論を述べる．



\section{自動獲得された上位概念の問題 \label{sec:hh-problems}}

本節では，隅田ら \cite{隅田:吉永:鳥澤:2009}の手法の出力を例に，
自動獲得された上位概念に見られがちな問題点について述べる．

自動獲得された上位概念の中には，
一般的なシソーラスにおいてルートノードの近くに位置して広範囲な下位概念をカバーするものや，
意味的に曖昧なものが存在するという問題が見られる．
例えば\isa{作品}{七人の侍}における上位概念は\xmp{作品}だが，
世の中には\xmp{作品}と呼べる物が数多く存在する．
さらに極端な例として，上位概念が\xmp{物}や\xmp{事}になっている上位下位関係も，自動で獲得されてしまう可能性がある．
このような上位概念を質問応答などの自然言語処理のアプリケーションで利用すると，より詳細な上位概念と比較してその有用性が低いことが多い．
例えば1節の例で言及したように「``七人の侍''とは何ですか？」という質問に対しては，
より詳細な上位概念である「黒澤明の映画作品」のほうが「作品」より適切な回答
と考えられる．また，「黒澤明の作品には何がありますか？」といったリスト形式の回答を求め
るような質問に対して，上位下位関係を回答の知識源として使うことによって，上位概念「黒
澤明の作品」の下位概念をリスト形式で回答できる\footnote{リスト形式の質問応答を行うタスクは，評価型ワークショップであるTREC QA task \cite{Dang2006,Dang2007}
で実施された．例えば「チューインガムの名前は？」といった質問に対して，そのインスタンスをすべて回答する．}
．一方，上位概念「作品」は他の映画作品や小説作品，音楽作品などの下位概念を持つため，「作品」が上位概念として含まれる上位下位関係のみを知識源として利用しても，このような質問に回答することは難しい．

表\ref{tab:hh-problems}に，
隅田らの手法で獲得された上位下位関係で頻出した
上位概念を挙げる．
例えば，\xmp{アルバム}は，写真のアルバムなのか音楽が収録されているアルバ
ムなのか分からず，曖昧である．
一方，\xmp{出演者}は，これだけでは何に出演したのか分からない．
この表から，自動獲得した上位下位関係の上位概念には，曖昧，または
広範囲な下位概念をカバーする
語が頻出していることがわかる．

\begin{table}[b]
\caption{隅田らの手法で獲得された上位下位関係中の上位概念（出現頻度の降順上位20語）}
\label{tab:hh-problems}
\input{02table01.txt}
\end{table}


このような問題点は，隅田らの手法に限らず発生すると考えられる．
「AなどのB」といった上位下位関係を明示する構文パターンから抽出する手法\cite{hearst92}においても，例えば「七人の侍などの作品」というフレーズからは，「七人の侍」の上位概念として「作品」が抽出される．
つまり，他の多くの上位下位関係獲得手法についても当てはまる．



\section{Wikipediaを用いた上位下位関係の獲得
\label{sec:Base-hh}}

本節では，隅田らが提案したWikipediaを用いた上位下位関係の獲得手法\cite{隅田:吉永:鳥澤:2009}について述べる．
この手法により獲得した上位下位関係が，\ref{sec:proposed-method}節で説明する詳細な上位下位関係獲得の処理対象となる．

\begin{figure}[b]
\begin{center}
\includegraphics{19-1ia2f1.eps}
\end{center}
\caption{Wikipedia記事の例：アップル　インコーポレイテッド}
\label{fig:wikip-article}
\end{figure}

この手法では，
Wikipedia記事の階層的なレイアウト構造を利用して上位下位関係
を獲得する．
図\ref{fig:wikip-article}に，Wikipedia記事の例として\xmp{アップル　インコーポレイテッド}
の記事を挙げる．
この記事は\xmp{Appleショップ}や\xmp{製品}という節があり，\xmp{Appleショップ}の下位には\xmp{北海道地方}，
\xmp{製品}の下位には
\xmp{コンピュータ}，\xmp{iPod}，\xmp{iPhone}などの小節がある．
さらに小節の中には，\xmp{Mac mini}や\xmp{MacBook}，
\xmp{MacBook Air}といった項目が存在する．
以後，これらの節見出し，小節タイトル，項目名をtermと呼ぶことにする．

\begin{figure}[b]
\begin{center}
\includegraphics{19-1ia2f2.eps}
\end{center}
\caption{Media Wikiソースコードの例：アップル　インコーポレイテッド}
\label{fig:mediawiki}
\end{figure}

図\ref{fig:wikip-article}に示すWikipedia記事から上位下位関係候補を抽出する処理では，Wikipediaがデータベースのダンプデータとして提供しているMediaWikiソースコード（図\ref{fig:mediawiki}）を利用する．
MediaWikiソースコードでは，節見出し，小節タイトル，項目名を表現するために特殊な修飾記号が用いられる．
例えば節見出しでは「==製品==」，項目名では「*** Mac mini」などの記号が用いられ，その修飾記号の種類，繰り返し数により，レイアウト構造上の上下関係が決定する．


隅田らの手法では，
まず，記事のレイアウト構造上の上下関係（節タイトルは小節
タイトルより上位にあり，小節タイトルは項目名より上位にある）を守りながら，
2つのtermから1つの上位下位関係候補を獲得する．
例えば図\ref{fig:wikip-article}の場合，
\isa{製品}{コンピュータ}や
\isa{コンピュータ}{Mac mini}，
\isa{製品}{Mac mini}などが獲得される．
次に，SVM \cite{Vapnik:1995}を用いて，獲得された上位下位関係候補
を正しそうなものとそうでないものに分類する．
素性として，以下に示す特徴を上位概念候補，下位概念候補から抽出して利用する．
\begin{itemize}
\item 上位概念候補，下位概念候補の品詞．
\item 上位概念候補，下位概念候補に含まれる形態素．
\item 上位概念候補，下位概念候補の表層文字列．
\item 上位概念候補，下位概念候補が属性語Xに一致するか否か．（属性語として，各記事の根ノード以外のノードに出現する単語を利用．）
\item 上位概念候補，下位概念候補の修飾記号（``=''，``*'' など）．
\item 上位概念候補と下位概念候補間のレイアウト構造上の距離．
\item 上位概念候補が「主な〜」，「〜のリスト」などの上位概念を表現する典型的なパターンに一致するか．
\item 上位概念候補と下位概念候補の末尾の1文字が一致するか．
\end{itemize}
訓練データは，隅田らが実験で用いたデータと同じものを使用した\footnote{この訓練データにより学習されたモデルファイルと上位下位関係獲得ツールは http://\linebreak[2]alaginrc.nict.go.jp/\linebreak[2]hyponymy/\linebreak[2]index.htmlで公開されている．}．
このデータは，Wikipediaから獲得した上位下位関係候補から29,900対を抽出し，人手により上位下位関係か否かを判定することにより作成している．


この処理を
2009-09-27版のWikipediaに適用することにより，1,925,676ペアの上位下位関係を適合率90\%で
獲得した．
この上位下位関係をベース上位下位関係（図\ref{fig:whole-procedure}(a)）と呼び，\ref{sec:proposed-method}節で説明する詳細な上位下位関係獲得の処理対象とする．

階層的なレイアウトを利用する手法とは別に，隅田らは，Wikipedia記事の定義文（記事の第一文に該当）を用いた手法と，
記事下部にあるカテゴリ情報を用いた手法も提案している．
これらの手法では記事タイトルが下位概念として使われるため，我々が提案する
記事タイトルによる上位下位関係の詳細化が適用できない．
そこで，
これら2つの手法により得られた上位下位関係はベース上位下位関係として用いず，
\ghype{}の生成の際に用いる（\ref{sec:G-hh}節）．
この処理により，2009-09-27版のWikipediaからは，522,709個の記事タイトルに対して1,472,035個の上位概念を適合率90\%で
獲得した．



\section{詳細な上位下位関係の獲得手法
\label{sec:proposed-method}}

\begin{figure}[b]
\begin{center}
\includegraphics{19-1ia2f3.eps}
\end{center}
\caption{提案手法の処理の流れ}
\label{fig:whole-procedure}
\end{figure}

\ref{sec:hh-problems}節で述べた通り，ベース上位下位関係の上位概念の
中には
広範囲な下位概念をカバーするもの
や意味的に曖昧なものが存在する．
そこで本節では，ベース上位下位関係を処理対象とした詳細な上位下位関係の獲得手法について述べる．
図\ref{fig:whole-procedure}に，提案手法の処理の流れの全体像を示す．
まず，ベース上位下位関係の各上位概念をWikipedia記事のタイトルで詳細化し，
詳細化された上位概念を元の上位概念と下位概念の間に中間ノードとして挿入す
る（\ref{sec:T-hh}節）．
以降では，Wikipedia記事のタイトルで詳細化された上位概念を\thype{}と
呼ぶ．
また，\thype{}を中間ノードとして挿入された上位下位関係をT-上位下位関係と
呼ぶ（図\ref{fig:whole-procedure}(b)）．
次に，\thype{}中の記事タイトル箇所をその上位概念で抽象化する事で，
元の上位概念よりは詳細だが\thype{}よりは抽象的な新たな上位概念を得る．
以降では，この上位概念を\ghype{}と呼ぶ．
\ghype{}は，T-上位下位関係の上から二番目，つまり元の上位概念の直下に挿入
される（\ref{sec:G-hh}節）．
\thype{}に加え\ghype{}が挿入された上位下位関係を，これ以降，
G-上位下位関係と呼ぶ（図\ref{fig:whole-procedure}(c)）．
なお本手法では，上位概念
に関わらず，全ての
ベース上位下位関係を本提案手法により詳細化する．
以下，各処理手順を詳しく説明する．


\subsection{T-上位下位関係の獲得
\label{sec:T-hh}}

Wikipediaの記事に出現する節タイトル，小節タイトル，項目名などは，その記事のタイトルによって情報を補足できると考えられる．
ベース上位下位関係の上位概念は，Wikipediaの記事に出現する節タイトル，小節タイトル，項目名などに対応するため，
T-上位下位関係の獲得処理では，ベース上位下位関係の上位概念をWikipedia記事タイトルで情報を補い，\thype{}を生成する．
上位概念を補う記事タイトルは，その上位概念と下位概念の抽出元の記事から取得する．


\thype{}は，
元の上位概念とWikipedia記事タイトルを，助詞「の」によって連結して生成する．
例えば，上位概念\xmp{作品}と記事タイトル\xmp{黒澤明}は，助詞「の」によっ
て連結されて\xmp{黒澤明の作品}という\thype{}になる．


生成した\thype{}は，元の上位概念と下位概念の中間に挿入する．
この結果，
\isaThree{作品}{黒澤明の作品}{七人の侍}のように，三階層のT-上位下位関係が生成される（図\ref{fig:whole-procedure}(b)）．


\subsection{G-上位下位関係の獲得
\label{sec:G-hh}}

\thype{}は，Wikipedia記事タイトルとベース上位概念を「の」で連結して生成した．
次に，
\thype{}の中のWikipedia記事タイトルの箇所を，その上位概念で置
き換えることによって，さらなる上位概念となる\ghype{}を生成する．
例えば\xmp{黒澤明の作品}という\thype{}の場合，そのWikipedia記事タイトルの
箇所である\xmp{黒澤明}を上位概念である\xmp{映画監督}で置き換えて，
\xmp{映画監督の作品}という\ghype{}を生成する．

\ghype{}の生成では，Wikipedia記事タイトルの上位概念が必要になる．
Wikipedia記事タイトルの上位概念は，
隅田らの手法のうち，\ref{sec:Base-hh}節の最後で述べた，
Wikipedia記事の第一文を用いる手法と，
記事下部のカテゴリ情報を用いる手法によって獲得する．
例えば図\ref{fig:wikip-article}の場合，記事タイトルである
\xmp{アップル　インコーポレイテッド}の上位概念の候補がその第一文（「アップル社は，アメリカ合衆国...製造する多国籍企業である．」）と記事下部にあるカテゴリ情報
（カリフォルニアの企業，多国籍企業，携帯電話メーカー，
$\ldots$）に記載されている．
これらの上位概念候補は，\ref{sec:Base-hh}節で述べたSVM分類器に
よって上位概念か否か判定される．

生成した\ghype{}を，T-上位下位関係の中の元の上位概念と\thype{}の間に挿入
し，G-上位下位関係を生成する．
G-上位下位関係は，
例えば\isaFour{作品}{映画監督の作品}{黒澤明の作品}{七人の侍}のように，
四階層の上位下位関係となる．



\section{評価実験 \label{sec:evaluation}}

提案手法を評価するため，2009-09-27版の日本語Wikipediaダンプデー
タを対象として，提案手法によりG-上位下位関係を獲得した．
表\ref{tab:ex-acquired-G-hh}に，獲得したG-上位下位関係の例を挙げる．

\begin{table}[b]
\caption{評価実験で獲得されたG-上位下位関係の例}
\label{tab:ex-acquired-G-hh}
\input{02table02.txt}
\end{table}

生成したG-上位下位関係から以下の三種類の上位下位関係ペアを抽出し，各ペアが上位下位関係として妥当か評価を行った
（図\ref{fig:hh-kinds}）．

\begin{description}
 \item[ベース上位下位関係：] 隅田らの手法により獲得した上位下位関係
	    （例えば\isa{作品}{七人の侍}）
 \item[\ghype{}ペア：] \ghype{}とベース上位下位関係の下位概念
	    （例えば\isa{映画監督の作品}{七人の侍}）
 \item[\thype{}ペア：] \thype{}とベース上位下位関係の下位概念
	    （例えば\isa{黒澤明の作品}{七人の侍}）
\end{description}

\begin{figure}[htb]
\begin{center}
\includegraphics{19-1ia2f4.eps}
\end{center}
\caption{評価対象の三種類の上位下位関係ペア}
\label{fig:hh-kinds}
\end{figure}

Wikipediaダンプデータを解析した
結果，1,925,676個のベース上位下位関係，
6,347,472個の\ghype{}ペア，そして，
2,719,441個の\thype{}ペアを獲得した．
ベース上位下位関係は二記事以上に出現することがあるため，
出現した記事タイトルを補うことにより生成される\thype{}ペアの数はベース上位下位関係の数より多くなる．
また，2,719,441個の\thype{}ペアのうち2,113,040ペアに対しては，
一つのWikipedia記事タイトルに2つ以上の上位概念が獲得されたため，\ghype{}ペアの数は
\thype{}ペアの数より多い．
一方，\thype{}ペアのうち342,884ペアに対しては，上位概念（Wikipedia記事タ
イトル）が獲得できなかったため，それらに対応する\ghype{}ペアが得られなかっ
た．



獲得したG-上位下位関係から200サンプルを評価対象として抽出し，
それら200サンプルからベース上位下位関係，\thype{}ペア，\ghype{}ペアを取得した．
サンプリングしたG-上位下位関係の中で，22個の\thype{}に対する上位概念が自動獲得できなかったため，
これらは対応する\ghype{}ペアが得られなかった．
最終的に，ベース上位下位関係として200ペア，\thype{}ペアとして200ペア，
そして，
\ghype{}ペアとして，サンプリングしたG-上位下位関係から抽出可能な178ペアを評価した．



いずれも筆者ではない被験者三名により，これらのペアが上位下位関係として正しいかどうか評価を行った．
被験者は
次の三種類の評価ラベルを評価サンプルの各ペアに付与した．

\begin{description}
 \item[Good:] 上位下位関係として正しい．
 \item[Less good:] 上位下位関係としては正しいが，「``下位概念''とは何？」といった質問の回答として相応しくない上位概念
 \item[Bad:] 上位下位関係として間違っている．あるいは，上位概念または
	    下位概念が意味不明である．
\end{description}

評価サンプルの各ペアに対して，
被験者二名以上が選択したラベルを最終的な評価ラベルとした．
被験者が三名とも異なる判断をした場合は，著者の一人によって最終的な
評価ラベルを判断した\footnote{
578ペアの評価サンプルのうち9ペアがこのケースに該当した．
}．
被験者三名による評価アノテーションのKappa値は0.58であった．
これは，本評価実験の評価アノテーションにまずまずの安定性があることを示し
ている．

評価の指標として，
\pagebreak
次のように定義される重み付き適合率を用いた．
\begin{equation}
重み付き適合率=\frac{\#Good \times 1 + \#Less\ good \times 0.5 + \#Bad \times 0}{\#Good + \#Less\ good + \#Bad}
\label{formula:precision}
\end{equation}
ここで，$\#Good$，$\#Less\ good$，$\#Bad$は，それぞれのラベル数を示す．
本評価実験における重み付き適合率の計算式では，Goodラベルを1つの正解
サンプルとしてカウントし，Badラベルを正解サンプルとしてはカウント
しない．
この点は通常の適合率の計算と同じだが，Less goodラベル1つにつき，
0.5を正解サンプル数に追加する点が通常と異なる．
この重み付き適合率の計算方法はPasca \cite{pasca2007,pasca2009}も採用している．
また，Goodラベルのみを正解とした適合率の計算も行った．
表\ref{tab:result-hyp}に評価結果を挙げる．
この表の重み付き適合率のコラムを見ると，ベース上位下位関係，\ghype{}ペア，\thype{}ペアと，
獲得される上位概念が詳細なほど
重み付き適合率とGoodラベルのみを正解とした適合率が高くなっていることが読み取れる．

\begin{table}[t]
\caption{上位下位関係の評価結果}
\label{tab:result-hyp}
\input{02table03.txt}
\end{table}


次に，本実験におけるSVM分類器の効果について考察する．
隅田らは，SVMによるフィルタリング処理を行わない場合，Wikipedia記事の階層的なレイアウト構造から獲得した上位下位関係候補の適合率は0.284であると報告している\cite{隅田:吉永:鳥澤:2009}
\footnote{本実験における上位下位関係候補の獲得処理は，隅田らの手法と同じアルゴリズムを用いているため，この値が大きく変わることは無いと考えられる．}．
つまり，SVMによるフィルタリング処理を行わない場合のベース上位下位関係ではGoodとLess Goodを合わせても全体の0.284しか無く，残りの候補が上位下位関係では無いと判断される．
また，SVMによるフィルタリング処理を行わない場合，定義文から獲得した上位下位関係候補は0.894，カテゴリ情報からは0.705の適合率であると報告している．
本提案手法でも\ghype{}を生成する際に，定義文とカテゴリ情報からフィルタリング処理を行い獲得した上位概念を使用している．
このSVMによるフィルタリングの効果を明確にするため，
表\ref{tab:result-hyp}と同じ実験対象に対してフィルタリング処理を行わずに
\ghype{}を生成し，被験者三名による評価実験を行った．
結果を表\ref{tab:result-hyp2}に示す．
SVMによるフィルタリングを用いない結果（表\ref{tab:result-hyp2}）は，フィルタリングを用いる結果（表\ref{tab:result-hyp}）と比較して，重み付き適合率が0.157低く，SVMによるフィルタリングが効果的であることがわかる．


\begin{table}[t]
\caption{上位下位関係の評価結果（SVMによりフィルタリング処理を行わない場合）}
\label{tab:result-hyp2}
\input{02table04.txt}
\end{table}



表\ref{tab:result-hyp}の結果では，GoodとLess good，Badのコラムからは，
ベース上位下位関係，\ghype{}ペア，\thype{}ペアと，
獲得される上位概念が詳細なペアほど
Less goodと判定されるペアが減少し，GoodあるいはBadと判定されるペアが増加
する傾向にあることが読み取れる．
つまり，獲得される上位概念が詳細なペアほど，
詳細で正しい上位概念だけでなく，詳細だが間違っている上位概念も増加する傾
向にある．
詳細で正しい上位概念が増加することは，本研究の当初の狙い通りのポジティブな
側面であるが，間違っている上位概念が増加するのは予期しなかったネガティ
ブな側面である．
そこで，\thype{}ペアに焦点を当てて，本提案手法による
誤りの原因を次の三種類に分類した．

\begin{description}
 \item[エラータイプ1：] ベース上位下位関係の誤りが原因となり，間違いと判定された．
	    エラー全体の27.6\%を占める．\\
	    例）\isa{リンチバーグのヘリテイジ高校}{ペリーモン小学校}
 \item[エラータイプ2：] 助詞「の」が元の上位概念とWikipedia記事タイトルを
	    連結する表現として不適切であり，その結果生成された\thype{}が
	    意味不明なため，間違いと判定された．
	    エラー全体の3.4\%を占める．\\
	    例）\isa{原山理一郎のアナウンサー}{小林豊}
 \item[エラータイプ3：] Wikipedia記事タイトルによる詳細化によって上位概念
	    が下位概念を包含する
	    概念ではなくなったため（上位下位関係ではなくなったため），
	    間違いと判定された．
	    エラー全体の69.0\%を占める．\\
	    例）\isa{大垣市の公共施設}{図書館}
\end{description}

\textbf{エラータイプ1}の例
\isa{リンチバーグのヘリテイジ高校}{ペリーモン小学校}におけるベース上位下位関係は
\isa{ヘリテイジ高校}{ペリーモン小学校}であるが，これは上位下位関係として
間違いである．
\ref{sec:Base-hh}節で述べた通り，
ベース上位下位関係は隅田らの手法で獲得されるものであり，本提案手法は
隅田らの手法のwrapperとして機能するため，
隅田らの手法のエラーはそのまま本提案手法に引き継がれる．
つまり，エラータイプ1は提案手法を原因とはしていない．

\textbf{エラータイプ2}の例
\isa{原山理一郎のアナウンサー}{小林豊}におけるベース上位下位関係は
\isa{アナウンサー}{小林豊}であり，上位下位関係として正しい．
しかし，本提案手法により，\isa{アナウンサー}{小林豊}を獲得した
Wikipedia記事のタイトル\xmp{原山理一郎}を元の上位概念\xmp{アナウンサー}
に助詞「の」によって連結したため，\xmp{原山理一郎のアナウンサー}という
意味不明な上位概念が生成された．
この意味不明な上位概念が本来意味するところは
\xmp{原山理一郎と同期入社のアナウンサー}である．
つまり，元の上位概念とWikipedia記事タイトルを一様に助詞「の」で連結する
というナイーブな手法がこのタイプのエラーの原因となっている．

\textbf{エラータイプ3}の例
\isa{大垣市の公共施設}{図書館}におけるベース上位下位関係は
\isa{公共施設}{図書館}であり，これは上位下位関係として正しい．
このベース上位下位関係
を獲得したWikipedia記事の
タイトルが\xmp{大垣市}である．
そのため，本提案手法により\isa{大垣市の公共施設}{図書館}という
T-上位下位関係が獲得された．
しかし，\xmp{大垣市の公共施設}という概念は，
元の上位概念である\xmp{公共施設}より詳細になってはいるが，
\xmp{図書館}という概念を包含していない
（大垣市の図書館以外にも図書館は存在する）ので，
\isa{大垣市の公共施設}{図書館}は上位下位関係としては間違いとなる．


本提案手法の間違いの中でエラータイプ3に属するものが69.0\%と多数を占める．
エラータイプ3に属する不適切な上位下位関係ペアの多くは，
下位概念が普通名詞によって表されるものであり，正解と判定された上位下位関係ペアは，
下位概念が固有名詞によって表されるものがほとんどであった．
つまり，下位概念が普通名詞で表されている上位下位関係ペアを出力から除外
することでエラータイプ3に属する間違いを減らすことができると考えられる．
そこで，次の条件のいずれかに合致するtermは普通名詞
である可能性が高い
と仮定し，下位概念が普通名詞である上位下位関係ペアを，
評価サンプルのベース上位下位関係，\thype{}ペア，\ghype{}ペアから除外した．

\begin{itemize}
 \item Wikipedia記事の節タイトル，あるいは小節タイトルとして使われているterm
 \item 一定記事数（実験では30記事）以上に出現したterm
\end{itemize}


\begin{table}[b]
\caption{普通名詞で表される下位概念を持つ上位下位関係を除外した場合の
評価結果}
\label{tab:result-hyp-filtering}
\input{02table05.txt}
\end{table}

表\ref{tab:result-hyp}と同じ処理対象に対して，下位概念が普通名詞と判断された上位下位関係を除外した場合の評価
結果を表\ref{tab:result-hyp-filtering}に示す．
下位概念が普通名詞と判断された上位下位関係を除外したため，ベース上位下位関係と\thype{}では処理対象数が200ペアから150ペアに，\ghype{}では178ペアから129ペアに減少している．
表\ref{tab:result-hyp}の結果と比べると，
\ghype{}ペアの重み付き適合率が6.7\%，
\thype{}ペアの重み付き適合率が8.4\%向上していることがわかる．
しかし，全処理対象に対する獲得ペア数は，\thype{}ペアが2,719,441ペアから
1,958,117ペアへ，\ghype{}ペアが6,347,472ペアから
4,960,751ペアへと減少した．
獲得ペア数を保ちながら重み付き適合率を向上させる手法の開発は今後の課題とする．



\section{応用 \label{sec:discussion}}

本節では，\ghype{}をより簡潔に言い換える手法と，
T-上位概念ペアの
\attval{対象}{属性}{属性値}関係としての解釈について議論する．

\subsection{\ghype{}のより簡潔な表現への言い換え}

\ghype{}のいくつかはより簡潔な表現に言い換えることができる．
この言い換え処理が自動化できれば，本提案手法で獲得した上位下位関係を
既存のシソーラスと関連づけることが可能になる．
例えば，\ghype{}として生成された
\xmp{映画監督の作品}は
\xmp{映画}に言い換えても問題ないと考えられる\footnote{「映画監督の作品」には「小説」などの可能性もあるが，ここでは主となる言い換え対象のみを扱う．}．
この言い換えにより，
本提案手法で獲得した\xmp{映画監督の作品}の下位概念
（映画のタイトルなどのインスタンスを含む）を既存のシソーラスの
\xmp{映画}の位置に追加することができる．

\begin{table}[b]
\caption{\ghype{}の簡潔な言い換え表現の例}
\label{tab:paraphrase-rules}
\input{02table06.txt}
\end{table}

そこで予備実験として，本提案手法で獲得した\ghype{}のうち最頻出の
20概念に対して簡潔な言い換え表現を手作業で作成し，
それらによって上位概念が言い換えられたG-上位下位関係の適合率を評価した．
表\ref{tab:paraphrase-rules}に，\ghype{}とその言い換え表現の例を挙げる．
言い換え対象の20の\ghype{}を含む\ghype{}ペアは
全部で59,890ペア，
この\ghype{}に含まれる下位概念の異なり数は54,981個であった．
その中から200ペアをサンプリングし，言い換え後の上位概念と下位概念のペアが上位下位関係であるか判定する実験を行った．
実験では，筆者を含まない三名の被験者により判定を行い，二名以上が支持した結果を最終的な判定として使用した．
三名の被験者の一致率を示すKappa値は0.674で，十分な一致率であると考えられる．
実験の結果，言い換え後の上位概念と下位概念のペアが上位下位関係として正しいと判定された適合率は78.0\%であった．

言い換え後の上位概念は既存のシソーラスに存在する単語を利用しているため，言い換え表現を20表現用意するだけで，異なり数54,981個の下位概念を
適合率78.0\%で既存のシソーラスに追加できることがわかる．
全ベース上位下位関係における下位概念異なり数は1,199,826個であり，わずか20個の言い換え表現で，下位概念全体の4.6\%をカバーしていることがわかる．
今後，重複する下位概念などの情報を利用することによりこの言い換え表現を自動獲得し，
カバー率を向上させることが課題となる．


\subsection{T-上位概念ペアの\attval{対象}{属性}{属性値}関係としての解釈}

T-上位概念ペアは，Wikipedia記事から獲得したベース上位下位関係と，
そのWikipedia記事のタイトルから構成される．
このWikipedia記事のタイトルとベース上位下位関係の上位概念，下位概念は，対象とその属性，属性値
という3つ組として
解釈することができる．
例として\isa{黒澤明の作品}{七人の侍}というT-上位概念ペアを挙げる．
このT-上位概念ペアでは，\xmp{黒澤明}がWikipedia記事のタイトルで，
\isa{作品}{七人の侍}がその記事から獲得された元のベース上位下位関係である．
この場合，\xmp{作品}と\xmp{七人の侍}を\xmp{黒澤明}という対象の属性，属性
値と解釈することができる．
同様に，\isa{シリコングラフィックスの製品}{IRIS Crimson}というT-上位概念ペアの
場合も，\xmp{製品}と\xmp{IRIS Crimson}を
\xmp{シリコングラフィックス}という対象の属性，属性値と解釈することができる．

\ref{sec:evaluation}節にある通り本提案手法による上位概念の詳細化は高い性能を示しているが，
このことは，T-上位概念ペアが\attval{対象}{属性}{属性値}関係として解釈可
能であるという上記の観察結果によって，次のように説明できる．
一般的に，属性は，それがどの対象の属性かを明示することで詳細化できる
と言える．
本提案手法は，属性と上位概念のterm，対象とWikipedia記事タイトルを対応づ
けた上でこの一般論に倣い，
上位概念のtermがどのタイトルのWikipedia記事から得られたtermかを明示する
ことで上位概念を詳細化している．
従って，どの対象かを明示することで属性を詳細化できるという一般論が正しい
限りにおいて，本提案手法は正しく上位概念を詳細化できる．

T-上位概念ペアが\attval{対象}{属性}{属性値}関係として解釈でき
るという仮説が正しいかどうかを明らかにするために，
T-上位概念ペアを\attval{対象}{属性}{属性値}関係として評価した．
まず，\ref{sec:evaluation}節の評価実験で使用したG-上位下位関係200サンプル
（普通名詞で表される下位概念を持つ上位下位関係も含む）から，
ベース上位下位関係に対応する元の上位概念と下位概念，\thype{}のWikipedia
記事タイトル箇所を取り出し，
\attval{Wikipedia記事タイトル}{上位概念}{下位概念}の3つ組を200個
用意した．
この評価データを「T-上位概念セット」と呼ぶ．
これらとは別に，比較のため，隅田らの手法の処理途中で得られる
上位下位関係候補（SVMで分類される前のベース上位下位関係の候補．
\ref{sec:Base-hh}節を参照）と，
それらの出所であるWikipedia記事のタイトルによって，
\attval{Wikipedia記事タイトル}{上位概念候補}{下位概念候補}の3つ組を200個
用意した．
この評価データを「上位下位候補セット」と呼ぶ．
2つの評価データの違いは，上位下位候補セットには上位下位関係とし
ては不適切な上位概念と下位概念がより多く含まれているという点にある．

次に，3名の被験者（いずれも著者ではない）によって，これらの3つ組が\attval{対象}{属性}{属性値}として正しいかを評価する実験を行った．
評価サンプルは，T-上位概念セットの200と上位下位候補セットの200の計
400である．
これら400サンプルはシャッフルした上で被験者に提示した．
評価の際は，
次の3種類の評価ラベルを使用した．

\begin{description}
 \item[Vital:] \attval{対象}{属性}{属性値}として適切．
 \item[Okay:] \attval{対象}{属性}{属性値}として適切だが，その対象に
	    とって当該の属性，属性値は本質的なものとは言えない．
 \item[Wrong:] \attval{対象}{属性}{属性値}として不適切．
\end{description}

\ref{sec:evaluation}節の評価実験と同様，
2名以上の被験者が付与したラベルを各3つ組の最終的な評価ラベルとした．
もし3名の被験者が皆異なる判断をした場合，著者の一人が最終的な評価ラベル
を決定した\footnote{
著者の一人が評価ラベルを決めたケースは400サンプル中9サンプルであった．}．
被験者3名による評価ラベリングのKappa値は0.51であり，
本実験の評価ラベリングにまずまずの安定性があることを示している．
重み付き適合率は，\ref{sec:evaluation}節の評価実験で使用した，
式(\ref{formula:precision})
と同様に，ラベルがVitalであるものを1.0，Okeyを0.5，Wrongを0として正解サンプル数をカウントして算出した
\cite{pasca2007,pasca2009}．
評価結果を表\ref{tab:result-attval}に示す．

\begin{table}[b]
\caption{T-上位概念ペアの\attval{対象}{属性}{属性値}としての評価結果}
\label{tab:result-attval}
\input{02table07.txt}
\end{table}

T-上位概念セットの\attval{対象}{属性}{属性値}関係としての重み付き適合率が94.0\%
であることから，T-上位概念ペアが\attval{対象}{属性}{属性値}関係として解釈
できるという仮説は正しいと考えられる．
この重み付き適合率は，表\ref{tab:result-hyp}におけるT-上位下位概念ペアの重み付き適合率より高い．これは，
\ref{sec:evaluation}節で述べたエラータイプ3のものが，\attval{対象}{属性}{属性値}関係としては，
正しい関係と判定されることに起因する．
例えば，エラータイプ3の例\attval{大垣市}{公共施設}{図書館}は，\attval{対象}{属性}{属性値}関係としては正しい．

一方，上位下位候補セットの\attval{対象}{属性}{属性値}関係としての適
合率は53.5\%と低い．
このことは，
Wikipedia記事タイトルとその記事から取り出した2つのterm
（節タイトル，小節タイトル，項目名）ならどんなものでも
\attval{対象}{属性}{属性値}関係として解釈できるわけではない，ということ
を示唆している．
つまり，2つのtermが上位下位関係として適切な場合にのみ，
\attval{Wikipedia記事タイトル}{上位概念のterm}{下位概念のterm}が
\attval{対象}{属性}{属性値}関係として解釈できる，ということを
意味している．

\section{関連研究 \label{sec:related-word}}

大量文書からの上位下位関係の獲得手法はこれまでに数多く提案されてきた．
これらは
言語表現パターンを用いるもの
\cite{hearst92,ando04}，
クラスタリングに基づくもの
\cite{pantel04,etzioni05}，
HTML文書の構造を利用するもの
\cite{shinzato04}，
Wikipediaの構造を利用するもの
\cite{隅田:吉永:鳥澤:2009,oh09,Yamada:EMNLP:2009}
に大きく分類することができる．

上位下位関係を構成する概念の詳細さの問題に取り組んだ研究は我々の
知る限りHovyらの研究 \cite{hovy09}のみである．
Hovyらは，Doubly-Anchored Patternと呼ばれる語彙統語パ
ターンを用いたbootstrap手法によって，``people / Shakespeare'' といった
上位下位関係に中間語writersを挿入する手法を提案した．
しかし彼らの手法では，あらかじめ決めた ``animals'' と ``people'' という2種類のルートコンセプトのみ
を対象としている．
一方，本提案手法では，処理対象に制限はなく，あらゆる上位概念を扱うことができる．


本提案手法ではWikipediaを知識獲得源として利用しているが，
Wikipediaからの知識獲得研究は近年活発化している
\cite{kazama07,ponzetto07,suchanek07,nastase08,
隅田:吉永:鳥澤:2009,oh09,Yamada:EMNLP:2009}．
Wikipediaからの知識獲得という文脈における本研究の新規性は，
Wikipediaの百科事典としての性質を利用することで，
上位下位関係としてだけではなく，\attval{対象}{属性}{属性値}関係としても
解釈可能な知識を獲得する手法を開発した点にある．
一般的に，\attval{対象}{属性}{属性値}関係における属性と属性値のペアは，上位下位関係と解釈できないものも多数存在する．
提案手法により獲得できる\attval{対象}{属性}{属性値}関係は，その属性と属性値が上位下位関係を持つものに限定しているが，
\attval{対象}{属性}{属性値}関係を大量かつ高精度に獲得している．


\section{おわりに \label{sec:conclusion}}

本稿では，
自動獲得した上位下位関係の上位概念
を，Wikipediaの情報を利用することで，より詳細にする手法を
提案した．
本手法により，2,719,441個の\thype{}ペアを重み付き適合率85.3\%で，
6,347,472個の\ghype{}ペアを重み付き適合率78.6\%で獲得することができた．
さらに，下位概念が普通名詞である上位下位関係ペアを除く処理を行うことにより，
1,958,117個の\thype{}ペアに対する重み付き適合率を93.7\%，
4,960,751個の\ghype{}ペアの重み付き適合率を85.3\%に向上できることを確認した．
この結果は，ベースとしている上位下位関係獲得手法\cite{隅田:吉永:鳥澤:2009}における適合率（1,925,676ペアに対して90.0\%）と比較して十分な精度であると考えられる．
また，
\ghype{}をより簡潔に言い換える
（例えば\xmp{映画監督の作品}を\xmp{映画}に言い換える）
実験を行い，わずか20個の\ghype{}の言い換え表現を作成することで，
59,890個の下位概念を適合率78.0\%で既存のシソーラスに追加できる可能性があること
を明らかにした．
最後に，本手法で獲得した上位下位関係が，
\attval{黒澤明}{作品}{七人の侍}などのように，
\attval{対象}{属性}{属性値}として解釈できることについて示した．

提案手法により生成した詳細な上位下位関係を使用することによって，質問応答におけるよ
り適切な回答の生成や，「黒澤明の作品」の一覧といった「対象—属性」に対する属性値の検索
が可能となる．この「対象—属性」に対する属性値の検索結果は，リスト形式の回答を求める
ような質問応答のタスク\cite{Dang2006,Dang2007}でも有用となる．さらに提案手法は，上位概
念を詳細化して既存のシソーラスを拡張する手法としても利用可能と考えられる．

提案手法では\thype{}を生成する際，元の上位概念とWikipediaの記事タイトルを助詞「の」によって連結した．
助詞「の」は多様な意味で用いることができるので，我々が実験した範囲では，この単純な方法がほとんど
の場合に成功する．
しかし，助詞「の」以外に，上位概念とWikipedia記事タイトルを結ぶより適切
な表現が存在することもある．
例えば\xmp{作品}と\xmp{黒澤明}の場合，「の」よりも「による」で連結した方
が，日本語表現として適切な\thype{}を生成できる．
Torisawa \cite{torisawa01}は与えられた2つの名詞を連結する最も適切な表現
を選択する手法を開発した．
Torisawaの手法により我々の提案手法がさらに洗練されたものになる可能性が高
いが，これは今後の課題とする．




\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Ando, Sekine, \BBA\ Ishizaki}{Ando
  et~al.}{2004}]{ando04}
Ando, M., Sekine, S., \BBA\ Ishizaki, S. \BBOP 2004\BBCP.
\newblock \BBOQ Automatic Extraction of Hyponyms from {J}apanese Newspaper
  Using Lexico-syntactic Patterns.\BBCQ\
\newblock In {\Bem Proceedings of the 4th International Conference on Language
  Resources and Evaluation (LREC)}, \mbox{\BPGS\ 387--390}.

\bibitem[\protect\BCAY{Dang, Lin, \BBA\ Kelly}{Dang et~al.}{2006}]{Dang2006}
Dang, H., Lin, J., \BBA\ Kelly, D. \BBOP 2006\BBCP.
\newblock \BBOQ Overview of the TREC 2006 Question Answering Track.\BBCQ\
\newblock In {\Bem Proceedings of the Fifteenth Text REtrieval Conference}.

\bibitem[\protect\BCAY{Dang, Lin, \BBA\ Kelly}{Dang et~al.}{2007}]{Dang2007}
Dang, H., Lin, J., \BBA\ Kelly, D. \BBOP 2007\BBCP.
\newblock \BBOQ Overview of the TREC 2007 Question Answering Track.\BBCQ\
\newblock In {\Bem Proceedings of the Sixteenth Text REtrieval Conference}.

\bibitem[\protect\BCAY{Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland,
  Weld, \BBA\ Yates}{Etzioni et~al.}{2005}]{etzioni05}
Etzioni, O., Cafarella, M., Downey, D., Popescu, A.-M., Shaked, T., Soderland,
  S., Weld, D.~S., \BBA\ Yates, A. \BBOP 2005\BBCP.
\newblock \BBOQ Unsupervised named-entity extraction from the web: An
  experimental study.\BBCQ\
\newblock {\Bem Artificial Intelligence}, {\Bbf 165}  (1), \mbox{\BPGS\
  91--134}.

\bibitem[\protect\BCAY{Hearst}{Hearst}{1992}]{hearst92}
Hearst, M.~A. \BBOP 1992\BBCP.
\newblock \BBOQ Automatic Acquisition of Hyponyms from Large Text
  Corpora.\BBCQ\
\newblock In {\Bem Proceedings of the 14th conference on Computational
  Linguistics (COLING)}, \mbox{\BPGS\ 539--545}.

\bibitem[\protect\BCAY{Hovy, Kozareva, \BBA\ Riloff}{Hovy
  et~al.}{2009}]{hovy09}
Hovy, E., Kozareva, Z., \BBA\ Riloff, E. \BBOP 2009\BBCP.
\newblock \BBOQ Toward Completeness in Concept Extraction and
  Classification.\BBCQ\
\newblock In {\Bem Proceedings of the 2009 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, \mbox{\BPGS\ 948--957}.

\bibitem[\protect\BCAY{Kazama \BBA\ Torisawa}{Kazama \BBA\
  Torisawa}{2007}]{kazama07}
Kazama, J.\BBACOMMA\ \BBA\ Torisawa, K. \BBOP 2007\BBCP.
\newblock \BBOQ Exploiting {W}ikipedia as External Knowledge for Named Entity
  Recognition.\BBCQ\
\newblock In {\Bem Proceedings of the Joint Conference on Empirical Methods in
  Natural Language Processing and Computational Natural Language Learning
  (EMNLP-CoNLL)}, \mbox{\BPGS\ 698--707}.

\bibitem[\protect\BCAY{Nastase \BBA\ Strube}{Nastase \BBA\
  Strube}{2008}]{nastase08}
Nastase, V.\BBACOMMA\ \BBA\ Strube, M. \BBOP 2008\BBCP.
\newblock \BBOQ Decoding {W}ikipedia Categories for Knowledge
  Acquisition.\BBCQ\
\newblock In {\Bem Proceedings of the 23rd AAAI Conference on Artificial
  Intelligence (AAAI)}, \mbox{\BPGS\ 1219--1224}.

\bibitem[\protect\BCAY{Oh, Uchimoto, \BBA\ Torisawa}{Oh et~al.}{2009}]{oh09}
Oh, J.-H., Uchimoto, K., \BBA\ Torisawa, K. \BBOP 2009\BBCP.
\newblock \BBOQ Bilingual Co-Training for Monolingual Hyponymy-Relation
  Acquisition.\BBCQ\
\newblock In {\Bem Proceedings of ACL-09: IJCNLP}, \mbox{\BPGS\ 432--440}.

\bibitem[\protect\BCAY{Pantel \BBA\ Ravichandran}{Pantel \BBA\
  Ravichandran}{2004}]{pantel04}
Pantel, P.\BBACOMMA\ \BBA\ Ravichandran, D. \BBOP 2004\BBCP.
\newblock \BBOQ Automatically Labeling Semantic Classes.\BBCQ\
\newblock In {\Bem Proceedings of the Human Language Technology and North
  American Capter of the Association for Computational Linguistics Coference
  (HLT-NAACL)}, \mbox{\BPGS\ 321--328}.

\bibitem[\protect\BCAY{Pasca}{Pasca}{2007}]{pasca2007}
Pasca, M. \BBOP 2007\BBCP.
\newblock \BBOQ Organizing and Searching the World Wide Web of Facts---Step
  Two: Harnessing the Wisdom of the Crowds.\BBCQ\
\newblock In {\Bem Proceedings of the 16th World Wide Web Conference (WWW)},
  \mbox{\BPGS\ 101--110}.

\bibitem[\protect\BCAY{Pasca}{Pasca}{2009}]{pasca2009}
Pasca, M. \BBOP 2009\BBCP.
\newblock \BBOQ Outclassing Wikipedia in Open-Domain Information Extraction:
  Weakly-Supervised Acquisition of Attributes over Conceptual
  Hierarchies.\BBCQ\
\newblock In {\Bem Proceedings of the 12th Conference of Europian Chapter of
  the Association of Computational Linguistics (EACL)}, \mbox{\BPGS\ 639--647}.

\bibitem[\protect\BCAY{Ponzetto \BBA\ Strube}{Ponzetto \BBA\
  Strube}{2007}]{ponzetto07}
Ponzetto, S.~P.\BBACOMMA\ \BBA\ Strube, M. \BBOP 2007\BBCP.
\newblock \BBOQ Deriving a Large-Scale Taxonomy from Wikipedia.\BBCQ\
\newblock In {\Bem Proceeding of the 22nd Conference on the Advancement of
  Artificial Intelligence (AAAI)}, \mbox{\BPGS\ 1440--1445}.

\bibitem[\protect\BCAY{Shinzato \BBA\ Torisawa}{Shinzato \BBA\
  Torisawa}{2004}]{shinzato04}
Shinzato, K.\BBACOMMA\ \BBA\ Torisawa, K. \BBOP 2004\BBCP.
\newblock \BBOQ Extracting Hyponyms of Prespecified Hypernyms from Itemizations
  and Headings in Web Documents.\BBCQ\
\newblock In {\Bem Proceedings of the 20th Conference on Computational
  Linguistics (COLING)}, \mbox{\BPGS\ 938--944}.

\bibitem[\protect\BCAY{Snow, Jurafsky, \BBA\ Ng}{Snow et~al.}{2005}]{snow05}
Snow, R., Jurafsky, D., \BBA\ Ng, A.~Y. \BBOP 2005\BBCP.
\newblock \BBOQ Learning Syntactic Patterns for Automatic Hypernym
  Discovery.\BBCQ\
\newblock In {\Bem Proceedings of the Neural Information Processing Systems
  (NIPS)}.

\bibitem[\protect\BCAY{Suchanek, Kasneci, \BBA\ Weikum}{Suchanek
  et~al.}{2007}]{suchanek07}
Suchanek, F.~M., Kasneci, G., \BBA\ Weikum, G. \BBOP 2007\BBCP.
\newblock \BBOQ {Yago: A Core of Semantic Knowledge}.\BBCQ\
\newblock In {\Bem Proceedings of the 16th World Wide Web Conference (WWW)},
  \mbox{\BPGS\ {697--706}}.

\bibitem[\protect\BCAY{Torisawa}{Torisawa}{2001}]{torisawa01}
Torisawa, K. \BBOP 2001\BBCP.
\newblock \BBOQ An Unsuperveised Method for Canonicalization of {J}apanese
  Postpositions.\BBCQ\
\newblock In {\Bem Proceedings of the 6th Natural Language Processing Pacific
  Rim Symposium (NLPRS)}, \mbox{\BPGS\ 211--218}.

\bibitem[\protect\BCAY{Vapnik}{Vapnik}{1995}]{Vapnik:1995}
Vapnik, V.~N. \BBOP 1995\BBCP.
\newblock {\Bem The Nature of Statistical Learning Theory}.
\newblock Springer-Verlag New York, Inc., New York, USA.

\bibitem[\protect\BCAY{Yamada, Torisawa, Kazama, Kuroda, Murata, De~Saeger,
  Bond, \BBA\ Sumida}{Yamada et~al.}{2009}]{Yamada:EMNLP:2009}
Yamada, I., Torisawa, K., Kazama, J., Kuroda, K., Murata, M., De~Saeger, S.,
  Bond, F., \BBA\ Sumida, A. \BBOP 2009\BBCP.
\newblock \BBOQ Hypernym Discovery Based on Distributional Similarity and
  Hierarchical Structures.\BBCQ\
\newblock In {\Bem Proceedings of the 2009 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, \mbox{\BPGS\ 929--937}. Association for
  Computational Linguistics.

\bibitem[\protect\BCAY{隅田\JBA 吉永\JBA 鳥澤}{隅田 \Jetal
  }{2009}]{隅田:吉永:鳥澤:2009}
隅田飛鳥\JBA 吉永直樹\JBA 鳥澤健太郎 \BBOP 2009\BBCP.
\newblock Wikipediaの記事構造からの上位下位関係抽出.\
\newblock \Jem{自然言語処理}, {\Bbf 16}  (3), \mbox{\BPGS\ 3--24}.

\end{thebibliography}


\begin{biography}
\bioauthor{山田　一郎}{
1993年名古屋大学大学院修士課程修了．同年NHK入局．2008から2011年（独）情報通信研究機構出向．
現在NHK放送技術研究所主任研究員．博士（情報科学）
}
\bioauthor{橋本　　力}{
2005年京都大学情報学研究科産学官連携研究員を経て，2007年山形大学大学院理
工学研究科助教，2009年より独立行政法人情報通信研究機構専攻研究員．博士（言語科学，情報学）．
}
\bioauthor{呉　　鍾勲}{
2005年KAIST（韓国科学技術院）電子電算学科電算学専攻博士課程卒業．
同年KAIST研究員を経て，（独）情報通信研究機構に専攻研究員として着任．博
士（工学）．自然言語処理の研究に従事．
}
\bioauthor{鳥澤健太郎}{
1995年東京大学大学大学院博士課程中退．同年同大学院助手．北陸先端科学技術大学院大学助教授を経て，現在，（独）情報通信研究機構情報分析研究室室長．博士（理学）．日本学術振興会賞など受賞．
}
\bioauthor{黒田　　航}{
現京都大学・京都工芸繊維大学（非常勤講師），早稲田大学情報教育研究所（招聘研究員）．
元（独）情報通信研究機構知識創成コミュニケーション研究センター言語基盤グループ研究員．
京都大学から人間・環境学博士を取得．言語学の認知科学と自然言語処理と言語教育を
融合する研究に従事．
}
\bioauthor[:]{Stijn De Saeger}{
2006年北陸先端科学技術大学院大学知識科学研究科博士課程修了．博士（知識科
学）．北陸先端科学技術大学院大学研究員を経て，2007年に情報通信研究機構に
入所．2008年にNICT MASTARプロジェクト言語基盤グループに専攻研究員として
着任．自然言語処理を用いた知識獲得の研究に従事．
}
\bioauthor{土田　正明}{
2005年東京理科大学大学院修士課程修了．同年4月よりNECに入社．2009年4月
から2011年3月まで（独）情報通信研究機構に出向し，現在はNECに復帰．2008年
人工知能学会大会優秀賞を受賞．
}
\bioauthor{風間　淳一}{
2004年東京大学大学院情報理工学系研究科博士課程修了．博士（情報理工
学）．同年北陸先端科学技術大学院大学助手．2008年より情報通信研究機構．
現在，情報分析研究室主任研究員．
}


\end{biography}

\biodate

\end{document}
