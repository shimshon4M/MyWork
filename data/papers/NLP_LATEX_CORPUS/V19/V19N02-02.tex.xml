<?xml version="1.0" ?>
<root>
  <jtitle>トピック情報を用いたブートストラップ法に基づく語彙獲得</jtitle>
  <jauthor>貞光九月齋藤邦子今村賢治松尾義博菊井玄一郎</jauthor>
  <jabstract>本論文ではブートストラップ法を用いた語彙獲得を行う際に，トピック情報を用いることでセマンティックドリフトを緩和し，獲得精度を向上できることを示す．獲得対象とする語を含む文書の大域的情報であるトピック情報を，統計的トピックモデルを用いて推定し，識別モデルを用いたブートストラップ法における3つの過程で利用する．1つ目は識別モデルにおける素性として，2つ目は負例生成の選択基準として，3つ目は学習データの多義性解消のために用いる．実験において，提案手法を用いることでセマンティックドリフトを軽減し，語彙の獲得精度が6.7から28.7%向上したことを示す．</jabstract>
  <jkeywords>語彙獲得，ブートストラップ法，セマンティックドリフト，統計的トピックモデル，LDA</jkeywords>
  <section title="はじめに">自然言語処理技術を用いた多様なアプリケーションにおいて，対象ドメインに特化した辞書が必要となる場面は多く存在する．例えば情報検索タスクにおいて，検索クエリとドメイン辞書とを併用することで検索結果をドメイン毎に分類して提示することを可能としたり，特定のドメインに特化した音声認識システムにおいてはそのドメインに応じた認識辞書を用いた方が音声認識精度が高いことが知られている．一方で，特定のドメインに対する要求でなく，ドメイン非依存の場面においても，詳細なクラスに分類した上で体系的な辞書を用いる必要が生じる場合がある．例えば関根らの定義した拡張固有表現は，従来のIREX固有表現クラスが8クラスであったのに対し，200もの細分化されたクラスを持つ．橋本らによって作成された関根の拡張固有表現に基づくラベル付きコーパスにより，機械学習による拡張固有表現抽出器の研究がなされているが，コーパスにおいて付与された各クラスの出現数にはばらつきがあり，極端に学習データの少ないクラスも存在する．コーパスから単純な学習により固有表現抽出器を構築した場合，これら低頻度のクラスについて正しく学習できないことが予想されるため，各クラス毎の直接的な辞書の拡充が必要とされる．このようにドメインやクラスに依存した辞書の重要性は高いが，一方で辞書の作成には大きな人的コストがかかってしまうため，可能な限りコストをかけずにドメイン依存の語彙を獲得したいという要求がある．本論文で対象とする語彙獲得タスクは，ドメインやクラスに応じた少量の語彙集合，特に固有表現集合で表される教師データを用いて，新たな固有表現集合を獲得することを目的とする．なお，本論文では固有表現をエンティティ，初期に付与される教師データをシードエンティティと呼ぶこととする．語彙獲得タスクにおいては，教師データを繰り返し処理により増加させることのできる，ブートストラップ法を用いた手法が多く提案されており，本論文でも同様にブートストラップ法に基づいた手法を提案する．ブートストラップ法の適用により，初期に少量のシードエンティティしか存在しない場合であっても，手掛かりとなる情報，すなわち学習データを逐次的に増加させることが可能であるため，大規模なエンティティ獲得に繋がる．しかしブートストラップ法を用いたエンティティ獲得における課題として，獲得されるエンティティの持つ意味が，シードエンティティ集合の元来の意味から次第に外れていくセマンティックドリフトと呼ばれる現象があり，エンティティ獲得精度を悪化させる大きな要因となっている．本論文では，従来用いられてきた局所的文脈情報だけではなく，文書全体から推定されるトピック情報を併用することで，セマンティックドリフトの緩和とエンティティ獲得の精度向上を図る．本論文におけるトピックとは，ある文書において述べられている「政治」や「スポーツ」等のジャンルを指し，統計的トピックモデル（以下トピックモデル）を用いて自動的に推定する．本論文ではエンティティ獲得精度向上のために，トピック情報を3通りに用いた手法を提案する．第一に，識別器を用いたブートストラップ法における素性として利用する．第二に，識別器において必要となる学習用の負例を自動的に生成する尺度として利用する．第三に，教師データ中のエンティティの多義性を解消することで，適した教師データのみを利用する．以下2節で先行研究とその課題，3節でトピック情報を用いた詳細な提案手法，4節で実験結果について報告し，提案手法が少量のシードからのエンティティ獲得において効果があることを示す．</section>
  <section title="ブートストラップ法を用いた語彙獲得における課題"/>
  <subsection title="ブートストラップ法とセマンティックドリフト">本節では，ブートストラップ法によるエンティティ獲得の基本的な処理の流れと，その課題について述べる．はじめに，ブートストラップ法に基づくエンティティと属性の関係獲得法であるEspressoについて述べる．属性とは獲得対象とするエンティティ集合において，複数のエンティティが共通して関係する語（``has-a''や``is-a''等の関係）であるとする．例えばエンティティ「ヤクルト」と「巨人」の属性は，「監督」(has-a)や「球団」(is-a)等となる．関係獲得タスクは語彙獲得タスクを含んだタスクと捉えられるため，両者を比較することに意味はある．Espressoでは，初期に与えられるシードエンティティとシード属性の組から，それらを含んで出現する文脈パターンを手掛かりとして，新たなエンティティ--属性ペアに対し，自己相互情報量(PMI)に基づいて定義されたスコア関数に基づいてスコアを付与する．ここでの文脈パターンの例としては，「NTT」をエンティティ(X)，「株価」を属性(Y)とした場合，「X(NTT)/の/Y（株価）/が/反発」といったものがあげられる．Espressoはブートストラップ法の各繰り返しにおいて，スコア関数値を高くするようなエンティティ--属性ペアを新たな正例として獲得するフェーズと，文脈パターンの獲得フェーズを交互に行い，必要なエンティティ--属性ペア数が得られるまで繰り返す．ブートストラップ法を用いることで少量のシードエンティティのみが与えられた場合でも，教師データを増加させつつ新たなエンティティを獲得していくことが可能なため，本稿でもEspressoと同様，ブートストラップ法に基づいた語彙獲得を行っていく．ブートストラップ法によって少量のシードエンティティから新たなエンティティ集合を獲得する際の主な課題として，獲得する対象が本来獲得すべき種類とは異なる対象へと次第に変わっていってしまうという現象があげられる．例えば獲得対象が企業名である場合に，「NTT」と「トヨタ」をシードエンティティとして与え，Espresso等のエンティティ獲得アルゴリズムにより「ヤクルト」が獲得できたとする．しかし「ヤクルト」には企業名以外にも，プロ野球球団名や飲料品名といった多義性が存在するため，次の繰り返しにおいて獲得されるエンティティが「巨人」等の本来獲得対象としていたエンティティではないものに遷移していく場合がある．この現象はセマンティックドリフトと呼ばれ，ブートストラップ法に基づく語彙獲得における精度低下の大きな要因となっている．</subsection>
  <subsection title="識別モデルに基づくブートストラップ法と課題">先行研究では，新たなエンティティを選択する際のスコア関数を独自に定義することでセマンティックドリフトを抑え，エンティティを精度良く獲得する手法が提案されている．これらのスコア関数は，基本的にはEspressoと同様にシードエンティティの特徴になるべく近い特徴を持つエンティティに対し，高いスコアを与えるように設計されている．スコア関数についての研究とは異なる観点で提案されたのがBellareらの識別モデルに基づくブートストラップ法である．彼らの方法では識別モデルからのスコアによってスコア関数を構築するため，柔軟な素性設計が可能となる．例えば，「X(NTT)/の/Y（株価）/が/上昇」という文脈を考えた時，素性関数fによってf(surf.=``の'',position=X+1)=1,f(surf.=``上昇'',position=Y+2)=1といった素性が構築される．BellareらはEspressoと同様に関係獲得タスクに識別モデルに基づくブートストラップ法を適用しているが，文脈パターンに相当する素性の重みは，識別学習によって自動的に付与される．そのためEspressoにおける文脈パターン獲得フェーズは不要となり，代わりにエンティティ獲得フェーズと属性獲得フェーズとに分けた手法が提案されている．我々はBellareらの手法に若干の変更を加えたものをベースラインとして用いることとした．このベースラインについては節で詳しく述べる．Bellareらの手法及び我々のベースラインシステムには3つの課題が残存する．1つ目の課題は，大域的な情報が識別モデルに反映されていないという点である．識別モデルの導入により素性の柔軟な設計が可能になった一方，彼らは局所的な文脈中の単語の表層と品詞のみを素性として用いるのみで，識別モデルの利点を積極的には用いていない．局所的文脈に基づく素性のみでは，エンティティの曖昧性を解消できない場合がしばしばある．例えばエンティティ「ヤクルト」は企業名としても球団名としても存在する．「ヤクルト」に対して「捕手」のような属性を付与することによって，ある程度曖昧性を解消することは可能であるが，属性を付与した場合でもなお曖昧性が残る場合もある．ここで属性として「広報」が与えられ，文書が次のように与えられている場合を考える．「18日の夜，ヤクルトの広報担当者が取材に対してコメントを発表した．18日の試合で途中退場したY選手は，診断の結果軽いねんざと診断された，とコメントは伝えている．」一文目だけを見た場合，このヤクルトは企業名を指すか球団名を指すかは明らかではない．文書全体を読むことで，このエンティティが「球団名」を指していることが明らかになるが，局所的な文脈パターンのみを用いた場合，文書全体からの大域的情報を利用することはできない．我々は文書全体を通して存在するトピックを，エンティティ識別の際の素性として用いる方法を節において述べる．2つ目の課題は，識別学習における負例の問題である．識別学習では正例と負例が必要になることが一般的である．Bellareらは現在の正例以外全てを負例として扱っているが，この場合も偽負例が混じる可能性が排除できない上，正例と負例の量が大きく乖離するというデータ非平衡の問題もある．一方，Mintzらは複数のクラスに属する正例群を与えた後，別のクラスに属するエンティティと属性を擬似的な負例ペアとすることで負例を生成している.しかし，1つのクラスのみを獲得対象とする場合，このような負のクラスを加えることには人的コストがかかる上，属性を組み合わせたとしても，エンティティ「ヤクルト」に対する多義属性「広報」が存在するように，属性の多義性によって偽負例が生成されてしまう可能性がある．3つ目の課題はシードエンティティの質及び獲得された正例エンティティの多義性についての問題である．少量のシードエンティティのみを手がかりとして行う語彙獲得タスクでは，シードエンティティによる精度への影響は大きい．Pantelらは大規模なWEBに対して，比較的単純なスコアリング関数を用いて効率的なエンティティ獲得手法を提案しており，10個程度のシードエンティティにより十分な精度でエンティティ集合が得られると報告している．一方でVyasらはシードエンティティの選択によりエンティティ獲得の結果に影響が出ることを示している．特に多義性のあるシードエンティティが混入した場合にセマンティックドリフトが生じやすく，精度の劣化は大きいと考えられるため，Vyasらは精度を落とす可能性の高いシードを除去するアルゴリズムを提案している．この問題はシードエンティティに限らず，獲得された後に教師データとして用いられるエンティティについても同様が生じてしまう．我々はこれら3つの課題に対し，トピック情報を用いて解決する手法を以下で提案する．</subsection>
  <section title="トピック情報を用いたブートストラップ法"/>
  <subsection title="ベースライン手法">本節ではBellareらの手法を基としたベースライン手法について述べる．なお，本節ベースライン手法は図の実線矢印で，次節以降で述べる提案手法は破線矢印で表している．本ベースライン手法がBellareらの手法と異なる点は，獲得対象がエンティティに限られるという点である．そのため，本ベースライン手法ではエンティティ獲得と属性獲得との交互獲得は行わず，初期に正例属性集合として与えた後の属性集合は不変であるとする．新規属性獲得を行うことも可能ではあるが，獲得された属性集合に偽正例が混じることによってセマンティックドリフトが生じるリスクを排除するために，エンティティのみの獲得を行うこととした．ベースライン法においては，はじめに人手によってN_e個の正例シードエンティティ集合E_Pが与えられた後，シードエンティティとのPMIの大きい順に各名詞のランキングを行う．ランキングされた名詞のうちスコアの高い方からN_a個の正例属性集合(A_p)を選択する．N_e及びN_aは事前に調整するパラメータであり，本論文ではいずれも10とした．エンティティ--属性ペアとしてのシードは，シードエンティティ集合E_Pと正例属性集合A_Pとを組み合わせることで得た．次にこのエンティティ--属性ペアを，正例教師データ用の文書集合を獲得する際の検索クエリとして用いる．検索の結果得られる，あるエンティティ--属性ペアe,aを含む正例文書集合をD_e,aと表す．1つ1つの文書を個別に教師データとして用いるのではなく，同じエンティティ--属性ペアを含む文書をまとめることにより，過適応の緩和が期待できる．正例文書集合D_e,aを元にe,aの周辺文脈についての素性化を行う一方，学習用の負例についても文書集合全体からランダムに選択した後に素性化を行い，これらを元に識別モデルを学習する．次に識別モデルの適用方法について述べる．新規正例エンティティとなりうる候補エンティティは，正例属性aA_Pの近傍に出現する固有表現e'のみに限定する．訓練データの場合と同様，過適応緩和のため，識別対象e',aは文書集合D_e',aとしてまとめられ，素性化処理を行った後に識別モデルが適用される．識別モデル適用の結果出力されるスコアをs(e,a)とし，正例属性集合A_pについてs(e,a)の和をとったスコア_aA_Ps(e,a)の値の高い方から順に，任意の種類数の新規正例エンティティを獲得する．</subsection>
  <subsection title="トピック素性とトピックモデル">節で1つ目の課題として述べたように，識別モデルにおける素性としてこれまでは局所的文脈に基づく素性が用いられてきた．我々は文脈情報に加え，トピック情報を併用することでエンティティの持つ曖昧性を解消し，セマンティックドリフトの影響を緩和する．文書の背景にあるトピックを利用する場合，文書に対して明示的にトピックラベルが付与されているデータであれば，そのラベルを直接トピック情報として用いることができるが，全ての文書にトピックラベルを人手で付与するにはコストがかかる．本稿ではラベル無しの文書集合しか存在しない場合でもトピック情報の取得を可能にするため，文書のトピックと単語との関係をモデル化するトピックモデルを用いる．トピックモデルは，文書のトピックと関連の強い単語に高い確率を付与することで，文書をより緻密に表現できるモデルであり，情報検索等多様なアプリケーションにおいて利用されている．例えばある文書のトピックがスポーツであるならば，「サッカー」といったスポーツに関する単語が出現しやすく，「国会」といった単語が出現しにくい，といった大域的情報を扱うことができる．本稿ではトピックモデルとして，各文書におけるトピック間の共起関係をディリクレ分布によって表現するLatentDirichletAllocation(LDA)を用いることとする．LDAをはじめとするトピックモデルを用いることで，具体的には文書dにおけるトピックzの事後確率p(z|d)を計算することが可能となる．LDAを用いた場合，事後確率を解析的に求めることは困難であるが，変分ベイズ法を用いて近似的に事後確率を求めたり，マルコフ連鎖モンテカルロ法を用いて近似的に事後確率を推定することが可能である．例えば，節の「ヤクルト」の例に関して，トピックモデルはトピックz=``野球''に対して高い事後確率を付与することが期待される．この事後確率は文書dのトピックzらしさを表現していることに他ならないので，識別における大域的素性として直接的に活用できる．我々の手法において，エンティティ--属性ペアe,aに対するトピック素性_t(z,e,a)は，LDAの事後確率に基づいて以下のように計算される．[_t(z,e,a)=_dD_e,ap(z|d)_z^_dD_e,ap(z^|d).]</subsection>
  <subsection title="トピック情報に基づく負例生成">正例のみが存在する状況下で識別モデルを利用する際に問題となるのは，学習用の負例をいかに生成するかという点であり，節において2つ目の課題としていた．例えば初期の正例以外全てを負例として扱う場合や，ランダムに負例を選択する場合，実際には正例である事例を，誤って負例として扱ってしまう偽負例を生じてしまい，識別結果に対しても悪影響を及ぼす可能性がある．我々の目的は偽負例の生成を抑制するというだけでなく，正例と負例の量を平衡に保ちつつ，セマンティックドリフトを緩和するために幅広いジャンルから負例としてふさわしいものを獲得することである．本節ではトピックモデルを用いることでこのような要求を満たす負例を自動的に獲得する手法について述べる．負例生成問題は，正例とラベルなしデータのみが存在する場合における主要な問題と捉えられている．しかし先行研究における手法はある程度大きな規模の正例データを想定しており，我々が用いる非常に少量の正例データについては有効に機能しないと考えられる．そこで，前節で用いたトピックモデルの尺度において，正例からできるだけ遠い事例を負例として選択する手法を提案する．トピックの分布は単語の分布と比べ比較的密であり，少量の正例データからでも正のトピックが推定可能である．各異なり単語を独立次元とするベクトル表現では，例えば「プリウス」と「キャディラック」では全く異なる次元に存在するが，トピックを独立次元とするベクトル表現で捉えると，これらの単語を含む文書は同じトピック次元上に存在する可能性が高く，逆に言えば，負例はそれ以外のトピック次元中に存在しやすい．トピックに基づくこの尺度をトピックzに対する``正のトピックスコア''PT(z)と呼び，本スコアを元に負例にふさわしい文書を選択していく．正のトピックスコアPT(z)を，以下のように正例文書集合D_e,a中の各文書が与えられた時の事後確率の和として定義する．PT(z)の低い方から50%のトピックを負のトピックとし，負のトピック各々において同数ずつ，総数が正例文書数と等しくなるように文書を選択した．この際の文書の選択基準としては，負のトピックに対する事後確率が高く，かつエンティティ候補となり得る固有表現と属性に相当する名詞が，任意のウインドウサイズ内に現れる文書であるとした．本実験に用いたウインドウサイズは3単語である．</subsection>
  <subsection title="トピック情報による正例の多義性解消">本節では節で挙げた3つ目の課題，正例の教師データに多義性が含まれ得るという課題を解決する手法を提案する．正例の中には多義性を持つものも存在するため，その正例が出現する全ての文書を正例の抽出対象として用いることはセマンティックドリフトを引き起こす要因となる（例えば節の「ヤクルト」の例があげられる）．従来研究ではこのようなセマンティックドリフトを引き起こす要因となるシードエンティティを除外する手法が提案されている．これに対し，我々はトピックを用いることにより，エンティティを無条件に除外するのではなく，ドメインに合ったトピックでは活かし，ドメインから外れたトピックでは除外するといったような，細かな処理を可能とする手法を提案する．「ヤクルト，広報」というエンティティ--属性の二つ組に加え，「ヤクルト，広報，z=``野球''」のような三つ組の形とすることで，より確実性の高い正例集合を作ることができる．具体的には，前節で述べた正のトピックスコアPT(z)をここでも利用する．まず，任意の閾値thにおいて，PT(z)&gt;thを満たすトピックzを正のトピックとする．もしも条件を満たすzが1つもない場合は，最もPT(z)の高いzを正のトピックとする．そして正例文書集合の中から，正のトピックに含まれる全てのトピックz^に対し，p(z^|d)thとなるような文書dを正例文書集合から除外する．なお，シードエンティティが与えられているか否かに関わらず，文書単位のトピック事後確率は事前に全て計算しておくことが可能であるため，本手法の適用は比較的高速に行うことが可能である．本節で述べた手法は，節のトピック素性をハード制約として用いた場合と捉えることができる．</subsection>
  <section title="実験"/>
  <subsection title="実験条件">本節では提案手法の有効性を示すために，少量のシードエンティティからの新規エンティティ獲得精度を比較し，その結果についての考察を行う．実験には2008年5月の日本語ブログ約3000万記事を用いた．単語及び固有表現を処理単位として素性に変換しており（以後簡単のため固有表現を含めて単語と呼ぶ），形態素解析にはJTAGを，IREX定義に基づく固有表現抽出器には最小誤り分類基準に基づくCRFを用いた．素性を獲得する素性テンプレートとしては``(head)entity(mid.)attribute(tail)''を用いた．head,mid.tailに位置する各単語は表層，品詞，固有表現ラベルに対し，その位置情報を付加した上で素性に変換する．文脈のウインドウサイズ(|head|,|mid|,|tail|)はそれぞれ最大で2単語とし，素性は正例，負例を通じて最低5回以上出現しているものを用いた．本節では「車名」「番組名」「スポーツ組織名」の3つのドメインを対象に実験を行う．一回の繰り返しで獲得するエンティティ種類数は100種類とし，合計10回の繰り返しを経て，最終的に1000種類の新規エンティティを獲得する．シードとしたエンティティと属性を表に示す．正例属性はシードエンティティとのPMIの高いものから順に10個を選択したが，番組名においては，属性として明らかにふさわしくないと判断したものを主観的に除去した（「この間」と「さっき」）．識別器にはSVM^lightの2次多項式カーネルを用いた．トピックモデルの学習と適応にはMessagePassingInterface(MPI)でLDAを利用できるParallelLDAを用い，トピック数100のLDAを学習，適応した．トピックモデルの学習コーパスは，本実験で用いる2008年5月のブログコーパス31日分のうち，14日分の記事約1400万記事を用いた．予備実験の検討より，学習におけるマルコフ連鎖モンテカルロ法のサンプリング回数は200回とし，うち50回を初期値への依存を弱めるためのburn-inとして用いた．実験条件として以下の4条件に基づいて実験を行った．1.ベースライン：節で述べたものに相当する2.ベースラインにトピック素性を追加した手法3.2.に対し負例生成法を追加した手法4.3.に対し正例の多義性解消法を追加した手法（図の全破線矢印部に一致）システムが獲得した1000個のエンティティについて，2人の評価者が商用検索エンジンを用いて検索し，エンティティと各ドメイン名のAND検索の検索結果上位40件中に，シードエンティティと同じ使い方をされているものが存在するか否かという観点で，正解または不正解のラベルを付与した．また獲得された単語のうち，固有表現抽出器が誤って獲得した固有表現以外の単語（例えば「番組名」における「月9」等）については不正解とした．評価者間の値は0.895であった．2人の評価者間で評価が異なった場合，第3の評価者が評価を行い，その評価を正しい評価として用いた．</subsection>
  <subsection title="実験結果と考察">表に各ドメイン毎の実験結果を示す．表中の値は精度と有意差を表している．トピック素性を用いた手法2.においては，車名とスポーツ組織名のドメインにおいて改善を示している．また負例生成法は車名と番組名のドメインにおいて改善を示している．これは，負例生成法が偽負例を選択するリスクを低減させたことが要因の1つと考えられる．同様に正例の多義性解消法においても車名と番組名において精度の改善を示している．スポーツ組織名のドメインにおいてはトピック素性を追加した場合に明らかな改善が見られたものの，ある程度の改善がなされてしまったために，他の2つの手法による改善は見られなかった．車名における精度が他のドメインより低いのは，「バイク名」のような比較的近い意味のエンティティが獲得されたことに起因する．これら似たドメインというのは，文脈的特徴が似ているだけでなく，トピックによる特徴も近くなったためと考える．提案手法が有効に機能した結果，ベースラインにおいて生じていたセマンティックドリフトが軽減されたということを示すため，ターゲットドメインに近いトピックと遠いトピックに属する単語を表に挙げる．表は以下に定義される正のトピックz_hと負のトピックz_l,z_eに属する特徴的な単語を示している．z_h（2行目）PT(z)が最大となるトピックであり，正のトピックとして用いられる．z_e（4行目）ベースラインにおいて観察されるエンティティのセマンティックドリフトを抑えるのに効果があったトピック．PT(z)の大きい順にソートした際に下位半分に現れる負のトピックの1つから選択したトピック．z_l（5行目）PT(z)を最小とするトピックであり，負のトピックとして用いられる．各トピックにおける特徴単語として，スコアp(v|z)/p(v)が最も高くなる3単語を選択した．ここでp(v|z)はLDAにおけるモデルパラメータ，p(v)は単語vのユニグラム確率であり，コーパス全体からの単純な最尤推定で求められる．正例の多義性解消法が有効に機能するためには，正のトピックz_hが対象ドメインに近い必要がある．反対に負例生成法が有効に機能するためには，下位半分のトピックに含まれるトピックz_l,z_eが対象ドメインから遠い必要がある．表を見ると，このいずれもを満たしていることが確認できる．例えば表中「車名」において，最も近いトピックには「車検」という単語等を含み，最も遠いトピックには「内科」という単語を含んでいるため，対象ドメインに対しそれぞれ近い単語，遠い単語が選ばれていると言える．さらに効果的な負のトピックとして，電子機器のトピックが選ばれているために，ベースラインにおいて獲得された「iPod」等の単語が提案手法では獲得されなかった．この傾向は「車名」以外のドメインにおいても確認でき，提案手法の語彙獲得精度の向上に繋がった要因であると考えられる．</subsection>
  <section title="関連研究">先行研究においては，文書/文レベルの全ての単語を素性とした分布類似度を用いたアプローチ(distributionalapproach)が提案されている．これらの手法は大域的情報を用いた手法とみなすことができるが，単語の素性空間は非常に多次元かつ疎な空間であり，データ量が増えた場合においてもこの問題を完全に解消することはできない．我々の手法はトピック情報という中間的な単位に落とし込むことでこれらの問題を解消する．我々が用いたトピックモデルは一種の確率的クラスタリングモデルであるので，エンティティ獲得にクラスタリング情報を用いた先行研究としてPascaらの研究を挙げて比較する．Pascaらはエンティティの獲得だけでなく，周辺文脈をクラスタリングし，その中からクラスを代表するにふさわしい単語を選択してクラス名として定義する．さらに検索クエリログを用いて，当該クラス内のエンティティと共に用いられるクエリを当該クラスの属性であるとする，「クラス，エンティティ，属性」の3つ組を取得する手法を提案している．Pascaらの手法ではクラスタリングを用いているものの，クラスタリング対象範囲は周辺の文脈にとどまる．これに対し我々の手法は文書全体からトピックを推定する点で，より広域な情報を取り入れることができる．また提案手法は語彙獲得の目的に特化させるため，Pascaらで用いられていたクラス名を，エンティティの候補が対象クラスに属するか否かを判定するための属性の1つ（``is-a''の属性）として扱う．属性をクラス名のみに絞った方が適合率は高くなると考えられるが，局所的な文脈中にはクラス名が存在しない場合も多い．例えば書籍の場合，書籍タイトルの前後に「本」や「書籍」といったクラスを表わす単語が共起することは少ない．このため，他の属性と併用することで，より高精度かつ網羅的なエンティティ獲得が可能となる．トピックモデルを用いた関連研究として，selectionalpreferencesをモデル化するために，LDAを拡張した生成モデルを利用したRitterらの研究が挙げられる．Ritterらの手法は我々の手法に最も近いものと言えるが，生成モデルであるか識別モデルであるかの違いがあり，局所的文脈素性と柔軟に統合できるという点で我々のモデルには優位性がある．節で述べた負例生成は，正例とラベルなしデータのみが存在する場合においての主要な問題と捉えられている．しかし先行研究における手法はある程度の規模の正例データを想定しており，非常に少量な正例データについては有効に機能しないと考えられる．これに対し，本稿では少量の正例データからでも適切に負例を生成可能な手法を提案した．一方McIntoshは，複数クラスの語彙獲得タスクにおいて獲得されたエンティティが，シードエンティティよりもそれ以降のイテレーションに得られたエンティティ集合に近い場合に負例であると自動的に判定し，さらに負例のクラスタリングと拡張を行うことで，適切な負例集合を得る手法を提案している．またKisoらは単語の共起関係をグラフ上で表現し，HITSスコアの高い単語が正例に該当しない場合はそれらをストップリストとして用いることで，セマンティックドリフトを抑える手法を提案している．McIntoshやKisoらの手法が，セマンティックドリフトを生じやすい単語を直接的に負例として捉えることを主眼としているのに対し，我々はセマンティックドリフトが生じる先のトピックに制約を設ける目的で負例を捉えるという点で異なる．特にMcIntoshの手法では，セマンティックドリフトを抑える効果の高い負例を抽出できる可能性が高い反面，本来の正例が負例になってしまう偽負例を生じる可能性がある．本稿ではセマンティックドリフトを生じやすい単語，言いかえると正例・負例両方の多義性が存在する単語の場合，節のトピック情報による多義性解消を併用することで，負例として当該単語が用いられている事例では，正例としても負例としても用いないという判断を行っている．一方正例として当該単語が用いられている事例では，正例学習データとして用いることで，学習データを可能な限り増やしていくというブートストラップ法の観点に見合った手法となっている．本稿ではリソースとして文書集合を用いたが，一方でクエリログを用いたエンティティ獲得の研究も進められている．小町らはクエリログ中に共起する単語をエンティティ及び属性とみなし，ブートストラップ法に基づくエンティティ獲得法の提案を行っている．クエリログを使った他の手法としては，他にもSekineらの研究やPascaらの研究が挙げられる．しかし，クエリログ単独ではトピックのような大域的な文脈を考慮することができず，また，非公開で一般的に入手が困難なリソースであるという現実的な側面もある．我々はこれらの観点から文書をリソースとして用いることとした．</section>
  <section title="まとめと今後の課題">本稿ではトピック情報を用いた3通りの手法により，エンティティ獲得精度を改善できることを示した．従来の識別モデルを用いたブートストラップ法の課題であった，大域的情報を取り込んだ素性の設計，教師データにおける負例の生成，正例教師データにおける多義性を持ったエンティティの存在といった諸問題を，トピックモデルから得られるトピック情報を用いることで解消した．今後のさらなる獲得精度向上のためには，トピックモデルの粒度を目的のドメインに合わせていくことが必要である．このためにはトピックモデルに対する能動学習が有効であると考える．また関連研究の1つとして挙げた分布類似度を用いたアプローチとの比較や統合についても検証する必要もある．別の観点としては，ブートストラップ法のグラフ理論的な拡張があげられる．小町らはエンティティ獲得のアルゴリズムをグラフ理論に基づいて解釈し，グラフカーネルの一種であるラプラシアンカーネルを導入することで性能を改善している．トピックモデルを扱えるグラフ理論に基づく枠組みとしては，Cohnら提案したPHITSがあり，彼らの考えを導入することができれば，より高い精度のエンティティ獲得法を構築できると考える．</section>
</root>
