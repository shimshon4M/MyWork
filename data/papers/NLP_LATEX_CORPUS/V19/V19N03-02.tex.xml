<?xml version="1.0" ?>
<root>
  <jtitle>語義曖昧性解消のための領域適応手法の	決定木学習による自動選択</jtitle>
  <jauthor>古宮嘉那子奥村学</jauthor>
  <jabstract>ソースドメインのデータによって分類器を学習し，ターゲットドメインに適応することを領域適応といい，近年さまざまな手法が研究されている．しかし，語義曖昧性解消(WSD:WordSenseDisambiguation)について領域適応を行った場合，最も効果的な領域適応手法は，ソースデータとターゲットデータの性質により異なる．本稿ではそれらの性質から，WSDの対象単語タイプ，ソースドメインとターゲットドメインの組み合わせに対して，最も効果的な領域適応手法を決定木学習を用いて自動的に選択する手法について述べるとともに，どのような性質が効果的な領域適応手法の決定に影響を与えたかについて考察する．</jabstract>
  <jkeywords>語義曖昧性解消，領域適応，手法選択，決定木学習</jkeywords>
  <section title="はじめに">自然言語処理で使われる帰納学習では，新聞データを用いて新聞用の分類器を学習するなど，ドメインAのデータを用いてドメインA用の分類器を学習することが一般的である．しかし一方，ドメインBについての分類器を学習したいのに，ドメインAのデータにしかラベルがついていないことがあり得る．このとき，ドメインA（ソースドメイン）のデータによって分類器を学習し，ドメインB（ターゲットドメイン）のデータに適応することを考える．これが領域適応であり，様々な手法が研究されている．しかし，語義曖昧性解消(WordSenseDisambiguation，WSD)について領域適応を行った場合，最も効果的な領域適応手法は，ソースドメインのデータ（ソースデータ）とターゲットドメインのデータ（ターゲットデータ）の性質により異なる．SVM等の分類器を利用してWSDを行う際にモデルを作る単位である，WSDの対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組を1ケースとして数えるとする．本稿では，このケースごとに，データの性質から，最も効果的な領域適応手法を，決定木学習を用いて自動的に選択する手法について述べるとともに，どのような性質が効果的な領域適応手法の決定に影響を与えたかについて考察する．本稿の構成は以下のようになっている．まず節で領域適応の関連研究について紹介する．節では領域適応手法をどのように自動選択するかについて述べる．節では本研究で用いたデータについて説明する．節では決定木学習におけるラベル付きデータの作成方法と学習方法について述べ，節に結果を，節に考察を，節にまとめを述べる</section>
  <section title="関連研究">領域適応は，学習に使用する情報により，supervised，semi-supervised，unsupervisedの三種に分けられる．まずsupervisedの領域適応は，訓練事例として少量のターゲットドメインだけでなく大量のソースドメインのデータを加えて学習を行うもので，訓練事例としてソースデータまたは少量のターゲットデータだけを利用する場合よりも，分類器を改良することを目指す．次のsemi-supervisedの領域適応は，ラベルつきのソースデータに加え，ラベルなしのターゲットデータを利用し，訓練事例としてソースデータだけを利用する場合よりも，分類器を改良することを目指す．また，最後のunsupervisedの領域適応は，ラベルつきのソースデータで学習後，ターゲットデータで実行する．本研究で扱うのは，supervisedの領域適応である．領域適応の研究は様々な分野で研究が行われており，ここではその一部を紹介する．まず，は，EMアルゴリズムによる語義の事前確率推定によりWSDの領域適応を行っている．も，EMアルゴリズムによる事前確率推定を行っているが，これは能動学習により事例をターゲットドメインから加えるsupervisedの領域適応である．Count-mergingにより重要文に重みをつけることで，性能を向上させている．また，はシーケンスラベリングを例にsupervisedの領域適応を行っている．素性空間の次元を「ソースデータの素性空間」「ターゲットデータの素性空間」「ソースデータとターゲットデータ共通の素性空間」に相当する三倍にし，モデルを三倍に拡張して実験を行うというもので，様々なsupervisedの領域適応に併用できる手法である．利点として，上記の併用可能性に加え，実装が簡単で処理が速いこと，マルチドメインに拡張が簡単（素性空間の次元をドメイン数+1倍にすればよい）であることが挙げられる．さらに，はをsemi-supervisedのために拡張した．この手法がなぜ有効なのかはまだ解き明かされていないが，拡張前の利点を引き継いでいるだけでなく，ラベルなしのターゲットデータを利用することでよりよい性能が得られる．は，semi-supervisedのWSDの領域適応を行った．大量のラベルなしのソースデータに，ラベルなしのターゲットデータを加えて行列を作り，特異値分解(SVD)により素性圧縮をして分類器を学習する手法である．または，大量のラベルなしのソースデータの代わりに，少量のラベルつきのソースデータを使用して，同様の手法でsupervisedの領域適応を行っている．は領域適応を行う際，事例の重み付けにより性能が向上することを示した．この手法は様々なsupervisedまたはsemi-supervisedの領域適応との併用が可能である．また，領域適応に悪影響を及ぼすソースデータを特定して削除することも試みているが，ソースデータの削除は事例の重み付けを行わなければ有効であるが，事例の重み付けを行った場合には有効ではないと結論づけている．はターゲットデータとソースデータの周辺確率を似せるようにカーネル空間を学習した後，条件確率がターゲットデータに似ているソースデータの事例をクラスタリングベースの事例選択を用いて選び，その事例を利用して領域適応を行っている．はWeb上からランダムに取得したラベルなしデータを利用して，より高いレベルの素性を作成するためにスパースコーディングを利用したself-taughtlearningを提案している．これはunsupervisedの領域適応の一種である．はco-trainingにおいて領域適応を行ったco-adaptationの研究である．boostingによる線形補完により領域適応を行い，両方の分類器においてエラー率が低下したことを報告している．またはsemi-supervisedの領域適応である．この研究では，ソースデータ中とターゲットデータ中の単語の類似度を計算するために，pivotfeature（ソースデータとターゲットデータの両方でよく出てくる単語）の周りの単語の重みを計算する．この重みの行列にSVDを適用して新しい素性空間を作り，オリジナルの素性に新しい素性を加えて使用するという手法をとっている．本稿に最も近い研究は，である．この研究では，多様なドメインからなる文書を構文解析する際，最も良いモデルは異なるという問題に注目している．彼らは様々な混合モデルによる構文解析の正解率を回帰分析で予測し，それぞれのターゲットデータに対して，最も高い正解率を出すと予測されたモデルを利用して構文解析を行っている．本研究との最も大きな違いは，対象のタスクが構文解析ではなく語彙曖昧性解消である点である．そのため，本論文ではケースという単位ごとに最適な領域適応を行う．また，彼らは複数のソースドメインから抽出した用例を混合して訓練事例とした領域適応を想定しているが，我々は想定していない．本研究では決定木学習を用いることで，どのような性質が最適な領域適応の決定に影響を与えるのかについて考察する．本稿では，ソースデータとターゲットデータの性質をもとに領域適応に用いる手法を自動選択する手法について述べる．これに関連した研究としてやがある．は，構文解析において，分野間距離をはかり，より適切なコーパスを利用して領域適応を行えるようにした．また，は，構文解析において，自動的にタグ付けされたコーパスを用いて，ソースデータとターゲットデータの類似度から性能を予測できることを示した．これらの研究では，領域間の距離からソースデータとして利用できるコーパスを選択するという立場をとっているが，本研究では領域間の距離などの性質から，手法を選択するという立場をとる</section>
  <section title="領域適応手法の自動選択"/>
  <subsection title="ケースごとの領域適応手法の自動選択">本論文では，ケースという単位を定義し，ケースごとに適切な領域適応を行う．本論文におけるケースとは，SVM等の分類器を利用してWSDを行う際にモデルを作る単位である．WSDの分類器は，対象単語タイプ，ソースドメイン，ターゲットドメインの三つ組に対してひとつ作られるので，この三つ組をケースと呼ぶ．例えば，ケースを（対象単語タイプ，ソースドメイン，ターゲットドメイン）の順に書くと，（出る，新聞，Yahoo!知恵袋），（出る，Yahoo!知恵袋，新聞），（手，Yahoo!知恵袋，新聞）は全て別のケースである．最適な領域適応手法は，ソースデータとターゲットデータの性質により異なるが，WSDにおけるソースデータとターゲットデータの訓練事例集合は，ソースやターゲットになるコーパスのドメインだけでなく，WSDの対象単語も含めたケースごとに定まる．したがって，ケースごとに適切な領域適応手法を自動的に選択し，その手法を適宜用いて領域適応を行えば，どれかひとつの手法を用いるよりも，WSDの性能が向上することが予想される．このため，決定木学習を用いて，ケースごとに領域適応手法の自動選択を行う．決定木学習の素性にはソースデータとターゲットデータの性質を利用し，ラベル（教師値）には，WSDの正解率を比較した際に，そのケースにおいて最も正解率が高かった領域適応手法を用いる．決定木学習を用いるのは，どのような性質が最適な領域適応手法の決定に影響を与えるのかを明示的に示すことができる上，少量の訓練事例から学習しても十分な分類精度が得られるからである．また，n個の領域適応手法から選択する際には，pairwise方式で_nC_2通りの二分決定木をつくり，最終的にそれらを統合することで，ひとつのケースにつきひとつの領域適応手法を決定する．なお，本論文で扱う領域適応手法は，どれもsupervisedの領域適応であるため，最終的にどの領域適応手法が選択されるかは不明な段階でも，先にターゲットデータに対する少量の語義のタグ付けが必要である．本論文では，一般公開されているYahoo!知恵袋，白書，新聞の三つのタグ付きコーパスから，144ケースのラベル付きデータを作成して決定木学習を行った．これらのラベル付きデータの素性ベクトルには，ソースデータとターゲットデータのJS距離などを用いており，それぞれのケースの対象単語タイプ，ソースドメイン，ターゲットドメインが何なのかという情報は与えていない．WSDの領域適応の問題が生じた場合には，問題のケースごとに，本論文で叙述するように素性ベクトルを作成して決定木への入力とし，決定木によって最適な領域適応手法を選択する．本論文では決定木学習の有効性を144ケースの交差検定によって示す</subsection>
  <subsection title="WSDのための領域適応手法">WSDのための領域適応手法として，本研究では以下に示す三つを用いる．したがって，pairwise方式で三つ（TOとRS，TOとFD，RSとFD）の二分決定木をつくり，最終的にそれらを統合することで，ひとつのケースにつきひとつの領域適応手法を決定する．以降，決定木の用例の単位であるケースと区別するために，WSDの用例の単位をトークンと呼ぶ．WSDの対象単語をwとすると，トークンはwの用例と等しい．それぞれソースドメインとターゲットドメインのコーパス中のwの用例が，ソースデータとターゲットデータの訓練事例であるため，ケースごとにソースデータとターゲットデータの数や性質は異なる．TO:TargetOnly．ソースデータを用いず，ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものだけを訓練事例にする．RS:RandomSampling．ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．FD:フィルタリングによる削除．ランダムに選んだ少量のターゲットデータのトークンに語義をタグ付けしたものとソースデータの両方を訓練事例にする．このときソースデータは，フィルタリングによりターゲットデータにある一定の閾値以上似ているデータのみを用いる．FDでは以下の手順を取る．なお，ターゲットデータやソースデータのトークンは，後述するWSDの素性を要素としたベクトルとして表されている．ターゲットデータのトークンt_iTについて，全ソースデータのトークンs_jSとのコサイン類似度sim_i,jを計算する．ソースデータのトークンs_jSについて，それぞれ最も自身と近いターゲットデータのトークンt_j,nearestを特定する．ソースデータのトークンs_jSについてt_j,nearestとの類似度sim_j,nearestをもとに，訓練事例とするかどうかを判定する．ここで，sim_j,nearestが0.8以上のソースデータs_jを訓練事例に含めた．なおsim_i,jを計算する際，重みづけや正規化は行っていない．なお，追加するターゲットデータ数は常に10トークンとした．分類器としてはマルチクラス対応のSVM(libsvm)を使用した．カーネルは予備実験の結果，線形カーネルが最も高い正解率を示したため，これを採用した．また，学習の素性には，で使われている以下の17素性を用いた．WSDの対象単語の前後二語までの形態素の表記（4素性）WSDの対象単語の前後二語までの品詞（4素性）WSDの対象単語の前後二語までの品詞の細分類（4素性）WSDの対象単語の前後二語までの分類コード（4素性）係り受け（1素性）		対象単語が名詞の場合はその名詞が係る動詞	対象単語が動詞の場合はその動詞のヲ格の格要素	分類語彙表の分類コードにはを使用した</subsection>
  <subsection title="決定木学習のラベル">作成する三つの二分決定木のうち，ここではTOとRSの決定木のラベル（教師値）について述べる．作成する決定木によって，TOとRSを，それぞれTOとFD，またはRSとFDに読み替えていただきたい．ケースごとに，最もWSDの正解率がよかった手法によって，TOとRSとSameの三種類のうちのひとつのラベルをつける．これらのつけ方は節で述べる．決定木は，ケースごとにソースデータとターゲットデータの性質から，TOかRSのどちらの手法を使って領域適応するべきかを判定していることに留意いただきたい．TO:RSよりTOを使用した方がWSDの正解率が良いケースRS:TOよりRSを使用した方がWSDの正解率が良いケースSame:TOとRSのどちらを使ってもWSDの正解率に差がないケースなお，TOとRSのどちらを使ってもWSDの正解率に差がないケースには，Sameラベルを使用せず，どちらかの手法に強制的に割りつけることも可能であるが，このような正解率に差がないケースが比較的多かったため(c.f.決定木とラベル付け手法別に見たラベルの分布)，本論文ではSameラベルを使って決定木の分類性能をあげている</subsection>
  <subsection title="決定木学習の素性">最適な領域適応手法はソースデータとターゲットデータの分布や距離などの性質によって異なると考えられるため，決定木には以下の24種類の合計40の素性を利用する．なお，手法1と手法2は作成する二分決定木によって，RSとTO，またはRSとFD，またはTOとFDが相当する．また，データ1とデータ2は手法1と手法2に準じ，それぞれRSの場合にはソースデータ，TOの場合にはターゲットデータ，FDの場合にはターゲットデータに閾値以上似たソースデータが相当する．手法1のシミュレーションの正解率手法2のシミュレーションの正解率ふたつの正解率の比(()/())データ1のトークン数データ2のトークン数ふたつのデータのトークン数の比(()/())データ1の語義数データ2の語義数辞書中の語義数データ1のMFS（MostFrequentSense:データ中最も頻出する語義）のトークン数データ2のMFSのトークン数MFSの語義がデータ1とデータ2で同じかデータ1のMFSのパーセンテージ(()/())データ2のMFSのパーセンテージ((9/())データ2のMFSのデータ1中でのパーセンテージ(()/())データ1のMFSのデータ2中のパーセンテージ(()/())データ1とデータ2の語義タグのジェンセン・シャノン・ダイバージェンス（JS距離）データ1とデータ2の間のWSDの素性ごとの分布のJS距離データ1とデータ2の間の素性ごとのJS距離を足しあわせたもの（()を17種類足しあわせた値）データ1とデータ2の素性をひとつの単位としたときのJS距離新語義の数データ1とデータ2で共通する語義数データ1とデータ2で共通する語義の，データ1中のパーセンテージ(()/())データ1とデータ2で共通する語義の，データ2中のパーセンテージ(()/())なお，()と()のシミュレーションの正解率としては，手法ごとに以下を用いる．RS：ソースデータのシミュレーションの正解率．ソースデータで分類器を学習し，語義をタグ付けしたターゲットデータ10トークンで評価した正解率TO：TOのシミュレーションの正解率．ターゲットデータ10トークンに語義をタグ付けし，LeaveOneOut法で評価を行った際の正解率FD：FDのシミュレーションの正解率．ターゲットデータに閾値以上似たソースデータで分類器を学習し，語義をタグ付けしたターゲットデータ10トークンで評価した正解率また，()と()のトークン数には，手法ごとに以下を用いる．ただし，()〜()，()，()において，TOのデータ数は10トークンとする．RS：全ソースデータのトークン数TO：全ターゲットデータのトークン数FD：全ソースデータの4/5（5分割交差検定のうち一試行）のうち，ターゲットデータに閾値以上似ているトークンの数また，()と()の語義数には，手法ごとに以下を用いる．RS：全ソースデータ中に出現する語義の異なり数TO：語義をタグ付けした10トークンのターゲットデータ中に出現する語義の異なり数FD：ソースデータの全トークンの4/5のうち，ターゲットデータに閾値以上似たデータに出現する語義の異なり数また，()と()，()のMFSには，手法ごとに以下を用いる．RS：全ソースデータ中の，全ソースデータのMFSを語義に持つトークンの数TO：語義をタグ付けしたターゲットデータ10トークンの中の，語義をタグ付けしたターゲットデータ10トークンのMFSを語義に持つトークンの数FD：「全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータ」中の，「全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータ」のMFSを語義に持つトークンの数さらに，()〜()のJS距離は，カルバック・ライブラー・ダイバージェンスを対称にしたものであり，H(P)が分布Pのエントロピーであるとき，以下の式で与えられる．また，()では，RS：全ソースデータの4/5TO：ターゲットデータの10トークンFD：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークンの語義タグの分布間のJS距離を用いたが，()のJS距離では，RS：全ソースデータTO：全ターゲットデータFD：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークンの間のWSDの素性（形態素情報など17種類．節参照）の素性ごとの分布のJS距離を，()のJS距離では，これらのデータのWSDの素性（形態素情報など17種類）をつなげて，ひとつの単位としたものの分布のJS距離を用いた．これは，17種類全ての素性が等しいときにだけ，同じ要素と考えてJS距離を求めるものである．また，()の共通語義も，()のJS距離の際のデータのうち，手法に対応したふたつのデータに出現した語義の異なり数である．また，()の新語義の数は，RSとTOの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータのみに出現する語義の異なり数RSとFDの決定木：全ソースデータの4/5のうち，ターゲットデータに閾値以上似たデータに出現せず，全ソースデータのみに出現する語義の異なり数TOとFDの決定木：語義をタグ付けしたターゲットデータ10トークンに出現せず，全ソースデータの4/5のうち，ターゲットデータに閾値以上似たトークンのみに出現する語義の異なり数になる．決定木作成アルゴリズムにはC4.5を利用し，二分決定木を作成した．また，五分割交差検定を行った．決定木作成の枝刈りの閾値は訓練事例の1/4を開発用データとした予備実験により最適化した．なお，このとき決定木作成の閾値にはノードのエントロピーの値を使用し，0,0.1,0.2...というように0.1きざみで試した．閾値の最適化の際に，最高の正解率の決定木の閾値が複数ある場合には，決定木がより小さいときの閾値を採用した</subsection>
  <section title="データ">実験には，現代日本語書き言葉均衡コーパス（BCCWJコーパス）の白書のデータとYahoo!知恵袋のデータ，またRWCコーパスの毎日新聞コーパスの三つのデータを利用し，ソースデータとターゲットデータを変えることで，全部で6通りの領域適応を行った．これらのデータには岩波国語辞典の語義が付与されている．これらのコーパス中の多義語のうち，ソースデータおよびターゲットデータ中にともに50トークン以上存在する単語を実験対象とした．WSDを行う単語の異なり数は，白書⇔Yahoo!知恵袋：24白書⇔新聞：22Yahoo!知恵袋⇔新聞：26であり，最終的なケースの数は，28単語，合計144のケースとなった．ターゲットコーパス別に見たケースの最小，最大，平均トークン数をtab:table1に示す．また，実験には岩波国語辞典の小分類の語義を採用した．全WSDの対象単語の語義数ごとの内訳をtab:Thelistoftargetwordsに示す．また，領域適応によるWSDの実験には五分割交差検定を用いた．RSのときのこの様子をfig:two-1に示す．RSの場合には，ソースデータの4/5（ソースデータの濃い灰色の部分）に加え，ターゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）から10トークン（白い部分）を訓練事例とする．FDの際には，ソースデータの4/5（ソースデータの濃い灰色の部分）に関して，ターゲットデータの4/5（ターゲットデータの白の部分と薄い灰色の部分）との類似度を測り，一定以上似たデータと10トークン（白い部分）を訓練事例とする．テストデータは，ターゲットデータの残りの1/5（黒い部分）である</section>
</root>
