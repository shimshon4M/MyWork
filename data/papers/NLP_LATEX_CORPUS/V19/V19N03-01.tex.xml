<?xml version="1.0" ?>
<root>
  <jtitle>テキストの表層情報と潜在情報を利用した適合性フィードバック</jtitle>
  <jauthor>原島純黒橋禎夫</jauthor>
  <jabstract>適合性フィードバックの手法の多くは，テキストに表層的に出現する単語の情報だけを用いて検索結果をリランキングしている．これに対し，本稿では，テキストに表層的に出現する単語の情報だけでなく，テキストに潜在的に現れうる単語の情報も利用する適合性フィードバックの手法を提案する．提案手法では，まず検索結果に対してLatentDirichletAllocation(LDA)を実行し，各文書に潜在する単語の分布を推定する．ユーザからフィードバックが得られたら，これに対してもLDAを実行し，フィードバックに潜在する単語の分布を推定する．そして，表層的な単語の分布と潜在的な単語の分布の両方を用いてフィードバックと検索結果中の各文書との類似度を算出し，これに基づいて検索結果をリランキングする．実験の結果，2文書（合計3,589単語）から成るフィードバックが与えられたとき，提案手法が初期検索結果のPrecisionat10(P@10)を27.6%改善することが示された．また，提案手法が，フィードバックが少ない状況でも，初期検索結果のランキング精度を改善する特性を持つことが示された（e.g.,フィードバックに57単語しか含まれていなくても，P@10で5.3%の改善が見られた）．</jabstract>
  <jkeywords>情報検索，適合性フィードバック，LDA</jkeywords>
  <subsection title="文書モデルP^HYB">_d_i()の構築D_q中の各文書d_i(i=1,,I)について，d_iの表層情報と潜在情報の両方を含む言語モデルP^HYB_d_i()を構築する．まず，各文書d_iについて，LDAを用いて，d_iの潜在情報を含む言語モデルP^LDA_d_i()を構築する．具体的な手順は次の通りである．まず，D_qに対してLDAを実行し，D_qに対するLDAのパラメータ_kと_k(k=1,,K)，_i(i=1,,I)を推定する（節参照）．次に，各文書について，推定された各パラメータ及び式()を用いてP^LDA_d_i()を構築する．P^LDA_d_i()は，d_iに潜在するトピックの分布を基に構築されており，各単語がd_iに潜在的に現れうる確率の分布になる（式()参照）．次に，構築されたP^LDA_d_i()とP^DIR_d_i()を次式によって混合し，P^HYB_d_i()を構築する．ただし，0a1とする．P^DIR_d_i()は，各文書の表層的な単語の分布を基に構築される（式()参照）．P^DIR_d_i()とP^LDA_d_i()を混合することで，d_iの表層情報と潜在情報の両方を含む言語モデルを構築することができる．</subsection>
  <section title="はじめに">検索エンジンの主な目的は，ユーザの情報要求に適合する文書をランキング形式でユーザに提供することである．しかし，情報要求に見合うランキングを実現するのは容易ではない．これは，ユーザが入力するクエリが一般的に，短く，曖昧であり，ユーザの情報要求を推定するのが困難であることに起因する．例えば「マック価格」というクエリは，「Mac（コンピュータ）」の価格とも，「マクドナルド」の価格とも，もしくは他の「マック」の価格とも解釈できる．そのため，どの「マック」に関する文書が求められているのか分からなければ，ユーザの情報要求に見合うランキングを実現するのは難しい．このような問題を解決する方法の一つとして，適合性フィードバックがある．適合性フィードバックでは，ユーザから明示的（もしくは擬似的）に得られるフィードバックを利用することで，検索結果のランキングを修正する．具体的には，次のような手続きに従ってランキングの修正を行う．クエリに対する初期検索結果をユーザに提示する．初期検索結果中から，情報要求に適合する文書をユーザに選択させる．選択された文書（フィードバック）を利用して，初期検索結果のランキングを修正する．例えば，「Mac（コンピュータ）」の価格に関する文書がフィードバックとして得られれば，ユーザがこの話題に関心を持っていると推測できる．そして，この情報を基に検索結果のランキングを修正することができる．適合性フィードバックには，ベースとするランキングアルゴリズムに応じて，様々な手法がある．Rocchioの手法やIdeの手法は，ベクトル空間モデルに基づくランキングアルゴリズムに対する適合性フィードバックの手法として有名である．確率モデルに基づくランキングアルゴリズムにおいては，フィードバックを用いて，クエリ中の単語の重みを修正したり，クエリを拡張することができる．言語モデルに基づくランキングアルゴリズムに対しては，Zhaiらの手法が代表的である．このように適合性フィードバックには様々な手法があるが，それらの根底にあるアイディアは同じである．すなわち，適合性フィードバックでは，フィードバックと類似する文書を検索結果の上位にリランキングする．ここで，既存の手法の多くは，テキスト（フィードバック及び検索結果中の各文書）に表層的に出現する単語の情報だけを用いて類似度を算出している．すなわち，テキストに含まれていない単語の情報は利用していない．しかし，表層的には出現していなくても，そのテキストに潜在的に現れうる単語の情報は，リランキングに役に立ちうると考えられる．上の「マック」の例であれば，仮にフィードバック（この例では「Mac（コンピュータ）」の価格に関する文書）に「CPU」や「ハードディスク」などの単語が含まれていなくても，これらの単語はフィードバックとよく関連しており，潜在的にはフィードバックに現れうる．検索結果中の適合文書（i.e.,「Mac（コンピュータ）」の価格に関する文書）についても同様のことが言える．仮にある適合文書にこれらの単語が含まれていなくても，これらの単語は適合文書によく関連しており，潜在的にはその文書に現れうる．このように，テキストに現れうる単語の情報があれば，フィードバックと検索結果中の各文書との類似度を算出する際に有用であると考えられる．そこで，本稿では，テキストに表層的に存在する単語の情報だけでなく，テキストに潜在的に現れうる単語の情報も利用する適合性フィードバックの手法を提案する．提案手法では，まずLatentDirichletAllocation(LDA)を用いて，テキストに潜在するトピックの分布を推定する．次に，推定された潜在トピックの分布を基に，各テキストに潜在的に現れうる単語の分布を推定する．そして，推定された潜在的な単語の分布とテキストの表層的な単語の分布の両方を用いて，フィードバックと検索結果中の各文書との類似度を算出し，これを基に検索結果をリランキングする．実験の結果，2文書（合計3,589単語）から成るフィードバックが与えられたとき，提案手法が初期検索結果のPrecisionat10(P@10)を27.6%改善することが示された．また，提案手法が，フィードバックが少ない状況でも，初期検索結果のランキング精度を改善する特性を持つことが示された（e.g.,フィードバックに57単語しか含まれていなくても，P@10で5.3%の改善が見られた）．以降，本稿では，次の構成に従って議論を進める．章では，提案手法の基礎をなす，言語モデルに基づくランキングアルゴリズムについて概説する．章では，提案手法で使用するLDAについて解説する．章では，提案手法について説明する．章では，提案手法の有効性を調査するために行った実験と，その結果について報告する．最後に，章で，本稿の結論を述べる．</section>
  <section title="言語モデルに基づくランキング">本章では，言語モデルに基づくランキングアルゴリズムについて概説する．ここで紹介する技術は，章で説明する提案手法の基礎をなしている．</section>
  <subsection title="概要">言語モデルに基づくランキングアルゴリズムは，三つのタイプに分類できる．すなわち，クエリの尤度に基づく方法，文書の尤度に基づく方法，カルバック・ライブラー情報量に基づく方法の三つである．クエリの尤度に基づく方法では，文書セット中の各文書d_h(h=1,,H)について，d_hを表す言語モデルP_d_h()を構築する．ユーザによってクエリqが入力されたら，各文書d_hについて，P_d_h()がクエリを生成する確率P_d_h(q)を計算する．そして，P_d_h(q)が高い順に各文書をランキングする．文書の尤度に基づく方法は，クエリの尤度に基づく方法と逆のアプローチを採る．すなわち，クエリqを表す言語モデルP_q()を構築し，文書セット中の各文書d_hについて，P_q(d_h)を計算する．そして，P_q(d_h)が高い順に各文書をランキングする．カルバック・ライブラー情報量に基づく方法では，P_q()とP_d_h()の両方を構築する．そして，各文書d_hについて，P_q()とP_d_h()のカルバック・ライブラー情報量KL(P_q()||P_d_h())を計算し，これが小さい順に各文書をランキングする．</subsection>
  <subsection title="言語モデルの構築方法">クエリや文書を表す言語モデルは，MaximumLikelihoodEstimation(MLE)やDIRichletsmoothedestimation(DIR)などの方法を用いて構築する．MLEでは，テキストt（tはクエリや文書）における単語wの生起確率P^MLE_t(w)を次式によって算出する．ただし，tf(w,t)はtにおけるwの出現頻度を表す．また，|t|は，tに含まれる単語数を表す．一方，DIRでは，tにおけるwの生起確率P^DIR_t(w)を次式によって算出する．ただし，D_allは文書セットを表す．また，はスムージングパラメータを表す．DIRでは，MLEと異なり，D_allにおけるwの出現頻度が加味されており，スムージングが行われている．</subsection>
  <subsection title="代表的な適合性フィードバックの手法">言語モデルに基づくランキングアルゴリズムに対する代表的な適合性フィードバックの手法として，Zhaiらの手法がある．Zhaiらの手法では，フィードバックとして与えられた文書集合F=(f_1,,f_G)に対して，Fを表す言語モデルP_F()を構築する．次に，P_F()とP_q()（初期検索結果を得るために使用したクエリモデル）を足し合わせ，新しいクエリモデルを構築する．そして，新しいクエリモデルを用いて，初期検索結果のランキングを修正する．Zhaiらの手法は，言語モデルに基づくランキングアルゴリズムに対する基本的な適合性フィードバックの手法として重要である．しかし，彼らの手法では，テキストに表層的に存在する単語の情報しか用いられていない．これに対し，提案手法では，テキストに潜在的に現れうる単語の分布を推定し，この情報も用いて適合性フィードバックを行う．</subsection>
  <section title="LDA">本章ではLDAについて解説する．LDAは，提案手法において，各単語がテキストに潜在的に現れうる確率を推定するために用いられる．</section>
  <subsection title="パラメータの推定方法">LDAでは，変分ベイズ法やギブスサンプリングなどを用いてパラメータを推定する．ギブスサンプリングを用いれば，より厳密な推定結果が得られる．実装も容易なため，一般的にはギブスサンプリングが用いられることが多い．しかし，ギブスサンプリングには推定に時間を要するという欠点がある．一方，変分ベイズ法は，厳密な推定結果は得られないが，高速に動作する．即時性が要求される検索というタスクの性質を考慮し，提案手法では変分ベイズ法を用いる．以下，変分ベイズ法による推定方法について説明する．まず，訓練データ中の各文書d_i(i=1,,I)について，変分パラメータ_i=(_i1,,_iK)と_i=(_i1,,_iJ)を導入する．ただし，_ij=(_ij1,,_ijK)である．そして，式()と式()を交互に計算し，これらの値を更新する．_ijk&amp;_kj((_ik)-(_k'=1^K_ik'))_ik&amp;=_k+_j=1^J_ijktf(w_j,d_i)alignただし，はディガンマ関数を表す．次に，更新された_iと_iを用いて，_kと_kを更新する．_kと_kの更新には，ニュートン-ラフソン法や固定点反復法を用いる．ここでは固定点反復法による_kと_kの更新式を示す．更新式は次の通りである．_kj&amp;_i=1^I_ijktf(w_j,d_i)_k&amp;=_i=1^I(_k+n_ik)-(_k)_i=1^I(_0+|d_i|)-(_0)_k^oldalignただし，n_ik=_j=1^J_ijktf(w_j,d_i)，_0=_k'=1^K_k'とする．また，_k^oldは更新前の_kを表すものとする．以降，_iと_iの更新と，_kと_kの更新を繰り返すことで，各パラメータの値を推定することができる．_kと_kの値が推定されれば，式()を用いて，文書d_iの生成確率を求めることができる．また，_iの値が推定されれば，次式を用いて，文書d_iにおける単語w_jの生起確率P^LDA_d_i(w_j)を求めることができる．ここで，_ik/_k'=1^K_ik'は，d_iに潜在するトピックの分布に相当する．これに基づいて_kjを足し合わせることで，w_jがd_iに潜在的に現れうる確率を求めることができる．</subsection>
  <subsection title="未知テキストに対する適用">LDAはProbabilisticLatentSemanticAnalysis(PLSA)をベイズ的に拡張したモデルと位置付けられる．PLSAに対するLDAの長所として，LDAは未知テキスト（訓練データ中に含まれないテキスト）に関する確率も推定できるという点が挙げられる．未知テキストtにLDAを適用するときは，tに対して変分パラメータ_tと_tを導入し，式()と式()を用いてこれらの値を推定する．ただし，_kと_kには，訓練データによって推定された値を用いる．_tが推定されれば，式()を用いて，未知テキストtにおける単語w_jの生成確率P_t^LDA(w_j)を求めることができる．提案手法では，LDAのこの長所を利用して，各単語がフィードバックに潜在的に現れうる確率を求めている．</subsection>
  <subsection title="情報検索におけるLDAの利用">LDAは，自然言語処理や画像処理，音声認識など，様々な分野で利用されている．情報検索の分野では，例えばWeiらが，クエリの尤度に基づくランキング手法にLDAを利用している．また，Yiらは文書の尤度に基づくランキング手法に，Zhouらはカルバック・ライブラー情報量に基づくランキング手法にLDAを利用している．これらの研究は，LDAを用いて各文書の文書モデルを構築し，それぞれのスコア（e.g.,クエリの尤度）に基づいてクエリに対する検索結果を取得するものである．本研究では，さらに，ユーザからフィードバックが得られる問題（i.e.,適合性フィードバックの問題）に焦点を当てる．我々は，フィードバックに対してもLDAを用いてその言語モデルを構築し，構築されたフィードバックモデルを用いて検索結果を修正する．</subsection>
  <section title="提案手法">本章では，提案手法の概要と，提案手法を構成する各ステップについて詳説する．</section>
  <subsection title="初期検索結果の取得">提案手法では，カルバック・ライブラー情報量に基づいて，各文書をランキングする．まず，文書セットD_all中の各文書d_h(h=1,,H)について，DIRに基づく文書モデルP^DIR_d_h()をあらかじめ構築しておく．ユーザからクエリqが与えられると，qに対してMLEに基づくクエリモデルP^MLE_q()を構築する．そして，D_all中のqを含む各文書について，P^MLE_q()とP^DIR_d_h()のカルバック・ライブラー情報量を計算する．すなわち，クエリqに対する文書d_hの重要度は，次式のように定義される．この重要度に従って各文書をランキングし，qに対する初期検索結果D_qを得る．クエリモデルの構築にMLEを用いたのは，言語モデルに基づくランキングに関する先行研究(e.g.,)に倣ってのことである．なお，クエリモデルの構築にMLEを用いた場合，カルバック・ライブラー情報量に基づくランキングは，クエリの尤度に基づくランキングと等価になる．</subsection>
  <subsection title="リランキング">D_qをリランキングするため，まず新しいクエリモデルを構築する．新しいクエリモデルP^NEW_q()は，D_qを得るために使用したクエリモデルP^MLE_q()と，Step3で構築したフィードバックモデルP^HYB_F()を次式のようにして混合し，構築する．ただし，0b1とする．最後に，D_q中の各文書d_iについて，P^HYB_d_i()とP^NEW_q()のカルバック・ライブラー情報量を算出する．すなわち，クエリqとフィードバックFが与えられた下での文書d_iの重要度を次式のように定義する．re`-ranking_score(d_i,q,F)=-KL(P^NEW_q()||P^HYB_d_i())eqnarrayこの重要度に従って各文書をリランキングすることで，検索結果のランキングを修正する．</subsection>
  <section title="実験">本章では，提案手法の有効性を調査するために行った実験と，その結果について報告する．</section>
  <subsection title="実験データ">実験は，第3回NTCIRワークショップで構築されたウェブ検索評価用テストセットを用いて，これを行った．テストセットは，11,038,720ページの日本語ウェブ文書と，47個の検索課題から成る．検索課題ごとに，約2,000文書に，その課題に対する適合度が付与されている．ただし，適合度は「高適合」「適合」「部分適合」「不適合」のいずれかである．これらの適合度が付与された文書を用いて，検索結果のランキング精度を測ることができる．図に検索課題の一例を示す．各タグが表す意味内容は次の通りである．実験では，TITLEタグの単語をクエリとして使用した．ただし，提案手法では，検索の質を高めるため，クエリを含む文書（クエリを構成する各タームが最低でも1回以上出現する文書）のみをスコア付けの対象として収集する（節参照）．そのため，TITLEタグの全ての単語を用いると，多くの検索課題において，検索される文書数が極端に少なくなってしまった．例えば，課題番号0027，0047，0058などは，それぞれ17文書，5文書，14文書しか検索できなかった．課題番号0061に至っては1文書も検索できなかった．このように検索される文書が少ないと，適合性フィードバックの有効性が検証しにくい．すなわち，実際に適合性フィードバックによって初期検索結果のランキングが改善されても，その結果がP@10などの評価尺度の値に反映されにくく，適合性フィードバックが有効に働いたかどうかが判断しづらい．そこで，実験では，この問題を避けるため，十分な検索結果が得られるように，クエリとして使用する単語をTITLEタグの最初の2語のみとした．ただし，「十分」の定義は「100文書以上」とした．また，RDOCタグのIDが付与された文書を，ユーザのフィードバックとして使用した．上で述べた通り，これらは課題作成者本人によって選択された代表的な適合文書であり，フィードバックとして使用するのに最適と考えられる．これらの文書は，提案手法の初期検索結果に含まれるとは限らない．初期検索結果に含まれない場合，これらをユーザのフィードバックとして使用するのは奇異に感じられるかもしれない．しかし，これらの文書は，仮に初期検索結果に含まれていた場合も，リランキング前後のランキング精度を測定・比較する際，結局ランキングから取り除かれる（節で後述）．言い換えれば，これらは，初期検索結果に含まれていた場合も，初期検索結果に含まれない場合のように，検索結果中に存在していないものとして扱われる．このように，どちらの場合でも存在していないものとして扱われることを考えると，これらの文書が初期検索結果に含まれているか含まれていないかは重要ではない．以上を踏まえ，実験では，これらが初期検索結果に含まれているか含まれていないかは問題にしなかった．47個の検索課題のうち，7個の検索課題（課題番号:0011,0018,0032,0040,0044,0047,0061）については，実験で使用しなかった．これは，上で述べたようにクエリとして使用する単語を2語にしても，十分な文書（i.e.,100文書）が検索できなかったためである．さらに，残った40課題を，開発データと評価データに分けて使用した．開発データは，提案手法のパラメータを最適化するために使用した．評価データは，提案手法のランキング精度を測定するために使用した．開発データには8課題（課題番号：0008〜0017）を，評価データには32課題（課題番号：0018〜0063）を使用した．</subsection>
  <subsection title="実験用検索システム">実験を行うため，提案手法に従って適合性フィードバックを行う検索システムを作成した．実装の詳細は以下の通りである．検索対象とする文書セット(i.e.,D_all)には，テストセットの11,038,720文書を使用した．また，文書セット中の各文書について，次の手順に従って文書モデルを構築した．Shinzatoらの手法を用いて本文を抽出し，JUMANを用いて各文を解析する．解析結果及び式()を用いて，DIRに基づく文書モデルを構築する．ただし，先行研究に倣って，=1,000とした．クエリが与えられたら，次の手順に従ってクエリモデルを構築した．JUMANを用いてクエリを解析する．解析結果及び式()を用いて，MLEに基づくクエリモデルを構築する．LDAの実装については次の通りである．パラメータ_k(k=1,,K)の初期値は1とした．また，_k(k=1,,K)の初期値にはランダムな値を与えた．_iと_iを更新する際の反復回数と，_kと_kを更新する際の反復回数は，それぞれ10回とした．LDAで考慮する語彙数Jは100とした．ただし，LDAで考慮する語彙は，初期検索結果に対する重要度を基に選出した．ここで，初期検索結果D_qに対する単語wの重要度は，df(w,D_q)*(H/df(w,D_all))と定義した．ただし，df(w,D)はDにおけるwの文書頻度を表す．</subsection>
  <subsection title="ランキング精度の測定方法">適合性フィードバックの効果は，適合性フィードバック前のランキング（i.e.,初期検索結果のランキング）と，適合性フィードバック後のランキングを比較することで検証できる．このとき，フィードバックとして使用する文書の扱いに気を付けなければならない．例えば，適合性フィードバック前後のランキングをそのまま比較すると，後者が有利になってしまう．これは，フィードバックとして与えられた文書（適合であることが分かっている文書）が，適合性フィードバック後のランキングの上位に含まれやすいためである．そこで，適合性フィードバック前後のランキングを比較する際，フィードバックとして与えられた文書を適合性フィードバック後のランキングから取り除くという方法が考えられる．しかし，この方法だと，適合性フィードバック前のランキングが有利になってしまう．これは，適合文書が少ないときに特に問題となる．以上を踏まえ，実験では，ランキングの精度を測定する際，フィードバックとして使用した文書を各ランキングから取り除いた．これにより，適合性フィードバック前後のランキングを公平に比較することができる．ランキング精度の評価尺度には，P@10，MeanAveragePrecision(MAP)，NormalizedDiscountedCumulativeGainat10(NDCG@10)を用いた．ただし，P@10及びMAPを測定する際は，「高適合」「適合」「部分適合」の文書を正解，「不適合」及び適合度が付与されていない文書を不正解とした．また，NDCG@10は，「高適合」の文書を3点，「適合」の文書を2点，「部分適合」の文書を1点として算出した．</subsection>
  <subsection title="リランキング性能の調査">まず，提案手法が初期検索結果のランキング精度をどの程度改善できるか調査した．具体的には，初期検索結果のランキング精度と，提案手法によってリランキングを行った後のランキング精度を比較し，提案手法の有効性を検証した．実験には評価データを使用し，各検索課題の初期検索結果を取得する際は，節で述べたように，TITLEタグの最初の2単語をクエリとして用いた．また，実験では，initial_score（式()参照）の上位100件を初期検索結果とした．提案手法を実行する際は，RDOCタグの最初の2文書をフィードバックとして用いた．なお，これらの文書に含まれる単語数は平均3,589語であった．提案手法に必要な3つのパラメータa，b，Kの値は，それぞれ0.2，0.9，50とした．これらは，節で述べる実験の結果を基に決定した．結果を表に示す．INITは各検索課題に対する初期検索結果のランキング精度の平均値を，OURSは提案手法実行後のランキング精度の平均値を表す．比較のため，初期検索結果に対してベースラインとなる手法を実行したときの結果も示した．ZHAIはZhaiらの手法を，OURS(a=0.0)は提案手法から潜在情報を除いた手法を表す．ただし，ZHAIとOURS(a=0.0)は本質的にはほとんど同じ手法である．両手法とも，フィードバックの表層の単語分布を文書セット全体の単語分布で補正することでフィードバックモデルを構築し，これを用いてリランキングを行っている．違うのは単語分布の補正の仕方だけである（前者はEMアルゴリズムを用い，後者はDIRを用いて補正を行っている）．OURS(a=0.0)では，b=0.5とした．これも，節で述べる実験の結果を基に決定した．DICもベースラインとなる手法を表す．提案手法の核となるアイディアは，テキスト（フィードバック及び検索結果中の各文書）に潜在的に現れうる単語の情報を適合性フィードバックに利用することである．同義語辞書や関連語辞書などの知識リソースを用いても，同様のアイディアを実現することができる．DICでは，OURS(a=0.0)をベースに，テキスト中の各単語が同義語を持つ場合，その同義語もそのテキストに出現しているとみなした上でリランキングを行った．ただし，同義知識は，Shibataらの手法を用いて例会小学国語辞典と岩波国語辞典から獲得した．獲得された同義知識（e.g.,「コンピュータ」＝「電子計算機」，「ポテト」＝「じゃが芋」＝「ばれいしょ」）は4,597個であった．表を見ると，すべての尺度において，OURSがINITを大きく上回っている．例えばP@10は27.6%改善しており，提案手法が初期検索結果をうまくリランキングできたことが分かる．また，提案手法は，ZHAIやOURS(a=0.0)より高い性能を示した．ZHAIやOURS(a=0.0)は，テキストの表層情報だけを用いて適合性フィードバックを行っている．一方，提案手法は，テキストの表層情報に加え，テキストの潜在情報も用いて適合性フィードバックを行っている．提案手法がこれらの手法を上回ったことから，潜在情報が適合性フィードバックに有用であったことが分かる．さらに，リランキング結果を調査したところ，提案手法が，テキストに表層的には出現しないが潜在的には現れうる単語の情報をうまく利用していることが確認できた．図の検索課題を例に取ると，「宗教」や「祝日」「聖書」などの単語は，情報要求によく関連するが，フィードバックとして使用した文書には含まれていなかった．そのため，ZHAIやOURS(a=0.0)では，これらの単語の情報を使用することができなかった．一方，提案手法では，これらの単語がフィードバックにおいてもある程度の確率で現れうると推定できた．具体的には，「宗教」「祝日」「聖書」は，それぞれ0.0046，0.0037，0.0024の確率で現れうると推定できた．なお，フィードバックに1回出現した単語として「クリスマス」や「ＥＡＳＴＥＲ」などがあったが，これらの生起確率の推定値は，それぞれ0.0093，0.0060であった．提案手法では，これらの推定結果を用いることで，これらの単語を含む検索結果中の適合文書を上位にリランキングすることができた．DICはあまり有効に機能せず，その結果はZHAIやOURS(a=0.0)の結果を少し上回る程度であった．この原因は，我々が構築した同義語辞書のカバレッジにあると思われる．DICは，よりカバレッジの高い知識リソースが利用できれば（同義語や関連語などの知識をより多く利用できれば），より有効に機能する可能性を持つ．しかし，そのようなリソースを構築するのは容易ではない．一方，提案手法でも，単語と単語が関連するという知識を必要とする．しかし，DICと違って，何のリソースも必要としない．すなわち，提案手法では，LDAを用いることで，単語と単語が関連するという知識を検索結果から動的に獲得することができる．章の「マック価格」というクエリを例に取ると，このクエリに対する検索結果には「CPU」や「ハードディスク」「ハンバーガー」「ポテト」などの単語が含まれると考えられる．提案手法では，検索結果に対してLDAを実行することで，「CPU」と「ハードディスク」が関連するという知識や「ハンバーガー」と「ポテト」が関連するという知識を，トピックという形で動的に獲得することができる．そして，獲得された知識を用いることで，文書に「ハードディスク」という単語が出現していなくても，「CPU」という単語が出現していれば，「ハードディスク」も潜在的にはその文書に現れうると推測できる．このように，DICと比べると，（カバレッジの高低に関わらず）何のリソースも必要としないという点で，提案手法の方が優れている．提案手法は擬似適合性フィードバックにも適用可能である．そこで，これに対するリランキング性能も調査した．擬似適合性フィードバックでは，初期検索結果の上位n文書を適合文書とみなし，適合性フィードバックを行う．実験では，n=10として初期検索結果をリランキングし，リランキング前後のランキング精度を比較した．ただし，擬似適合性フィードバックでは，明示的なフィードバック（適合であることが分かっている文書）は存在しない．そのため，ランキングの精度を測る際，他の実験のように，RDOCタグの文書を各ランキングから除くことはしなかった．結果を表に示す．INITの値が表と違うのは，ランキング精度を算出する際，RDOCタグの文書を除いていないからである．表を見ると，普通の適合性フィードバックに比べると改善の度合いは小さいが，P@10やNDCG@10の値が上昇している．例えば，P@10では8.2%の改善が見られる．このことから，擬似適合性フィードバックにおいても提案手法がある程度機能することが分かる．</subsection>
  <subsection title="フィードバックが少ない状況でのリランキング性能">現実的には，ユーザが多くのフィードバックを与えてくれるとは考えにくい．そのため，適合性フィードバックの手法は，フィードバックが少ない状況でも機能するべきである．この実験では，このような状況をシミュレートし，フィードバックが少なくても提案手法が機能するかを調査した．具体的には，提案手法に与えるフィードバックを少しずつ減らしていき，リランキング性能がどのように変化するかを調査した．提案手法に与えるフィードバックの分量Gは，G=2^1,2^0,2^-1,,2^-5とした．ただし，例えばG=2^1は，フィードバックとして2文書を用いることを意味している．また，例えばG=2^-1は，フィードバックとして1適合文書の半分だけを用いることを意味している．この場合，適合文書中の単語をランダムに半分抽出し，それらを用いて適合性フィードバックを行った．G&lt;1の場合も調査したのは，フィードバックとして文書より小さい単位（e.g.,文書のタイトル，スニペット）が与えられた場合を想定し，このような場合にも提案手法が機能するかを調べたかったからである．結果を図に示す．比較のため，提案手法から潜在情報を除いたとき(i.e.,OURS(a=0.0))の性能の変化も示した．また，INITは初期検索結果のランキング精度を表す．図から，Gが小さいときでも，提案手法が高い性能を示すことが分かる．例えばG=2^0のとき，提案手法は初期検索結果を24.5%改善している．さらに，G=2^-5のときでも，5.3%の改善が見られた．なお，G=2^-5のとき，フィードバックFに含まれる単語数は平均57語であった．一方，OURS(a=0.0)を見ると，Gが小さくなるにつれ，ほとんど改善が見られなくなった．OURS(a=0.0)ではテキストの表層情報しか利用していない．そのため，Gが小さくなるにつれて利用できる情報が少なくなり，初期検索結果を改善できなくなったと考えられる．一方，提案手法では，表層情報だけでなく潜在情報も利用している．利用できる情報が多い分，Gが小さいときでも，初期検索結果のランキングを改善することができたと考えられる．</subsection>
  <subsection title="パラメータとリランキング性能の関係">提案手法には3つのパラメータa，b，Kがある．aはP^DIR_d_i()とP^LDA_d_i()の混合比を調整するパラメータ（式()及び式()参照），bはP^MLE_q()とP^HYB_F()の混合比を調整するパラメータ（式()参照），KはLDAのトピック数である．節及び節で述べた実験では，OURSのパラメータをa=0.2，b=0.9，K=50とした．また，OURS(a=0.0)のパラメータをb=0.5とした．これらの値は予備実験の結果を基に決定した．提案手法の性能を最大限に発揮するためには，パラメータとリランキング性能の関係について知る必要がある．予備実験では，この関係を知るため，様々な(a,b,K)の組み合わせについて提案手法のリランキング性能を調査し，その結果を比較した．ただし，a=0.0,0.1,,1.0，b=0.0,0.1,,1.0，K=10,20,,100とし，全1,210通りの組み合わせについて，調査を行った．開発データを用いて調査した．ある(a,b,K)の組み合わせに対するリランキング性能は，他の実験と同じようにして，これを測定した．すなわち，開発データ中の各検索課題について初期検索結果を取得し，提案手法を用いてこれらをリランキングした後，全課題におけるP@10の平均値を算出した．他の実験と同様，クエリにはTITLEタグの最初の2単語を，フィードバックにはRDOCタグの最初の2文書を用いた．結果を表及び図に示す．表は，実験結果を(a,b)についてまとめたものである．表中の各セルの値は，各(a,b)の組み合わせについて，各KのP@10を平均したものである．例えば，(a,b)=(0.1,0.2)のセルは，(a,b,K)=(0.1,0.2,10),(0.1,0.2,20),,(0.1,0.2,100)のP@10の平均値が0.286であったことを示している．各列においてもっともP@10が高いセルは，その値を太字で装飾した．また，各行においてもっともP@10が高いセルは，その値に下線を引いた．表から，(a,b)=(0.1,0.9)or(0.2,0.9)のとき，リランキング性能がもっとも良いことが分かる．また，a=0.0のとき（潜在情報を考慮しないとき）は，bが大体0.3〜0.5のとき，リランキング性能が良い．一方，a0.1のとき（潜在情報を考慮したとき）は，bが大体0.8〜1.0のとき，リランキング性能が良い．a=0.0のときより，性能が良くなるbの値（及びそのときのランキング精度）が大きくなっている．これは，潜在情報を考慮することで，フィードバックモデルの信頼度が増すことを示唆している．図は，Kによるリランキング性能の変化を示している．図では，表においてリランキング性能が良かった3つの(a,b)の組み合わせ(a,b)=(0.1,0.9),(0.2,0.9),(0.3,0.9)について，Kによる性能の変化を示した．図から，Kが大体50〜70のとき，リランキング性能が良いことが分かる．以上の結果をまとめると，提案手法がその性能を発揮するパラメータは，(a,b)=(0.1,0.9)or(0.2,0.9)，Kは大体50〜70となる．</subsection>
  <subsection title="LDA の実行時間">提案手法では，検索結果中の各文書に対するP^LDA_d_i()を構築するため，検索結果に対してLDAを実行する．また，フィードバックに対するP^LDA_F()を構築する際は，フィードバックに対してLDAを実行する．本節では，これらの処理に要する時間について考察する．実験では，各検索課題の検索結果（100文書）に対してLDA（PerlとCを組み合わせて実装）を実行するのに，13.1〜16.0秒を要した．この程度の時間であれば，提案手法を実行する上で，問題にはならない．適合性フィードバックは，(1)システムによる検索結果の提示，(2)ユーザによる検索結果の閲覧，適合文書の選択，(3)適合文書を用いた検索結果のリランキングという三つのステップから成る．ここで，一般的に考えて，(2)には1分以上はかかると思われる．従って，まずユーザに検索結果を提示し，ユーザが検索結果を閲覧している裏でLDAを実行するようなシステムの構成を採れば，(3)に移る前にLDAの実行を終えることができる．このように，検索結果が100文書程度であれば，LDAの実行時間は問題にならない．一方，検索結果は，より大きくなり得る．検索結果が大きくなると，LDAの実行時間も大きくなってしまう．これを解決する一つの方法は，ランキングの上位だけを検索結果とすることである．例えば，多くの文書が検索されても，上位100文書だけを検索結果とすれば，上述の通り，LDAの実行時間は問題にならない．別の方法として，変分パラメータの推定を並列化することも考えられる．LDAの実行時間は，変分パラメータの推定に要する時間が多くを占める．ここで，各文書に対する変分パラメータは，他の文書に対する変分パラメータと独立である．従って，各文書に対する変分パラメータの推定を並列化し，LDAの実行時間を削減することができる．例えば，Nallapatiらは，50ノードのクラスタを用いることでLDAの実行時間を14.5倍高速化できたと報告している．提案手法でも並列化を取り入れることで，LDAの実行時間を削減することができると思われる．最後に，フィードバックに対してLDAを実行するのに要した時間を報告する．これは1秒にも満たないものであった．例えば，フィードバックが2文書の場合，実行に要した時間は，わずか0.1〜0.2秒であった．従って，フィードバックに対するLDAの実行時間も問題にはならない．</subsection>
  <section title="おわりに">本稿では，テキストの表層情報と潜在情報の両方を利用する適合性フィードバックの手法を提案し，その有効性について議論した．提案手法では，LDAを用いて，フィードバックや検索結果中の各文書に潜在的に現れうる単語の分布を推定した．そして，表層的な単語の分布と潜在的な単語の分布の両方を用いてフィードバックと検索結果中の各文書との類似度を算出し，これに基づいて検索結果をリランキングした．実験では，2文書（合計約3,589単語）から成るフィードバックが与えられたとき，提案手法が初期検索結果のP@10を27.6%改善することを示した．また，提案手法が，フィードバックが少ない状況でも，初期検索結果のランキング精度を改善する特性を持つことを示した（e.g.,フィードバックに57単語しか含まれていなくても，P@10で5.3%の改善が見られた）．今後の課題としては，ネガティブフィードバックの利用が挙げられる．提案手法は高い性能を示したが，ポジティブフィードバック（ユーザが適合と判定した文書）を扱う機構しか持ち合わせていない．ネガティブフィードバック（ユーザが不適合と判定した文書）も利用することで，さらに性能を上げることができないか検討中である．document</section>
</root>
