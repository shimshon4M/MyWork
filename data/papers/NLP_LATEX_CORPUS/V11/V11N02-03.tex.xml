<?xml version="1.0" ?>
<root>
  <title>講演の書き起こしに対する統計的手法を用いた文体の整形</title>
  <author>下岡和也南條浩輝河原達也</author>
  <jabstract>講演音声のような話し言葉の書き起こしや音声認識結果には、話し言葉特有の表現が数多く含まれており講演録などのアーカイブとして二次利用しにくいため、文章として適した形態に整形する必要がある。本稿では、統計的機械翻訳の考え方に基づいて講演の書き起こしを整形された文章に自動的に変換する方法を提案する。本研究で扱う処理は、フィラーの削除、句点の挿入、助詞の挿入、書き言葉表現への変換、文体の統一である。これらの処理を統合的に行うようにビームサーチを導入した。実際の講演の書き起こしを用いた定量的な評価により統計的な手法の有効性が示され、句点と助詞の挿入に関して高い精度を得ることができた。</jabstract>
  <jkeywords>話し言葉,音声認識,統計的機械翻訳,自動整形,自動要約</jkeywords>
  <section title="緒論">音声認識研究の対象は、読み上げ音声から講演や会議などの話し言葉に移行している。このような話し言葉は日本語では特に、文章に用いる書き言葉と大きく異なり可読性がよくない。そのため、書き起こしや音声認識結果を講演録や議事録などのアーカイブとして二次利用する際には、文章として適切な形態に整形する必要がある。実際に講演録や議事録の作成の際には、人手によりそのような整形が行われている。これまでに、放送ニュースなどを対象とした自動要約の研究が行われている。これらは主に、頻出区間や重要語句の抽出といった処理、つまり発話された表現をそのまま用いることによって要約を作成している。しかし、話し言葉表現が多く含まれる場合には、要約を作成する際にまず話し言葉から書き言葉へ変換する必要がある。実際に人間が要約を作成する際には、このような書き言葉表現への変換に加えて、不必要な部分の削除や必要な語の挿入、さらに1つの文書内での「ですます」調／「である」調などの文体の統一といった処理も行っている。本研究では講演の書き起こしに対してこのような整形を自動的に行うことを考える。現在、文章を整形するソフトウェアも存在しているが、これらはパターンマッチング的に規則ベースで変換を行っており、言語的な妥当性や前後との整合性はあまり考慮されていない。また、基本的に1対1の変換を行っているので、変換の候補が複数ある場合への対処が容易ではない。学会講演とその予稿集との差分をとることで書き言葉と話し言葉の変換規則を自動抽出する研究が村田らにより行われているが、変換の際の枠組みは本質的に同じと考えられ、また実際に変換を行い文章を整形する処理は実現されていない。これに対して本研究では、規則に基づいて1対1の変換を行うのではなく、話し言葉と書き言葉を別の言語とみなした上で統計的な機械翻訳の手法を適用し、確率モデルによりもっともらしい表現に変換し実際に文章を整形することをめざす。</section>
  <section title="整形作業における処理">講演録編集者は、書き起こしから講演録や要約を作成する際に、通常次の4段階の作業を行う。第一段階の一次整形では、フィラーの削除や書き言葉表現への変換、助詞の挿入などを行う。第二段階の文法的チェックでは、言語的に正しくない助詞や接続詞を適切なものに修正する。ポリティカルチェックでは、差別用語などの不適切な表現の修正を行う。第三段階の意味的チェックでは、専門用語が正しく用いられているかの確認を行う。実際に講演録編集者が、「日本語話し言葉コーパス」（CSJ）のいくつかの講演について整形・要約したものを参考にして、(a)から(i)で第一段階、(j)と(k)で第二段階の作業についてそれぞれ例を挙げながら説明する。本研究では、これらの過程のうち、(a)から(d)の一次整形の処理について取り扱う。これらの処理だけでもかなり読みやすいものに整形される反面、これ以上の処理については、内容の理解を含めた高度な処理が必要であると考えられるからである。参考のために図に書き起こし、図に整形された文章の例を示す。</section>
  <section title="統計的手法による文体の整形"/>
  <subsection title="統計的機械翻訳のアプローチ">現在、音声認識や機械翻訳の研究において統計的な手法が広く用いられている。入力系列をX、出力系列をYとすると、これらはXを観測した際のYの事後確率P(Y|X)を最大にするYを求めるという枠組みで捉えられ、ベイズ規則により次の式(1)のように定式化される。ここで、P(Y)は系列Yが生起する事前確率、P(X|Y)は系列Yから系列Xが生起する条件付き確率である。右辺の分母P(X)は、Yの決定に影響しないので無視できる。音声認識の場合は、Xは入力音声、Yは出力単語列となる。この場合は、音響モデルによりP(X|Y)を、言語モデルによりP(Y)を求めている。機械翻訳の場合は、Xを入力言語、Yを出力言語としてP(Y|X)を最大にするYを求めることで、入力言語Xを出力言語Yに変換する。この場合、P(Y)は出力Yの言語的な自然性を評価するもので、音声認識と同様に言語モデルにより求める。P(X|Y)の計算には変換モデルを仮定し、その確率を求める。変換モデルとは、入力単語はある出力単語系列(nullを含む)に対応づけられるという仮定の下で、どの単語に対応するかを文全体における相対的な位置も考慮して確率で表したものである。2章で述べたように、書き起こしの文体と整形した文章の文体はかなり異なっており、書き起こしの単語列と整形された文章の単語列を異なる言語とみなすことができる。そこで、本研究では書き起こしの文体を整形する際に、書き起こしを整形した文章に翻訳すると考えて、機械翻訳と同様に統計的手法を適用することを検討する。ただし、一般の機械翻訳と異なり、本研究で扱う処理では単語の順序の入れ替わりは考慮しない。本研究では上記の変換確率と言語モデル確率を1対1で組み合わせるのではなく、言語的妥当性を重視するために言語モデル確率に重みを乗じることにする。また、言語モデル確率の値として対数尤度を用いるが、対数尤度は単語の数が多くなるほど値が小さくなるので、単語数に応じた補正を行う。これらは対数スケールで行われ、以下の式(2)で示される仮説スコアを定義する。(a,b)のパラメータは音声認識のデコーディングにおいて通常用いられ、aは言語重み、bは挿入ペナルティと呼ばれている。本研究では、Yの言語モデルとして単語3-gramを用いる。この場合、Y=(y_1y_N)について、(P(Y)=_i=1^NP(y_i|y_i-1,y_i-2))として求められる。変換モデル確率P(X|Y)の計算においても、同様にX=(x_1x_M)とY=(y_1y_N)の部分列に対する確率を規定して(デフォルトはP(x_i|y_j)=1forx_i=y_j)その積を求めるが、この単位は可変長(1から数単語)である。以下では、フィラーの削除、書き言葉表現への変換、助詞の挿入、句点の挿入、文体の統一のそれぞれの処理において、この枠組みをどのように実現するかについて説明する。なお本研究では、書き起こしを形態素解析した結果を入力データとして用いている。形態素解析には、ChaSenver2.02を用いている。また、話者がポーズをおいた箇所にはその情報がポーズ長とともに記録されている。</subsection>
  <subsection title="フィラーの削除">ここでは、P(X|Y)は整形文Yに対応する話し言葉Xにおいてフィラーが挿入される確率とする。フィラーは、発話のどの部分にも出現する可能性があるが、特に句読点の後によく出現する傾向がある。ただし、整形された文章にフィラーは一切出現しない。つまり、Yをフィラーを含む単語列であると仮定すると、P(Y)の値は0となり、P(Y|X)の値も0となる。これはP(X|Y)の値にかかわらず書き起こしの単語列Xから全てのフィラーが削除されることを意味している。</subsection>
  <subsection title="書き言葉表現への変換">ここでは、P(x|y)(x,yは１つ以上の単語からなる句)は書き言葉表現の話し言葉表現への変換確率と解釈される。講演録編集者が一次整形を行う際、文章の順序を入れ替える操作は行わないので、元の書き起こしと講演録編集者により一次整形された文章を照合し、句単位で対応づけを行うことで、P(x|y)の値を学習・推定することができる。ただし本研究では、正解の講演録の数が完全な学習には不十分であったため、あらかじめ人手により書き言葉から話し言葉への変換規則を作成しておき、それらに対してのみ確率を推定することとした。作成した変換規則数は64個あり、その一部を表に示す。</subsection>
  <subsection title="助詞の挿入">ここでは、P(x|y)は整形された文章のある単語列パターンyに含まれる助詞が話し言葉xにおいて脱落する確率と解釈される。書き起こしと講演録編集者により整形された文章を比較したところ、次のような「品詞」「助詞」「品詞」のパターンyにおいて助詞が脱落していた。「名詞」(助詞)「名詞」(例)「このお話しを幹事の方から」「名詞」(助詞)「動詞」(例)「我々は作ってきたわけです」「名詞」(助詞)「形容詞」(例)「非常に能力が高くなって」「名詞」(助詞)「接続詞」(例)「これはつまりサンプルごとの」そこで、これらのパターンの助詞が脱落する規則をあらかじめ作成しておき、それが生起する確率P(x|y)を書き起こしと一次整形の対応づけにより推定する。用意した変換パターン数は13個あり、その一部を表に示す。そして、それらの助詞を挿入する場合としない場合との尤度を比較することによって助詞を挿入するかしないか、どの助詞を挿入するのか判定を行う。</subsection>
  <subsection title="句読点の挿入">「日本語話し言葉コーパス」（CSJ）の書き起こしには句読点がなく、その代わりに話者のポーズ情報が記録されている。ここでは、整形された文章の単語列Yに含まれる句読点が、音声(書き起こしの単語列X)においてポーズに変換される確率P(x=ポーズ|y=句読点)を考える。なお、本研究では句点のみを扱う。なぜなら、句点を挿入する位置は人によらずほぼ一定であるが、読点を挿入する位置は様々であり定量的な評価を行うのが難しいためである。音声認識における句点の挿入に関する研究は、これまでにも行われているが、これらが扱っているのは旅行会話などの短い話し言葉であり、講演のように長い話し言葉は扱っておらず、また、主に言語モデル(P(Y)に相当)による情報しか用いられていない。文末には、「です」「ます」などのような典型的な表現が多い反面、話し言葉においては独特の表現が文の区切りになることがある。文末での「〜と」と文頭での「で〜」である。その例を以下に挙げる。（例）「単位が使われていたと。あるいは」++「大きく違う。でそのままでは」そこで、本研究ではP(x_i=ポーズ長|y_j=句点)の確率において、以下の3通りのモデル化を考える。x_iにおいてはポーズの長さの情報も考慮する。上記3通りについて、4章で比較・評価する。</subsection>
  <subsection title="文体の統一">話し言葉を書き言葉に変換する際に、その変換候補が複数ある場合には、どれを採用するかの判定を言語モデル確率P(Y)に基づいて行う。ここで、使用する言語モデルを異なるものにすると、変換結果も異なったものになる。本研究では2種類の言語モデルを用いることによって、それぞれ文体が「ですます」調あるいは「である」調に統一することができるか検討する。使用する言語モデルは、講演録のコーパスから作成されたものと、新聞記事のコーパスから作成されたものを用いる。前者の言語モデルを用いると「ですます」調の文体に、後者の言語モデルを用いると「である」調の文体に統一されると期待される。ただし、例えば「ですます」調の文でも「〜であると思われます」といった表現があるため、単純に「である」という表現をすべて「です」や「であります」という表現に変えればよいわけではない。ここでは、変換モデル確率において、表の各グループ(同一行)間で相互に変換可能としたが、変換確率は等しいものとし、その選択はP(Y)に基づいて行うものとした。なお、変換の際に動詞の語幹が変化する表現、例えば「思います」→「思う」などの表現については変換規則を用意していない。</subsection>
  <subsection title="デコーディングアルゴリズム">これまでに、講演の書き起こしから整形された文章を生成する処理とモデルについて述べてきた。本研究では、確率P(Y)の計算に単語3-gramモデルを用いるので、これらの処理を逐次的に行うのではなく、統合的に行うように実装する必要がある。なぜなら、これらの処理を個別に行うと、すぐ前後に別の処理をする必要のある表現が存在する場合、式(2)の尤度の計算に影響を与えるからである。したがって、前後2単語に着目する必要のある表現が存在しなくなる範囲において、そのすべての変換パターンの尤度を比較して出力単語列を決定する。その様子を図に示す。変換で複数の候補が生成されうることも考慮すると、可能な仮説の数は組み合わせ的に爆発するので、探索アルゴリズムを導入する必要がある。本研究ではビームサーチを行う。具体的には、生成したパターンの数が100を越えた場合は、そこまでの範囲で尤度を計算し、上位100個のパターンのみを選択することにした。</subsection>
  <section title="実験と評価"/>
  <subsection title="データと実験条件">以上の手法を用いて講演の書き起こしを整形し、その評価を行った。評価データとして、CSJに含まれる実際に学会で行われた4講演を用いた。評価データの概要および処理時間を表に示す。なお使用したマシンのCPUはIntelXeon2.8GHz、メモリは2GBである。また、P(Y)の計算に用いる言語モデルは、毎日新聞記事データで学習されたものと、Web講演録で学習されたものの2種類であるが、4.5節以外ではWeb講演録の方を使用している。P(X|Y)推定のための講演の書き起こしと整形文章のデータは評価データ以外のCSJの18講演を用いている。次節以降、行った実験の結果と評価について述べる。なお、3.2節のフィラーの削除は完全に機械的に行える。また、3.3節の書き言葉表現への変換もおおむね行えた。</subsection>
  <subsection title="デコーディングパラメータについて">3.1節で述べた式(2)の2つのパラメータについてまず検討した。評価尺度として、句点の挿入および助詞の挿入についてのF値の平均を用いる。句点挿入のモデルは最もよいものを用いている。様々な言語重み・挿入ペナルティの値について行った実験結果を図に示す。結果として(言語重み,挿入ペナルティ)=(5,8)の時にF値が最大となった。したがって、以降の実験はこれらの値を用いて行う。表4の処理時間もこの場合の計測値である。</subsection>
  <subsection title="句点の挿入">3.5節で述べた3通りの句点挿入の実験結果を表に示す。ポーズ長制限なしで挿入する場合は適合率が低い。その主な原因は、「〜と」「〜た」の後と「で〜」の前のポーズが誤って句点に変換されることが多いためである。「ます」「です」などの後のポーズが誤って句点に変換されることはなかった。「〜た」という表現は文末表現であるが、同時に文中にもよく使われるため、例えば「〜使われてきた&lt;pause&gt;データベースが〜」→「〜使われてきた。データベースが〜」のような誤りが起こる。また、「〜と」の場合は、例えば、「〜しようと思うと&lt;pause&gt;このように〜」→「〜しようと思う。このように〜」のような場合に誤ってポーズが句点に変換された。一方、平均ポーズ長以上に挿入する場合においては再現率が低い。その主な原因は、「ます」「です」などの、通常書き言葉で文末表現になるものの後で、ポーズ長が短い箇所が対象外になったためである。したがって、「です」「ます」などの典型的な文末表現部分にある句点はあらゆる時間長のポーズになりうるが、「〜と」「で〜」「〜た」の部分にある句点は平均ポーズ長以上の長さのポーズになるとするモデルを導入した。その結果、再現率・適合率とも高い精度を得ることができた。</subsection>
  <subsection title="言語モデルの使いわけ">次に、3.6節で述べた言語モデルの違いによる文体の変化について評価を行った。結果を表に示す。入力データでは「ですます」調が81.5%、「である」調が18.5%であった。講演録言語モデルを用いて整形した場合は81.1%が「ですます」調に、新聞記事言語モデルを用いて整形した場合は47.7%が「である」調になった。入力データが基本的に「ですます」調であるため、講演録モデルを用いた場合はほとんど変換されていない。一方、新聞記事モデルを用いた場合は、「である」調の割合が30%程度増えている。しかし、全体の半分程度しか「である」調にならないのは、3.6節でも述べたように、今回の変換モデルでは動詞の語幹が変化する表現に対応していないためである。</subsection>
  <subsection title="規則ベースの手法との比較">最後に、完全な規則ベースによる手法を用いて実験を行い、本論文で提案した統計的手法との比較を行う。ここでは、句点の挿入および助詞の挿入について評価した。句点の挿入については次の規則を用いた。3.5節及び4.3節における考察に基づいて、ポーズの閾値についても最も妥当なものにした。・「です」「ます」などの典型的な文末表現の後のポーズは全て句点に変換・「〜と」「〜た」「で〜」の部分のポーズは、平均ポーズ長以上なら句点に変換また助詞の挿入については、コンテキストを考えずに言語モデルの学習テキストにおいて出現頻度が高いものを挿入規則として抽出した。例えば学習テキスト中において、「名詞助詞動詞」の並びで出現頻度が最大となる助詞は「が」であったため、「名詞動詞」となっている箇所には、その前後のコンテキストは考えずに、出現回数が最大の「が」を挿入するという規則を抽出した。以上の手法により行った実験結果と提案手法との比較を表、表に示す。句点の挿入に関しては、規則ベースの方が再現率は若干高いものの、適合率が大幅に低下しており、誤った挿入がおよそ4倍に増えている。助詞の挿入に関しては、F値が0.759から0.696に低下している。以上より、提案手法の有効性が確認された。</subsection>
  <subsection title="整形結果の具体例">ここでは、提案手法により図１で示した書き起こしを整形した具体例を図に示す。なお、本来入力は形態素解析結果であるが、図１では見やすくするために活用形や形態素番号などの情報は省いて示している。句点の挿入はおおむね正しく行えており、また、「結果の方見ていきたい」に「を」が挿入されているなどの整形が行えている。しかし、「になりますで１つ１つ」の所では、ポーズが本来の文末位置とは少しずれた所にあるため、句点が正しく挿入されていない。また、この場合、「調音地図」というパターンが３回以上出現しているため、これを専門用語であるとみなして助詞の挿入箇所の候補にはしていない。ただし、図２と比較すると言い直し部分の削除などを行っていない。</subsection>
  <section title="結論">統計的な機械翻訳の考え方に基づいて文体の整形を自動的に行う手法を提案した。行った処理は、フィラーの削除、句点の挿入、助詞の挿入、書き言葉表現への変換及び文体の統一である。ビームサーチを導入してこれらを統合的に行い、実際の講演の書き起こしを整形された文章に変換した。正解の文章として講演録編集者によって一次整形されたものを用いて、句点の挿入と助詞の挿入に関して定量的な評価を行った。句点の挿入においてはF値で0.835、助詞の挿入においてはF値で0.759という高い精度が得られた。また、実験的評価により、規則ベースの手法に比べて統計的なアプローチが有効であること、及び変換モデル確率P(x|y)の効果が示された。今後の課題としては、書き言葉表現への変換に関して人手により変換規則を作成するのではなく、大規模なコーパスから規則を抽出して変換確率P(x|y)を推定することや、文体の統一に関して不十分であった箇所に対応することが挙げられる。また、今回は正しい書き起こしを用いて評価を行ったが、今後は音声認識結果に適用していく予定である。</section>
</root>
