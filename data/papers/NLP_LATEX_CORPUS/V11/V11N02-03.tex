\documentstyle[epsfig,jnlpbbl]{jnlp_j}
\setcounter{page}{3}
\setcounter{巻数}{2}
\setcounter{号数}{3}
\setcounter{年}{1995}
\setcounter{月}{7}
\受付{1995}{5}{6}
\再受付{1995}{7}{8}
\採録{1995}{9}{10}

\setcounter{secnumdepth}{2}

\title{講演の書き起こしに対する統計的手法を用いた文体の整形}
\author{下岡 和也\affiref{KUIS} \and  南條 浩輝\affiref{KUIS} \and  河原 達也\affiref{KUIS}}

\headauthor{下岡 和也・南條 浩輝・河原 達也}
\headtitle{講演の書き起こしに対する統計的手法を用いた文体の整形}

\affilabel{KUIS}{京都大学 情報学研究科}
{School of Informatics, Kyoto University}

\jabstract{
講演音声のような話し言葉の書き起こしや音声認識結果には、話し言葉特有の表現が
数多く含まれており講演録などのアーカイブとして二次利用しにくいため、文章として適した形態に
整形する必要がある。本稿では、統計的機械翻訳の考え方に基づいて
講演の書き起こしを整形された文章に自動的に変換する方法を提案する。
本研究で扱う処理は、フィラーの削除、
句点の挿入、助詞の挿入、書き言葉表現への変換、文体の統一である。
これらの処理を統合的に行うようにビームサーチを導入した。
実際の講演の書き起こしを用いた
定量的な評価により統計的な手法の有効性が示され、句点と助詞の
挿入に関して高い精度を得ることができた。
}
\jkeywords{話し言葉, 音声認識, 統計的機械翻訳, 自動整形, 自動要約}

\etitle{Automatic Transformation of Lecture Transcription into \\ 
Document Style using Statistical Framework}
\eauthor{Kazuya Shitaoka\affiref{KUIS} \and Hiroaki Nanjo\affiref{KUIS} \and Tatsuya Kawahara\affiref{KUIS}} 

\eabstract{
Transcriptions and speech recognition results of lectures include many expressions
peculiar to spoken language.
Thus, it is necessary to transform them into document style
for practical use of them.
We apply the statistical approach used by machine translation
to automatic transformation of the spoken language into document style sentences.
We deal with deletion of fillers, insertion of periods, insertion of particles,
conversion to written expressions and unification of the end-of-sectence style.
A beam search is introduced to apply these processings in an integrated manner.
Experimental evaluation using real lecture transcriptions
comfirms that the statistical transformation framework
works well and we achieved high recall and precision rates of period and particle insertion.
}

\ekeywords{spontaneous speech, speech recognition, machine translation, text processing, summarization}

\begin{document}
\maketitle



\section{緒論}

音声認識研究の対象は、読み上げ音声から講演や会議などの話し言葉に移行している。
このような話し言葉は日本語では特に、文章に用いる書き言葉と大きく異なり可読性がよくない。
そのため、書き起こしや音声認識結果を講演録や議事録などのアーカイブとして二次利用する際には、
文章として適切な形態に整形する必要がある。実際に講演録や議事録の作成の際には、
人手によりそのような整形が行われている。

これまでに、放送ニュースなどを対象とした自動要約の研究が行われている
\cite{98-NL-126-10,98-NL-126-9,SP96-28,99-SLP-29-18,SP2000-116}。
これらは主に、頻出区間や重要語句の抽出といった処理、
つまり発話された表現をそのまま用いることによって要約を作成している。
しかし、話し言葉表現が多く含まれる場合には、要約を作成する際にまず話し言葉から
書き言葉へ変換する必要がある。実際に人間が要約を作成する際には、
このような書き言葉表現への変換に加えて、不必要な部分の削除や必要な語の挿入、
さらに1つの文書内での「ですます」調／「である」調などの文体の統一といった処理も行っている。

本研究では講演の書き起こしに対してこのような整形を自動的に行うことを考える。
現在、文章を整形するソフトウェアも存在しているが、これらはパターンマッチング的に
規則ベースで変換を行っており、言語的な妥当性や前後との整合性はあまり考慮されていない。
また、基本的に1対1の変換を行っているので、変換の候補が複数ある場合への対処が容易ではない。
学会講演とその予稿集との差分をとることで書き言葉と話し言葉の変換規則を自動抽出する
研究が村田らにより行われている\cite{murata_nl2002_diff,murata_nl2001_henkei}が、
変換の際の枠組みは本質的に同じと考えられ、また実際に変換を行い文章を整形する処理は実現されていない。
これに対して本研究では、規則に基づいて1対1の変換を行うのではなく、
話し言葉と書き言葉を別の言語とみなした上で統計的な機械翻訳の手法を適用し、
確率モデルによりもっともらしい表現に変換し実際に文章を整形することをめざす。

\section{整形作業における処理}

講演録編集者は、書き起こしから講演録や要約を作成する際に、通常次の4段階の作業を行う。

\begin{description}
\item [(1)  一次整形]
\item [(2)  長文の分割、文法的チェック、ポリティカルチェック]
\item [(3)  意味的チェック]
\item [(4)  要約の作成]
\end{description}

第一段階の一次整形では、フィラーの削除や書き言葉表現への変換、助詞の挿入などを行う。
第二段階の文法的チェックでは、言語的に正しくない助詞や接続詞を適切なものに修正する。
ポリティカルチェックでは、差別用語などの不適切な表現の修正を行う。
第三段階の意味的チェックでは、専門用語が正しく用いられているかの確認を行う。

実際に講演録編集者が、「日本語話し言葉コーパス」（CSJ）\cite{ICSLP2000}の
いくつかの講演について整形・要約したものを
参考にして、(a)から(i)で第一段階、(j)と(k)で第二段階の作業についてそれぞれ例を挙げながら
説明する。

\begin{description}
\item [(a) フィラーの削除 ] \verb+ +\\ 「あのー」や「えっと」といった間投語はすべて削除する。

\item [(b) 書き言葉表現への変換] \verb+ +\\ 次に挙げるような話し言葉表現の書き言葉表現への変換を行う。\\
(例)「行っ\underline{てるん}ですが」→「行っ\underline{ているの}ですが」\\
\verb+   +「規則合成\underline{っていう}方式」→「規則合成\underline{という}方式」\\
上記の例では話し言葉と書き言葉が1対1に対応しているが、そうでない場合を以下に示す。\\
(例)「このように\underline{いたして}\underline{おります}」→「このように\underline{して}\underline{います}」
「このように\underline{して}\underline{いる}」「このように\underline{して}\underline{おります}」\\
このような場合は、全体として「ですます調」か「である調」に統一されるように留意する。

\item [(c) 助詞の挿入] \verb+ +\\ 話し言葉では、しばしば助詞が脱落して発話されるので、適切な助詞を挿入する。\\
(例)「観測されたらそれ適当な分布で」→「観測されたらそれ\underline{を}適当な分布で」\\
\verb+   +「先程も話しありましたが」→「先程も話しがありましたが」

\item [(d) 句読点の挿入] \verb+ +\\ 書き起こしに句読点がない場合は、適当な箇所に句読点を挿入する必要がある。
 
\item [(e) 倒置部の修正] \verb+ +\\ 話し言葉では、倒置を用いて発話されることがあるので、通常の語順に修正する。\\
(例)「日本語は前寄りでも後寄りでも一応‘あ’なんですね\underline{音韻的には}。」                        
→「日本語は前寄りでも後寄りでも\underline{音韻的には}一応‘あ’なんですね。」

\item [(f) 言い淀みをしている部分の削除] \verb+ +\\ 話者が言い淀みをした部分は全て削除する。\\
(例)「このようなスペクトルの\underline{ドッ}、ギャップがですね」

\item [(g) 説明を付け加えている部分の削除]  \verb+ +\\ 言葉の説明を付け加えている部分を削除する。\\
(例)「モデル化を行い、\underline{そのモデル自体HMMですが}、そのモデルから」\\
このような表現は必ずしも削除されるわけではなく、別の表現に書き換えられることもある。\\
(例)「こういうHMM、\underline{我々はMSD-HMMと呼んでいる}」→「こういう\underline{HMM(MSD-HMM)}」

\item [(h) 独り言の部分の削除] \verb+ +\\ 本論と関係ないことを発話している部分を削除する。\\
(例)「えー、そろそろ時間なんですが、」

\item [(i) 言い直し部分の削除] \verb+ +\\ 言い直しをしている部分は削除する。\\
(例)「これは、テキスト\underline{テキスト}からの音声合成を」\\
\verb+   +「上唇の、\underline{ごめんなさい これ間違いです}」

\item [(j) 長文の分割] \verb+ +\\ 一文が非常に長い場合は、適切な接続詞を用いることでいくつかの単文に分割する。\\
(例)「〜日本人としてある意味で嬉しいところ\underline{あるんですけどもどうして}こういう技術が考え
られたかというと、〜」
→「〜日本人としてある意味で嬉しいところ\underline{があります。どうして}こういう技術が
考えられたかというと、〜」

\item [(k) 助詞・接続詞の修正]\verb+ +\\ より適切な助詞や接続詞がある場合は、それに訂正する。\\
(例)「どのようにして音声の合成を\underline{するかということが}」→「どのようにして音声の合成を\underline{するかが}」

\end{description}

本研究では、これらの過程のうち、(a)から(d)の一次整形の処理について取り扱う。
これらの処理だけでもかなり読みやすいものに整形される反面、これ以上の処理については、内容の理解を含めた
高度な処理が必要であると考えられるからである。
参考のために図\ref{kakiokosi}に書き起こし、図\ref{kouenroku}に整形された文章の例を示す。

\begin{figure}[t]
\small
\begin{center}
\begin{tabular}{l}
\hline
続い て え 結果 方 見 て いき たい と 思い ます ＜pause-647-msec＞ で えー まず \\
えーとー こちら あの 英語 話者 アメリカ 人 の えー 英語 話者 による え 語頭 に \\
Ｒ Ｌ を 含む 単語 えーっと Ｒ の ライト と Ｌ の ライト の 調音 について \\
＜pause-333-msec＞ えーっと 一 名 の 例 を 示し まし た ＜pause-513-msec＞で 縦 \\
軸 と この グラフ で いう 縦 軸 と 横 軸 という の は えー この ＜pause-304-msec＞ \\
調音 地図 という の の 元 に なっ て いる 距離 マトリックス ＜pause-385-msec＞ を \\
＜pause-255-msec＞ より 反映 する よう に その ＭＤＳ と いう まー ＜pause-654-msec＞ \\
え 手法 が え 抽出 し た えー 次元 一 と 二 と いう ふう に なり ます で 一つ一つ の \\
＜pause-326-msec＞ 点 グラフ 内 の 一つ一つ の 点 が ＜pause-306-msec＞ え 発話 の 一 回 \\
一 回 ＜pause-470-msec＞ を えー 示し て い て ＜pause-389-msec＞ え 同じ 単語 の えー \\
＜pause-203-msec＞ 点 を えー 見易い よう に ちょっと ＜pause-311-msec＞ 見易く えーっと \\
丸 で 囲ん で グルーピング し て おり ます ＜pause-1298-msec＞ \\
\hline
\end{tabular}
\caption{書き起こしの例}
\label{kakiokosi}
\end{center}
\vspace{-1.0mm}
\end{figure}

\begin{figure}[t]
\small
\begin{center}
\begin{tabular}{l}
\hline
続いて、結果の方を見ていきたいと思います。まず、こちらはアメリカ人の英語話者による \\
語頭に R、Lを含む単語、Rのライトと、Lのライトの調音について１名の例を示しました。\\
この グラフで縦軸 と横軸というのは、この調音地図のもとになっている距離マトリックスを \\
 より 反映するように、ＭＤＳという手法が抽出した次元１と２というようになります。\\
グラフ内の 一つ一つの点が 発話の一回一回を示していて、同じ単語の点を見やすく丸で \\
囲んでグルーピングしております。\\
\hline
\end{tabular}
\caption{人手により整形された文章の例}
\label{kouenroku}
\end{center}
\vspace{-1.0mm}
\end{figure}

\section{統計的手法による文体の整形}

\subsection{統計的機械翻訳のアプローチ}

現在、音声認識や機械翻訳の研究において
統計的な手法が広く用いられている。入力系列を$X$、出力系列を$Y$
とすると、これらは$X$を観測した際の$Y$の事後確率$P(Y|X)$を最大にする
$Y$を求めるという枠組みで捉えられ、ベイズ規則により次の式(1)のように
定式化される。ここで、$P(Y)$は系列$Y$が生起する事前確率、
$P(X|Y)$は系列$Y$から系列$X$が生起する条件付き確率である。
右辺の分母$P(X)$は、$Y$の決定に影響しないので無視できる。
\begin{equation}
\max_{Y}P(Y|X) = \max_{Y}{P(Y)P(X|Y)\over P(X)}
\end{equation}
音声認識\cite{text2}の場合は、$X$は入力音声、$Y$は
出力単語列となる。この場合は、
音響モデルにより$P(X|Y)$を、言語モデルにより$P(Y)$を求めている。

機械翻訳\cite{Brown,ICSLP98-209,ICSLP98-826}の場合は、$X$を入力言語、$Y$を出力言語として
$P(Y|X)$を最大にする$Y$を求めることで、入力言語$X$を出力言語$Y$に
変換する。この場合、$P(Y)$は出力$Y$の言語的な自然性を評価するもので、
音声認識と同様に言語モデルにより求める。
$P(X|Y)$の計算には変換モデルを仮定し、その確率を求める。
変換モデルとは、入力単語はある出力単語系列(nullを含む)に対応づけられる
という仮定の下で、どの単語に対応するかを文全体に
おける相対的な位置も考慮して確率で表したものである。

2章で述べたように、書き起こしの文体と整形した文章の文体はかなり
異なっており、書き起こしの単語列と整形された文章の単語列を
異なる言語とみなすことができる。そこで、本研究では書き起こしの文体を整形する際に、
書き起こしを整形した文章に翻訳すると考えて、
機械翻訳と同様に統計的手法を適用することを検討する。
ただし、一般の機械翻訳と異なり、本研究で扱う処理では単語の順序の
入れ替わりは考慮しない。

本研究では上記の変換確率と言語モデル確率を1対1で
組み合わせるのではなく、言語的妥当性を重視するために
言語モデル確率に重みを乗じることにする。
また、言語モデル確率の値として対数尤度を用いるが、
対数尤度は単語の数が多くなるほど値が小さくなるので、
単語数に応じた補正を行う。
これらは対数スケールで行われ、以下の式(2)で示される仮説スコアを定義する。
($a$,$b$)のパラメータは音声認識のデコーディングにおいて通常用いられ、
$a$は言語重み、$b$は挿入ペナルティと呼ばれている。
\begin{equation}
\max_{Y}\{\log(P(X|Y))+a*\log(P(Y))+b*(Yの単語数)\}
\end{equation}

本研究では、$Y$の言語モデルとして単語3-gramを用いる。
この場合、$Y$=($y_1 \cdots y_N$)について、
\(P(Y)=\prod_{i=1}^{N}P(y_i|y_{i-1},y_{i-2})\)として求められる。
変換モデル確率$P(X|Y)$の計算においても、同様に$X$=($x_1 \cdots x_M$)と
$Y$=($y_1 \cdots y_N$)の部分列に対する確率を規定して(デフォルトは
$P(x_i|y_j)=1$ for $x_i=y_j$)その積を求めるが、この単位は可変長(1から数単語)である。

以下では、フィラーの削除、書き言葉表現への変換、助詞の挿入、
句点の挿入、文体の統一のそれぞれの処理において、
この枠組みをどのように実現するかについて説明する。

なお本研究では、書き起こしを形態素解析した
結果を入力データとして用いている。形態素解析には、ChaSen ver2.02
を用いている。また、話者がポーズをおいた箇所にはその情報がポーズ長
とともに記録されている。

\subsection{フィラーの削除}

ここでは、$P(X|Y)$は整形文$Y$に対応する話し言葉$X$において
フィラーが挿入される確率とする。
フィラーは、発話のどの部分にも出現する可能性があるが、
特に句読点の後によく出現する傾向がある。

ただし、整形された文章にフィラーは一切出現しない。つまり、$Y$を
フィラーを含む単語列であると仮定すると、
$P(Y)$の値は0となり、$P(Y|X)$の値も0となる。
これは$P(X|Y)$の値にかかわらず書き起こしの単語列$X$から全てのフィラーが削除されることを意味している。

\begin{table}[t]
\small
\begin{center}
\caption{書き言葉への変換規則・確率の一部}\label{kakikae}
\vspace{2.0mm}
\begin{tabular}{|l|l|l|}					\hline
書き言葉($y$)		& 話し言葉($x$) 	& $P(x|y)$ 	\\\hline\hline
という			& っていう   		& 0.14		\\
			& という		& 0.86		\\\hline
が			& けども		& 0.036		\\
 			& けど 			& 0.042		\\
			& が			& 0.922		\\\hline
どのよう		& どういう風 		& 0.46		\\
			& どのよう		& 0.54		\\\hline
（〜し）ている		& （〜し）てる 		& 0.12		\\
			& （〜し）ている	& 0.88		\\\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[t]
\begin{center}
\caption{助詞の脱落パターンと確率の一部}\label{joshi}
\vspace{2.0mm}
\begin{tabular}{|l|l|}					\hline
パターン$y$		& 脱落確率$P(x|y)$		\\\hline\hline
名詞 は 名詞		& 0.073   			\\
名詞 を 名詞		& 0.032				\\\hline
名詞 は 動詞		& 0.056				\\
名詞 を 動詞 		& 0.042 			\\\hline
名詞 は 形容詞		& 0.20			 	\\
名詞 が 形容詞		& 0.024 			\\\hline
名詞 は 接続詞		& 0.16				\\\hline
\end{tabular}
\end{center}
\end{table}

\subsection{書き言葉表現への変換}

ここでは、$P(x|y)$($x$,$y$は１つ以上の単語からなる句)は
書き言葉表現の話し言葉表現への変換確率と解釈される。
講演録編集者が一次整形を行う際、文章の順序を入れ替える
操作は行わないので、元の書き起こしと講演録編集者により一次整形された文章を
照合し、句単位で対応づけを行うことで、$P(x|y)$の値を学習・推定することができる。
ただし本研究では、正解の講演録の数が完全な学習には不十分であったため、
あらかじめ人手により書き言葉から話し言葉への変換規則
を作成しておき、それらに対してのみ確率を推定することとした。
作成した変換規則数は64個あり、その一部を表\ref{kakikae}に示す。

\subsection{助詞の挿入}

ここでは、$P(x|y)$は整形された文章のある単語列パターン$y$に含まれる助詞が
話し言葉$x$において脱落する確率と解釈される。書き起こしと講演録編集者
により整形された文章を比較したところ、次のような「品詞」「助詞」「品詞」
のパターン$y$において助詞が脱落していた。
\begin{itemize}
\item 「名詞」(助詞)「名詞」\\ (例)「このお話し\underline{を}幹事の方から」
\item 「名詞」(助詞)「動詞」\\ (例)「我々\underline{は}作ってきたわけです」
\item 「名詞」(助詞)「形容詞」\\ (例)「非常に能力\underline{が}高くなって」
\item 「名詞」(助詞)「接続詞」\\ (例)「これ\underline{は}つまりサンプルごとの」
\end{itemize}

そこで、これらのパターンの助詞が脱落する規則をあらかじめ作成しておき、
それが生起する確率$P(x|y)$を書き起こしと一次整形の対応づけにより推定する。
用意した変換パターン数は13個あり、その一部を表\ref{joshi}に示す。
そして、それらの助詞を挿入する場合としない場合との尤度を比較することによって
助詞を挿入するかしないか、どの助詞を挿入するのか判定を行う。

\subsection{句読点の挿入}

「日本語話し言葉コーパス」（CSJ）の書き起こしには句読点がなく、
その代わりに話者のポーズ情報が記録されている。
ここでは、整形された文章の単語列$Y$に含まれる句読点が、
音声(書き起こしの単語列$X$)においてポーズに変換される確率$P(x=ポーズ|y=句読点)$を考える。
なお、本研究では句点のみを扱う。
なぜなら、句点を挿入する位置は人によらずほぼ一定であるが、
読点を挿入する位置は様々であり定量的な
評価を行うのが難しいためである。
音声認識における句点の挿入に関する研究は、
これまでにも行われているが\cite{nakashima_2001,takesawa_1999,Euro_1999}、
これらが扱っているのは旅行会話などの短い話し言葉であり、
講演のように長い話し言葉は扱っておらず、
また、主に言語モデル($P(Y)$に相当)による情報しか用いられていない。

文末には、「です」「ます」などのような典型的な
表現が多い反面、話し言葉においては独特の
表現が文の区切りになることがある。
文末での「〜と」と文頭での「で〜」である。
その例を以下に挙げる。\\
（例）「単位が使われていたと。あるいは」\\
\verb+    +「大きく違う。でそのままでは」

そこで、本研究では$P(x_i=ポーズ長|y_j=句点)$の確率において、
以下の3通りのモデル化を考える。$x_i$においてはポーズの長さの
情報も考慮する。

\begin{description}
\item[(1)  すべてのポーズを対象\verb+ +($x_i > 0$):]

整形した文章$Y$における句点が
あらゆる長さのポーズに変換されうると
する。この場合は、書き起こし$X$における
ポーズがすべて句点に変換されうることになり、
その判定を言語モデル確率$P(Y)$を用いて行う。
著者らが以前報告した講演音声の自動インデキシングの
研究\cite{hasegawa}では、この考え方が用いられている。

\item[(2)  平均以上の長さのポーズを対象\verb+ +($x_i > \theta$):]

句点の挿入箇所には、ある程度長いポーズが
おかれると考えられるので、変換確率$P(x_i=ポーズ長|y_j=句点)$において、
句点がある閾値$\theta$以上の長さのポーズに変換されるとする。
ここで、講演では発話速度が話者によってまちまちであり、
それに応じてポーズのおかれる長さも大きく異なるため、
すべての講演者に対して同一の値を閾値として用いるのは適切でない。
そこで、閾値として各話者ごとの平均ポーズ長を用いることにする。
予備実験においても、一定の値を閾値として
用いる場合には、平均ポーズ長が最良であった。
この場合、平均ポーズ長以上のポーズに対してのみ
$P(Y)$を考慮して句点に変換するか否かの判定を行う。

\item[(3)  表現に依存してポーズ長が変わると仮定\verb+ +($x_i > \theta$,\verb+  + 
$\theta$が$y_{j-1}$,$y_{j+1}$に依存):]

「です」「ます」などの典型的な文末表現に付随する句点はあらゆる
時間長のポーズになりうるが、書き言葉では通常文の区切り表現とならない
「〜と」「で〜」、あるいは文中にも頻繁に使われる「〜た」の部分にある句点は
平均ポーズ長以上の長さのポーズになると仮定する。この場合、「ます」「です」
などの後のポーズは長さに関係なく句点に変換されうるが、「〜と」「で〜」「〜た」
の部分のポーズは平均長以上のポーズに限り、句点に変換されうることになる。
この場合も、最終的には$P(Y)$を考慮して判定を行う。
\end{description}

上記3通りについて、4章で比較・評価する。

\subsection{文体の統一}

話し言葉を書き言葉に変換する際に、
その変換候補が複数ある場合には、どれを採用するかの
判定を言語モデル確率$P(Y)$に基づいて行う。
ここで、使用する言語モデルを異なる
ものにすると、変換結果も異なったものになる。

本研究では2種類の言語モデルを
用いることによって、それぞれ文体が「ですます」調あるいは「である」調
に統一することができるか検討する。
使用する言語モデルは、講演録の
コーパスから作成されたものと、新聞記事のコーパスから
作成されたものを用いる。
前者の言語モデルを用いると「ですます」調の文体に、
後者の言語モデルを用いると「である」調の文体に
統一されると期待される。

ただし、例えば「ですます」調の文でも
「〜であると思われます」といった表現があるため、
単純に「である」という表現をすべて「です」や「であります」という
表現に変えればよいわけではない。ここでは、
変換モデル確率において、表\ref{desumasu}
の各グループ(同一行)間で相互に変換可能としたが、
変換確率は等しいものとし、その選択は$P(Y)$に基づいて行うものとした。
なお、変換の際に動詞の語幹が変化する表現、
例えば「思います」→「思う」などの
表現については変換規則を用意していない。

\subsection{デコーディングアルゴリズム}

これまでに、講演の書き起こしから整形された
文章を生成する処理とモデルについて述べてきた。
本研究では、確率$P(Y)$の計算に単語3-gramモデル
を用いるので、これらの処理を逐次的に行うのではなく、
統合的に行うように実装する必要がある。
なぜなら、これらの処理を個別に行うと、
すぐ前後に別の処理をする必要の
ある表現が存在する場合、式(2)の尤度の計算に影響を
与えるからである。

したがって、前後2単語に着目する必要のある表現が
存在しなくなる範囲において、そのすべての変換パターン
の尤度を比較して出力単語列を決定する。
その様子を図\ref{renzoku}に示す。
変換で複数の候補が生成されうることも考慮すると、可能な仮説の数は
組み合わせ的に爆発するので、探索アルゴリズムを導入する必要がある。
本研究ではビームサーチを行う。具体的には、
生成したパターンの数が100を越えた場合は、そこまでの範囲で尤度を計算し、上位100個の
パターンのみを選択することにした。

\begin{table}[t]
\begin{center}
\caption{「ですます」調・「である」調の変換パターン}\label{desumasu}
\vspace{2.0mm}
\begin{tabular}{|l|}			\hline
です・であります・である・だ		\\\hline
でした・でありました・であった・だった  \\\hline
します・いたします・する		\\\hline
しました・いたしました・した		\\\hline
おります・います・いる			\\\hline
おりました・いました・いた		\\\hline
あります・ございます・ある		\\\hline
ありました・ございました・あった	\\\hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}[t]
\begin{center}
      \scalebox{1.0}{\includegraphics{renzoku.eps}}
    \end{center}
    \caption{変換の仮説生成}
    \label{renzoku}
\end{figure}

\section{実験と評価}

\subsection{データと実験条件}

以上の手法を用いて講演の書き起こしを整形し、その評価を行った。
評価データとして、CSJに含まれる実際に学会で行われた4講演を用いた。評価データの概要および
処理時間を表\ref{kouen}に示す。なお使用したマシンのCPUはIntel Xeon2.8GHz、メモリは2GBである。
また、$P(Y)$の計算に用いる言語モデルは、毎日新聞記事データで
学習されたもの\cite{kawahara}と、Web講演録で学習されたもの\cite{katou}の2種類であるが、
4.5節以外ではWeb講演録の方を使用している。
$P(X|Y)$推定のための講演の書き起こしと整形文章のデータは評価データ以外のCSJの18講演を用いている。
次節以降、行った実験の結果と評価について述べる。
なお、3.2節のフィラーの削除は完全に機械的に行える。また、3.3節の書き言葉表現への変換もおおむね行えた。

\subsection{デコーディングパラメータについて}

3.1節で述べた式(2)の2つのパラメータについてまず検討した。
評価尺度として、句点の挿入および助詞の挿入についてのF値の平均を用いる。
句点挿入のモデルは最もよいものを用いている。
様々な言語重み・挿入ペナルティの値について行った実験結果を図\ref{parameter}に示す。
結果として(言語重み,挿入ペナルティ)=(5,8)の時にF値が最大となった。
したがって、以降の実験はこれらの値を用いて行う。 表4の処理時間もこの場合の計測値である。

\begin{figure}[t]
\begin{center}
      \scalebox{0.5}{\includegraphics{FM3.eps_new}} 
    \end{center}
    \vspace{-1.0mm}
    \caption{パラメータの種々の値に対する句点および助詞挿入のF値の平均}
    \label{parameter}
\end{figure}

\begin{table}[t]
\small
\centering
\caption{評価データの概要および処理時間}\label{kouen}
\begin{tabular}{|r||r|r|r|r|} \hline
&\multicolumn{2}{c|}{講演}&整形文&処理時間 \\ \cline{2-4}
&\multicolumn{1}{c|}{時間}&サイズ&サイズ& (sec)\\ \hline \hline
 A01M0035		  &28分    &5557語 &5378語 &17.42\\ \hline
 A01M0007		  &30分    &3899語 &3802語 &13.65\\ \hline
 A01M0074		  &13分    &2509語 &2451語 &5.97\\ \hline
 A05M0031	 	  &27分    &5371語 &4854語 &19.99\\ \hline
\end{tabular}
\vspace{-4.0mm}
\end{table}

\subsection{句点の挿入}

3.5節で述べた3通りの句点挿入の実験結果を表\ref{pause}に示す。

ポーズ長制限なしで挿入する場合は適合率が低い。その主な原因は、
「〜と」「〜た」の後と「で〜」の前のポーズが誤って句点に
変換されることが多いためである。「ます」「です」
などの後のポーズが誤って句点に変換されることはなかった。
「〜た」という表現は文末表現であるが、同時に文中にもよく使われるため、
例えば「〜使われてきた$<$pause$>$データベースが〜」→「〜使われてきた。データベースが〜」
のような誤りが起こる。また、「〜と」の場合は、
例えば、「〜しようと思うと$<$pause$>$このように〜」→「〜しようと思う。このように〜」
のような場合に誤ってポーズが句点に変換された。

一方、平均ポーズ長以上に挿入する場合においては再現率が低い。
その主な原因は、「ます」「です」などの、通常書き言葉で文末表現
になるものの後で、ポーズ長が短い箇所が対象外になったためである。
したがって、「です」「ます」などの典型的な文末表現部分にある句点は
あらゆる時間長のポーズになりうるが、「〜と」「で〜」「〜た」の部分に
ある句点は平均ポーズ長以上の長さのポーズになるとするモデルを導入した。
その結果、再現率・適合率とも高い精度を得ることができた。

\begin{table}[t]
\small
\caption{句点挿入の実験結果}
\centering
 \begin{tabular}{|l||c|c|c|}
\hline
			&再現率			&適合率		&F値		\\\hline\hline
ポーズ長制限なし	& 309/371		& 309/410	&0.791		\\
			& (83.2\%)		& (75.4\%)	&		\\\hline
平均ポーズ長以上	& 239/371		& 239/255	&0.763		\\
			& (64.4\%)		& (93.7\%)	&		\\\hline
表現に依存して変化	& 283/371		& 283/306	&0.835		\\
			& (76.3\%)		& (92.3\%)	&		\\\hline	
 \end{tabular}
 \label{pause}
\vspace{-3.0mm}
\end{table}

\subsection{助詞の挿入}

次に、3.4節で述べた助詞の挿入に関する評価を行った。
助詞が脱落している箇所は4講演で計47箇所あった。それらに対して、

・プロの編集者が作成した講演録において挿入されている助詞

・上記に含まれないが、意味的に妥当な助詞 \\
を正解としてそれぞれ再現率を評価した。

また、挿入されたすべての助詞に対して

・意味的に妥当である

・許容範囲である \\
の2段階で適合率を評価した。

これらの評価基準に対して、統計的手法の有効性を調べるために、
3.4節で述べたパターンの変換確率$P(x|y)$に関して次の2つの場合の比較を行った。
\begin{description}
\item[(1) $P(x|y)$の値として、統計的に推定したものを用いる]
\item[(2) あらかじめ$P(x|y)$の値を全て1に設定する]
\end{description}

\begin{table}[t]
\footnotesize
\begin{center}
\caption{助詞挿入の実験結果}
 \begin{tabular}{|l||c|c|c|}
\hline
 $P(x|y)$の値		&再現率			&適合率			&F値		\\\hline\hline
 統計的に推定		& 37/47(78.7\%)		& 68/123(55.3\%)	&0.650		\\
 			& (プロの講演録と一致)	& (意味的に妥当)	&		\\
  			& 42/47(89.4\%)		& 81/123(65.9\%) 	&0.759		\\
			& (意味的に妥当)	& (許容範囲)		&		\\\hline
 あらかじめ		& 33/47(70.2\%)		& 83/187(44.4\%)	&0.544		\\
 全て1に設定		& (プロの講演録と一致)	& (意味的に妥当)	&		\\
 			& 42/47(89.4\%)		& 109/187(58.3\%)	&0.706		\\
			& (意味的に妥当)	& (許容範囲)		&		\\\hline
 \end{tabular}
 \label{joshikekka}
\end{center}
\vspace{-7.0mm}
\end{table}

結果を表\ref{joshikekka}に示す。適合率で大きな差が見られ、
許容範囲のものまで正解にした場合において$P(x|y)$も用いた場合の方が
7.6\%向上している。さらに、挿入された
絶対数も約2/3に減少しており、実際に生成されたテキストの
読みやすさという観点において大きく改善されている。

誤って助詞が挿入された
箇所の多くは「名詞」「名詞」のパターンであった。
学会講演において用いられる
専門用語の多くが複合名詞であるため、形態素解析
を行うと「名詞」「名詞」と分解され、助詞の挿入箇所の候補になる。
そこで、「名詞」「名詞」と連続しているもののうち、
3回以上出現すればその箇所は専門用語であると判断するようにした。これにより
多くの専門用語は助詞の挿入箇所の候補にならなくなったが、
1〜2回しか使われていない専門用語や、人名・機関名などの固有名詞
が複数の形態素に分解された結果、助詞が挿入されることがあった。
例えば「データ ベース」や「東京 大学」などである。参考までに、誤り箇所から
これらの複合名詞の箇所を除いて集計すると、適合率は許容範囲のものまでを
正解とした場合で79.4\%(81/102)となった。

\subsection{言語モデルの使いわけ}

次に、3.6節で述べた言語モデルの違いによる文体の変化について評価を行った。結果を表\ref{buntai}に示す。
\begin{table}[t]
\small
\caption{言語モデルの違いの影響}
\centering
 \begin{tabular}{|l||c|c|}
\hline
 $P(Y)$のモデル		& 「ですます」調 	& 「である」調		\\\hline\hline
 新聞記事モデル		& 52.3\%		& 47.7\%		\\\hline
 講演録モデル		& 81.1\%		& 18.9\%		\\\hline
 \end{tabular}
 \label{buntai}
\vspace{-3.0mm}
\end{table}

入力データでは「ですます」調が81.5\%、「である」調が18.5\%であった。

講演録言語モデルを用いて整形した場合は81.1\%が「ですます」調に、
新聞記事言語モデルを用いて整形した場合は47.7\%が「である」調になった。
入力データが基本的に「ですます」調であるため、講演録モデルを用いた場合は
ほとんど変換されていない。
一方、新聞記事モデルを用いた場合は、「である」調の割合が30\%程度増えている。
しかし、全体の半分程度しか「である」調にならないのは、
3.6節でも述べたように、今回の変換モデルでは動詞の語幹が変化する表現
に対応していないためである。

\subsection{規則ベースの手法との比較}

最後に、完全な規則ベースによる手法を用いて実験を行い、
本論文で提案した統計的手法との比較を行う。
ここでは、句点の挿入および助詞の挿入について評価した。

句点の挿入については次の規則を用いた。 3.5節及び4.3節における
考察に基づいて、ポーズの閾値についても最も妥当なものにした。

・「です」「ます」などの典型的な文末表現の後のポーズは全て句点に変換

・「〜と」「〜た」「で〜」の部分のポーズは、平均ポーズ長以上なら句点に変換

また助詞の挿入については、コンテキストを考えずに
言語モデルの学習テキストにおいて出現頻度が高いものを挿入規則として抽出した。
例えば学習テキスト中において、「名詞 助詞 動詞」の並びで出現頻度が最大となる
助詞は「が」であったため、「名詞 動詞」となっている箇所には、
その前後のコンテキストは考えずに、出現回数が最大の「が」を挿入するという規則を抽出した。

以上の手法により行った実験結果と提案手法との比較を表\ref{comp_kuten}、表\ref{comp_joshi}に示す。
句点の挿入に関しては、規則ベースの方が再現率は若干高いものの、適合率が大幅に低下しており、
誤った挿入がおよそ4倍に増えている。助詞の挿入に関しては、F値が0.759から0.696に低下している。
以上より、提案手法の有効性が確認された。

\begin{table}[t]
\small
\caption{規則ベースと提案手法との比較(句点挿入)}
\centering
 \begin{tabular}{|l||c|c|c|}
\hline
			&再現率			&適合率			&F値		\\\hline\hline
規則ベース		& 301/371(81.1\%)	& 301/392(76.8\%)	&0.789		\\\hline
提案手法		& 283/371(76.3\%)	& 283/306(92.3\%)	&0.835		\\\hline
 \end{tabular}
 \label{comp_kuten}
\vspace{-3.0mm}
\end{table}

\begin{table}[t]
\small
\caption{規則ベースと提案手法との比較(助詞挿入)}
\centering
 \begin{tabular}{|l||c|c|c|}
\hline
			&再現率			&適合率			&F値		\\\hline\hline
規則ベース		& 26/47(55.3\%)		& 60/91(65.9\%)		&0.601		\\
			& (プロの講演録と一致)	& (意味的に妥当)	&		\\
			& 31/47(66.0\%)		& 67/91(73.6\%)		&0.696		\\
			& (意味的に妥当)	& (許容範囲)		&		\\\hline
提案手法		& 37/47(78.7\%)		& 68/123(55.3\%)	&0.650		\\
			& (プロの講演録と一致)	& (意味的に妥当)	&		\\
			& 42/47(89.4\%)		& 81/123(65.9\%)	&0.759		\\
			& (意味的に妥当)	& (許容範囲)		&		\\\hline
 \end{tabular}
 \label{comp_joshi}
\vspace{-3.0mm}
\end{table}

\begin{figure}[t]
\small
\begin{center}
\begin{tabular}{l}
\hline
続い て 結果 の 方 を 見 て いき たい と 思い ます 。 まず こちら 英語 話者 \\
アメリカ 人 の 英語 話者 による 語頭 に Ｒ Ｌ を 含む 単語 Ｒ の ライト \\
と Ｌ の ライト の 調音 について 一 名 の 例 を 示し まし た 。縦 軸 と この \\
グラフ で いう 縦 軸 と 横 軸 という の は この 調音 地図 という の の 元 に \\
なっ て いる 距離 マトリックス を より 反映 する よう に ＭＤＳ と いう 手法 が \\
抽出 し た 次元 一 と 二 と いう よう に なり ます で 一つ 一つ の 点 の グラフ \\
内 の 一つ一つ の 点 が 発話 の 一 回 一 回 を 示し て い て 同じ 単語 の 点 \\
を 見易い よう に 見易く 丸 で 囲ん で グルーピング し て い ます 。\\

\hline
\end{tabular}
\caption{提案手法による整形結果}
\label{output}
\end{center}
\vspace{-1.0mm}
\end{figure}

\subsection{整形結果の具体例}

ここでは、提案手法により図１で示した書き起こしを整形した具体例を図\ref{output}に示す。
なお、本来入力は形態素解析結果であるが、図１では見やすくするために
活用形や形態素番号などの情報は省いて示している。
句点の挿入はおおむね正しく行えており、また、「結果 の 方 見 て い き たい」
に「を」が挿入されているなどの整形が行えている。しかし、「に なり ます で １つ １つ」
の所では、ポーズが本来の文末位置とは少しずれた所にあるため、句点が正しく挿入されていない。
また、この場合、「調音 地図」というパターンが３回以上出現しているため、
これを専門用語であるとみなして助詞の挿入箇所の候補にはしていない。
ただし、図２と比較すると言い直し部分の削除などを行っていない。

\section{結論}

統計的な機械翻訳の考え方に
基づいて文体の整形を自動的に行う手法を提案した。
行った処理は、フィラーの削除、句点の挿入、助詞の挿入、書き言葉表現への変換及び文体の統一である。
ビームサーチを導入してこれらを統合的に行い、実際の講演の書き起こしを整形された文章に変換した。
正解の文章として講演録編集者によって一次整形されたものを用いて、
句点の挿入と助詞の挿入に関して定量的な評価を行った。
句点の挿入においてはF値で0.835、助詞の挿入においては
F値で0.759という高い精度が得られた。
また、実験的評価により、規則ベースの手法に比べて統計的なアプローチが
有効であること、及び変換モデル確率$P(x|y)$の効果が示された。

今後の課題としては、書き言葉表現への変換に関して
人手により変換規則を作成するのではなく、大規模なコーパス
から規則を抽出して変換確率$P(x|y)$を推定することや、
文体の統一に関して不十分であった箇所に対応することが挙げられる。
また、今回は正しい書き起こしを用いて評価を行ったが、今後は
音声認識結果に適用していく予定である。


\vspace{5.0mm}
\acknowledgment

本研究は，開放的融合研究『話し言葉工学』プロジェクト
の一環として行われた。
東京工業大学の古井貞煕教授をはじめとして、
ご協力を頂いた関係各位に感謝いたします。


\bibliographystyle{jnlpbbl}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Chen}{Chen}{1999}]{Euro_1999}
Chen, C. \BBOP 1999\BBCP.
\newblock \BBOQ {Speech Recognition with Automatic Punctuation}\BBCQ\
\newblock In {\Bem Proc. Eurospeech}.

\bibitem[\protect\BCAY{I.Garcia-Varea, F.Casacuberta, \BBA\
  H.Ney}{I.Garcia-Varea et~al.}{1998}]{ICSLP98-209}
I.Garcia-Varea, F.Casacuberta, \BBA\ H.Ney \BBOP 1998\BBCP.
\newblock \BBOQ {An Iterative, DP-Based Search Algorithm For Statistical
  Machine Translation}\BBCQ\
\newblock In {\Bem Proc. ICSLP}, \lowercase{\BVOL}~4.

\bibitem[\protect\BCAY{P.Brown, S.Pietra, V.Pietra, \BBA\ R.Mercer}{P.Brown
  et~al.}{1993}]{Brown}
P.Brown, S.Pietra, V.Pietra, \BBA\ R.Mercer \BBOP 1993\BBCP.
\newblock \BBOQ {The Mathematics of Statistical Machine Translation : Parameter
  Estimation}\BBCQ\
\newblock In {\Bem Proc. Computational Linguistics}, \lowercase{\BVOL}~19.

\bibitem[\protect\BCAY{S.Furui, K.Maekawa, \BBA\ H.Isahara}{S.Furui
  et~al.}{2000}]{ICSLP2000}
S.Furui, K.Maekawa, \BBA\ H.Isahara \BBOP 2000\BBCP.
\newblock \BBOQ {Toward the realization of spontaneous speech recognition -
  introducing of a japanese priority program and preliminary results -}\BBCQ\
\newblock In {\Bem Proc. ICSLP}, \lowercase{\BVOL}~3.

\bibitem[\protect\BCAY{Y.Wang \BBA\ A.Waibel}{Y.Wang \BBA\
  A.Waibel}{1998}]{ICSLP98-826}
Y.Wang\BBACOMMA\  \BBA\ A.Waibel \BBOP 1998\BBCP.
\newblock \BBOQ {Fast Decoding For Statistical Machine Translation}\BBCQ\
\newblock In {\Bem Proc. ICSLP}, \lowercase{\BVOL}~6.

\bibitem[\protect\BCAY{加藤, 南條, 河原}{加藤\Jetal }{2000}]{katou}
加藤一臣, 南條浩輝, 河原達也 \BBOP 2000\BBCP.
\newblock \JBOQ {講演音声認識のための音響・言語モデルの検討}\JBCQ\
\newblock \Jem{信学技報}, SP2000-97, NLC2000-49 (SLP-34-23).

\bibitem[\protect\BCAY{若尾, 江原, 白井}{若尾\Jetal }{1998}]{98-NL-126-9}
若尾孝博, 江原暉将, 白井克彦 \BBOP 1998\BBCP.
\newblock \JBOQ {短文分割を利用したテレビ字幕自動要約}\JBCQ\
\newblock \Jem{情報処理学会研究報告}, 98-NL-126-9.

\bibitem[\protect\BCAY{竹沢 他}{竹沢\JBA 他}{1999}]{takesawa_1999}
竹沢寿幸\BBACOMMA\  他 \BBOP 1999\BBCP.
\newblock \JBOQ {発話単位の分割または接合による言語処理単位への変換手法}\JBCQ\
\newblock \Jem{言語処理学会誌}, {\Bbf 6巻}  (2号), 83--95.

\bibitem[\protect\BCAY{中嶋 山本}{中嶋\JBA 山本}{2001}]{nakashima_2001}
中嶋秀治\BBACOMMA\  山本博史 \BBOP 2001\BBCP.
\newblock \JBOQ {音声認識過程での発話分割のための統計的言語モデル}\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 42巻}  (11号), 2681--2688.

\bibitem[\protect\BCAY{長谷川, 秋田, 河原}{長谷川\Jetal }{2001}]{hasegawa}
長谷川将宏, 秋田祐哉, 河原達也 \BBOP 2001\BBCP.
\newblock \JBOQ {談話標識の抽出に基づいた講演音声の自動インデキシング}\JBCQ\
\newblock \Jem{情報処理学会研究報告}, 01-SLP-36-6.

\bibitem[\protect\BCAY{村田}{村田}{2002}]{murata_nl2002_diff}
村田真樹 \BBOP 2002\BBCP.
\newblock \JBOQ {diff を用いた言語処理 --- 便利な差分検出ツール mdiff の利用
  ---}\JBCQ\
\newblock \Jem{言語処理学会誌}, {\Bbf 9巻}  (2号), 91--110.

\bibitem[\protect\BCAY{村田 井佐原}{村田\JBA
  井佐原}{2001}]{murata_nl2001_henkei}
村田真樹\BBACOMMA\  井佐原均 \BBOP 2001\BBCP.
\newblock \JBOQ
  {同義テキストの照合に基づくパラフレーズに関する知識の自動獲得}\JBCQ\
\newblock \Jem{情報処理学会研究報告}, 2001-FI-61, 2001-NL-142.

\bibitem[\protect\BCAY{中沢, 遠藤, 古川, 豊浦, 岡}{中沢\Jetal }{1996}]{SP96-28}
中沢正幸, 遠藤隆, 古川清, 豊浦潤, 岡隆一 \BBOP 1996\BBCP.
\newblock \JBOQ
  {音声波形からの音素片記号系列を用いた音声要約と話題要約の検討}\JBCQ\
\newblock \Jem{電子情報通信学会技術報告}, SP96-28.

\bibitem[\protect\BCAY{鹿野, 伊藤, 河原, 武田, 山本}{鹿野\Jetal }{2001}]{text2}
鹿野清宏, 伊藤克亘, 河原達也, 武田一哉, 山本幹雄 \BBOP 2001\BBCP.
\newblock \Jem{「音声認識システム」}.
\newblock オーム社.

\bibitem[\protect\BCAY{河原 他}{河原\JBA 他}{2000}]{kawahara}
河原達也\BBACOMMA\  他 \BBOP 2000\BBCP.
\newblock \JBOQ
  {日本語ディクテーション基本ソフトウェア(99年度版)の性能評価}\JBCQ\
\newblock \Jem{情処学研報}, SLP-31-2, NL-137-7.

\bibitem[\protect\BCAY{堀 古井}{堀\JBA 古井}{1999}]{99-SLP-29-18}
堀智織\BBACOMMA\  古井貞煕 \BBOP 1999\BBCP.
\newblock \JBOQ {話題語と言語モデルを用いた音声自動要約法の検討}\JBCQ\
\newblock \Jem{情報処理学会研究報告}, 99-SLP-29-18.

\bibitem[\protect\BCAY{堀 古井}{堀\JBA 古井}{2000}]{SP2000-116}
堀智織\BBACOMMA\  古井貞煕 \BBOP 2000\BBCP.
\newblock \JBOQ {係り受けSCFGに基づく音声自動要約法の改善}\JBCQ\
\newblock \Jem{電子情報通信学会技術報告}, SP2000-116.

\bibitem[\protect\BCAY{加藤}{加藤}{1998}]{98-NL-126-10}
加藤直人 \BBOP 1998\BBCP.
\newblock \JBOQ {ニュース文要約のための局所的要約知識獲得とその評価}\JBCQ\
\newblock \Jem{情報処理学会研究報告}, 98-NL-126-10.

\end{thebibliography}

\begin{biography}
\biotitle{略歴}
\bioauthor{下岡 和也}
{
2002年 京都大学工学部情報学科卒業.
現在, 同大学院情報学研究科知能情報学専攻修士課程在籍.
音声認識・理解の研究に従事．
}
\bioauthor{南条 浩輝}
{
1999年 京都大学工学部情報学科卒業．
2001年 同大学院情報学研究科修士課程了．
現在，同博士後期課程在学中．
音声認識・理解の研究に従事．
情報処理学会，日本音響学会各会員．
}
\bioauthor{河原 達也}
{
1987年 京都大学工学部情報工学科卒業．
1989年 同大学院修士課程修了．
1990年 同博士後期課程退学．
同年   京都大学工学部助手．
1995年 同助教授．
1998年 同大学情報学研究科助教授．
2003年 同大学学術情報メディアセンター教授．
現在に至る．
この間，
1995年から96年まで 米国ベル研究所客員研究員．
1998年から ＡＴＲ客員研究員．
1999年から 国立国語研究所非常勤研究員．
2001年から 科学技術振興事業団さきがけ研究21研究者．
音声認識・理解の研究に従事．

京大博士（工学）．
1997年度 日本音響学会粟屋賞受賞．
2000年度 情報処理学会坂井記念特別賞受賞．
情報処理学会連続音声認識コンソーシアム代表．
IEEE SPS Speech TC委員．
情報処理学会，電子情報通信学会，日本音響学会，人工知能学会，言語処理学会，IEEE各会
}


\end{biography}

\end{document}
