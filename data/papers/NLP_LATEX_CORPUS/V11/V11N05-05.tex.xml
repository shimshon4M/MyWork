<?xml version="1.0" ?>
<root>
  <title/>
  <author/>
  <jkeywords/>
  <section title="Introduction">Therearemanyproblemsinnaturallanguageprocessingforwhichhavingaparaphrasewouldbeveryusefulinformation.Taskssuchasdetailedparsingormachinetranslationoftenfailorstruggleonsomesentencesduetoacombinationoftheirlengthandthenatureofthesentenceitself.Havingaparaphraseathandwouldgivesuchsystemsasecondchance,orachancetogeneratepossibilitiesnotconsideredusingonlytheoriginalsourcesentence.Possibleusesofaparaphraserincludesentencesummarization,corpusnormalizationandimprovingautomaticmachinetranslationevaluationbyexpandingthereferencesetwithparaphrases,oneofthemainthemesofthispaper.Thisarticlepresentstwoautomaticparaphrasers,onebasedontheprinciplesofstatisticalmachinetranslation,theotherbasedondata-orientedtranslationmethods.Weevaluatetheperformanceoftheparaphrasersusingbothhumanandautomaticmethods,andapplythebestparaphrasertothetaskofimprovingmachinetranslationevaluation.Thisarticlethereforeisdividedintotwoparts,thefirstpartconsistingofSections~to,comparesthequalityofparaphrasesproducedbytheautomaticparaphraserstothoseproducedbybothhumans,andasimplebaselinemodel.Section~introducestheconceptofparaphrasingasmachinetranslation.Section~explainsthedata-orientedapproachtoparaphrasingindetail.Sectionpresentstheexperimentalevaluationoftheautomaticparaphrasers,anddiscussestheseresults.Inthesecondpartofthearticle,Section,weinvestigatetheapplicationofthedata-orientedparaphrasertotheimprovementofmachinetranslationevaluation.Welookattheeffectofaddingautomaticallygeneratedparaphrasestothereferencesetsusedformachinetranslationevaluation.Section~givesabriefoverviewoftheseexperiments.Sectionexplainstheexperimentalmethodology,describingthenatureofthedata,thescoringmethods,themachinetranslationsystemsinvolvedintheexperimentsandthestatisticalmethodsemployedtoevaluatetheresults.Sectionpresentstheresults.Sectiondescribesanexperimentdesignedtoinvestigatethepropertiesofparaphrasesthatmightmakethemusefulformachinetranslationevaluation.Finally,Sectionofferssomeconcludingremarksanddirectionsforfutureresearch.</section>
  <section title="Paraphrasing by Statistical Machine Translation">Itispossibletoviewtheprocessofparaphrasingasamachinetranslationtask.Thisistheapproachadoptedthroughoutthispaper.Inthisparadigm,aparaphraseofatextualsegment(inourcase,asinglesentence)isderivedbyaprocessoftranslationfromthesourcelanguagedirectlyintothesamelanguage.Thisprocessisdirectinthesensethatitisone-step,ratherthana``round-trip''translationfromonelanguageintothesamelanguageviaanexplicitsecondintermediateinterlingualstage.evaluateaparaphraser(wewilldenotethisSMTP)basedonstatisticalmachinetranslation(SMT)techniques.useasimilartechnique,directlyusingSMTtogenerateparaphraseswithaphrase-baseddecoder.Inourcase,thepubliclyavailableGIZA++software~wasusedtobuildthemodelstobeusedfortranslationtogetherwithanin-house-developedmulti-stackdecoder.Thestatisticalmachinetranslationtechniquelearnstotranslatebyderivingstatisticsfromalargecorpusofsentencepairs,onesentenceinthepairbeingasentenceinthesourcelanguage,theothersentenceinthepairbeingthetranslationofthesourcesentenceinthetargetlanguage(inourcasethisisaparaphraseofthesourcesentence).Thesestatisticsarethencombinedinareverse-channelmodeltoprovidethemostprobabletranslation.In,acorpusofJapanesesentencepairswaspreparedfromacorpusconsistingofgroupsofparaphrases,byclusteringthesentenceswithinthegroupforsimilarity,andpairingsimilarsentencesfromtheseclusters.Thesentencesineachpairbeingparaphrasesofeachother.TheSMTPwasthentraineddirectlyfromthesesentencepairs.TheparaphrasesfromtheSMTPsystemwerecomparedtothosegeneratedbyhumanannotatorsandalsotothosefromasimplebaselinemodelbasedonmaximumbi-gramprobabilityusedin~.ThebestparaphrasefromeachofthesourceswasgradedforadequacyaccordingtothescaledefinedinSection~.TheresultsshowedtheparaphrasesfromtheSMT-basedsystemweresuperiortothoseofthebaselinemodel.Wewillusethissystemastheprimarybenchmarkbywhichtojudgethedata-orientedparaphraserpresentedinthefollowingsections.</section>
  <section title="Data-Oriented Paraphrasing">Manyalternativetechniquesareavailableformachinetranslation.Thispaperinvestigatestheapplicationofdata-orientedtranslationmethodstoparaphrasing.ThebasicprincipleisthesameastheSMT-basedapproach,withonlytheunderlyingmachinetranslationmethodologybeingdifferent.Thedata-orientedtranslation(DOT)modelisbasedondata-orientedparsing(DOP).Theprincipleunderlyingdata-orientedparsingisthatparsesforpreviouslyunseensentencescanbeconstructedinaprobabilisticmannerbycombiningfragments(thataresubtrees)ofparsetreesextractedfromsentencesofatreebankcorpus.Thefragments,ineffect,formagrammarfromwhichparsetreesforunseensentencescanbebuilt.Eachparsemayhavemanypossiblederivations,andtheparseprobabilityisthesumoftheprobabilitiesofeachofitsderivations.ThelatestincarnationsoftheDOPparserhaveperformancecomparabletothestateoftheartinstatisticalparsers.Themodusoperandiofthedata-orientedtranslationtechniqueissimilartoDOP.However,inthiscase,twotreesareconstructedatthesametime:atreeforthesentenceinthesourcelanguage,andthecorrespondingtreeforthesentenceinthetargetlanguage.Thefragmentsinthiscasecontainlinksbetweensemanticallyequivalentnodesinthesourceandtargetfragments,theideabeingthatlinkednodescanbeinterchangedwithoutlossofmeaning.ApairoflinkedtreesisillustratedbytheupperpairinFigure~.Thefollowingsectionsexplainthenatureofthesefragments,theiruseinconstructingnewparaphrases,andthemethodusedtoextractthemfromthetrainingcorpus.</section>
  <subsection title="Automatic Phrase Alignment">Theprocessoffragmentgenerationstartsfromacorpusofsentencepairs.ThenatureofthetrainingdataisthesameasfortheSMTapproach.However,thesesentencepairsareprocessedbyathree-stepprocessinordertogeneratethefragmentsneededbythedata-orientedparaphraser.Thefirststepinvolvesparsingthesentenceswithaphrase-structuregrammar.Inthesecondstepweautomaticallyalignthewordsofthesentencesineachpair.Thethirdstepistoalignthenon-leafnodesintheparsetrees,usinganalignmentofthewords.Incontrastto,weautomaticallylabelthelinksbetweenequivalentnodesofthesubtreesusingatechniquebasedon.Handlabelingtheselinksisextremelylaborintensive,andbeingabletolabelthemautomaticallygivesustheabilitycreatealargecorpuswithoutextensivehumaneffort.Thecorpususedfortheexperimentsreportedin~isonly266treepairs.Wewereabletouseacorpusofaround300,000treepairsfortheseexperiments.Ouraimistomapnodesinthesourceparsetree,denotedT^s=(V^s,E^s)tonodesinthetargettree,T^t=(V^t,E^t).WhereV^s=v^s_1,v^s_2,v^s_n,andV^t=v^t_1,v^t_2,v^t_marethevertexsetsofthesourceandtargettreesrespectively,andE^sandE^taretheiredgesets.Thealgorithmdefinesamappingbetweenasubsetofthenodesofthesourceandtargettrees;:V^sV^t,andproceedsasfollows:Parsethesentences--Forthepurposesoftheseexperimentsweusedthepubliclyavailableparserof~.Alignthewordsinthesentences--WechosetousethewordalignmentsoutputbytheEGYPTmachinetranslationsoftware~.AsetLoflinkedwordpairsisproduced.Selecti(0&lt;i&lt;L)wordlinksfromamongallofthelinks,collectallofthesyntacticnodes(non-terminalsymbols)thatincludethelinks,andexcludeallotherwordlinksintheleavesfromtheparsedtrees.Comparethesyntacticcategoriesofallnodescapturedinprocess3.Whenidenticalnodecategoriesarefound,regardtheleavesofthenodesasequivalentphrases.Ifcandidatesofasentenceorauxiliaryverbphrasecategoryareacquired,thecandidatewhichcoversthemaximumareaisselected.Inotherambiguouscasesthecandidatewhichcoverstheminimumareaisselected.Repeat3.and4.forallwordlinkcombinations.</subsection>
  <subsection title="Linked Subtree Extraction">Afterthetreepairshavebeenlinked,weextractlinkedsubtrees(orfragments)ofthesepairsthatwillbeusedasagrammartoderivetheparaphrases(allofthetreepairsinFigure~arefragments).Foreachpairoflinkedtrees,wecollectallpairsofconnectedsubtrees(andtheirlinks),whoserootnodesarelinked,andthatsatisfyallofthefollowingconditions:Foreachpairoflinkednodesinthefragment,either;bothnodeshavenochildren,orallofthechildrenfromthecorrespondingoriginaltree.Everynon-linkednodeinbothsubtreesofthefragmenthasallofthechildrenfromthecorrespondingoriginaltree.Bothofthesubtreesofthefragmentconsistofmorethanonenode.Thecollectionofallfragmentsfromthecorpusistermedthebagoflinkedsubtreepairs,B.Eachfragmentf_ihasacountwhichrepresentsthenumberoftimesthatfragmentoccurredinthecorpus.Whenderivingaparseweusethiscounttocomputetheprobabilityofselectingthisfragmentfromthebagasthenextstepinaderivation,P(f_i).Theprobabilityissimplyitscount,f_i,dividedbythesumofcountsofallsubtreeswiththesamerootnodelabel(thelabeloftherootnodesofthetreesinf_iwillbedenotedr(f_i))inthebagofalllinkedsubtrees.Thisprobabilityisgivenby:</subsection>
  <subsection title="Paraphrase Derivation">Derivationsofparaphrasesareconstructedusingthebagoflinkedsubtreepairsbymeansofacompositionoperator.Intuitivelythisoperatordefinestheconditionsforcombiningfragments,andisillustratedinFigure~.Formally,theoperatorisdefinedontwofragmentsf_1=T^s_1,T^t_1andf_2=T^s_2,T^t_2iff.r(f_2)isthesameasthelabeloftheleftmostnon-wordleafnodeofT^s_1.TheresultofthiscompositionisalinkedtreepairT^s_3,T^t_3whereT^s_3isT^s_1withitsleftmostnon-wordleafnodev_i^s_1replacedbythesourcesubtreeoff_2,T^s_2.Byvirtueofthemannerinwhichfragmentsareconstructed,thisleftmostnon-wordleafnode,willbelinkedtoanodeinthetargetsubtreeofthefragment;(v^s_1_i)=v^t_1_j.Nodev^t_1_j,isreplacedbythetargetsubtreeT^t_2,toyieldT^t_3.WewritethiscompositionasT^s_1,T^t_1T^s_2,T^t_2=T^s_3,T^t_3or,morecompactly,f_1f_2=f_3.Theprobabilityaderivationf_1f_2f_Nisgivenby:Asingletargetsentencew_tcanhavemanypossiblederivationsfromasourcesentencew_s.Summingoverallpossiblederivationsyieldstheparaphraseprobability.WeselectthebestparaphraseastheonewiththehighestP(w_tw_s).[t]''from``Iliketennis''.figure*</subsection>
  <subsection title="Disambiguation">Itisnecessarytofindthemostprobableparaphrase,givenallofthederivationsarisingfromthesourcesentence.Inpractice,thesourcesentenceisparsedusingachartparseraccordingtothegrammaroftreefragmentsdefinedbythesourcesubtreesofthefragmentsinthebagofalllinkedsubtrees,naturallyproducinga(notnecessarilycorrect)parsetreeforthetargetparaphrase.Sincemanyderivationsforthesamesentencearepossible,itisnotsufficienttofindthemostprobablederivation(forwhichefficientsearchalgorithmsexiste.g.~),butratherwemustsearchoverthesumsofallderivationsforthetargetparaphrase.Weadoptaconventionalapproach(e.g.)ofMonteCarlosamplingofthederivationstoestimatetheparaphraseprobabilities.Theideabeingthatasufficientlylargesamplewillapproximatetheunderlyingdistributionaccurately.Fortheexperimentsinthispaper,1500sampleswereused.</subsection>
  <subsection title="Practical Considerations">Theexperimentsdescribedhererepresentthefirstlarge-scaletestoftheDOTtechnique,andproblemsaroseduetothesizeofthetask.Asignificantproblemwascausedbythelargenumberoffragmentsitispossibletogenerate,bothoverall,andfromlongsentences.Toovercomethis,wearbitrarilyimposedalimitof10,000fragmentsfromanysinglesentence,andwealsodiscardedanyfragmentsthatoccurredlessthanathreshold(inthiscase5)numberoftimesinthecorpus.Wealsousedatwo-stepapproachtoderivingtheparaphrases;inthefirststepweparsedthesentencewithCharniak'sparser,inthesecondwederivedtheparaphraseinamannerthatwasconsistentwiththeparsefromtheparser.Thisreducedthesizeofthechartneededtoparsethesentence,andalsoreducedthesizeofthesearchspace,howeverevenwiththisstrongconstraintontheparsingthenumberoffragmentsinvolvedintheparse,andsizeofthechartcanstillbelarge.Tohandlethecaseofunknownwords,andalsoensurethesystemwouldalwaysoutputatleastoneparaphrase,thesetoffragmentsgeneratedfrompairingthesourcesentencewithitselfwasaddedtothetrainingsetbeforethesentencewasparaphrased.</subsection>
  <section title="Experiments"/>
  <subsection title="Training Data">ThedataweusedfortheseexperimentsisasubsetoftheATRParaphraseCorpus.Thecorpusconsistsofabout50,000sentences(500,000words)ofparaphrasedsentencesdrawnfromthekindofphrasebooksproducedtoaidtravelers.Thereareapproximately1000seedsentencesthathavebeenparaphrasedtoproducethisdata.Thatis,onaverageeachofthese1000seedsentencesgaverisetoapproximately50paraphrasedsentences.Theparaphraseswereparaphrasesonthesyntacticstructurelevelasopposedtosimpleword-synonym-basedparaphrases.Inthisdomainthesentenceslengthisfairlyshort,theaveragelengthofsentencesinthecorpusbeingapproximately10words.Forthepurposesoftheseexperimentswegeneratedapproximately300,000sentencepairsusingthetechniquedescribedinthenextsubsection,althoughalargernumberofpairscouldhavebeengenerated.ThesesentencepairswerethenparsedwithCharniak'sparser~andtheirparsetreeswerelinkedusingthemethodsetoutinSection~.</subsection>
  <subsubsection title="Sentence Pair Generation">Thetrainingdataforthedata-orientedparaphraserconsistedofpairsofparaphrases.Thenumberofpossiblepairingsisprohibitivelylarge,thereforeweselectsentencepairsfromthesetofallpossiblepairings.Wegeneratethetrainingdataforthemachinetranslationsystembyfirstclusteringtheparaphrasedsentences.Notethattheclusteringisdonewithingroupsofsentencesthatareparaphrasesofasingleseedsentence,allsentenceswithinaclusterwillthereforehavethesamemeaning.Thepurposeoftheclusteringistoreducethesizeofthetrainingsetinamannerwhichensuresthatthesentencepairsusedfortrainingarerelativelysimilartoeachotherintermsofeditdistance:thenumberofinsertion,deletionorword-for-wordsubstitutionoperationsrequiredtotransformonesentenceintoanother.Weemployedthefollowingagglomerativeclusteringalgorithm:Assigneachsentenceinthesetofparaphrasedsentencestoitsowncluster;Foreachpossiblepairofclusters,calculatethedistancebetweenthem(theaverageeditdistancebetweenmembersoftheclusters);Mergethetwoclosestclusters;Repeatfrom2.untilthereisonlyonecluster.Theresultofthisclusteringisatree,ordendrogram,theleafnodesofthistreearesentences.Leavesthatareclosetoeachotherinthetree,arealsosimilarintermsofeditdistance.Non-leafnodesdefinesetsofsimilarsentences.Clustersofsimilarsentencesofvaryinggranularitycanbeextractedfromthedendrogrambyselectingclustersofsentenceswhicharetheleavesofsubtreesofthedendrogram.Weselectedsuchsubtreesaccordingtoathresholdofaverageintra-clustereditdistanceoftheirleafnodes.Theideabehindthisistobeabletoselectclustersofspecifiedgranularityfromthedendrogram.Thethresholdwassetarbitrarilytocontrolthenumberofsentencesfromwhichtogenerateparaphrasesbyselectingthemfromclustersofsentenceswithapproximatelythesamesimilaritybetweenthesentenceswithintheclusters.Fromtheresultingclusterswegeneratedtrainingexamplesbypairingthesentencesinthecluster.Itisimportanttonotethatalthoughthepairingsaremadebetweenpairsofsimilarsentences,thesentencesalsomustbeparaphrasesbecausetheclusteringisperformedwithingroupsofparaphrases.Forexample,althoughthesentences``Idoloveyou''and``Idonotloveyou''aresimilar,theywillnotappearinthetraining/testdatabecausetheyarenotparaphrasesofoneanother.Themotivationbehindthisapproachisthatsentencesthataresimilarintermsofeditdistanceshouldalsomakeagoodsentencepairinthetrainingofamachinetranslationdevicebecausethetransformationnecessarytotransformonesentenceintotheotherissimpler.Approximately3millionfragments(afterthresholding)wereextracted(usingthemethodsdescribedinSection~)fromthealignedtreepairsderivedfromthesesentencepairs.</subsubsection>
  <subsection title="Evaluation">Weevaluatedparaphrasesfromfoursources:humanparaphrases,adata-orientedparaphraser(DOPP),astatisticalmachinetranslationbasedparaphraser(SMTP),andasimplebaselinemodel.Thehumanparaphraseswereasampleofunseenhumanparaphrasedsentencesfromthecorpus.Inthecaseofautomaticallygeneratedoutput,weevaluatedthehighestprobabilitysentencethatdifferedfromtheoriginalinputsentence.Thetestdataconsistedofunseensentencesdrawnfromthesamesampleasthetrainingdata.Following,weincludedabaselinemodelbasedonmaximumword-bigramprobabilityofthetargetsentence.Themaximumword-bigramprobabilitybaselinegeneratesanecessarilyshortedparaphraseoftheoriginalsentencebyworddeletion,andthereforeperhapsitisalittleunfairtocallitabaseline.WeconsiderthedirectSMT-basedsystemtobeasuperiorbaselineforparaphrasingbecauseitprovideshigherqualitytrueparaphrases~.</subsection>
  <subsubsection title="Statistical Machine Translation">InparaphrasesaregeneratedforsentencesdirectlyusingastatisticalmachinetranslationsystemtrainedonJapanesesentencepairsfromaparaphrasecorpus.WeimplementedasimilarsystembasedonIBMModel3toparaphraseEnglishdirectly.ThesystemconsistedofthepubliclyavailableEGYPTsoftware,andanin-house-developedmulti-stackdecoder.ThesystemwastrainedonthesamedataastheDOPPsystem.ThesentencesinFigure~showexamplesoftheinputandoutputofthesystems.Theevaluationofmachinetranslationoutputisalwaysacontroversialundertaking,thereforewehaveevaluatedinthreeways,usingbothautomaticandhumanevaluationmethods.Theseevaluationmethodsaresetoutinthefollowingsections.</subsubsection>
  <subsubsection title="Adequacy Score">Wescoredtheparaphrasesasmachinetranslationoutputusinganadequacytest.Sentencesweregraded(from1to5)bythreeindependentnativeEnglishspeakingevaluatorsaccordingtothefollowingscale:40sentencesfromeachofthesourcesweremixedrandomlyandgradedatthesametimebythethreehumanjudgeswhoweretoldthesentenceswereallgeneratedautomatically.TheresultsareshowninTable~.Allannotatorsscoredthesystemsintheorder:baseline~&lt;~SMTP~&lt;~DOPP~&lt;~human.TheresultsweresubjectedtoaT-testtodeterminewhetherallofthedifferencesbetweenthescoresofthetechniquesweresignificant.Thetestsshowthatatp&lt;0.05thisisthecase.Allthreeannotatorsassignedthesamescoretoaparaphrasein47%ofcases.Theaverageinter-annotatoragreementmeasuredbytheKappastatisticwas0.63,onlyamoderatelevelofagreement,pointingtotheambiguityoftheclassificationtask.[ht]table*</subsubsection>
  <subsubsection title="BLEU and NIST Scores">Inasecondevaluation,wescoredtheoutputfromthefourparaphrasesources(i.e.humanparaphrases,DOPP,SMTP,andthesimplebaselinemodel)againstasetofreferenceparaphrasesconsistingof13differentalternativehumanparaphrasesforeachtestsentence.Forthisevaluationa200-sentencesupersetofthetestsetusedfortheadequacyevaluationwasused.Thesourcesentencesthemselveswereexcludedfromthereferenceset.Theoutputwasscoredusingversion0.9cofthepubliclyavailableMTEVAL-KITevaluationsoftware~forbothNISTandBLEUscores.ThesescoresareshowninTable~.AllthreeautomaticsystemshadconsiderablylowerBLEUscoresthanthehuman.However,theDOPPsystemhadthehighestNISTscore.</subsubsection>
  <subsubsection title="Grammaticality">Inafinalevaluationtomeasurethesyntacticcorrectnessoftheparaphrases,weusedanoveltechniquebasedonCharniak'sparser~.Testsentenceswereparsedusingtheparser,andthenumberofincompletesentencefragments(labeledwithFRAG)intheparseswascounted.Theunderlyinghypothesisbeingthattheparserwillhavemoredifficultyassigningsyntacticstructuretoungrammaticalwordsequencesthantogrammaticalones.Asimpleexperimentwasperformedtoinvestigatethishypothesis.Theevaluationsetwasgraduallydegradedbyinterchangingwordsatrandom.Eachwordinthe200sentencetestsetwasexchangedwithadifferentrandomly-selectedwordfromthesamesentencewithprobabilityP_i.ForeachvalueofP_i,20differentrandomrunswereconductedtogetanestimateofthevarianceoftheresults.TheresultsareshowninFigure~andshowaclearrelationshipbetweensentencedegradationandFRAGcount.Theresultsforthefourparaphrasingsystems(showninTable~)indicatethatthedata-orientedparaphraserproducesmoregrammaticaloutputthanboththeSMTPsystemandthesimplebaselinemodel.</subsubsection>
  <subsection title="Discussion">TheDOPPparaphrasingsystemdifferssubjectivelyfromtheothersystemsinthatthemostprobableparaphraseisalmostalwaystheoriginalsentenceitself,andmanyofthehighlyprobableparaphrasecandidatesaresimilartothesourcesentence.TheSMTPsystembycontrastseemstobemoreaggressive,producingparaphrasesthatoftendiffersubstantiallyfromthesourcesentence.TheDOPPsystemexhibitsreasonablebehaviorforaprobabilisticsystemtrainedonthisdata.However,itdoesbegthequestion:``Whatdowemeanbyagoodparaphrase?''.Forsomeapplications,asentencewithsignificantlydifferentstructuretotheoriginalsourcewillbedesirable.TheDOPPsystemiscapableofproducingsuchparaphrases,buttheyarenotthemostprobablecandidates.Theresultspresentedhereareverypromising.TheDOPPsystemperformedwell;itsscoresignificantlybetterthanthebaselinemodel,andasgoodas,orbetterthantheoutputfromtheSMT-basedsystem.Theclusteringalgorithmweemployed,allowedustoselectausefulsubsetfromthepotentiallyhugetrainingdata,andbyusinganautomaticmethodforaligningphrasalstructuresinparsetreestogetherwithapurpose-madeparaphrasecorpus,wewereabletogeneratesufficientdatatoconductthefirstlarge-scaleevaluationoftheDOTmethod.Inthenextsectionweinvestigatetheusefulnessofaparaphraserwhenusedtoexpandmachinetranslationevaluationsets.Wechosetousethedata-orientedparaphraserastheautomaticparaphraserforthefollowingexperimentsbecauseitwasthemostsuccessfulautomaticparaphraserintheinitialstudy.</subsection>
  <section title="Application to Machine Translation Evaluation"/>
  <subsection title="Overview">Inmachinetranslation(MT),thewidediversityofpossiblecorrecttargettranslationsofasinglesourcesentencemakesitdesirabletohaveasmanyreferencesaspossiblewhenusingautomaticmachinetranslationevaluation.WeexaminetheusefulnessofapplyinganautomaticparaphrasertoaugmentthereferencesinthereferencesetsusedforautomaticMTevaluation.Adata-orientedparaphraserwastrainedonacorpusofEnglishsentencepairswhichareparaphrasesofeachother.GivenaninputEnglishsentence,theparaphraserisabletoprobabilisticallygeneratealargesetofparaphrases.Referencesetscontainingbetween1and116referencesweregeneratedbymixing1to16human-producedreferencesandupto100oftheirmostprobableparaphrases.TheoutputfromninedifferentMTsystemswasthenevaluatedusingthesereferencesetsusingthreeautomaticscoringsystems.ThescoredsentenceswerethenanalyzedusingSpearmanRankCorrelationwiththecategoricalscoresassignedbythehumanjudges.Theaimistodeterminewhethertheadditionalsyntheticparaphrasesincreasethecorrelationoftheautomaticevaluationscheme'srankstothehumanranking.AnincreaseincorrelationindicatingthattheautomaticsystemismoresimilartoahumaninrankingtheMToutput.</subsection>
  <subsection title="Experimental Methodology"/>
  <subsubsection title="Test Data">Ourtestdataconsistedofasetof345EnglishsentencesthathavebeentranslatedfromJapanesebyninedifferentmachinetranslationsystems(seelaterinthissection).These345EnglishsentenceshavebeenrandomlyselectedfromtheBasicTravelExpressionCorpus(BTEC).EachoutputfromthemachinetranslationsystemswasscoredbynineindependentnativeEnglishspeakinghumanevaluatorswhowerealsofamiliarwiththesourcelanguage,Japanese.Eachsentencewasassignedagradeinaccordancewiththeafive-pointscaleforadequacyandgrammaticality.Asinglegradewasderivedforeachsentencebyselectingthemediangradefromtheninegradesassignedbythehumanjudges.Testsetsof1000pseudo-documentswereconstructedbytakingrandomsamplesof30sentencesfromthe345testsentencesinthemannerof.Thisisbecausestatisticsbasedonshorttranslationsofasinglesentenceprovedtobeunreliable.</subsubsection>
  <subsubsection title="Reference Data">Foreachofthe345testsentences,16differentreferencetranslationswerepreparedbyhumanannotators.Thesereferenceswerethenparaphrasedbythedata-orientedparaphraser,andtheresultsorderedaccordingtotheprobabilityassignedbythedata-orientedparaphraser.Referencesetswerepreparedwithvaryingmixturesofparaphrasedandhumanreferences.Theparaphrasesbeingselectedaccordingtoprobability.Intheeventthatinsufficientparaphraseswereproducedbytheparaphraserforaparticularsentence,thefirsthumanreferencewasusedinplaceofthemissingreferences,thoughthisrarelyoccurredinpractice.</subsubsection>
  <subsubsection title="Automatic Scoring Methods">Weusedthreedifferentautomaticscoringsystemsfortheseexperiments:BLEU,NISTandmWER.Thesearedescribedbrieflybelow:</subsubsection>
  <subsubsection title="Corrected Spearman Rank Correlation">Following,wechosetouseSpearmanRankCorrelationtoevaluatehowsimilarourautomaticMTevaluationsweretohumanevaluations.Insteadofcorrelatingtheabsolutevaluesofthescoresthemselves,thescoredtestdataisorderedbyscore,andassignedarankindicatingitspositioninthisordering.Theranksthemselvesarethenanalyzedforcorrelation.Byusingthisschemeweareplacingimportanceonensuringourautomaticscoringsystemrankstranslationsinthesamewaythatahumanjudgewouldrankthem,ratherthanexaminingcorrelationsintheabsolutevaluesassignedbythescoringmethods.WechosetouseavariantcalledCorrectedSpearmanRankCorrelationwhichcorrectsforcaseswheretiedranksoccur.Tiedrankscanoccurinthehumangradingsincethereareonly5categories.</subsubsection>
  <subsubsection title="The Machine Translation Systems Used">TheoutputfromnineJapanesetoEnglishmachinetranslationsystemswasusedforthisstudy,theseconsistedofthreedifferentreleases,spacedatsixmonthintervals,ofthreetypesofMTsystem:</subsubsection>
  <subsection title="Results">Ourresultssupportthefindingsof~,showingthataddingmorereferencestothereferencessetimprovestheMTevaluationperformance,exceptinthecaseofNISTwheremorethan4referencesdegradestheevaluationperformance(showninFigure~).ForNIST,16referencesoffersacomparablelevelofperformancetojustasinglereference.Asimilareffectwasreportedin~.Ourmainresults(showninFigures~to),showthat(withtheexceptionofNISTscoring)itispossibleforreferencesgeneratedbyanautomaticparaphrasertoimprovemachinetranslationevaluationperformance.ResultsforBLEUareshowninFigures~and~.Figure~showsthatthecorrelationwiththehumanrankingisincreasedbyadding(uptoabout30)paraphrasesforallnumbersofhumanreferences.Fromthegraphitisapparentthataddingmorethan30paraphrasesdoesnotresultinimprovedevaluationperformance,andforlargernumbersofhumanreferencestheseadditionalreferencesdegradeevaluationperformance.Whenaddingmorethan30paraphrases,thesetofaddedparaphrasescontainsmanylowerprobabilityparaphraseswhichareincorrect,orevennonsensesentences,however,althoughtheevaluationperformancecanbedegraded,theeffectissmall,theprocessbeingquiterobusttotheadditionofthisnoise.Apossibleexplanationisthatitisunlikelyforanincorrectlytranslatedsentencetobeclosetoanyofthesenoiseparaphrases.Theprimaryfactordeterminingtheusefulnessoftheaddedparaphrasesbeingthenumberofcorrectparaphrasesadded.Figure~showsthesameresultlookingattheeffectofincreasingthenumberofrealreferenceswithafixednumberofparaphrases.Thebottomlineshowstheeffectofincreasingthenumberofreferencesintheabsenceofanyparaphrases.Aswouldbeexpected,theevaluationperformancesteadilyimproveswiththeadditionofmorereferences.Thedifferencebetweenthetopandbottomlinesonthegraphindicatestheamountofimprovementduetoaddingvaryingnumbersofparaphrases.Thisispositiveinallcases,buttheamountofimprovementdiminisheswithincreasingnumbersofreferences.AnalogousresultsforNISTareshowninFigures~and~.ThesefiguresshowthataddingparaphrasesonlydegradestheperformanceoftheNISTscoring.Thisdegradationwasunderstandable,sinceperformancecanbedegradedevenwhenaddingonlyhumangeneratedreferences(Figure~).ItisdifficulttoexplainwhyincreasingthenumberofreferencestotheNISTscoredoesnotresultinbettercorrelationwiththehumanranking.Onewouldexpectthatsincethecountsusedintheestimatesofinformationcontributioninthescorewerebasedonmoredata,theestimatewouldbecomemoreaccurate,therebyimprovingtheeffectivenessofthescore.Onepossiblecontributingfactormightbethecompositionofthen-gram'sinfluence.Weobservedthatasthenumberofreferencesincreased,sodidtheproportionofthescorethatwascontributedbyhigher-ordern-grams.Furthermore,wealsoobservedthatdecreasingthemaximumn-gramsizeusedbythescoringimprovedthecorrelationwithhumanrankingonthisdata.TheresultsformWERareshowninFigures~and~.Figure~showsthattheperformanceisimprovedforallnumbersofhumanreferencesbyaddingupto10paraphrases,butaddingmorethan10resultsindegradedperformance.Forlargernumbersofreferencesthedegradationcangivelowerperformancethanthatwithoutaddedparaphrases.ThiseffectisalsoshowninFigure~,thelinerepresentingonlyhumanreferencescuttingupthoughthelinesfor15,20and30paraphrasesasthenumberofreferencesincreases.However,Figure~alsoshowsthattheperformanceofasinglehumanreferenceaugmentedby10paraphrasesisroughlyequivalenttothatwith4humanreferences.</subsection>
  <section title="Further Analysis">Thissectiondescribesanexperimenttoinvestigatewhattypeofparaphrasesmightbethemostusefultoadd.Therearemanypossiblecandidatestoconsiderasfactorswhichmightinfluenceaparaphrase'susefulness.Forexamplethecriteriamightrangefromamethodassimpleasasentence-length-basedscore,tosomethinginvolvingadetailedsyntacticorsemanticanalysisoftheparaphrases.Weinvestigatetheeffectofperhapsthemostobviousfactor,thatishow``common''theparaphraseisinthelanguage.Theassumptionherebeingthataparaphraseinthereferencesetislikelytobeusefulifitisacommonlyusedexpressioninthetargetlanguage.Putanotherway,obscureorinfrequentlyusedexpressionsareunlikelytobegeneratedbythemachinetranslationsystem,andthereforereferencesofthistypecannotbeexpectedtobeasusefulascommonlyusedlanguage.Totestthishypothesisweperformedanexperimentwherereferenceswereselectedfromthesetof16human-producedreferencesaccordingtoalanguagemodelprobability.Webuiltasimpleunigramlanguagemodelfromall16referencesentencesforeachindividualtranslation,andthenscoredthereferencesentencesthemselvesusingthissmalllanguagemodel.Sincelanguagemodelshaveatendencytofavourshortersentences,weusedtheaveragelogprobabilityperwordtoscorethereferencesratherthanthetruelanguagemodelprobability.Weconstructedtwoseparatereferencesetsforeachexperiment;oneconsistedofthetopNreferencesaccordingtothelanguagemodel,theotherconsistedofthebottomNreferencesaccordingtothelanguagemodel.WeranexperimentsfortheBLEU,NISTandmWERscoringsystems,andweranseparateexperimentsusingN=1,2,4and8references.TheresultswhichareshowninFigures~andpartiallyconfirmtheoriginalhypothesis.Forallscoringsystemsandallnumbersofreferencesitisthecasethatchoosingthehighest-rankedreferencesaccordingtothelanguagemodelyieldsabettermachinetranslationevaluationthanchoosingthelowest-rankedreferences.However,bothofthesemethodsforchoosingparaphrasesareworsethansimplyselectingparaphrasesrandomly.Choosingparaphrasesrankedhighlybythelanguagemodelbeingonlyslightlyworsethanrandom,andusinglow-rankedparaphrasesbeingconsiderablyworse.Oneinterpretationoftheseresultsisthatthebeststrategyforselectingparaphrasesnostrategyatall.Whenchoosingreferencesrandomlywearesamplingrandomlyfromasetof16human-generatedparaphrases.Whenselectinghigh-scoringparaphrasesusingalanguagemodel,wearebiasingoursampletoexcluderarerexampleswhich(inappropriatelysmallquantities)doimproveevaluationperformance.Perhapstheoldadagethatthebesttypeofdataismoredataholdstruehere.Theremaybeotherfactorsthatdoidentifyspecificcharateristicsofparaphrasesasbeingmoreusefulthanothers,butweleavethisasanopentopicforfutureresearch.</section>
  <section title="Conclusion">Theexperimentsreportedhereexaminetwodifferentwaystoautomaticallyparaphrasetext:bystatisticalmachinetranslation,andbydata-orientedtranslation.Theresultsshowthataccordingtoahumanassessmentofadequacy,thedata-orientedmethodwasthesuperiorofthetwomethods.Wepresentedexperimentstodeterminewhethersyntheticparaphrasesgeneratedbythedata-orientedtechniquecouldimproveautomaticmachinetranslationevaluation.Syntheticparaphrasesandhuman-generatedparaphrasesweremixedinvaryingproportionsandaddedtothereferencesetsforthreeautomaticevaluationscoringmethods.Thecorrelationoftherankingdefinedbytheseautomaticscoreswithhumanrankingwasusedasawayofevaluatingtheevaluation.Theresultswereveryencouraging,forBLEUandmWERscoringtheperformancewasenhanceduntilthenumberofparaphrasesreachedanoptimalvalue.Preparingreferencesbyhandisanexpensiveprocessandtheabilitytoobtainsimilarevaluationperformanceusingfewerhumanreferencesisverydesirable.Inthefuture,weplantodeveloptheparaphraserfurther.Byimprovingthequalityoftheparaphrasesweexpecttoincreasethepotencyofthistechnique.researchwassupportedinpartbytheTelecommunicationsAdvancementOrganizationofJapan.document</section>
</root>
