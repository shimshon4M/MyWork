\documentclass{nlp}
\usepackage{multirow}
\begin{document}

\setcounter{page}{19}
\setcounter{Volume}{11}
\setcounter{Number}{9}
\setcounter{Year}{2004} 
\setcounter{Month}{10}
\received{2004}{1}{9}
\revised{2004}{5}{21}
\accepted{2004}{7}{5}


\def\tr#1#2{}
\def\trr#1#2{}

\newcounter{exnum}
\setcounter{exnum}{1}
\renewcommand{\labelenumi}{}
\renewcommand{\labelenumii}{}


\title{WWWを用いた書き言葉特有語彙から話し言葉語彙への用言の言い換え}
\author{鍜治 伸裕\affiref{tokyo} \and 岡本 雅史\affiref{tokyo} \and 黒橋 禎夫\affiref{tokyo}\affiref{sakigake}}

\headauthor{鍜治，岡本，黒橋}


\affilabel{tokyo}{東京大学大学院情報理工学系研究科, Graduate School of
Information Science and Technology, the University of Tokyo}
\affilabel{sakigake}{科学技術振興機構 さきがけ，PRESTO, JST}

\begin{abstract}
 書き言葉で使われる語彙と，話し言葉で使われる語彙には大きな違いがある．
 そのため，書き言葉テキストから合成された音声は不自然なものとなってしま
 う．書き言葉テキストからでも自然な音声の合成を可能にするために，本論文
 では，書き言葉特有語彙から話し言葉語彙への言い換えを学習する手法を提案
 する．ある表現が書き言葉特有語彙であるか，話し言葉語彙であるかは，その
 表現の書き言葉コーパスでの出現確率と話し言葉コーパスでの出現確率をもと
 にして判断する．書き言葉コーパスと話し言葉コーパスはWWWから自動収集した
 ものを用いる．実験の結果，書き言葉コーパスと話し言葉コーパスの収集精度
 は94\%，言い換え学習の精度は79\%であり，提案手法の有効性を示すことがで
 きた．
 \end{abstract}

\keywords{言い換え，書き言葉，話し言葉，暗示的意味，WWW}

\etitle{Paraphrasing Predicates from Written Language Specific
Vocabulary into Spoken Language Vocabulary Using the World Wide Web}

\eauthor{Nobuhiro Kaji\affiref{tokyo} {\hspace*{-6pt}\rm ,}
Masashi Okamoto\affiref{tokyo} {\hspace*{-6pt}\rm ,}
Sadao Kurohashi\affiref{tokyo}\affiref{sakigake}}

\begin{eabstract}
  There are a lot of differences between expressions used in written
 language and spoken language. This paper represents a method of
 paraphrasing written language specific vocabulary into spoken language
 vocabulary. They can be distinguished based on the occurrence
 probability in written and spoken language corpora which are
 automatically collected from WWW. Experimental results indicated the
 effectiveness of our method. The precision of the collected corpora was
 94\%, and the accuracy of learning paraphrases was 79\%.
\end{eabstract}

\ekeywords{paraphrase, written language, spoken language, connotation, WWW}


\maketitle


\section{はじめに}
音声情報は，我々にとって身近な情報形態であるうえに，効率的に情報を伝達で
きるという特徴を持っている\cite{Hayashi99,Nadamoto01}．しかしながら，現
在，我々が利用できる電子情報の大半はテキスト情報であり，音声情報は比較的
少ない．こうした背景から，音声合成技術を利用したアプリケーションが関心を
集めている\cite{Fukuhara01}．音声合成を使えば，既存のテキスト情報を音声
情報に変換してユーザに提供することができる．

しかし，こうしたアプリケーションの開発には二つの問題点がある．一つは，合
成された音声のアクセントやイントネーションが不自然であるという，音声合成
の質の問題である．もう一つは，書き言葉と話し言葉で使われる表現に違いがあ
るため，音声合成の入力テキストが書き言葉だった場合，通常の話し言葉では殆
んど使われなような表現が音声化されてしまうことがある，という問題である．
これら二つの問題のうち，前者はよく知られた問題であるが，後者は今までほと
んど指摘されなかった．そこで我々は，自然言語処理の言い換え技術を用いて，
後者の問題を解決することを考えた．言い換え技術は，文の平易化
\cite{Inui01,Inui03}や質問応答\cite{Lin01,Ulf02,Duclaye03}などへの応用例
が多いが，このような試みは初めてである．

以下では，まず書き言葉と話し言葉の相違について考察する．書き言葉と話し言
葉のもっとも基本的な相違は，話し言葉の同時性である\cite{Hatake87}．話し
言葉を使ったコミュニケーションでは，話し手が情報の送信を行うと同時に，聞
き手が受信することになる．こうした同時性は，聞き手に負担を強要することに
なる．例えば，話し言葉では，話し手が会話のペースを設定することになり，聞
き手がそれを制御することはできない．もし書き言葉であれば，読み手はテキス
トをゆっくり読もうと早く読もうと自由であるし，途中で読むのを中断すること
さえできる．

そのため，話し言葉は，書き言葉に比べて聞き手の負担が低い表現を使う傾向に
ある．例えば「難解な語彙が用いられることが少ない」「一つ一つの文が比較的
短い」などがあげられる．畠は，このような話し言葉の特徴を{\bf 冗長性}
\footnote{いわゆる「冗長性」という語とは違う意味で使われている．}と呼ん
でいる\cite{Hatake87}．もちろん，これは大まかな傾向であり，例えば講演の
ように冗長性が低い話し言葉もある．しかし，畠も指摘しているように，冗長性
とは，いわゆる話し言葉がもつ基本的な特徴であると言える．そのため，本論文
では冗長性の高い話し言葉だけを想定して議論を行う．冗長性の高い話し言葉を
定義することは難しいが，ここでは畠の分類にしたがって次のように考える．畠
は，冗長性に着目して話し言葉を以下の四つに分類している\cite{Hatake87}．
\begin{description}
 \item[第I類] 発話の形成から発話までほとんど時間的経過のないもので非常に
	    冗長性が高い．(例)おしゃべり
 \item[第II類] 伝達内容が多少準備されているが，言語化そのものは即興で行
	    われるもの．第I類ほどではないが冗長性は高い．(例)相談，打ち
	    合わせ，連絡，座談会
 \item[第III類] かなり計画的で時間をかけた発話．言語化自体もある程度準備
	    されていて，冗長性は低い．(例)講演，講義
 \item[第IV類] 言語化の即興がほとんどない発話．冗長性は非常に低い．(例)
	    ニュース，青年の主張
\end{description}
本論文では，話し言葉として第I類と第II類を想定して議論を進める．


\begin{figure}[h]
 \begin{center}
  \scalebox{0.5}{\includegraphics{task.eps}}
 \end{center}
 \caption{書き言葉特有語彙から話し言葉語彙への言い換え}
 \label{fig:task}
\end{figure}

書き言葉と話し言葉の差異の中でも，本論文は語彙の問題を扱う．以下では，書
き言葉では使われるが話し言葉では殆んど使われない語彙を{\bf 書き言葉特有
語彙}と呼び，話し言葉で通常使われる語彙を{\bf 話し言葉語彙}と呼ぶ．すな
わち本論文では，書き言葉特有語彙を話し言葉語彙への言い換える，という問題
を取り上げる．これを図で説明すると次のようになる(図\ref{fig:task})．まず，
(1)書き言葉で使う表現，(2)話し言葉で使う表現，(3)どちらでも使われない不
自然な表現，の三種類の表現を考える．不自然な表現を考慮しているのは，書き
言葉特有語彙を自動処理で言い換えた先が，不自然な表現になる場合がたまにあ
るからである．図中の2つの円は，書き言葉で使う表現と話し言葉で使う表現を
表している．そして，2つの円の外の部分は，どちらでも使われない不自然な表
現を表している．二つの円の重複部分は，書き言葉と話し言葉の両方で使う表現
である．書き言葉特有語彙とは，書き言葉で使う表現から，書き言葉と話し言葉
の両方で使う表現を除いたもので，左円の中の色がついた部分にあたる．話し言
葉語彙とは，話し言葉で使う表現のことなので，図中の白い部分にあたる．

書き言葉特有語彙から話し言葉語彙への言い換えは，図\ref{fig:task}の矢印で
表されているような言い換えであると言える．それ以外の言い換えは，破線矢印
で表している．破線矢印の言い換えは，話し言葉で使われない表現(書き言葉特
有語彙または不自然な表現)が言い換え先になっているもの((A)(B)(C))と，話し
言葉語彙が言い換え対象になっているもの((C)(D)(E)(F))がある．図
\ref{fig:task}からも分かるように，入力となる書き言葉テキストには，言い換
える必要のない表現(二つの円の重複部分)が存在している．言い換えは，いわば
「単言語内翻訳」と考えることができるため，機械翻訳との類似性がしばしば指
摘されている\cite{Sato99}．しかし，このように言い換えは，変換対象とする
必要のない表現が入力テキストに含まれているという点で，機械翻訳とは大きく
異なっている．

本論文は，書き言葉特有語彙から話し言葉語彙への言い換えを学習する方法を提
案する．ある表現が書き言葉特有語彙であるか，話し言葉語彙であるかは，その
表現の書き言葉コーパスでの出現確率と話し言葉コーパスでの出現確率をもとに
判断する．コーパスは既存のものではなく，WWWから自動収集した大規模なもの
を利用する．提案手法の流れは以下のようになっている(図\ref{fig:outline})．
\begin{list}{}{}
 \item[(1)] Kajiらの手法を利用して，国語辞典から用言の言い換えペアを学習
	    する\cite{Kaji02}．
 \item[(2)] 書き言葉コーパスと話し言葉コーパスをWWWから自動収集する．
 \item[(3)] それら二つのコーパスを用いて，(1)で学習した言い換えの中から，
	    書き言葉特有語彙から話し言葉語彙への言い換えを選び出す．
\end{list}
入力テキストを，話し言葉に適したテキストに言い換えるためには，当然，用
言以外の表現も言い換え対象とする必要がある．しかし，あらゆる表現を言い換
え対象とすることは，現在の言い換え技術では困難なので，言い換え対象を用言
に限定して議論を行う．
\begin{figure}[h]
 \begin{center}
  \scalebox{0.7}{\includegraphics{outline.eps}}
 \end{center}
 \caption{提案手法の流れ}
 \label{fig:outline}
\end{figure}


\section{関連研究}
2つの表現が言い換えの関係にあるとは，それらがほぼ同一の意味を表している
ということであるが，こうした場合に2つの表現が全く同じ意味を表しているこ
とは少なく，たいていは微妙な違いが存在している．この違いは2種類に分けて
考えることができる．1つ目は，指示的意味(denotation)の違いで，2つ目は，ス
タイルなどの暗示的意味(connotation)の違いである．本研究は，ある表現が話
し言葉として使われるかどうか，という暗示的意味の違いを扱った研究と位置づ
けることができる．

言い換えの自動学習に関する研究は多いが\cite{Lin01,Barzilay03}，学習され
た言い換えの間にどのような違いがあるかについて，議論を行っている研究は少
ない．本研究のように，言い換え間の暗示的意味の違いを扱った研究には，以下
のようなものがある．Edmondsらは，暗示的意味の違いを計算機で表現するモデ
ルを提案している\cite{Edmonds02}．そしてInkpenらは，そのモデルのパラメー
タを同義語辞書から自動学習する方法を提案している\cite{Inkpen01}．だが，
同義語辞書のような既存の言語資源に暗示的意味の違いが十分に記述されている
とは考えにくい．これに対して本論文で提案する手法は，コーパスでの出現確率
にもとづくもので，既存の言語資源に依存しない．

一方，Inuiらは，暗示的意味の違いの中でも可読性の違いに焦点をあて，トレー
ニングコーパスを使って可読性の違いを判定する手法を提案している
\cite{Inui01}．トレーニングコーパスは，まず大量の言い換えのペアを用意し
て，そして，どちらが読み易いかを専門家にタグ付けしてもらって作成されてい
る．Inuiらの試みと本研究は，コーパスを使って暗示的意味の違いを判定すると
いう点で類似しているが，Inuiらは統語的な言い換えを扱っているのに対して，
本研究は語彙的な言い換えを扱っているという違いがある．

村田らは，我々と同様に，書き言葉から話し言葉への言い換えを扱っている
\cite{Murata01,Murata02}．村田らの手法は，話し言葉コーパスにより多く出現
する表現に言い換えるというものである．これに対して本論文は，書き言葉コー
パスと話言葉コーパスの両方を利用した機械学習に基づく手法を提案する．また，
村田らの手法は，人手で用意された書き言葉コーパスと話し言葉コーパスを前提
としているが，本論文では，書き言葉コーパスと話し言葉コーパスを自動収集す
る．

文体が異なる2つのコーパス(書き言葉と話し言葉，イギリス英語とアメリカ
英語など)を統計的に比較して，どちらか一方の文体に特有の語彙を発見する試
みは多い\cite{Kilgarriff01}．しかし，こうした研究では言い換えとの関連は
十分に議論されていない．

特定の文体のコーパスを自動収集するという試みに関しては，Tambouratzisらが
DemotikiコーパスとKatharevouaコーパス
\footnote{DemotikiとKatharevouaは，ギリシャ語の変異(variation)の一つであ
る}を収集する方法を提案している\cite{Tam00}．また，Bulykoらは，我々と同
様にWWWから話し言葉コーパスを自動収集する手法を提案している
\cite{Bulyko03}．自動収集の手がかりとして，Bulykoらは既存の話し言葉コー
パスのN-gramの情報を使っている．これに対して我々の手法は，後述するように，
待遇表現に着目しているという点が異なる．


\section{用言の言い換え学習}
\label{sec:learn}
用言の定義文には，その用言の言い換えが含まれているので，言い換えの学習に
利用することができる．そこで，先行研究の手法を用いて，国語辞典の定義文か
ら用言の言い換えを学習する\cite{Kaji02}．以下に，用言とその定義文の具体
例を示す．用言は太字で示している．
\vspace{10pt}
\begin{enumerate}
 \item
      \begin{enumerate}
       \item {\bf 激怒する}

	     [ \underline{激しく }怒る ] こと
       \item {\bf 相乗りする}

	     \underline{\underline{乗物などに}} [ \underline{いっしょに} のる ] こと
       \item {\bf 発汗する}

	     [ \underline{\underline{汗を}} かく ] こと
      \end{enumerate}
\end{enumerate}
\addtocounter{exnum}{1}
\vspace{10pt}
一般に，用言の定義文の主辞は用言であり，主辞には副詞や名詞がかかる場合が
ある．例えば(1a)，(1b)，(1c)の定義文の主辞は，「怒る」，「のる」，「かく」
である．主辞にかかる副詞は一重線で，主辞にかかる名詞は二重線で表している．
そして，定義文に含まれる言い換えは括弧でくくっている．

主辞とそれにかかる副詞は，必ず言い換えに含まれると考えることができる．主
辞に名詞がかかっている場合，それが言い換えに含まれるかどうかは見出し語に
よって異なるが，\cite{Kaji02}の手法で判断できる．ほとんどの場合，言い換
えに含まれる名詞は0個か1個である．したがって，定義文から取り出される言い
換えは，「副詞$*$名詞$?$用言」という形をしていると仮定できる
\footnote{
$*$は0以上，$?$は1以上を表す．
}．以下では，見出し語である用言をsourceと呼び，定義文から取り出された言
い換えをtargetと呼ぶ．そして，この二つのペアを言い換えペアと呼ぶ．

この手法によって，例解小学国語辞典\cite{RSK97}から5,836の言い換えのペア
を学習した．例えば，上記の定義文からは次のような言い換えペアが学習された．
\vspace{10pt}
\begin{enumerate}
 \item
      \begin{enumerate}
       \item 激怒する $\rightarrow$ 激しく怒る
       \item 相乗りする $\rightarrow$ いっしょにのる
       \item 発汗する $\rightarrow$ 汗をかく
      \end{enumerate}
\end{enumerate}
\vspace{10pt}
\addtocounter{exnum}{1}
こうして学習された言い換えペアの中から，次節以降に述べる方法を用いて，書
き言葉特有語彙から話し言葉語彙への言い換えを選び出す．


\section{WWWからの書き言葉コーパスと話し言葉コーパスの自動収集}
提案手法は，書き言葉特有語彙から話し言葉語彙への言い換え(図
\ref{fig:task})を，sourceとtargetの書き言葉コーパスでの出現確率と，話
し言葉コーパスでの出現確率に基づいて選び出す．そのためには，大規模な書き
言葉コーパスと話し言葉コーパスが必要となるが，問題は，どのようにして大規
模な話し言葉コーパスを準備するのかということである．日本語の話し言葉コー
パスは，\cite{Maekawa00,Takezawa02}など最近少しずつ整備されてきているが，
いずれも規模が小さい．

そこで次のような解決方法を考案した．まず，話し言葉語彙は，チャットや掲示
板，日記，メールといったくだけたテキストに使われている語彙で近似できると
いう仮説をたてた．そして，WWW上のそうしたテキストを話し言葉コーパスとし
て自動収集する，新聞記事などの典型的な書き言葉テキストを書き言葉コーパス
として自動収集する，ということを考えた．自動収集が可能になれば，大規模な
コーパスを用意することが可能となる．

ここで問題は，上記のような仮説の妥当性であるが，次の二つの理由からこれは
妥当であると考えている．まず第一に，冒頭で述べた通り話し言葉の基本的な特
徴は冗長性であると考えることができるので，書かれたテキストであっても冗長
性が高ければ代用できると予想できる．畠は，冗長性が高いテキストの例として，
日記や家族への手紙をあげているが\cite{Hatake87}，チャットやメールなどに
も同様のことが言えると考えられる．第二に，WWWからチャットのようなくだけ
たテキストを自動収集して，そこから言語モデルを学習することによって，音声
認識の精度が向上するという報告があ\cite{Bulyko03}．これは，チャットのよ
うなテキストと，実際の発話が非常に類似していることを意味する．このことも，
我々の仮説の裏付けと捉えることができる．

図\ref{fig:collect}に収集手法の概要を示す．まず，WWWからWebページを集め
てきて，そこからhtmlタグなどの不要な部分を取り除く．こうして得られたコー
パスをWWWコーパスと呼ぶ．そして，各ページを(1)書き言葉(2)話し言葉(3)判断
困難の三つに分けて，(1)または(2)に分類されたページだけを，書き言葉コーパ
ス，話し言葉コーパスとして利用する．各ページを，書き言葉と話し言葉の二種
類ではなく，三種類に分類するのは，WWWコーパスには人間でも書き言葉か話し
言葉かの判断の難しいページがあり，そうしたページを無理に分類して利用しよ
うとすれば，質の悪いコーパスが集まる原因になると考えられるからである．

\begin{figure}[h]
 \begin{center}
  \scalebox{0.6}{\includegraphics{collect.eps}}
 \end{center}
 \caption{コーパスの自動収集}
 \label{fig:collect}
\end{figure}


\subsection{待遇表現にもとづく分類}
各ページを，書き言葉，話し言葉，判断困難に分類するために，待遇表現の
一種である親愛表現と丁寧表現に着目した．

「聞き手に対する尊敬や親愛や軽侮などの態度を表す言語表現」を待遇表現とい
う．待遇表現は，書き言葉よりも話し言葉で多く使われるという傾向がある．
話し言葉は，特定の聞き手を想定して使われることが多いので，その聞き手に
対する待遇表現が使われることが多い．これに対して，新聞記事などの書きこと
ばは，不特定の読み手を想定して使われるのが普通である．そのため，基本的に
は待遇表現を使わないという傾向がある．

日本語は，用言の活用形や用言に付属する機能語によって，待遇表現の一種であ
る親愛表現と丁寧表現を表すことができる．親愛表現とは，聞き手に対する親愛
の感情を表す表現で，機能語「ね」や「よ」などを使うことによって表すことが
できる．例えば(3)は，機能語「ね」をつけることによって聞き手への親愛を表
している．
\vspace{10pt}
\begin{enumerate}
 \item 今度お稽古できる時には，もっとやりますから\underline{ね}
       \addtocounter{exnum}{1}
\end{enumerate}
\vspace{10pt}
   
丁寧表現とは，聞き手に対する丁寧な態度を表す表現のことで，「〜です」「〜
ます」といった表現によって表すことができる．
\vspace{10pt}
\begin{enumerate}
 \item
      \begin{enumerate}
       \item すぐ近くに見える虹がとても\underline{きれいです}
       \item またあんな感動を味わえたら，と思い\underline{ます}
      \end{enumerate}
\end{enumerate}
\vspace{10pt}
\addtocounter{exnum}{1}
(4a)は形容詞「きれいだ」を「ですます形活用」で使うことによって丁寧さを表
している．(4b)は機能語「ます」を使うことによって丁寧さを表している．

親愛表現と丁寧表現は，話し言葉で非常に多く出現するうえに，形態素解析と
簡単なルールによって認識できる．そこで，各ページが書き言葉，話し言葉，
判断困難のいずれであるかを判定するために，次の二つの数値を用いた．
\begin{itemize}
 \item 親愛表現を含む文数$/$ページに含まれる全文数
 \item 丁寧表現を含む文数$/$ページに含まれる全文数
\end{itemize}
前者を親愛表現率，後者を丁寧表現率と呼ぶ．


\subsection{自動収集}
各ページの親愛表現率と丁寧表現率を求める．そのためには，親愛表現と丁寧表
現を含む文を判定する必要がある．判定は以下のように行う．まず，WWWコーパ
スをJuman
\footnote{
http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman.html
}を用いて形態素解析する．そして，次の機能語のうちいずれか一つでも含む文
は親愛表現を含むとする．
\begin{quote}
 ね，よ，わ，さ，ぜ，な
\end{quote}
次に，それ以外の文で，次の機能語のうちいずれか一つでも含む文，もしくは
「ですます活用」の用言を含む文は丁寧表現を含むとする．
\begin{quote}
 です，ます，ください，ございます
\end{quote}
このようにして，親愛表現と丁寧表現を含む文を判定し，各ページの親愛表現率
と丁寧表現率を求める．

収集されたWWWコーパスの一部を人手で調査し，表\ref{collect}のような分類規
則を作成した．この規則にしたがって，ページを書き言葉，話し言葉，判定
困難の三つにわける．そして，書き言葉または話し言葉に分類されたページ
だけを収集する．
\begin{table}[h]
 \begin{center}
  \caption{分類規則}
  \label{collect}
  \begin{tabular}{ll}\hline
   親愛表現率 $=$ 0 かつ 丁寧表現率 $=$ 0     & $\rightarrow$ 書き言葉 \\ \hline
   親愛表現率 $>$ 0.2                         &                          \\
   または                                     & $\rightarrow$ 話し言葉 \\
   親愛表現率 $>$ 0.1 かつ 丁寧表現率 $>$ 0.2 &                          \\ \hline
   上記以外                                   & $\rightarrow$ 判断困難   \\ \hline
  \end{tabular}
 \end{center}
\end{table}


\subsection{評価}
収集に使用したWWWコーパスと，収集された書き言葉コーパスと話し言葉コー
パスの規模を表\ref{data}にしめす．WWWコーパスのサイズは336,341ページ，
391,582,073語である．そして，収集された書き言葉コーパスのサイズは
38,472ページ，38,941,503語で，話し言葉コーパスのサイズは33,186ページ，
51,801,168語であった．
\begin{table}[h]
 \begin{center}
  \caption{コーパスの規模}
  \label{data}
  \begin{tabular}{lrr}\hline
                      & ページ数  & 語数        \\ \hline
   WWWコーパス        & 336,341   & 391,582,073 \\ \hline
   書き言葉コーパス & 38,472    &  38,941,503 \\
   話し言葉コーパス & 33,186    &  51,801,168 \\ \hline
  \end{tabular}
 \end{center}
\end{table}


\paragraph{既存のコーパスとの比較}
収集された話し言葉コーパスと，既存の話し言葉コーパスの規模を比較した．
我々の知る限り最も大規模なものは「日本語話し言葉コーパス」であり
\cite{Maekawa00}，その規模はおよそ7,000,000語である．一方，収集された話
し言葉コーパスは51,801,168語を含んでおり，こうした既存のコーパスと比較し
ても十分に大きなものを構築できたといえる．


\paragraph{適合率による評価}
提案手法にとって重要なのは適合率であり，再現率は問題ではない．なぜなら，
我々の手法は大規模なWWWコーパスからの自動収集というアプローチなので，た
とえ再現率が低くても適合率が高ければ，高い質で大規模なコーパス収集が可能
になるからである．逆に適合率が低ければ，たとえ再現率が高くとも質の良いコー
パス収集は不可能である．

書き言葉または話し言葉として収集されたページをランダムに240ページ取
り出し，そのうち何ページが正しく集められいるかという適合率による評価を行っ
た．240ページの中には，手法が書き言葉と判断したページが125ページ，話し
言葉と判断したページが115ページ含まれていた．

評価は，2人の被験者(以下では被験者1，被験者2と呼ぶ)が個別に次のような手
順で行った．各被験者は，各ページを書き言葉，話し言葉，判断困難の3つ
に分類する．このとき，そのページが手法によって書き言葉として収集された
か，話し言葉として収集されたのかは，被験者に知らせていない．そして，提
案手法が書き言葉/話し言葉として選んだページを被験者も書き言葉/話し言葉と
して選んだ場合にのみ，そのページは正しく収集されたと考えた．

提案手法の適合率を表\ref{eval1}に示す．被験者1は240ページ中228ページが正
しく収集されていたと判断し，被験者2は240ページ中221ページが正しく収集さ
れていたと判断した．各被験者による適合率は95(=228/240)\%と92(=221/240)\%
で，その平均は94\%あった．この数字を見るかぎり十分な質のコーパスが得られ
たと考えられる．
\begin{table}[h]
 \begin{center}
  \caption{適合率}
  \label{eval1}
    \begin{tabular}{lc@{}cc@{}c}\hline
                      & \multicolumn{2}{c}{被験者1} & \multicolumn{2}{c}{被験者2} \\ \hline
   書き言葉コーパス   & 95\% & (119/125) & 89\% & (110/125) \\
   話し言葉コーパス   & 94\% & (109/115) & 97\% & (111/115) \\ \hline
   合計               & {\bf 95\%} & (228/240) & {\bf 92\%} & (221/240) \\ \hline
  \end{tabular}
 \end{center}
\end{table}

\paragraph{具体例}
以下に，自動収集された書き言葉コーパスの一部を示す．
\begin{itemize}
 \item 世界的に患者が広まっているＳＡＲＳに関して，２００３年４月３日か
       ら上海の各種新聞，テレビ，ラジオも報道し始めた．３月下旬ごろに１
       度「上海では確認されていない．」という報道がされて以来だ．報道に
       よれば現在上海市では一人の患者がＳＡＲＳの疑いがあるということで
       病院に隔離されている．
       
 \item 静岡市を流れる安倍川流域で，江戸時代に「友釣り禁止令」が出された．
       友釣りという漁法が流行して，その面白さに若者が熱中した．「肝心な
       農業を放棄して困る」というのが，禁止令の理由である．百四十年以上
       も昔から，友釣りに夢中だったお国柄のことだ．本県が今「友釣り人口
       日本一」といわれる理由は，このように歴史が証明している．アユ特集
       の県内各河川漁協で見るように，今年は天然アユが極めて大量に川を上っ
       た．

 \item 診察室で医療者がみる姿かたちだけでなく，患者の目や心に映るこうし
       た波風を理解し，それに基づいて日々の医療を創りあげて行くことが，
       いわゆるＱＯＬを重視した医療であろう．一人ひとりの患者のＱＯＬを
       知るには，基本的には彼女に問いかけ，話をよく聴く以外に術はない．
\end{itemize}
次に，話し言葉コーパスの一部を示す．
\begin{itemize}
 \item 美味しいキムチを食べましょ〜！最近よくお客さんから質問される事が
       あります．「スーパーでよくキムチを買うんやけどスーパーで売ってい
       るキムチって何で酸っぱいの？」結構こんな印象を持ってる人がたくさ
       んいますよね．いつも聞かれたらこう答えるようにしています．「スー
       パーで売ってるキムチって大半がキムチと違う物やからやで」

 \item 今日、久しぶりにガンダムやってたねー．新聞見りゃ判ることだけど，
       一応教えとこと思って．電話したら，繋がりませんでした，ＰＨＳ．山
       奥へ走りに行ってたのかな？

 \item これに２５６ＭＢのメモリ乗せてマシンに負担のかかることをするのが
       楽しい．もうほとんどホビーだね，この感覚は．だってすぐベンチとり
       たくなるしね．やっぱり新しいシステムってわくわくするんだよ．クロッ
       クアップはしていない．ほら、いちおう業務マシンだから．
       
 \item 谷口：私ぐらいの歳になるとね・・・なかなか見つからないよ〜そう言
       う黒田君　最近仕事はどう？忙しい？\\
       黒田：仕事の量は同じですけどネ〜単価を値切られて困ってます．同じ
       だけの枚数書いても半分の値段ですから・・・\\
       谷口：でもあるだけでもイイじゃないの？世の中不景気だからネ〜
\end{itemize}


\paragraph{議論}
話し言葉として収集されたコーパス(115ページ)を分析したところ，多くの部分
は，掲示板(チャットも含める)や個人の日記のページから収集されていることが
分かった．29ページが掲示板から，18ページが個人の日記から収集されていた．
この結果は，我々の置いた仮説と一致する．また，具体例の最後にあるような，
発話や対談の書き起こし(または書き起こし風)のページが10ページ含まれていた．

提案手法は，親愛表現と丁寧表現を全く含んでいないページを，書き言葉コーパ
スとして収集する．しかし実際には(5a)と(5b)のように，親愛表現と丁寧表現を
全く含んでいないにもかかわらず，話し言葉的である文は存在する．提案手法は，
こうした文をうまく扱うことができず，それが収集の適合率を下げる大きな原因
となっていた．
\vspace{10pt}
\begin{enumerate}
 \item
      \begin{enumerate}
       \item 昔から買ってあるのに読んでいない本を\underline{ちんたら}読
	     み進める．
       \item 前はこんな\underline{せこい}こと言う店ではなかったのに．
      \end{enumerate}
\end{enumerate}
\addtocounter{exnum}{1}
\vspace{10pt}

今後は，今回の実験で収集された書き言葉コーパスと話し言葉コーパスを利用し
て，こうした文も扱えるようにしていきたい．具体的な方法としては，収集され
たコーパスと\cite{Kilgarriff01}などで議論されている手法を使い，書き言葉
や話し言葉に特有の語彙を自動学習し，それを利用することを考えている．例え
ば，「ちんたら」や「せこい」といった語が話し言葉に特有の語彙であることを
学習できれば，(5a)と(5b)は，いずれも話し言葉的な文であると判断することが
できる．

こうした改良を行えば，収集の精度が上がるだけでなく，収集されるコーパスの
規模を増やす効果も期待できる．今回の実験では，WWWコーパス336,341ページの
うち，書き言葉又は話し言葉コーパスとして収集されたのは，
71,658(38,472$+$33,186)ページであったが，さらに大規模なコーパス収集が可
能になると考えられる．


\section{言い換えペアの選択}
収集された書き言葉コーパスと話し言葉コーパスを用いて，
\ref{sec:learn}節で学習された言い換えペアの中から，sourceが書き言葉特
有語彙でtargetが話し言葉語彙であるような言い換えペアを選択する．このよ
うな言い換えペアを正例，それ以外の言い換えペアを負例と考れば，解くべき問
題は二値分類であると考えることができる．

本論文は，Support Vector Machine\cite{Vapnik95}を用いた手法を提案する．
ある表現が書き言葉特有語彙であるか話し言葉語彙であるかは，その表現の
書き言葉コーパスでの出現確率と話し言葉コーパスでの出現確率から判断で
きると考えられる．そこで，SVMに与える素性は，以下の4つの出現確率を用いた．
各素性は0から1までの連続値をとる．
\begin{list}{}{}
 \item[(1)] sourceの書き言葉コーパスでの出現確率
 \item[(2)] sourceの話し言葉コーパスでの出現確率
 \item[(3)] targetの書き言葉コーパスでの出現確率
 \item[(4)] targetの話し言葉コーパスでの出現確率
\end{list}


\subsection{出現確率}
以下では，ある表現$e$のコーパスでの出現確率($P(e)$)の計算方法を説明する．
上記の4つの素性は，この計算方法にしたがって求める．

\paragraph{出現頻度}
$P(e)$を求めるためには，まず，出現頻度($F(e)$)を求める必要がある．基本的
には，コーパスを形態素解析，構文解析すれば求まるが，以下の三点に留意した．
なお，形態素解析にはJUMAN，構文解析にはKNPを用いた．

まず第一に，同じ用言でも態が異なれば，異なる用言として出現頻度を数えた．
これは，用言の中には使役や受身などの態の違いによって出現頻度が大きく異な
るものがあるからである．例えば「漂う」と使役形「漂わせる」では，出現頻度
が大きく異なる．

次に，データスパースネスの問題に対処するため，副詞を無視するという近似を
行った．\ref{sec:learn}節ですでに述べたように，言い換えペアのtargetは
「副詞\hspace{-1pt}$*$体言\hspace{-1pt}$+$用言」という形をしている．$e$
がtargetで，たくさんの副詞や体言を含んでいるときには，すべて頻度が0になっ
てしまうことが考えられる．そこで，$e$の頻度を求めるさいには，副詞を無視
するという近似を行った．例えば「早く走る」の出現頻度は，コーパス中の「走
る」の出現頻度で近似する．副詞ではなく体言を無視するという近似も考えられ
るが，(6a)や(6b)の下線部のように体言と用言は慣用句を形成することがあり，
そうした場合に体言を無視してしまうと意味が大きく変わってしまうので，副詞
を無視するという近似を採用した．
\vspace{10pt}
\begin{enumerate}
 \item
      \begin{enumerate}
       \item {\bf 入手する}

	     \underline{手に入れる}こと
	     
       \item {\bf 憤る}
	     
	     \underline{腹を立てる}
      \end{enumerate}
\end{enumerate}
\addtocounter{exnum}{1}
2節で学習された5,836の言い換えのペアのうち，targetが副詞を含んでいるもの
は1436個，体言を含んでいるものは839個であった．

最後に，構文解析結果はすべて利用するのではなく，信頼度の高い部分だけを利
用した．$e$が体言を含んでいる場合に$F(e)$を求めるには，コーパス中の体言
と用言の係り受け情報が必要なので，構文解析が必要となる．しかし，構文解析
精度(90\%)は形態素解析の精度(99\%)と比べると低く，誤りが多い．そこで
\cite{Kawahara01}と同様のヒューリスティクスを使って，構文解析の信頼度の
高い部分だけを利用した．\cite{Kawahara01}の報告によると，このヒューリス
ティクスによって信頼度が高いと判断された部分では，構文解析の精度は97\%で
ある．


\paragraph{出現確率}
$F(e)$から$P(e)$を求める．一般に，$P(e)$は次のような式で定義される．
\begin{quote}
 $P(e)=F(e)/$ コーパス中の全表現数
\end{quote}
$e$が名詞を含んでいない場合，$F(e)$を計算するのにコーパス全体を使用する
のに対して，$e$が名詞を含んでいる場合，コーパスは解析の確信度の高い部分
しか使わない．そのため，$e$が名詞を含んでいる場合と含んでいない場合で，
上式の分母「コーパス中の全表現数」の値を変えるべきである．このことを踏ま
えて，$P(e)$を次のように計算する．
\begin{flushleft}
 \underline{$e$が名詞を含まない}
 \begin{quote}
  $P(e)=F(e)/$ コーパス中の用言数
 \end{quote}
 \underline{$e$が名詞を含む}
 \begin{quote}
  $P(e)=F(e)/$ コーパス中の「体言-用言」数
 \end{quote}
\end{flushleft}
「体言-用言」は，係り受けの関係にある体言と用言のペアをあらわす．「体言-
用言」数は，$F(e)$と同様に，構文解析の信頼度が高い部分だけで数える．

表\ref{tab:verb_num}に，学習された書き言葉コーパスと話し言葉コーパス
における用言数と「体言-用言」数を示す．いずれのコーパスでも，用言数は
「体言-用言」数よりも非常に大きな値となっており，上記のように2通りの計算
方法を用意する必要があることが分かる．
\begin{table}[h]
 \caption{各コーパスの用言数と「体言-用言」数}
 \label{tab:verb_num}
 \begin{center}
  \begin{tabular}{crr}\hline
                &        用言数 & 「体言-用言」数  \\ \hline
     書き言葉 &     3,169,253 &      769,876 \\
     話し言葉 &     5,186,414 &      849,905 \\ \hline
  \end{tabular}
 \end{center}
\end{table}


\subsection{評価}
2人の被験者がSVMで学習するためのデータセットを作成し，提案手法の評価を行っ
た．

\paragraph{データセット}
データセットは以下のように作成した．まずKajiらの手法を用いて，例解小学国
語辞典\cite{RSK97}から言い換えペアを自動学習した．そして，各言い換えペア
を2人の被験者が正例と負例に分類して，2人の被験者の判断が一致した200の言
い換えペアをデータセット(正例が70個，負例が130個)とした．

データセットを作成するために要した言い換えペアは247個であった．つまり，
被験者の判断が一致しなかった言い換えペアが47個あった．被験者の判断の一致
度を示すKappa統計量を求めたところ0.627であった．以下に，被験者の判断が一
致しなかった例を示す．
\vspace{10pt}
\begin{enumerate}
 \item 殺到する $\rightarrow$ 一度にどっと、おしよせる
\end{enumerate}
\vspace{10pt}
(7)の判断が食い違ったのは，targetがまわりくどい表現であることに一因があ
ると考えられる．targetは定義文から自動抽出されているが，定義文は一般のテ
キストよりもまわりくどい傾向があり，targetにも同様の傾向がみられる．そう
した表現を自然な話し言葉と考えるかどうかが，判断を別れさせる要因になった
と考えることができる．


\paragraph{実験結果}
20分割の交差検定によって評価を行った．実装には学習パッケージTinySVM
\footnote{
http://cl.aist-nara.ac.jp/{\tt\symbol{"7E}}taku-ku/software/TinySVM/"
}を用いた．カーネル関数を用いない場合(linear)と，カーネル関数に2次，3次
の多項式関数を使った場合(poly2，poly3)で実験を行った．表\ref{tab:result}
に，それぞれの場合の正例と負例の分類精度，正例に分類された言い換えペアの
適合率，正しく正例に分類された言い換えペアの再現率の値を示す．また，F値
もあわせて示す．各値は交差検定を行ったときの平均値となっている．カーネル
関数に2次の多項式を使った場合の精度が最も高く，そのときの精度は79\%であっ
た．交差検定を行ったときのF値のばらつきを調べたところ，標準偏差は23であっ
た．ばらつきは大きいが，これは，20分割した一つ一つのデータセットの規模が
小さいからであると考えることができる．
\begin{table}[h]
 \caption{実験結果}
 \label{tab:result}
\begin{center}
  \begin{tabular}{l||r|r|r}\hline
             & linear & poly2      & poly3 \\ \hline
   精度      & 72\%   & \bf{79\%}  & 76\%  \\
   適合率    & 60\%   & \bf{69\%}  & 63\%  \\
   再現率    & 59\%   & \bf{72\%}  & 62\%  \\
   F値      & 59\%   & \bf{70\%}  & 62\%  \\ \hline
  \end{tabular}
\end{center}
\end{table}


\paragraph{議論}
SVMに与える素性として使った出現確率は，自動収集された書き言葉コーパス
と話し言葉コーパスから求めている．つまり，素性の値は自動学習されている．
さらに，今回用意したデータセットも比較的小規模なものである．このことを踏
まえると，実験結果の79\%は十分に高い精度であり，使用した4つの素性は有効
に働いていると考えることができる．

求められた出現確率の中には，人間の直感と反する不適切な値が計算されたもの
があり，精度を下げている原因となっていた．そのような例として「観劇する」
がある．「観劇する」は，書き言葉特有語彙であると考えることができるが，
書き言葉コーパスで4回，話し言葉コーパスで43回出現していた．これを出現確
率になおすと，話し言葉コーパスでは書き言葉コーパスの約8倍出現していたこ
とになる．これは，コーパスを収集したWWWに一因があると考えられる．つまり，
観劇に関するWebページの大部分は劇好きの掲示板などであり，ニュース記事な
どは数が少ないと考えることができる．そのため，収集された書き言葉コーパス
は観劇の話題を殆んど含まず，「観劇する」が話し言葉コーパスの方により多く
出現したと考えることができる．

書き言葉コーパスと話し言葉コーパスの2コーパスを利用するという提案手法の
有効性を確かめるために，次のような2つの実験を行い，その結果を提案手法と
比較した．
\begin{itemize}
 \item 日本語には漢語と和語があり，大雑把にいうと前者は書き言葉特有語彙
       であり，後者は話し言葉語彙であると言える．そこで，sourceが漢語で
       targetが和語である言い換えペアを正例，それ以外を負例に分類した場
       合の，精度，適合率，再現率を求めた．ここでは，用言がサ変名詞であ
       れば漢語，それ以外ならば和語とした．実験の結果，精度，適合率，再
       現率はそれぞれ，59\%，40\%，39\%であった．
       
 \item 書き言葉コーパスと話し言葉コーパスの2コーパスを利用しなくとも，
       sourceとtargetの単純な使われやすさが分かれば，正例と負例をうまく
       分類できると考えることもできる．そこで，収集した書き言葉コーパス
       と話し言葉コーパスを1つにまとめた混合コーパスを使って，提案手法と
       同様にSVMを使って分類を行った．ここで素性に使ったのは，sourceの混
       合コーパスでの出現確率と，targetの混合コーパスでの出現確率の2つで
       ある．この二つの素性によって，sourceとtargetの単純な使われやすさ
       を学習できると考えられる．実験の結果，カーネル関数に3次の多項式関
       数を使った場合の結果が最も良かったが，精度，適合率，再現率はそれ
       ぞれ，71\%，57\%，46\%であった．
\end{itemize}       
提案手法は，上記の手法をいずれも上回る結果となり，書き言葉コーパスと話し
言葉コーパスを利用することの優位性を示すことができた．



\paragraph{具体例}
表\ref{tab:example}に，正例に分類された言い換えペアと，負例に分類された
言い換えペアの具体例と，それらの言い換えペアのもつ素性の値を示す．素性の
列は左から，sourceの書き言葉コーパスでの出現確率，sourceの話し言葉コーパ
スでの出現確率，targetの書き言葉コーパスでの出現確率，targetの話し言葉コー
パスでの出現確率を表す．出現確率は「出現頻度/コーパスの全表現数」という
表記になっている．targetの「コーパスの全表現数」は，targetが体言を含む場
合とそうでない場合で違った値になっている．×印は，言い換えペアの分類結果
が間違っていることを表す．

「商う $\rightarrow$ 商売をする」「食事する$\rightarrow$食べる」「優先す
る$\rightarrow$先に扱う」などは，sourceとtargetが漢語でるか和語であるか，
だけに注目していたのでは，正しく分類するのが難しい例であるが，提案手法で
はうまく分類できている．
\begin{table}[h]
 \caption{具体例}
 \label{tab:example}
 \begin{center}
  {\footnotesize
  \begin{tabular}{@{}c@{}|c@{}l|rrrr@{}}\hline
             &  &                                     & \multicolumn{4}{c}{素性}                                      \\ \cline{4-7}
    分類結果 &    \multicolumn{2}{c|}{言い換えペア}   & \multicolumn{2}{c}{source}    & \multicolumn{2}{c}{target}    \\ 
             &  &                                     & 書き言葉    &  話し言葉   & 書き言葉    & 話し言葉    \\ \hline
             &  & 商う $\rightarrow$ 商売をする       & 4/3,169,253   &  6/5,186,414  & 15/769,876    & 21/849,905    \\ [3pt]
             &  & 激化する $\rightarrow$ はげしくなる & 151/3,169,253 &  17/5,186,414 & 152/3,169,253 & 88/5,186,414  \\ [3pt]
    正       &  & 受諾する $\rightarrow$ 引き受ける   &  50/3,169,253 &   5/5,186,414 & 280/3,169,253 & 259/5,186,414 \\ [3pt]
    例       &  & 発汗する $\rightarrow$ 汗をかく     &   1/3,169,253 &   5/5,186,414 &  50/769,876   & 119/849,905   \\ [3pt]
             &×& きざだ   $\rightarrow$ 気取っている &   1/3,169,253 &   0/5,186,414 &  40/3,169,253 & 129/5,186,414 \\ [3pt]
             &×& 上京する $\rightarrow$ 東京へ行く   &  80/3,169,253 & 132/5,186,414 &   3/769,876   &  23/849,905   \\ \hline
             &  & へばる $\rightarrow$ へとへとに疲れる   &   6/3,169,253 &  36/5,186,414 &  32/3,169,253   & 366/5,186,414    \\ [3pt]
             &  & 食事する $\rightarrow$ 食べる           &  27/3,169,253 & 170/5,186,414 & 3,114/3,169,253 & 17,239/5,186,414 \\ [3pt]
   負        &  & 優先する $\rightarrow$ 先に扱う         & 312/3,169,253 & 249/5,186,414 & 2,008/3,169,253 & 2,125/5,186,414  \\ [3pt]
   例        &  & 引越しする $\rightarrow$ 転居する       &   3/3,169,253 &  89/5,186,414 &  35/3,169,253   &    14/5,186,414  \\ [3pt]
             &×& 伝聞する   $\rightarrow$ 伝え聞く       &   0/3,169,253 &   1/5,186,414 &  16/3,169,253   &    14/5,186,414  \\ [3pt]
             &×& 軟化する $\rightarrow$ 軟らかくなる     &  25/3,169,253 &   5/5,186,414 &  11/3,169,253   &     2/5,186,414  \\ \hline
  \end{tabular}
  }
 \end{center}
\end{table}

\paragraph{今後の課題}
畠の分類からも明らかなように，一口に話し言葉といっても様々な種類が存在す
る．本論文では，冗長性の高い話し言葉のみを扱っており，この問題に深く立ち
入らなかったが，今後は話し言葉のより詳細な分類を行い，その分類も考慮した
言い換えに取り組む予定である．

本論文で扱った用言の言い換え以外にも，複合名詞の言い換えや統語構造の変換
なども「書き言葉から話し言葉への言い換え」に必要であり，今後，取り組んで
いきたい．


\section{まとめ}
本論文では，話し言葉特有語彙から話し言葉語彙への言い換えを学習する方
法について述べた．提案手法は，書き言葉コーパスと話し言葉コーパスを
WWWから自動収集して，それらのコーパスでの出現確率を利用するものである．
実験の結果，書き言葉コーパスと話し言葉コーパスの収集精度は94\%，言い
換え学習の精度は79\%であり，提案手法の有効性を確認することができた．


\bibliographystyle{jnlpbbl}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Barzilay \BBA\ Lee}{Barzilay \BBA\
  Lee}{2003}]{Barzilay03}
Barzilay, R.\BBACOMMA\  \BBA\ Lee, L. \BBOP 2003\BBCP.
\newblock \BBOQ Learning to Paraphrase: An Unsupervised Approach Using
  Multiple-Sequence Alignment\BBCQ\
\newblock In {\Bem Proceedings of HLT/NAACL2003}.

\bibitem[\protect\BCAY{Bulyko\JBA Ostendorf \BBA\ Stolcke}{Bulyko
  et~al.}{2003}]{Bulyko03}
Bulyko, I.\JBA Ostendorf, M.\JBA  \BBA\ Stolcke, A. \BBOP 2003\BBCP.
\newblock \BBOQ Getting More Mileage from Web Text Sources for Conversational
  Speech Language Modeling using Class-Dependent Mixtures\BBCQ\
\newblock In {\Bem Proceedings of HLl/NAACL2003}, \BPGS\ 7--9.

\bibitem[\protect\BCAY{Duclaye \BBA\ Yvon}{Duclaye \BBA\
  Yvon}{2003}]{Duclaye03}
Duclaye, F.\BBACOMMA\  \BBA\ Yvon, F. \BBOP 2003\BBCP.
\newblock \BBOQ Learning Paraphrases to Improve a Question-Answering
  System\BBCQ\
\newblock In {\Bem Proceedings of the 10th Conference of EACL Workshop Natural
  Language Processing for Question-Answering}.

\bibitem[\protect\BCAY{Edmonds \BBA\ Hirst}{Edmonds \BBA\
  Hirst}{2002}]{Edmonds02}
Edmonds, P.\BBACOMMA\  \BBA\ Hirst, G. \BBOP 2002\BBCP.
\newblock \BBOQ Near-Synonymy and Lexical Choice\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 28}  (2), 105--144.

\bibitem[\protect\BCAY{Fukuhara\JBA Nishida \BBA\ Uemura}{Fukuhara
  et~al.}{2001}]{Fukuhara01}
Fukuhara, T.\JBA Nishida, T.\JBA  \BBA\ Uemura, S. \BBOP 2001\BBCP.
\newblock \BBOQ Public Opinion Channel: A System for Augmenting Social
  Intelligence of a Community\BBCQ\
\newblock In {\Bem Workshop notes of the JSAI-Synsophy International Conference
  on Social Intelligence Design}, \BPGS\ 22--25.

\bibitem[\protect\BCAY{畠弘巳}{畠弘巳}{1987}]{Hatake87}
畠弘巳 \BBOP 1987\BBCP.
\newblock \JBOQ 話しことばの特徴ー冗長性をめぐってー\JBCQ\
\newblock \Jem{「国文学 解釈と鑑賞」}, {\Bbf 52}  (7), 22--34.

\bibitem[\protect\BCAY{Hayashi\JBA Ueda\JBA Kurihara\JBA Yasumura\JBA Douke
  \BBA\ Ariyasu}{Hayashi et~al.}{1999}]{Hayashi99}
Hayashi, M.\JBA Ueda, H.\JBA Kurihara, T.\JBA Yasumura, M.\JBA Douke, M.\JBA
  \BBA\ Ariyasu, K. \BBOP 1999\BBCP.
\newblock \BBOQ TVML (TV program Making Language) - Automatic TV program
  Generation from Text-based Script -\BBCQ\
\newblock In {\Bem ABU Technical Review}.

\bibitem[\protect\BCAY{Hermjakob\JBA Echihabi \BBA\ Marcu}{Hermjakob
  et~al.}{2002}]{Ulf02}
Hermjakob, U.\JBA Echihabi, A.\JBA  \BBA\ Marcu, D. \BBOP 2002\BBCP.
\newblock \BBOQ Natural Language Based Reformulation Resource and Web
  Exploitation for Question Answering\BBCQ\
\newblock In {\Bem Proceedings of TREC2002 Conference}.

\bibitem[\protect\BCAY{Inkpen \BBA\ Hirst}{Inkpen \BBA\ Hirst}{2001}]{Inkpen01}
Inkpen, D.~Z.\BBACOMMA\  \BBA\ Hirst, G. \BBOP 2001\BBCP.
\newblock \BBOQ Building a Lexical Knowledge-Base of Near-Synonym
  Differences\BBCQ\
\newblock In {\Bem Proceedings of Workshop on WordNet and Other Lexical
  Sources}, \BPGS\ 47--52.

\bibitem[\protect\BCAY{Inui\JBA Fujita\JBA Takahashi\JBA Iida \BBA\
  Iwakura}{Inui et~al.}{2003}]{Inui03}
Inui, K.\JBA Fujita, A.\JBA Takahashi, T.\JBA Iida, R.\JBA  \BBA\ Iwakura, T.
  \BBOP 2003\BBCP.
\newblock \BBOQ Text Simplification for Reading Assistance: A Project
  Note\BBCQ\
\newblock In {\Bem Proceedings of the Second International Workshop on
  Paraphrasing}, \BPGS\ 9--16.

\bibitem[\protect\BCAY{Inui \BBA\ Yamamoto}{Inui \BBA\ Yamamoto}{2001}]{Inui01}
Inui, K.\BBACOMMA\  \BBA\ Yamamoto, S. \BBOP 2001\BBCP.
\newblock \BBOQ Corpus-Based Acquisition of Sentence Readability Ranking Models
  for Deaf People\BBCQ\
\newblock In {\Bem Proceedings of NLPRS2001}.

\bibitem[\protect\BCAY{Kaji\JBA Kawahara\JBA Kurohashi \BBA\ Sato}{Kaji
  et~al.}{2002}]{Kaji02}
Kaji, N.\JBA Kawahara, D.\JBA Kurohashi, S.\JBA  \BBA\ Sato, S. \BBOP
  2002\BBCP.
\newblock \BBOQ Verb Paraphrase based on Case Frame Alignment\BBCQ\
\newblock In {\Bem Proceedings of ACL2002}, \BPGS\ 215--222.

\bibitem[\protect\BCAY{Kawahara \BBA\ Kurohashi}{Kawahara \BBA\
  Kurohashi}{2001}]{Kawahara01}
Kawahara, D.\BBACOMMA\  \BBA\ Kurohashi, S. \BBOP 2001\BBCP.
\newblock \BBOQ Japanese Case Frame Construction by Coupling the Verb and its
  Closest Case Component\BBCQ\
\newblock In {\Bem Proceedings of HLT2001}, \BPGS\ 204--210.

\bibitem[\protect\BCAY{Kilgarriff}{Kilgarriff}{2001}]{Kilgarriff01}
Kilgarriff, A. \BBOP 2001\BBCP.
\newblock \BBOQ Comparing Corpora\BBCQ\
\newblock {\Bem International Journal of Corpus Linguistics}.

\bibitem[\protect\BCAY{Lin \BBA\ Pantel}{Lin \BBA\ Pantel}{2001}]{Lin01}
Lin, D.\BBACOMMA\  \BBA\ Pantel, P. \BBOP 2001\BBCP.
\newblock \BBOQ Discovery of inference Rules for Question Answering\BBCQ\
\newblock {\Bem Journal of Natural Language Engneering}, {\Bbf 7}  (4),
  343--360.

\bibitem[\protect\BCAY{Maekawa\JBA Koiso\JBA Furui \BBA\ Isahara}{Maekawa
  et~al.}{2000}]{Maekawa00}
Maekawa, K.\JBA Koiso, H.\JBA Furui, S.\JBA  \BBA\ Isahara, H. \BBOP 2000\BBCP.
\newblock \BBOQ Spontaneous Speech Corpus of Japanese\BBCQ\
\newblock In {\Bem Proceedings of LREC2000}, \BPGS\ 947--952.

\bibitem[\protect\BCAY{Murata \BBA\ Isahara}{Murata \BBA\
  Isahara}{2002}]{Murata02}
Murata, M.\BBACOMMA\  \BBA\ Isahara, H. \BBOP 2002\BBCP.
\newblock \BBOQ Automatic Extraction of Differences between Spoken and Written
  languages, and Automatic Translation from the Written to the Spoken
  Language\BBCQ\
\newblock In {\Bem Proceedings of the LREC2002}.

\bibitem[\protect\BCAY{Nadamoto\JBA Kondo \BBA\ Tanaka}{Nadamoto
  et~al.}{2001}]{Nadamoto01}
Nadamoto, A.\JBA Kondo, H.\JBA  \BBA\ Tanaka, K. \BBOP 2001\BBCP.
\newblock \BBOQ WebCarousel: Restructuring Web Search Results for Passive
  Viewing in Mobile Environments\BBCQ\
\newblock \Jem{7th International　Conference on Database Systems for Advanced
  Applications}, \BPGS\ 164--165.

\bibitem[\protect\BCAY{佐藤理史}{佐藤理史}{1999}]{Sato99}
佐藤理史 \BBOP 1999\BBCP.
\newblock \JBOQ 論文表題を言い換える\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 40}  (7), 2937--2945.

\bibitem[\protect\BCAY{Takezawa\JBA Sumita\JBA Sugaya\JBA Yamamoto \BBA\
  Yamamoto}{Takezawa et~al.}{2002}]{Takezawa02}
Takezawa, T.\JBA Sumita, E.\JBA Sugaya, F.\JBA Yamamoto, H.\JBA  \BBA\
  Yamamoto, S. \BBOP 2002\BBCP.
\newblock \BBOQ Toward a broad-coverage bilingual corpus for speech translation
  of travel conversations in the real world\BBCQ\
\newblock In {\Bem Proceedings of LREC2002}, \BPGS\ 147--152.

\bibitem[\protect\BCAY{Tambouratzis\JBA Markantonatou\JBA Hairetakis\JBA
  Vassiliou\JBA Tambouratzis \BBA\ Carayannis}{Tambouratzis
  et~al.}{2000}]{Tam00}
Tambouratzis, G.\JBA Markantonatou, S.\JBA Hairetakis, N.\JBA Vassiliou, M.\JBA
  Tambouratzis, D.\JBA  \BBA\ Carayannis, G. \BBOP 2000\BBCP.
\newblock \BBOQ Discriminating the registers and styles in the Modern Greek
  language\BBCQ\
\newblock In {\Bem Proceedings of Workshop on Comparing Corpora 2000}.

\bibitem[\protect\BCAY{Vapnik}{Vapnik}{1995}]{Vapnik95}
Vapnik, V. \BBOP 1995\BBCP.
\newblock {\Bem The Nature of Statistical Learning Theory}.
\newblock Springer.

\bibitem[\protect\BCAY{村田真樹\JBA 井佐原均}{村田真樹\JBA
  井佐原均}{2001}]{Murata01}
村田真樹\JBA  井佐原均 \BBOP 2001\BBCP.
\newblock \JBOQ 言い換えの統一的モデルー尺度に基づく変形の利用ー\JBCQ\
\newblock \Jem{言語処理学会第7回ワークショップ論文集}, \BPGS\ 21--26.

\bibitem[\protect\BCAY{大石初太郎}{大石初太郎}{1970}]{Ohishi70}
大石初太郎\JED\ \BBOP 1970\BBCP.
\newblock \Jem{話し言葉}.
\newblock 文化庁.

\bibitem[\protect\BCAY{田近洵一}{田近洵一}{1997}]{RSK97}
田近洵一\JED\ \BBOP 1997\BBCP.
\newblock \Jem{例解小学国語辞典}.
\newblock 三省堂.

\end{thebibliography}

\begin{biography}
\bioauthor{鍜治 伸裕}{2000年京都大学工学部電気電子工学科卒業．2002年京都
 大学大学院情報学研究科修了．現在，東京大学大学院情報理工学系研究科博士
 後期課程在学中．自然言語処理の研究に従事．
 }
 \bioauthor{岡本 雅史}{1994年早稲田大学政治経済学部政治学科卒業．1996年
 京都大学大学院人間・環境学研究科博士前期課程修了．1999年同大学院博士後
 期課程単位所得認定退学．現在，東京大学大学院情報理工学系研究科学術研究
 支援員．博士(人間・環境学)．認知言語学，語用論，コミュニケーション論の
 研究に従事．
 }
\bioauthor{黒橋 禎夫}{1989年京都大学工学部電気工学科第二学科卒業．1994年
 同大学院博士課程修了．京都大学工学部助手，京都大学大学院情報学研究科講
 師を経て，2001年東京大学大学院情報理工学系研究科助教授，現在に至る．自
 然言語処理，知識情報処理の研究に従事．
}
\end{biography}

\end{document}
