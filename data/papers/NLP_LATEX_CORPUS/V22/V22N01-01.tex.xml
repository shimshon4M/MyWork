<?xml version="1.0" ?>
<root>
  <jtitle>対話解析のためのゼロ代名詞照応解析付き述語項構造解析</jtitle>
  <jauthor>今村賢治東中竜一郎泉朋子</jauthor>
  <jabstract>本稿では，日本語を対象とした対話用述語項構造解析を提案する．従来，述語項構造解析は，主に新聞記事を対象に研究されてきた．新聞と対話ではさまざまな違いが存在するが，本稿ではこれを包括的に扱うため，対話用述語項構造解析器の構築を，新聞から対話への一種のドメイン適応とみなす．具体的には，対話では省略や代名詞化が新聞記事に比べて頻繁に現れるため，ゼロ代名詞照応機能付きの述語項構造解析をベースとし，これを対話に適応させる．パラメータ適応と，訓練コーパスがカバーしきれない語彙知識を大規模平文コーパスから自動獲得することにより，新聞記事用のものに比べ，対話に対して高精度な述語項構造解析を実現した．</jabstract>
  <jkeywords>述語項構造解析，ゼロ代名詞照応，対話，ドメイン適応，係り受け言語モデル</jkeywords>
  <section title="はじめに">述語項構造解析(predicate-argumentstructureanalysis)は，文から述語とその格要素（述語項構造）を抽出する解析タスクである．述語項構造は，「誰が何をどうした」を表現しているため，この解析は，文の意味解析に位置付けられる重要技術の一つとなっている．従来の述語項構造解析技術は，コーパスが新聞記事であるなどの理由で，書き言葉で多く研究されてきた．一方，近年のスマートフォンの普及に伴い，Apple社のSiri，NTTドコモ社のしゃべってコンシェルなど，音声による人とコンピュータの対話システムが，身近に使われ始めている．人・コンピュータの対話システムを構築するためには，人間の発話を理解し，システム発話とともに管理する必要があるが，述語項構造は，対話理解・管理に対しても有効なデータ形式であると考えられる．しかし，新聞記事と対話では，発話人数，口語の利用，文脈など，さまざまな違いがあるため，既存の新聞記事をベースとした述語項構造解析を対話の解析に利用した際の問題は不明である．たとえば，以下の対話例を考える．この例では，最初の発話から，述語が「ほしい」，そのガ格が「iPad」である述語項構造が抽出される．2番目の発話では，述語が「買う」であることはわかるが，ガ格，ヲ格が省略されているため，述語項構造を得るためには，ガ格が発話者A，ヲ格が「iPad」であることも併せて解析する必要がある．このように，対話では省略がごく自然に出現する（これをゼロ代名詞と呼ぶ）ため，日本語の対話の述語項構造解析には，ゼロ代名詞照応解析処理も必要となる．本稿では，人とコンピュータの対話システム実現のため，従来に比べ対話を高精度に解析する述語項構造解析を提案する．本稿で対象とするタスクは，以下の2点をともに解決するものである．日本語で必須格と言われているガ格，ヲ格，ニ格に対して，述語能動形の項を決定する．ゼロ代名詞照応解析を行い，文や発話内では項が省略されている場合でも，先行した文脈から項を決定する．本稿の提案骨子は，対話のための述語項構造解析器の構築を，新聞から対話へのドメイン適応とみなすことである．具体的には，新聞記事用に提案されたゼロ代名詞照応機能付き述語項構造解析を，話題を限定しない雑談対話に適応させる．そして，対話と新聞のさまざまな違いを，個々の違いを意識することなく，ドメイン適応の枠組みで包括的に吸収することを目指す．は，意味役割付与のドメイン適応に必要な要素として，未知語対策とパラメータ分布の違いの吸収を挙げている．本稿でも，未知語およびパラメータ分布の観点から対話に適応させる．そして，新聞記事用より対話に対して高精度な述語項構造解析を提案する．我々の知る限り，ゼロ代名詞を多く含む対話を，高精度に解析する述語項構造解析器は初である．以下，第章では，英語意味役割付与，日本語述語項構造解析の関連研究について述べる．章では，我々が作成した対話の述語項構造データと新聞の述語項構造データを比較し，対話の特徴について述べる．第章では，今回ベースとした述語項構造解析方式の概要を述べ，第章では，これを対話用に適応させる．実験を通じた評価は章で述べ，第章でまとめる．</section>
  <section title="関連研究">近年の日本語の述語項構造解析は，教師あり学習をベースにしている．これは，英語の意味役割付与の考え方を参考にし，日本語の問題に当てはめたものである．英語の意味役割付与も，近年は意味役割として，述語とその項（格要素ごとの名詞句）に関する情報を付与しており，述語項構造解析と非常に似たタスクとなっている．</section>
  <subsection title="英語の意味役割付与">英語の意味役割付与は，が教師あり学習を用いた方式を提案して以来，コーパスが整備されてきた．国際ワークショップCoNLL-2004,2005で行われた共有タスクでは，PropBankを元にした評価が行われた．PropBankは，文に対して，述語とその項を注釈付けしたコーパスで，文自体は，PennTreebank（元記事はWallStreetJournal）から取られているため，ここで行われた評価も新聞記事に対するものである（このあたりの経緯は，が整理している）．OntoNotesは，ニュース記事，ニュース放送，放送における対話など，複数のジャンルを含んだコーパスである．付与された情報には，意味役割も含んでいるが，現在は共参照解析のデータとして使用されるに留まり，対話解析への適用はこれから期待されるところである．意味役割付与は，タスク指向対話の意味理解にも利用される場合がある．は，電話のコールセンタにおけるユーザとオペレータとの対話において，述語と項の対を素性としたコールタイプ分類器を構築している．ここで，述語・項の対は，ユーザ発話をPropBankベースの意味役割付与器で解析することで得ている．彼らの実験は，素性として用いる場合は新聞記事用の意味役割付与器でも効果があることを示したが，本稿では，対話における述語項構造解析自体の精度向上を狙っている．は，同じくコールセンタ対話に対して，FrameNetに準拠する意味役割付与を行っている．彼らは，コールセンタ対話を解析するため，分野依存の意味フレームをFrameNetに追加して，スロット（フレーム要素）の穴埋めを行っている．コールセンタ対話のように，意味役割が非常に限定される場合は，フレーム追加で対応できるが，タスクを限定しない雑談対話の場合は，分野依存フレームの追加は困難である．なお，述語だけでなく，事態性名詞（例えば，動詞`decide'に対する事態性名詞`decision'）に対する意味役割付与の研究もある．事態性名詞の場合，英語でも格要素を省略して表現することがあるため（たとえば，``thedecision''の対象格は省略されている），日本語のゼロ代名詞と同様の問題を解決する必要がある．</subsection>
  <subsection title="日本語の述語項構造解析">日本語では，奈良先端大が，述語項構造と照応データを新聞記事に付与したNAISTテキストコーパスを公開している．NAISTテキストコーパスは，毎日新聞の記事に対して，日本語で必須格と言われているガヲニ格の名詞句を，各述語に付与したものである．名詞句は，述語能動形の格に対して付与されている．また，名詞句は述語と同じ文内に限らず，ゼロ代名詞化されている場合は，先行詞までさかのぼって付与されている．述語項構造解析も，上記コーパスを利用したものが多く提案されている．日本語の場合，ゼロ代名詞が存在するため，述語項構造解析時に，文をまたがるゼロ代名詞照応も解釈する場合がある（たとえば）．新聞記事以外を対象とした述語項構造解析研究には，以下のものがある．は，ブログなどを含むWebテキストを対象に，特に一人称・二人称表現に焦点を当てた照応解析法を提案している．彼らは同時に述語項構造解析も行っており，本稿のタスクと類似している．彼らはWebテキストを解析するにあたり，外界照応（記事内に項の実体が存在しない）を著書（一人称），読者（二人称），その他の人，その他に分けるという拡張を行っている．本稿でも，NAISTテキストコーパス（バージョン1.5）の分類に従い，外界照応を一人称，二人称，その他に分け，項の推定を行う．また，は，ビジネスメールを対象とした述語項構造解析を試みている．彼らは新聞記事用の述語項構造解析器をそのままビジネスメール解析に適用したが，一人称・二人称外界照応は，ほとんど解析できなかったと報告している．英語，日本語いずれも，現状の意味役割付与，述語項構造解析は新聞記事のような正書法に則って記述されたテキストやWebテキスト，メールを対象としている．非常に限定されたタスクを扱うコールセンタ対話の例はあるが，タスクを限定しない雑談対話を解析した際の精度や問題点については不明である．</subsection>
  <section title="雑談対話の特徴">まず我々は，2名の参加者による雑談対話を収集し，その対話に述語項構造データの付与を行った．雑談対話は，参加者が自由なテーマ（話題）を設定し，キーボード対話形式で収集した．したがって，音声対話に含まれるような相槌や言い直しは少ない．参加者の話題は，食事，旅行，趣味，テレビ・ラジオなどである．述語項構造アノテーションは，NAISTテキストコーパスに準拠する形で行った．雑談対話と，その述語項構造解析アノテーションの例を図に示す．今回作成した雑談対話コーパスと，NAISTコーパスの統計量を表に示す．対話コーパスは，NAISTコーパスの約1/10のサイズである．また，1文/発話の長さ（形態素数）は，雑談対話コーパスはNAISTコーパスの1/3程度と短い．NAISTコーパスは，訓練，開発，テストに3分割したのに対し，対話コーパスは訓練とテストの2分割とした．対話の特徴を分析するため，この2つのコーパスの比較を行った．表は，訓練セットにおける項の分布を示したものである．各項は，述語との位置関係や文法関係などにより問題の難しさが異なるため，以下の6タイプに分類した．最初の2つ（係受および文内ゼロ）は述語と項が同じ文に存在する場合である．係受:述語と項が直接の係り受け関係にある場合文内ゼロ:述語と項が同じ文（発話）内にあるが，直接の係り受け関係がない場合文間ゼロ:述語と項が異なる文にある場合exo1/exo2/exog:項が記事（対話）内に存在しない外界照応．それぞれ，一人称ゼロ代名詞，二人称ゼロ代名詞，それ以外（一般）を表す．これを見ると，対話ではすべての格で，係受タイプの項が減少している．それ以外のタイプについては，ガ格と，ヲ格ニ格で傾向が異なっている．ガ格では，文内ゼロ代名詞も対話の場合に減少し，減少分は一人称・二人称外界照応(exo1,exo2)に割り当てられている．つまり，ガ格では，文内の項が減少し，ゼロ代名詞が新聞に比べて頻発する．ただし，その先行詞は一人称・二人称代名詞である可能性が高いと言うことができる．ヲ格ニ格では，係受タイプの項の減少分は，文間ゼロ代名詞またはその他の外界照応(exog)に割り振られている．つまり，新聞記事では，大部分は述語と同じ文内に現れていたヲ格ニ格の項が，対話では別の発話に現れることが多くなり，1文に閉じない照応解析が重要となる．</section>
  <section title="ゼロ代名詞照応付き述語項構造解析"/>
  <subsection title="基本方式">本稿でベースとする述語項構造解析は，の方法である．これは，新聞記事を対象とした方法であるが，文内に存在する項，文間の項，外界照応を同時に解析できるという特徴があるため，対話の解析にも適していると判断した．処理は，記事（対話）全体を入力とし，各文（発話）ごとに以下のステップを実行する．入力文を形態素・構文解析する．構文解析時には，同時に文節とその主辞を特定しておく．なお，今回は対話コーパスに関しては，形態素解析器MeCab，構文解析器CaboChaで形態素・文節係り受け・主辞情報を自動付与した．NAISTコーパスに関しては，NAISTコーパス1.5付属のIPA体系の形態素・構文情報を利用した．文から述語文節を特定する．今回は評価のため，コーパスの正解述語を用いたが，対話システム組み込みの際には，主辞が動詞，形容詞，形容動詞，名詞＋助動詞「だ」の文節を述語文節とし，品詞パターンで決定する．対象述語の存在する文，およびそれより前方の文から，項の候補となる文節を取得する．文節の内容語部を候補名詞句とする．具体的には，以下の文節が候補となる．対象述語の文に含まれる，内容語部が名詞句であるすべての文節を文内の候補とする．その際，述語文節との係り受け関係は考慮しない．対象述語より前方の文から，文脈的に項の候補となりうる文節を加え，文間の候補とする．詳細は節で述べる．記事内に実体を持たない疑似候補として，外界照応(exo1,exo2,exog)と，任意格のため格を必要としない(NULL)を特殊名詞句として加える．述語文節，項の候補名詞句，両者の関係を素性化し，ガ，ヲ，ニ格独立に，候補からもっとも各格にふさわしい名詞句を選択器で選択する（図）．本稿では，の方式から，若干の変更を行っている．変更点は以下のとおりである．では，特殊名詞句は1種類（NULLのみ）であったが，本稿では4種類(NULL,exo1,exo2,exog)に拡張した．は，外界照応を含む一人称，二人称ゼロ代名詞（論文では著者・読者表現）の照応解析を行うことで，それ以外のゼロ代名詞の照応解析精度も向上したと報告している．本稿でも，特殊名詞句の種別を増やすこととする．素性が異なる．本稿では，節で述べる素性を使用したが，これはの基本素性を拡張，追加したものである．また，文脈を考慮する素性（文献ではSRLOrder，Used）は使用せず，簡略化した．これは，文脈管理を外部モジュールに任せるためで，詳細はで述べる．係り受け言語モデル（節参照）を1種類から3種類に拡張した．</subsection>
  <subsection title="選択器のモデル">選択器のモデルは，最大エントロピー分類に基づく．具体的には，選択器は記事内の述語vごとに，候補名詞句集合Nから，以下の式を満たす名詞句nを選択する．n&amp;=argmax_n_jNP(d(n_j)=1|X_j;M_c)(d(n_j)=1|X_j;M_c)&amp;=1Z_c(X)_k_ckf_k(d(n_j)=1,X_j)_c(X)&amp;=_n_jN_k_ckf_k(d(n_j)=1,X_j)	_j&amp;=n_j,v,Aalignただし，nは1つの候補名詞句，Nは候補名詞句集合，d(n_j)は，名詞句n_jが項となったときのみ1となる関数，M_cは格c（ガ，ヲ，ニのいずれか）のモデルである．また，f_k(d(n_j)=1,X_j)は素性関数，_ckは格毎の素性関数の重み，v,Aはそれぞれ述語，および形態素・構文解析済みの記事全体である．訓練時には，ある述語の候補名詞句集合ごとに，正解の名詞句と，それ以外のすべての候補名詞句との事後確率差を大きくするように学習する．具体的には，以下の損失関数を最小化するモデルM_cを，格ごとに学習する．_c&amp;=-_iP(d(n_i)=1|X_i;M_c)+12C_k||_ck||^2alignただし，n_iは，訓練セットのi番目の述語に対する正解名詞句，X_iは，訓練セットのi番目の正解名詞句，述語，記事の組n_i,v_i,A_i，Cは過学習を制御するためのハイパーパラメータで，開発セットにおける精度が最高になるように，あらかじめ設定しておく．式()で，述語の候補名詞句集合毎に正規化を行っているため，()式では，候補名詞句集合から，正解名詞句が選ばれた時に確率1.0，それ以外の名詞句では確率0.0に近づくようにモデルが学習される．</subsection>
  <subsection title="素性">選択器で使用する素性に関しては，英語の意味役割付与に関する研究（たとえば）と同様に，(1)述語に関する素性，(2)名詞句に関する素性，(3)両者の関係に関する素性を使用する．詳細を表に示す．二値の素性関数は，テンプレートの引数が完全一致したときのみ1，それ以外では0を返す関数である．たとえばPred素性において，主辞形態素の見出しが1万種類あったとすると，1万の二値関数が定義され，主辞形態素の見出しと一致した関数だけが1を返す．実数値の素性関数は，テンプレートの引数に応じた実数を返す．なお，これらは名詞句の選択用モデルの素性であるので，名詞句Nounと，すべての二値素性を組み合わせた素性も使用している．本稿で特徴的な素性は，大規模データから自動構築した必須格情報Frameと係り受け言語モデル（3種類）であるが，これらについては節で述べる．</subsection>
  <subsection title="文脈処理">本稿では，人とコンピュータの対話システム実現のための解析器を想定している．この対話システムは，ユーザとシステムが交互に発話するもので，システムに組み込まれた対話管理部が両者の発話履歴や，現在話されている話題（焦点）を管理する．述語項構造解析部はユーザ発話を解析し，発話生成部がシステム発話を生成するというものである．従来の述語項構造解析器も，現在の解析対象文より以前の文を文脈として利用し，ゼロ代名詞照応解析に利用している．は，解析器内部で以前の文や話題（焦点）の管理（これを文脈管理と呼ぶ）を行っていた．しかし，述語項構造解析器内部で文脈管理を行うより，対話システムの対話管理部が文脈管理を行った方が，ユーザ発話とシステム発話を協調的に管理できる可能性が高い．本稿ではこのように考え，文脈管理は外部モジュールの担当と位置付ける．そして評価用に，新聞記事と対話で同じ文脈管理方法を使用する．なお，本稿の方式は，選択器に与える文間の候補名詞句を取捨選択することによって文脈の制御を行っているので，候補名詞句を外部モジュールから陽に与えることで，文脈管理方法を変更することができる．今回使用した文脈管理方法は，具体的には以下のとおりである．対象述語の発話より以前の発話をさかのぼり，他の述語を含む発話（これを有効発話と呼ぶ）を見つける．これは，述語を含まない発話を無視するためである．有効発話と対象述語の発話の間に出現した全名詞句と，有効発話の述語で項として使われた名詞句（有効発話内の場合もあれば，それ以前の発話の名詞句の場合もある）を候補として加える．項として使われた名詞句は，その後も繰り返し使われることが多く，これに制限することで，効率的に候補を削減することができるという観察結果に基づく．また，項として使われている限り，さかのぼる文数に制限がないため，広い文脈を見ることができる．</subsection>
  <section title="雑談対話への適応">前節で述べた方法は，対話，新聞記事に共通の処理である．これを対話解析に適したものにするため，パラメータの適応，および大規模コーパスから自動獲得した知識の適用を行う．</section>
  <subsection title="モデルパラメータの適応">NAISTコーパスと対話コーパスの項分布の差異は，選択器のモデルパラメータをドメイン適応することで調整する．本稿では，モデルパラメータの適応手法として，素性空間拡張法を用いる．これは，素性空間を3倍に拡張することで，ソースドメインデータをターゲットドメインの事前分布とみなすのと同じ効果を得る方法である．具体的には，以下の手順で選択器のモデルを学習・適用する．まず，素性空間を共通，ソース，ターゲットの3つに分割する．NAISTコーパスをソースドメインデータ，対話コーパスをターゲットドメインデータとみなし，NAISTコーパスから得られた素性を共通とソース空間にコピーして配置する．対話コーパスから得られた素性は共通とターゲット空間にコピーして配置する．拡張された素性空間上で，通常通りパラメータ推定を行う．結果，ソース・ターゲットデータ間で無矛盾な素性は，共通空間のパラメータが強調され（絶対値が大きくなる），ドメインに依存する素性は，ソースまたはターゲット空間のパラメータが強調される．選択器が項を選択する際は，ターゲット空間と共通空間の素性だけ用いる．この空間のパラメータは，ターゲットドメインに最適化されているだけでなく，ソースドメインデータだけに現れた共通空間の素性も利用して，項選択ができる．</subsection>
  <subsection title="大規模コーパスからの知識獲得">本稿では，訓練コーパスに含まれない未知語への対策として，大規模コーパスから自動獲得した2種類の知識を利用する．どちらも大規模平文コーパスを自動解析して，集計やフィルタリングをすることで獲得する．当然誤りも含むが，新出語に対しても，ある程度の確かさで情報を与えることができる．これらを選択器の素性として使い，モデルを学習することにより，情報の信頼度に応じたパラメータが学習される．</subsection>
  <subsubsection title="必須格情報（Frame素性）">格フレームは，述語の必須格と，その格を埋める名詞句の種類（通常は意味クラス）を保持するフレーム形式の情報で，述語項構造解析や意味役割付与の重要な手がかりとなる．本稿で使う必須格情報は，格フレームのうち，格が必要か否か（必須格か任意格か）だけについて情報を与える辞書である．本稿の必須格情報は，大規模平文テキストコーパスから，以下の方法で自動構築する．これは，(1)項が述語と直接係り受け関係にある場合，述語に対する項の格は，項の名詞句に付随する格助詞と一致することが多い，(2)必須格なら，その格の出現率は他の述語より平均的に高い，という仮定をもとにしている．まず，本稿の述語項構造解析と同様（節参照）に，平文を形態素・構文解析し，品詞パターンで述語文節とその主辞を特定する．述語文節に直接係る文節を取得し，機能語部に格助詞を持つ文節だけを残す．もし，そのような文節が1つ以上あるなら，その述語を集計対象として，述語頻度，格助詞の出現頻度を集計する．述語に関しては，高頻度述語から順番に，最終的な辞書サイズを考慮して選択する．個々の格に関しては，以下の条件をすべて満たす格を，必須格とみなす．述語v,格cが，対数尤度比検定において，危険率0.1%以下で有意に多く共起していること（p0.001;対数尤度比10.83）．各述語における格cの出現率が，全述語における格の出現率（平均）より10%以上高いこと．以上の方法で，2種類の必須格情報辞書を作成した．一つは，ブログ約1年分（約23億文．以下Blogコーパスと呼ぶ）から，48万述語の情報を獲得した（これをBlog辞書と呼ぶ）．もう一つは新聞記事12年分（約770万文．以下Newsコーパスと呼ぶ）から約20万述語の情報を獲得した（同News辞書）．表は，雑談対話コーパス訓練セットの正解述語項構造と必須格情報辞書を比較し，必須格情報辞書の述語カバー率と格毎の精度を算出したものである．述語カバー率は，対話コーパスに出現した述語が必須格情報辞書に含まれている場合，カバーしたと判断した．結果，Blog辞書で98.5%，News辞書で96.4%で，ほぼ等しかった．また，格毎の精度は，正解の述語項構造に格が付与されているか否かと，必須格情報上の必須格性が一致しているかどうかを測定したもので，Blog辞書，News辞書でほぼ同じ傾向を示している．格毎に見ると，ガ格の精度が低いが，これは，雑談対話コーパスでは，ほぼすべての述語に対してガ格が付与されている（つまり，ガ格が必須）にも関わらず，BlogコーパスやNewsコーパスではそれがゼロ代名詞化されているため，自動獲得では必須格とは判断できなかったためである．ヲ格の全体精度は91%以上と，格によっては高い精度を持つ辞書となっている．</subsubsection>
  <subsubsection title="係り受け言語モデル">係り受け言語モデル(languagemodel;LM)は，三つ組述語v,格c,名詞句nの共起のしやすさを表現するモデルである．頻出表現に高いスコアを与えることによって，出現する単語間に意味的関連が存在することを表現する意図がある．ここでは，述語v,格c,名詞句nそれぞれの生成確率をn-gramモデルで算出し，選択器の識別モデルで全体最適化を行う．具体的には，以下の実数値を算出し，表の係り受け言語モデル素性の素性関数値として使用する．その結果，選択器は，候補名詞句集合から，頻出表現に含まれる名詞句nを優先して選択することになる．なお，未知語を表す特殊単語&lt;unk&gt;を含む確率で補正してる理由は，対数確率（-〜0.0の範囲）を正の値に補正するためである．P(n|c,v)-P(&lt;unk&gt;|c,v)P(v|c,n)-P(v|c,&lt;unk&gt;)P(c|n)-P(c|&lt;unk&gt;)本稿の係り受け言語モデルは，が1種類（P(n|c,v)相当）のみ使用していたのに対し，識別モデルが互いに依存しあう素性を含めることができるという特徴を利用し，3種類に拡張している．また，述語vから見た格cの生成確率(P(c|v))は，述語ごとに格を必要とする度合であり，必須格情報と重なるため，係り受け言語モデルからは除外した．3種類の係り受け言語モデルは，節で抽出した述語，格，名詞句を集計し，SRILMでバックオフモデルを構築した．係り受け言語モデルも，Blogコーパス，Newsコーパスからそれぞれ作成した．これを，それぞれBlog言語モデル，News言語モデルと呼ぶ．言語モデルのカバー率を，雑談対話コーパス訓練セットに出現する三つ組が係り受け言語モデルの元になった三つ組に含まれるかどうかで測定すると，Blog言語モデルの場合，76.4%をカバーしていた．一方，Newsの言語モデルの場合，カバー率は38.3%だった．News言語モデルに比べ，Blog言語モデルは対話コーパスに出現する係り受けの三つ組のカバレッジが高い．</subsubsection>
  <section title="実験">本節では，表に示したコーパスを用い，対話における述語項構造解析の精度を，パラメータ適応，大規模コーパスから自動獲得した知識の効果という観点から評価する．評価はすべて雑談対話コーパステストセットで行う．評価指標には，項の適合率，再現率から算出したF値を用いる．</section>
  <subsection title="実験1: パラメータ適応の効果">まず，パラメータ適応の効果を測定するため，訓練方法を変えた3方式の比較を行った．表の(a)，(b)，(c)カラムがその結果で，それぞれ(a)素性空間拡張によるドメイン適応を行った場合（適応．提案法），(b)NAISTコーパスだけで訓練した場合（NAIST訓練．従来の新聞記事用解析に相当），(c)対話コーパスだけで訓練した場合（対話訓練）を表す．まず，(a)適応と(b)NAIST訓練を比較すると，多くの場合，適応の方が有意に精度がよいという結果になった（記号が有意差ありを表す）．特に合計の精度では，すべての格で適応が有意に勝っている．タイプ別の精度を見ると，特徴的なのは，ガ格の一人称，二人称外界照応(exo1,exo2)である．これらはガ格の項のうちの約28%を占めているが，exo1で70.2%，exo2で46.8%のF値で解析可能となった．他にも，ヲ格ニ格の文間ゼロ，exogなど，NAIST訓練ではほとんど解析できなかったタイプの項が解析できるようになった．(a)適応と(c)対話訓練を比較すると（参照），雑談対話コーパスは訓練セットのサイズが小さいにも関わらず，両者の精度が近くなった．適応の合計精度が有意に良かったのは，ニ格のみである．これには2つの理由が考えられる．対話コーパス量が十分であり，NAISTコーパスの影響をほとんど受けない場合．適応がNAISTコーパスの知識を活かしきっていない場合．言い換えると，NAISTコーパスに出現する言語現象と，対話に出現する言語現象に重なりが少ないため，NAISTコーパスが影響しない場合．前者の場合，コーパスサイズに対する学習曲線が今回のデータ量で飽和していることで検証できる．本稿で作成した対話コーパスはNAISTコーパスの約1/10の訓練セットであるため，学習曲線は描かなかった．後者の場合，対話コーパスサイズを大きくすると，述語項構造解析の精度も向上する．今後，さらに対話コーパスを作成し，検証する必要がある．</subsection>
  <subsection title="実験2: 自動獲得知識の比較">表の(a)(d)(e)は，提案方法（適応）の評価結果である．ただし，必須格情報および係り受け言語モデルは，それぞれ(a)Blog,Blog，(d)News,Blog，(e)Blog,Newsに変えて評価している．まず，必須格情報辞書を(a)Blogから(d)Newsに変えた場合を比較すると（参照），両者の間で有意差があったのは，ヲ格の文内ゼロのみで，ほぼすべての場合で有意差はなかった．一方，係り受け言語モデルを(a)Blogから(e)Newsに変更すると（参照），若干精度に差が出た．特に，文法関係より意味関係を重視する文内・文間ゼロでは，有意に精度が悪化したものが多く（ガ格の文間ゼロ，ヲ格の文内・文間ゼロ，ニ格の文内ゼロ），その結果，合計の精度でも，ヲ格は約3ポイント低下した．ゼロ代名詞照応のように，述語と項の間に文法的な関係が弱い場合，意味的関連性を共起から判断する係り受け言語モデルが相対的に重要となる．そのため，係り受け言語モデルの違いが精度に影響しやすい．図は，適応方式において，それぞれ必須格情報辞書の述語カバー率，係り受け言語モデルの三つ組述語v,格c,名詞句nのカバー率を意図的に変化させて，述語項構造解析のF値を測定したグラフである．必須格情報，係り受け言語モデルともに，Blogコーパスから作成したものを利用した．必須格情報のカバー率は高頻度述語から順番に，雑談対話コーパス訓練セットの述語のカバー率が指定した割合になるまで選択した．係り受け言語モデルの三つ組は，同じく雑談対話コーパス訓練セット上での三つ組カバー率が指定した割合になるまで，ランダムに選択した．グラフに示したF値は，格の合計である．図(a)をみると，必須格情報については，格の種類にかかわらず，述語カバー率を変えてもほぼ同じ精度となった．この理由を分析したところ，テストセットに出現する大部分の述語は，訓練セットに出現したためであった．実際，雑談対話テストセットに出現する5,333述語のうち，4,442述語（83.3%）は雑談対話コーパス訓練セット，またはNAISTコーパス訓練セットに出現していた．つまり，訓練セットだけでテストセットの大部分をカバーできており，それ以外の述語しか，必須格情報が有効に作用しなかったため，カバー率の影響がほとんど出なかったと考えられる．一方，係り受け言語モデルの三つ組は，雑談対話テストセットに出現した5,056組（外界照応exo1,exo2,exogは除く）のうち，訓練セットがカバーしたのは1,063組（21.0%）であった．そのため，図(b)のように，係り受け言語モデルのカバー率を上げると，述語項構造解析の精度も向上した．ただし，ガ格に関しては，自動獲得元コーパスにおいてもガ格がゼロ代名詞化され，自動獲得精度が十分ではなかったため，カバー率を上げても述語項構造解析精度は向上しなかった．まとめると，自動獲得した知識は，訓練コーパスのカバレッジが高い部分では効果がほとんどなく，低い部分を補完するのに有効である．そのため，雑談対話のように幅広い話題を対象とする対話には適している．</subsection>
  <subsection title="雑談対話コーパスを使用せずに適応する場合">ドメイン適応のシチュエーションとして，新聞記事コーパスしか存在しない状況で，述語項構造解析器を対話に適応させなければならない場合が考えられる．本節では，NAISTテキストコーパスと自動獲得知識だけでモデルを学習し，自動獲得知識がどの程度有効か，検証する．表は，NAISTコーパス訓練セットでモデルを学習し，雑談対話コーパステストセットでF値を測定した結果である．ただし，自動獲得知識の組み合わせ必須格情報,係り受け言語モデルは，(b)Blog,Blog，(b-1)なし,Blog，(b-2)Blog,なし，(b-3)なし,なしに変えている．(b)は，表の再掲である．これを見ると，多くの場合で(b)Blog,Blogが有意に勝っており，自動獲得知識が有効に作用していると言ってよい．しかし，これらはすべてNAIST訓練の結果であり，ほとんど（またはまったく）解析できなかったタイプの項（たとえば，ガ格のexo1,exo2，ヲ格の文間ゼロ，ニ格の文内・文間ゼロ）は，必須格情報辞書，係り受け言語モデルをどのように変えようとも，ほとんど解析できない状況には変わりはなかった．本稿の提案方式である表の(a)適応は，NAIST訓練では解析できなかったタイプの項も解析できるようにする効果があった．自動獲得した知識は，すでに解析できるタイプの項の精度改善には効果があるが，対話で新たに出現したタイプの項を解析する効果はない．したがって，たとえ少量でも対話の述語項構造データを作成し，適応させることが望ましい．</subsection>
  <subsection title="対話解析例">図は，旅行に関する雑談対話の一部について，正解述語項構造，(a)適応方式，(b)NAIST訓練方式，(b-3)NAIST訓練（ただし，必須格情報辞書，係り受け言語モデルなし）の出力を並べて表示したものである．発話ごとに差異を分析すると，以下の特徴が得られた．発話番号1で，正解がexogになっているのは，アノテータは，「話した」のは発話者ABの両方であると判断したためである．本発話の解釈によっては，exo1でも誤りではないと思われる．発話番号2のガ格の正解はexo2である．しかし，(a)適応は，exo1を選択した．日本語の場合，一人称・二人称は，文末表現（この例では「下さい」）に特徴が現れるが，選択器にSuffix素性があるにも関わらず，正しく選択できなかった．発話番号3のガ格の正解はexo1である．(a)適応は正しく選択したが，(b)(b-3)NAIST訓練は，一人称／二人称の外界照応をほとんど選択しないため，発話番号1に現れた「私」を選択した．しかし，発話番号1の「私」は発話者Aを示しており，発話番号3のexo1（発話者B）とは異なる．もし文間ゼロタイプの項を割り当てるとすると，発話番号2の「あなた」が正解となる．本稿では，外界照応と人称代名詞を別に扱っているが，本来は共参照解析を導入して，exo1/exo2と「私」「あなた」が同一実体であることを認識すべきである．その際，発話者がどちらなのか意識して，同一性を判断する必要がある．発話番号6にも同様な現象が現れているが，ガ格正解exo2に相当する表現が発話番号2「あなた」まで遡らなければならないため，(b)(b-3)NAIST訓練では，exogとなった．発話番号3のニ格の正解は「海外旅行」だが，(b-3)NAIST訓練（自動獲得知識なし）では，NULLと誤った．「海外旅行にはまる」は，NAISTコーパス訓練セットには出現せず，係り受け言語モデルの三つ組に出現する表現だったため，係り受け言語モデルなしのNAIST訓練では解析に失敗した．発話番号5のニ格の正解は，「スペインとポルトガル」であるべきだが，本稿の方式は文節を単位に処理するため，2文節以上にまたがる名詞句は，主辞だけを付与する仕様である．また，発話番号4のガ格の正解は，直前発話（発話番号3）全体と考えることもできる．しかし，文節単位に格要素を割り当てるため，アノテータはもっとも近い表現「海外旅行」を正解として割り当てた．発話番号6において，(a)適応は，ニ格「ポルトガル」を前文から正しく補完した．なお，「ポルトガルに行く」は，NAISTコーパス訓練セットには存在しないが，係り受け言語モデルの三つ組には存在する表現である．</subsection>
  <section title="まとめ">本稿では，対話解析のための述語項構造解析を提案した．われわれはこれを新聞から対話への一種のドメイン適応とみなし，従来新聞記事で研究されていた述語項構造解析を，対話に適用した．対話と新聞記事では項の分布が異なるため，素性空間拡張法を用いて，モデルパラメータを適応させた．また訓練コーパスに現れない未知語を補完するため，大規模平文データから，必須格情報，係り受け言語モデルを自動獲得し，項選択器のモデルに適用した．結果，少量でも対話コーパスを訓練に加えることで，新聞記事のコーパスだけでは解析できなかったタイプ（ガ格の一人称・二人称ゼロ代名詞や，文間ゼロ代名詞，外界照応）も解析可能となった．ただし，パラメータ適応自体の効果は限定的であった．また，自動獲得知識の有効性は，訓練セットがテストセットをどの程度カバーしているかに依存する．必須格情報は，テストセットに出現する述語の大部分が訓練セットに出現していたため，必須格情報のカバレッジの影響はほとんどなかった．一方係り受け言語モデルでは，テストセットに出現する述語，格，名詞句の三つ組の21%しか訓練セットでカバーしていなかったため，カバレッジの高いモデルの精度が向上した．特に，ヲ格ニ格に関しては，三つ組カバレッジが高い方が，ゼロ代名詞照応解析精度の向上に寄与することを確認した．なお，必須格情報および係り受け言語モデルは，格フレームの選択選好とみなすこともできる．格フレームは，大規模コーパスから自動獲得したものが存在するので，これを利用する方法もある．両者の比較は，今後検討してゆきたい．今回は，パラメータ分布の差異，語彙のカバレッジに着目したが，新聞と対話では，他にもさまざまな違いがあると考えられる．たとえば，話者交替は対話特有の現象であるが，それが述語項構造やゼロ代名詞にどう影響するかなどは，本稿では扱わなかった．また，われわれは文脈管理に，対話システムの発話管理機能を利用することを考えているが，対話システムとしての有効性評価も実施する予定である．</section>
</root>
