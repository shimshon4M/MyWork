    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvipdfm]{graphicx}
\usepackage{amsmath}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\usepackage{array}

\usepackage{ascmac}
\usepackage{gb4e}
\noautomath
\usepackage{error-type-all_new}
\usepackage{error-id-all}
\newcommand{\WSD}{}
    \newcommand{\MHLE}{}
    \newcommand{\COR}{}
    \newcommand{\SYS}{}
\newcommand{\SF}{}
\newcommand{\ulf}{}
\newcommand{\eid}[1]{}
    \newcommand{\bccwj}{}



\Volume{22}
\Number{5}
\Month{December}
\Year{2015}

\received{2015}{5}{15}
\revised{2015}{7}{31}
\accepted{2015}{9}{11}

\setcounter{page}{319}

\jtitle{クラスタリングを利用した語義曖昧性解消の\\
誤り原因のタイプ分け}
\jauthor{新納　浩幸\affiref{Author_1} \and 村田　真樹\affiref{Author_2} \and 白井　清昭\affiref{Author_3} \and 福本　文代\affiref{Author_4} \and \\
	藤田　早苗\affiref{Author_5} \and 佐々木　稔\affiref{Author_1} \and  古宮嘉那子\affiref{Author_1} \and 乾　　孝司\affiref{Author_8}}
\jabstract{
語義曖昧性解消の誤り分析を行う場合，まずどのような原因からその誤りが生
じているかを調べ，誤りの原因を分類しておくことが一般的である．この分類
のために，分析対象データに対して分析者 7人が独自に設定した誤り原因のタ
イプを付与したが，各自の分析結果はかなり異なり，それらを議論によって統
合することは負荷の高い作業であった．そこでクラスタリングを利用してある
程度機械的にそれらを統合することを試み，最終的に 9種類の誤り原因として
統合した．この 9種類の中の主要な 3つの誤り原因により，語義曖昧性解消の
誤りの 9割が生じていることが判明した．またタイプ分類間の類似度を定義す
ることで，統合した誤り原因のタイプ分類が，各自の分析結果を代表している
ことを示した．また統合した誤り原因のタイプ分類と各自の誤り原因のタイプ
分類を比較し，ここで得られた誤り原因のタイプ分類が標準的であることも示
した．
}
\jkeywords{語義曖昧性解消，誤り分析，クラスタリング}

\etitle{Classification of Word Sense Disambiguation Errors \\
Using a Clustering Method}

\eauthor{Hiroyuki Shinnou\affiref{Author_1} \and Masaki Murata\affiref{Author_2} \and Kiyoaki Shirai\affiref{Author_3} \and 
	Fumiyo Fukumoto\affiref{Author_4} \and Sanae Fujita\affiref{Author_5} \and Minoru Sasaki\affiref{Author_1} \and 
	Kanako Komiya\affiref{Author_1} \and Takashi Inui\affiref{Author_8}}

\eabstract{
As a first step of word sense disambiguation (WSD) errors analysis, 
generally we need investigate the causes of errors and classify them. 
For this purpose, seven analysts classified the error data for analysis from
their unique standpoints.  
Next, we attempted to merge the results from the analyses.  
However, merging these results through discussions was difficult
because the results differed significantly.  
Therefore, we  used a clustering method for a certain level of automatic merger.
Consequently, we classified WSD errors into nine types,
and it turned out that the three main types of errors covers 90\% of the total WSD errors.
Moreover, we showed that 
the merged error types represented seven results
and was standardized by defining the similarity between two classifications 
and comparing it with each analysis result.
}
\ekeywords{Word Sense Disambiguation, Error Analysis,  Clustering}

\headauthor{新納，{\kern-0.25zw}村田，{\kern-0.25zw}白井，{\kern-0.25zw}福本，{\kern-0.25zw}藤田，{\kern-0.25zw}佐々木，{\kern-0.25zw}古宮，{\kern-0.25zw}乾}
\headtitle{クラスタリングを利用した語義曖昧性解消の誤り原因のタイプ分け}

\affilabel{Author_1}{茨城大学工学部情報工学科}{Department of Computer and Information Sciences, Ibaraki University}
\affilabel{Author_2}{鳥取大学大学院工学研究科情報エレクトロニクス専攻}{Department of Information and Electronics, Tottori University }  
\affilabel{Author_3}{北陸先端科学技術大学院大学情報科学研究科}{School of Information Science, Japan Advanced Institute of Science and Technology}
\affilabel{Author_4}{山梨大学大学院総合研究部}{Interdisciplinary Graduate School, University of Yamanashi}
\affilabel{Author_5}{NTT コミュニケーション科学基礎研究所}{NTT Communication Science Laboratories}  
\affilabel{Author_8}{筑波大学大学院システム情報工学研究科}{Graduate School of SIE, University of Tsukuba}



\begin{document}
\maketitle


\section{はじめに}

Project Next NLP\footnote{https://sites.google.com/site/projectnextnlp/} は自然言語処理 (NLP) の
様々なタスクの横断的な誤り分析により，今後
の NLP で必要となる技術を明らかにしようとするプロジェクトである．
プロジェクトでは誤り分析の対象のタスクが18個設定され，
「語義曖昧性解消」はその中の 1 つである．
プロジェクトではタスク毎にチームが形成され，
チーム単位でタスクの誤り分析を行った．
本論文では，我々のチーム（「語義曖昧性解消」のチーム）で行われた
語義曖昧性解消の誤り分析について述べる．特に，誤り分析の初期の段階で必要となる
誤り原因のタイプ分けに対して，我々がとったアプローチと
作成できた誤り原因のタイプ分類について述べる．

なお本論文では複数の誤り原因が同じと考えられる事例をグループ化し，
各グループにタイプ名を付ける処理を「誤り原因のタイプ分け」と呼び，
その結果作成できたタイプ名の一覧を「誤り原因のタイプ分類」と呼ぶことにする．

誤り分析を行う場合，(1) 分析対象のデータを定める，(2) その分析対象データを各人が分析する，
(3) 各人の分析結果を統合し，各人が同意できる誤り原因のタイプ分類を作成する，
という手順が必要である．
我々もこの手順で誤り分析を行ったが，
各人の分析結果を統合することが予想以上に負荷の高い作業であった．
統合作業では分析対象の誤り事例一つ一つに対して，各分析者が与えた誤り原因を持ち寄って議論し，
統合版の誤り原因を決定しなければならない．
しかし，誤りの原因は一意に特定できるものではなく，しかもそれを各自が独自の視点でタイプ分け
しているため，名称や意味がばらばらな誤り原因が持ち寄られてしまい議論がなかなか収束しないためであった．

そこで我々は「各人が同意できる誤り原因のタイプ分類」を
各分析者のどの誤り原因のタイプ分類とも類似している誤り原因のタイプ分類であると考え，
この統合をある程度機械的に行うために，各自が設定した誤り原因をクラスタリングすることを試みた．
また，本論文では「各分析者のどのタイプ分類とも類似している」ことに
対し，「代表」という用語を用いることにした．
つまり，我々が設定した目標は「各分析者の誤り原因のタイプ分類
を代表する誤り原因のタイプ分類の作成」である．
クラスタリングを行っても，目標とするタイプ分類を自動で作成できるわけではないが，
ある程度共通している誤り原因を特定でき，それらを元に
クラスタリング結果を調整することで目標とする誤り原因のタイプ分類が作成できると考えた．

具体的には，各自の設定した誤り原因を対応する事例を用いてベクトル化し，それらのクラスタリングを行った．
そのクラスタリング結果から統合版の誤り原因を設定し，
クラスタリング結果の微調整によって最終的に 9種類の誤り原因を持つ
統合版の誤り原因のタイプ分類を作成した．
この 9種類の中の主要な 3つの誤り原因により，語義曖昧性解消の誤りの 9割が生じていることが判明した．
考察では誤り原因のタイプ分類間の類似度を定義することで，
各分析者の作成した誤り原因のタイプ分類と統合して作成した誤り原因のタイプ分類が，
各分析者の視点から似ていることを確認した．
これは作成した誤り原因のタイプ分類が分析者7名のタイプ分類を代表していることを示している．
また統合した誤り原因のタイプ分類と
各自の誤り原因のタイプ分類を比較し，
ここで得られた誤り原因のタイプ分類が標準的であることも示した．


\section{分析対象データ}

誤り分析用のデータは SemEval-2 の日本語 WSD タスクから作成した\cite{semeval-2010}．
SemEval-2 のデータは対象単語が 50 単語あり，各対象単語に対して
50個の訓練用例と50個のテスト用例が存在する．
また用例中の対象語には岩波国語辞典\cite{iwakoku5}の語義が付与されている．
つまり語義識別のラベルは岩波国語辞典の語義である．

まず SemEval-2 のコンペの際に baseline とされたシステムを構築した．
以降，本論文ではこのシステムを「分析用システム」と呼ぶ．
学習アルゴリズムは SVM であり，以下の 20 種類の特徴量を利用する．

\vspace{0.5\Cvs}
\small
\begin{verbatim}
       e1= 二つ前の単語表記,   e2= 二つ前の品詞,   e3= その細分類,   
       e4= 一つ前の単語表記,   e5= 一つ前の品詞,   e6= その細分類,     
       e7= 対象単語の表記,   e8= 対象単語の品詞,   e9= その細分類,     
       e10= 一つ後の単語表記,  e11= 一つ後の品詞,   e12= その細分類,
       e13= 二つ後の単語,  e14= 二つ後の品詞,  e15= その細分類,  e16= 係り受け,
       e17= 二つ前の分類語彙表の値（5桁）,   e18= 一つ前の分類語彙表の値（5桁）,
       e19= 一つ後の分類語彙表の値（5桁）,   e20= 二つ後の分類語彙表の値（5桁）
          
\end{verbatim}
\normalsize

baseline システムは分類語彙表 ID の4桁と5桁を同時に使う形になっていたが，
分析用システムでは 5桁のみとした．また一般に一つの単語に対しては複数の分類語彙表 ID が存在するので，
\verb| e17,e18,e19,e20 | に対する素性は複数になる場合もある．

例として，以下の用例（「息子とその婚約者に会っていこうかと考えた」）\footnote{このように SemEval-2 のデータは形態素解析結果を XML 形式で表現している．}に対する素性リストを示す．対象単語は記号 (*) のついた「あう」である．

\vspace{0.5\Cvs}
\begin{screen}
\small
\begin{verbatim}
<sentence>
・・・
<mor pos="名詞-普通名詞-一般" rd="ムスコ">息子</mor>
<mor pos="助詞-格助詞" rd="ト">と</mor>
<mor pos="連体詞" rd="ソノ">その</mor>
<mor pos="名詞-普通名詞-サ変可能" rd="コンヤク">婚約</mor>
<mor pos="接尾辞-名詞的-一般" rd="シャ">者</mor>
<mor pos="助詞-格助詞" rd="ニ">に</mor>
<mor pos="動詞-一般" rd="アッ" bfm="アウ" sense="166-0-2-1-0">会っ</mor>  (*)
<mor pos="助詞-接続助詞" rd="テ">て</mor>
<mor pos="動詞-非自立可能" rd="イコー" bfm="イク">いこう</mor>
<mor pos="助詞-終助詞" rd="カ">か</mor>
<mor pos="助詞-格助詞" rd="ト">と</mor>
<mor pos="動詞-一般" rd="カンガエ" bfm="カンガエル" sense="9590-0-0-1-0">考え</mor>
<mor pos="助動詞" rd="タ" bfm="タ">た</mor>
・・・
</sentence>
\end{verbatim}
\end{screen}
\vspace{0.5\Cvs}

対象単語の一つ前の単語表記は「に」なので，\verb|`e4=に'| となる．この単語の品詞情報から
\linebreak
\verb|`e5=助詞'|，\verb|`e6=格助詞'|となる．同様にして \verb|e1| から \verb|e15| が設定できる．
また用例は CaboCha\footnote{http://taku910.github.io/cabocha/} により係り受けの解析がなされ，
対象単語を含む文節の最も近い係先の単語の原形が\verb|e16| に設定される．
この場合は\verb|`e16=いく'| となる．
次に二つ前の単語「者」に対する分類語彙表 ID は
\verb|1.1000,7,1,2| と\verb|1.2020,1,1,4| であり．
前者から上位5桁を取ると \verb|11000| となり，
後者から上位5桁を取ると \verb|12020| となる．
そのため\verb|e17|は\verb|`e17=11000'|と\verb|`e17=12020'|の2つが設定される．
一つ前の単語「に」と一つ後の単語「て」は助詞なので分類語彙表 ID は無視する．
二つ後の単語「いこう」に対する分類語彙表 ID は
\verb|2.3000,6A,2,1| と \verb|2.3320,5,1,2|から
\verb|`e20=23000'|と\verb|`e20=23320'|が設定される\footnote{これは間違いである．
正しくは「いこう」の原形「いく」に対する分類語彙表 ID を与えなくてはならない．
分析用システムでは baseline システムを忠実に再現したためこのような不備も生じている．}．
以上より，上記用例の素性リストは以下となる．

\vspace{0.5\Cvs}
\small
\begin{verbatim}
    ( e1=者, e2=接尾辞, e3=名詞的, e4=に, e5=助詞, e6=格助詞, e7=会っ, e8=動詞,
      e9=一般, e10=て, e11=助詞, e12=接続助詞, e13=いこう, e14=動詞, e15=非自立可能, 
      e16=いく, e17=11000, e17=12020, e20=23000, e20=23320 )
\end{verbatim}
\normalsize
\vspace{0.5\Cvs}

「あう」の訓練データの 50用例を全て素性リストに直し，
その要素の異なり数 $N$ を次元数とした $N$ 次元ベクトルを設定する\footnote{この例の場合，$N = 335$ であった．}．
訓練データとテストデータの用例を素性リストに変換し，
$N$ 次元ベクトルの $i$ 次元目に対応する要素が存在すれば $i$ 次元の値を 1 に，存在しなければ 0 とすることで，
その素性リストは素性ベクトルに変換できる．
この素性ベクトルを利用して SVM による学習と識別が可能となる．
SVM の学習は libsvm\footnote{http://www.csie.ntu.edu.tw/{\textasciitilde}cjlin/libsvm/} の線形カーネルを用いた．指定できるパラメータは全て default のままである．

SVM により識別した結果，テスト事例 2,500 のうち，誤りは 577 事例であった
\footnote{平均正解率は 76.92\% であり，これは SemEval-2 の参加システム中，最高値であった．}．
ここから新語義と未出現語義の事例を除くと 543事例となった．
ここからランダムに 50個の事例を選出し，この50事例を誤り分析の対象事例とした．
この 50事例は付録1に記した．


\section{各人の分析結果}

前述した 50事例の分析対象データに対して，我々のチームのメンバーの内7名
（村田，白井，福本，新納，藤田，佐々木，古宮）が独自に誤り分析を行った．
分析結果として，各人は分析対象の 50事例に対して，各自が設定した誤り原因の記号をつけた．
表\ref{kekka-all}がその結果である．

\begin{table}[p]
\caption{50事例に対する各自の分析結果}
\label{kekka-all}
\input{01table01.txt}
\end{table}

各自の記号の意味やどのような観点で分析したかを以下に述べる．


\subsection{村田の分析：解き方に着目}
\label{sec:tokikata}

採用した誤り分析の考え方・方法論について述べる．
普遍的な誤り分析を目指して，以下の誤り分析のフレームワークを用いる．

\begin{itemize}
\item 
誤り事例を人手で考察し，人ならそれを正しく解くには
どう解くかを考えて，その事例の解析に有効な特徴（解き方）を見つける．
その特徴が学習データにあるかを確認する．
\item
誤り分析の際には，
正解に至るまでの誤り原因をすべて網羅して調べる．
これは，複数の誤り原因が存在する場合があり，
一つの原因だけを見つけるのでは誤り分析としては不十分な場合がある
ためである．
\end{itemize}

具体的な誤り分析の手順は以下のとおりである．まず，各事例の対象単語の品詞を調べる．
次に，品詞を参考にして各事例の解き方を調べる．
最後に，解き方を参考にして各事例の誤り原因を調べる．

以降，以上の方法論・手順に基づき行った調査結果について述べる．
まず各事例の対象単語の品詞を調べた．
品詞の出現数を表\ref{tab:murata_pos}に示す．
表の「記号」の列はその品詞のデータに付与した記号である．

次に各事例の解き方を調べた．
解き方はある程度対象語の品詞に依存する．
このため対象語の品詞を考慮しながら，解き方を考える．
各事例に解き方のタグを付与する．
解き方（解析に有効な特徴）の出現数を表\ref{tab:murata_solve}に示す．
表の「記号」の列は，実際に事例に付与したタグの記号である．
タグは一つの事例に複数重複してふられる場合がある．
「解き方未判定」は，難しい事例で解き方が思いつかなかった
ものである．
「文パターン」は，
例えば「対象語の直前に『て』がある文パターンの場合語義Xになる」という
説明が辞書にある場合があり，そのような文パターンを利用して解く方法である．
「表現自身」は，例えば「対象語において漢字Xを使う場合は語義Yになる」という
説明が辞書にある場合がありそのような情報を利用して解く方法である．

\begin{table}[b]
\vspace{-0.5\Cvs}
\caption{品詞の出現数}
\label{tab:murata_pos}
\input{01table02.txt}
\end{table}
\begin{table}[b]
\caption{解き方の出現数}
\label{tab:murata_solve}
\input{01table03.txt}
\end{table}
\begin{table}[b]
\caption{誤り原因の出現数}
\label{tab:murata_error}
\input{01table04.txt}
\end{table}

次に各事例の誤り原因を調べた．
各事例で付与した解き方のタグを参考にして，
誤り原因を調べた．
誤り原因の出現数を表\ref{tab:murata_error}に示す．
表の「記号」の列は，実際に事例に付与したタグの記号である．
タグは一つの事例に複数重複してふられる場合がある．

表の「分析が困難」は，
分析が困難で分析を行っていないものを意味する．
より綿密な作業により分析ができる可能性がある．
「シソーラスの不備」は，シソーラスの不備の他，
シソーラスでの多義性の解消が必要な場合を含む．
「素性も学習データもあるのに解けていない」は，
解くときに役立つ素性も存在し，その素性を持つ学習データも
あるのに解けていない場合である．
その素性を持つ学習データの事例数が少ないか，
他の素性や学習データが悪さをした可能性がある．
「格解析が必要」は，
能動文，受け身文，連体などの正規化や，格の把握が
必要な場合である．
「入力文の情報が少なすぎる」は，
入力文だけでは文が短く，その文だけでは
語義識別ができない場合である．
前後の文など，より広範囲の文脈の情報の入力が必要
な場合である．

解き方の分類に基づき，いくつか誤り分析の事例を示す．

「格に取る名詞（対象語が用言の場合）」が解き方の場合を示す．
対象語が用言の場合，格に取る名詞が語義識別に役立つ表現と
なりやすい\cite{Murata_murata_s2j_nlp2003_new}．格に取る名詞を中心に眺めて誤り分析を行う．

事例 ID 3 の誤り事例を考察する．
対象文は「…悲鳴をあげながら…」で，
対象単語は「あげる」である．
動詞「あげる」の格になっている「悲鳴」が語義識別に役立つ
個所となる．
現在のデータでは対象データの「悲鳴」が分類語彙表の情報を持たない．
他のバージョンの分類語彙表には「悲鳴」の情報がある．
「悲鳴」の類似事例「声」が多数学習データにある．
シソーラスの情報をよりよく利用することで改善できる事例である．
誤りの分類としては，
「t: シソーラスの不備」を与えている．

意味ソート\cite{murata_msort_nlp}を使うと，学習データに類似事例があるかどうかを
簡明に知ることができる．
「悲鳴」が存在する分類語彙表を利用して意味ソートを行った．
意味ソートとは，単語群を分類語彙表の意味の順に並べる技術である．
「あげる」の学習データにおいて，「あげる」のヲ格の単語を
取り出し，その単語の意味ソートを行った．
注目している単語「悲鳴」の近くの単語群での意味ソート結果は
「13030010201: 顔(545-0-1-1), 13031010101: 声(545-0-1-2), 13031021203: 歓声(545-0-1-2), 13031050102: 叫び声(545-0-1-2), 13031050304: 悲鳴＊(545-0-1-2), 13041060106: 顔(545-0-1-1), 13061110102: 声(545-0-1-2)」である．
単語の後ろの括弧にはその単語を含むデータの文の分類先を示し，
単語の前の数字はその単語の分類語彙表の番号である．
今解析している単語には「＊」の記号を付与している．
意味ソートの結果では，「叫び声」が類似事例としてあることが
すぐにわかる．

「共起語（主に対象語が名詞の場合）」が解き方の場合を示す．
対象語が名詞の場合，同一文の共起語が語義識別に役立つ表現と
なりやすい\cite{Murata_murata_s2j_nlp2003_new}．
同一文には共起語が多く存在するため，この場合の誤り分析は
基本的に困難である．
事例 ID 14 の誤り事例を考察する．
対象文は，「…事件で、鶴見署は二十一日現場で…」であり，
対象単語は「現場」である．
対象単語は名詞であるので，共起語が役立ちやすく，
この例では，「事件」「署」が語義識別に役立つ．
今の素性では
対象単語の前方2形態素，後方2形態素しか素性に用いておらず，
同一文の単語すべては素性に使っていない．
今の素性では，「事件」「署」が使えない．
共起語の素性を使えるように素性を拡張する必要がある．
学習データを見たところ，共起語が重なる事例がなさそうであり，
学習データ不足の問題もあるようだった．
この事例には，
誤りの分類としては，
「f: 素性の種類の不足」「d: 学習データの不足」を与えている．

「言い換え」が解き方の場合を示す．
事例 ID 7 の誤り事例を考察する．
対象文は，「…自己防衛の意味でも…」であり，
対象単語は「意味」である．
正解語義は「表現や行為の意図・動機。」であり，
システム出力の誤り語義は，「その言葉の表す内容。意義。」である．
対象語の「意味」を「動機」に言い換えることが可能であることを認識できれば，
正解語義「表現や行為の意図・動機。」と推定できるようになると思われる．
この事例には，
誤りの分類としては，
「p: 言い換え技術が必要」を与えている\footnote{言い換え技術での
処理方法として，以下が考えられる．
「動機」「内容」を含む文を収集し，それを「意味」の語義「動機」の場合
の学習データ，「意味」の語義「内容」の場合
の学習データとして利用して解く方法である．
これは文献\cite{Mihalcea1999,Goda2013}と類似した考え方になる．}．



\subsection{白井の分析：機械学習の素性の問題を中心に}

まず，誤り分析の考え方について述べる．
特に着目したのは機械学習の素性の問題である．
テスト文から抽出された素性に不適切なものがないか，
テスト文の素性と同じものが訓練データに出現するか，
有力な手がかりとなる情報で素性として表現できていないものはないか，
といった観点から分析を進めた．
それ以外にも誤り原因と考えられるものは全て洗い出した．

\begin{figure}[b]
\vspace{-0.5\Cvs}
\begin{center}
\includegraphics{22-5ia1f1.eps}
\end{center}
\caption{白井による誤り原因のタイプ分類}
\label{fig:typology-sirai}
\vspace{-0.5\Cvs}
\end{figure}

誤り原因のタイプ分類を図{\ref{fig:typology-sirai}} に示す．
大きくは
手法の問題，前処理の問題，知識の問題，データの不備，問題設定の不備
に分類し，これらをさらに細かく分類した．
図中の( )はそれぞれの要因に該当する誤り事例の数，
[ ]は分析対象とした50事例に占める割合である\footnote{
  1つの誤り事例に対して複数の要因が割り当てられることもあるので，
  ( )内の数字の和は50を越える．
}．
枠内の数字は付録2に記載されている誤り原因IDに対応する．

\begin{table}[b]
\caption{【素性抽出が不適切】の細分類}
\label{tab:inapproriate-feature}
\input{01table05.txt}
\end{table}

【手法の問題】は機械学習手法に関する問題が見つかった事例である．
【訓練データの不足】は，
他に手がかりとなる情報がある場合\footnote{
  【訓練データの不足】に分類した事例は，必ず他の誤り原因にも分類している．
}と，
テスト文に類似した事例が訓練データにないと語義を識別しようがない場合
（【他に手がかりなし】）に分けた．
後者の多くは定型的な言い回しで語義が決まる事例である．
例えば，「指揮を*とる*」は決まり文句に近く，
この文が訓練データにないと「とる」の語義を決めるのは難しい．
【素性抽出が不適切】は表\ref{tab:inapproriate-feature} のような
文の正規化をした上で素性を抽出するべき事例である．
【有効な素性の不足】は，
語義曖昧性解消の手がかりとなる情報が素性として利用されていない場合である．
分析用システムでは最小限の素性しか使用していないため，
トピック素性（スポーツや事件といったトピックの文内に出現するということで
語義が決まる事例があった），文脈中の自立語，構文素性など，
先行研究で既に使われている素性の不足も分類されている．
また，【長いコロケーション】とは，
分析用システムでは前後2単語を素性としていたが，
対象語からの距離が3以上の単語で語義が決まる場合である．
【素性のコーディングが困難】とは，
語義を決める手がかりは発見できたが，高度な言語処理や推論を必要とし，
機械学習の素性として表現することが難しい事例である．
文の深い解釈が必要な場合（【文の解釈】）と
文章全体の解釈が必要な場合（【文脈の解釈】）に分けた．
【学習アルゴリズムの問題】とは，
語義曖昧性解消に必要な素性は抽出できていて，類似用例も訓練データに存在するが，
SVMで学習された分類器では正解を選択できなかった事例である．
他の機械学習アルゴリズムなら正しく解ける可能性がある．
【消去法】とは，該当しない語義を除外することで正解の語義がわかる事例を指す．
例えば
「かえって医師の処方を経ないで入手できる*市場*が生じている」
という文での「市場」は，
21128-0-0-1の意味（野菜などを得る市場）でもなければ
21128-0-0-3の意味（株式市場）でもないことから，
21128-0-0-2の意味（売行き先）とわかる．
このような事例は教師あり学習とは別の枠組で解く必要があるかも知れない．

【前処理の問題】は前処理の誤りに起因する事例である．
【知識の問題】は外部知識の不備が誤りの原因となっているものである．
【データの不備】はタグ付けされた語義の誤りである．
【問題設定の不備】に分類したのは，
対象語の解析対象文における品詞と辞書見出しにおける品詞が一致せず，
そもそも対象語として不適切であった事例である．
今回の分析では上記は少数の事例しか該当しなかったが，
多くの外部知識を用いたり，
文節の係り受け解析など多くの前処理を必要とするシステムでは，
これらの原因ももっと細かく分類する必要があるだろう．

教師あり学習に基づく手法を用いるという前提で，
今後語義曖昧性解消の正解率を向上させるには，
【訓練データの不足—他に手がかりなし】に分類した事例が多いことから，
訓練データを自動的または半自動的に拡充するアプローチが有望である．
また，【素性抽出が不適切】や【有効な素性の不足】で考察した問題点に
対応することも考えられる．
ただし，
表\ref{tab:inapproriate-feature} に示すような正規化の処理を導入しても
誤った解析結果が得られたり，
単純に素性を追加しても素性数が多すぎて過学習を引き起こすなど，
単純な対応だけでは語義曖昧性解消の正解率の向上に結びつかない可能性もあり，
深い研究が必要であろう．
また，【素性のコーティングが困難】に分類した事例は，
現時点での言語処理技術では対応が難しい事例だが，
誤り原因の20\%程度を占めており，軽視できない．
これらの事例に対応することは，チャレンジングではあるが，
必要であると考える．


\subsection{福本の分析：解消に必要となる知識・処理に着目}

語義曖昧性解消に必要となる知識に着目し，分析対象の50事例について誤りの原
因を分析した．まず，語義識別に必要となる知識が(1) 語義曖昧性解消タスク内か，
(2) 語義曖昧性解消タスク外かで大別した．さらに(2) 語義曖昧性解消タスク外 については，
語義曖昧性解消の前処理として必要となる形態素解析など，他の言語処理タスクで得られる知識にも着
目し，それらに関する影響の有無を調査した．誤り原因のタイプ分類を以下に示
す．括弧は各誤り原因に該当する事例数とその割合（(1)と(2)での割合，及び各
詳細項目での割合）を示す．また，``*''で囲まれた単語は語義識別の対象単語を示す．

\begin{enumerate}
\item 語義曖昧性解消タスク内の問題（40事例，80\%）

\begin{enumerate}
\item 語義の記載がない．（1事例，2.5\%）\\
「くもりを*取る*」というテスト事例において，「くもり」に関する語義情報が分類
      語彙表に存在しないため，「くもり」と「取る」での共起による語義識別
      が難しく，「取る」が訓練事例数の多い語義に識別されている.
\item  テスト事例と類似した事例が，訓練事例中に存在しない．（11事例，27.5\%）\\
訓練事例不足の問題である．例えば「見せて*あげる*事ですね。」のように，動詞連用
       形+「て」と「あげる」のパターンが訓練事例中に存在していないために，
       誤って識別されている．
\item テスト事例の語義が，訓練事例中では低頻度で出現している．（4事例，10\%）\\
語義の分布に片寄りがあるものの，対象としているテスト事例中の語義の特
      徴と高頻出の語義が持つ特徴との区別が困難であるために，低頻出の語義
      であるテスト事例の語義が正しく識別できない．例えば「私の*場所*だ!」
      であるテスト事例が該当し，「ところ．場」の意味の訓練事例は49事例，正解語義である「居る
      ところ」は1事例であるために，「ところ．場」に誤って識別されている.
\item 解消に必要な情報が欠如している．（10事例，25\%）\\
この誤り原因に相当する事例として，例えばテスト事例「*相手*をすべて倒した」において，「倒した」（行為）の対象
      が「*相手*」（人）であることから，共起関係を利用することにより「*相手*」
      が「自分と対抗して物事を争う人」に識別可能である．しかし語義の前後
      2単語というウィンドウサイズの制限により，識別に必要な「倒した」に関
      する情報（素性）が
欠如している．
\item 語義同士の意味が互いに類似しているために，識別が非常に難しい．（14事例，35\%）\\
この誤りは，誤り原因の中で最も多くの事例が相当した誤りである．「発
      音を*教え*てください。」などのように，「*教え*」が「知識や技能を身につける
      ように導く」という語義か，正解である「自分の知っていることを告げ示
      す」か，両者の語義が類似しているために識別が難しい.
\end{enumerate}

\item 語義曖昧性解消タスク外の問題（10事例，20\%）

\begin{enumerate}
\item 形態（語義を含む）．（7事例）

\begin{enumerate}
\item 形態素解析における品詞推定誤り．（2事例，20\%）\\
識別の対象単語と共起して出現する単語の品詞が誤っ
て識別されているために，品詞，及び共起関係の情報が利用できないとい
う問題である．例えば，ひらがな表記の「神のみ*まへ*の」において形態素解析
      において「御前」と認識されていない.
\item テスト事例の単語について，その同義語・類義語に関する情報が辞書に掲
      載されていない．（3事例，30\%）\\
この誤りは，例えば「悲鳴を*あげ*ながら」というテスト事例において，訓練事
      例中に存在する「歓声」が「悲鳴」と意味的に類似していることが分類語
      彙表に記載されていれば，「悲鳴」と「あげる」との共起関係により識別
      が可能であると考えられる.
\item 識別の対象となっている単語と共起している単語に曖昧さが存在して
      いる．（1事例，10\%）\\
例えば「レベリングは*技術*がいる」というテスト事例において，「技術」と共
      起関係にある「いる」は「必要である」という語義と「豆などを煎る」と
      いう語義が存在する．分類語彙表の情報として「豆などを煎る」が素性と
      してテスト事例に付与されて
      いるため，共起の語彙情報を利用することができない．
\item 慣用句表現の認識（1事例，10\%）\\
「めどが*立つ*。」が相当する．識別の対象となっている単語を慣用句表現と
      して認識する必要がある.
\end{enumerate}

\item 構文（1事例，10\%）

\begin{enumerate}
\item 複合名詞の認識\\
「国際*電話*」の事例のように，複合名詞が正しく認識されず，識別の対象
      単語である「*電話*」が複合名詞の一部として出現している．
\end{enumerate}

\item 文脈（2事例，20\%）

\begin{enumerate}
\item 省略語の補完\\
例えば「*開い*たときに請求書ご案内が上に来るように入れます。」のように，
      対象単語である「開く」の主語が省略されているため，共起関係など，語義識別に
      必要な情報が利用できない．
\end{enumerate}
\end{enumerate}
\end{enumerate}

語義曖昧性解消タスク内の誤り原因に相当する事例は40事例であり,タスク外の事例は10事例
であったことから，誤りの多くは語義曖昧性解消の
処理方法に問題があると考えられる．語義曖昧性解消内の誤り原因のうちの6事例は，既存の学習手
法や統計手法の工夫により語義を正しく識別できた．一方，例えば
上述した(1)における(e)の「*教え*てください」や，
「島がびっしょり濡れているようにさえ*見え*た」における「見え」が(a) 「目に
うつる」，(b) 「そう感じ取れる」 において，(a)と識別するために必要となる素性が何
かを明かにすることが難しい事例も存在した．文内に限定した語彙・語義情報を
用いた手法の限界であり，今後は文外に存在する情報，例えば分野に依存した主要語
義に関する情報とも組み合わせることにより，語義曖昧性解消を行う方法なども考えられる．
今後のさらなる調査と検討が必要である．


\subsection{新納の分析：手法の問題の機械的排除}
\label{sec:shinnou}

採用した誤り分析の考え方・方法論について述べる．
基本的に，自身の誤り原因のタイプ分類を作成し，分析対象の各誤り事例に
設定した誤り原因のタイプを付与した．
特徴としては「手法の問題」という誤り原因を設定したことである．
ここでの分析対象のデータは SVM を利用した場合の誤りである．
SVM を利用したために生じる誤りは分析の重要度が低いと考えた．
そこで SVM 以外の他の学習手法を試し，SVM 以外の2つ以上の学習手法で正解となるような
（SVM での）誤りの事例の誤り原因を「手法の問題」として機械的に取り除いた．
残された誤り事例に対してのみ，その誤り原因を精査するアプローチを取った．

設定した誤りの原因は，まず (1)手法の問題，であり，それ以外に
(2)意味の問題，(3)知識の問題，及び (4)領域の問題，の計4タイプの誤り原因を設けた．
(2)，(3)，(4) については更に詳細化した．
以下各タイプがどのような誤りかと，それをどのように判定したかを述べる．


\subsubsection{手法の問題}

分析対象のデータは，学習手法として SVM を使った場合の誤りであり，他の手法を用いた場合には
誤りにならないこともある．ここでは最大エントロピー法 (ME)，Naive Bayes 法 (NB)，決定リスト (DL)，及び
最大頻度語義 (MFS) の 4 つを試した．

まず各手法の SemEval-2 のデータに対する正解率を\mbox{表\ref{shin-tab-1}}に示す．

\begin{table}[b]
\caption{各手法の SemEval-2 の正解率 (\%)}
\label{shin-tab-1}
\input{01table06.txt}
\end{table}
\begin{table}[b]
\caption{手法間の差分}
\label{shin-tab-2}
\input{01table07.txt}
\end{table}

SVM が最も正解率が高いが，他の手法の正解の事例を完全にカバーしているわけでない．
\mbox{表\ref{shin-tab-2}}に正解の事例の差分を示す．
\mbox{表\ref{shin-tab-2}}は行が誤りを，列が正解を表している．
例えば行（\mbox{NB-×}），列（\mbox{ME-○}）の要素は 98 であるが，これは
NB で誤りであった事例のうち ME では正解であった事例数が 98 存在したことを意味する．
\mbox{表\ref{shin-tab-2}}から分かるように，手法 A が手法 B よりも正解率が
高いからといって，必ずしも，手法 B が正解していた事例すべてを手法 A が正しく識別できる訳でない．
これは手法を選択した際に生じる副作用であり，誤りの 1 つの原因であると考えられる．
そして，ここでは SVM では誤りだが，他の 2つ以上の手法で正解となっていた誤りの
事例を「手法の問題」（記号 4）と判定した．

表\ref{shin-tab-2}はSemEval-2のデータ全体での事例数を示している．
2つ以上の手法で正解であった事例の数は198であったが，
誤り分析の対象とした50事例に限れば8事例が該当した．
これらを「手法の問題」と分類した．


\subsubsection{意味の問題}

語義曖昧性解消の問題設定自体に誤りの原因があると考えられるものを「意味の問題」と判定した．
この下位分類として (a) 辞書の語義が似ていて識別困難（記号 1-a），(b) 深い意味解析が必要（記号 1-b），
(c) 表現自体からしか識別できない（記号 1-c），
及び (d) テスト文の問題（記号 1-d），の4つを設けた．

語義曖昧性解消の問題設定では，対象単語の語義が固定的に与えられる．
ある対象単語が持つ複数の語義は，明確に異なる場合もあるが，非常に似ている場合もある．
もしある語義 s1 と s2 が非常に似ている場合，それらを区別することは明らかに困難であり，
それらを取り違えた誤りの原因は，問題自体の困難性から生じていると考えた．
このようなタイプの誤りを「(a) 辞書の語義が似ていて識別困難」とした．
例えば事例 27は対象単語「強い」の
語義 34522-0-0-1 「積極的に働く力にあふれている．」と
語義 34522-0-0-2 「抵抗力に富み，簡単には壊れたりくずれたりしない．」
を区別する問題だが，どちらの語義も互いの意味を想起させるため，
意味的に非常に似ていると判断した．

上記の (a) のタイプであっても深い意味解析が可能であれば解決できるものを「(b) 深い意味解析が必要」とした．
例えば事例 1は対象単語「相手」の
語義 117-0-0-2 「物事をするとき，行為の対象となる人．」と
語義 117-0-0-3 「自分と対抗して物事を争う人．」を区別する問題である．
「争う人」も「行為の対象となる人」であることは明かであり，意味的には非常に近く (a) である．
ただしその「行為」が「争い」なのかどうかを深い意味解析で判断できれば解決できるため，
「(b) 深い意味解析が必要」のタイプと判定した．
(a) のタイプでかつ (b) であるかどうかは，「深い意味解析」の深さの度合いである．
技術的に可能なレベルの深さと思えれば (b) をつけた．

次に「(c) 表現自体からしか識別できない」のタイプであるが，
これは語義曖昧性解消の問題として不適と思えるものである．例えば慣用表現中の単語に語義が
存在していると考えるのは不自然である．
また語義曖昧性解消の問題では，対象単語が自立語であることは暗黙の了解である．
つまり単語の品詞自体が名詞や動詞であっても，その単語が機能語に近いものであれば，
語義曖昧性解消の問題として不適と考えられる．
このようなタイプの誤りを「(c) 表現自体からしか識別できない」とした．
例えば事例 21 の対象単語「する」，事例 48 の対象単語「やる」を，このタイプの誤りとした．

最後に「(d) テスト文の問題」のタイプであるが，これは単純にテスト文に手がかりとなる単語が
ほとんどないために誤るものである．これは「意味の問題」ではないが，
問題設定自体に誤りの原因があると捉え，この範疇に含めた．
例えば事例 10 の「*教え* て下さい．」などがこのタイプの誤りである．


\subsubsection{知識の問題}

語義曖昧性解消を教師あり学習により解決するアプローチをとった場合，
前述した「手法の問題」「意味の問題」以外の誤りの原因は，
システムに何らかの知識が不足していたためと考えられる．
そこで「手法の問題」「意味の問題」以外の誤り原因を「知識の問題」と判定した．

不足している知識（解決のために必要としている知識）としては，
現状のシステムの枠組みから考え，(a) その表現自体が訓練データに必要（記号 2-a），
(b) 周辺単語に同じ単語が必要（記号 2-b），及び (c) 周辺単語に類似単語が必要（記号 2-c），の3つを設定した．

例えば事例 9 の「…待ち伏せて詫びを *入れる* 振りをしながら…」の「入れる」の
語義の識別には「詫びを入れる」が訓練データに必要と考え，
「(a) その表現自体が訓練データに必要」と判定した．
また事例 30 の「…朝日新聞からの国際 *電話* に対して…」の「電話」の語義の識別も
「国際電話」が訓練データに必要だと考えた．

また事例 32 の「どうすればくもりを *取る* ことが出来ますか？」の
「取る」の語義は単語「くもり」が対象単語の周辺に存在することが必要と考え，
「(b) 周辺単語に同じ単語が必要」と判定した．(a) との差異は少ないが，
(a) は慣用表現に近い表現であり，単語間に別の単語が挿入できない，態が変化できない，などの
特徴があるが，(b) は「くもりをきれいに取る」や「きれいに取ったくもり」という表現が可能であり，
慣用表現とは異なると考えた．

また事例 45 の「…患者はどこの病院でも *診* て貰えない…」の「診る」の語義は
対象単語の周辺に「病院」と類似の単語が存在することが必要だと考え，
「(c) 周辺単語に類似単語が必要」と判定した．


\subsubsection{領域の問題}

語義曖昧性解消の誤りは上記までの項目のいずれかに該当すると考えられるが，
特殊なケースとして訓練データのコーパス内にはまれにしか出現しない表現が，
テストデータとして出現したために生じる誤りが存在する．
これは領域適応の問題であり，教師あり学習により問題解決を図った場合に
必ず生じる問題である\cite{da-book}．この原因の誤りを「領域の問題」と判定した（記号 3-a）．
例えば事例 4 や事例 42 はテスト文が古文であり，学習の対象であった領域とは異なっている．
このような誤りを「領域の問題」と判定した．


\subsection{藤田の分析： 素性に着目}\label{sec:fujita}

まず，採用した誤り分析の考え方について述べる．
教師あり学習の場合，適切なラベルと素性を得ることができればほぼ正しく識別可能だと考
えられる．適切な素性があるにも関わらず誤りになる場合，素性に付与する重みが適切ではな
いなど，学習器側の問題だと考えることができる．そこで，当初は，適切な素性があるかどう
か，あるならば，素性に対する重みの付与などが適切かどうかを調査することを考えた．ただ
し，そもそも適切な素性が得られていないものが大半だったため，最終的には重みの適切さに
ついての詳細な調査は行わず，素性を増やした場合でも誤りとなる事例について，原因と
対処方法について考察した．


以下，\ref{sec:fujita-feas}節では，分析対象の 50 事例に対して，素性の重なりに着目した分析を示す．
さらに，\ref{sec:fujita-mhle}節では，
自前の語義曖昧性解消システムを用いて分析対象の 50 事例の語義識別を行い，
そのシステムでも誤りとなった 16事例についての詳細
な分析結果を示す．
最後に
~\ref{sec:fujita-matome}節で，語義曖昧性解消というタスクを考える上で，今後考えるべ
き問題点について考察する．


\subsubsection{素性の重なりの調査}\label{sec:fujita-feas}

まず，分析用システムの出力語義（以下，\SYS{}）と正解語義（以下，\COR{}）が付
与された訓練データから得られる素性と，対象のテスト文から得られる素性
の重なりを調査した．

例えば，\eid{13} の場合，対象テスト文の19種類の素性のうち，10種類
は\SYS{}と\COR{}の両方の訓練データに出現し，8種類は両方に出現しない．差
がある素性は，1種類（`e17=11950'，2語前の分類語彙表の値）のみであり，こ
れは，\SYS{}の訓練データのみに出現している．
つまり，\COR{}にのみ出現するような特徴的な素性は得られていないことがわかる．

\COR{}の訓練データにだけ存在する（手がかりになる可能性が高い）素性が存
在するかどうかに着目すると，分析対象とした 50事例のうち，
\COR{}の訓練データにだけ出現する素性があるテスト文は17 事例(34 \%)\footnote{このうち，
\ref{sec:fujita-mhle}節でも誤りとなったのは，3事例(\eid{24,42,47})だった．}
であり，そうした素性がないテスト文が33事例(66 \%)を占めた．
素性の不足に対応するには，学習データ自体を何らかの方法で増やすか，
学習データが変わらない場合には，利用する素性を増やす必要がある．


分析用システムでは，与えられた訓練データだけを用いており，利用している素性も
比較的少ない．
しかし，\eid{13}の場合でも，同一文中に
「ライン」や「経験」など，他に素性として有効そうな語があることから，
ウインドウ幅を広げたり，Bag-of-words (BOW) を利用することでも正解となる可能性がある．
また，分析用システムでは，辞書の例文を訓練データとして利用していないが，
例文は重要な手がかりであり，簡便に追加できる訓練データとなり得る．

そこで，次節では，例文などを訓練データに用いた自前のシステ
ム(\cite{Fujita:Fujino:2013}．以降，このシステムを「藤田のシステム」と呼ぶ．)の結果と比較し，両方で共通する
誤り事例に対して，誤り分析を行う．


\subsubsection{共通の誤り事例}
\label{sec:fujita-mhle}


まず，\SF{}の概要を説明する．\SF{}は，2段階に分けられる．Step-1では，
語義が付与されていない生コーパスの中から辞書の例文を含む文を抽出し，
ラベルありデータとして自動獲得する．
例えば，語義 15615-0-0-2の例文「工事{\bf 現場}」を含む文として，
例(\ref{s:genba})\footnote{日本経済新聞1999年版より抜粋}のような文を
ラベルありデータとして
利用できる．特に人間用の紙の辞書の場合，省スペース化のため，例文は非常
に短いことが多い．Step-1では，例文だけをラベルありデータとして追加する
より，より長くて情報量の多い文を自動獲得できるこ
とが利点である．

 \begin{exe}
 \ex \label{s:genba}
 足場 など を 組み合わせ て 建設 \ulf{工事 {\bf 現場}} や 各種 工場 の ライン を つくる 。
 \end{exe}

Step-2では，ラベルありデータとラベルなしデータを訓練データとして，
半教師あり学習法（ハイブリッド法，{\it Maximum Hybrid
Log-likelihood Expectation:} \MHLE, \cite{Fujino:Ueda:Nagata:2010}）を適用
する．
\MHLE{}では，ラベルありデータで
学習させたMEモデル（識別モデル）とラベルなしデータで学習させたNBモデル（生
成モデル）を統合して分類器を得る．

素性は，分析用システムで利用している素性以外に，
各語の原形，前後3語以内の
bigrams, trigrams, skipbigrams，
各対象語と同一文内に出現する全内容語の原形，
トピック分類の結果\footnote{Gibbsサンプリングを用いたトピック分
類 (http://gibbslda.sourceforge.net/) を行い，分類されたトピック番号を利用．}
を利用している．ただし，
係り受け情報(e16)と分類語彙表の値(e17--e20)は
利用していない．

もちろん，\SF{}を利用した場合，正解になるばかりではなく，
逆に分析用システムでは正解だったテスト文が不正解になる
場合もあるが，本節では両者の共通の誤り事例を取り上げる．
分析対象の50事例の内，\SF{}でも誤った事例は 16事例であった．その分析結果を表~\ref{tab:fujita-16}に示す．

\begin{table}[b]
\caption{共通した誤り事例の分析}
\label{tab:fujita-16}\small
\input{01table08.txt}
\end{table}

表~\ref{tab:fujita-16}から，[A] [B]は両手法で解くことは困難だと
考えられる．
[C][D]は素性の問題だが，[C]の場合は，両手法で採用していない項構
造解析(Semantic Role Labeling, SRL \cite{srl})を正しく行うことができれば，正解となる可能性がある．
なお，これらの対象語はすべて動詞であり，動詞の\WSD{}には，SRLが特に重要であることが
わかる．ただし，
係り受け解析誤りも含まれる誤り事例については，係り受け解析の精度向上により正解
できる可能性もある．
一方，[D]の場合，利用した素性が不適切だったり，少
なすぎたと考えられるので，適切な素性を取り出したり，利用素性を増やすことで正
解できる可能性がある．


しかしながら，[D]は\SF{}でも誤りとなっている．
[D]の誤り事例について，
\pagebreak
\ref{sec:fujita-feas}節と同様，\SF{}で得られ
た素性の重なりを調べると，訓練データの追加\footnote{ただし，追加されたラベル
  ありデータは\eid{39}の場合で 3文，そのうち\COR{}にあたるもの
  は1文，\eid{41}の場合で57文，そのうち\COR{}にあたるものは4文だっ
  た．}とBOW等の利用にも関わらず，少なくともラベルありデータにおい
て，\COR{}にのみ出現した素性はなく，逆に\SYS{}にのみ出現した素性がある
という結果だった．なお，両誤り事例とも，\COR{}の語義は元の訓練データに
も，それぞれ1回と4回しか出現しない低頻度語義である．
両対象語は，語義の頻度分布のエントロピー
 ($E(w) = - \sum_{i}^{} p(s_{i}|w) \log {p(s_{i}|w)}$. ここで， $p(s_{i}|w)$ は，単語$w$の語義が$s_i$となる確率．\cite{Shirai:2003j})による難易度分類では，低難易度の語に分類される．
つまり，ある語義が圧倒的に多く出現するため低難易度の語に分類されるが，
そうした語の低頻度語義の識別の難しさを示している．


\subsubsection{考察}
\label{sec:fujita-matome}

前節の分析結果をふまえ，
重要だと考える点について考察する．


まず，従来の\WSD{}の問題設定で今後取り組むべき課題として，以下の項目を上げる．

\begin{enumerate}
\item データの質の向上:
 人手作成データの一貫性の担保が必要．（表~\ref{tab:fujita-16},[A]）
\item 素性の追加:
 特に動詞について，係り受け精度の向上や項構造解析の組み込みが必要．（表~\ref{tab:fujita-16},[C]）
\item ラベルありデータの追加等:
 特に低頻度語義に対して対処方法の考案が必要．（表~\ref{tab:fujita-16},[D]）
\end{enumerate}

また，今後の方向性として，現在の\WSD{}の枠組みにこだわらず，他のタスク
でも利用されるには，どういった語義，どういった粒度で識別すべきか検討す
ることが重要だと考える．
特に，そもそも人間にとっても識別が困難な語義（表~\ref{tab:fujita-16},[B]）の推定が必要なのか，
アプリケーションや領域によって必要とされる語義の粒度や種類が異なるにも関わらず，
一律に扱ってよいのかどうか，といった点を考慮すべきだと考えている．


\subsection{佐々木の分析：パターンの差異に着目}

まず，ここでの誤り分析の考え方について述べる．注目したのは訓練データから得られるパターンと
テスト事例から得られるパターンとの差異である．
ここでいうパターンとは対象語の周辺に現れる素性（単語や品詞など）の組み合わせを指している．
一般に教師あり学習では，訓練データから得られるパターンの集合
とテスト事例から得られるパターンとの比較によって識別処理が行われる．
つまり誤りの原因はパターンの差異から生じると考えられる．
そして，その差異の原因として以下の2点に注目して誤り分析を行った．

\begin{itemize}
\item[(1)] 訓練データに不足しているパターン
\item[(2)] 訓練データから抽出される不適切なパターン
\end{itemize}

(1) はテスト事例のパターンが訓練事例に含まれないことから生じる誤りに対応する．
(2) は識別に有効そうなパターンが訓練事例に存在しているにも関わらず生じている
誤りに対応する．(2) は適切なパターンを抽出できていないことが原因だと考えた．

\begin{table}[b]
\caption{誤り原因のタイプ分類と出現数}
\label{tab:sasaki_error}
\input{01table09.txt}
\end{table}

作成した誤り原因のタイプ分類を表 \ref{tab:sasaki_error} に示す．
分析対象の 50事例に表\ref{tab:sasaki_error}のタイプを付与するが，ここでは重複も許すことにした．
以下，各誤り原因について述べる．
「構文情報の不足」はテスト事例の文の構造の情報を捉えていないことを表す．
例えば，対象単語を含む単語間の係り受け関係を考慮した素性の不足，
格関係のような文の意味的構造を表現した素性の不足などが挙げられる．
「考慮する単語の不足」は語義を識別できる特徴的な共起単語が少ないことを
表す．テスト事例において対象単語の前後に出現する共起単語や訓練事例に出現する共起単語の特徴
では語義を識別することが難しい場合をこのタイプの誤りとした．
「パターンの一部が不足」は品詞情報など，単語表層以外の特徴的な情報が不足していることを表す．
語義を識別できる特徴には名詞や動詞などの特徴的な単語だけではなく，
接続する品詞によって語義が決定する場合もある．
助詞や助動詞といった品詞を含むパターンが大きく影響して誤りとなる場合をこのタイプの誤りとした．
「概念情報の不足」は手がかりとして使う単語の上位・下位関係にある単語を利用していないことを表す．
テスト事例において対象単語の前後に出現する共起単語に対し，単語を表層形で利用すると訓練事例の単語と一致しないが，外部辞書として概念体系を使うと同じ概念として一致する場合がある．
同じ概念ではあるが概念体系を利用していないために誤って
識別する誤りをこのタイプとした．
「表記のずれ」は訓練事例に識別のためのパターンは存在するが，異表記が原因で誤ったタイプである．
「文が短く，手がかりがない」は文が短く，特徴が捉えにくいことを表す．
「再実験では正解した例」は誤り事例集合作成時は異なる語義に分類されたが，再実験を行った結果正しく分類された事例を表す．
2節の実験では libsvm の default のパラメータ設定を採用したので，
モデルの複雑度を調節するコストはC=1，学習を止める停止基準値は
eps=0.001 としていたが，C=5 及び eps=0.1 と設定して再実験したところ，
いくつかの誤り事例に対して正解が得られた．このように SVM の学習パ
ラメータの変更によって語義を正しく識別できた事例の誤り原因は「再実
験では正解した例」としてまとめた．

次に，ここで行ったいくつかの誤り分析の例を示す．
最も出現数の多い「パターンの一部が不足」の例として，
「早く元気な顔を見せて *あげる* 事ですね．」を見てみる．
「見せてあげる」と同様の「〜してあげる」というパターンが訓練事例に
存在していれば適切に識別できると考えられる．
しかし，訓練事例にはそのようなパターンの事例は存在しなかった．
その一方で，「あげる事です」に対応する「あげる＋普通名詞＋助動詞」の
パターンが異なる語義の事例として存在するために，この用例は誤った語義に識別されたと思われる．
「考慮する単語の不足」の例として，「…発音を *教え* てください…」を見てみる．
この事例の正しい語義は「知識や技能を身につけるように導く」であり，
「〜てください」のパターンが識別に有効そうであるが，
誤って識別した語義「知っていることを告げ示す」と共起単語を比較した結果，
どちらの語義でもこのパターンが生じていた．
このパターン以外に識別に有効そうな素性は存在していないため，結果的に誤っている．
このような問題に対処するには，
訓練事例数を数多く用意し，「教える」の前に接続する単語の種類を揃える
必要があると考える．
「概念情報の不足」の例として，「…悲鳴を *あげ* ながらずんずん進んだ…」がある．
この事例の正しい語義は「勢い・資格・価値・程度を高める．」である．
辞書にはこの語義の用例として「声を（高く）出す．」があるため，
この語義が正解であることは明らかである．
しかし，分析用システムは「取り出して言う．」と誤って識別した．
正しい語義の訓練事例には「声」，「叫び声」，「歓声」といった声に関連する単語が含まれているため，
テスト事例の「悲鳴」も含めて同じ「声」の概念として捉えることができれば識別可能だったと考えられる．
「表記のずれ」の例として，「落札する前に聞いた方が *いい* ですか？」がある．
訓練事例には正しい語義の事例で
「ほうがいいです」との表記
を持つものがあり，
テスト事例の「方」をひらがなの「ほう」に変更して識別を行うと適切に語義を識別することができた．
このように，異表記を正しく解析できないために誤ることもある．


\subsection{古宮の分析：最大頻度語義と素性に注目}

\begin{table}[b]
\caption{古宮による誤り原因のタイプ分類とその出現数}
\label{tab:komiya}\label{komiya1}
\input{01table10.txt}
\end{table}

機械学習の観点から誤りの原因の分析を行った．具体的には，訓練事例中の最頻出語義（Most Frequent Sense, 以下MFS）
の割合や，テスト事例と訓練事例の間の素性の違いと共通性を見ることで，機械学習の特質から説明できる誤りを主に分析した．
分析の結果を表\ref{tab:komiya}に示す．
なお，「MFSに誤分類」の2つの分類（表\ref{komiya1}のMと (M)）には重複して分類されることはないが，これらと
「テスト事例の素性が訓練事例の素性と等しい」（表\ref{komiya1}のF）と
「分からない，自信がない」（表\ref{komiya1}の？）については
重複して分類されることがある．

ここでの分析では，まず，MFS に注目した．
分析用システムの識別結果が a であり，それが誤りであった場合，
a は対象単語の MFS である
可能性が高いと考えたためである．
そこで，「MFSに誤って分類された」事例と，そうでない事例の分類を
行った．すると，分析対象の 50事例中の32事例が「MFSに誤って分類された」事例
であることが分かった．
更に，「MFSに誤って分類された」事例の中で，
MFS と第二位の比率を持つ語義（第二語義）との訓練事例数の差が小さい（4 以内の）
ものが5事例であり，残りの27事例は，
MFS と第二語義との訓練事例数の差が大きい（8 以上の）ものであった．
なお，差が5から7の事例は存在しなかった\footnote{また，残りの18事例のうち，二値分類ではない事例が
12事例あったが，そのうちの9事例が第二語義
に識別されていた．}．


例えば，最も顕著な例は対象単語の「場所」である．
「場所」の50個の訓練事例のうち，
49事例が語義 41150-0-0-1（ところ）であり，語義 41150-0-0-2 （居るところ）は1事例
しかなかった．
その結果，「場所」のテスト事例はすべて語義 41150-0-0-1 と識別されて
おり，テスト事例中に 2つあった語義 41150-0-0-2は誤りとなっていた．

このことから，誤りの原因として，機械学習の特質により，MFSに誤って
分類されるということが大きいことが分かる．また，この例にも見られるように，
今回の分析で用いた訓練事例の少なさから，
少量の事例しか持たない語義は十分に学習ができていないことがあったと思われる．


次に，テスト事例の素性が訓練事例の素性と等しいことで，誤っている事例を
目視で探した．例えば，「意味」の事例の一つ，
「…これらの単語で*意味*が通じるよ…」の
「意味」（正解は語義 2843-0-0-1（その言葉の表す内容．意義．））は，
「対象の単語の一つ後の形態素」が「が」である，という素性が強く働いた
ためであると思われる．この素性は語義 2843-0-0-3（表現や行為のもつ価値．意義．）
に頻出していたことから，語義 2843-0-0-3 に誤って識別されている．
この例は，語義 2843-0-0-3 として訓練事例にあった
「意味がある」「意味がない」に「意味が通じる」という
表現が少し似ていた，と見ることができる．このようなものは22事例 あった．

このように表現の類似性は，実際に語義曖昧性解消の手掛かりともなるが，
逆に誤りの原因ともなっている．
なお，このような，素性が誤りの原因と思われる事例 に対しては，「F」を付与した．
また，訓練事例中に何度も現れる顕著な素性ではない場合には，素性が
強く働いたかどうか分からないため，「F」とともに「?」も付与した．
さらに，これらの観点から分類が難しかったものに対しては，単独で「?」を付与した．

また，他にも，ここでの誤り分類のタイプには含めなかったが，
この素性が訓練事例にあれば識別可能だと思われる素性が，訓練事例にない場合が2つ存在した．
一つは，「…早く元気な顔を見せて*あげる*事ですね…」であり，
正解は語義 545-0-3-2（敬語としての用法）だが，手掛かりとなりそうな
「ひとつ前の形態素が『て』である」という素性が訓練事例には存在しなかった．

また，「…ええ水をお*あたえ*くださいませ…」の
正解は語義 755-0-0-1 （自分の物を他人に渡し，その人のものとする．）であり，
この「おあたえくださる」という
表現は典型的であると思われるが，訓練事例に「与えてください」のように「与える」と「くださる」の間に「て」を
はさむ用法はあっても，このような用法は存在しなかった．

最後に，分類語彙表の値に曖昧性があり，本来の意味ではない値が付与されていたために，誤った事例が1つあった．
「…凝固する際に*出る*熱を冷やしているから…」という用例で，
これは，「〜（の）際（さい）」という表現が「きわ」として誤って解析されたために誤った例である．
「出る」の訓練事例には「きわ」と同じ意味分類を持つ「外」などを2つ前の形態素に
もつ事例が2つあった．


\section{クラスタリングを用いた分析結果の統合}

\subsection{誤り原因のクラスタリング}

前掲の\mbox{表\ref{kekka-all}}が各自の分析結果である．誤り分析の次のステップとしては，
これらを統合し，
各人が同意できる統一した誤り原因のタイプ分類を作成し，
それに対する考察を行う必要がある．
しかし各自の分析結果を統合する作業は予想以上に負荷が高かった．
統合作業では分析対象の誤り事例一つ一つに対して，各分析者が与えた誤り原因を持ち寄って議論し，
統合版の誤り原因を決定しなければならない．
しかし，誤りの原因は一意に特定できるものではなく，しかもそれを各自が独自の視点でタイプ分け
しているため，名称や意味がばらばらな誤り原因が持ち寄られてしまい
議論がなかなか収束しないためであった．
また統合の処理を議論によって行う場合，結果的に誰かの分析結果を
ベースに修正していく形になってしまう．誰の分析結果をベースにすればよいかも正解はなく，
しかもある人の分析結果をベースにした時点で，他の人の分析結果に含まれるかもしれない
重要な情報を捨ててしまう危険性もある．
つまり分析者全員が同意できるような誤り原因のタイプ分類を，
グループ内の主観に基づく議論のみから作成するのは，負荷が高い作業になってしまう．

このような背景から，我々は各自の誤り原因を要素とする集合を作り，それをクラスタリングすることで，
ある程度機械的な誤り原因のタイプ分けを試みた．
クラスタリングでは分析者全員の分析結果を公平に扱っている．
またクラスタリングによって作成できた誤り原因のタイプ分類は
各人のタイプ分類を代表しているタイプ分類になっていることが期待できる．
結果として，このようなアプローチで作成した誤り原因のタイプ分類は，
各分析者が同意できるものとなり，しかも
統合作業の負荷を大きく減らすことができると考えた．

各自の分析では分析対象の 50事例に対して，各自が設定した誤り原因の記号を付与している形になっている．
見方を変えて各自が設定した誤り原因の記号の 1 つ 1 つに注目すると，50個の対象事例のどの事例が
その誤り原因に対応しているかを見ることができる．対応する事例に 1 を，対応しない事例に 0 を与えれば，
誤り原因は 50次元のベクトルに変換することができる．
そしてこのベクトルの距離が近いほど誤り原因の意味が近いと考えることができるため，
ベクトルに変換した誤り原因のクラスタリングが可能となる．

まず各自の誤り原因を取り出すと，全部で 75個存在した．
この 75 個の誤り原因がクラスタリングの対象である．
処理のために各誤り原因に ID 番号を付与した．
また誰が設定した誤り原因かがわかりやすいように，番号には各人を表す記号を前置している．
m- は村田，sr- は白井，fk- は福本，sn- は新納，fj- は藤田，
ss- は佐々木，k- は古宮を意味する．
この誤り原因と ID 番号との対応は付録2 に記した．
また付録2には誤り原因の意味（簡単な説明）も付与している．
以後，誤り原因に対してはこの ID 番号によって参照することにする．
75 個の各誤り原因を 50 次元のベクトルに変換し，そのノルムを 1 に正規化した後に
Ward 法によりクラスタリングを行った\cite{shinnou-r-book}．
このクラスタリング結果であるデンドログラムを\mbox{図\ref{cl-kekka}}に示す．

\begin{figure}[b]
\begin{center}
\includegraphics{22-5ia1f2.eps}
\end{center}
\caption{クラスタリング結果}
\label{cl-kekka}
\end{figure} 


\subsection{クラスタの抽出}

誤り原因の総数が 75 個，分析者が 7 人であり，その平均から考え，誤り原因は
10 個前後に設定するのが適切だと考えた．
そこで\mbox{図\ref{cl-kekka}} のデンドログラムから目視により，\mbox{図\ref{cl-ext}}に示す A から M の
13個のクラスタを取り出した．
各クラスタに含まれる誤り原因の ID番号を\mbox{表\ref{cls-nakami}}に示す．
またクラスタ内の各誤り原因には対応する事例が存在するので，その総数と種類数も\mbox{表\ref{cls-nakami}}に示す．

\begin{figure}[t]
\begin{center}
\includegraphics{22-5ia1f3.eps}
\end{center}
\caption{クラスタの設定}
\label{cl-ext}
\end{figure} 
\begin{table}[t]
\caption{クラスタ内の誤り原因と対応する事例数}
\label{cls-nakami}
\input{01table11.txt}
\end{table}


\subsection{各自の分析結果の統合}
\label{type-wake}

クラスタリングにより A から M の 13個のクラスタを取り出した．次に各クラスタに
意味を与える必要がある．
この意味を与えることで各自の分析結果の統合が完成する．
ただし各クラスタに正確に 1 つの意味を与えることは困難である．
通常，クラスタにある意味を設定した場合，クラスタ内にはその意味とは異なる要素が含まれることが多い．

ここでは各クラスタ内の要素（誤り原因）を精査し，その意味を設定する．
意味を割り当てることができたクラスタが統合版の誤り原因となる．
次にその意味から考え，不適な要素を省いたり別クラスタに移動させたりすることで，
最終的な統合を行う．


\subsubsection{クラスタの意味の付与とクラスタの合併}

クラスタに意味を付与するには，クラスタ内の類似している要素に注目し，
それらの共通の意味を抽出することで行える．
この段階で意味が同じクラスタは合併することができる．
以下，各クラスタについてその内容を表にまとめる．その表の「注目」の列に
``○'' がついているものが意味付けを行うために注目した要素である．

\begin{description}
\item[クラスタ A:【削除】] 
\end{description}

クラスタ A の内容は以下の通りである．意味付けは困難でありこのクラスタは削除する．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{63}  &   1   &  & \et{63} \\
\ei{11}  &   1   &  & \et{11} \\
\ei{17}  &   1   &  & \et{17} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ B: テスト文に問題あり] 
\end{description}

クラスタ B の内容は以下の通りであり，意味は「テスト文に問題あり」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{8}  &     1 & ○ & \et{8} \\
\ei{57}  &     1 & ○ & \et{57} \\
\ei{49}  &     2 & ○ & \et{49} \\
\ei{70}  &     3 & ○ & \et{70} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ C:【削除】] 
\end{description}

クラスタ C の内容は以下の通りである．意味付けは困難でありこのクラスタは削除する．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{21} &   1  &    & \et{21} \\
\ei{9}  &   4  &    & \et{9} \\
\ei{48} &   3  &    & \et{48} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ D:【削除】] 
\end{description}

クラスタ D の内容は以下の通りである．意味付けは困難でありこのクラスタは削除する．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{34}  &     1  &    & \et{34} \\
\ei{69}  &     3  &    & \et{69} \\
\ei{45}  &     1  &    & \et{45} \\
\ei{50}  &     4  &    & \et{50} \\
\ei{30}  &     1  &    & \et{30} \\
\ei{73}  &     5  &    & \et{73} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ E: シソーラスの問題 ] 
\end{description}

クラスタ E の内容は以下の通りであり，意味は「シソーラスの問題」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{41}  &  \phantom{0}3  & ○ & \et{41} \\
\ei{4}  &  \phantom{0}5  & ○ & \et{4} \\
\ei{60}  &  \phantom{0}1  &    & \et{60} \\
\ei{36}  &  11 &    & \et{36} \\
\ei{52}  &  11 & ○ & \et{52} \\
\ei{68}  &  19 & ○ & \et{68} \\
\ei{31}  &  \phantom{0}6  & ○ & \et{31} \\
\ei{10}  &  \phantom{0}4  &    & \et{10} \\
\ei{16}  &  \phantom{0}1  &    & \et{16} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ F: 学習アルゴリズムの問題 ] 
\end{description}

クラスタ F の内容は以下の通りであり，意味は「学習アルゴリズムの問題」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{27}  &   \phantom{0}5   & ○ & \et{27} \\
\ei{54}  &   \phantom{0}8   & ○ & \et{54} \\
\ei{74}  &   12  & ○ & \et{74} \\
\ei{20}  &   \phantom{0}3   &    & \et{20} \\
\ei{71}  &   \phantom{0}5   & ○ & \et{71} \\
\ei{1}  &   10  &    & \et{1} \\
\ei{39}  &   14  &    & \et{39} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\ei{74} (\et{74}) に ``○'' を付けている．
\ei{74} は古宮が設定した分類である．古宮の分類観点を見ると，\ei{74} が付けられた事例は
MFS の観点あるいは素性の様子からでは誤りの原因が特定できないものである
ことがわかる．これは分析用システムで利用した SVM による影響と見なせる．
そのため \ei{74} も「学習アルゴリズムの問題」と見なした．

\begin{description}
\item[クラスタ G: 訓練データの不足 ] 
\end{description}

クラスタ G の内容は以下の通りであり，意味は「訓練データの不足」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{28}  &   \phantom{0}2  &    & \et{28} \\
\ei{35}  &   \phantom{0}1  &    & \et{35} \\
\ei{43}  &   \phantom{0}1  &    & \et{43} \\
\ei{51}  &   \phantom{0}9  & ○ & \et{51} \\
\ei{2}  &   19 & ○ & \et{2} \\
\ei{75}  &   22 &    & \et{75} \\
\ei{13}  &   13 & ○ & \et{13} \\
\ei{55}  &   32 & ○ & \et{55} \\
\ei{67}  &   26 & ○ & \et{67} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\ei{55} (\et{55}) に ``○'' を付けている．
藤田のシステムは訓練データを拡張した手法である．
そのシステムで正解となったということで，その誤りの原因を「訓練データの不足」と見なした．

\begin{description}
\item[クラスタ H: 共起語の多義性 ] 
\end{description}

クラスタ H の内容は以下の通りであり，意味は「共起語の多義性」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{22}  &   1   &  ○  & \et{22} \\
\ei{42}  &   1   &  ○  & \et{42} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ I: 構文・格・項構造の素性不足 ] 
\end{description}

クラスタ I の内容は以下の通りであり，意味は「構文・格・項構造の素性不足」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{15}  &   1  & ○ & \et{15} \\
\ei{58}  &   2  & ○ & \et{58} \\
\ei{59}  &   3  & ○ & \et{59} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ J: データの誤り ] 
\end{description}

クラスタ J の内容は以下の通りであり，意味は「データの誤り」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{32}  &   2  & ○  & \et{32} \\
\ei{6}  &   2  & ○  & \et{6} \\
\ei{61}  &   1  & ○  & \et{61} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ K: 深い意味解析が必要 ] 
\end{description}

クラスタ K の内容は以下の通りであり，意味は「深い意味解析が必要」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{29}  &    \phantom{0}2 &    & \et{29} \\
\ei{19}  &    \phantom{0}2 &    & \et{19} \\
\ei{7}  &    \phantom{0}5 & ○ & \et{7} \\
\ei{56}  &    \phantom{0}9 & ○ & \et{56} \\
\ei{46}  &   14 & ○ & \et{46} \\
\ei{47}  &    \phantom{0}9 & ○ & \et{47} \\
\ei{37}  &    \phantom{0}4 & ○ & \et{37} \\
\ei{26}  &    \phantom{0}4 & ○ & \et{26} \\
\ei{62}  &    \phantom{0}1 &    & \et{62} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\ei{46} (\et{46}) に ``○'' を付けている．
\ei{46} は新納が設定した分類である．新納は \ei{46} と\ei{47} (\et{47}) を区別しているが，
そこでの説明にもあるように，これらの違いは一概に判断できない．
\ei{46} のタイプの誤りのほとんどは，その文脈上で人間は語義を識別できると考え，
ここではまとめることにした．
また \ei{56} (\et{56}) にも ``○'' を付けているが，
これは \ei{46} あるいは \ei{47} の意味と考えられるためである．

\begin{description}
\item[クラスタ L:【クラスタ I と合併】] 
\end{description}

クラスタ L の内容は以下の通りであり，意味は「構文・格・項構造の素性不足」とした．
これはクラスタ I の意味と同じであり，クラスタ L はクラスタ I と合併する．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & \multicolumn{1}{c}{意味}  \\
\hline
\ei{18}  &    \phantom{0}5  &    & \et{18} \\
\ei{3}  &    \phantom{0}2  & ○ & \et{3} \\
\ei{24}  &    \phantom{0}5  & ○ & \et{24} \\
\ei{72}  &    27 &    & \et{72} \\
\ei{65}  &    15 & ○ & \et{65} \\
\ei{66}  &    18 &    & \et{66} \\
\ei{44}  &    \phantom{0}2  &    & \et{44} \\
\ei{53}  &    \phantom{0}4  &    & \et{53} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

\begin{description}
\item[クラスタ M: 素性のコーディングが困難 ] 
\end{description}

クラスタ M の内容は以下の通りであり，意味は「素性のコーディングが困難」とした．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{>{\hspace{1.5zw}}l|c|c|l}
\hline
\multicolumn{1}{c|}{誤り原因 ID} &  事例数  &  注目 & 意味  \\
\hline
\ei{12}  &  \phantom{0}6  &    & \et{12} \\
\ei{25}  &  \phantom{0}7  & ○ & \et{25} \\
\ei{5}  &  13 &    & \et{5} \\
\ei{38}  &  10 & ○ & \et{38} \\
\ei{40}  &  \phantom{0}2  &    & \et{40} \\
\ei{64}  &  \phantom{0}1  &    & \et{64} \\
\ei{33}  &  \phantom{0}2  &    & \et{33} \\
\ei{14}  &  \phantom{0}3  &    & \et{14} \\
\ei{23}  &  \phantom{0}2  &    & \et{23} \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

以上より記号 B, E, F, G, H, I, J, K 及び M で示される 9 個の統合版の誤り原因を設定した（表13 参照）．


\subsubsection{クラスタリング結果の調整}

クラスタリングの対象であった75個の誤り原因のうち，統合版の誤り原因に置き換えられるものは
35種類であった．残り 40種類の誤り原因の中で統合版の誤り原因に置き換えられるものを調べた．
基本的には各分析者が自身の設定した誤り原因の意味と統合版の誤り原因の意味を比較することで行った．
結果，以下の\mbox{表\ref{okikae}}に示した 11 個の置き換えができると判断した．

上記の調整を行った後の統合版の誤り原因は\mbox{表\ref{kekka-type2}}にまとめられる．
本論文ではこれを「統合版誤り原因のタイプ分類」と名付けることにする．

\begin{table}[t]
\caption{統合版の誤り原因への置き換え}
\label{okikae}
\input{01table12.txt}
\end{table}
\begin{table}[t]
\caption{統合版誤り原因のタイプ分類}
\label{kekka-type2}
\input{01table13.txt}
\end{table}



\subsection{事例への誤り原因のラベル付与}

ここでは分析対象の 50事例を統合版誤り原因のタイプ分類に基づいてラベル（記号）を付与する．
まず対象事例に対する各自の分析結果である\mbox{表\ref{kekka-all}}の各記号を，
統合版誤り原因のタイプ分類の記号に置き換える．
次に2名以上が同じ記号を付けていた場合に，その記号をその事例に対する誤り原因とする．
結果を\mbox{表\ref{kekka-all3}}に示す．
「統合タイプ」の列が統合版誤り原因のタイプ分類による記号を表す．

\begin{table}[p]
\caption{50事例に対する統合版の誤り原因の付与}
\label{kekka-all3}
\input{01table15.txt}
\end{table}

以下に示す対象事例の 25, 42 には記号が付与されなかった．
これらの事例に対しては，誤り原因が分析者により異なり，
共通した原因がなかったためであるといえる．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{c|p{364pt}}
\hline
事例 ID & \multicolumn{1}{c}{テスト文} \\
\hline
25	& ただ飲みすぎは神経が完全に麻痺して *立た* なくなったり、射精が出来なくなることがあるので、ほどほどに・・・。  \\
\hline
42	& 千早ぶる神のみ *まへ* のたちばなも　もろ木も共においにける哉　（倭訓栞　前編十四多）  \\
\hline
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

また\mbox{表\ref{kekka-all3}}から得られる統合版の誤り原因の事例数を大きい順に\mbox{表\ref{kekka-all4}}に示す．
累積カバー率はその順位までのタイプを使って分析対象の50事例をどの程度カバーしているかを表す．
\mbox{表\ref{kekka-all4}}から誤りの 9割は上位 3つの「G: 訓練データの不足」「K: 深い意味解析が必要」
「E: シソーラスの問題」のいずれか，あるいはそのいくつかが原因であることがわかる．

\begin{table}[t]
\caption{統合版の誤り原因の事例数と累積カバー率}
\label{kekka-all4}
\input{01table14.txt}
\end{table}


\section{考察}

\subsection{統合版誤り原因のタイプ分類の評価}

ここでは統合版誤り原因のタイプ分類の評価を行う．
本論文が目標としたタイプ分類は分析者7名のタイプ分類を代表するタイプ分類であるため，
この観点から評価を行う．そのために，誤り原因のタイプ分類間の類似度を定義し，
各タイプ分類間の類似度を測る．
統合版誤り原因のタイプ分類がどの分析者の誤り原因のタイプ分類とも類似していれば，
統合版誤り原因のタイプ分類が本論文で目標としていたタイプ分類であることがいえる．

$A$と$B$を誤り原因のタイプ分類とし，$A$と$B$の類似度$Sim(A,B)$の定義を行う．
$A$の要素である各誤り原因は，本論文のクラスタリングで利用したように 50次元のベクトルで表現できる
\footnote{\mbox{表\ref{kekka-all3}}を用いれば，統合版誤り原因のタイプ分類も同様に，
その要素となっている9種類の誤り原因が50次元のベクトルで表現できる．}．
そして$A$の誤り原因が$m$種類のとき，$A$は以下のような集合で表現できる．
\begin{equation}
 A = \left\{ a_1, a_2, \cdots, a_m  \right\}    
\end{equation}
同様に，$B$の誤り原因が$n$種類のとき，$B$は以下のような集合で表現できる．
\begin{equation}
 B = \left\{ b_1, b_2, \cdots, b_n  \right\}    
\end{equation}
ここで$a_i$や$b_j$は50次元のベクトルである．

本論文では$Sim(A,B)$を以下で定義する．
\begin{equation}
 Sim(A,B) = \max_{Q} \sum_{(i,j) \in Q} s(a_i,b_j)     
\end{equation}

ここで$s(a_i,b_j)$は$a_i$と$b_j$の類似度であり，ここでは内積を用いる．
また$Q$は誤り原因のラベルの対応関係を表す．
例えば$A$のラベルが$\{1,2\}$であり，$B$のラベルが$\{1,2,3\}$である場合，
ラベルの対応は以下の 6通りが存在する．$Q$はこの中のいずれかになる．

\begin{verbatim}
    { (1,1), (2,2) },   { (1,2), (2,1) },  { (1,2), (2,3) }
    { (1,3), (2,2) },   { (1,1), (2,3) },  { (1,3), (2,1) }
\end{verbatim}

つまり$Sim(A,B)$はラベル間の対応$Q$に基づく誤り原因間の類似度の和を意味する．
問題は最適な$Q$の求め方であるが，一般にこれは組み合わせの数が膨大になるため，求めることが困難である．
ここでは単純に以下の擬似コードで示される貧欲法により$Q$を求め，その$Q$を用いて
$Sim(A,B)$を算出することにした．

\vspace{0.5\Cvs}
\begin{screen}
\small
\begin{verbatim}
     Q <- {}; K <- {1,2,・・・,m}; H <- {1,2,・・・,n}
     while((K != {}) ∧ (H != {})) {
        (i,j) = argmax s(a_i,b_j)   with  (i,j) ∈ (K,H)
        Q <- Q + { (i,j) }
        K <- K - {i}; H <- H - {j} 
     }
     return Q
\end{verbatim}
\end{screen}
\vspace{0.5\Cvs}

上記の疑似コードの概略を述べる．まず$A$も$B$も記号の添え字でラベルを表すことにする．
$A$のラベルの集合を$K$，
$B$のラベルの集合を$H$
とする．各$(i,j) \in (K,H)$
に対して，$sim(a_i,b_j)$を求めることで，
$sim(a_i,b_j)$が最大となる$(i,j)$が求まる．
これを$Q$に追加し，$K$から$i$
を，また$H$から$j$を取り除く．この処理を
$K$か$H$のどちらかの集合が空になるまで続け，
最終的な$Q$を出力とする．

またここではラベルの意味を考慮して$Q$を設定していないことに注意しておく．
我々の問題ではラベルに意味が付けられている．
このラベルの意味から要素間の対応を取り$Q$を設定することも可能である．
しかしここではそのようなアプローチは取らなかった．
つまりここでは分析者$A$が誤り原因$i$に付与した（主観的な）意味と，
分析者$B$が誤り原因$j$に付与した（主観的な）意味が似ているか似ていないかは考慮せずに，
$i$や$j$のラベルが付与された事例の分布のみから$i$と$j$の類似度を測っている．

またここでの誤り原因のタイプ分類では，1つの事例に対して複数の誤り原因を与えることを許している．
このため明らかに 1 つの事例に多くの誤り原因を与える方が類似度が高くなる．
この問題の解消のために 1 つの事例に$k$個の誤り原因を与えている場合，
その部分の頻度を$1/k$に修正した．さらに統合版誤り原因のタイプ分類では，事例 25, 42 に
ラベルを付与していない．一方，他の分析者は「わからない」「分析していない」などのラベルも許して
全ての事例にラベルを付与している．公正な評価のため，
統合版誤り原因のタイプ分類による事例 25, 42 にも便宜上「その他」というラベルを付与した．



上記の処理により各誤り原因のタイプ分類間の類似度を求めた結果を
\mbox{表\ref{kekka-kousatu1}}に示す．
表中の各人の名前はその人の誤り原因のタイプ分類を示し，【統合】は統合版誤り原因のタイプ分類を示す．
また類似度の横の括弧内の数値は，その行に注目して類似度の大きい順の順位を表す．


\begin{table}[t]
\caption{誤り原因のタイプ分類間の類似度}
\label{kekka-kousatu1}
\input{01table16.txt}
\end{table}
\begin{table}[t]
\caption{誤り原因タイプ分類の評価結果}
\label{kekka-datou-hyouka}
\input{01table17.txt}
\end{table}

各人の縦の列の順位を足して，要素数で割った結果を\mbox{表\ref{kekka-datou-hyouka}}に示す．
この値が低いほど，全体として他のタイプ分類と類似していることを示しており，
統合版誤り原因のタイプ分類が最も良い値を出している．
これは統合版誤り原因のタイプ分類が，
分析者7名のタイプ分類を代表していることを意味し，
本論文が目標としていたタイプ分類であることを示している．


\subsection{統合版誤り原因のタイプ分類を利用した各人の分析結果の比較}

ここでは統合版誤り原因のタイプ分類を利用して各人の分析結果の関係を考察する．

各人の誤り分析に対する分析結果は，細かく見ると，
誤り原因のタイプ分類の構築とそのタイプ分類
に従った対象事例への誤り原因のラベル付与からなっている．
各人の分析結果は誤り原因のタイプ分類が異なっているために，直接比較することはできないが，
各人が設定した誤り原因を統合版の誤り原因に変換し，誤り原因のラベルを統一することで，
各人の分析結果を比較できる．
具体的には\mbox{表\ref{kekka-all3}}が，統合版誤り原因のタイプ分類を利用して
誤り原因のラベルを統一した各人の分析結果と見なせる．
ラベルが付与されていない場合は，仮想的に 10番目の誤り原因のラベル「その他」が付与されていると考える．
これによって\mbox{表\ref{kekka-all3}}から各人の分析結果を$50 \times 10$の行列として
表現できる\footnote{行はその大きさを1に正規化しておく．}．
行列間の距離を各行（事例）間の距離の和で定義すれば，各人の分析結果間の距離が\mbox{表\ref{each-kyori}}の
ように求まる．

\mbox{表\ref{each-kyori}}から多次元尺度法を利用して，
各人の分析結果の位置関係を 2 次元にマップしたものが\mbox{図\ref{tajigen-syakudo}}である．

\begin{table}[b]
\caption{各人の分析結果間の距離}
\label{each-kyori}
\input{01table18.txt}
\end{table}
\begin{figure}[b]
\begin{center}
\includegraphics{22-5ia1f4.eps}
\end{center}
\caption{各人の分析結果の位置関係}\label{tajigen-syakudo}
\end{figure} 

\mbox{図\ref{tajigen-syakudo}}の各人の点はほぼ均等に分布しており，各人の分析結果は互いに
かなり異なることが確認できる．その上で以下の2点も認められる．

\begin{itemize}
        \item[(a)] 村田，白井，藤田，佐々木の 4 者の点（分析結果）は比較的近くに集まっている．
        \item[(b)] 古宮の点（分析結果）は比較的孤立している．
\end{itemize}

(a) は，\mbox{表\ref{each-kyori}}から
距離の近い分析者の組を順に並べると
\mbox{(村田, 藤田)}，\mbox{(村田,白井)}，\linebreak
\mbox{(藤田,佐々木)}，\mbox{(白井,藤田)}
となっていることからも裏付けられる．
また上記 4 者の距離が近いのは誤り原因 G 「訓練データの不足」の事例数のためと考えられる．
以下の表は各人の分析結果に対して，誤り原因 G が与えられた事例数である．

\vspace{0.5\Cvs}
\begin{center}
\small
\begin{tabular}{c|c|c|c|c|c|c}
\hline
村田  & 白井 & 福本 & 新納 & 藤田 & 佐々木 & 古宮  \\
\hline
 19   &  19  &  11  &   9  &  32  &   26   &   0   \\
\hline 
\end{tabular}
\end{center}
\vspace{0.5\Cvs}

村田，白井，藤田，佐々木の 4 者の分析結果に誤り原因 G が与えられた事例数は，
どれも比較的大きな値であることがわかる．
このため 4 者の類似度が高くなり，比較的近くに集まったと考えられる．

(b) は古宮の分析結果からほぼ明らかである．
古宮の分析結果には，誤り原因 F 「学習アルゴリズムの問題」しか与えられていない．
このため他の分析者と誤り原因の一致する事例が極端に少ない．
例えば佐々木とは 50事例中，誤り原因が一致するものは 2 つしかない．
一致する事例数が少ないと距離が大きくなり，結果的に孤立した位置となる．


\subsection{統合版誤り原因のタイプ分類と各人のタイプ分類の差}

ここでは統合版誤り原因のタイプ分類に置き換えられなかった各人が設定した誤り原因に注目し，
それらが統合版誤り原因のタイプ分類に置き換えられなかった理由を調べることで，
統合版ならびに各人の誤り原因のタイプ分類の特徴を考察する．

本論文ではクラスタリングを利用して各人の分析結果である誤り原因のタイプ分類を統合した．
原理的には多数決と各人の設定した誤り原因の意味を勘案してタイプ分けを行ったことに相当する．
統合の過程で各人の分析結果の一部は切り捨てられ，結果的に，統合版に含まれていない．
具体的には付録2の表の「統合版の誤り原因」の欄が空欄になっているものがそれに当たる．

「切り捨てられた」と言ってもクラスタリング結果の調整を行っているので，
実際は，設定した誤り原因が統合版の誤り原因のどれにも
置き換えられないと判断された結果である．
各人が設定したある誤り原因がある統合版の誤り原因に
置き換えられるかどうかの判断は，主観的な部分も大きく，困難である．
また事例数が少ないものは，統合版の構築には影響が出ないために，
無理矢理置き換えることを避けたという事情も考えられる．
一方，ある誤り原因が統合版の誤り原因に
置き換えられないことが比較的明らかなものも多い．
これはその誤り原因が独自の観点のためである．
例えば白井の \ei{28}（\et{28}）， \ei{29}（\et{29}），
新納の \ei{53}（\et{53}），
藤田の \ei{64}（\et{64}）などである．
また古宮の設定した誤り原因のほとんど（4 中 3つ）が統合版の誤り原因に
置き換えられていない．
具体的には \ei{72}（\et{72}）, \ei{73}（\et{73}）及び \ei{75}（\et{75}）である．
古宮のタイプ分類は，語義曖昧性解消の問題を分類問題として一般化した上で，
その現象ベースから誤りの原因を考えようとしたものであり，
上記 3 つはどれも独自の観点と見なせる．
また福本の \ei{40}（\et{40}）， \ei{43}（\et{43}）， \ei{44}（\et{44}）及び \ei{45}（\et{45}）は
福本が「語義曖昧性解消タスク外の問題」と位置づけたものであり，これも独自の観点と見なせる．


独自の観点とは多少異なるが，統合版の誤り原因の異なるタイプの部分的な和になっている，言わば，
混合した観点も統合版の誤り原因とは異なると考えた．
例えば村田の \ei{1}（\et{1}）は，主に以下の2種類の誤り原因に対応する．

\begin{itemize}
      \item[(1)] 同一文内の共起語を素性に利用すべき
      \item[(2)] 分類語彙表の分類番号の3桁や4桁も利用すべき
\end{itemize}
(1) は統合版誤り原因 K 「深い意味解析が必要」に対応し，
(2) は統合版誤り原因 E 「シソーラスの問題」に対応すると考えられる．
つまり村田の \ei{1}（\et{1}）はこれらを混合した観点と言える．
佐々木の \ei{66}（\et{66}）の場合，テスト事例あるいは訓練事例における「単語の不足」であるため，
統合版誤り原因 G 「訓練データの不足」と統合版誤り原因 K 「深い意味解析が必要」の
混合した観点となっている．

統合版の誤り原因に置き換えられなかった各人が設定した誤り原因のほとんどは独自の観点か
混同した観点であり，しかも事例数が少ない．
この点から統合版誤り原因のタイプ分類は，
各人のタイプ分類を代表するタイプ分類であるだけでなく，
各人が設定した誤り原因の主要部分が反映された
タイプ分類でもある．
その結果，統合版誤り原因のタイプ分類は，標準的な語義曖昧性解消の誤り原因のタイプ分類になっていると考えられる．
また標準的な誤りの原因のタイプ分類を定量的なデータと共に提示できた意味は大きい．
語義曖昧性解消の問題に新たに取り組む者にとって，
標準的な手法を用いた場合に，どのような誤りがどの程度出現するのかの目安を得られることは有益である．
その上で独自の手法を考案する際，提案手法がどのような誤りの解決を狙っているのかといった
研究の位置づけも明確になる点も長所である．

最後に，ここで作成した統合版誤り原因のタイプ分類の問題点として，
タイプの粒度の問題が存在することを注記しておく．
本論文では統合版誤り原因のタイプ分類を作成するのにクラスタリングを利用している．
そこではまず誤り原因のクラスタを 13個作成したが（\mbox{図\ref{cl-ext}}参照），
1つのクラスタに最大1つのタイプしか与えなかった．
これはタイプの粒度を一定に保つために行った処置である．
このためある粒度のタイプ分けは行えているが，その粒度が粗すぎることも考えられる．
例えば統合版誤り原因 G 「訓練データの不足」と言っても，
どのようなタイプの「訓練データ」なのかで詳細化できる．
また統合版誤り原因 K 「深い意味解析が必要」も，どのような「意味解析」なのかで
詳細化ができる．このような詳細化は有益であり，本研究の今後の課題と言える．


\section{おわりに}

本論文では Project Next NLP の「語義曖昧性解消」チームの活動として行われた
語義曖昧性解消の誤り原因のタイプ分けについて述べた．誤り分析の対象事例を設定し，メンバーの7名が
各自誤り分析を行った．
各自の分析結果はかなり異なり，
それらを議論によって統合することは負荷が高いことから，
ここでは各自の設定した誤り原因（計75個）を対応する事例を用いてベクトル化し，
それらのクラスタリングを行うことで，ある程度機械的に統合処理を行った．

クラスタリングによって統合版の誤り原因を特定し，
クラスタリング結果の微調整によって最終的な誤り原因のタイプ{分類を作成した}．
得られた誤り原因の主要な 3つにより，語義曖昧性解消の誤りの 9割が生じていることも判明した．
また得られたタイプ分類はタイプ分類間の類似度を定義して考察した結果，
分析者 7名のタイプ分類を代表するものであることも示した．
また統合した誤り原因のタイプ分類と
各自の誤り原因のタイプ分類を比較し，
ここで得られた誤り原因のタイプ分類が標準的であることも示した．

本研究で得られた誤り原因のタイプ分類は標準的であり，それを定量的なデータと共に提示できた
意味は大きい．今後，一部のタイプを詳細化することで改善していけると考える．
この点が今後の課題である．

\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Fujino, Ueda, \BBA\ Nagata}{Fujino
  et~al.}{2010}]{Fujino:Ueda:Nagata:2010}
Fujino, A., Ueda, N., \BBA\ Nagata, M. \BBOP 2010\BBCP.
\newblock \BBOQ A Robust Semi-supervised Classification Method for Transfer
  Learning.\BBCQ\
\newblock In {\Bem Proceedings of the 19th ACM International Conference on
  Information and Knowledge Management (CIKM'10)}, \mbox{\BPGS\ 379--388}.

\bibitem[\protect\BCAY{Fujita \BBA\ Fujino}{Fujita \BBA\
  Fujino}{2013}]{Fujita:Fujino:2013}
Fujita, S.\BBACOMMA\ \BBA\ Fujino, A. \BBOP 2013\BBCP.
\newblock \BBOQ Word Sense Disambiguation by Combining Labeled Data Expansion
  and Semi-Supervised Learning Method.\BBCQ\
\newblock {\Bem Transactions on Asian Language {\linebreak}Inforamtion
  Processing, Association for Computinng Machinery (ACM)}, {\Bbf 12}  (7),
  \mbox{\BPGS\ 676--685}.

\bibitem[\protect\BCAY{Gildea \BBA\ Jurafsky}{Gildea \BBA\
  Jurafsky}{2002}]{srl}
Gildea, D.\BBACOMMA\ \BBA\ Jurafsky, D. \BBOP 2002\BBCP.
\newblock \BBOQ Automatic Labeling of Semantic Roles.\BBCQ\
\newblock {\Bem Computational linguistics}, {\Bbf 28}  (3), \mbox{\BPGS\
  245--288}.

\bibitem[\protect\BCAY{Mihalcea \BBA\ Moldovan}{Mihalcea \BBA\
  Moldovan}{1999}]{Mihalcea1999}
Mihalcea, R.\BBACOMMA\ \BBA\ Moldovan, D.~I. \BBOP 1999\BBCP.
\newblock \BBOQ An Automatic Method for Generating Sense Tagged Corpora.\BBCQ\
\newblock In {\Bem Proceedings of the American Association for Artificial
  Intelligence (AAAI-1999)}, \mbox{\BPGS\ 461--466}.

\bibitem[\protect\BCAY{村田\JBA 神崎\JBA 内元\JBA 馬\JBA 井佐原}{村田 \Jetal
  }{2000}]{murata_msort_nlp}
村田真樹\JBA 神崎享子\JBA 内元清貴\JBA 馬青\JBA 井佐原均 \BBOP 2000\BBCP.
\newblock
  意味ソートmsort—意味的並べかえ手法による辞書の構築例とタグつきコーパスの作成例と情報提示システム例—.\
\newblock \Jem{言語処理学会誌}, {\Bbf 7}  (1), \mbox{\BPGS\ 51--66}.

\bibitem[\protect\BCAY{村田\JBA 内山\JBA 内元\JBA 馬\JBA 井佐原}{村田 \Jetal
  }{2003}]{Murata_murata_s2j_nlp2003_new}
村田真樹\JBA 内山将夫\JBA 内元清貴\JBA 馬青\JBA 井佐原均 \BBOP 2003\BBCP.
\newblock SENSEVAL2J 辞書タスクでの CRL
  の取り組み—日本語単語の多義性解消における種々の機械学習手法と素性の比較—.\
\newblock \Jem{言語処理学会誌}, {\Bbf 10}  (3), \mbox{\BPGS\ 115--133}.

\bibitem[\protect\BCAY{西尾\JBA 岩淵\JBA 水谷}{西尾 \Jetal }{1994}]{iwakoku5}
西尾実\JBA 岩淵悦太郎\JBA 水谷静夫 \BBOP 1994\BBCP.
\newblock \Jem{岩波国語辞典第五版}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{Okumura, Shirai, Komiya, \BBA\ Yokono}{Okumura
  et~al.}{2011}]{semeval-2010}
Okumura, M., Shirai, K., Komiya, K., \BBA\ Yokono, H. \BBOP 2011\BBCP.
\newblock \BBOQ On SemEval-2010 Japanese WSD Task.\BBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 18}  (3), \mbox{\BPGS\ 293--307}.

\bibitem[\protect\BCAY{白井}{白井}{2003}]{Shirai:2003j}
白井清昭 \BBOP 2003\BBCP.
\newblock SENSEVAL-2 日本語辞書タスク.\
\newblock \Jem{自然言語処理}, {\Bbf 10}  (3), \mbox{\BPGS\ 3--24}.

\bibitem[\protect\BCAY{S{\o}gaard}{S{\o}gaard}{2013}]{da-book}
S{\o}gaard, A. \BBOP 2013\BBCP.
\newblock {\Bem Semi-Supervised Learning and Domain Adaptation in Natural
  Language Processing}.
\newblock Morgan \& Claypool.

\bibitem[\protect\BCAY{強田\JBA 村田\JBA 三浦\JBA 徳久}{強田 \Jetal
  }{2013}]{Goda2013}
強田吉紀\JBA 村田真樹\JBA 三浦智\JBA 徳久雅人 \BBOP 2013\BBCP.
\newblock 機械学習を用いた同義語の使い分け.\
\newblock \Jem{言語処理学会第 19 回年次大会}, \mbox{\BPGS\ 585--587}.

\bibitem[\protect\BCAY{新納}{新納}{2007}]{shinnou-r-book}
新納浩幸 \BBOP 2007\BBCP.
\newblock \Jem{R で学ぶクラスタ解析}.
\newblock オーム社.

\end{thebibliography}


\appendix
    \section{誤り分析対象の 50 用例}

\vspace{-0.5\Cvs}
\noindent\small
\scalebox{0.84}{
\begin{tabular}{c|>{\hspace{1zw}}l|p{384pt}}
\hline
事例 ID & \multicolumn{1}{c|}{SemEval ID} &  \multicolumn{1}{c}{テスト文} \\
\hline
1 & 117-46 &  翌日の新聞は「体重六十六キロの日本人が七百三十二キロを破る」とか「六十六キロが五百七十五秒で *相手* をすべて倒した」と書き立てた。\\
\hline
2   &   545-11   &  早く元気な顔を見せて *あげる* 事ですね。\\
\hline
3   &   545-34   &  海水は思ったより冷たくて、おとうさんも私も悲鳴を *あげ* ながらずんずん進んだ。\\
\hline
4   &   755-30   &  さらにはまた、甲の女には与え得べからざるものを乙の女に、また乙の女には *与え* 得べからざるものを丙の女に、与え得るということもあろう。\\
\hline
5   &   755-48   &  村の人らは、お宮さんにおまいりして、「どうぞ、ええ水をお *あたえ* くださいませ」てお願いしてたんやと。\\
\hline
6   &   2843-10   & 脂肪を落とすという *意味* なら二の腕のみを細くするのは無理と思いますが、代謝を良くさせむくみを取るということなら何とか・・・？\\
\hline
7   &   2843-26   & 相手を尊重する意味でも、自己防衛の *意味* でも。\\
\hline
8   &   2843-50   & エミヤのように無理して平常を装う「やせがまん」も、これらの単語で *意味* が通じるよ。\\
\hline
9   &   2998-37   & 十月八日の夜、清瀬の帰りを待ち伏せて詫びを *入れる* 振りをしながら、マニラのバグラスの親分から託かったことがあると持ちかけた。\\ \hline
10   &  5541-15   & *教え* て下さい。\\
\hline
11   &  5541-35   & あれで　木曜と　木曜の時に　手をぶらぶらさせてる時の　発音を　 *教え* てください。\\
\hline
12   &  10703-2   & レべリングは結構 *技術* がいるみたいですね？\\
\hline
13   &  15615-1   &  入社３年目からずっと間接部門にいて *現場* （ライン）の経験も乏しいです。\\
\hline
14   &  15615-47   & 横浜市鶴見区内のマンションで昨年６月、男女４人の遺体が見つかった事件で、鶴見署は二十一日、 *現場* で自殺した同区潮田町、配管工上原三義容疑者（当時二十四歳）を被疑者死亡のまま殺人容疑で横浜地検に書類送検した。\\
\hline
\end{tabular}
}
\clearpage

\noindent
\scalebox{0.84}{
\begin{tabular}{c|>{\hspace{1zw}}l|p{384pt}}
\hline
事例 ID & \multicolumn{1}{c|}{SemEval ID} &  \multicolumn{1}{c}{テスト文} \\
\hline
15   &  17877-24   &  あとは今少子化で親が *子供* ばかりを監視し、思いどうりにしようとする事が、ある一定の年齢までは我慢できても、小学生くらいになると爆発するといわれます。\\
\hline
16   &  17877-49   &  《子供がおかしいと言う前に、大人は *子供* に向き合っているのか》\\
\hline
17   &  21128-3   &  このため、定期借地権を活用することで、初期投資や地価下落リスクなどを抑制した事業展開もみられるようになってきており、土地利用における多様な需要に応えられる環境を土地 *市場* にもたらすとともに、新たな土地需要を喚起していると考えられる。\\
\hline
18   &  21128-28   & この結果、かえって医師の処方を経ないで入手できる *市場* が生じている。\\
\hline
19   &  21128-45   & ６社と別の１社で *市場* を占有している。\\
\hline
20   &  24646-6   &  何か、病院と保険会社間での *情報* の行き来があるのでしょうか？\\
\hline
21   &  27236-3   &  したがって、アメリカのビジネスモデルと日本の従来のビジネスモデルの両方に精通していて、アメリカのモデルのアイデアをベースに *し* ながら、日本型のビジネスモデルをつくれる経営者が、日本では最も強いビジネスモデルを創造できるということになる。\\
\hline
22   &  27236-31   & たいていの場合は、数回に分けてじょじょに色を薄く *し* ていく治療なので、段階的に治していきます。\\
\hline
23   &  31472-5   &  二十四歳頃は間接部門（総務部）が嫌でラインへの異動希望も *だし* ていましたが、その部署で６年働いた頃結婚もして子供もうまれました。\\
\hline
24   &  31472-50   & いずれも耐震強度が０．５以下であることが判明し、４棟は退去勧告が *出さ* れている。\\
\hline
25   &  31640-13   & ただ飲みすぎは神経が完全に麻痺して *立た* なくなったり、射精が出来なくなることがあるので、ほどほどに・・・。\\
\hline
26   &  31640-37   & ところが、これまでの半導体生産方式では、ばらつき、雑音が多過ぎて誤動作してしまうため、四端子デバイスの実用化は夢と考えられたが、われわれのラジカル反応ベースの半導体生産技術の完成によってばらつき、雑音が完全に抑制できるようになったため、ようやく実用化のめどが *立っ* た。\\
\hline
27   &  34522-17   & 彼らによって今後、 *強い* ベンチャーが続々と誕生してくる可能性が出てきた。\\
\hline
28   &  35478-23   & ダムの場合はコンクリートの中に冷却水を流すチューブが縦横無尽に走っていて、コンクリートがゆっくり凝固する際に *出る* 熱を冷やしているから、収縮があるレベルに抑えられ、ひびが入らないのだという。\\
\hline
29   &  35478-43   & ９日のニューヨーク株式市場は、高値警戒感から利益を確定するための売りが *出* て、ダウ工業株平均は７営業日ぶりに下落した。\\
\hline
30   &  35881-44   & 二十・三十（十四・三十）　ＩＣＲＣアンマン事務所のムイーン・キッシースさんは、朝日新聞からの国際 *電話* に対して「今は衛星電話も含め、インターネット、無線など、バグダッドとは、すべての連絡手段が断たれている。現地からの連絡もない。医薬品を送る準備をしているが、バグダッドまでの陸路の安全が保証されれば、すぐにでも向かう予定だ」と話した。\\
\hline
31   &  37713-8   &    どうすればくもりを *取る* ことが出来ますか？\\
\hline
32   &  37713-22   & そこで、皆様に質問ですが、ヤフオクでは出品するだけで１品ごとに手数料を *とら* れると今日友人から聞きました。\\
\hline
33   &  37713-37   & もちろん白川氏が実際に経営の指揮を *とる* わけではない。\\
\hline
34   &  40289-27   & 待ち時間がほとんどなく、５時間の滞在で７〜８つのアトラクションに *乗れ* ました。\\
\hline
35   &  40333-17   & しかも、その *場合* 、講習後に大変難しい筆記試験があり、合格しなければ、免許取り消しになると交通課の方に脅かされました。\\
\hline
36   &  40699-20   &  側から *入っ* て、いちばん奥の、上座に当たる位置に、左から吉田松蔭、頼三樹三郎（鴨崖）…と居並び、更に西側にかけて、安政大獄で処刑された志士達、合わせて十五人、東側から南側にかけて、桜田門外で井伊直弼を襲撃した水戸藩士ら（うち一人は薩摩藩士）十八人、松蔭の墓だけ少し大きめの他、すべて同じ形、大きさの墓が整然と居流れています。\\
\hline
37   &  40699-40   & 、四月に *入り* 芝の根が勢いよく伸びてきたことや、二月以降、同スタジアムを管理する埼玉県が芝の養生に努めたことが、改善につながったとの見方を示した。\\
\hline
38   &  41135-31   & 夜は粟津歓迎の柔道大会が開かれ、ブーシュ・デュ・ローヌ県の県知事やマルセイユ市長、民間及び軍隊関係のお歴々を *初め* 柔道家、そして一般市民達が観戦し盛会だった。\\
\hline
39   &  41150-32   &   ここは、かけがえのない私の *場所* だ！\\
\hline
40   &  41912-26   & 知恵袋の中の回答を見ていると、「 *早* 過ぎる！」という方がちらほら…。\\
\hline
41   &  44126-6   &  *開い* たときに「請求書ご案内」が上に来るように入れます・・。\\
\hline
\end{tabular}
}
\clearpage

\noindent
\scalebox{0.84}{
\begin{tabular}{c|>{\hspace{1zw}}l|p{384pt}}
\hline
事例 ID & \multicolumn{1}{c|}{SemEval ID} &  \multicolumn{1}{c}{テスト文} \\
\hline
42   &  48488-8   &  千早ぶる神のみ *まへ* のたちばなも　もろ木も共においにける哉　（倭訓栞　前編十四多）\\
\hline
43   &  49355-13   & 島がびっしょり濡れているようにさえ *見え* た。\\
\hline
44   &  49812-15   & また、テレワークを導入した企業の二十三．一％が、テレワークは「非常に効果があった」と答え、七十二．七％の企業が「ある程度効果があった」と答えており、テレワークを導入した大半の企業が積極的な効果を *認め* ている（図表４）。\\
\hline
45   &  50038-16   & けど難病患者や理解の少ない病気の患者はどこの病院でも *診* て貰えないのでしょうか？\\
\hline
46   &  51332-36   & 女は両手に皿を *持っ* てキッチンから出てきて、ひとつをぼくの前に、ひとつを自分の席に置く。\\
\hline
47   &  51409-24   & この創造的な知識の活用能力としての「コンピテンス」をどう定義し、どう内容を定めていくかは、まだまだ議論と研究の最中で明確ではありませんが、二十一世紀の教育が「コンピテンス」と呼ばれる一般的な知的能力を *求め* て展開することは確実です。\\
\hline
48   &  52310-21   & 送られてきた封筒には出品者の住所氏名が書いてあるので根に持って意味もなく保管して *やり* ます。\\
\hline
49   &  52935-25   &   見なければ *よかっ* たです。\\
\hline
50   &  52935-41   &   落札する前に聞いた方が *いい* ですか？\\
\hline
\end{tabular}
}
\normalsize

    \section{各人の誤り原因の一覧}

\noindent
\small
\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|p{24zw}}
\hline
誤り原因 ID  &  分析者  & 記号 & 事例数 & \begin{tabular}{@{}c@{}}統合版の\\ 誤り原因 \end{tabular}  & \multicolumn{1}{c}{意味} \\ 
\hline
\ei{1}    & 村田 & f      & 10 &               & \et{1} \\
\ei{2}    &  〃  & d      & 19 &  G    & \et{2} \\
\ei{3}    &  〃  & s      & 2  &  I    & \et{3} \\
\ei{4}    &  〃  & t      & 5  &  E    & \et{4} \\
\ei{5}    &  〃  & n      & 13 &       & \et{5} \\
\ei{6}    &  〃  & w      & 2  &  J    & \et{6} \\
\ei{7}    &  〃  & p      & 5  &  K    & \et{7} \\
\ei{8}    &  〃  & i      & 1  &  B    & \et{8} \\
\ei{9}    &  〃  & u      & 4  &  F    & \et{9} \\
\ei{10}   &  〃  & c      & 4  &  I    & \et{10} \\
\ei{11}   &  〃  & r      & 1  &  M    & \et{11} \\
\ei{12}   & 白井 & 12     & 6  &  G    & \et{12} \\
\ei{13}   &  〃  & 13     & 13 &  G    & \et{13} \\
\ei{14}   &  〃  & 14     & 3  &  I    & \et{14} \\
\ei{15}   &  〃  & 15     & 1  &  I    & \et{15} \\
\ei{16}   &  〃  & 16     & 1  &  I    & \et{16} \\
\ei{17}   &  〃  & 17     & 1  &       & \et{17} \\
\ei{18}   &  〃  & 18     & 5  &       & \et{18} \\
\ei{19}   &  〃  & 19     & 2  &       & \et{19} \\
\ei{20}   &  〃  & 20     & 3  &       & \et{20} \\
\ei{21}   &  〃  & 21     & 1  &       & \et{21} \\
\ei{22}   &  〃  & 22     & 1  &  H    & \et{22} \\
\ei{23}   &  〃  & 23     & 2  &       & \et{23} \\
\ei{24}   &  〃  & 24     & 5  &  I    & \et{24} \\
\ei{25}   &  〃  & 25     & 7  &  M    & \et{25} \\
\ei{26}   &  〃  & 26     & 4  &  K    & \et{26} \\
\hline
\end{tabular}
}
\clearpage

\noindent
\resizebox{\textwidth}{!}{
\begin{tabular}{c|c|c|c|c|p{24zw}}
\hline
誤り原因 ID  &  分析者  & 記号 & 事例数 & \begin{tabular}{@{}c@{}}統合版の\\ 誤り原因 \end{tabular}  & \multicolumn{1}{c}{意味} \\ 
\hline
\ei{27}   &  〃  & 27     & 5  &  F    & \et{27} \\
\ei{28}   &  〃  & 28     & 2  &       & \et{28} \\
\ei{29}   &  〃  & 29     & 2  &       & \et{29} \\
\ei{30}   &  〃  & 30     & 1  &       & \et{30} \\
\ei{31}   &  〃  & 31     & 6  &  E    & \et{31} \\
\ei{32}   &  〃  & 32     & 2  &  J    & \et{32} \\
\ei{33}   &  〃  & 33     & 2  &  J    & \et{33} \\
\ei{34}   &  〃  & 34     & 1  &       & \et{34} \\
\ei{35}   & 福本 & 1-a    & 1  &   E   & \et{35} \\
\ei{36}   &  〃  & 1-b    & 11 &   G   & \et{36} \\
\ei{37}   &  〃  & 1-c    & 4  &   K   & \et{37} \\
\ei{38}   &  〃  & 1-d    & 10 &   M    & \et{38} \\
\ei{39}   &  〃  & 1-e    & 14 &   K   & \et{39} \\
\ei{40}   &  〃  & 2-a-i  & 2  &       & \et{40} \\
\ei{41}   &  〃  & 2-a-ii & 3  &   E   & \et{41} \\
\ei{42}   &  〃  & 2-a-iii& 1  &   H   & \et{42} \\
\ei{43}   &  〃  & 2-a-iv & 1  &       & \et{43} \\
\ei{44}   &  〃  & 2-c-i  & 2  &       & \et{44} \\
\ei{45}   &  〃  & 2-b-i  & 1  &       & \et{45} \\
\ei{46}   & 新納 & 1-a    & 15  &   K   & \et{46} \\
\ei{47}   &  〃  & 1-b    & 10  &   K   & \et{47} \\
\ei{48}   &  〃  & 1-c    & 3  &       & \et{48} \\
\ei{49}   &  〃  & 1-d    & 2  &  B    & \et{49} \\
\ei{50}   &  〃  & 2-a    & 4  &       & \et{50} \\
\ei{51}   & 新納 & 2-b            & 9  &   G         & \et{51} \\
\ei{52}   &  〃  & 2-c            & 11 &   E         & \et{52} \\
\ei{53}   &  〃  & 3-a            & 4  &             & \et{53} \\
\ei{54}   &  〃  & 4              & 8  &   F         & \et{54} \\
\ei{55}   & 藤田 & *              & 32 &   G         & \et{55} \\
\ei{56}   &  〃  & Difficult      & 9  &   K         & \et{56} \\
\ei{57}   &  〃  & TooShort       & 1  &   B         & \et{57} \\
\ei{58}   &  〃  & Kakari         & 2  &   I         & \et{58} \\
\ei{59}   &  〃  & SRL            & 3  &   I         & \et{59} \\
\ei{60}   &  〃  & BothAreOK      & 1  &             & \et{60} \\
\ei{61}   &  〃  & GuessIsCorrect & 1  &   J         & \et{61} \\
\ei{62}   &  〃  & FeaMakingError & 1  &             & \et{62} \\
\ei{63}   &  〃  & FewFea         & 1  &             & \et{63} \\
\ei{64}   &  〃  & Ancient        & 1  &             & \et{64} \\
\ei{65}   & 佐々木 & a            & 15 &   I         & \et{65} \\
\ei{66}   &  〃  & b              & 18 &             & \et{66} \\
\ei{67}   &  〃  & c              & 26 &   G         & \et{67} \\
\ei{68}   &  〃  & d              & 19 &   E         & \et{68} \\
\ei{69}   &  〃  & e              &  3 &             & \et{69} \\
\ei{70}   &  〃  & f              &  3 &  B          & \et{70} \\
\ei{71}   &  〃  & z              &  5 &   F          & \et{71} \\
\ei{72}   & 古宮 & M              &  29 &             & \et{72} \\
\ei{73}   &  〃  & (M)            &  4  &             & \et{73} \\
\ei{74}   &  〃  & ?              &  12 &  F           & \et{74} \\
\ei{75}   &  〃  & F              &  22 &             & \et{75} \\
\hline
\end{tabular}
}
\normalsize

\clearpage

\begin{biography}

\bioauthor{新納　浩幸}{
1985年東京工業大学理学部情報科学科卒業．
1987年同大学大学院理工学研究科情報科学専攻修士課程修了．
同年富士ゼロックス，翌年松下電器を経て，
1993年より茨城大学工学部助手．2015年同学部教授．現在に至る．
博士（工学）．
機械学習や統計的手法を用いた自然言語処理の研究に従事．
言語処理学会，情報処理学会，人工知能学会各会員．
}

\bioauthor{村田　真樹}{
1993年京都大学工学部電気工学第二学科卒業．
1997年同大学院工学研究科電子通信工学専攻博士課程修了．博士（工学）．
同年，京都大学にて日本学術振興会リサーチ・アソシエイト．
1998年郵政省通信総合研究所入所．
2010年鳥取大学大学院工学研究科教授．現在に至る．
自然言語処理，情報抽出の研究に従事．
言語処理学会，情報処理学会，電子情報通信学会，人工知能学会各会員．
}

\bioauthor{白井　清昭}{
1993年東京工業大学工学部情報工学科卒業．
1998年同大学院情報理工学研究科博士課程修了．
同年同大学院助手．
2001年北陸先端科学技術大学院大学情報科学研究科助教授．現在に至る．
博士（工学）．
統計的自然言語解析に関する研究に従事．
情報処理学会，人工知能学会，電子情報通信学会各会員．
}

\bioauthor{福本　文代}{
1986年学習院大学理学部数学科卒．
同年沖電気工業株式会社入社．総合システム研究所勤務．
1988年より1992年まで財団法人新生代コンピュータ技術開発機構へ出向．
1993年マンチェスター工科大学計算言語学部修士課程修了．
同大学客員研究員を経て1994年より山梨大学工学部助手，2010年同学部教授，現在に至る．
自然言語処理の研究に従事．理博．ACM, ACL, 情報処理学会各会員．
}

\bioauthor{藤田　早苗}{
1999年奈良先端科学技術大学院大学情報科学研究科博士前期課程修了．
同年，NTT日本電信電話株式会社入社．
現在，NTT コミュニケーション科学基礎研究所 研究主任．博士（工学）．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，人工知能学会各会員．
}

\bioauthor{佐々木　稔}{
1996年徳島大学工学部知能情報工学科卒業．
2001年同大学大学院博士後期課程修了．博士（工学）．
2001年12月茨城大学工学部情報工学科助手．
現在，茨城大学工学部情報工学科講師．
機械学習や統計的手法による情報検索，自然言語処理等に関する研究に従事．
言語処理学会，情報処理学会各会員．
}

\bioauthor{古宮嘉那子}{
2005年東京農工大学工学部情報コミュニケーション工学科卒．
2009年同大大学院博士後期課程電子情報工学専攻修了．
博士（工学）．同年東京工業大学精密工学研究所研究員，
2010年東京農工大学工学研究院特任助教，
2014年茨城大学工学部情報工学科講師．現在に至る．
自然言語処理の研究に従事．
情報処理学会，人工知能学会，言語処理学会各会員．
}

\bioauthor{乾　　孝司}{
2004年奈良先端科学技術大学院大学情報科学研究科博士課程修了．
日本学術振興会特別研究員，東京工業大学統合研究院特任助教等を経て，
2009年筑波大学大学院システム情報工学研究科助教．2015年同准教授．現在に至る．
博士（工学）．自然言語処理の研究に従事．近年はCGMテキストに対する評判分析に興味をもつ．
}


\end{biography}


\biodate




\end{document}
