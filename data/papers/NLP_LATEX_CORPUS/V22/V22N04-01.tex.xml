<?xml version="1.0" ?>
<root>
  <jtitle>DeepBeliefNetworkを用いた検索用語の予測</jtitle>
  <jauthor>馬青谷河息吹村田真樹</jauthor>
  <jabstract>	本稿は機械学習を用いて関連語・周辺語または説明文書から適切な検索用語を予測する手法を提案する．機械学習には深層学習の一種であるDeepBeliefNetwork(DBN)を用いる．DBNの有効性を確認するために，用例に基づくベースライン手法，多層パーセプトロン(MLP)，サポートベクトルマシン(SVM)との比較を行った．学習と評価に用いるデータは手動と自動の2通りの方法でインターネットから収集した．加えて，自動生成した疑似データも用いた．各種機械学習の最適なパラメータはグリッドサーチと交差検証を行うことにより決定した．実験の結果，DBNの予測精度はベースライン手法よりはるかに高くMLPとSVMのいずれよりも高かった．また，手動収集データに自動収集のデータと疑似データを加えて学習することにより予測精度は向上した．さらに，よりノイズの多い学習データを加えてもDBNの予測精度はさらに向上したのに対し，MLPの精度向上は見られなかった．このことから，DBNのほうがMLPよりもノイズの多い学習データを有効利用できることが分かった．</jabstract>
  <jkeywords>深層学習，DeepBeliefNetwork，検索用語予測，関連語，周辺語，情報検索支援</jkeywords>
  <section title="はじめに">Googleに代表される現在の検索エンジンはその性能が非常によくなってきており，適切な検索用語（キーワード）さえ与えてやればおおむね期待通りの検索結果が得られる．しかし一方，多くのユーザ，特に子どもや高齢者，外国人などにとって検索対象を表す適切な検索用語（特に専門用語など）を見つけることは往々にしてそう簡単ではない．マイクロソフトの「現在の検索で不満に思う点」に関する調査によれば，57.6%の人が適切なキーワード探しの難しさに不満を感じている．また，「何か欲しい情報を求めて検索エンジンを利用しているのに，それを利用するための適切なキーワードをまた別のところで探さねばならないという，堂々巡りをした経験を持つ人も多いはず」とも指摘されている．これは2010年の調査ではあるが，現在においてもこれらの不満点が大方解消されたとは言い難い．そこで，関連語・周辺語（たとえば「コンピュータ」，「前の状態」，「戻す」）またはそれらの語から構成される文を手掛かりに適切な検索用語（この場合「システム復元」）を予測・提示する検索支援システムがあればより快適な検索ができるのではないかと考えられる．本研究では，ITや医療など様々な分野において，これらの分野の関連語・周辺語またはそれらの語から構成される文を入力とし，機械学習を用いて適切な検索用語を予測・提示する検索支援システムの開発を目標としている．このような研究は，すくなくとも日本語においては我々が調べた限りではこれまでなされていなかった．本稿ではその第一歩として，分野をコンピュータ関連に限定し，深層学習(DeepLearning)の一種であるDeepBeliefNetwork(DBN)を用いた予測手法を提案する．近年，深層学習は様々な分野で注目され，音声認識~や画像認識~のみならず，自然言語処理の諸課題への応用にも優れた性能を出している．それらの諸課題は，形態素・構文解析~，意味処理~，言い換え~，機械翻訳~，文書分類~，情報検索~，その他~を含む．さらに，統一した枠組みで品詞タグ付け・チャンキング・固有表現認識・意味役割のラベル付けを含む各種の言語処理課題を取り扱えるニューラルネットおよび学習アルゴリズムも提案されている~．しかしながら，われわれの知っている限りでは，前に述べたような情報検索支援に関する課題に深層学習を用いた研究はこれまでなされていない．したがって，本稿で述べる研究は主に二つの目的を持っている．一つは，関連語・周辺語などから適切な検索用語を正確に予測する手法を提案することである．もう一つは，深層学習がこのような言語処理課題において，従来の機械学習手法である多層パーセプトロン(MLP)やサポートベクトルマシン(SVM)より優れているか否かを確かめることである．本研究に用いたデータはインターネットから精度保証がある程度できる手動収集と，ノイズは含まれるが規模の大きいデータの収集が可能な自動収集との2通りの方法で収集した．加えて，ある程度規模が大きく精度もよい疑似データも自動生成して用いた．機械学習のパラメータチューニングはグリッドサーチと交差検証を用いて行った．実験の結果，まず，学習データとして手動収集データのみを用いても自動収集データと疑似データを加えてもDBNの予測精度は用例に基づくベースライン手法よりははるかに高くMLPとSVMのいずれよりも高いことが確認できた．また，いずれの機械学習手法も，手動収集データにノイズの多い自動収集データとノイズの少ない疑似データを加えて学習することにより予測精度が向上した．さらに，手動収集データにノイズの多い自動収集データのみを加えて学習した場合，DBNとSVMには予測精度の向上が見られたがMLPにはみられなかった．この結果から，MLPよりもDBNとSVMのほうがノイズに強くノイズの多い学習データも有効利用できる可能性が高いと言えよう．</section>
  <section title="関連語・周辺語コーパス">機械学習を用いて関連語・周辺語から検索用語を予測・提示する場合，その学習データとして，入力（関連語・周辺語）と正解となるレスポンス（検索用語）のペアからなるコーパスが必要となる．本稿ではこのようなコーパスを「関連語・周辺語コーパス」と呼ぶ．また，教師あり機械学習では，レスポンスをラベルと呼ぶ場合が多いので，本稿では検索用語をラベルと呼ぶ．表~はコーパスの入力（関連語・周辺語とその元となる説明文書）とラベルのペアの例を示す．本章では，コーパスデータの収集・作成方法について述べる．また，収集・作成したデータからの関連語・周辺語の抽出方法と特徴ベクトルの構成方法について述べる．</section>
  <subsection title="手動収集と自動収集">本研究では，ラベルを説明している文書には関連語・周辺語が多く含まれると考え，インターネットからこのようなWebページを手動と自動の2通りの方法で収集した．手動収集では人手でラベルを説明するWebページを選別し収集する．一方，自動収集では，ラベルの後に「とは」「は」「というものは」「については」「の意味は」の5語を付けて（たとえば，ラベルが「グラフィックボード」であれば「グラフィックボードとは」「グラフィックボードというものは」などで）Googleで検索したものを説明文書として収集する．手動収集データは規模が小さい代わりに精度が高く，自動収集データは精度が低い代わりに規模が大きい．</subsection>
  <subsection title="疑似データ">機械学習の汎化能力を向上させるために，学習データとして，精度は高いが規模が小さい手動収集データに加え，精度はそれほど高くない（つまり，ノイズはある）が相対的に規模の大きい自動収集データを用いることにした．しかし，自動収集したデータには説明文書とラベルがそもそも一致しない，つまり説明文書へのラベルが履き違えられている可能性も考えられる．そのために，手動で収集した説明文書をオリジナルのデータとしてとらえ，それらに適度なノイズを加えて作成した疑似データも用いることにした．このようなデータは自動収集したデータに比べノイズが少なくラベルの履き違いもないと考えることができる．疑似データの具体的な生成手順は以下の通りである．オリジナルの説明文書からすべての異なり単語を抽出する．個々のオリジナルの説明文書に対し，追加，削除，または追加&amp;削除の処理を加える．具体的には，手順(1)で抽出した単語のうち，説明文書にない単語を説明文書の単語数の10%個ランダムに選んで加える，説明文書から単語を説明文書の単語数の10%個ランダムに選んで削除する，または上記の（10%ずつの）追加と削除を同時に施す，という処理を等確率（つまり，それぞれを1/3の確率）で行う．手順(2)で得られたデータを疑似データとする．なお，この生成方法においては，1つのオリジナルの説明文書に対し，疑似データを複数生成することが可能である．</subsection>
  <subsection title="評価データ">評価データは学習データとは別に自動収集したものを用いる．ただし，自動収集データは，ラベルが正確とは限らないため，評価データとして用いても適切な評価とならない可能性がある．そのため，評価データとして自動収集データの中からラベルの正しいものを人手で選別して用いることにした．</subsection>
  <subsection title="関連語・周辺語抽出とベクトル変換">以下の手順(1)〜(4)で説明文書から関連語・周辺語を抽出する．それに手順(5)(6)を加えることにより，機械学習に必要な特徴ベクトルへの変換を行う．手動収集のデータを形態素解析し，名詞（固有名詞，サ変接続，一般）を抽出する．名詞が連続しているならば，日本語同士なら結合し，英語同士なら空白を間に入れて結合し，1つの単語と見なす．各ラベルから出現頻度がトップ50以内の単語を抽出する．ラベル間で重複している単語を除外する．本研究では，以下に述べる考えに基づき2ラベル間で重複する単語を除外する，または，3ラベル以上で共通する単語を除外するという2通りの方法を採用した．まず，各ラベルにできるだけ特徴的な単語のみを素性にするためには重複単語をできるだけ除外するのが効果的と考える．また，今回は実験規模が小さくあまり問題にならないが，予測用語の数の増加に伴う特徴ベクトル次元の大幅な増加を抑える1つの方法として重複単語を除外することが考えられる．特徴ベクトル次元の抑制はまた一般的に，学習におけるデータスパースネス問題の緩和にもつながる．しかし一方，ラベル間の単語重複をまったく認めないと，たとえば「USBメモリ」のような，「USB」や「メモリ」に共通する重要な単語を除外してしまう問題も考えられる．そのため，本研究では2ラベル間の重複を許容し3ラベル以上で共通する単語を除外する方法も用いる．上記手順で得られた単語をベクトルの要素とし，個々の要素はその単語が出現していれば1，出現していなければ0の2値を取る．2.1,2.2,2.3節で述べたすべてのデータに対し形態素解析を行い，手順(5)にしたがって特徴ベクトルに変換する．</subsection>
  <section title="深層学習">深層学習とは従来の機械学習より深い層構造をしている機械学習手法全般のことを指す．その代表的な手法としてDeepBeliefNetwork(DBN)~とStackedDenoisingAutoencoder(SdA)~が提案されている．数多くの課題において，その両者の性能がほぼ同じと言われているが，本研究ではよりスマートなアーキテクチャを有するDBNを用いることにした．深層学習は，本来経験則で行っていた特徴抽出を機械学習に組み込もうとしてできたものである．そのため，DBNは，RestrictedBoltzmannMachine(RBM)を複数並べ教師なし学習の特徴抽出器として利用する多層のニューラルネットと，ラベルを出力する教師あり学習の最終層から構成される．特徴抽出器の教師なし学習はPre-training，最終層の教師あり学習はFine-tuningと呼ばれる．</section>
  <subsection title="Restricted Boltzmann Machine (RBM)">RBMは制限付きボルツマンマシンとも呼ばれ，学習データの確率分布を教師なし学習で表現する（言い換えれば，学習データの生成モデルを統計的な機械学習の方法で構築する），一種の確率的なグラフィカルモデルである．本来のボルツマンマシンの可視層と隠れ層のユニット間の結合を制限することにより，効率的な教師なし学習を実現している．RBMの構造は図~に示しているように可視層と隠れ層の2層から構成され，層内ユニット間に結合がなく，層間のユニット，すなわち可視ユニット(v_1,v_2,,v_m)と隠れユニット(h_1,h_2,,h_n)，は結合されている．以下，その学習アルゴリズム~を簡潔に述べておく．学習データvが可視層に与えられたとき，まず，式(1)，(2)，そして再度(1)の順で条件付確率に基づくサンプリングを行う．P(h_i^(k)=1|v^(k))=sigmoid(_j=1^mw_ijv_j^(k)+c_i)(v_j^(k+1)=1|h^(k))=sigmoid(_i=1^nw_ijh_i^(k)+b_j)gatherただし，k(1)はサンプリングの繰り返し回数，v^(1)=v，w_ijはユニットv_jとh_i間の結合の重み，そして，b_jとc_iは可視層と隠れ層のユニットv_jとh_iのオフセット（バイアス）である．サンプリングをk回行った後，重みとオフセットは以下のように更新される．WW+(h^(1)v^T-P(h^(k+1)=1|v^(k+1))v^(k+1)T)bb+(v-v^(k+1))cc+(h^(1)-P(h^(k+1)=1|v^(k+1)))gatherただし，は学習率である．Wは微小な乱数m+n,46m+n]内の一様乱数を用いる（ただし，mとnはそれぞれ可視層と隠れ層のユニット数である）．その数学的な考えについてはを参照されたい．，b,cは0で初期化する．サンプリングの繰り返し回数が十分多いときはGibbssamplingと呼ばれており計算コストが非常に高い．そのため，通常，サンプリングをk回のみ行うk-ContrastiveDivergence（略してCD-k）と呼ばれる方法が採用される．実際，k=1(CD-1)でも結果が十分よいことが経験的に知られており，本研究もk=1に設定して学習を行う．ここでN個の学習データに対しCD-kと呼ばれるサンプリング方法でe回繰り返し学習を行う手順を図~にまとめる．学習が進むにつれ，可視層のサンプルv^(k+1)が学習データvに近づいていく．</subsection>
  <subsection title="Deep Belief Network (DBN)">図~は一例として，三つのRBMと教師あり学習器から構成されるDBNを示す．ただし実際，DBNを構成するRBMの数は可変である．それらRBMはPre-trainingとも呼ばれ，教師なしの特徴抽出器として機能する．一方，教師あり学習器はFine-tuningとも呼ばれ，入力（図~の場合はその入力から得られたRBM3の出力）とラベルのペア（つまり正解付学習データ）を学習することにより未知の入力に対しても適切なラベルを出力できるようになる．図に示しているように前方のRBMの隠れ層は後方のRBMの可視層となっている．ここでは簡便化のために，RBMの層（ただし入力層を除く）をDBNの隠れ層と見なす．つまり，図の例は三層の隠れ層のDBNである（隠れ層の数とRBMの数は同じであることに注意されたい）．なお，教師あり学習はいろいろな方法で実現できるが，本稿ではロジスティク回帰を用いることにした．三つのRBMを持つDBNの学習手順を図~にまとめる．</subsection>
  <section title="実験"/>
  <subsection title="実験設定"/>
  <subsubsection title="データ">学習と評価には10個のラベルとそれらの入力（説明文書）のペアから構成されるデータを用いた．表~はラベル名と各ラベルの入力（説明文書）の数とそれらの全ラベルに占める割合を示す．ただし，学習データは，手動収集データをベースとし，そのベースとなるデータに異なる数の自動収集データと疑似データを加えることにより13個のデータセット（表~）を作成して用いた．表中のm300はベースとなるデータセットで手動で収集した300個のデータである．また，たとえばa2400は2,400個の自動収集データとm300で構成されたデータセット，p2400は2,400個の疑似データとm300から構成されたデータセット，そしてa2400p2400は2,400個の自動収集データ，2,400個の疑似データ，そしてm300から構成されたデータセットである．また，評価には学習データと異なる100個のデータを用いた．個々の説明文書は2.4節で述べた方法で，2ラベル間で重複する単語を除外する場合と3ラベル以上で共通する単語を除外する場合においてそれぞれ182と223次元の特徴ベクトルに変換される．</subsubsection>
  <subsubsection title="パラメータのチューニング">各種の機械学習の各学習データセットにおける最適なパラメータは，それぞれの学習データセットに対しグリッドサーチと5-fold交差検証を行って決定した．グリッドサーチに用いるパラメータの詳細は表~にまとめている．たとえば，DBNの入力が182次元の場合の構造（隠れ層）の欄に152-121-91がある．これは，そのDBNは182-152-121-91-10という構造を持つ，ということを表している．ただし，数字182と10は入力層と出力層のユニット数であり，それぞれ特徴ベクトルの次元数とラベルの数に対応している．また，これら隠れ層のユニット数は恣意的にではなく，前半の3つについては線形等間隔に設定している．すなわち，入力層のユニット数(182)から，ピラミッド的に，最初の隠れ層のユニット数を1825/6(152)，次の隠れ層のユニット数を1824/6(121)，そして，最後の隠れ層のユニット数を1823/6(91)のように設定している．一方，後半の3つについては，Bengioのの薦め，すなわち，過学習への対処が適切であれば隠れ層のユニット数は基本的に多いほどよい，ネットワーク構造は各層が同じサイズでよい場合が多い（ピラミッドまたは逆ピラミッドである必要はない）に基づき，すべての隠れ層のユニット数を入力層のユニット数の3/2倍であるように設定した．入力層のユニット数が223の場合も同様な考え方に基づいて設定した．DBNがMLPとSVMよりパラメータが多いため，同じ細かさのグリッドサーチで最適なパラメータを決めてしまうと，パラメータの多いDBNのほうが細かなチューニングができるため有利になる可能性がある．このようなバイアスをなくすために，MLPとSVMについてそのパラメータグリッドをより細かくし，MLPとSVMの探索すべきパラメータセットの数（つまり，パラメータの組み合わせの数）をDBNのそれと等しいかそれ以上にした．一方，MLPについては，構造，学習率，学習回数がDBNとまったく同じものも比較に用いた．本稿では後者をMLP1，前者をMLP2と呼ぶ．その結果，DBNとMLP2は同じく864通りのパラメータセット，SVM(Linear)とSVM(RBF)は900通りのパラメータセット，また，MLP1は72通りのパラメータセットを持つことになる．</subsubsection>
  <subsubsection title="ベースライン">MLPとSVMに加え，用例に基づく手法をベースラインとして比較実験に加えた．これは，評価データを学習データの一つひとつと比較し，共通する単語のもっとも多い，または共通する単語数をその評価データの単語数で正規化した値がもっとも大きい学習データのラベルを評価データのラベルとする方法である．ここで両者をそれぞれBaseline1とBaseline2と呼ぶ．図~は本手法および本手法による予測結果の正解率算出のアルゴリズムを示す．ただし，カウントに用いる単語は2.4節で述べた(1)〜(4)の手順に従って説明文書から抽出されたものである．</subsubsection>
  <subsection title="実験結果"/>
  <subsubsection title="182次元の特徴ベクトルを使用した場合">図~は各機械学習において，異なる学習データセットを用いた場合の評価データへの予測精度を示す．ここでの精度は，各パラメータセットの交差検証誤差を昇順（小さい順）に並べたときの上位N個（ただしNは5から30まで可変）のパラメータセットを用いた場合の平均精度である．なお，本論文に用いられている平均精度はすべてマクロ平均で算出したものである．図に示しているように，全般的に見れば，学習データセットa2400p2400を用いた場合（逆三角形マークの点線），すなわち手動収集データに自動収集データと疑似データの両方を最も多く加えた場合，DBNとMLPは最高の精度，そしてSVMもほぼ最高の精度を出している．また，手動収集データに自動収集データと疑似データの両方を適度に加えた場合（点線）は，手動収集データのみの場合（星マークの太線）に比べ，DBNとMLPとSVM(RBF)の予測精度はおおむね向上している．しかしSVM(Linear)についてはそのような傾向は見られなかった．さらに，手動収集データのみを用いた場合と，自動収集データと疑似データのどちらか一方のみを手動収集データに加えた場合について比べると，DBNとSVM(RBF)については自動収集データのみを加えた場合（実線），MLPについては疑似データのみを加えた場合（破線）のほうがそれぞれに精度の向上が見られた．自動収集データのほうが疑似データよりもノイズが多いことから，上記結果はDBNとSVM(RBF)のほうがMLPよりもノイズの多い学習データを有効利用できる可能性が高いことを示している．図~は各機械学習間の評価データへの予測精度の比較を示す．ここでの精度は図~と同様，各パラメータセットの交差検証誤差を昇順に並べたときの上位N個（ただしNは5から30まで可変）のパラメータセットを用いた場合の平均精度である．学習データセットも図~のとまったく同じであるがそれらの詳細の明示は省略されている．ただし，各グラフの縦軸の範囲が統一されているため，グラフDBNvs.SVM(RBF)において，SVM(RBF)の精度が0.9未満なもの（計4本の線）が表示されていない（なお，すべての結果は図~には示されている）．この図からはDBNのほう（実線）が他の機械学習（破線）より性能がよいことが一目瞭然にわかる．表~，，，はそれぞれ，各学習データセットを用いた場合の，ベースラインの予測精度，交差検証誤差が最小のパラメータセットを用いた場合の予測精度，交差検証誤差を昇順に並べたときの上位5個，10個のパラメータセットを用いた場合の平均予測精度を示す．まず，機械学習とは対照的に，ベースライン手法では，ノイズの多い学習データを加えても（つまり，手動収集データに自動収集データのみを加えた場合と，自動収集データと疑似データの両方を加えた場合），予測精度の向上に役立たないばかりか，逆に，これらのデータは予測精度を大きく下げてしまった．次に，ほとんどの場合において，ベースラインの予測精度は機械学習のそれよりかなり低かった．また，ほとんどの場合において，DBNがすべての機械学習において最高の予測精度を出している（各学習セットにおいて各機械学習手法中の最高の精度は太字で表されている）．</subsubsection>
  <subsubsection title="223次元の特徴ベクトルを使用した場合">前節の実験結果はすでに提案手法の予測精度が従来の機械学習手法より高いことを示しただけでなく，学習データにおけるノイズに対する頑健性もある程度示せたと考える．しかし上記実験では，手動学習データのラベル間の重複単語を除外していたため，疑似データの作成時はそれらをノイズとして加えることができず，提案手法のノイズへの頑健性に疑問が残る．本節の実験は，2ラベル間の重複単語を残しているため，前節の実験よりも，より適切にノイズの頑健性を確認できると考える．図~は図~と同様，各機械学習において，異なる学習データセットを用いた場合の評価データへの予測精度を示す．DBNのグラフにおいて，すべての点線と2本の実線が星マークの太線（つまり手動データ）の上にあること，また，SVM(RBF)においてすべての点線と実線が星マークの太線の上にあることから，前の実験結果と同様，DBNとSVM(RBF)については疑似データを含めたノイズのある学習データの利用が有効であることが確認できる．一方，MLPとSVM(Linear)については，手動データの星マークの太線がほとんど一番上に位置していることから，疑似データを含めたノイズのある学習データの有効性がほとんど見られない．すなわち，MLPとSVM(Linear)のノイズに対する頑健性については，前節の実験結果よりも悪い結果となった（逆にDBNの優位性がより顕著になったとも言える）．なお，182次元の特徴ベクトルを用いた実験結果ではa2400p2400を用いた場合（逆三角形マークの点線），すなわち手動収集データに自動収集データと疑似データの両方を最も多く加えた場合，DBNが最高の精度を出しているのに対し，本実験結果ではDBNはa600p600を用いた場合（正三角形マークの点線）に最高の精度を出している．これは，精度の高いデータに対し，加えてよいノイズのあるデータについては適正の数があるはずで，次元数が増えると個々の特徴ベクトルの本来のノイズの度合いが増強したため，ノイズデータの適正数が減少したと考えることができ，両者の結果は矛盾しないと思われる．</subsubsection>
  <subsubsection title="有意差検定">交差検証誤差が最小のパラメータセットを用いた場合と，交差検証誤差を昇順に並べたときの上位10個のパラメータセットを用いた場合について，DBNと他の手法との性能の有意差検定を行った．交差検証誤差が最小のパラメータセットを用いた場合，各学習データセットについて単独で検定を行うとデータ数が少なすぎるため，各学習データセットの結果を1つにまとめて符号検定とt検定を行った．一方，交差検証誤差上位10個のパラメータセットを用いた場合は各学習データセットについて単独でt検定を行った．検定結果を表~，に示す．これらの結果から，182次元と223次元の特徴ベクトルのいずれを用いても，多数の場合においてDBNが他の手法より有意に優れていることが確認できる．また，詳細をみると，たとえばa2400p2400の学習データセットについては182次元の特徴ベクトルを，a600p600/a1200p1200の学習データセットについては223次元の特徴ベクトルを用いたほうが有意差が顕著であることがわかり，特徴ベクトルの構成方法について，DBNと他の手法との性能差の観点からどれが一番よいかは一概に断言することができない．最後に，参考として，各手法のラベル（検索語）ごとの予測精度（表~）と，交差検証誤差が最小のパラメータセット（表~）を示しておく．表~から，182次元の「PCケース」を除き各ラベルへの予測精度にばらつきが小さいことがわかる．また，全般的にDBNのほうがほかの手法より各ラベルに対する予測精度がよいことがわかる．さらに，たとえばDBNの予測精度は182次元の場合のほうが10個中の6個のラベルについて223次元の場合に勝っており，182次元と223次元のどちらのほうがよいかが一概に言えないことがわかる．表~には，隠れ層のユニット数が182次元で273，223次元で335が多く出現しており，隠れ層のユニット数は多いほうがよいというBengioの提言と合致している．</subsubsection>
  <section title="本課題の意義について">本研究では特定の分野の関連語・周辺語または説明文書を入力としたときの検索用語の予測・提示を行う検索支援を想定している．まず，説明文書による支援の意義は，たとえばThe5thNTCIRWorkshopMeetingonEvaluationofInformationAccessTechnologies:InformationRetrieval,QuestionAnsweringandCross-LingualInformationAccessのようなワークショップ型共同研究における長い文書を検索課題としたタスクからも類推できる．つまり，たとえばユーザが関連語・周辺語もはっきりわからないときはその支援要求を文書の形で伝える（入力する）ニーズはあると考える．また一方，当然のことではあるが，本研究では，少数キーワード（関連語・周辺語）による検索用語の予測も期待している．実際，表~は，DBNについて，各学習データセットを用いた場合の，表~に示す3関連語・周辺語（+1ノイズ語）による全検索用語の平均予測精度を示している．実験はまだ小規模ではあるが，この結果は提案手法が少数キーワードによる支援も可能であることを示唆していると思われる．</section>
  <section title="結び">本稿では深層学習の代表的な手法であるDeepBeliefNetwork(DBN)を用いて関連語・周辺語またはそれらの語から構成される説明文書から適切な検索用語を予測する手法を提案した．DBNの有効性を確認するために，用例に基づくベースライン手法，多層パーセプトロン(MLP)，およびサポートベクトルマシン(SVM)との比較を行った．学習と評価に用いるデータは手動と自動の2通りの方法でインターネットから収集した．加えて，自動生成した疑似データも用いた．各種機械学習の最適なパラメータはグリッドサーチと交差検証を行うことにより決めた．実験の結果，DBNの予測精度はベースライン手法よりはるかに高くMLPとSVMのいずれよりも高かった．また，手動収集データに自動収集のデータと疑似データを加えて学習することにより予測精度は向上した．さらに，よりノイズの多い学習データを加えてもDBNの予測精度はさらに向上した．しかしながらこの場合MLPの精度向上は見られなかった．このことから，DBNのほうがMLPよりもノイズの多い学習データを有効利用できることが分かった．なお，まだ少数の実験例しかなかったが，提案手法が少数キーワードによる支援も可能であることを示唆した実験結果も得られた．今後はより大規模な評価実験を通じ，提案手法の有効性の確認を行うとともに，様々な分野における実用的な検索用語の予測システムを構築していく予定である．</section>
</root>
