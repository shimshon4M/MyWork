<?xml version="1.0" ?>
<root>
  <jtitle>クラスタリングを利用した語義曖昧性解消の誤り原因のタイプ分け</jtitle>
  <jauthor>新納浩幸村田真樹白井清昭福本文代	藤田早苗佐々木稔古宮嘉那子乾孝司</jauthor>
  <jabstract>語義曖昧性解消の誤り分析を行う場合，まずどのような原因からその誤りが生じているかを調べ，誤りの原因を分類しておくことが一般的である．この分類のために，分析対象データに対して分析者7人が独自に設定した誤り原因のタイプを付与したが，各自の分析結果はかなり異なり，それらを議論によって統合することは負荷の高い作業であった．そこでクラスタリングを利用してある程度機械的にそれらを統合することを試み，最終的に9種類の誤り原因として統合した．この9種類の中の主要な3つの誤り原因により，語義曖昧性解消の誤りの9割が生じていることが判明した．またタイプ分類間の類似度を定義することで，統合した誤り原因のタイプ分類が，各自の分析結果を代表していることを示した．また統合した誤り原因のタイプ分類と各自の誤り原因のタイプ分類を比較し，ここで得られた誤り原因のタイプ分類が標準的であることも示した．</jabstract>
  <jkeywords>語義曖昧性解消，誤り分析，クラスタリング</jkeywords>
  <section title="はじめに">ProjectNextNLPは自然言語処理(NLP)の様々なタスクの横断的な誤り分析により，今後のNLPで必要となる技術を明らかにしようとするプロジェクトである．プロジェクトでは誤り分析の対象のタスクが18個設定され，「語義曖昧性解消」はその中の1つである．プロジェクトではタスク毎にチームが形成され，チーム単位でタスクの誤り分析を行った．本論文では，我々のチーム（「語義曖昧性解消」のチーム）で行われた語義曖昧性解消の誤り分析について述べる．特に，誤り分析の初期の段階で必要となる誤り原因のタイプ分けに対して，我々がとったアプローチと作成できた誤り原因のタイプ分類について述べる．なお本論文では複数の誤り原因が同じと考えられる事例をグループ化し，各グループにタイプ名を付ける処理を「誤り原因のタイプ分け」と呼び，その結果作成できたタイプ名の一覧を「誤り原因のタイプ分類」と呼ぶことにする．誤り分析を行う場合，(1)分析対象のデータを定める，(2)その分析対象データを各人が分析する，(3)各人の分析結果を統合し，各人が同意できる誤り原因のタイプ分類を作成する，という手順が必要である．我々もこの手順で誤り分析を行ったが，各人の分析結果を統合することが予想以上に負荷の高い作業であった．統合作業では分析対象の誤り事例一つ一つに対して，各分析者が与えた誤り原因を持ち寄って議論し，統合版の誤り原因を決定しなければならない．しかし，誤りの原因は一意に特定できるものではなく，しかもそれを各自が独自の視点でタイプ分けしているため，名称や意味がばらばらな誤り原因が持ち寄られてしまい議論がなかなか収束しないためであった．そこで我々は「各人が同意できる誤り原因のタイプ分類」を各分析者のどの誤り原因のタイプ分類とも類似している誤り原因のタイプ分類であると考え，この統合をある程度機械的に行うために，各自が設定した誤り原因をクラスタリングすることを試みた．また，本論文では「各分析者のどのタイプ分類とも類似している」ことに対し，「代表」という用語を用いることにした．つまり，我々が設定した目標は「各分析者の誤り原因のタイプ分類を代表する誤り原因のタイプ分類の作成」である．クラスタリングを行っても，目標とするタイプ分類を自動で作成できるわけではないが，ある程度共通している誤り原因を特定でき，それらを元にクラスタリング結果を調整することで目標とする誤り原因のタイプ分類が作成できると考えた．具体的には，各自の設定した誤り原因を対応する事例を用いてベクトル化し，それらのクラスタリングを行った．そのクラスタリング結果から統合版の誤り原因を設定し，クラスタリング結果の微調整によって最終的に9種類の誤り原因を持つ統合版の誤り原因のタイプ分類を作成した．この9種類の中の主要な3つの誤り原因により，語義曖昧性解消の誤りの9割が生じていることが判明した．考察では誤り原因のタイプ分類間の類似度を定義することで，各分析者の作成した誤り原因のタイプ分類と統合して作成した誤り原因のタイプ分類が，各分析者の視点から似ていることを確認した．これは作成した誤り原因のタイプ分類が分析者7名のタイプ分類を代表していることを示している．また統合した誤り原因のタイプ分類と各自の誤り原因のタイプ分類を比較し，ここで得られた誤り原因のタイプ分類が標準的であることも示した．</section>
  <section title="分析対象データ">誤り分析用のデータはSemEval-2の日本語WSDタスクから作成した．SemEval-2のデータは対象単語が50単語あり，各対象単語に対して50個の訓練用例と50個のテスト用例が存在する．また用例中の対象語には岩波国語辞典の語義が付与されている．つまり語義識別のラベルは岩波国語辞典の語義である．まずSemEval-2のコンペの際にbaselineとされたシステムを構築した．以降，本論文ではこのシステムを「分析用システム」と呼ぶ．学習アルゴリズムはSVMであり，以下の20種類の特徴量を利用する．e1=二つ前の単語表記,e2=二つ前の品詞,e3=その細分類,e4=一つ前の単語表記,e5=一つ前の品詞,e6=その細分類,e7=対象単語の表記,e8=対象単語の品詞,e9=その細分類,e10=一つ後の単語表記,e11=一つ後の品詞,e12=その細分類,e13=二つ後の単語,e14=二つ後の品詞,e15=その細分類,e16=係り受け,e17=二つ前の分類語彙表の値（5桁）,e18=一つ前の分類語彙表の値（5桁）,e19=一つ後の分類語彙表の値（5桁）,e20=二つ後の分類語彙表の値（5桁）verbatimシステムは分類語彙表IDの4桁と5桁を同時に使う形になっていたが，分析用システムでは5桁のみとした．また一般に一つの単語に対しては複数の分類語彙表IDが存在するので，|e17,e18,e19,e20|に対する素性は複数になる場合もある．例として，以下の用例（「息子とその婚約者に会っていこうかと考えた」）に対する素性リストを示す．対象単語は記号(*)のついた「あう」である．&lt;sentence&gt;・・・&lt;morpos=&quot;名詞-普通名詞-一般&quot;rd=&quot;ムスコ&quot;&gt;息子&lt;/mor&gt;&lt;morpos=&quot;助詞-格助詞&quot;rd=&quot;ト&quot;&gt;と&lt;/mor&gt;&lt;morpos=&quot;連体詞&quot;rd=&quot;ソノ&quot;&gt;その&lt;/mor&gt;&lt;morpos=&quot;名詞-普通名詞-サ変可能&quot;rd=&quot;コンヤク&quot;&gt;婚約&lt;/mor&gt;&lt;morpos=&quot;接尾辞-名詞的-一般&quot;rd=&quot;シャ&quot;&gt;者&lt;/mor&gt;&lt;morpos=&quot;助詞-格助詞&quot;rd=&quot;ニ&quot;&gt;に&lt;/mor&gt;&lt;morpos=&quot;動詞-一般&quot;rd=&quot;アッ&quot;bfm=&quot;アウ&quot;sense=&quot;166-0-2-1-0&quot;&gt;会っ&lt;/mor&gt;(*)&lt;morpos=&quot;助詞-接続助詞&quot;rd=&quot;テ&quot;&gt;て&lt;/mor&gt;&lt;morpos=&quot;動詞-非自立可能&quot;rd=&quot;イコー&quot;bfm=&quot;イク&quot;&gt;いこう&lt;/mor&gt;&lt;morpos=&quot;助詞-終助詞&quot;rd=&quot;カ&quot;&gt;か&lt;/mor&gt;&lt;morpos=&quot;助詞-格助詞&quot;rd=&quot;ト&quot;&gt;と&lt;/mor&gt;&lt;morpos=&quot;動詞-一般&quot;rd=&quot;カンガエ&quot;bfm=&quot;カンガエル&quot;sense=&quot;9590-0-0-1-0&quot;&gt;考え&lt;/mor&gt;&lt;morpos=&quot;助動詞&quot;rd=&quot;タ&quot;bfm=&quot;タ&quot;&gt;た&lt;/mor&gt;・・・&lt;/sentence&gt;verbatimscreen対象単語の一つ前の単語表記は「に」なので，|`e4=に'|となる．この単語の品詞情報から|`e5=助詞'|，|`e6=格助詞'|となる．同様にして|e1|から|e15|が設定できる．また用例はCaboChaにより係り受けの解析がなされ，対象単語を含む文節の最も近い係先の単語の原形が|e16|に設定される．この場合は|`e16=いく'|となる．次に二つ前の単語「者」に対する分類語彙表IDは|1.1000,7,1,2|と|1.2020,1,1,4|であり．前者から上位5桁を取ると|11000|となり，後者から上位5桁を取ると|12020|となる．そのため|e17|は|`e17=11000'|と|`e17=12020'|の2つが設定される．一つ前の単語「に」と一つ後の単語「て」は助詞なので分類語彙表IDは無視する．二つ後の単語「いこう」に対する分類語彙表IDは|2.3000,6A,2,1|と|2.3320,5,1,2|から|`e20=23000'|と|`e20=23320'|が設定される．以上より，上記用例の素性リストは以下となる．(e1=者,e2=接尾辞,e3=名詞的,e4=に,e5=助詞,e6=格助詞,e7=会っ,e8=動詞,e9=一般,e10=て,e11=助詞,e12=接続助詞,e13=いこう,e14=動詞,e15=非自立可能,e16=いく,e17=11000,e17=12020,e20=23000,e20=23320)verbatim「あう」の訓練データの50用例を全て素性リストに直し，その要素の異なり数Nを次元数としたN次元ベクトルを設定する．訓練データとテストデータの用例を素性リストに変換し，N次元ベクトルのi次元目に対応する要素が存在すればi次元の値を1に，存在しなければ0とすることで，その素性リストは素性ベクトルに変換できる．この素性ベクトルを利用してSVMによる学習と識別が可能となる．SVMの学習はlibsvmcjlin/libsvm/の線形カーネルを用いた．指定できるパラメータは全てdefaultのままである．SVMにより識別した結果，テスト事例2,500のうち，誤りは577事例であった．ここから新語義と未出現語義の事例を除くと543事例となった．ここからランダムに50個の事例を選出し，この50事例を誤り分析の対象事例とした．この50事例は付録1に記した．</section>
  <section title="各人の分析結果">前述した50事例の分析対象データに対して，我々のチームのメンバーの内7名（村田，白井，福本，新納，藤田，佐々木，古宮）が独自に誤り分析を行った．分析結果として，各人は分析対象の50事例に対して，各自が設定した誤り原因の記号をつけた．表がその結果である．各自の記号の意味やどのような観点で分析したかを以下に述べる．</section>
  <subsection title="村田の分析：解き方に着目">採用した誤り分析の考え方・方法論について述べる．普遍的な誤り分析を目指して，以下の誤り分析のフレームワークを用いる．誤り事例を人手で考察し，人ならそれを正しく解くにはどう解くかを考えて，その事例の解析に有効な特徴（解き方）を見つける．その特徴が学習データにあるかを確認する．誤り分析の際には，正解に至るまでの誤り原因をすべて網羅して調べる．これは，複数の誤り原因が存在する場合があり，一つの原因だけを見つけるのでは誤り分析としては不十分な場合があるためである．具体的な誤り分析の手順は以下のとおりである．まず，各事例の対象単語の品詞を調べる．次に，品詞を参考にして各事例の解き方を調べる．最後に，解き方を参考にして各事例の誤り原因を調べる．以降，以上の方法論・手順に基づき行った調査結果について述べる．まず各事例の対象単語の品詞を調べた．品詞の出現数を表に示す．表の「記号」の列はその品詞のデータに付与した記号である．次に各事例の解き方を調べた．解き方はある程度対象語の品詞に依存する．このため対象語の品詞を考慮しながら，解き方を考える．各事例に解き方のタグを付与する．解き方（解析に有効な特徴）の出現数を表に示す．表の「記号」の列は，実際に事例に付与したタグの記号である．タグは一つの事例に複数重複してふられる場合がある．「解き方未判定」は，難しい事例で解き方が思いつかなかったものである．「文パターン」は，例えば「対象語の直前に『て』がある文パターンの場合語義Xになる」という説明が辞書にある場合があり，そのような文パターンを利用して解く方法である．「表現自身」は，例えば「対象語において漢字Xを使う場合は語義Yになる」という説明が辞書にある場合がありそのような情報を利用して解く方法である．次に各事例の誤り原因を調べた．各事例で付与した解き方のタグを参考にして，誤り原因を調べた．誤り原因の出現数を表に示す．表の「記号」の列は，実際に事例に付与したタグの記号である．タグは一つの事例に複数重複してふられる場合がある．表の「分析が困難」は，分析が困難で分析を行っていないものを意味する．より綿密な作業により分析ができる可能性がある．「シソーラスの不備」は，シソーラスの不備の他，シソーラスでの多義性の解消が必要な場合を含む．「素性も学習データもあるのに解けていない」は，解くときに役立つ素性も存在し，その素性を持つ学習データもあるのに解けていない場合である．その素性を持つ学習データの事例数が少ないか，他の素性や学習データが悪さをした可能性がある．「格解析が必要」は，能動文，受け身文，連体などの正規化や，格の把握が必要な場合である．「入力文の情報が少なすぎる」は，入力文だけでは文が短く，その文だけでは語義識別ができない場合である．前後の文など，より広範囲の文脈の情報の入力が必要な場合である．解き方の分類に基づき，いくつか誤り分析の事例を示す．「格に取る名詞（対象語が用言の場合）」が解き方の場合を示す．対象語が用言の場合，格に取る名詞が語義識別に役立つ表現となりやすい．格に取る名詞を中心に眺めて誤り分析を行う．事例ID3の誤り事例を考察する．対象文は「…悲鳴をあげながら…」で，対象単語は「あげる」である．動詞「あげる」の格になっている「悲鳴」が語義識別に役立つ個所となる．現在のデータでは対象データの「悲鳴」が分類語彙表の情報を持たない．他のバージョンの分類語彙表には「悲鳴」の情報がある．「悲鳴」の類似事例「声」が多数学習データにある．シソーラスの情報をよりよく利用することで改善できる事例である．誤りの分類としては，「t:シソーラスの不備」を与えている．意味ソートを使うと，学習データに類似事例があるかどうかを簡明に知ることができる．「悲鳴」が存在する分類語彙表を利用して意味ソートを行った．意味ソートとは，単語群を分類語彙表の意味の順に並べる技術である．「あげる」の学習データにおいて，「あげる」のヲ格の単語を取り出し，その単語の意味ソートを行った．注目している単語「悲鳴」の近くの単語群での意味ソート結果は「13030010201:顔(545-0-1-1),13031010101:声(545-0-1-2),13031021203:歓声(545-0-1-2),13031050102:叫び声(545-0-1-2),13031050304:悲鳴＊(545-0-1-2),13041060106:顔(545-0-1-1),13061110102:声(545-0-1-2)」である．単語の後ろの括弧にはその単語を含むデータの文の分類先を示し，単語の前の数字はその単語の分類語彙表の番号である．今解析している単語には「＊」の記号を付与している．意味ソートの結果では，「叫び声」が類似事例としてあることがすぐにわかる．「共起語（主に対象語が名詞の場合）」が解き方の場合を示す．対象語が名詞の場合，同一文の共起語が語義識別に役立つ表現となりやすい．同一文には共起語が多く存在するため，この場合の誤り分析は基本的に困難である．事例ID14の誤り事例を考察する．対象文は，「…事件で、鶴見署は二十一日現場で…」であり，対象単語は「現場」である．対象単語は名詞であるので，共起語が役立ちやすく，この例では，「事件」「署」が語義識別に役立つ．今の素性では対象単語の前方2形態素，後方2形態素しか素性に用いておらず，同一文の単語すべては素性に使っていない．今の素性では，「事件」「署」が使えない．共起語の素性を使えるように素性を拡張する必要がある．学習データを見たところ，共起語が重なる事例がなさそうであり，学習データ不足の問題もあるようだった．この事例には，誤りの分類としては，「f:素性の種類の不足」「d:学習データの不足」を与えている．「言い換え」が解き方の場合を示す．事例ID7の誤り事例を考察する．対象文は，「…自己防衛の意味でも…」であり，対象単語は「意味」である．正解語義は「表現や行為の意図・動機。」であり，システム出力の誤り語義は，「その言葉の表す内容。意義。」である．対象語の「意味」を「動機」に言い換えることが可能であることを認識できれば，正解語義「表現や行為の意図・動機。」と推定できるようになると思われる．この事例には，誤りの分類としては，「p:言い換え技術が必要」を与えている．</subsection>
  <subsection title="白井の分析：機械学習の素性の問題を中心に">まず，誤り分析の考え方について述べる．特に着目したのは機械学習の素性の問題である．テスト文から抽出された素性に不適切なものがないか，テスト文の素性と同じものが訓練データに出現するか，有力な手がかりとなる情報で素性として表現できていないものはないか，といった観点から分析を進めた．それ以外にも誤り原因と考えられるものは全て洗い出した．誤り原因のタイプ分類を図に示す．大きくは手法の問題，前処理の問題，知識の問題，データの不備，問題設定の不備に分類し，これらをさらに細かく分類した．図中の()はそれぞれの要因に該当する誤り事例の数，[]は分析対象とした50事例に占める割合である．枠内の数字は付録2に記載されている誤り原因IDに対応する．【手法の問題】は機械学習手法に関する問題が見つかった事例である．【訓練データの不足】は，他に手がかりとなる情報がある場合と，テスト文に類似した事例が訓練データにないと語義を識別しようがない場合（【他に手がかりなし】）に分けた．後者の多くは定型的な言い回しで語義が決まる事例である．例えば，「指揮を*とる*」は決まり文句に近く，この文が訓練データにないと「とる」の語義を決めるのは難しい．【素性抽出が不適切】は表のような文の正規化をした上で素性を抽出するべき事例である．【有効な素性の不足】は，語義曖昧性解消の手がかりとなる情報が素性として利用されていない場合である．分析用システムでは最小限の素性しか使用していないため，トピック素性（スポーツや事件といったトピックの文内に出現するということで語義が決まる事例があった），文脈中の自立語，構文素性など，先行研究で既に使われている素性の不足も分類されている．また，【長いコロケーション】とは，分析用システムでは前後2単語を素性としていたが，対象語からの距離が3以上の単語で語義が決まる場合である．【素性のコーディングが困難】とは，語義を決める手がかりは発見できたが，高度な言語処理や推論を必要とし，機械学習の素性として表現することが難しい事例である．文の深い解釈が必要な場合（【文の解釈】）と文章全体の解釈が必要な場合（【文脈の解釈】）に分けた．【学習アルゴリズムの問題】とは，語義曖昧性解消に必要な素性は抽出できていて，類似用例も訓練データに存在するが，SVMで学習された分類器では正解を選択できなかった事例である．他の機械学習アルゴリズムなら正しく解ける可能性がある．【消去法】とは，該当しない語義を除外することで正解の語義がわかる事例を指す．例えば「かえって医師の処方を経ないで入手できる*市場*が生じている」という文での「市場」は，21128-0-0-1の意味（野菜などを得る市場）でもなければ21128-0-0-3の意味（株式市場）でもないことから，21128-0-0-2の意味（売行き先）とわかる．このような事例は教師あり学習とは別の枠組で解く必要があるかも知れない．【前処理の問題】は前処理の誤りに起因する事例である．【知識の問題】は外部知識の不備が誤りの原因となっているものである．【データの不備】はタグ付けされた語義の誤りである．【問題設定の不備】に分類したのは，対象語の解析対象文における品詞と辞書見出しにおける品詞が一致せず，そもそも対象語として不適切であった事例である．今回の分析では上記は少数の事例しか該当しなかったが，多くの外部知識を用いたり，文節の係り受け解析など多くの前処理を必要とするシステムでは，これらの原因ももっと細かく分類する必要があるだろう．教師あり学習に基づく手法を用いるという前提で，今後語義曖昧性解消の正解率を向上させるには，【訓練データの不足—他に手がかりなし】に分類した事例が多いことから，訓練データを自動的または半自動的に拡充するアプローチが有望である．また，【素性抽出が不適切】や【有効な素性の不足】で考察した問題点に対応することも考えられる．ただし，表に示すような正規化の処理を導入しても誤った解析結果が得られたり，単純に素性を追加しても素性数が多すぎて過学習を引き起こすなど，単純な対応だけでは語義曖昧性解消の正解率の向上に結びつかない可能性もあり，深い研究が必要であろう．また，【素性のコーティングが困難】に分類した事例は，現時点での言語処理技術では対応が難しい事例だが，誤り原因の20%程度を占めており，軽視できない．これらの事例に対応することは，チャレンジングではあるが，必要であると考える．</subsection>
  <subsection title="福本の分析：解消に必要となる知識・処理に着目">語義曖昧性解消に必要となる知識に着目し，分析対象の50事例について誤りの原因を分析した．まず，語義識別に必要となる知識が(1)語義曖昧性解消タスク内か，(2)語義曖昧性解消タスク外かで大別した．さらに(2)語義曖昧性解消タスク外については，語義曖昧性解消の前処理として必要となる形態素解析など，他の言語処理タスクで得られる知識にも着目し，それらに関する影響の有無を調査した．誤り原因のタイプ分類を以下に示す．括弧は各誤り原因に該当する事例数とその割合（(1)と(2)での割合，及び各詳細項目での割合）を示す．また，``*''で囲まれた単語は語義識別の対象単語を示す．語義曖昧性解消タスク内の問題（40事例，80%）語義の記載がない．（1事例，2.5%）「くもりを*取る*」というテスト事例において，「くもり」に関する語義情報が分類語彙表に存在しないため，「くもり」と「取る」での共起による語義識別が難しく，「取る」が訓練事例数の多い語義に識別されている.テスト事例と類似した事例が，訓練事例中に存在しない．（11事例，27.5%）訓練事例不足の問題である．例えば「見せて*あげる*事ですね。」のように，動詞連用形+「て」と「あげる」のパターンが訓練事例中に存在していないために，誤って識別されている．テスト事例の語義が，訓練事例中では低頻度で出現している．（4事例，10%）語義の分布に片寄りがあるものの，対象としているテスト事例中の語義の特徴と高頻出の語義が持つ特徴との区別が困難であるために，低頻出の語義であるテスト事例の語義が正しく識別できない．例えば「私の*場所*だ!」であるテスト事例が該当し，「ところ．場」の意味の訓練事例は49事例，正解語義である「居るところ」は1事例であるために，「ところ．場」に誤って識別されている.解消に必要な情報が欠如している．（10事例，25%）この誤り原因に相当する事例として，例えばテスト事例「*相手*をすべて倒した」において，「倒した」（行為）の対象が「*相手*」（人）であることから，共起関係を利用することにより「*相手*」が「自分と対抗して物事を争う人」に識別可能である．しかし語義の前後2単語というウィンドウサイズの制限により，識別に必要な「倒した」に関する情報（素性）が欠如している．語義同士の意味が互いに類似しているために，識別が非常に難しい．（14事例，35%）この誤りは，誤り原因の中で最も多くの事例が相当した誤りである．「発音を*教え*てください。」などのように，「*教え*」が「知識や技能を身につけるように導く」という語義か，正解である「自分の知っていることを告げ示す」か，両者の語義が類似しているために識別が難しい.語義曖昧性解消タスク外の問題（10事例，20%）形態（語義を含む）．（7事例）形態素解析における品詞推定誤り．（2事例，20%）識別の対象単語と共起して出現する単語の品詞が誤って識別されているために，品詞，及び共起関係の情報が利用できないという問題である．例えば，ひらがな表記の「神のみ*まへ*の」において形態素解析において「御前」と認識されていない.テスト事例の単語について，その同義語・類義語に関する情報が辞書に掲載されていない．（3事例，30%）この誤りは，例えば「悲鳴を*あげ*ながら」というテスト事例において，訓練事例中に存在する「歓声」が「悲鳴」と意味的に類似していることが分類語彙表に記載されていれば，「悲鳴」と「あげる」との共起関係により識別が可能であると考えられる.識別の対象となっている単語と共起している単語に曖昧さが存在している．（1事例，10%）例えば「レベリングは*技術*がいる」というテスト事例において，「技術」と共起関係にある「いる」は「必要である」という語義と「豆などを煎る」という語義が存在する．分類語彙表の情報として「豆などを煎る」が素性としてテスト事例に付与されているため，共起の語彙情報を利用することができない．慣用句表現の認識（1事例，10%）「めどが*立つ*。」が相当する．識別の対象となっている単語を慣用句表現として認識する必要がある.構文（1事例，10%）複合名詞の認識「国際*電話*」の事例のように，複合名詞が正しく認識されず，識別の対象単語である「*電話*」が複合名詞の一部として出現している．文脈（2事例，20%）省略語の補完例えば「*開い*たときに請求書ご案内が上に来るように入れます。」のように，対象単語である「開く」の主語が省略されているため，共起関係など，語義識別に必要な情報が利用できない．語義曖昧性解消タスク内の誤り原因に相当する事例は40事例であり,タスク外の事例は10事例であったことから，誤りの多くは語義曖昧性解消の処理方法に問題があると考えられる．語義曖昧性解消内の誤り原因のうちの6事例は，既存の学習手法や統計手法の工夫により語義を正しく識別できた．一方，例えば上述した(1)における(e)の「*教え*てください」や，「島がびっしょり濡れているようにさえ*見え*た」における「見え」が(a)「目にうつる」，(b)「そう感じ取れる」において，(a)と識別するために必要となる素性が何かを明かにすることが難しい事例も存在した．文内に限定した語彙・語義情報を用いた手法の限界であり，今後は文外に存在する情報，例えば分野に依存した主要語義に関する情報とも組み合わせることにより，語義曖昧性解消を行う方法なども考えられる．今後のさらなる調査と検討が必要である．</subsection>
  <subsection title="新納の分析：手法の問題の機械的排除">採用した誤り分析の考え方・方法論について述べる．基本的に，自身の誤り原因のタイプ分類を作成し，分析対象の各誤り事例に設定した誤り原因のタイプを付与した．特徴としては「手法の問題」という誤り原因を設定したことである．ここでの分析対象のデータはSVMを利用した場合の誤りである．SVMを利用したために生じる誤りは分析の重要度が低いと考えた．そこでSVM以外の他の学習手法を試し，SVM以外の2つ以上の学習手法で正解となるような（SVMでの）誤りの事例の誤り原因を「手法の問題」として機械的に取り除いた．残された誤り事例に対してのみ，その誤り原因を精査するアプローチを取った．設定した誤りの原因は，まず(1)手法の問題，であり，それ以外に(2)意味の問題，(3)知識の問題，及び(4)領域の問題，の計4タイプの誤り原因を設けた．(2)，(3)，(4)については更に詳細化した．以下各タイプがどのような誤りかと，それをどのように判定したかを述べる．</subsection>
  <subsubsection title="手法の問題">分析対象のデータは，学習手法としてSVMを使った場合の誤りであり，他の手法を用いた場合には誤りにならないこともある．ここでは最大エントロピー法(ME)，NaiveBayes法(NB)，決定リスト(DL)，及び最大頻度語義(MFS)の4つを試した．まず各手法のSemEval-2のデータに対する正解率をに示す．SVMが最も正解率が高いが，他の手法の正解の事例を完全にカバーしているわけでない．に正解の事例の差分を示す．は行が誤りを，列が正解を表している．例えば行（），列（）の要素は98であるが，これはNBで誤りであった事例のうちMEでは正解であった事例数が98存在したことを意味する．から分かるように，手法Aが手法Bよりも正解率が高いからといって，必ずしも，手法Bが正解していた事例すべてを手法Aが正しく識別できる訳でない．これは手法を選択した際に生じる副作用であり，誤りの1つの原因であると考えられる．そして，ここではSVMでは誤りだが，他の2つ以上の手法で正解となっていた誤りの事例を「手法の問題」（記号4）と判定した．表はSemEval-2のデータ全体での事例数を示している．2つ以上の手法で正解であった事例の数は198であったが，誤り分析の対象とした50事例に限れば8事例が該当した．これらを「手法の問題」と分類した．</subsubsection>
  <subsubsection title="意味の問題">語義曖昧性解消の問題設定自体に誤りの原因があると考えられるものを「意味の問題」と判定した．この下位分類として(a)辞書の語義が似ていて識別困難（記号1-a），(b)深い意味解析が必要（記号1-b），(c)表現自体からしか識別できない（記号1-c），及び(d)テスト文の問題（記号1-d），の4つを設けた．語義曖昧性解消の問題設定では，対象単語の語義が固定的に与えられる．ある対象単語が持つ複数の語義は，明確に異なる場合もあるが，非常に似ている場合もある．もしある語義s1とs2が非常に似ている場合，それらを区別することは明らかに困難であり，それらを取り違えた誤りの原因は，問題自体の困難性から生じていると考えた．このようなタイプの誤りを「(a)辞書の語義が似ていて識別困難」とした．例えば事例27は対象単語「強い」の語義34522-0-0-1「積極的に働く力にあふれている．」と語義34522-0-0-2「抵抗力に富み，簡単には壊れたりくずれたりしない．」を区別する問題だが，どちらの語義も互いの意味を想起させるため，意味的に非常に似ていると判断した．上記の(a)のタイプであっても深い意味解析が可能であれば解決できるものを「(b)深い意味解析が必要」とした．例えば事例1は対象単語「相手」の語義117-0-0-2「物事をするとき，行為の対象となる人．」と語義117-0-0-3「自分と対抗して物事を争う人．」を区別する問題である．「争う人」も「行為の対象となる人」であることは明かであり，意味的には非常に近く(a)である．ただしその「行為」が「争い」なのかどうかを深い意味解析で判断できれば解決できるため，「(b)深い意味解析が必要」のタイプと判定した．(a)のタイプでかつ(b)であるかどうかは，「深い意味解析」の深さの度合いである．技術的に可能なレベルの深さと思えれば(b)をつけた．次に「(c)表現自体からしか識別できない」のタイプであるが，これは語義曖昧性解消の問題として不適と思えるものである．例えば慣用表現中の単語に語義が存在していると考えるのは不自然である．また語義曖昧性解消の問題では，対象単語が自立語であることは暗黙の了解である．つまり単語の品詞自体が名詞や動詞であっても，その単語が機能語に近いものであれば，語義曖昧性解消の問題として不適と考えられる．このようなタイプの誤りを「(c)表現自体からしか識別できない」とした．例えば事例21の対象単語「する」，事例48の対象単語「やる」を，このタイプの誤りとした．最後に「(d)テスト文の問題」のタイプであるが，これは単純にテスト文に手がかりとなる単語がほとんどないために誤るものである．これは「意味の問題」ではないが，問題設定自体に誤りの原因があると捉え，この範疇に含めた．例えば事例10の「*教え*て下さい．」などがこのタイプの誤りである．</subsubsection>
  <subsubsection title="知識の問題">語義曖昧性解消を教師あり学習により解決するアプローチをとった場合，前述した「手法の問題」「意味の問題」以外の誤りの原因は，システムに何らかの知識が不足していたためと考えられる．そこで「手法の問題」「意味の問題」以外の誤り原因を「知識の問題」と判定した．不足している知識（解決のために必要としている知識）としては，現状のシステムの枠組みから考え，(a)その表現自体が訓練データに必要（記号2-a），(b)周辺単語に同じ単語が必要（記号2-b），及び(c)周辺単語に類似単語が必要（記号2-c），の3つを設定した．例えば事例9の「…待ち伏せて詫びを*入れる*振りをしながら…」の「入れる」の語義の識別には「詫びを入れる」が訓練データに必要と考え，「(a)その表現自体が訓練データに必要」と判定した．また事例30の「…朝日新聞からの国際*電話*に対して…」の「電話」の語義の識別も「国際電話」が訓練データに必要だと考えた．また事例32の「どうすればくもりを*取る*ことが出来ますか？」の「取る」の語義は単語「くもり」が対象単語の周辺に存在することが必要と考え，「(b)周辺単語に同じ単語が必要」と判定した．(a)との差異は少ないが，(a)は慣用表現に近い表現であり，単語間に別の単語が挿入できない，態が変化できない，などの特徴があるが，(b)は「くもりをきれいに取る」や「きれいに取ったくもり」という表現が可能であり，慣用表現とは異なると考えた．また事例45の「…患者はどこの病院でも*診*て貰えない…」の「診る」の語義は対象単語の周辺に「病院」と類似の単語が存在することが必要だと考え，「(c)周辺単語に類似単語が必要」と判定した．</subsubsection>
  <subsubsection title="領域の問題">語義曖昧性解消の誤りは上記までの項目のいずれかに該当すると考えられるが，特殊なケースとして訓練データのコーパス内にはまれにしか出現しない表現が，テストデータとして出現したために生じる誤りが存在する．これは領域適応の問題であり，教師あり学習により問題解決を図った場合に必ず生じる問題である．この原因の誤りを「領域の問題」と判定した（記号3-a）．例えば事例4や事例42はテスト文が古文であり，学習の対象であった領域とは異なっている．このような誤りを「領域の問題」と判定した．</subsubsection>
  <subsection title="藤田の分析： 素性に着目">まず，採用した誤り分析の考え方について述べる．教師あり学習の場合，適切なラベルと素性を得ることができればほぼ正しく識別可能だと考えられる．適切な素性があるにも関わらず誤りになる場合，素性に付与する重みが適切ではないなど，学習器側の問題だと考えることができる．そこで，当初は，適切な素性があるかどうか，あるならば，素性に対する重みの付与などが適切かどうかを調査することを考えた．ただし，そもそも適切な素性が得られていないものが大半だったため，最終的には重みの適切さについての詳細な調査は行わず，素性を増やした場合でも誤りとなる事例について，原因と対処方法について考察した．以下，節では，分析対象の50事例に対して，素性の重なりに着目した分析を示す．さらに，節では，自前の語義曖昧性解消システムを用いて分析対象の50事例の語義識別を行い，そのシステムでも誤りとなった16事例についての詳細な分析結果を示す．最後に~節で，語義曖昧性解消というタスクを考える上で，今後考えるべき問題点について考察する．</subsection>
  <subsubsection title="素性の重なりの調査">まず，分析用システムの出力語義（以下，）と正解語義（以下，）が付与された訓練データから得られる素性と，対象のテスト文から得られる素性の重なりを調査した．例えば，13の場合，対象テスト文の19種類の素性のうち，10種類はとの両方の訓練データに出現し，8種類は両方に出現しない．差がある素性は，1種類（`e17=11950'，2語前の分類語彙表の値）のみであり，これは，の訓練データのみに出現している．つまり，にのみ出現するような特徴的な素性は得られていないことがわかる．の訓練データにだけ存在する（手がかりになる可能性が高い）素性が存在するかどうかに着目すると，分析対象とした50事例のうち，の訓練データにだけ出現する素性があるテスト文は17事例(34%))だった．であり，そうした素性がないテスト文が33事例(66%)を占めた．素性の不足に対応するには，学習データ自体を何らかの方法で増やすか，学習データが変わらない場合には，利用する素性を増やす必要がある．分析用システムでは，与えられた訓練データだけを用いており，利用している素性も比較的少ない．しかし，13の場合でも，同一文中に「ライン」や「経験」など，他に素性として有効そうな語があることから，ウインドウ幅を広げたり，Bag-of-words(BOW)を利用することでも正解となる可能性がある．また，分析用システムでは，辞書の例文を訓練データとして利用していないが，例文は重要な手がかりであり，簡便に追加できる訓練データとなり得る．そこで，次節では，例文などを訓練データに用いた自前のシステム(．以降，このシステムを「藤田のシステム」と呼ぶ．)の結果と比較し，両方で共通する誤り事例に対して，誤り分析を行う．</subsubsection>
  <subsubsection title="共通の誤り事例">まず，の概要を説明する．は，2段階に分けられる．Step-1では，語義が付与されていない生コーパスの中から辞書の例文を含む文を抽出し，ラベルありデータとして自動獲得する．例えば，語義15615-0-0-2の例文「工事現場」を含む文として，例()のような文をラベルありデータとして利用できる．特に人間用の紙の辞書の場合，省スペース化のため，例文は非常に短いことが多い．Step-1では，例文だけをラベルありデータとして追加するより，より長くて情報量の多い文を自動獲得できることが利点である．足場などを組み合わせて建設工事現場や各種工場のラインをつくる。exeStep-2では，ラベルありデータとラベルなしデータを訓練データとして，半教師あり学習法（ハイブリッド法，MaximumHybridLog-likelihoodExpectation:,）を適用する．では，ラベルありデータで学習させたMEモデル（識別モデル）とラベルなしデータで学習させたNBモデル（生成モデル）を統合して分類器を得る．素性は，分析用システムで利用している素性以外に，各語の原形，前後3語以内のbigrams,trigrams,skipbigrams，各対象語と同一文内に出現する全内容語の原形，トピック分類の結果を利用している．ただし，係り受け情報(e16)と分類語彙表の値(e17--e20)は利用していない．もちろん，を利用した場合，正解になるばかりではなく，逆に分析用システムでは正解だったテスト文が不正解になる場合もあるが，本節では両者の共通の誤り事例を取り上げる．分析対象の50事例の内，でも誤った事例は16事例であった．その分析結果を表~に示す．表~から，[A][B]は両手法で解くことは困難だと考えられる．[C][D]は素性の問題だが，[C]の場合は，両手法で採用していない項構造解析(SemanticRoleLabeling,SRL)を正しく行うことができれば，正解となる可能性がある．なお，これらの対象語はすべて動詞であり，動詞のには，SRLが特に重要であることがわかる．ただし，係り受け解析誤りも含まれる誤り事例については，係り受け解析の精度向上により正解できる可能性もある．一方，[D]の場合，利用した素性が不適切だったり，少なすぎたと考えられるので，適切な素性を取り出したり，利用素性を増やすことで正解できる可能性がある．しかしながら，[D]はでも誤りとなっている．[D]の誤り事例について，節と同様，で得られた素性の重なりを調べると，訓練データの追加の場合で3文，そのうちにあたるものは1文，41の場合で57文，そのうちにあたるものは4文だった．とBOW等の利用にも関わらず，少なくともラベルありデータにおいて，にのみ出現した素性はなく，逆ににのみ出現した素性があるという結果だった．なお，両誤り事例とも，の語義は元の訓練データにも，それぞれ1回と4回しか出現しない低頻度語義である．両対象語は，語義の頻度分布のエントロピー(E(w)=-_i^p(s_i|w)p(s_i|w).ここで，p(s_i|w)は，単語wの語義がs_iとなる確率．)による難易度分類では，低難易度の語に分類される．つまり，ある語義が圧倒的に多く出現するため低難易度の語に分類されるが，そうした語の低頻度語義の識別の難しさを示している．</subsubsection>
  <subsubsection title="考察">前節の分析結果をふまえ，重要だと考える点について考察する．まず，従来のの問題設定で今後取り組むべき課題として，以下の項目を上げる．データの質の向上:人手作成データの一貫性の担保が必要．（表~,[A]）素性の追加:特に動詞について，係り受け精度の向上や項構造解析の組み込みが必要．（表~,[C]）ラベルありデータの追加等:特に低頻度語義に対して対処方法の考案が必要．（表~,[D]）また，今後の方向性として，現在のの枠組みにこだわらず，他のタスクでも利用されるには，どういった語義，どういった粒度で識別すべきか検討することが重要だと考える．特に，そもそも人間にとっても識別が困難な語義（表~,[B]）の推定が必要なのか，アプリケーションや領域によって必要とされる語義の粒度や種類が異なるにも関わらず，一律に扱ってよいのかどうか，といった点を考慮すべきだと考えている．</subsubsection>
  <subsection title="佐々木の分析：パターンの差異に着目">まず，ここでの誤り分析の考え方について述べる．注目したのは訓練データから得られるパターンとテスト事例から得られるパターンとの差異である．ここでいうパターンとは対象語の周辺に現れる素性（単語や品詞など）の組み合わせを指している．一般に教師あり学習では，訓練データから得られるパターンの集合とテスト事例から得られるパターンとの比較によって識別処理が行われる．つまり誤りの原因はパターンの差異から生じると考えられる．そして，その差異の原因として以下の2点に注目して誤り分析を行った．訓練データに不足しているパターン訓練データから抽出される不適切なパターン(1)はテスト事例のパターンが訓練事例に含まれないことから生じる誤りに対応する．(2)は識別に有効そうなパターンが訓練事例に存在しているにも関わらず生じている誤りに対応する．(2)は適切なパターンを抽出できていないことが原因だと考えた．作成した誤り原因のタイプ分類を表に示す．分析対象の50事例に表のタイプを付与するが，ここでは重複も許すことにした．以下，各誤り原因について述べる．「構文情報の不足」はテスト事例の文の構造の情報を捉えていないことを表す．例えば，対象単語を含む単語間の係り受け関係を考慮した素性の不足，格関係のような文の意味的構造を表現した素性の不足などが挙げられる．「考慮する単語の不足」は語義を識別できる特徴的な共起単語が少ないことを表す．テスト事例において対象単語の前後に出現する共起単語や訓練事例に出現する共起単語の特徴では語義を識別することが難しい場合をこのタイプの誤りとした．「パターンの一部が不足」は品詞情報など，単語表層以外の特徴的な情報が不足していることを表す．語義を識別できる特徴には名詞や動詞などの特徴的な単語だけではなく，接続する品詞によって語義が決定する場合もある．助詞や助動詞といった品詞を含むパターンが大きく影響して誤りとなる場合をこのタイプの誤りとした．「概念情報の不足」は手がかりとして使う単語の上位・下位関係にある単語を利用していないことを表す．テスト事例において対象単語の前後に出現する共起単語に対し，単語を表層形で利用すると訓練事例の単語と一致しないが，外部辞書として概念体系を使うと同じ概念として一致する場合がある．同じ概念ではあるが概念体系を利用していないために誤って識別する誤りをこのタイプとした．「表記のずれ」は訓練事例に識別のためのパターンは存在するが，異表記が原因で誤ったタイプである．「文が短く，手がかりがない」は文が短く，特徴が捉えにくいことを表す．「再実験では正解した例」は誤り事例集合作成時は異なる語義に分類されたが，再実験を行った結果正しく分類された事例を表す．2節の実験ではlibsvmのdefaultのパラメータ設定を採用したので，モデルの複雑度を調節するコストはC=1，学習を止める停止基準値はeps=0.001としていたが，C=5及びeps=0.1と設定して再実験したところ，いくつかの誤り事例に対して正解が得られた．このようにSVMの学習パラメータの変更によって語義を正しく識別できた事例の誤り原因は「再実験では正解した例」としてまとめた．次に，ここで行ったいくつかの誤り分析の例を示す．最も出現数の多い「パターンの一部が不足」の例として，「早く元気な顔を見せて*あげる*事ですね．」を見てみる．「見せてあげる」と同様の「〜してあげる」というパターンが訓練事例に存在していれば適切に識別できると考えられる．しかし，訓練事例にはそのようなパターンの事例は存在しなかった．その一方で，「あげる事です」に対応する「あげる＋普通名詞＋助動詞」のパターンが異なる語義の事例として存在するために，この用例は誤った語義に識別されたと思われる．「考慮する単語の不足」の例として，「…発音を*教え*てください…」を見てみる．この事例の正しい語義は「知識や技能を身につけるように導く」であり，「〜てください」のパターンが識別に有効そうであるが，誤って識別した語義「知っていることを告げ示す」と共起単語を比較した結果，どちらの語義でもこのパターンが生じていた．このパターン以外に識別に有効そうな素性は存在していないため，結果的に誤っている．このような問題に対処するには，訓練事例数を数多く用意し，「教える」の前に接続する単語の種類を揃える必要があると考える．「概念情報の不足」の例として，「…悲鳴を*あげ*ながらずんずん進んだ…」がある．この事例の正しい語義は「勢い・資格・価値・程度を高める．」である．辞書にはこの語義の用例として「声を（高く）出す．」があるため，この語義が正解であることは明らかである．しかし，分析用システムは「取り出して言う．」と誤って識別した．正しい語義の訓練事例には「声」，「叫び声」，「歓声」といった声に関連する単語が含まれているため，テスト事例の「悲鳴」も含めて同じ「声」の概念として捉えることができれば識別可能だったと考えられる．「表記のずれ」の例として，「落札する前に聞いた方が*いい*ですか？」がある．訓練事例には正しい語義の事例で「ほうがいいです」との表記を持つものがあり，テスト事例の「方」をひらがなの「ほう」に変更して識別を行うと適切に語義を識別することができた．このように，異表記を正しく解析できないために誤ることもある．</subsection>
  <subsection title="古宮の分析：最大頻度語義と素性に注目">機械学習の観点から誤りの原因の分析を行った．具体的には，訓練事例中の最頻出語義（MostFrequentSense,以下MFS）の割合や，テスト事例と訓練事例の間の素性の違いと共通性を見ることで，機械学習の特質から説明できる誤りを主に分析した．分析の結果を表に示す．なお，「MFSに誤分類」の2つの分類（表のMと(M)）には重複して分類されることはないが，これらと「テスト事例の素性が訓練事例の素性と等しい」（表のF）と「分からない，自信がない」（表の？）については重複して分類されることがある．ここでの分析では，まず，MFSに注目した．分析用システムの識別結果がaであり，それが誤りであった場合，aは対象単語のMFSである可能性が高いと考えたためである．そこで，「MFSに誤って分類された」事例と，そうでない事例の分類を行った．すると，分析対象の50事例中の32事例が「MFSに誤って分類された」事例であることが分かった．更に，「MFSに誤って分類された」事例の中で，MFSと第二位の比率を持つ語義（第二語義）との訓練事例数の差が小さい（4以内の）ものが5事例であり，残りの27事例は，MFSと第二語義との訓練事例数の差が大きい（8以上の）ものであった．なお，差が5から7の事例は存在しなかった．例えば，最も顕著な例は対象単語の「場所」である．「場所」の50個の訓練事例のうち，49事例が語義41150-0-0-1（ところ）であり，語義41150-0-0-2（居るところ）は1事例しかなかった．その結果，「場所」のテスト事例はすべて語義41150-0-0-1と識別されており，テスト事例中に2つあった語義41150-0-0-2は誤りとなっていた．このことから，誤りの原因として，機械学習の特質により，MFSに誤って分類されるということが大きいことが分かる．また，この例にも見られるように，今回の分析で用いた訓練事例の少なさから，少量の事例しか持たない語義は十分に学習ができていないことがあったと思われる．次に，テスト事例の素性が訓練事例の素性と等しいことで，誤っている事例を目視で探した．例えば，「意味」の事例の一つ，「…これらの単語で*意味*が通じるよ…」の「意味」（正解は語義2843-0-0-1（その言葉の表す内容．意義．））は，「対象の単語の一つ後の形態素」が「が」である，という素性が強く働いたためであると思われる．この素性は語義2843-0-0-3（表現や行為のもつ価値．意義．）に頻出していたことから，語義2843-0-0-3に誤って識別されている．この例は，語義2843-0-0-3として訓練事例にあった「意味がある」「意味がない」に「意味が通じる」という表現が少し似ていた，と見ることができる．このようなものは22事例あった．このように表現の類似性は，実際に語義曖昧性解消の手掛かりともなるが，逆に誤りの原因ともなっている．なお，このような，素性が誤りの原因と思われる事例に対しては，「F」を付与した．また，訓練事例中に何度も現れる顕著な素性ではない場合には，素性が強く働いたかどうか分からないため，「F」とともに「?」も付与した．さらに，これらの観点から分類が難しかったものに対しては，単独で「?」を付与した．また，他にも，ここでの誤り分類のタイプには含めなかったが，この素性が訓練事例にあれば識別可能だと思われる素性が，訓練事例にない場合が2つ存在した．一つは，「…早く元気な顔を見せて*あげる*事ですね…」であり，正解は語義545-0-3-2（敬語としての用法）だが，手掛かりとなりそうな「ひとつ前の形態素が『て』である」という素性が訓練事例には存在しなかった．また，「…ええ水をお*あたえ*くださいませ…」の正解は語義755-0-0-1（自分の物を他人に渡し，その人のものとする．）であり，この「おあたえくださる」という表現は典型的であると思われるが，訓練事例に「与えてください」のように「与える」と「くださる」の間に「て」をはさむ用法はあっても，このような用法は存在しなかった．最後に，分類語彙表の値に曖昧性があり，本来の意味ではない値が付与されていたために，誤った事例が1つあった．「…凝固する際に*出る*熱を冷やしているから…」という用例で，これは，「〜（の）際（さい）」という表現が「きわ」として誤って解析されたために誤った例である．「出る」の訓練事例には「きわ」と同じ意味分類を持つ「外」などを2つ前の形態素にもつ事例が2つあった．</subsection>
  <section title="クラスタリングを用いた分析結果の統合"/>
  <subsection title="誤り原因のクラスタリング">前掲のが各自の分析結果である．誤り分析の次のステップとしては，これらを統合し，各人が同意できる統一した誤り原因のタイプ分類を作成し，それに対する考察を行う必要がある．しかし各自の分析結果を統合する作業は予想以上に負荷が高かった．統合作業では分析対象の誤り事例一つ一つに対して，各分析者が与えた誤り原因を持ち寄って議論し，統合版の誤り原因を決定しなければならない．しかし，誤りの原因は一意に特定できるものではなく，しかもそれを各自が独自の視点でタイプ分けしているため，名称や意味がばらばらな誤り原因が持ち寄られてしまい議論がなかなか収束しないためであった．また統合の処理を議論によって行う場合，結果的に誰かの分析結果をベースに修正していく形になってしまう．誰の分析結果をベースにすればよいかも正解はなく，しかもある人の分析結果をベースにした時点で，他の人の分析結果に含まれるかもしれない重要な情報を捨ててしまう危険性もある．つまり分析者全員が同意できるような誤り原因のタイプ分類を，グループ内の主観に基づく議論のみから作成するのは，負荷が高い作業になってしまう．このような背景から，我々は各自の誤り原因を要素とする集合を作り，それをクラスタリングすることで，ある程度機械的な誤り原因のタイプ分けを試みた．クラスタリングでは分析者全員の分析結果を公平に扱っている．またクラスタリングによって作成できた誤り原因のタイプ分類は各人のタイプ分類を代表しているタイプ分類になっていることが期待できる．結果として，このようなアプローチで作成した誤り原因のタイプ分類は，各分析者が同意できるものとなり，しかも統合作業の負荷を大きく減らすことができると考えた．各自の分析では分析対象の50事例に対して，各自が設定した誤り原因の記号を付与している形になっている．見方を変えて各自が設定した誤り原因の記号の1つ1つに注目すると，50個の対象事例のどの事例がその誤り原因に対応しているかを見ることができる．対応する事例に1を，対応しない事例に0を与えれば，誤り原因は50次元のベクトルに変換することができる．そしてこのベクトルの距離が近いほど誤り原因の意味が近いと考えることができるため，ベクトルに変換した誤り原因のクラスタリングが可能となる．まず各自の誤り原因を取り出すと，全部で75個存在した．この75個の誤り原因がクラスタリングの対象である．処理のために各誤り原因にID番号を付与した．また誰が設定した誤り原因かがわかりやすいように，番号には各人を表す記号を前置している．m-は村田，sr-は白井，fk-は福本，sn-は新納，fj-は藤田，ss-は佐々木，k-は古宮を意味する．この誤り原因とID番号との対応は付録2に記した．また付録2には誤り原因の意味（簡単な説明）も付与している．以後，誤り原因に対してはこのID番号によって参照することにする．75個の各誤り原因を50次元のベクトルに変換し，そのノルムを1に正規化した後にWard法によりクラスタリングを行った．このクラスタリング結果であるデンドログラムをに示す．</subsection>
  <subsection title="クラスタの抽出">誤り原因の総数が75個，分析者が7人であり，その平均から考え，誤り原因は10個前後に設定するのが適切だと考えた．そこでのデンドログラムから目視により，に示すAからMの13個のクラスタを取り出した．各クラスタに含まれる誤り原因のID番号をに示す．またクラスタ内の各誤り原因には対応する事例が存在するので，その総数と種類数もに示す．</subsection>
  <subsection title="各自の分析結果の統合">クラスタリングによりAからMの13個のクラスタを取り出した．次に各クラスタに意味を与える必要がある．この意味を与えることで各自の分析結果の統合が完成する．ただし各クラスタに正確に1つの意味を与えることは困難である．通常，クラスタにある意味を設定した場合，クラスタ内にはその意味とは異なる要素が含まれることが多い．ここでは各クラスタ内の要素（誤り原因）を精査し，その意味を設定する．意味を割り当てることができたクラスタが統合版の誤り原因となる．次にその意味から考え，不適な要素を省いたり別クラスタに移動させたりすることで，最終的な統合を行う．</subsection>
  <subsubsection title="クラスタの意味の付与とクラスタの合併">クラスタに意味を付与するには，クラスタ内の類似している要素に注目し，それらの共通の意味を抽出することで行える．この段階で意味が同じクラスタは合併することができる．以下，各クラスタについてその内容を表にまとめる．その表の「注目」の列に``○''がついているものが意味付けを行うために注目した要素である．クラスタAの内容は以下の通りである．意味付けは困難でありこのクラスタは削除する．クラスタBの内容は以下の通りであり，意味は「テスト文に問題あり」とした．クラスタCの内容は以下の通りである．意味付けは困難でありこのクラスタは削除する．クラスタDの内容は以下の通りである．意味付けは困難でありこのクラスタは削除する．クラスタEの内容は以下の通りであり，意味は「シソーラスの問題」とした．クラスタFの内容は以下の通りであり，意味は「学習アルゴリズムの問題」とした．74(74)に``○''を付けている．74は古宮が設定した分類である．古宮の分類観点を見ると，74が付けられた事例はMFSの観点あるいは素性の様子からでは誤りの原因が特定できないものであることがわかる．これは分析用システムで利用したSVMによる影響と見なせる．そのため74も「学習アルゴリズムの問題」と見なした．クラスタGの内容は以下の通りであり，意味は「訓練データの不足」とした．55(55)に``○''を付けている．藤田のシステムは訓練データを拡張した手法である．そのシステムで正解となったということで，その誤りの原因を「訓練データの不足」と見なした．クラスタHの内容は以下の通りであり，意味は「共起語の多義性」とした．クラスタIの内容は以下の通りであり，意味は「構文・格・項構造の素性不足」とした．クラスタJの内容は以下の通りであり，意味は「データの誤り」とした．クラスタKの内容は以下の通りであり，意味は「深い意味解析が必要」とした．46(46)に``○''を付けている．46は新納が設定した分類である．新納は46と47(47)を区別しているが，そこでの説明にもあるように，これらの違いは一概に判断できない．46のタイプの誤りのほとんどは，その文脈上で人間は語義を識別できると考え，ここではまとめることにした．また56(56)にも``○''を付けているが，これは46あるいは47の意味と考えられるためである．クラスタLの内容は以下の通りであり，意味は「構文・格・項構造の素性不足」とした．これはクラスタIの意味と同じであり，クラスタLはクラスタIと合併する．クラスタMの内容は以下の通りであり，意味は「素性のコーディングが困難」とした．以上より記号B,E,F,G,H,I,J,K及びMで示される9個の統合版の誤り原因を設定した（表13参照）．</subsubsection>
  <subsubsection title="クラスタリング結果の調整">クラスタリングの対象であった75個の誤り原因のうち，統合版の誤り原因に置き換えられるものは35種類であった．残り40種類の誤り原因の中で統合版の誤り原因に置き換えられるものを調べた．基本的には各分析者が自身の設定した誤り原因の意味と統合版の誤り原因の意味を比較することで行った．結果，以下のに示した11個の置き換えができると判断した．上記の調整を行った後の統合版の誤り原因はにまとめられる．本論文ではこれを「統合版誤り原因のタイプ分類」と名付けることにする．</subsubsection>
  <subsection title="事例への誤り原因のラベル付与">ここでは分析対象の50事例を統合版誤り原因のタイプ分類に基づいてラベル（記号）を付与する．まず対象事例に対する各自の分析結果であるの各記号を，統合版誤り原因のタイプ分類の記号に置き換える．次に2名以上が同じ記号を付けていた場合に，その記号をその事例に対する誤り原因とする．結果をに示す．「統合タイプ」の列が統合版誤り原因のタイプ分類による記号を表す．以下に示す対象事例の25,42には記号が付与されなかった．これらの事例に対しては，誤り原因が分析者により異なり，共通した原因がなかったためであるといえる．またから得られる統合版の誤り原因の事例数を大きい順にに示す．累積カバー率はその順位までのタイプを使って分析対象の50事例をどの程度カバーしているかを表す．から誤りの9割は上位3つの「G:訓練データの不足」「K:深い意味解析が必要」「E:シソーラスの問題」のいずれか，あるいはそのいくつかが原因であることがわかる．</subsection>
  <subsection title="統合版誤り原因のタイプ分類の評価">ここでは統合版誤り原因のタイプ分類の評価を行う．本論文が目標としたタイプ分類は分析者7名のタイプ分類を代表するタイプ分類であるため，この観点から評価を行う．そのために，誤り原因のタイプ分類間の類似度を定義し，各タイプ分類間の類似度を測る．統合版誤り原因のタイプ分類がどの分析者の誤り原因のタイプ分類とも類似していれば，統合版誤り原因のタイプ分類が本論文で目標としていたタイプ分類であることがいえる．AとBを誤り原因のタイプ分類とし，AとBの類似度Sim(A,B)の定義を行う．Aの要素である各誤り原因は，本論文のクラスタリングで利用したように50次元のベクトルで表現できる．そしてAの誤り原因がm種類のとき，Aは以下のような集合で表現できる．同様に，Bの誤り原因がn種類のとき，Bは以下のような集合で表現できる．ここでa_iやb_jは50次元のベクトルである．本論文ではSim(A,B)を以下で定義する．ここでs(a_i,b_j)はa_iとb_jの類似度であり，ここでは内積を用いる．またQは誤り原因のラベルの対応関係を表す．例えばAのラベルが1,2であり，Bのラベルが1,2,3である場合，ラベルの対応は以下の6通りが存在する．Qはこの中のいずれかになる．(1,1),(2,2),(1,2),(2,1),(1,2),(2,3)(1,3),(2,2),(1,1),(2,3),(1,3),(2,1)verbatimつまりSim(A,B)はラベル間の対応Qに基づく誤り原因間の類似度の和を意味する．問題は最適なQの求め方であるが，一般にこれは組み合わせの数が膨大になるため，求めることが困難である．ここでは単純に以下の擬似コードで示される貧欲法によりQを求め，そのQを用いてSim(A,B)を算出することにした．Q&lt;-;K&lt;-1,2,・・・,m;H&lt;-1,2,・・・,nwhile((K!=)∧(H!=))(i,j)=argmaxs(a_i,b_j)with(i,j)∈(K,H)Q&lt;-Q+(i,j)K&lt;-K-i;H&lt;-H-jreturnQverbatimscreen上記の疑似コードの概略を述べる．まずAもBも記号の添え字でラベルを表すことにする．Aのラベルの集合をK，Bのラベルの集合をHとする．各(i,j)(K,H)に対して，sim(a_i,b_j)を求めることで，sim(a_i,b_j)が最大となる(i,j)が求まる．これをQに追加し，Kからiを，またHからjを取り除く．この処理をKかHのどちらかの集合が空になるまで続け，最終的なQを出力とする．またここではラベルの意味を考慮してQを設定していないことに注意しておく．我々の問題ではラベルに意味が付けられている．このラベルの意味から要素間の対応を取りQを設定することも可能である．しかしここではそのようなアプローチは取らなかった．つまりここでは分析者Aが誤り原因iに付与した（主観的な）意味と，分析者Bが誤り原因jに付与した（主観的な）意味が似ているか似ていないかは考慮せずに，iやjのラベルが付与された事例の分布のみからiとjの類似度を測っている．またここでの誤り原因のタイプ分類では，1つの事例に対して複数の誤り原因を与えることを許している．このため明らかに1つの事例に多くの誤り原因を与える方が類似度が高くなる．この問題の解消のために1つの事例にk個の誤り原因を与えている場合，その部分の頻度を1/kに修正した．さらに統合版誤り原因のタイプ分類では，事例25,42にラベルを付与していない．一方，他の分析者は「わからない」「分析していない」などのラベルも許して全ての事例にラベルを付与している．公正な評価のため，統合版誤り原因のタイプ分類による事例25,42にも便宜上「その他」というラベルを付与した．上記の処理により各誤り原因のタイプ分類間の類似度を求めた結果をに示す．表中の各人の名前はその人の誤り原因のタイプ分類を示し，【統合】は統合版誤り原因のタイプ分類を示す．また類似度の横の括弧内の数値は，その行に注目して類似度の大きい順の順位を表す．各人の縦の列の順位を足して，要素数で割った結果をに示す．この値が低いほど，全体として他のタイプ分類と類似していることを示しており，統合版誤り原因のタイプ分類が最も良い値を出している．これは統合版誤り原因のタイプ分類が，分析者7名のタイプ分類を代表していることを意味し，本論文が目標としていたタイプ分類であることを示している．</subsection>
  <subsection title="統合版誤り原因のタイプ分類を利用した各人の分析結果の比較">ここでは統合版誤り原因のタイプ分類を利用して各人の分析結果の関係を考察する．各人の誤り分析に対する分析結果は，細かく見ると，誤り原因のタイプ分類の構築とそのタイプ分類に従った対象事例への誤り原因のラベル付与からなっている．各人の分析結果は誤り原因のタイプ分類が異なっているために，直接比較することはできないが，各人が設定した誤り原因を統合版の誤り原因に変換し，誤り原因のラベルを統一することで，各人の分析結果を比較できる．具体的にはが，統合版誤り原因のタイプ分類を利用して誤り原因のラベルを統一した各人の分析結果と見なせる．ラベルが付与されていない場合は，仮想的に10番目の誤り原因のラベル「その他」が付与されていると考える．これによってから各人の分析結果を5010の行列として表現できる．行列間の距離を各行（事例）間の距離の和で定義すれば，各人の分析結果間の距離がのように求まる．から多次元尺度法を利用して，各人の分析結果の位置関係を2次元にマップしたものがである．の各人の点はほぼ均等に分布しており，各人の分析結果は互いにかなり異なることが確認できる．その上で以下の2点も認められる．村田，白井，藤田，佐々木の4者の点（分析結果）は比較的近くに集まっている．古宮の点（分析結果）は比較的孤立している．(a)は，から距離の近い分析者の組を順に並べると，，，となっていることからも裏付けられる．また上記4者の距離が近いのは誤り原因G「訓練データの不足」の事例数のためと考えられる．以下の表は各人の分析結果に対して，誤り原因Gが与えられた事例数である．村田，白井，藤田，佐々木の4者の分析結果に誤り原因Gが与えられた事例数は，どれも比較的大きな値であることがわかる．このため4者の類似度が高くなり，比較的近くに集まったと考えられる．(b)は古宮の分析結果からほぼ明らかである．古宮の分析結果には，誤り原因F「学習アルゴリズムの問題」しか与えられていない．このため他の分析者と誤り原因の一致する事例が極端に少ない．例えば佐々木とは50事例中，誤り原因が一致するものは2つしかない．一致する事例数が少ないと距離が大きくなり，結果的に孤立した位置となる．</subsection>
  <subsection title="統合版誤り原因のタイプ分類と各人のタイプ分類の差">ここでは統合版誤り原因のタイプ分類に置き換えられなかった各人が設定した誤り原因に注目し，それらが統合版誤り原因のタイプ分類に置き換えられなかった理由を調べることで，統合版ならびに各人の誤り原因のタイプ分類の特徴を考察する．本論文ではクラスタリングを利用して各人の分析結果である誤り原因のタイプ分類を統合した．原理的には多数決と各人の設定した誤り原因の意味を勘案してタイプ分けを行ったことに相当する．統合の過程で各人の分析結果の一部は切り捨てられ，結果的に，統合版に含まれていない．具体的には付録2の表の「統合版の誤り原因」の欄が空欄になっているものがそれに当たる．「切り捨てられた」と言ってもクラスタリング結果の調整を行っているので，実際は，設定した誤り原因が統合版の誤り原因のどれにも置き換えられないと判断された結果である．各人が設定したある誤り原因がある統合版の誤り原因に置き換えられるかどうかの判断は，主観的な部分も大きく，困難である．また事例数が少ないものは，統合版の構築には影響が出ないために，無理矢理置き換えることを避けたという事情も考えられる．一方，ある誤り原因が統合版の誤り原因に置き換えられないことが比較的明らかなものも多い．これはその誤り原因が独自の観点のためである．例えば白井の28（28），29（29），新納の53（53），藤田の64（64）などである．また古宮の設定した誤り原因のほとんど（4中3つ）が統合版の誤り原因に置き換えられていない．具体的には72（72）,73（73）及び75（75）である．古宮のタイプ分類は，語義曖昧性解消の問題を分類問題として一般化した上で，その現象ベースから誤りの原因を考えようとしたものであり，上記3つはどれも独自の観点と見なせる．また福本の40（40），43（43），44（44）及び45（45）は福本が「語義曖昧性解消タスク外の問題」と位置づけたものであり，これも独自の観点と見なせる．独自の観点とは多少異なるが，統合版の誤り原因の異なるタイプの部分的な和になっている，言わば，混合した観点も統合版の誤り原因とは異なると考えた．例えば村田の1（1）は，主に以下の2種類の誤り原因に対応する．同一文内の共起語を素性に利用すべき分類語彙表の分類番号の3桁や4桁も利用すべき(1)は統合版誤り原因K「深い意味解析が必要」に対応し，(2)は統合版誤り原因E「シソーラスの問題」に対応すると考えられる．つまり村田の1（1）はこれらを混合した観点と言える．佐々木の66（66）の場合，テスト事例あるいは訓練事例における「単語の不足」であるため，統合版誤り原因G「訓練データの不足」と統合版誤り原因K「深い意味解析が必要」の混合した観点となっている．統合版の誤り原因に置き換えられなかった各人が設定した誤り原因のほとんどは独自の観点か混同した観点であり，しかも事例数が少ない．この点から統合版誤り原因のタイプ分類は，各人のタイプ分類を代表するタイプ分類であるだけでなく，各人が設定した誤り原因の主要部分が反映されたタイプ分類でもある．その結果，統合版誤り原因のタイプ分類は，標準的な語義曖昧性解消の誤り原因のタイプ分類になっていると考えられる．また標準的な誤りの原因のタイプ分類を定量的なデータと共に提示できた意味は大きい．語義曖昧性解消の問題に新たに取り組む者にとって，標準的な手法を用いた場合に，どのような誤りがどの程度出現するのかの目安を得られることは有益である．その上で独自の手法を考案する際，提案手法がどのような誤りの解決を狙っているのかといった研究の位置づけも明確になる点も長所である．最後に，ここで作成した統合版誤り原因のタイプ分類の問題点として，タイプの粒度の問題が存在することを注記しておく．本論文では統合版誤り原因のタイプ分類を作成するのにクラスタリングを利用している．そこではまず誤り原因のクラスタを13個作成したが（参照），1つのクラスタに最大1つのタイプしか与えなかった．これはタイプの粒度を一定に保つために行った処置である．このためある粒度のタイプ分けは行えているが，その粒度が粗すぎることも考えられる．例えば統合版誤り原因G「訓練データの不足」と言っても，どのようなタイプの「訓練データ」なのかで詳細化できる．また統合版誤り原因K「深い意味解析が必要」も，どのような「意味解析」なのかで詳細化ができる．このような詳細化は有益であり，本研究の今後の課題と言える．</subsection>
  <section title="おわりに">本論文ではProjectNextNLPの「語義曖昧性解消」チームの活動として行われた語義曖昧性解消の誤り原因のタイプ分けについて述べた．誤り分析の対象事例を設定し，メンバーの7名が各自誤り分析を行った．各自の分析結果はかなり異なり，それらを議論によって統合することは負荷が高いことから，ここでは各自の設定した誤り原因（計75個）を対応する事例を用いてベクトル化し，それらのクラスタリングを行うことで，ある程度機械的に統合処理を行った．クラスタリングによって統合版の誤り原因を特定し，クラスタリング結果の微調整によって最終的な誤り原因のタイプ分類を作成した．得られた誤り原因の主要な3つにより，語義曖昧性解消の誤りの9割が生じていることも判明した．また得られたタイプ分類はタイプ分類間の類似度を定義して考察した結果，分析者7名のタイプ分類を代表するものであることも示した．また統合した誤り原因のタイプ分類と各自の誤り原因のタイプ分類を比較し，ここで得られた誤り原因のタイプ分類が標準的であることも示した．本研究で得られた誤り原因のタイプ分類は標準的であり，それを定量的なデータと共に提示できた意味は大きい．今後，一部のタイプを詳細化することで改善していけると考える．この点が今後の課題である．</section>
  <section title="誤り分析対象の 50 用例">0.840.840.84</section>
  <section title="各人の誤り原因の一覧">!!document</section>
</root>
