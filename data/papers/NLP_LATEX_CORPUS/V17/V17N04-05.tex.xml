<?xml version="1.0" ?>
<root>
  <jtitle>コーパスごとの類似度を考慮した用例に基づく	感情推定手法の改善</jtitle>
  <jauthor>三品賢一土屋誠司鈴木基之任福継</jauthor>
  <jabstract>発話文を感情ごとに分類したコーパスを構築し，入力文と最も類似度が高い発話文を含むコーパスの感情を推定結果として出力する用例ベースの感情推定手法が提案されている．従来手法ではコーパスを構築する際，発話テキストの収集者が個人個人で発話文の分類先を決定しているため，分類先を決定する基準が個々によってぶれてしまう．これにより，例えば``希望''のコーパスの中に喜びの発話文が混じるといったことが起こり，推定成功率を下げてしまう．本稿ではこの問題を解決するため，コーパスごとにおける入力文の形態素列の出現回数を用いて，入力文とコーパスの類似度を定義する．そしてこの類似度を従来手法に導入した新たな類似度計算式を提案する．これにより，誤って分類されてしまった発話文の影響を緩和することができる．評価実験では従来手法と比べて成功率が21.5</jabstract>
  <jkeywords>感性情報処理，類似度計算，用例ベース，N-gram</jkeywords>
  <subsubsection title="  適合率">適合率p_n(x,s)は，入力文xと感情コーパス中の1文sの間で共通なが多く存在するかを表す値である．共通なが多いほどp_n()は大きくなる．xとsを用いて，p_n(x,s)は次のとおりに定義されている．p_n(x,s)=_	G_n(s)Count^*_n(x,s,)	_G_n(s)Count_n(s,)^*_n(x,s,)=Count_n(x,),	Count_n(s,)	gatherここでG_n(s)をsに含まれる``連続するn個の形態素から作られる形態素N-gram''の集合を返す関数とする．Count_n(x,)は，x中のの出現数を返す．sがxと共通なを持っていなければCount^*_n()はすべてのw_nで0になるため，p_n()は入力文と感情コーパス中の1文がどれほど共通なを持っているかの指標となる．p_n()を求める例として，形態素unigramの適合率p_1(x,s)と形態素bigramの適合率p_2(x,s)を計算する．xを``明日からの旅行が楽しみです''，sを``明日がすごく楽しみです''とする．このときの形態素unigramのCount_1()とCount^*_1()の値を表に示す．表と式()より，p_1(x,s)は1/2であることがわかる．また形態素bigramのCount_2()とCount^*_2()の値を表に示す．表と式()より，p_2(x,s)は2/5であることがわかる．なお，形態素bigramには文頭や文末を表す記号はと同様に用いていない．</subsubsection>
  <section title="はじめに">コミュニケーションの手段として，メールやWebの掲示板を日常的に利用するシーンは非常に多い．メールやWebの掲示板によるコミュニケーションの特徴として，非言語情報が欠落しているため，会話時に相手から感じる対人圧力が低くなり，気軽に考えていることを書き出すことができるメリットがあげられる．しかし一方で，メッセージの受け取り手はテキストの内容のみから相手の考えを読み取らなければならないため，ちょっとした言葉の誤解が，感情的な問題へと発展していくことがある．また，書き方によっては書き手の感情が伝わりにくいことがあったり，書き手はそれほど怒っていないにもかかわらず，非常に怒っているようにとらえられたりと，過剰に感情が伝わってしまうこともある．このように，書き手が思っている程，伝えたいことが相手に伝わらない傾向があるため，メールやWebの掲示板では相手に誤解を与えやすいというデメリットを持っているといえる．そこで我々は上記の問題点を解決するため，テキストから読み手が想起する書き手の感情を推定し，推定結果を書き手に示すことでテキストを書き手に修正させ，相手に誤解を与えないようにするシステムの開発を目指した研究を行っている．このようなシステムを実現するためには，読み手が想起する書き手の感情をテキスト中の発話文から推定する手法が必要となる．発話文からの感情推定手法として，目良らは複数の事象の格フレームタイプのうち，どれに入力文が当てはまるかを判定し，該当した格フレームタイプに対応する情緒計算式を用いて発話者の感情が快か不快かを判定する手法を提案している．この手法では，あらかじめ用意した情緒計算式のほかに，ユーザの嗜好情報を基にした単語に対する好感度データを用いる．単語に限らず，文の冒頭に現れる副詞や文末表現によって話し手の意図や心的態度を表すモダリティも，感情推定に有用であることが考えられる．文末表現から情緒を推定する可能性についての検討を徳久らが行っており，文末表現と情緒の間に若干の相関がみられたと報告している．単語や文末表現に感情の属性を振ったとしても，単語や文末表現の組み合わせによって感情が変化すると考えられる．そのため，単語や文末表現を用いて感情推定を行うためには，これらの組み合わせに対応して感情を出力するルールの作成が必要になると考えられる．ルールの例として，例えば``嬉しい''という語に``喜び''の属性が割り振られていたとする．ここで``嬉しいことなんてひとつもない''という文の感情を推定する場合，推定結果としては``喜び''ではなく``悲しみ''や``怒り''といった感情が出力されるべきである．``喜び''の単語が含まれているからといって，単純に``喜び''を出力してよいわけではない．ここで``悲しみ''や``怒り''を出力するためのルールを作成しておくことで，感情推定が可能になる．しかし，このようなルールの作成は単語に感情の属性を割り振る作業以上にコストがかかると考えられる．この問題を解決する方法として，三品らは用例に基づく感情推定手法を提案している．この手法では，発話者が表現している感情ごとに発話文を分類した感情コーパスを用い，入力文と最も類似度が高い発話文が含まれる感情コーパスの感情を推定結果として得る．類似度計算には機械翻訳システムの性能のスコアを求めるBLEUを用いている．この手法を実装するためには発話文を収集して感情ごとに分類した感情コーパスを構築すればよく，先に述べた例のようなルールを作成する必要がない．しかし，この手法は感情推定成功率が決して高くないため，類似度の計算式を改良する必要がある．この方法では入力文とコーパス中の各文の類似度を計算し，その最大値の文が持つ感情を出力している．そのため，次のような特異な文によって感情推定に失敗することがある．感情が異なっていても，たまたま表現や文型が類似している文コーパスを構築する際に誤って分類された文感情が異なるが類似している文の例として，``嫌悪''の文``嫌いなんです''と``喜び''の文``好みなんです''があげられる．ともに名詞の後に``なんです''が続く形となっており，文型が類似している．ここで入力文として``好きなんです''が与えられたとき，入力文の``なんです''は二つの文に存在しており，形態素数も同じであるため，``嫌悪''と``喜び''の文とのBLEUスコアは同じになってしまう．その結果，``嫌悪''と``喜び''が出力されてしまう．この推定結果としては``喜び''のみが出力されることが適切であると考えられる．また，コーパスを構築する際には誤って分類される発話文を完全に取り除くことは非常に困難であると考えられる．このことから，誤って分類された発話文の影響を最小限に抑える手段が必要となる．本稿では三品らの手法を改善し，()や()の文による影響を抑え，感情推定成功率を向上させる手法を提案する．本稿では，まず章で従来手法である``BLEUを類似度計算に用いた用例に基づく感情推定手法''について述べる．次に章で，従来手法で用いられていた類似度計算式とは異なる新たな類似度計算式を提案する．また，この新たに提案する類似度計算式で，どのようにして従来手法の問題点を解決するかについて述べる．そして章では従来手法と提案手法の感情推定成功率の比較を行う．また三品らの方法とは異なる感情推定の従来法として，SVMを用いた感情推定を行い，結果を比較する．最後に章でまとめと今後の課題を述べる．</section>
  <section title="BLEUを類似度計算に用いた用例に基づく感情推定手法"/>
  <subsection title="概要">三品らによって提案された類似度計算を用いた用例に基づく感情推定アルゴリズムは次の式で定式化される．ここでxを入力文，E(x)を推定結果となる感情，C_eを感情eのコーパス，sをC_eに含まれる文，sim(x,s)をxとsの類似度を返す関数とする．三品らはsim()にBLEUを用いている．この手法は，発話文を発話者の感情別に分類して構築した感情コーパスを用いることで感情推定を行う用例ベースの手法である．発話文の分類先は，発話文の収集者が発話者の感情を判定することで決定する．図に発話文からの感情推定の流れを示す．まず発話者の感情によって分類された感情コーパスを用意しておく．次に発話者の感情を推定する対象となる発話文を入力とする．そして，各感情コーパスに含まれる発話文と入力文との類似度を求める．最後に各感情コーパス別に，得られた類似度の最大値を求める．この類似度が入力文が表現している感情のスコアとなる．スコアは0から1までの値をとり，値が大きいほどその感情を表しているという意味になる．得られた類似度の中で最も値が大きい類似度の感情を，感情推定結果として出力する．この方法では図における類似度の計算にBLEUを用いている．用例ベースではない手法では，単語や文末表現への感情属性の付与や，単語や文末表現の組み合わせから感情を導出するルールを作成する必要が出てくるため，作業コストが非常に高いと考えられる．しかし従来手法のような用例ベースのシステムを構築する際には，発話文を集め，発話者の感情ごとに発話文を分類してコーパスを構築すればよく，用例ベースではない手法と比べて作業コストが低いと考えられる．</subsection>
  <subsection title="BLEU">BLEUは機械翻訳システムが出力した複数の翻訳候補文から，システムの翻訳精度を評価するための尺度である．BLEUは次のとおりに定義されている．なお，ではN=4を用いている．p_n(x,y)は機械翻訳文xと人による翻訳文yにおける共通数の適合率（適合率）を返す関数であり，BPは機械翻訳文が人による翻訳文に比べて簡潔すぎることによる適合率のペナルティである．三品らの方法では，BLEUにおける機械翻訳文をコーパス中の1文，人による翻訳文を入力文と変更して，類似度計算に用いている（以下，式()をsim_と表記する）．</subsection>
  <subsubsection title="適合率のペナルティ">ここでは感情コーパス中の1文sが入力文xに比べて簡潔すぎることによる適合率のペナルティBPについて説明する．sがxに比べて簡潔すぎる場合，sに含まれるほとんどの形態素をxが含んでいる可能性がある．この場合はp_nが大きくなり，BLEUスコアが高くなってしまう．つまり，簡潔な文を数多く含んでいる感情コーパスのほうが，入力文との類似度が高くなりやすくなってしまうので，これを防ぐためにBPが用いられる．g(x)をxの形態素数を返す関数として，BPは次のとおりに定義される．xを``明日からの旅行が楽しみです''，sを``明日がすごく楽しみです''としたとき，g(x)=7，g(s)=6となるため，BP=e^1-7/60.846となる．これはsが短かすぎるため，適合率へペナルティが課せられることを意味する．</subsubsection>
  <section title="提案手法"/>
  <section title="評価実験"/>
  <subsection title="提案手法と従来手法の比較">提案手法では従来手法と比べ，下記の2点が異なる．各感情コーパスにおける``入力文の形態素N-gram''の出現回数によって決まるペナルティFPの導入形態素N-gramの適合率の相加平均による類似度計算評価実験では上記の2点によって感情推定の成功率がどの程度変化するのかを調べる．</subsection>
  <subsubsection title="実験設定">実験には，基本的な感情であり，収集したコーパス中に比較的頻出した``喜び''，``怒り''，``嫌悪''，``希望''の4種類の感情カテゴリを用いた．各感情コーパスには838文の発話文が含まれる．発話文はWeb上の掲示板から8名の作業者によって収集した．発話文の分類先となる感情コーパスは，作業者の主観によって決定した．また発話文の分類先は複数選ぶことを許容した．入力となる文とその感情は次の手順で決定した．まず，感情コーパスに含まれない，別途掲示板から収集した文を無作為な順番で被験者4名に提示し，被験者に文の感情を判定させる．このとき，判定結果としての感情を``喜び''，``怒り''，``嫌悪''，``希望''の中から0個以上を選ばせる．被験者4名のうち3名以上の判定結果が一致した文を各感情ごとに51文ずつ用意し，入力文として用いる．なお，この予備実験で入力文に割り振られた感情の数はすべて1つとなった．感情推定の成功条件として，出力として得られる4つの感情類似度のうち，最も値が大きい類似度の感情と，入力文の感情が一致すれば成功とした．上記の()，()の効果を確かめるために，実験に用いた類似度計算式は三品らの方法（式()）とRECARE（式()）に加え，BLEUにFPのみを導入したsim_BLEUFP^+（式()）と，RECAREからFPを除いたsim_RECAREFP^-を用いた．sim_RECAREFP^-を次のとおりに定義する．</subsubsection>
  <subsubsection title="実験結果と考察">類似度の計算に用いるのnの値を変化させながら，推定成功率を計算した．図に感情推定の成功率を示す．三品らの方法で最も推定成功率が良好だったのはN=2を用いたときの60.3%であり，提案手法ではN=3を用いたときの81.8%であった．ここでは，まず()のFPを導入したことによる成功率の影響について考察する．図より，FP無しのsim_RECAREFP^-で最も良好だった成功率57.8%(N=3)と比べて，FP有りの提案手法sim_RECAREの成功率81.8%が大きく上回っていることがわかる．同様に，FP無しの従来手法sim_BLEUの成功率60.3%と比べて，FP有りのsim_BLEUFP^+で最も良好だった成功率77.9%(N=1)が大きく上回っている．これらのことから，形態素N-gramの適合率の平均の求め方に関わらず，FPの導入が成功率の向上に寄与していることがわかる．次に()の，類似度計算に形態素N-gramの適合率の相加平均を用いたことによる成功率の影響を考察する．N=2以降でNが増加するにつれて，三品らの方法の成功率は減少しているが，提案手法においては成功率の減少は認められなかった．このことから，形態素N-gramの適合率の相加平均を類似度計算に用いることは，高次のNを用いたときの成功率の改善に効果があることがわかる．なお，類似度計算に相乗平均を用い，FPを導入した方法(sim_BLEUFP^+)は，Nを増加させると急激にその性能を落としていた．この原因は，Nが大きくなると共通の形態素N-gramがコーパス中に存在しなくなる割合が増加するため，式()において，1文中のすべてのw_nでC_ew_nが0になる，という場合が増加したためであった．提案方法においては，類似度計算に相加平均を用いることでこの問題を解決し，Nが大きい場合においても高い性能を維持していることがわかった．このような場合は，共通形態素N-gramが存在しないため，FPと同様に形態素N-gram適合率(p_n(x,s))も0になる．そこで，sim_BLEUFP^+だけではなく，同じように相乗平均を利用している従来方法(sim_BLEU)も影響を受けると考えられる．本実験においては，従来方法における類似度計算に式()を用いている．この式ではp_n(x,s)の対数をとっているために，実装上，もしp_n(x,s)=0であった場合は，非常に小さな正の値にフロアリングした上で対数を求めていた．そのため，sim_BLEUFP^+のように急激に性能を落とすことはなかったと考えられる．このことを確認するため，式()を式()と同様，対数を用いない形に変形した上で，フロアリングをせずに実験を行ったところ，sim_BLEUもsim_BLEUFP^+と同様，Nが大きくなるとその性能を急激に落とす結果となった．</subsubsection>
  <subsection title="提案手法とSVMの比較">三品らの方法とは異なる従来手法の一つとして，良好なクラス分類が可能なSVM(SupportVectorMachine)による感情推定を行い，提案手法との比較を行った．本稿では学習，分類を行うプログラムとして，SVM^lightを用いた．</subsection>
  <subsubsection title="クラス分類モデルの構築">クラス分類モデルは感情コーパスの数と同じ数だけ構築する．例えば，``怒り''の分類モデルを構築する場合，ポジティブデータを``怒り''のコーパスに含まれる発話文から生成した特徴ベクトル，ネガティブデータを``怒り''以外の感情コーパスに含まれる発話文から生成した特徴ベクトルと定義し，学習を行う．本稿で学習に用いるポジティブデータの量はネガティブデータの量に比べて少なく，デフォルト値では良好な分類性能が得られない．そこでcostfactor(C_+/C_-)の計算には，Morikらが定義した次の式を用いた．costfactor以外の学習パラメータはデフォルト値を用いた．また学習パラメータで与えるカーネルのタイプもデフォルトである線形カーネルを用いた．</subsubsection>
  <section title="まとめ">本稿では，``感情が異なっていても，たまたま表現や文型が類似している文''や，``コーパスを構築する際に誤って分類された文''の影響を改善し，高い精度で感情推定を実現するための類似度計算手法であるRECAREを提案した．入力文で使われている形態素N-gramが，各感情コーパス間でどの程度偏っているか，といったことを表す値であるFPを定義し，BLEUをベースとした類似度計算に導入した．更に，高次のN-gramに対する学習サンプル数の不足からくる，いわゆる「ゼロ頻度問題」に対処するため，相乗平均で計算されるBLEUをベースとした類似度を変形し，相加平均を用いて類似度計算を行う方法を提案した．評価実験の結果，従来手法に比べ，推定精度が60.3%から81.8%へと大きく向上し，また問題としていた2種類の文のうち，特に``たまたま表現や文型が類似している文''の影響を効果的に低減させていることを確認した．また形態素N-gramを素性に用いたSVMによる感情推定に比べ，提案手法ではNが大きい場合に推定精度の低下がほとんど見られず，発話文の感情推定には提案手法が有効であることを示した．今後，「希望」や「自信」，「脅迫」といった更に複雑な感情を加えた時の性能の評価，また，必要があれば推定結果として複数の感情を出力することが可能となるようなアルゴリズムの改善について検討を行う予定である．</section>
</root>
