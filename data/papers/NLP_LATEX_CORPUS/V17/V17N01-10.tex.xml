<?xml version="1.0" ?>
<root>
  <section title="Introduction">Anaphoraresolutionhasbeenstudiedintensivelyinrecentyearsbecauseofitssignificanceinmanynaturallanguageprocessing(NLP)applicationssuchasinformationextractionandmachinetranslation.Innominalanaphora,ananaphor(typicallyadefinitenounphrase)anditsantecedentintheprecedingdiscourseholdseitheradirectanaphoricrelation(e.g.coreference)oranindirectrelation(e.g.,bridgingreference~Clark77bridging).Directanaphoricrelationreferstoalinkinwhichananaphorandanantecedentareinsucharelationassynonymyandhypernymy/hyponymy,asinhouse--building.Indirectanaphoricrelation,ontheotherhand,referstoalinkinwhichananaphorandanantecedenthavesuchrelationsasmeronymy/holonymyandattribute/valueasinticket--price.Fortheothercase,anounphraseoccasionallyholdsanexophoricrelationtoanantecedentthatliesoutsidethediscoursethatthenounphrasepresents.Recentstudiesinanaphoraresolutionhaveproposedtheresolutionframeworksforeachdirectandindirectanaphoriccaserespectively~soon01_coref,iida05_coref,poesio04_lbd,placingthemainfocusonthedirectanaphoriccase.Theidentificationofexophoricrelations,incontrast,hasbeenpaidlittleattentionintheliterature.Anaphoricitydetermination,whichisthetaskofdeterminingwhetherananaphorhasanantecedentintheprecedingdiscourseornot,isrelatedtoidentifyingexophoricrelations,butthemethodsforanaphoricitydeterminationarenotdesignedtoexplicitlycaptureexophoricrelationsbecausetheyaretunedforfindingNPcoreferencechainsindiscourse.However,forthepracticaluseofanaphoraresolution,weneedtosolvethefollowingnon-trivialproblem:inarealtext,anaphorssuchasdefinitenounphrasescanoccuraseitherdirectanaphoric,indirectanaphoricorexophoricrelations,whichisnoteasytodisambiguatefromitssurfaceexpression.Thatis,inanaphoraresolution,itisnecessarytojudgewhatkindofanaphoricrelationisusedtotieananaphorandits(potential)antecedent(henceforth,wecallthistaskanaphoratypeclassification).Infact,ourcorpusanalysis(detailedinSection)showsthatmorethan50%ofnounphrasesmodifiedbyadefinitenessmodifierhavenon-trivialambiguityintermsoftheanaphoratypesthathavetobeclassifiedforeachgiventext.Giventheseissues,wedecomposethetaskofnominalanaphoraresolutionasacombinationoftwodistinctbutarguablyinterdependentsubtasks.Antecedentselection:thetaskofidentifyingtheantecedentofagivenanaphor,andAnaphoratypeclassification:thetaskofjudgingwhatkindofanaphoratypeisusedforagivenanaphor,i.e.,classifyingagivenanaphorintodirectanaphoric,indirectanaphoricorexophoric.Giventhistaskdecomposition,threeunexploredissuesimmediatelycomeup:Inthispaper,weexploretheseissuestakingJapaneseasourtargetlanguage.Specifically,wefocusonanaphoraresolutionfornounphrasesmodifiedbyadefinitenessmodifier,asdetailedinthenextsection.Thispaperisorganizedasfollows.Inthenextsection,wedescribeourmotivationforthisworkmorespecifically.InSection3,wereviewpreviousworkofantecedentselectionandanaphoratypeclassification.InSection4,wegiveadetailedexplanationofourinvestigations.InSection5,thedatasetforourexperimentsisdescribed.WethenshowtheexperimentalsetupandresultsofourinvestigationsanddiscussioninSection6.Finally,theconclusionispresentedalongwithfuturework.</section>
  <section title="Motivation for our approach">Asmentioned,ananaphorcanholdadirectorindirectrelationwithitsantecedent.Occasionally,ananaphorreferstoanantecedentthatisnotinthesamediscourse.Thetermsdirectanaphoraandindirectanaphorahavebeenusedtodenotesomedifferentanaphoricphenomenainpreviousworks,e.g.directanaphorain~vieira00_defdescindicatesonlythereferencethatananaphoranditsantecedenthaveidenticalheadwords,whereasdirectanaphorain~mitkov00_anaincludesasynonymousorgeneralization/specializationlinkofananaphoranditsantecedent.Asaresult,weredefinethefollowingthreeanaphoratypestodenotetheuseofanaphoricexpressionsinourclassificationtask:directanaphora:Ananaphorreferstoitsantecedentdirectly.Inexample(),TheCDreferstothenewalbumdirectly.ex:direct_anaphoraHernewalbumwasreleasedyesterday.IwanttogettheCDassoonaspossible.indirectanaphora:Ananaphorhasanantecedentrelatedwiththeanaphorratherthanreferredto,asinexample().ex:indirect_anaphoraTheartistannounced.IwanttogettheCDassoonaspossible.TheCDreferstohernewsongindirectly.ThediscourseentitythatdirectlycorrespondstotheCDisnotintheprecedingsentence;insteadhernewsongisconsideredasanantecedentoftheCDbecauseitisassociatedwiththeCD.exophora:Ananaphorthathasnoantecedentinatextisregardedasexophoric.Anexophoricexpressionistypicallyusedinnewspaperarticles;forinstance,thedayreferstothedateofthepost.Forourtargetlanguage,Japanese,nounphrases(NP)behavesimilarlytothoseinEnglish;thatis,adefiniteNPmaybearadirectanaphoricrelationbutmayalsobearanindirectanaphoricrelationtoitsantecedentasshowninexamples()and().ex:jp_direct新しいミニバン_(i')が発売された。この新型車_(i)は燃費が非常によい。Anewminivan_(i')wasreleased.Thevehicle_(i)hasgoodgasmileage.ex:jp_indirect家具屋で机_(i')を見た。そのデザイン_(i)は素晴らしかった。Isawadesk_(i')inafurnitureshop._(i)wasmarvelous.``この新型車(thevehicle)''refersto``新しいミニバン(anewminivan)''directlyin(),while``そのデザイン(thedesign)''refersto``机(adesk)''indirectlyin().Asseenfromtheaboveexamplesex:direct_anaphora,ex:indirect_anaphoraandreportedinSection1,theanaphoratypecanbedifferentforauniqueexpression.Inotherwords,theanaphoratypehastobedisambiguatedtakingitsappearingcontextintoaccount.InJapanese,however,theproblemcanbeevenmorecomplexbecauseadefiniteNPisnotalwaysmarkedbyadefinitenessmodifier,suchasthis（この），the（その），orthat（あの）．Forexample,bareNP大統領(president)refersto韓国大統領(KoreanPresident)intextex:japanese.ex:japanese今月4日、韓国大統領_(i')が来日した。大統領_(i)は翌日の記者会見で新プランの詳細を語った。KoreanPresident_(i')visitedJapanonthe4ththismonth.The)president_(i)talkedaboutthedetailsofhisnewplanatthenewsconferencenextday.Forthisreason,itissometimesdifficultevenforhumanannotatorstodeterminethedefinitenessofabareNP.AsthefirststeptowardcompleteunderstandingofJapaneseNPanaphora,wefocusonanaphoraresolutionforNPsmarkedwitheitherthisNP（この+NP），theNP（その+NP）orthatNP（あの+NP），whichaccountforalargeproportionofoccurrencesofnominalanaphorainJapanesetexts.</section>
  <section title="Related work">Inthissection,wereviewpreviousresearchonanaphoraresolutionforantecedentselectionandanaphoratypeclassificationrespectively.InSection,welookoverhowthepreviousworkhadtakentheapproachestoantecedentselectionfordirectanaphoraandindirectanaphora.InSection,wediscussVieiraandPoesio'sworkandNakaiwa'sworkonanaphoratypeclassification.</section>
  <subsection title="Antecedent selection">Awiderangeofapproachestoanaphoraresolutionhasbeenproposedinearlierwork.Thereexisttwomainapproaches:rule-basedapproachesandmachinelearning-basedapproaches.Incontrasttotherule-basedapproachessuchas~Brennan,Lappin,Baldwin,Nakaiwa,Okumura,Mitkov,empirical,ormachinelearning-basedapproacheshavebeenshowntobeacost-efficientsolutionachievingperformancethatiscomparabletothebestperformingrule-basedsystems.Mostofthesestudiesfocusonlyonthecoreferenceresolutiontask,particularlyinthecontextofevaluation-orientedresearchprogramssuchasMessageUnderstandingConference(MUC)andAutomaticContentExtraction(ACE).Tothecontrary,themethodsforindirectanaphoraresolutionhavebeenrelativelyunexploredcomparedwithdirectanaphora.Thoseworksareimplementedbyrule-basedapproaches~[etc.]poesio97_bd,murata99_xnoy,razvan03_asocwebandlearning-basedapproaches~poesio04_lbd,encodingthecenteringtheory~grosz95_centering,lexicalresourcessuchasWordNet~fellbaum98_wnandweb-basedknowledge.Incomparisontodirectanaphora,theresolutionofindirectanaphoraisstillamuchmoredifficulttaskbecauseitisrequiredtocapturethewidevarietyofsemanticrelations(e.g.store--thediscount,drilling--theactivity).Forexample,poesio02_aclexproposedacquiringthelexicalknowledgeofthemeronymyrelationsforresolvingbridgingdescriptionsbyusingsyntacticpatternssuchastheNPofNPandNP'sNP.Recallthattheseworksarebasedontheassumptionthatthesystemknowsthatthegivenanaphorisdirectanaphoraorindirectanaphora,whichmotivatesustoexplorethedesignoftheantecedentselectionmodel.</subsection>
  <subsection title="Anaphora type classification">AsmentionedinSection1,therehasbeenlittleattentionpaidtotheissueofanaphoratypeclassification.Exceptionscanbeseenin~nakaiwa95_extraand~vieira00_defdesc.Nakaiwa'sworkfocusesontheextra-sententialresolutionofJapanesezeropronounsinmachinetranslation.Theyidentifyzeropronounswhosereferentistheextra-sententialelementsuchasI,weandyoubyusingthesemanticconstraintssuchasmodalexpressions,verbalsemanticattributes.Intheirclassification,theverbsdependedonbypronounsareimportantclues,whereasthecontextualinformationisimportantinanaphoratypeclassificationasmentionedinSection.VieiraandPoesio'swork(2000)ismotivatedbycorpusstudyfortheuseofdefinitedescriptions..Theirsystemdoesnotonlyfindanantecedentbutclassifiesagivendefinitedescriptionintothefollowingthreecategories.directanaphora:subsequent-mentiondefinitedescriptionsthatrefertoanantecedentwiththesameheadnounasthedescription;bridgingdescriptions:definitedescriptionsthateither(i)haveanantecedentdenotingthesamediscourseentity,butusingadifferentheadnoun(asinhouse...building),or(ii)arerelatedbyarelationotherthanidentitytoanentityalreadyintroducedinthediscourse;discourse-new:first-mentiondefinitedescriptionsthatdenoteobjectsnotrelatedbysharedassociativeknowledgetoentitiesalreadyintroducedinthediscourse.Comparedwithourtaxonomy,theirdefinitionofdirectanaphoraisrestrictedtothecasewhereananaphoranditsantecedenthaveanidenticalhead.Therefore,theothercases(e.g.apairofnewalbumandtheCD)arenotregardedasdirectanaphorabutsuchcasesareclassifiedintobridgingdescriptions.Thedefinitionofdiscourse-new,ontheotherhand,referstothesamenotionasourdefinitionofexophoraexceptthatthegenericuseofthedefinitearticletheasinplaythepianoisclassifiedintodiscourse-new.NotethatJapanesedefinitenessmodifiersarenotusedinsuchaway.Intheirwork,thesystemchoosesthecorrectanaphoratypeofagivendefiniteNPandifpossible,findsitsantecedentfollowingasetofhand-codedrulesonthebasisofthelexicalandsyntacticfeatures.Theprocesscanberegardedasfournotablesteps.Thesystemappliessomeheuristicsexploitinglexicalandsyntacticfeaturesbasedonhawkins78todetectnon-anaphoriccases(`unfamiliaruse'or`largersituationuse'inHawkins'swork)toananaphor.Ifthetestsucceeds,itinterpretstheanaphorasdiscourse-new.Thesystemtriestofindasame-headantecedent(i.e.,anantecedentasdirectanaphora)fromasetofpotentialcandidatesappearingintheprecedingdiscourse.Ifasuitablecandidateisfound,thesystemclassifiesananaphorasdirectanaphoraandreturnsthecandidateasitsantecedent.Therulestorecognizediscourse-new,suchas`pre-modifieruse'and`propernounuse'(e.g.theUnitedStates),areappliedtoananaphor.Ifthetestsucceeds,theanaphorisclassifiedasdiscourse-new.ThesystemtriestofindanNPassociatedwithananaphor(whichiscalledananchorintheirwork)intheprecedingdiscourse.IfsuchanNPisfound,theanaphorisclassifiedasbridgingdescriptionandjudgestheNPasitsanchor.Otherwise,thesystemdoesnotoutputanymore.Theheuristicstodetectnon-anaphoricordiscourse-newanaphorsarebasedonthesyntacticandlexicalfeatures,whiletherulesfordirectanaphoraandbridgingdescriptionssimplytrytofindanantecedent.Consequently,theirworkcanbesaidtofocusondetectingdiscourse-newdescriptionscomparedtoourwork.Theyreportedtheirsystemachieved57%recalland70%precisionintheirempiricalevaluation.Notethattheirsystemcarriesoutanaphoratypeclassificationbeforeantecedentselection.However,itremainsunexploredhowtointegrateantecedentidentificationandanaphoratypeclassificationintoanaphoraresolution,whichistobeinvestigatedasissue2andissue3,whichweaddressedinSection1.</subsection>
  <section title="Model">ThepurposeofourworkistoinvestigatethethreeunexploredissuesshowninSection1.Firstofall,weexplainourlearning-basedantecedentselectionmodelsandanaphoratypeclassificationmodels.</section>
  <subsubsection title="Classify-then-Select (C/S) model">Givenananaphor,ananaphoratypeclassifierfirstdetermineswhetheranaphorbearseitherdirectanaphora,indirectanaphoraorexophora.Iftheanaphoratypeisjudgedasdirectanaphora,thenthedirectantecedentselectionmodeliscalled.Iftheanaphoratypeisjudgedasindirectanaphora,ontheotherhand,thentheindirectantecedentselectionmodeliscalled.Thereisnoantecedentselectionmodelcalledifexophoraisselected.Byalteringthechoiceofinformationusedinanaphoratypeclassification,thefollowingtwoalternativemodelsareavailablefortheClassify-then-Selectconfiguration,eachofwhichisillustratedinFigure.a-Classify-then-Select(aC/S)Model:Classifyanaphoratypeofagivenanaphorbyusingtheanaphoranditspropertiesbeforeselectingtheantecedent.c-Classify-then-Select(cC/S)Model:Classifyanaphoratypeofagivenanaphorbyusingtheanaphor,itspropertiesandthelexicalandsyntacticinformationfromallpotentialantecedentsbeforeselectingtheantecedent.BycomparingthecC/SmodelwiththeaC/Smodel,wecanseetheeffectofusingcontextualinformationinanaphoratypeclassification.ThefeaturesetusedinthemodelsisdetailedinSection.</subsubsection>
  <subsubsection title="Select-then-Classify (S/C) model">Givenananaphor,anantecedentselectionmodelfirstselectsthemostlikelyantecedentandananaphoratypeclassifierdeterminestheanaphoratypebyutilizinginformationfromboththeanaphorandtheselectedcandidateantecedent(s).ThiswayofconfigurationhasanadvantageovertheClassify-then-Selectmodelsinthatitdeterminestheanaphoratypeofagivenanaphortakingintoaccounttheinformationofitsmostlikelycandidateantecedent.Thecandidateantecedentselectedinthefirststepcanbeexpectedtoprovidecontextualinformationusefulforanaphoratypeclassification:forexample,ifhernewsongisselectedasthebestcandidateantecedentinexampleex:atc_sample,theanaphoratypewillbeeasilyidentifiedbyusingthelexicalknowledgethatCDisthesemanticallyrelatedobjectofsong.ex:atc_sampleTheartistannounced.IwanttogettheCDassoonaspossible.Sincewehavetwochoicesofantecedentselectionmodels(i.e.,thesingleandseparatemodels)asshownin,finallyatleastthefollowingfourmodelsareavailableforanaphoratypeclassification,eachofwhichisillustratedinFigure.s-Select-then-Classify(sS/C)Model:Selectthebestcandidateantecedentwiththesinglemodelandthenclassifytheanaphoratype.d-Select-then-Classify(dS/C)Model:Selectthebestcandidateantecedentbythedirectanaphoramodelandthenclassifytheanaphoratype.Ifthecandidateisclassifiedasindirectanaphora,searchfortheantecedentwiththeindirectanaphoramodel.i-Select-then-Classify(iS/C)Model:Analogoustothed-Select-then-Classify(dS/C)modelwiththestepsreversed.p-Select-then-Classify(pS/C)Model:Callthedirectanaphoraandindirectanaphoramodelsinparalleltoselectthebestcandidateantecedentforeachcaseandthenclassifytheanaphoratypereferringtobothcandidates.ThepS/Cconfigurationprovidesrichercontextualinformationforclassifyinganaphoratypethananyotherconfigurationbecauseitcanalwaysrefertothemostlikelycandidateantecedentsofdirectanaphoraandindirectanaphora,whichmaybeusefulfordetermininganaphoratype.Weadopttheone-versus-restmethodforthethree-wayclassificationinourexperiments.Inotherwords,werecastthemulti-classclassificationproblemascombinationsofabinaryclassification.Givenananaphor,eachanaphoratypeclassifieroutputsascorethatrepresentsthelikelihoodofitsanaphoratype.Accordingtothesethreescores,weselecttheanaphoratypethatachievesthemaximumscore.Thetrainingprocedureofeachmodeldependsonwhichkindsofinformationisneeded.Toexemplifyhowtocreatetraininginstances,assumethatwehavethefollowingtexttocreatetraininginstances.training_example_(3')isanartistwhocomesfromtheUSA_(1).Sheannounced_(2')yesterday.'mlookingforwardtohearing_(2).Thebeautifulvoice_(3)willattractme.withannotatedasthefollowing:theUSA_(1)::exophorathenewsong_(2)--hernewsong_(2')::directanaphorathebeautifulvoice_(3)--MariahCarey_(3')::indirectanaphoraIntheaC/Smodel,theinformationofananaphorisneededtodetermineanaphoratype.Sincetherearethreeinstancesintraining_example,theclassifieristrainedwiththeUSA_(1)asexophoricinstance,thenewsong_(2)asdirect-anaphoricinstanceandthebeautifulvoice_(3)asindirect-anaphoricinstance.ForthecC/Sconfiguration,inadditiontotheanaphorinformation,theclassifiertakesallthepotentialantecedents.Morespecifically,theclassifieristrainedwiththepairoftheanaphoranditspotentialantecedents,hence,theUSA_(1),(MariahCarey,anartist)asexophoricinstance,thenewsong_(1),(MariahCarey,anartist,theUSA,she,hernewsong,yesterday,I)asdirect-anaphoricinstanceandthebeautifulvoice_(3),(MariahCarey,anartist,theUSA,she,hernewsong,yesterday,I,thenewsong)as-anaphoricinstance--Theprecomputation.....FortheS/Cconfiguration,weusethepairofananaphorandannotatedantecedentorpseudo-antecedentasatraininginstance.Itdependsontheanaphoratypeofinterestedanaphorandthetypeofantecedentselectionmodelthattheclassifierutilizestodeterminewhetheritisannotatedantecedentorpseudo-antecedent.Atfirst,inthesS/Cconfiguration,theclassifierselectspseudo-antecedentoftheUSA_(1)usingthesinglemodelsincethereisnoannotatedantecedentinthetrainingset.Supposeanartistisselected;wecreateatraininginstanceofexophorafromtheUSA_(1)pairedwithanartist.Fordirect-anaphoricandindirect-anaphoricinstances,wesimplytaketheanaphorandtheannotatedantecedent,i.e.thenewsong_(2),hernewsong_(2')andthebeautifulvoice_(3),MariahCarey_(3')aseachtraininginstance.Second,thecaseofthedS/Cconfigurationisslightlymorecomplex.AnalogouslytothesS/Cmodel,fortheUSA_(1),weobtainthepseudo-antecedentusingthedirectantecedentselectionmodel.Supposeanartistisselected;thepairtheUSA_(1),anartistisusedasanexophoricinstance.Forthenewsong_(2),weusethepairthenewsong_(2),hernewsong_(2')asdirect-anaphoricinstance.Forthebeautifulvoice_(3),however,sincetheannotatedantecedentMariahCarey_(3')isunlikelytobeselectedasthebestcandidateofthebeautifulvoice_(3)bythedirectantecedentselectionmodel,theclassifierdoesnotusetheannotatedexample.IndS/Canaphoratypeclassificationfashion,itisrequiredtoclassifythebeautifulvoice_(3)pairedwiththepseudo-bestcandidateselectedbythedirectantecedentselectionmodelastheindirectanaphora.Wethereforerunthedirectantecedentselectionmodeltoselectthepseudo-bestcandidate.Supposeyesterdayisselected;wecreateatraininginstanceofindirectanaphorafromthebeautifulvoice_(3)pairedwithyesterday.AnanalogousmethodappliesalsototheiS/Cconfiguration;thatis,weruntheindirectantecedentselectionmodeltoselectthepseudo-bestcandidateexceptfortheindirect-anaphoricinstancethebeautifulvoice_(3).WeassumethatMariahCareyisselectedasthepseudo-bestcandidatefortheUSA_(1)andanartistforthenewsong_(2).Wecreatethefollowingtraininginstances:theUSA_(1),MariahCareyasexophora,thenewsong_(2)anartistasdirectanaphora,thebeautifulvoice_(3),MariahCarey_(3')asindirectanaphora.Finally,inthepS/Cconfiguration,weneedtripletsananaphor,adirect-anaphoricantecedent,anindirect-anaphoricantecedent.FortheUSA_(1),sincewehavenoannotatedantecedentsfordirectandindirectanaphora,werunboththedirectandindirectantecedentselectionmodeltoselectpseudo-bestcandidatesoftheUSA_(1).SupposingthatanartistisselectedbythedirectantecedentselectionmodelandMariahCareyisselectedbytheindirectmodel,wecreateatraininginstanceofexophorafromtheUSA_(1),anartist,MariahCarey.Forthenewsong_(2),sincewehavenoannotatedantecedentforindirectanaphora,theindirectantecedentselectionmodelischosentoselectthepseudo-bestcandidate.Supposeanartistisselected;wecreateadirect-anaphorictraininginstancethenewsong_(2),hernewsong_(2'),anartist.Forthebeautifulvoice_(3),analogoustothenewsong_(2),supposingyesterdayisselectedbythedirectantecedentselectionmodel,wecreateanindirect-anaphorictraininginstancethebeautifulvoice_(3),yesterday,MariahCarey_(3').</subsubsection>
  <section title="Dataset">Fortrainingandtestingourmodels,wecreatedanannotatedcorpusthatcontains2,929newspaperarticlesconsistingof19,669sentencesfor2,320broadcasts,18,714sentencesfor609editorials,whichisthesamearticlesasintheNAISTTextCorpus~iida07_ntc.TheNAISTTextCorpusalsocontainsanaphoricrelationsofnounphrases,buttheyarestrictlyrestrictedascoreferencerelations(i.e.twoNPsmustrefertothesameentityintheworld).Forthisreason,mostNPsmarkedwithadefinitenessmodifierthatweneedarenotannotatedevenwhentwoNPshaveadirect-anaphoricrelation.Therefore,were-annotated(i)directanaphoricrelations,(ii)indirectanaphoricrelationsand(iii)exophoricnounphrasesofnounphrasesmarkedbyoneofthethreedefinitenessmodifiers,thatisthis（この），the（その），andthat（あの）．Inthespecificationofourcorpus,notonlynounphrasesbutverbphrasesarechosenasantecedents.Forexample,theverbalpredicatecalculatesinadvanceisselectedasanantecedentoftheprecomputationinexampleverbal.verbalシステムは前もって値を計算する_(i')。その前計算_(i)はシステムの性能を大幅に向上させている。Thesystemcalculates_(i')thevalueinadvance._(i)significantlyimprovesitsperformance.Wealsoannotatedanaphoricrelationsinthecasewhereananaphorisanaphoricwithmorethantwoantecedents.Forexample,welabelanaphoricrelationsforthetwopairsofNPsmousedevices--theotheritemsandkeyboards--theotheritemsasseeninexamplemultiple_antecedent.multiple_antecedentABCコンピュータはマウス_(i')とキーボード_(j')の値下げを発表した。その他の商品_(i,j)については値下げをしないと主張した。ABCcomputerannouncedthattheyreducedthepriceofmousedevices_(i')and_(j').Theyclaimedthattheywouldnotcutthepriceoftheotheritems_(i,j).Finally,weobtained1,264instancesofdirectanaphora,2,345instancesofindirectanaphora,and470instancesofexophora.ThedetailedstatisticsareshowninTable~.Toassessthereliabilityoftheannotation,weestimateditsagreementratewiththetwoannotatorsfrom418examplesintermsofKstatistics~siegel88_kappa.ItresultedinK=0.73,whichindicatesgoodreliability.Formeasuringtheagreementratioofantecedentselection,weused322examples(109fordirectanaphoraand213forindirectanaphora)whoseanaphoratypesareidenticallyidentifiedbybothtwoannotators.Theagreementratiowascalculatedastheagreement.Whenmultipleantecedentsareannotated,thecriterionofmatchingisthatoneoftheantecedentsisatleastidenticalwithoneoftheantecedentsannotatedbytheotherannotator.accordingtothefollowingequation:Agreement=.Theagreementratioforannotatingdirect-anaphoricrelationobtained80.7%(88/109).However,for21exampleswhoseantecedentsarenotidenticallyselectedbytheannotators,ouranalysisrevealedthat52.4%(11/21)oftheseexamplesarecaseswheretheantecedentsannotatedbythetwoannotatorsaredifferentbutinanaphoricrelation,whichshouldberegardedasanagreement.Therefore,theinter-annotatoragreementratioofdirect-anaphoricrelationachieves90.8%(99/109),whichindicatesgoodreliabilitybutitisrequiredtoconsideranaphoricchainsintheannotationprocedure.Theagreementratioofindirect-anaphoricrelation,ontheotherhand,obtainedacomparativelylowerratioof62.9%(134/213).Oneofthetypicallynon-matchingcasesisshowninexampleex:unmatched_indirect.ex:unmatched_indirect政府_(i)は明日までに委員_(j)を決める方針だ。その人選_(k)は我々にも影響が及ぶだろう。_(i)isgoingtodetermine_(j)bytomorrow.Probablytheelection_(k)willalsoaffectus.Inthisexample,boththegovernmentandthememberofthecommitteeareconsideredtobeassociatedobjectsoftheelection,whichindicatesthatmultiplediscourseelementsareoftenassociatedwithoneanaphorinvarioussemanticrelationsinindirectanaphora.Weshouldreflectonsuchproblemswhentheannotationschemeandtaskdefinitionofindirectanaphoraresolutionareargued,includingbridgingreferenceresolution.</section>
  <section title="Evaluation">WeconductempiricalevaluationsinordertoinvestigatethethreeissuesshowninSection1.First,wecomparetwoantecedentselectionmodels,thesingleandseparatemodelsdescribedinSectioninordertofindoutissue1,i.e.,whetheranantecedentselectionmodelshouldbetrainedseparatelyfordirectanaphoraandindirectanaphora.Second,theanaphoratypeclassificationmodelsdescribedinSectionareevaluatedtoexplorewhatinformationhelpswiththeanaphoratypeclassification(issue2).Finally,weevaluatetheoverallaccuracyoftheentireanaphoraresolutiontasktoexplorehowthemodelscanbebestconfigured(issue3).Inourexperiments,weusedanaphorswhoseantecedentisaheadofNPthatappearsintheprecedingcontextoftheanaphor(i.e.,cataphoraisignored),onlytakingarticlesinthebroadcastdomainintoaccount.Therefore,weused572instancesofdirectanaphora,878instancesofindirectanaphoraand248instancesofexophora.Theevaluationwascarriedoutby10-foldcross-validation.Inourevaluationofantecedentselection,ifaselectedantecedentisinthesamedirect-anaphoricchainasthelabeledantecedent,thisselectedantecedentisevaluatedascorrect.Forcreatingbinaryclassifiersusedinantecedentselectionandanaphoratypeclassification,weadoptedSupportVectorMachines~vapnik95_svmhttp://svmlight.joachims.org/,withapolynomialkernelofdegree2anditsdefaultparameters.</section>
  <subsection title="Feature set">Thefeaturesetforantecedentselectionisdesignedbasedontheofcoreferenceresolution~[etc.]iida05_coref,1073102,soon01_coref,denis-baldridge:2008:EMNLP,1075119assummarizedinTable~.Inaddition,weintroducethefollowinglexicalsemanticfeatures:WN_SEMANTIC_RELATION:Inordertocapturevarioussemanticrelationsbetweenananaphoranditsantecedent,weincorporatethebinaryfeaturesthatrepresentthesemanticrelationfoundintheJapaneseWordNet0.9~isahara08_wnja.SYNONYMOUSandIS_HYPONYM_OF_ANAPHOR:Werecognizesynonymousandhyper-hyponymrelationsbyusingaverylargeamountofsynonymandhypernym-hyponymrelations(aboutthreemillionhypernymyrelationsandtwohundredthousandsynonymyrelations)automaticallycreatedfromWebtextsandWikipedia~sumi08_hypowiki.BGH_ID,BGH_COMMON_ANC:WeincorporatethelexicalinformationobtainedfromtheBunruiGoiHyothesaurus~nlsi64_bgh.Weencodetheinformationastwotypes:(i)binaryfeaturesthatrepresentthesemanticclassID,and(ii)areal-valuedfeaturethatindicatesthedepthofthelowestcommonancestorofananaphoranditscandidate.SIMILARITY:Torobustlyestimatesemanticsimilaritiesbetweenananaphoranditscandidateantecedent,weadoptthecosinesimilaritybetweenananaphorandcandidateantecedent,whichiscalculatedfromacooccurrencematrixof(n,c,v),wherenisanounphraseappearinginanargumentpositionofaverbvmarkedbyacaseparticlec.Thecooccurrencesarecountedfromtwodecadesworthofnewspaperarticles,andtheirdistributionP(n,c,v)isestimatedbypLSI~hofmann99_plsiwith1,000hiddentopicclassestoovercomethedatasparsenessproblem.PMI:Thedegreeofindirect-anaphoricassociationbetweenananaphorANAandcandidateCNDiscalculateddifferentlydependingonwhetherCNDisanounorpredicate.Forthecaseofanoun,wefollowtheliteratureofindirectanaphoraresolution~[etc.]poesio04_lbd,murata99_xnoytocapturesuchsemanticrelationsaspart-whole.TheassociativenessiscalculatedfromthecooccurrencesofANAandCNDinthepatternof``CNDのANA(ANAofCND)''.FrequenciesofcooccurrencecountsareobtainedfromtheWebJapaneseN-gramVersion1~kudo07_gng.Forthecaseofapredicate,ontheotherhand,theassociativenessiscalculatedfromthecooccurrencesofANAandCNDinthepatternwhereCNDsyntacticallydependson(i.e.modifies)ANA(inEnglish,thepatternlike``ANAthat(subj)CND'').Ifwefindmanyoccurrencesof,forexample,``闘う(tofight)''modifying``夢(adream)''inacorpus,then``夢(adream)''islikelytorefertoaneventreferredtoby``闘う(tofight)''asindream.dreamチャンピオンと闘い_(i')たい。その夢_(i)は実現すると信じている。Iwantto_(i')thechampion.Ibelievethedream_(i)willcometrue.Foranaphoratypeclassification,weuseadifferentfeaturesetdependingontheconfigurationdescribedin.FortheClassify-then-Selectconfiguration,assummarizedinTable~,itincludessuchfeaturesasHAS_SYNONYM_OF_ANAPHORandHAS_STRING_MATCHED,whichcapturecontextualinformationencodedfromallpotentialantecedents,basedontheliterature~[etc.]vieira00_defdesc.FortheSelect-then-Classifyconfigurations,ontheotherhand,ananaphoratypeclassifierusesthebestcandidate(s)selectedinantecedentselectionphaseasitscontextualinformation,insteadoftheinformationencodedfromallthepotentialantecedents.ThissortofinformationisencodedasfeaturesanalogoustothatforantecedentselectionassummarizedinTable~.</subsection>
  <subsection title="Results of antecedent selection">TheresultsofantecedentselectionareshowninTable.TheresultsindicatethattheSeparateModeloutperformstheSingleModelontwoanaphoratypes.Asforissue1,weconcludethattheinformationusedforantecedentselectionshouldbeseparatedforeachanaphoratypeandtheselectionmodelsshouldbetrainedforeachanaphoratype.WethereforediscardtheSingleModelforthefurtherexperiments(i.e.discardingsS/Cmodel).Wealsoillustratethelearningcurvesofeachmodel,showninFigure.Reducingthetrainingdatato50%,25%,12.5%,6.25%and3.13%,weconductedtheevaluationoverthreerandomtrialsforeachsizeandaveragedtheaccuracies.Figureindicatesthatinthedirectantecedentselectionmodeltheaccuracybecomesbetterasthetrainingdataincrease,whereastheincreaseoftheindirectonelooksdifficulttoimprovealthoughourdatasetincludedmoreinstancesforindirectanaphorathanforthedirectone.Theseresultssupportthefindinginpreviousworkthatanindirectanaphoraishardertoresolvethandirectanaphoraandsuggestthatweneedamoresophisticatedantecedentselectionmodelforindirectanaphora.Ourerroranalysisrevealedthatamajority(about60%)oferrorsindirectanaphorawerecausedbythefactthatbothcorrectandincorrectcandidatesbelongtothesamesemanticcategory.Exampled_errorshowsatypicalselectionerror:d_error私は映画_(j)の知識がないが、『フランケンシュタイン』_(i')ぐらいは知っている。この映画_(i)は、本当に名作だ。Idon'thavegoodknowledgeofmovies_(j)butstillknowof``Frankenstein''_(i').thinkthismovie_(i)isindeedagreatmasterpiece.wherethewrongcandidate``映画_(j)(movies_(j))''wasselectedastheantecedentof``この映画_(i)(thismovie_(i))''.Ascanbeimaginedfromthisexample,thereisstillroomforimprovementbycarefullytakingintoaccountthiskindoferrorusingothercluessuchasinformationfromsalience.Forindirectanaphora,weanalyzedourresourcetocapturetheassociativenessbetweenananaphoranditsantecedent,encodedasPMIinthefeatureset.Ouranalysisindicatedthatabouthalfofthepattern`ANTofANA',whichoccurredinthetestdata,hadbeenassignedaminusvalue,i.e.,nopositiveassociationfoundbetweenananaphoranditsantecedentfortheresourcewhenapplyingPMI.Toevaluatethecontributiontoourmodel,weconductedanevaluationwherethePMIfeaturesetwasdisabled.Asaresultofthisadditionalevaluation,themodelobtained51.4%(451/878),whichisnosignificantdifferencecomparedwiththeoriginalaccuracy.Weneedtofindmoreusefulcluestocapturetheassociativenessbetweenananaphorandtherelatedobjectinindirectanaphora.Thelowqualityofourannotatingdataofindirect-anaphoricrelation,asmentionedinSection~,mightbealsooneofthereasonsforthelowaccuracyofindirectanaphoraresolution.</subsection>
  <subsection title="Results of anaphora type classification">Now,wemoveontoissue2andissue3.TheresultsofanaphoratypeclassificationareshowninTable.ThecC/Smodelobtainedthelowestaccuracyof73.6%,whichindicatesthatcontextualinformationfeaturesproposedintheliterature~[etc.]vieira00_defdesc,suchasHAS_STRING_MATCHED,werenotactuallyinformative.NotethattheperformanceofthecC/SmodelislowerthantheaC/Smodel,whichidentifiesananaphoratypebyusingonlytheinformationofananaphor.Ontheotherhand,thedS/Cmodelsuccessfullyimproveditsperformancebyusingtheinformationofselectedcandidateantecedentasthecontextualinformation.ThedS/Cmodelachievedthebestaccuracyof78.7%,whichindicatesthattheselectedbestcandidateantecedentprovidesusefulcontextualinformationforanaphoratypeclassification.TheiS/CandpS/Cmodels,however,donotimprovetheirperformanceaswellasthedS/Cmodelalthoughitusestheselectedbestcandidate(s)information.ItisconsideredthatthefundamentalreasonisthepoorperformanceoftheindirectantecedentselectionmodelasshowninTable,i.e.,theindirectantecedentselectionmodeldoesnotprovidecorrectcontextualinformationtoanaphoratypeclassification.ItisexpectedthatalltheS/Cmodelsgetbetterperformancewhentheantecedentselectionmodelimproves.TheidentificationofexophoraisamoredifficulttaskthantheotheranaphoratypesasshowninthelowF-measureandrecallinTable.OuranalysisfortheexophoricinstancesmisclassifiedbythedS/Cmodelrevealedthatthetypicalerrorsweretemporalexpressionssuchas年(year),日(day)and時期(period).Weobservedthatsuchexpressionsoccurredasnotonlyexophorabutalsoastheotheranaphoratypesmanytimes,assummarizedinTable,whichindicatesthattheinterpretationoftemporalexpressionisalsoimportantforidentifyingtheotheranaphoratypes.Inourcurrentframework,however,itishardtorecognizesuchexpressionsaccuratelysincethepreciserecognitionoftemporalexpressionsisrequiredtoidentifyarelationbetweenaneventspecifiedbytheexpressionandtheotherevents.Weconsiderintegratingtheframeworkoftemporalrelationidentification,whichhasbeenproposedintheevaluation-orientedstudiessuchasTempEval,withanaphoratypeclassificationframework,whichwillbeourfuturework.</subsection>
  <subsection title="Results of overall anaphora resolution">Finally,weevaluatedtheoverallaccuracyoftheentireanaphoraresolutiontaskgivenby:Accuracy=.TheresultsareshowninTable~.Again,thedS/Cmodelachievedthebestaccuracy,whichissignificantlybetterthantheClassify-then-Selectmodels.</subsection>
  <section title="Conclusion">WehaveaddressedthethreeissuesofnominalanaphoraresolutionforJapaneseNPsmarkedbyadefinitenessmodifierundertwosubtasks,i.e.,antecedentselectionandanaphoratypeclassification.Theissuesweaddressedwere:(i)howtheantecedentselectionmodelshouldbedesigned,(ii)whatinformationhelpsanaphoratypeclassification,and(iii)howtheantecedentselectionandanaphoratypeclassificationshouldbecarriedout.Ourempiricalevaluationsshowedthattheseparatemodelachievedbetteraccuracythanthesinglemodel,andthed-Select-then-Classifyandp-Select-then-Classifymodelsgivethebestresults.Wehavemadeseveralfindingsthroughtheevaluations:(i)anantecedentselectionmodelshouldbetrainedseparatelyforeachanaphoratypeusingtheinformationusefulforidentifyingitsantecedent,(ii)thebestcandidateantecedentselectedbyanantecedentselectionmodelprovidescontextualinformationusefulforanaphoratypeclassification,and(iii)theantecedentselectionshouldbecarriedoutbeforeanaphoratypeclassification.However,thereisstillconsiderableroomforimprovementinbothsubtasks.Ourerroranalysisforantecedentselectionrevealsthatthewrongantecedent,whichbelongstothesamesemanticcategoryascorrectantecedent,islikelytobeselectedwhileselectingdirect-anaphoricantecedent,andtheassociationmeasureofindirect-anaphoricrelatednessdoesnotcontributetoselectingtheindirect-anaphoricantecedent.Wewillincorporatetheinformationthatcapturessalienceandvariousnoun-nounrelatednessintoantecedentselectioninfuturework.Foranaphoratypeclassification,ouranalysisrevealsthattemporalexpressionstypicallycauseerrorintheidentificationofexophora.Torecognizesuchexpressionsprecisely,wewillconsiderintegratingtemporalrelationidentificationwithanaphoratypeclassification.Ourfutureworkalsoincludestakinggeneralnounphrasesintoaccountinanaphoraresolution.wouldliketothankthereviewersofthispaperfortheirhelpfulcomments.document</section>
</root>
