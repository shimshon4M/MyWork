    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.2}
\usepackage[dvips]{graphicx}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{multirow}
\usepackage{amsmath,amssymb}
\usepackage[noreplace,multi]{otf}
\usepackage{slashbox}



\Volume{17}
\Number{2}
\Month{April}
\Year{2010}


\received{2009}{7}{1}
\revised{2009}{10}{1}
\rerevised{2009}{10}{23}
\accepted{2010}{2}{22}

\setcounter{page}{3}


\jtitle{中国語への翻字における関連語抽出の応用}
\jauthor{黄　　海湘\affiref{Author_1} \and 藤井　　敦\affiref{Author_2}}
\jabstract{
外国語を翻字するときに，日本語や韓国語ではカタカナやハングルなどの表音文字を用いるのに対して，中国語では漢字を用いる．
しかし，漢字は表意文字であるため，発音が同じでも漢字によって意味や印象は異なる可能性がある．
この問題を解消するために，ユーザが与えた関連語に基づいて翻字に使用する漢字を選択する手法がある．
しかしユーザの負担が大きいため，本研究は，翻字対象の関連語をWorld Wide Webから自動的に抽出し，中国語への翻字に使用する手法を提案する．
評価実験によって提案手法の有効性を示す．
}
\jkeywords{翻字，意味，印象，表意文字，関連語}


\etitle{An Application of Related Term Extraction to Transliteration into Chinese}
\eauthor{HaiXiang Huang\affiref{Author_1} \and Atsushi Fujii\affiref{Author_2}} 
\eabstract{
To transliterate foreign words, in Japanese and Korean, phonograms such as Katakana and Hangul are used. In Chinese, the pronunciation of a source word is spelled out with Kanji characters. However, because Kanji comprises ideograms, different characters are associated with the same pronunciation but can potentially convey different meanings and impressions. 
To select appropriate Kanji characters, an existing method requests a user to provide one or more related terms, but it is expensive.
In this paper, we propose a method to select characters in transliteration into Chinese using related terms automatically extracted from the World Wide Web.
We show the effectiveness of our method experimentally.
}
\ekeywords{Transliteration, Meaning, Impression, Ideograms, Related terms}

\headauthor{黄，藤井}
\headtitle{中国語への翻字における関連語抽出の応用}

\affilabel{Author_1}{筑波大学大学院図書館情報メディア研究科}{Graduate School of Library, Information and Media Studies, University of Tsukuba}
\affilabel{Author_2}{東京工業大学大学院情報理工学研究科}{Graduate School of Information Science and Engineering, Tokyo Institute of Technology}



\begin{document}
\maketitle


\section{はじめに}

科学技術や文化の発展に伴い，新しい用語が次々と作られインターネットによって世界中に発信される．
外国の技術や文化を取り入れるために，これらの用語を迅速に母国語へ翻訳する必要性が高まっている．
外国語を翻訳する方法には「意味訳」と「翻字」がある．
意味訳は原言語の意味を翻訳先の言語で表記し，翻字は原言語の発音を翻訳先の言語における音韻体系で表記する．
専門用語や固有名詞は翻字されることが多い．

日本語や韓国語はカタカナやハングルなどの表音文字を用いて外国語を翻字する．
それに対して，中国語は漢字を用いて翻字する．
しかし，漢字は表意文字であるため，同じ発音に複数の文字が対応し，文字によって意味や印象が異なる．
その結果，同音異義の問題が発生する．
すなわち，翻字に使用する漢字によって，翻字された用語に対する意味や印象が変わってしまう．

例えば，飲料水の名称である「コカコーラ（Coca-Cola）」に対して様々な漢字列で発音を表記することができる．
公式の表記は「\UTFC{53EF}\UTFC{53E3}\UTFC{53EF}\UTFC{4E50} /ke--ko--ke--le/」であり，原言語と発音が近い．
さらに，「\UTFC{53EF}\UTFC{53E3}」には「美味しい」，「\UTFC{53EF}\UTFC{4E50}」には「楽しい」という意味があり，飲料水として良い印象を与える．
「Coca-Cola」の発音に近い漢字列として「\UTFC{53E3}\UTFC{5361}\UTFC{53E3}\UTFC{62C9} /ko--ka--ko--la/」もある．
しかし，「\UTFC{53E3}\UTFC{5361}」には「喉に詰まる」という意味があり，飲料水の名称として不適切である．

また，「人名」や「地名」といった翻字対象の種別によっても使用される漢字の傾向が異なる．
例えば，「\UTFC{5B9D}」と「\UTFC{5821}」の発音はどちらも/bao/である．
「\UTFC{5B9D}」には「貴重」や「宝物」などの意味があり中国語で人名や商品名によく使われるのに対して，「\UTFC{5821}」には「砦」や「小さい城」などの意味があり中国語で地名によく使われる．

以上の例より，中国語への翻字においては，発音だけではなく，漢字が持つ意味や印象，さらに翻字対象の種別も考慮して漢字を選択する必要がある．
この点は，企業名や商品名を中国に普及させてブランドイメージを高めたい企業にとって特に重要である．

翻字に関する既存の手法は，「狭義の翻字」と「逆翻字」に大別することができる．
「狭義の翻字」は，外国語を移入して新しい用語を生成する処理である\cite{Article_10,Article_11,Article_16,Article_18}.
「逆翻字」は既に翻字された用語に対する元の用語を特定する処理である\cite{Article_01,Article_02,Article_04,Article_05,Article_06,Article_07,Article_08,Article_09,Article_12,Article_14}．
逆翻字は主に言語横断検索や機械翻訳に応用されている．どちらの翻字も発音をモデル化して音訳を行う点は共通している．
しかし，逆翻字は新しい用語を生成しないため，本研究とは目的が異なる．
本研究の目的は狭義の翻字であり，以降，本論文では「翻字」を「狭義の翻字」の意味で使う．

中国語を対象とした翻字の研究において，\cite{Article_10,Article_16,Article_18}は人名や地名などの外来語に対して，発音モデルと言語モデルを単独または組み合わせて使用した．
それに対して，\cite{Article_11,Article_19,Article_21}は翻字対象語の意味や印象も使用した．

\cite{Article_11}は，外国人名を翻字する際に，対象人名の言語（日本語や韓国語など），性別，姓名を考慮した．
しかし，この手法は人名のみを対象としているので企業名や商品名などには利用できない．
\cite{Article_19}は翻字対象語の発音と印象を考慮し，\cite{Article_21}は翻字対象語の種別も考慮した．
\cite{Article_19}と\cite{Article_21}では，翻字対象の印象を表す「印象キーワード」に基づいて，翻字に使用する漢字を選択する．
しかし，印象キーワードはユーザが中国語で与える必要がある．

本研究は，\cite{Article_19}と\cite{Article_21}の手法に基づいて，さらに印象キーワードを人手で与える代わりにWorld Wide Webから自動的に抽出して中国語への翻字に使用する手法を提案する．
以下，\ref{sec:method}で本研究で提案する手法について説明し，\ref{sec:exp}で提案手法を評価する．


\section{提案する翻字手法}\label{sec:method}

\subsection{概要}\label{sec:overview}

\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f1.eps}
\end{center}
 \caption{提案する翻字手法の概要}
 \label{fig:1}
\end{figure}

本研究で提案する翻字手法の概要を図\ref{fig:1}に示す． 
図\ref{fig:1}は，\cite{Article_21}と同様に左から「発音モデル」，「印象モデル」，「言語モデル」に大別される．
図\ref{fig:1}において，太い破線で囲まれた部分が本研究の特長である．
以下，\mbox{図\ref{fig:1}}に基づいて翻字手法について説明する．
本手法への入力は2つある．
1つ目は，翻字対象となる外国語の用語である．
2つ目は，翻字対象の種別として「人名」，「企業名」，「商品名」などのカテゴリを入力する．
本手法はこれらの入力に対して，1つ以上の漢字列を翻字の候補として出力する．
\cite{Article_21}では，3つ目の入力として翻字対象の意味や印象を表す「印象キーワード」を人手で入力する必要がある．
しかし，本手法ではWebから関連語を自動抽出する．
「発音モデル」，「印象モデル」，「言語モデル」に基づく翻字手法や関連語抽出手法そのものに新規性はない．
本研究の貢献は，{\cite{Article_21}の翻字手法に関連語抽出手法を統合して，
ユーザが印象キーワードを与える負担を削減する点にある．

図\ref{fig:1}の最左では，「発音モデル」によって翻字対象と発音が似ている漢字列とそれぞれの確率が得られており，これらの漢字列が翻字候補となる．
現在，翻字対象となる外国語として日本語のカタカナ語を対象としている．
カタカナ語は発音表記であるローマ字に変換することが容易だからである．
ただし，ローマ字表記に変換することができれば，他の言語を入力することも可能である．

図\ref{fig:1}の中央では，「印象モデル」によって，自動抽出した翻字対象の関連語に関連する漢字とそれぞれの確率が得られている．
図\ref{fig:1}では，「\UTFC{559C}\UTFC{7231}」，「\UTFC{666E}\UTFC{53CA}」，「\UTFC{666E}\UTFC{901A}」，「\UTFC{597D}」といった関連語の集合を用いて，「\UTFC{7231}」，「\UTFC{666E}」，「\UTFC{597D}」といった漢字とそれぞれの確率が得られている．

\cite{Article_19}と\cite{Article_21}では，関連語（印象キーワード）はユーザが中国語で与える必要がある．
したがって，ユーザは翻字対象が指す実体や概念について知っていなければならず，また，中国語も知っていなければならない．
その結果，システムを利用できるユーザが制限されてしまう．
本研究は関連語を自動抽出して，この問題を解消する．
なお，「印象キーワード」という用語は\cite{Article_21}に従っており，実際には人手で与えた関連語である．

図\ref{fig:1}の最右では，入力された種別に対応する言語モデルとして「企業名言語モデル」が選ばれている．

発音モデルで得られた翻字候補は複数になる場合があるため，それぞれに順位を付ける．
具体的には，発音モデルで得られた確率を印象モデルおよび言語モデルで得られた漢字の確率と統合して，翻字対象に順位を付ける．

以下，\ref{sec:prob}で確率的な漢字選択手法の全体像について説明する．
\ref{sec:pronu}〜\ref{sec:categ}で「発音」，「印象」，「言語」のモデル化について個別に説明し，\ref{sec:auto}で関連語の抽出について説明する．
\ref{sec:prob}〜\ref{sec:categ}は\cite{Article_21}に基づいている．


\subsection{漢字選択ための確率モデル}\label{sec:prob}

本研究における翻字の目的は，「翻字対象のローマ字表記$R$」，「関連語$W$」，「翻字対象の種別$C$」が与えられた条件のもとで，$P(K|R,W,C)$が最大になる漢字列$K$を選択することである．
式(\ref{eq:Bayes})を用いて$P(K|R,W,C)$を計算する．
\pagebreak
\begin{equation}
 \begin{split}
  P(K|R,W,C)&=\frac{P(R,W,C|K)\times P(K)}{P(R,W,C)} \\
            &\approx \frac{P(R|K)\times P(W|K)\times P(C|K)\times P(K)}{P(R,W,C)}\\
            &\propto P(R|K)\times P(W|K)\times P(C|K)\times P(K)\\
            &= P(R|K)\times P(W|K)\times P(C,K)\label{eq:Bayes}
 \end{split}
\end{equation}
式(\ref{eq:Bayes})の1行目はベイズの定理を用いた変形であり，2行目では$R$，$W$，$C$が互いに独立であると仮定している．
$P(R,W,C)$は$K$に依存しないため無視する．
最終的に，$P(K|R,W,C)$は$P(R|K)$，$P(W|K)$，$P(C,K)$の積として近似され，それぞれ「発音モデル」，「印象モデル」，「言語モデル」と呼ばれる．


\subsection{発音モデル}\label{sec:pronu}

発音モデルは，中国語の漢字列$K$が与えられた条件のもとで，ローマ字表記$R$が生成される条件付き確率$P(R|K)$であり，式(\ref{eq:Pronun})を用いて計算する．
ローマ字表記はヘボン式を使用し，中国語のピンイン$Y$を中間言語として，中国語の漢字に変換する．
\begin{equation}
 \begin{split}
  P(R|K)&\approx P(R|Y)\times P(Y|K) \\
        &\approx\prod_{i=1}^N P(r_{i}|y_{i})\times\prod_{i=1}^N P(y_{i}|k_{i})\label{eq:Pronun}
 \end{split}
\end{equation}
$r_{i}$，$y_{i}$，$k_{i}$はそれぞれローマ字の音節，ピンインの音節，漢字１文字である．
例えば，漢字列「\UTFC{7231}\UTFC{666E}\UTFC{751F}」が与えられた条件のもとで，ローマ字の音節「e pu son」が生成される確率を計算する場合は，ピンインの音節「ai pu sheng」を中継して，式(\ref{eq:Cyukei})のように計算する．
\begin{eqnarray}
&&P(\textrm{e pu son}|\textrm{\UTFC{7231}\UTFC{666E}\UTFC{751F}})\label{eq:Cyukei}\nonumber\\
&&=\!P(\textrm{e\,pu\,son}|\textrm{ai\,pu\,sheng})\!\times \!P(\textrm{ai\,pu\,sheng}|\,\textrm{\UTFC{7231}\UTFC{666E}\UTFC{751F}}) \nonumber\\
&&=\!P(\textrm{e}|\textrm{ai})\!\times \!P(\textrm{pu}|\textrm{pu})\!\times \!P(\textrm{son}|\textrm{sheng})\!\times \!P(\textrm{ai}|\textrm{\UTFC{7231}})\times \!P(\textrm{pu}|\textrm{\UTFC{666E}})\!\times \!P(\textrm{sheng}|\textrm{\UTFC{751F}})
\end{eqnarray}

\begin{table}[b]
\caption{ローマ字音節とピンイン音節の対応頻度と確率}
\label{table:Pry}
\input{02table01.txt}
\end{table}
\begin{table}[b]
\caption{ピンイン音節と漢字の対応頻度と確率}
\label{table:Pyk}
\input{02table02.txt}
\end{table}

式(\ref{eq:Pronun})中の$P(r_{i}|y_{i})$と$P(y_{i}|k_{i})$は式(\ref{eq:Ryk})を用いて計算する．
\begin{equation}
 \begin{split}
  P(r_{i}|y_{i})=\frac{F(r_{i},y_{i})}{\displaystyle{\sum_{j}}F(r_{j},y_{i})} \\
  P(y_{i}|k_{i})=\frac{F(y_{i},k_{i})}{\displaystyle{\sum_{j}}F(y_{j},k_{i})}\label{eq:Ryk}
 \end{split}
\end{equation}
$F(r_{i},y_{i})$はローマ字の音節$r_{i}$とピンインの音節$y_{i}$が対応する頻度であり，$F(y_{i},k_{i})$はピンインの音節$y_{i}$と漢字$k_{i}$が対応する頻度である．
これらの頻度を計算するために，日中対訳辞書\cite{Book_02}のピンイン付き中国語と対応するカタカナ語$1,136$対を参考にして，ローマ字とピンインの音節，ピンインの音節と漢字を人手で対応付けた．
これらの一部をそれぞれ表１と2に示す．
表\ref{table:Pry}と\ref{table:Pyk}において，中国語のピンインには，発音の四声に基づいて1〜4の識別子が付けられている．
表\ref{table:Pry}では，1つのローマ字音節$r_{i}$に複数のピンインの音節$y_{i}$が対応している．
例えば，ローマ字の「a」に対して，3種類のピンイン音節「a1」，「ai4」，「an1」が対応している．
表\ref{table:Pyk}では，確率$P(y_{i}|k_{i})$は$1.00$になる場合が多く，一般的には１つの漢字は１つのピンインと対応することが分かる．
しかし，「\UTFC{4F5B}」と「\UTFC{4F3D}」はそれぞれ2つのピンインと対応している．

翻字を行う際に，ローマ字表記$R$の分割が複数ある場合は，すべての可能な分割を考慮する．
例えば，「epuson（エプソン）」は，二つのピンイン列と一致して次のように分割される．
\begin{itemize}
\item e pu son: ai pu sheng
\item e pu so n: ai pu sou an
\end{itemize}



\subsection{印象モデル}\label{sec:meaning}

印象モデルは，漢字列$K$が与えられた条件のもとで，関連語列$W$が生成される条件付き確率$P(W|K)$である．
$W$と$K$をそれぞれ単語$w_{i}$と漢字１文字$k_{j}$の単位で分割して，$P(W|K)$を$P(w_{i}|k_{j})$に基づいて近似する．
しかし，$w_{i}$と$k_{j}$の数が常に同じであるとは限らないため，式(\ref{eq:Ass})を用いて$P(W|K)$を計算する．
すなわち，各$k_{j}$について$P(w_{i}|k_{j})$が最大となる$w_{i}$だけを考慮する．
\begin{equation}
 P(W|K)\approx {\displaystyle \prod_{j}}\max_{i}P(w_{i}|k_{j})\label{eq:Ass}
\end{equation} 

\begin{table}[b]
\caption{$P(w_{i}|k_{j})$の例}
\label{table:Pwk}
\input{02table03.txt}
\end{table}

表\ref{table:Pwk}に漢字3つと関連語4つに関する$P(w_{i}|k_{j})$を示す．
表中の「--」は，$w_{i}$と$k_{j}$が対応しないことを示している．
表\ref{table:Pwk}の例において，$P(W|K)$は式(\ref{eq:wk})のように計算される．
\begin{eqnarray}
&&P(\textrm{\UTFC{559C}\UTFC{7231} \UTFC{666E}\UTFC{53CA} \UTFC{666E}\UTFC{901A} \UTFC{751F}\UTFC{52A8}}|\textrm{\UTFC{7231}\UTFC{666E}\UTFC{751F}})\label{eq:wk} \nonumber\\
&&=\!P(\textrm{\UTFC{559C}\UTFC{7231}}|\textrm{\UTFC{7231}})\!\times \!P(\textrm{\UTFC{666E}\UTFC{53CA}}|\textrm{\UTFC{666E}})\!\times \!P(\textrm{\UTFC{751F}\UTFC{52A8}}|\textrm{\UTFC{751F}})=0.02 \times 0.03 \times 0.03\\
&&=0.000018  \nonumber
\end{eqnarray}

$P(w_{i}|k_{j})$は式(\ref{eq:Ass2})を用いて計算する．
\begin{equation}
P(w_{i}|k_{j})=\frac{F(w_{i},k_{j})}{{\displaystyle\sum_{w}}F(w,k_{j})}\label{eq:Ass2}
\end{equation}
$F(w_{i},k_{j})$は$w_{i}$ と$k_{j}$の共起頻度であり，本研究では漢字字典を用いて計算する．
すなわち，漢字字典の見出し漢字を$k_{j}$として，$k_{j}$の意味記述に使用されている単語を$w_{i}$とする．
中国語の漢字字典\footnote{\UTFC{65B0}\UTFC{534E}\UTFC{5B57}\UTFC{5178}\UTFC{7535}\UTFC{5B50}\UTFC{7248}（新華字典電子版）v1.0.}から外来語の表記に良く使われる見出し漢字$599$文字を人手で選択し，見出し漢字の意味記述をSuperMorpho\footnote{http://www.omronsoft.com/}で形態素解析して，単語と見出し漢字の共起頻度を計算した．\
表~\ref{table:kanji2word}に$F(w_{i},k_{j})$の例を示す．
表\ref{table:kanji2word}では，$P(w_{i}|k_{j})$が高いほど，漢字と単語の関係が強いことを示している．
例えば，「\UTFC{9AD8}（高い）」，「\UTFC{597D}（良い）」，「\UTFC{4E50}（楽しい）」という3つの漢字$k_{j}$に対して$P(w_{i}|k_{j})$が最も高い単語$w_{i}$は，それぞれ「\UTFC{52A0}\UTFC{9AD8}（高くする）」，「\UTFC{597D}\UTFC{5403}（おいしい）」，「\UTFC{4E50}\UTFC{4E8E}（喜び）」である．
ここで括弧内は各中国語に対する日本語訳を示す．

\begin{table}[t]
\caption{漢字辞典における漢字と単語との共起頻度と確率}
\label{table:kanji2word}
\input{02table04.txt}
\end{table}


\subsection{言語モデル}\label{sec:categ}

言語モデル$P(C,K)$は，用語の種別$C$に関するコーパスを用いてモデル化する．
具体的には，式(\ref{eq:Language})を用いて計算する．
\begin{equation}
P(C,K)=P(C) \!\times \!P(K|C) \propto P(K|C)\label{eq:Language}
\end{equation}
$P(C)$は$K$に依存しないので無視する．
原理的には，種別$C$のコーパスが与えられた条件のもとで，漢字列$K$が生成される条件付き確率を計算する．
実際は，種別$C$に関するコーパスを用いて漢字のNグラム確率を計算する．
現在は，$N=1$としている．
本研究では，以下に示す3種類の言語モデルを構築し，実験に使用した．
\begin{itemize}
\item 標準言語モデル：中国北京大学計算語言学研究所\footnote{http://icl.pky.edu.cn/}が富士通\footnote{http://www.frdc-fujitsu.com.cn/}と共同で作成した「PFR\UTFC{4EBA}\UTFC{6C11}\UTFC{65E5}\UTFC{62A5}\UTFC{6CE8}\UTFC{8BED}\UTFC{6599}\UTFC{5E93}（人民日報タグ付きコーパス）」\mbox{1998年}1月の新聞記事一ヶ月分から構築したモデルであり，異なり$4,540$（延べ$12,229,563$）の漢字を含む．
\item 企業名言語モデル：中国科学院計算技術研究所が主催している「\UTFC{4E2D}\UTFC{6587}\UTFC{81EA}\UTFC{7136}\UTFC{8BED}\UTFC{8A00}\UTFC{5904}\UTFC{7406}\UTFC{5F00}\UTFC{653E}\UTFC{5E73}\UTFC{53F0}（中国語自然言語処理オープンソース）」\footnote{http://www.nlp.org.cn/}が提供している$22,569$社を含む「\UTFC{516C}\UTFC{53F8}\UTFC{540D}\UTFC{5F55}\UTFC{5E93}（企業名リスト）」から構築したモデルであり，異なり$2,167$（延べ$78,432$）の漢字を含む．
\item 人名言語モデル：上記「\UTFC{4E2D}\UTFC{6587}\UTFC{81EA}\UTFC{7136}\UTFC{8BED}\UTFC{8A00}\UTFC{5904}\UTFC{7406}\UTFC{5F00}\UTFC{653E}\UTFC{5E73}\UTFC{53F0}」が提供している「\UTFC{5E26}\UTFC{8BCD}\UTFC{6027}\UTFC{8BCD}\UTFC{9891}\UTFC{7684}\UTFC{6269}\UTFC{5C55}\UTFC{8BCD}\UTFC{5178}（品詞および出現頻度付き拡張辞典）」から$38,406$件の人名を抽出して構築したモデルであり，異なり$2,318$（延べ$104,443$）の漢字を含む．
\end{itemize}

また，上記のモデルを構築する際に，SuperMorphoを用いてコーパスの形態素解析を行い，句読点，記号，機能語を事前に削除した．

\subsection{関連語の自動抽出}\label{sec:auto}

本研究では，翻字対象が指す実体や概念に対して，その意味や印象を中国語で表記した関連語をWebから自動的に抽出し，翻字に利用する．
図\ref{fig:2}に，「エプソン」の関連語を自動抽出する過程を示す．
図\ref{fig:2}の上部では翻字対象に関連する関連語候補を抽出し，下部では抽出する関連語を選択している．
以下，それぞれについて説明する．

\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f2.eps}
\end{center}
 \caption{関連語自動抽出の概要}
 \label{fig:2}
\end{figure} 

翻字対象の関連語を抽出するためには，翻字対象に関する文書が必要である．
例えば，翻字対象が商品名であれば，その商品を紹介する文書であり，翻字対象が企業名であれば，企業の理念などに関する文書である．
このような文書として，フリー百科事典「ウィキペディア（Wikipedia）」日本語版\footnote{http://ja.wikipedia.org/wiki/}の記事を利用した．
2009年6月15日の時点では約$150$万の項目があり，一般名詞，人名，地名，企業名，商品名などが登録されている．
図{\ref{fig:karati}}は地名「カラチ」をWikipediaで検索して得られた記事ページの抜粋である．
図{\ref{fig:karati}}において，最上部の「カラチ」は記事の名称（記事名）であり，その下は本文である．
図{\ref{fig:karati}}の{\mbox{「目次」}}に示されているように，本文は「1 歴史」，{\mbox{「2 気候」}}，{\mbox{「3 人口統計」}}などの「セクション（節）」によって構造化されることがある．

関連語候補の抽出は以下の手順に従って行う．
\begin{enumerate}
\item 翻字対象語をWikipediaで検索して記事ページを取得する．
現在の手法では，記事ページがない用語に対しては関連語を抽出することができない．
\item 取得した記事ページからHTMLタグを削除し，茶筌\footnote{http://chasen.naist.jp/hiki/ChaSen/}で形態素解析を行う．
\item 形態素解析の結果から，名詞と形容詞を翻字対象の関連語候補として抽出する．
ただし，「名詞」のうち「名詞—数」，「名詞—接尾—助数詞」，「名詞—副詞可能」，「名詞—非自立」，「名詞—代名詞」は抽出しない． 
図\ref{fig:2}では，「普及」や「普通」などの名詞と「好き」や「良い」などの形容詞が関連語の候補として抽出されている．
\end{enumerate}

\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f3.eps}
\end{center}
 \caption{Wikipediaにおける「カラチ」の記事ページの抜粋}
 \label{fig:karati}
\end{figure}

ここで，図{\ref{fig:karati}}に示した記事ページの本文は構造化されているため，上記の手順（2）において，
関連語抽出に有効な特定のセクション内だけを解析対象とする手法が考えられる．
しかし，
Wikipediaのガイドブックによる記事ページの編集方針\footnote{http://ja.wikipedia.org/wiki/Wikipedia:ガイドブック\_編集方針}では，記事は{\mbox「記事名（項目名）」}と{\mbox「本文」}で構成され，
本文の基本構成は概要から次第に詳細内容になり，
段落の数が多くなるようなら，「見出し」を付けて「セクション（節）」に分けるとしか規定していない．
見出しの付け方やセクションの分け方は記事の著者によって方針が異なる．

例えば，図{\ref{fig:karati}}で示した「カラチ」の記事ページは，
\pagebreak
「歴史」，「気候」，「人口統計」，「交通」，「姉妹都市」，「脚注」，「ギャラリー」の7セクションで構成されている．
一方，「ハワイ」の記事ページは，「歴史」，「地理」，「人口動勢」，「政治と法律」，「経済」，「教育」，「芸術・文化」，「日本との関わり」，「その他」，「注」，「関連項目」，「外部リンク」の12セクションで構成されている．
同じ地名に関する記述であるにも拘らず，「カラチ」と「ハワイ」の記事に共通するセクションは「歴史」だけである．
さらに，同じ見出しのセクションでも，著者によって記述の方針が異なる可能性がある．
このような状況では関連語抽出に有効なセクションを事前に定義することが困難である．
そこで，今回の実験では本文全体を対象として関連語の候補を抽出した．

Wikipediaから抽出した名詞と形容詞の中には，翻字対象との関連が低い語も含まれているため，翻字に使用する関連語を選択する必要がある．
単語間の関連度を計算する手法\cite{Article_22,Article_25}が複数提案されている．
本研究では，翻字対象と関連語候補間の相互情報量\cite{Article_03,Article_15}を計算して，その値が高い語を関連語として抽出する．
ここでいう相互情報量とは，正確にはpointwise mutual informationであり，式(\ref{eq:mutual})を用いて計算する．
\begin{equation}
I(X,Y)=\log \frac{P(X,Y)}{P(X)\times P(Y)} \label{eq:mutual}
\end{equation}
$P(X)$と$P(Y)$は単語$X$と$Y$それぞれの出現確率であり，$P(X,Y)$は$X$と$Y$が同時に出現する確率である．
ここでは便宜上，$X$を翻字対象，$Y$を1つの関連語候補とする．
図\ref{fig:2}の例では，$X$は「エプソン」であり，$Y$は「好き，普及，普遍，良い」のいずれかである．

関連語の選択は以下の手順に従って行う．
\begin{enumerate}
\item $P(X)$，$P(Y)$，$P(X,Y)$を計算するために，「$X$」，「$Y$」，「$X$ and $Y$」を検索キーワードとしてYahoo! JAPAN\footnote{http://www.yahoo.co.jp/}で検索し，検索結果の総数でそれぞれの確率を近似する．
\item 式(\ref{eq:mutual})の値が高い候補を関連語として選択する．
図\ref{fig:2}では，「エプソン」の関連語として「好き」，「普及」，「普通」，「良い」が選ばれている．
選択する関連語の件数は実験的に決めるパラメタである．\ref{sec:exp}の評価実験では，関連語の件数を段階的に変化させて翻字への影響について考察する．
\item （2）で選択した関連語を中国語に翻訳する．
原理的には，この作業は機械翻訳システムを利用することで自動化することができる．
しかし，現在はYahoo! JAPAN\footnote{http://honyaku.yahoo.co.jp/}を利用して人手で翻訳している．
ただし，Yahoo! JAPANで翻訳できずに原言語がそのまま返される関連語は削除する．
\mbox{図\ref{fig:2}}では，「\UTFC{559C}\UTFC{7231}」，「\UTFC{666E}\UTFC{53CA}」，「\UTFC{666E}\UTFC{901A}」，「\UTFC{597D}」はそれぞれ「好き」，「普及」，「普通」，「良い」に対する訳語であり，翻字対象の関連語として使用される．
\end{enumerate}



\section{評価実験}\label{sec:exp}

\subsection{実験方法}\label{sec:emethod}

本手法で提案した関連語抽出手法の翻字における有効性を評価するために，人手で関連語を与えた場合の結果と比較した．
具体的には，以下に示すモデルの組み合わせについて翻字精度を比較した．
\begin{itemize}
\item 発音モデル＋言語モデル
\item 発音モデル＋印象モデル＋言語モデル：関連語を自動抽出する
\item 発音モデル＋印象モデル＋言語モデル：関連語を人手で与える
\end{itemize}

各手法を順番に「音＋言」，「自動」，「人手」と呼ぶ．
「自動」は本研究の提案手法であり，「音＋言」と「人手」は，それぞれ期待される翻字精度の下限と上限を推定するための手法である．
本研究では\ref{sec:categ}で説明したように3種類の言語モデルを構築したため，翻字対象の種別に言語モデルを適応させた．
すなわち，翻字対象の種別が企業名であれば「企業名言語モデル」を使用し，人名であれば「人名言語モデル」を使用し，それ以外の翻字対象には「標準言語モデル」を使用した．

実験に使う翻字対象として，日中対訳辞書\cite{Book_02}に登録されているカタカナ語$1,136$語から\cite{Article_21}が使用した$210$語を選んだ．
しかし，Wikipediaで記事ページが検索されなかった用語は関連語を抽出できないため，翻字対象語から削除した．
また、Wikipediaで「曖昧さ回避のためのページ」が検索された用語も翻字対象語から削除した．
例えば，「アポロ」で検索すると「アポロ（小惑星）」や「アポロ（曲）」といった異なる語義について書かれた記事へのリンクが表示される．
本手法を実際に運用する場合，現状では複数のリンクから対象の語義に関する記事ページを自動的に特定することができない．
そこで，今回の実験では多義語を翻字対象語から削除した．
最終的に翻字対象として残った$128$語の内訳を表\ref{table:syubetsu}に示す．

\begin{table}[b]
\caption{翻字対象$128$語の内訳}
\label{table:syubetsu}
\input{02table05.txt}
\end{table}

各翻字対象語について，日本語が分かる中国人判定者2名に関連語を与えてもらった．
具体的には，翻字対象の$128$語に対して，日中対訳辞書\cite{Book_02}に記載された解説を2名の判定者に示し，意味を理解させた上で，中国語で１つ以上の関連語を与えてもらった．
ただし，判定者はWikipediaの記事を見ずに作業を行ったので，判定者が与えた関連語が全てWikipediaの記事に載っているとは限らない．
各翻字対象語に対して，判定者は自分が与えた関連語に関わっていると判断した語を正解訳語として1つ以上選んだ．
判定者が翻字対象に与えた関連語および選んだ正解訳語と不正解訳語の例を表\ref{table:examword}に示す．
表\ref{table:examword}において，
2列目の「中国語の関連語（日本語）」は，翻字対象に対して判定者が与えた関連語であり，括弧の中は筆者が付けた日本語訳である．
3列目の「正解」は判定者が正解と判断した訳語の全てであり，4列目の「不正解」は判定者が不正解と判断した訳語の一部である．
なお，翻字結果を公平に比較するために，「自動」と「人手」では翻字対象ごとに翻字に使用する関連語の数を揃えた．
具体的には，「自動」では式(\ref{eq:mutual})の値が高い関連語候補のうち，「人手」で使用された関連語と同じ件数だけを使用した．

\begin{table}[b]
\caption{判定者が選んだ正解訳語と不正解訳語および関連語の例}
\label{table:examword}
\input{02table06.txt}
\end{table}


評価尺度として「正解訳語の平均順位」を用いた．
「人手」では，各翻字対象について判定者2名に対する正解訳語の順位を平均し，さらに全翻字対象を横断して順位を平均した．
「自動」では，各翻字対象について各判定者が与えた関連語数に合わせて実験を行い，各判定者に対応する正解訳語の順位を平均し，さらに全翻字対象を横断して正解訳語の順位を平均した．
「音＋言」では，翻字結果が関連語に依存しないため判定者による正解訳語の順位には違いがなく，全翻字対象を横断して順位を平均した．

ここで，各翻字対象の「正解訳語」として，以下に示す3種類の解釈がある．
    \begin{enumerate}
    \makeatletter\renewcommand{\theenumi}{}\makeatother
\item 日中対訳辞書\cite{Book_02}に定義された訳語
\item 判定者2名の両方が適切と判定した訳語
\item 判定者のうち最低1名が適切と判定した訳語
\end{enumerate}
(a)は評価の客観性が最も高い．しかし，辞書に定義されていない用語でも訳語として適切な場合があるため，正解訳語の網羅性は最も低い．
(c)は正解訳語の網羅性が最も高い．しかし，判定者の主観に依存するため，評価の客観性は最も低い．
(b)は正解訳語の網羅性と評価の客観性ともに(a)と(c)の中間である．
本実験では，客観性が一番低い(c)を省略して，(a)と(b)について評価を行った．



\subsection{実験結果}\label{sec:result}

\begin{table}[b]
\caption{正解の種類(a)に対する正解訳語の平均順位}
\label{table:auto1}
\input{02table07.txt}
\end{table}
\begin{table}[b]
\caption{正解の種類(b)に対する正解訳語の平均順位}
\label{table:auto2}
\input{02table08.txt}
\end{table}


正解の種類(a)と(b)に対する翻字の実験結果をそれぞれ表\ref{table:auto1}と\ref{table:auto2}に示す．
表\ref{table:auto1}と\ref{table:auto2}において，2列目の「語数」は，正解訳語が少なくとも一つ存在する翻字対象の総数である．
表\ref{table:auto1}の\mbox{「語数」}は，日中対訳辞書の訳語を正解訳語としているため，すべての翻字対象語には正解訳語が存在し，128語になる．
それに対して，表\ref{table:auto2}の「語数」は，判定者2名の両方が適切と判断した訳語だけを正解訳語としているため，共通の正解訳語が存在しない翻字対象語を除いて，76語になる．
3列目の「関連語数の平均」と4列目の「正解訳語数の平均」は，各判定者が翻字対象一つにつき与えた関連語数と正解と判定した正解訳語数の平均である．
「正解訳語の平均順位」は\ref{sec:emethod}に示した3通りの手法に対する結果をそれぞれ示している．

表\ref{table:auto1}と\ref{table:auto2}では，「音＋言」の結果は関連語に依存しないため，判定者によらず必ず一致する．
表\ref{table:auto1}と\ref{table:auto2}の結果より，正解の種類に関係なく，「自動」と「人手」の平均順位は「音＋言」より高く，「人手」の平均順位が一番高かった．

\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f4.eps}
\end{center}
 \caption{正解の種類(a)における正解訳語の順位分布図}
 \label{fig:ca1}
\end{figure} 
\begin{figure}[b]
\begin{center}
\includegraphics{17-2ia2f5.eps}
\end{center}
 \caption{正解の種類(b)における正解訳語の順位分布図}
 \label{fig:ca2}
\end{figure}

図\ref{fig:ca1}と\ref{fig:ca2}は，表\ref{table:auto1}と\ref{table:auto2}の結果に対して「正解訳語の順位に関する分布」を分析した結果である．
図\ref{fig:ca1}の正解訳語が上位10位以内に存在した語数を見ると，「自動」は「人手」より少なく，「音＋言」より多かった．
この傾向は図\ref{fig:ca2}でも同様であった．

以上をまとめると，正解の種類と関係なく，自動抽出した関連語を利用して翻字を行う手法は，印象モデルを利用しない手法よりも有効であった．
また，翻字精度を多少犠牲にして，人手で関連語を与えるコストを削減することができた．

自動抽出する関連語を上位から1つずつ増やして，正解訳語の平均順位が変化する様子を調べた結果を図\ref{fig:num}に示す．
図\ref{fig:num}より，関連語を１つしか使用しない場合でも正解の種類(a)と(b)における正解訳語の平均順位はそれぞれ$219$と$78$であり，
表\ref{table:auto1}と\ref{table:auto2}にそれぞれ示した「音＋言」の平均順位（$229$と$102$）よりも高かった．
また，正解訳語の平均順位は関連語数が増えるにつれ高くなり，関連語数が$7$を超えたところでほぼ一定になった．

\begin{figure}[t]
\begin{center}
\includegraphics{17-2ia2f6.eps}
\end{center}
 \caption{関連語の数と正解訳語の平均順位}
 \label{fig:num}
\end{figure}
 


\subsection{考察}\label{sec:kousatu}

表\ref{table:yukou}と\ref{table:mukou}は，用語の種別ごとに翻字対象を1つずつ選んで，翻字に使用した関連語と正解の種類(a)における正解訳語の平均順位を示している．
表\ref{table:yukou}は自動抽出した関連語が有効だった翻字対象の例を示し，表\ref{table:mukou}は自動抽出した関連語が有効でなかった翻字対象の例を示している．
表\ref{table:yukou}の「順位」では「自動」における正解訳語の平均順位は「人手」より高く，逆に表\ref{table:mukou}では「自動」の順位は「人手」より低い．
表\ref{table:yukou}と\ref{table:mukou}の「中国語の関連語」において，「自動」では中国語に翻訳する前の日本語を括弧内に示す．
ただし，「人手」の関連語は判定者が直接中国語で入力したため，筆者が日本語訳を与えた．
「中国語の関連語」を見ると，自動的に抽出した関連語は人手で与えた関連語とあまり一致していない．
以下，この点について具体例を挙げながら考察する．

\begin{table}[t]
\caption{自動抽出した関連語が有効だった翻字対象の例}
\label{table:yukou}
\input{02table09.txt}
\end{table}

表\ref{table:yukou}を見ると，「カネボウ」では，企業名を付ける際には使用されないであろう
「\UTFC{7834}\UTFC{4EA7}（破産）」と「\UTFC{50B2}\UTFC{6162}（傲慢）」が関連語として使用されていた．
判定者が不適切な関連語を与えたことで評価実験の妥当性が損なわれていないか調べるために，全ての翻字対象について著者が関連語を吟味した．
その結果，「カネボウ」の\mbox{「\UTFC{7834}\UTFC{4EA7}（破産）」}と「\UTFC{50B2}\UTFC{6162}（傲慢）」以外の関連語には問題がなかった．
さらに，「カネボウ」の関連語から\mbox{「\UTFC{7834}\UTFC{4EA7}（破産）」}と\mbox{「\UTFC{50B2}\UTFC{6162}（傲慢）」}を削除し，
自動抽出した関連語数を人手の関連語数に揃えて再度実験を行った．
その結果，正解の種類や「人手」と「自動」といった手法の違いによらず，上記2つの関連語を削除する前と比べて実験結果は変わらなかった．
以上より，人手による不適切な関連語によって評価実験の妥当性が損なわれていないことを確認した．

\begin{table}[t]
\caption{自動抽出した関連語が有効でなかった翻字対象の例}
\label{table:mukou}
\input{02table10.txt}
\end{table}

別の例として，\mbox{「カラチ」}では，自動抽出した関連語の中に，\mbox{Wikipedia}の記事ページにある「カラチ」と関連が強いと考えられるいくつかの語が含まれていない．
例えば，「ムスリム」や「パキスタン」である．
「ムスリム」と「パキスタン」は関連語候補として抽出されたものの「カラチ」との相互情報量は関連語候補中それぞれ11位と12位だった．
他方において，判定者AとBが「カラチ」に与えた関連語の数はそれぞれ8語と10語だった．
人手と自動と関連語の数を揃えたため，「ムスリム」と「パキスタン」は最終的に関連語として選択されなかった．
本来関連が強い語を自動的に関連語として選択するためには，関連語候補を抽出する段階と抽出した候補を一定の基準で順位付ける段階のそれぞれにおいて改善の余地がある．

まず，関連語候補を抽出する段階では，記事ページ本文全体が抽出対象となっている点に問題がある．
表\ref{table:yukou}において「カラチ」の関連語を見ると，「外部リンク」というセクションから抽出された「リンク」が関連語として選択されている．
しかし，\mbox{Wikipedia}では\mbox{「外部リンク」}に見出し語に関する説明が書かれることは稀である．
「カラチ」の例に関して言えば，「外部リンク」のセクションを関連語抽出の対象から削除すれば，
\mbox{「リンク」}は関連語候補として抽出されず，その結果「ムスリム」や「パキスタン」の順位が相対的に上がる．
しかし，\mbox{「ハワイ」}の記事ページにおける「外部リンク」のセクションには，
「カウアイ観光局」や「オアフ島観光局」などのアンカーテキスト（リンクをはるためのテキスト）が記述されており，「カウアイ」や「オアフ島」などの「ハワイ」に関連する語を含んでいる．
すなわち，関連語抽出の対象から「外部リンク」を一律削除すればよいとは限らない．
また，\ref{sec:auto}節で議論したように，セクションの分け方，見出しの付け方，セクション内の記述内容に関する方針は記事の著者によって異なる．
以上より，関連語抽出において対象にすべきセクションとそれ以外を正確に区別することは難しい．これは今後も検討して解決すべき課題である．

関連語の候補に順位を付ける段階では，式(\ref{eq:mutual})で用いた相互情報量以外の計算方法を試し，本研究の目的にとって最適な手法について今後検討する必要がある．

表\ref{table:mukou}を見ると，「シャネル」では，自動抽出した関連語のうちいくつかが人手で与えた関連語と一致した．
例えば，「\UTFC{9999}\UTFC{6C34}（香水）」や「\UTFC{540D}\UTFC{724C}（ブランド）」などである．
しかし，人手で与えられた「\UTFC{534E}\UTFC{4E3D}（華やか）」や「\UTFC{8010}\UTFC{4E45}（耐久）」などのように翻字対象の印象を表す関連語がなく，翻字に有効でなかった．
「インテル」では，自動抽出した関連語に「インテル」に関する印象を表す語がなかった．
「カタール」では，自動抽出した関連語は全てカタール周辺国の国名であり，「カタール」自体を表す語として適切ではなかった．
「モナリザ」と「ディスコ」では，自動抽出した関連語の中に，翻字対象と関係のない語がいくつかあった．
例えば，「モナリザ」の「\UTFC{81EA}\UTFC{5DF1}（自分）」，「\UTFC{624B}（手）」，「\UTFC{6CA1}\UTFC{6709}（無く）」や，「ディスコ」の「\UTFC{597D}（良い）」，「\UTFC{56DE}\UTFC{6765}（帰り）」，「\UTFC{5236}（製）」である．
また，Yahoo! JAPANの翻訳システムによる誤訳もあった．
例えば，「ディスコ」に対する日本語の関連語「非常」は「とても」という意味なので，中国語の「\UTFC{5927}」ではなく「\UTFC{975E}\UTFC{5E38}」と訳されるべきであった．


\section{おわりに}

中国語では表意文字である漢字を翻字に使用するため，発音が同じでも使用する漢字によって翻字結果の意味や印象は異なる．
そこで，中国語への翻字では漢字の選択が重要である．
\cite{Article_21}は適切な漢字を選ぶために，発音だけでなく翻字対象の印象や種別を使用した．
しかし，彼らの手法では翻字対象の関連語をユーザが与えるため高価である．
本研究の貢献は，翻字対象の関連語をWebから自動的に抽出してユーザの負担を削減した点にある．

評価実験の結果，本手法は人手で関連語を与える手法よりも翻字精度が低かった．
しかし，漢字の意味や印象を考慮しない翻字手法よりは翻字精度が高かった．
しかし，自動抽出した関連語には翻字対象の特徴を適切に表現していない用語もあったため，
今後の課題として関連語抽出のさらなる精緻化が必要である．
また，Wikipediaで説明を得ることができない用語や多義語への対応も今後の課題である．



\bibliographystyle{jnlpbbl_1.4}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Al-Onaizan \BBA\ Knight}{Al-Onaizan \BBA\
  Knight}{2002}]{Article_01}
Al-Onaizan, Y.\BBACOMMA\ \BBA\ Knight, K. \BBOP 2002\BBCP.
\newblock \BBOQ Translating Named Entities Using Monolingual and Bilingual
  Resources.\BBCQ\
\newblock In {\Bem Proceedings of the 40th Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 400--408}.

\bibitem[\protect\BCAY{Bollegala, Matsuo, \BBA\ Ishizuka}{Bollegala
  et~al.}{2007}]{Article_22}
Bollegala, D., Matsuo, Y., \BBA\ Ishizuka, M. \BBOP 2007\BBCP.
\newblock \BBOQ Measuring Semantic Similarity between Words Using Web Search
  Engines.\BBCQ\
\newblock In {\Bem Proceedings of the 16th International World Wide Web
  Conference}, \mbox{\BPGS\ 757--766}.

\bibitem[\protect\BCAY{Chen, Hueng, Ding, \BBA\ Tsai}{Chen
  et~al.}{1998}]{Article_02}
Chen, H.~H., Hueng, S.~J., Ding, Y.~W., \BBA\ Tsai, S.~C. \BBOP 1998\BBCP.
\newblock \BBOQ Proper Name Translation in Cross-Language Information
  Retrieval.\BBCQ\
\newblock In {\Bem Proceedings of the 36th Annual Meeting of the Association
  for Computational Linguistics and the 17th International Conference on
  Computational Linguistics}, \mbox{\BPGS\ 232--236}.

\bibitem[\protect\BCAY{Church \BBA\ Hanks}{Church \BBA\
  Hanks}{1989}]{Article_03}
Church, K.~W.\BBACOMMA\ \BBA\ Hanks, P. \BBOP 1989\BBCP.
\newblock \BBOQ Word Association Norms, Mutual Information, and
  Lexicography.\BBCQ\
\newblock In {\Bem Proceedings of the 27th Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 76--83}.

\bibitem[\protect\BCAY{Fujii \BBA\ Ishikawa}{Fujii \BBA\
  Ishikawa}{2001}]{Article_04}
Fujii, A.\BBACOMMA\ \BBA\ Ishikawa, T. \BBOP 2001\BBCP.
\newblock \BBOQ Japanese/English Cross-Language Information Retrieval:
  Exploration of Query Translation and Transliteration.\BBCQ\
\newblock {\Bem {\em Computers and the Humanities}}, {\Bbf 35}  (4),
  \mbox{\BPGS\ 389--420}.

\bibitem[\protect\BCAY{黄\JBA 藤井\JBA 石川}{黄 \Jetal }{2007}]{Article_21}
黄海湘\JBA 藤井敦\JBA 石川徹也 \BBOP 2007\BBCP.
\newblock 中国語への翻字における確率的な漢字選択手法.\
\newblock \Jem{電子情報通信学会論文誌}, {\Bbf J90--D}  (10), \mbox{\BPGS\
  2914--2923}.

\bibitem[\protect\BCAY{Jeong, Myaeng, Lee, \BBA\ Choi}{Jeong
  et~al.}{1999}]{Article_05}
Jeong, K.~S., Myaeng, S.~H., Lee, J.~S., \BBA\ Choi, K.~S. \BBOP 1999\BBCP.
\newblock \BBOQ Automatic Identification and Back-Transliteration of Foreign
  Words for Information Retrieval.\BBCQ\
\newblock {\Bem {\em Information Processing \& Management}}, {\Bbf 35},
  \mbox{\BPGS\ 523--540}.

\bibitem[\protect\BCAY{Knight \BBA\ Graehl}{Knight \BBA\
  Graehl}{1998}]{Article_06}
Knight, K.\BBACOMMA\ \BBA\ Graehl, J. \BBOP 1998\BBCP.
\newblock \BBOQ Machine Transliteration.\BBCQ\
\newblock {\Bem {\em Computational Linguistics}}, {\Bbf 24}  (4), \mbox{\BPGS\
  599--612}.

\bibitem[\protect\BCAY{Kwok, Deng, Dinstl, Sun, Xu, Peng, \BBA\ Doyon}{Kwok
  et~al.}{2005}]{Article_08}
Kwok, K.~L., Deng, P., Dinstl, N., Sun, H.~L., Xu, W., Peng, P., \BBA\ Doyon,
  J. \BBOP 2005\BBCP.
\newblock \BBOQ CHINET: a Chinese Name Finder System for Document Triage.\BBCQ\
\newblock In {\Bem Proceedings of 2005 International Conference on Intelligence
  Analysis}.

\bibitem[\protect\BCAY{Kwok \BBA\ Deng}{Kwok \BBA\ Deng}{2002}]{Article_07}
Kwok, K.~L.\BBACOMMA\ \BBA\ Deng, P. \BBOP 2002\BBCP.
\newblock \BBOQ Corpus-based Pinyin Name Resolution.\BBCQ\
\newblock In {\Bem Proceeding of the First SIGHAN Workshop on Chinese Language
  Processing}, \mbox{\BPGS\ 41--47}.

\bibitem[\protect\BCAY{Lee \BBA\ Chang}{Lee \BBA\ Chang}{2003}]{Article_09}
Lee, C.~J.\BBACOMMA\ \BBA\ Chang, J.~S. \BBOP 2003\BBCP.
\newblock \BBOQ Acquisition of English-Chinese Transliterated Word Pairs from
  Parallel-Aligned Texts Using a Statistical Machine Transliteration
  Model.\BBCQ\
\newblock In {\Bem Proceedings of the HLT-NAACL 2003 Workshop on Building and
  Using Parallel Texts: Data Driven Machine Translation and Beyond},
  \mbox{\BPGS\ 96--103}.

\bibitem[\protect\BCAY{Li, Sim, Kuo, \BBA\ Dong}{Li et~al.}{2007}]{Article_11}
Li, H.~Z., Sim, K.~C., Kuo, J.~S., \BBA\ Dong, M. \BBOP 2007\BBCP.
\newblock \BBOQ Semantic Transliteration of Personal Names.\BBCQ\
\newblock In {\Bem Proceedings of the 45th Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 120--127}.

\bibitem[\protect\BCAY{Li, Zhang, \BBA\ Su}{Li et~al.}{2004}]{Article_10}
Li, H.~Z., Zhang, M., \BBA\ Su, J. \BBOP 2004\BBCP.
\newblock \BBOQ A Joint Source-Channel Model for Machine Transliteration.\BBCQ\
\newblock In {\Bem Proceedings of the 42nd Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 159--166}.

\bibitem[\protect\BCAY{Qu \BBA\ Grefenstette}{Qu \BBA\
  Grefenstette}{2004}]{Article_12}
Qu, Y.\BBACOMMA\ \BBA\ Grefenstette, G. \BBOP 2004\BBCP.
\newblock \BBOQ Finding Ideographic Representations of Japanese Names Written
  in Latin Script via Identification and Corpus Validation.\BBCQ\
\newblock In {\Bem Proceedings of the 42nd Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 183--190}.

\bibitem[\protect\BCAY{佐々木\JBA 佐藤\JBA 宇津呂}{佐々木 \Jetal
  }{2006}]{Article_25}
佐々木靖弘\JBA 佐藤理史\JBA 宇津呂武仁 \BBOP 2006\BBCP.
\newblock 関連用語収集問題とその解法.\
\newblock \Jem{{自然言語処理}}, {\Bbf 13}  (3), \mbox{\BPGS\ 151--175}.

\bibitem[\protect\BCAY{Stalls \BBA\ Knight}{Stalls \BBA\
  Knight}{1998}]{Article_14}
Stalls, B.~G.\BBACOMMA\ \BBA\ Knight, K. \BBOP 1998\BBCP.
\newblock \BBOQ Translating Names and Technical Terms in Arabic Text.\BBCQ\
\newblock In {\Bem Proceedings of the COLING/ACL Workshop on Computational
  Approaches to Semitic Languages}, \mbox{\BPGS\ 34--41}.

\bibitem[\protect\BCAY{鈴木\JBA 王}{鈴木\JBA 王}{2002}]{Book_02}
鈴木義昭\JBA 王文 \BBOP 2002\BBCP.
\newblock \Jem{日本語から引ける中国語の外来語辞典}.
\newblock 東京堂出版.

\bibitem[\protect\BCAY{Turney}{Turney}{2001}]{Article_15}
Turney, P.~D. \BBOP 2001\BBCP.
\newblock \BBOQ Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL.\BBCQ\
\newblock In {\Bem Proceedings of the Twelfth European Conference on Machine
  Learning}, \mbox{\BPGS\ 419--502}.

\bibitem[\protect\BCAY{Virga \BBA\ Khudanpur}{Virga \BBA\
  Khudanpur}{2003}]{Article_16}
Virga, P.\BBACOMMA\ \BBA\ Khudanpur, S. \BBOP 2003\BBCP.
\newblock \BBOQ Transliteration of Proper Names in Cross-Lingual Information
  Retrieval.\BBCQ\
\newblock In {\Bem Proceedings of the ACL 2003 Workshop on Multilingual and
  Mixed-language Named Entity Recognition}, \mbox{\BPGS\ 57--64}.

\bibitem[\protect\BCAY{Wan \BBA\ Verspoor}{Wan \BBA\
  Verspoor}{1998}]{Article_18}
Wan, S.\BBACOMMA\ \BBA\ Verspoor, C.~M. \BBOP 1998\BBCP.
\newblock \BBOQ Automatic English-Chinese Name Transliteration for Development
  of Multilingual Resources.\BBCQ\
\newblock In {\Bem Proceedings of the 36th Annual Meeting of the Association
  for Computational Linguistics and the 17th International Conference on
  Computational Linguistics}, \mbox{\BPGS\ 1352--1356}.

\bibitem[\protect\BCAY{Xu, Fujii, \BBA\ Ishikawa}{Xu et~al.}{2006}]{Article_19}
Xu, L.~L., Fujii, A., \BBA\ Ishikawa, T. \BBOP 2006\BBCP.
\newblock \BBOQ Modeling Impression in Probabilistic Transliteration into
  Chinese.\BBCQ\
\newblock In {\Bem Proceedings of the 2006 Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 242--249}.

\end{thebibliography}

\begin{biography}
\bioauthor{黄　　海湘}{
2002年3月獨協大学大学院博士前期課程（経済・経営情報専攻）修了．同年4月図書館情報大学大学院博士後期課程に
入学．現在，大学統合にともない筑波大学大学院図書館情報メディア研究科に在籍中．
}
\bioauthor{藤井　　敦}{
1993年3月東京工業大学工学部情報工学科卒業．1998年3月同大学大学院博士課程修了．現在，東京工業大学大学院情報理工学研究科准教授，博士（工学）．自然言語処理，情報検索，音声言語処理，Webマイニングの研究に従事．情報処理学会，人工知能学会，電子情報通信学会，日本データベース学会，Association for Computational Linguistics 各会員．
}
\end{biography}

\biodate



\end{document}
