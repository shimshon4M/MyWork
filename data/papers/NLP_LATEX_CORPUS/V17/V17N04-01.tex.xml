<?xml version="1.0" ?>
<root>
  <jtitle>タグ信頼度に基づく半自動自己更新型固有表現抽出</jtitle>
  <jauthor>齋藤邦子今村賢治</jauthor>
  <jabstract>本稿では条件付確率場に基づく固有表現抽出において，新たなドメインにモデルを適応するためのモデル学習コスト—正解データ作成コスト—を低減する2つの学習手法を提案する．本手法では，タグ単位の事後確率をタグ信頼度とみなし，信頼度の低いタグをシステムの解析誤りとして自動的に検出する．そして検出された解析誤りタグのみを修正の対象とするため，文全体の事後確率を利用する場合と比較して，修正が必要である箇所に効率よくコストを注力させることが可能となる．第1の学習手法として，能動学習に本手法を適用すると，システム出力の信頼度が低いタグのみを検出して人手修正対象とすることにより，従来手法と比較して修正コストが1/3に低減した．また，第2の学習手法として正解固有表現リストを利用したブートストラップ型学習に適用すると，解析誤りとして検出されたタグの上位候補から半自動的に正解タグを発見可能であった．この学習法では，大量のプレーンテキストから，半自動で正解データを作成できるため，更に学習コストを低減させる効果がある．</jabstract>
  <jkeywords>固有表現抽出，信頼度，事後確率，能動学習，ブートストラップ，学習コスト</jkeywords>
  <section title="はじめに">近年，様々な言語処理タスクにおいて，大量の正解データから学習した統計的言語モデルを解析に用いる教師あり機械学習のアプローチが広く普及している．このアプローチでは，言語の文法的な知識を統計的な特徴量として捉えることができ，形態素解析や固有表現抽出，機械翻訳などの自然言語処理で広く活用されている．本稿では固有表現抽出タスクに焦点をあてる．固有表現抽出は，形態素解析済みの各単語に対して，「どの種類の固有表現か」というタグを付与することにより実現されている．近年では，条件付確率場(ConditionalRandomFields;CRF)に基づく系列ラベリングが好成績を収めている．しかし，これらの教師あり機械学習に基づく言語処理では，モデルを学習するための正解データを構築するコストが極めて高いことが常に課題となっている．一方，情報検索や情報抽出の分野では，近年ブログなどのConsumerGeneratedMedia(CGM)を対象とした研究も多くなってきている．CGMは，テキストそのものが日々変化してゆくため，新しい語や話題が常に出現するという特徴がある．このような日々変化するテキストにモデルを適応させる確実な方法は，正解の追加データを作成することである．しかし，人手コスト問題のため，迅速に対応させるのは困難であった．これらの人手コストを削減するための従来研究として，能動学習，半教師あり機械学習，ブートストラップ型学習などが提案されてきた．能動学習は，膨大なプレーンテキスト集から学習効果の高いデータを取捨選択し，正解は選択されたデータのみに対して人手で付与する手法であり，人手コストを効果的に集中させることに着眼している．そのため，能動学習では学習効果の高いデータ（文）を選択するという，データセレクションが最も重要なポイントとなる．ここでのデータセレクションの単位は常に文である．一方，もしシステムの解析結果をそのまま正解データとして利用できれば，人手コストは大幅に削減可能である．しかし，現実には解析結果には解析誤りが存在するため，その解析誤りを一つ一つ人手で確認修正する作業が必要である．データセレクションの単位が文である限り，どこに解析誤りが存在するか明白ではないため，全てのタグをチェックする必要がある．しかし，実際には大部分のタグが正解であることが多いため，文全体の全てのタグを確認するコストは無駄が多い．本稿では，タグ単位の事後確率に基づいて算出したタグ信頼度を導入する．この手法では，文単位の信頼度ではなく，各単語に付与されうる全てのタグについてのタグ信頼度を計算する．そしてタグ信頼度に基づいて解析誤りタグを自動的に検出する．自動的に検出された解析誤り箇所だけを人手チェック・修正の対象とすれば，能動学習の学習効率は更に高まる．更に，もし検出された解析誤りを自動的に正解に修正できれば，更に学習コストを削減できる．本稿では，シードとなる正解固有表現リストを利用してブートストラップ的に正解データを収集する半自動自己更新型固有表現抽出を提案する．この手法では，予め人手でシードを準備するだけで，膨大なテキストからシードに存在する固有表現を含む正解データを自動的に収集し，モデル更新をすることが可能となる．本稿で提案する2つの学習手法の模式図を図に示す．タグ信頼度に基づいて大規模平文データからシステム解析誤りを自動検出し，誤りタグの有無でデータセレクションを実施する．誤りタグを人手で修正する能動学習（章）と，半自動で修正する自己更新型固有表現抽出UpdateNER（章）を本稿では提案する．以下，第章では固有表現抽出タスクについて述べ，第章では，今回提案するタグ信頼度について説明する．第章では，タグ信頼度を能動学習に適応したときの効果を示し，第章では半自動自己更新型固有表現抽出について説明する．第章で関連研究について述べ，第章でまとめる．</section>
  <section title="固有表現抽出">固有表現抽出とは，テキストに含まれる人名，地名，組織名などの固有表現を抽出するタスクである．本稿では，表に示すとおり，IREXで定義される8種の固有表現を抽出対象とし，IOB2方式に基づいて17種類のタグを使用する．例えば，``東京/都/に''という文は次のようにタグ付けされる：このタスクは単語列W=w_1w_nに対して固有表現の種類を表す固有表現タグ列T=t_1t_nを付与する系列ラベリング問題として考えることができる．近年，系列ラベリング問題ではCRFなどの識別モデルが成功を収めている．本稿ではlinear-chainCRFを利用し，固有表現タグ列の事後確率を以下の式で算出する．P(T|W)&amp;=1Z(W)_i=1^n(_a_af_a(t_i,w_i)+_b_bf_b(t_i-1,t_i))(W)&amp;=_T_i=1^n(_a_af_a(t_i,w_i)+_b_bf_b(t_i-1,t_i))alignw_iとt_iは位置iに置ける単語（周辺単語を含む）と固有表現タグ，f_a(t_i,w_i)，f_b(t_i-1,t_i)は当該単語及び固有表現タグがある条件を満たす時に1となる素性関数である．_a，_bは素性関数の重みであり，正解データから推定される．Z(W)は正規化項である．()式を最大化するタグ列が最尤タグ列であり，Viterbiアルゴリズムを利用して求められる．</section>
  <section title="タグ信頼度に基づく解析誤り検出"/>
  <subsection title="タグ事後確率">()式から，文全体の事後確率をタグ列全体の信頼度として利用することは自然であり，従来の能動学習では，通常，文全体の事後確率からデータ選択のための信頼度を算出していた．本稿では，文ではなくタグ単位の事後確率に着目し，この値をタグ自体の信頼度とみなす．そしてタグ信頼度の値を利用して解析誤りであるタグを自動的に判定する．図はタグ信頼度計算の模式図である．単語w_iのタグ候補t_i,jについての信頼度は，次式のように計算される．ここで_TP(t_i,j,T|W)はタグ候補t_i,jを通る全てのタグ列の事後確率を総和したものであり，周辺確率(marginalprobability)とも呼ばれる．なお，j=1,,kは表に示す固有表現タグの全種類に対応するものであり，本稿ではk=17である．タグ候補の信頼度は，前向きおよび後向きアルゴリズムにより以下のように効率的に算出することができる．ここで_i,j&amp;=_k_i-1,k(_a_af_a(t_i,w_i)+_b_bf_b(t_i-1,t_i))_i,j&amp;=_k_i+1,k(_a_af_a(t_i+1,w_i+1)+_b_bf_b(t_i,t_i+1))_0,j&amp;=1_n+1,j&amp;=1align以上のようにして，文中の各単語に付与されうる全てのタグに関して信頼度が得られる．</subsection>
  <subsection title="リジェクター">リジェクターは，タグ信頼度を参照し，システム出力の解析誤りを自動で検出する．各単語において，デコーダが出力した最尤タグt_dと信頼度1位タグt_1を参照し，以下のような手順で各固有表現タグが正解か不正解かを判定する．なお，最尤タグt_dは，()式を最大化するタグであり，信頼度1位タグt_1は()式を最大化するタグである．最尤タグt_dが信頼度1位タグt_1と不一致ならば，最尤タグt_dを解析誤りとしてリジェクトする[]でアクセプトされた場合，信頼度1位タグt_1の信頼度cs_1が閾値以下ならば最尤タグt_dを解析誤りとしてリジェクトするそれ以外であれば最尤タグt_dを正解としてアクセプトするstepenumerate閾値が高ければリジェクトされるタグ数が増え，人手のチェック・修正コストが増加する．実際の運用では，開発データにてリジェクト・アクセプトの判定誤り率が最小となるような閾値を設定すればよい．このようにして，タグ信頼度を利用することにより，タグを単位として解析誤りを検出することが可能となる．</subsection>
  <section title="能動学習">タグ単位での誤り検出は能動学習のデータセレクションに有効である．もし，文中にリジェクトタグが1つでも含まれれば，その文は，現在のモデル（ベースモデル）が確信を持って解析できない，何か新しい事象が存在していることを意味する．すなわち，このような文を優先的にモデル学習の対象とすることで高い学習効果を期待できる．そこでここでの能動学習では，文中にリジェクトタグを含むか否かに基づいたデータセレクションを採用する．また，選別された文について，全てのタグを人手でチェック・修正する必要は無く，リジェクトされたタグのみを対象としてチェック・修正すればよい．図は本稿で提案する能動学習のスキームを示したものである．固有表現抽出デコーダでは，初期正解データから学習したベースモデルに基づいて最尤タグが出力される．続いて章で示した手順で最尤タグの解析誤りを検出する．このステップでは，同じベースモデルを利用してタグ信頼度を計算し，その結果を参照してリジェクターで誤り検出を実行する．データセレクションにて少なくとも1つ以上のリジェクトタグを含む文のみを選別し，検出された誤りタグ（リジェクトタグ）のみを人手でチェック・修正する．最終的に，人手修正済みデータを初期正解データに追加し，モデルを再学習して更新する．</section>
  <subsection title="評価実験">今回，本稿で提案する能動学習の効果を学習コストの面から評価した．実験用にブログデータ（45,694文）をWebから収集し，表に示すとおり4つのセグメントに分割した．全データに対して予め人手で正解となる固有表現タグを付与したが，追加平文データに関しては，これらの正解タグは隠しておき，プレーンテキストとして扱う．そして人手修正を模する際にこの正解タグの情報を利用する．開発データは節で述べたリジェクター判定に利用する閾値を最適化する際に利用した．学習コストは人手でタグをチェック・修正した単語の割合(WCR:WordCheckRate)とみなした．WCRは，追加平文データに含まれる総単語数に対するチェックされた単語数の割合であり，次式で表される．WCR=チェックした単語数/総単語数displaymath本方式は，リジェクターの閾値に依存して，検出されるリジェクトタグ数が変化するため，閾値を0.1から1.0の範囲で0.1ずつ段階的に変更し，リジェクトタグを含む文のみをデータセレクションで選別して，誤り検出済みデータとした．それぞれの閾値で得られた誤り検出済みデータのうち，リジェクトタグだけを予め付与していた正解タグと変換した．この手順は，人手修正を模したものである．修正後のデータを初期正解データに追加し，ベースモデルを再学習する．この能動学習と比較するため，タグ単位ではなく文単位の信頼度に基づくデータセレクションによる能動学習と比較した．文全体の事後確率を信頼度とみなし，低信頼度の文を優先的に選択する能動学習である．本稿で提案するタグ単位の信頼度に基づく能動学習と異なり，文単位の信頼度の能動学習では，選択された文は全ての単語についてタグのチェックが必要であるとみなされる．以上，2つの能動学習について，再学習したモデルの精度と学習コスト(WCR)の関係を評価した．モデルの精度は評価データにおけるF値を利用した．</subsection>
  <subsection title="結果と考察"/>
  <subsubsection title="学習曲線と精度：">図に提案手法でのタグ単位のデータセレクションによる能動学習と，文単位のデータセレクションによる能動学習での学習曲線を示す．再学習後のモデルの精度がF値で0.76となるために，文単位での能動学習では全データの60%を人手でチェックするコストが必要だが，タグ単位での能動学習では，わずか20%で済む．言い換えると，タグ単位の能動学習は従来の文単位の能動学習と比較して学習コストを1/3に低減したことを意味する．また，図に，追加平文データのタグをまったく修正しないで，モデルを再学習して測定した精度も併せて示す．ベースモデルではF値0.612であったものが，タグ修正なしの追加平文データをすべて加えた場合はF値0.602に若干低下した．タグ修正なしデータには誤りタグが多く残存しており，そのためF値が低下したと考えられる．このように，ベースモデルによるデコード結果を単純に加えただけでは，学習データ量が増えても精度向上には寄与せず，悪化する場合もある．</subsubsection>
  <subsubsection title="タグ修正内容の分析：">更にタグ単位の能動学習の効果を調べるために，リジェクトタグに対して実施されたタグ修正の内容を以下の4タイプに分類して内訳を分析した．NoChange:リジェクトタグが修正不要OtoBI:リジェクトタグがOタグであり，B-又はI-タグに置換BItoO:リジェクトタグがB-又はI-タグであり，Oタグに置換BItoBI:リジェクトタグがB-又はI-タグであり，別のB-又はI-タグに置換表はリジェクター閾値が0.5の時のリジェクトタグについて，上記4タイプの分類の分布を示している．この閾値は開発データで，リジェクターの判定誤り率が最低となる値である．表からわかるとおり，NoChangeタイプの割合が最も多い．これはリジェクターが本来修正の必要の無いタグまで過剰にリジェクトしていることを意味する．この結果は，更新するモデルの精度そのものには悪影響を及ぼさないが，学習コストの面では無駄が含まれていることを示している．続いてOtoBIタイプが2番目に割合が多く，全体の1/3を占める．実質的な変化のなかったNoChangeタイプを除き，何かしらの修正が加わった3つのタイプ(OtoBI，BItoO，BItoBI)だけを考慮すると，OtoBIタイプは全修正の約60%を占める．つまり，ベースモデルでは固有表現として認識できなかったものが，固有表現に修正されたケースが最も多い．このことは，誤り検出済みデータ中には，初期正解データにはない，新しい固有表現が多く含まれていることを示唆している．</subsubsection>
  <section title="ブートストラップ型固有表現抽出">章で述べた通り，実際の修正では約60%がOタグをB-またはI-タグに変更する必要がある．この事実は固有表現抽出タスクの特徴に由来するものと推察される．つまり，固有表現抽出タスクでは，全コーパスの殆どはOタグで占められている．実際，章で我々が整備した追加平文データにおいても，91%がOタグであった．そのため固有表現の新語が文中に出現すると，ベースモデルではOタグが付与されてしまうことが多い．このようにOタグが支配的であるという傾向があるならば，OタグではないB-またはI-タグの候補の可能性を考慮することが必要である．即ち，Oタグがリジェクトされたときに，次に信頼度の高いタグは何かを調べることは意味があると考えられる．そこで，閾値0.5の時のタグ信頼度が上位2位までのタグについて，その精度を分析したものを表に示す．信頼度1位のタグ（1位タグ）がアクセプトとされた時，その精度は94%と高い．一方，1位タグがリジェクトされた時，1位タグの精度はわずか43%であった．しかし，信頼度2位のタグ（2位タグ）の精度は29%であり，1位タグと2位タグをどちらも考慮すると，いずれかに正解タグが存在する可能性が72%まで高まる．このことから，上位2位のタグまでを考慮することにより，システム出力のリジェクト箇所を自動的に修正できる可能性があることがわかる．図に，閾値0.5で1位タグがリジェクトされる場合は2位タグまで考慮するときのタグの状況を示す．以後，本稿ではこのラティス構造をタググラフと呼ぶ．``3丁目の夕日''という映画タイトル（固有物名ART）を1位タグだけでは正しく固有表現として認識できていない．しかし，2位タグまで考慮すると，正しいタグ列が存在していることがわかる．もしこの正解のタグ列を自動的にシステムが発見できれば，この正しいタグ列情報を人手修正した正解データと同等のものとして利用できる．</section>
  <subsection title="半自動自己更新型固有表現抽出">以上の考察をふまえ，新しい学習スキームである半自動自己更新型固有表現抽出(UpdateNER)を提案する．これは，予め用意する固有表現リストをシードとし，そのシードを利用してタググラフから正解のタグ列を発見する方式であり，シードを利用して新しいインスタンスを取得するブートストラップ型の学習に類似している．図にUpdateNERの概要を示す．リジェクターでは，タグ信頼度に基づいてリジェクト／アクセプト判定をした後，適宜2位までのタグを考慮したタググラフを出力する．ここでリジェクターは章で述べた処理手続きを以下のように変更して動作する．1位タグの信頼度スコアcs_1が閾値以上であれば，1位タグt_1のみをアクセプトする．それ以外は[]の処理へ進むcs_1が閾値より小さければ，1位タグt_1と更に2位タグt_2をアクセプトするstepenumerate後続のデータセレクションでは，2位までのタグ候補を有するタググラフ構造を持つ文を抽出する．そして，コンテキスト抽出にて以下の手順で正解タグ列が存在するかを調べ，該当するタグ列が存在すればそのタグ列を抽出する．タググラフ内で最長となる固有表現が成立するタグ列を選択する該固有表現が別途準備するシードリストである固有表現リストに存在していれば文全体のタグ列を正解タグ列として抽出するstepenumerateステップ[]では，タググラフの中から最も有望と思われるタグ列を選ぶことを意図して，最長となる固有表現が成立するルートを選択する．例えば，図で示すタググラフの場合，``3''，``丁目''，``の''，``夕日''の4単語が2位タグまでの候補を有しているため，16通りのタグ列が存在する．例えば，``BIII''，``BIIO''，``BIOO''，``OOOI''，``OOOO''などである．しかし，ここでは``BIII''のタグ列で最長の固有表現（``3丁目の夕日''で固有物名ART）が構成できるため，このタグ列を選択する．他の部分文字列からなる固有表現，例えば，``3''，``3丁目''，``3丁目の''でいずれも固有物名ARTとなるようなタグ列は全て無視される．ステップ[]では，ステップ[]で選択した有望なタグ列が本当に正解であるとみなしてよいかを判定する．タグ列の確からしさを判定するための手がかりが必要となるので，ここではシードとなる固有表現リストを準備し，表記と対応する固有表現タイプを記載しておく．このリストは，人手で必要な固有表現を登録しても良いし，辞書のような外部DBを利用して自動的に構築しても良い．もし同じ固有表現がステップ[]で選択されたタグ列および固有表現リストに存在していれば，このタグ列は正解であると判断されて正解データとして抽出される．そして，このようにして抽出されたデータを初期正解データに追加し，モデルを再学習する．以上のようにUpdateNERでは，シードを与えるだけで学習データの収集・構築を実行できるため，日々増大する固有表現にモデルを追随させることが可能となる枠組みを備えている．</subsection>
  <subsection title="結果">実験の結果，のべ2,100文が追加データとして抽出された．このデータのうち，6,125タグが誤りと推定されたリジェクトタグで，その中で2,038個は信頼度2位のタグが採用された．タググラフ付きデータが73,563文あったことを考えると，得られた文数は少ない．表に，人名(PSN)，地名(LOC)，組織名(ORG)，固有物名(ART)での解析精度について，ベースモデル，ユーザ辞書システム(userdic.)，UpdateNERの結果をそれぞれ示す．シードをユーザ辞書として扱う場合，再現率は向上するが，適合率は殆ど変化しないか，むしろARTでは0.667から0.620へと低下している．これはユーザ辞書を単に追加するだけでは固有表現抽出システムの性能を向上するには十分ではないことを示唆している．ユーザ辞書の枠組みでは，周囲のコンテキストを利用せず単に同一の単語列（表記）を発見すれば一意に固有表現と認定してしまうため，過剰に固有表現を抽出する危険があるからである．一方，UpdateNERでは再現率と適合率ともに向上している．例えば，ARTでは再現率が0.321から0.370，適合率が0.667から0.698へと向上している．この結果から，シードに存在する固有表現だけでなく，その固有表現の周囲の文全体のタグ列の情報がモデルの再学習には必須であると解釈できる．UpdateNERでは，シードの固有表現が出現する文全体でのタグ列，即ち，固有表現とそのコンテキストのうち，有望で確からしいものを自動的に発見して抽出すると言う点で優れている．シードを準備するには多少の人手コストが必要ではあるが，そのコストは正解データそのものを作成するコストと比較すれば極めて小さい．そのため，このUpdateNERの学習スキームは，実際に固有表現抽出システムを運用する場面においては学習コストを抑える1つの有望な手法であると考える．表で示す通り，ユーザ辞書システムもUpdateNERもORGに対しては効果が見られなかった．これはシードに含まれる固有表現の分布によるものと考えられる．Wikipediaから自動作成したシードでは，PSNの固有表現が74%と最も多かった．一方ORGはわずか11%しか存在せず，UpdateNERではORGについての正解データを抽出する機会が十分になかったものと考えられる．また，同じ表記でもORGとPSNの曖昧性が生じるケースはもともと多いため，PSNが支配的なシードを利用したUpdateNERではORGをPSNに過剰に学習してしまっている可能性もある．今後，シードの分布とその学習効果への影響は検討を進めたい．なお，UpdateNERでは，初期正解データへの追加データには誤りが含まれる可能性があることを指摘しておく．実験では，追加したデータにどの程度の誤りが含まれていたかは調査できていない．ただし，第章の実験では誤りタグを含むデータを追加して再学習することは精度を若干低下させることが示されていることと，本実験において精度の低下があまり見られないことを考え合わせると，本手法で追加するデータには，モデルの性能に悪影響を与えるような誤りはほとんど含まれないと推察される．</subsection>
  <subsection title="考察">従来の機械学習の手法と比較して，UpdateNERの一番の特徴は1位タグが信頼できない時に2位タグまで考慮する点にある．これにより特に固有表現抽出タスクのようにベースモデルではOタグであると認識されたとき，次点の候補が何であるかを考慮することが可能となった．しかしUpdateNERには，2つの大きな制約がある．1つは2位タグまでに正解が存在しなければ自動的に正解データとして抽出することができない，という点である．もう1つはその固有表現がシードにも存在していなければならない，という点である．これらの2つの制約があるため，UpdateNERが自動的に収集・修正できる正解データの範囲は狭いと考えられる．この弱点を克服するには，実運用にてUpdateNERとタグ単位でのデータセレクションによる能動学習を組み合わせる手法が有望であると考えている．能動学習の場合，2位までに正解が存在しなければならないという制約はないため，単純に解析誤りを人手で優先的に修正して学習対象とすることが可能である．即ち，能動学習ではベースモデルが解析誤りをするデータ全般を学習対象とすることとなり，その学習範囲はUpdateNERよりも広い．そのため，能動学習ではベースモデルの精度を底上げするような学習に向いていると考えられる．一方，UpdateNERは日々増大する膨大なテキストから半自動で正解データを収集できるという利点があり，新語への追随学習には向いていると言える．そこで，例えば，短期的にはUpdateNERで毎週モデルの新語追随学習を実行し，中期的には1ヵ月或いは半年といった間隔で能動学習を行ってベースモデルの底上げをする，というような運用形態が考えられる．今後，実際のシステム運用上での本手法の効果について，評価を実施したい．</subsection>
  <section title="関連研究">能動学習は固有表現抽出タスクへの適応に限らず，様々な自然言語処理タスクへの適応が研究されており，品詞タグ付け，テキスト分類，構文解析，単語選択での曖昧性解消など数多くの関連研究がある．いずれの場合も信頼度や情報量といった何かしらの指標に基づいて学習効果の高いデータを選択することが重要であり，その指標の算出やデータセレクションの単位は基本的に文，もしくは一定の語数以上の単語列であった．今回我々が提案する能動学習では，モデル出力の信頼度を指標とするが，その算出単位は文単位ではなく，タグ単位である点が従来研究とは異なる．更にデータセレクションも文単位ではなく，タグ単位でリジェクト／アクセプトを決定し，リジェクトタグのみを修正箇所対象として絞っているため，更なる学習コストの削減に繋がった．なお，では，本稿と同様にタグ単位の信頼度に基づいた能動学習を英語の固有表現抽出タスクで評価しており，本稿と同程度のコスト削減効果を報告している．今回，我々は更にタグ単位の信頼度を利用して半自動で誤り修正を行うUpdateNERの提案および評価を実施した点が新しい．一方，特に機械学習の分野において，正解データだけでなく膨大な量のプレーンテキストを利用する半教師あり学習の研究も進められている．自然言語処理タスクでは，語義曖昧性解消，テキスト分類，チャンキング・固有表現抽出などへも適応されている．特に近年は，GigaWord単位のプレーンテキストも入手可能になってきたため，このデータを正解データと組み合わせてモデル学習することにより従来技術の性能限界を超える可能性が示唆されている．ただし，今回我々がターゲットとしているのは，日々語彙や話題の変化が激しいブログなどのCGMドメインにおいて，モデルを低コストで再学習するタスクであり，このような状況を反映するようなGigaWord単位のプレーンテキストを入手するのは困難であると考えられる．そのため，膨大な量のプレーンテキストを利用する半教師あり学習をそのまま適応することは現実的ではない．プレーンテキストを利用するという点で半教師あり学習と類似する手法にブートストラップ学習の研究がある．これは，少量のシードを準備して，シードと同じカテゴリに属する新しいインスタンスをプレーンテキストから自動獲得する学習法である．本稿のUpdateNERはシードを準備するだけで，データセレクションとその修正・抽出までを自動的に実行するブートストラップ学習とみなすことができる．しかし，従来のブートストラップは新しいインスタンスを獲得して辞書（シソーラス）を構築することを目的としているのに対し，本手法では，固有表現単体ではなく，固有表現を含むタグ列，即ちコンテキスト全体を獲得している点が異なる．モデルの再学習のためには固有表現辞書だけではなく，固有表現を含むコンテキストそのものが必要である．UpdateNERではブートストラップ学習を適用して最終的には教師あり学習の枠組みでモデル更新を実現するという点が新しい．この学習コストはシードを準備する部分のみのため，能動学習と比較しても極めて低く抑えられるという利点もあり，本手法は有効である．</section>
  <section title="おわりに">本稿では，タグ単位の事後確率から算出したタグ信頼度を利用してモデルの学習コストを削減する2つの手法を提案した．本手法ではタグ信頼度から解析誤りタグを自動的に判定することが可能である．そしてタグ単位でデータセレクションを行うことでベースモデルが学習対象とすべき箇所を効果的に発見でき，かつ，人手のコストを解析誤り箇所のみに集中させることが可能となった．まず始めに，本手法を能動学習に適応して評価した結果，従来の文単位でデータセレクション・修正する能動学習と比較して，学習コストを1/3まで低減できた．能動学習はベースモデルが解析誤りするデータ全般を学習対象とできるため，モデル全体の精度向上を狙った学習に効果があると考えられる．次に，本手法を利用して半自動自己更新型固有表現抽出(UpdateNER)を提案した．この手法はシードと2位までのタグ候補を利用してブートストラップ的に正解データを自動生成するものである．この手法では，予めシードを準備するだけで膨大なテキストから正解データを自動的に収集・構築することが可能となった．この学習では，日々増大する膨大なテキストを利用してモデルを新語追随させることを狙った学習に効果がある．能動学習とUpdateNERを組み合わせることでモデル更新の学習コストを抑えた固有表現抽出システムの運用が可能となる．document</section>
</root>
