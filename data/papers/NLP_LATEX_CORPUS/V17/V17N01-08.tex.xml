<?xml version="1.0" ?>
<root>
  <jtitle>テキスト結束性を考慮したentitygridに基づく局所的一貫性モデル</jtitle>
  <jauthor>横野光奥村学</jauthor>
  <jabstract>本論文ではentitygridを用いたテキストの局所的な一貫性モデルに対する改善について述べる．entitygridベースの既存モデルに対して，テキスト結束性に寄与する要素である接続関係，参照表現，語彙的結束性，また，より詳細な構文役割の分類を組み込んだモデルを提案し，その性能を検証する．語彙的結束性に関しては，語彙的連鎖を用いたクラスタリングを行う．テキスト中の文の並びに対して，より一貫性のある文の順番の判定と，人手による評価に基づいた要約テキストの比較の2種類の実験を行い，その結果，本論文で提案する要素がentitygridモデルの性能の改善に寄与することが明らかになった．</jabstract>
  <jkeywords>テキスト一貫性，テキスト結束性，テキストの評価</jkeywords>
  <section title="はじめに">テキストの評価は，自動要約や機械翻訳などのようなテキストを生成するタスクにおいて手法の評価として用いられるだけでなく，例えば人によって書かれた小論文の自動評価といったように，それ自体を目的とすることもある．言語処理の分野においては前者のような手法評価の観点からテキスト評価に着目することが多く，例えば自動要約の評価で広く用いられているROUGEや機械翻訳で用いられているBLEUのような評価尺度が存在している．これらの評価手法は特に内容についての評価に重点が置かれている．つまり，評価対象のテキストが含んでいなければならない情報をどの程度含んでいるかということに焦点が当てられている．しかし，実際にはテキストは単に必要な情報を含んでいれば良いというわけではない．テキストには読み手が存在し，その読み手がテキストに書かれた内容を正しく理解できなければ，そのテキストは意味をなさない．読み手の理解を阻害する原因には，難解な語彙の使用，不適切な論理展開や文章の構成などが挙げられる．これらはテキストの内容に関する問題ではなく，テキストそのものに関する問題である．従って，テキストの内容が正しく読み手に伝わるかどうかを考慮するならば，その評価においては内容に関する評価だけでなく，テキストそのものについての評価も重要となる．テキストそのものについての性質のうち，テキスト一貫性とは文章の意味的なまとまりの良さであり，例えば因果関係や文章構造などによって示される文同士の繋がりである．意味的なまとまりが悪ければ，テキストの内容を読み手が正確に理解することが困難になると考えられる．このことから一貫性の評価はテキストの内容が正しく伝わることを保証するために必要であると言える．また，テキスト一貫性が評価できるようになると，テキストを生成するシステムにおいて，例えば，一貫性が良くなるように文章を構成したり，一貫性の観点からの複数の出力候補のランク付けが可能となり，出力するテキストの質を高めることができる．テキスト一貫性は局所的な一貫性と大域的な一貫性という2種類のレベルに分類できる．局所的な一貫性とは相前後する2文間における一貫性であり，大域的な一貫性とは文章における話題の遷移の一貫性のことである．一貫性の評価に関しては，この局所的な一貫性と大域的な一貫性の両方についてそれぞれ考えることができるが，局所的な一貫性は大域的な一貫性にとって重要な要素であり，局所的な一貫性の評価の精度の向上が大域的な一貫性の評価に影響すると考えられる．以上のことから，本論文では，テキスト一貫性，特に局所的な一貫性に焦点を当て，この観点からのテキストの評価について述べる．テキストの性質について，テキスト一貫性と並べて論じられるものにテキスト結束性がある．これは意味的なつながりである一貫性とは異なり，文法的なつながりである．一貫性が文脈に依存しているのに対し，結束性は脱文脈的で規則的な性質である．テキスト結束性に寄与する要素は大きく参照，接続，語彙的結束性に分けられる．これらはテキストの表層において現れる要素である．一貫性は先に述べたように意味のまとまりの良さであり，これに寄与する要素は明示的な形では現れない．一貫性と結束性はどちらもテキストのまとまりに関する性質であり，それぞれが独立ではなく互いに関係している．従って，テキストの表層に現れる，結束性に関係する要素である接続表現や語彙的結束性を一貫性モデルにおいても考慮することで性能の向上が期待できる．2章で述べるように，局所的な一貫性に関する研究はテキスト中の隣接する文間の関係を単語の遷移という観点から捉えているものが多い．その中でもBarzilayらの研究は，この領域における他の研究において多く採用されているentitygridという表現を提案しており，先駆的な研究として注目に値する．しかし，3章で詳述するように，このモデルでは要素の遷移の傾向のみ考慮しており，テキストのまとまりに関係している明示的な特徴はほとんど利用されていない．そこで本論文では4章で詳述するように，一貫性モデルに結束性に関わる要素を組み込むことによって，結束性を考慮に入れた局所的な一貫性モデルを提案する．</section>
  <section title="関連研究">Barzilayらは局所的な一貫性のモデルとしてentitygridを提案している．このモデルはテキスト中で述べられている要素の遷移に着目している．これは，センタリング理論で示されているように，一貫性のあるテキストではその文中の要素の出現に規則性があるという考えに基づいている．Elsnerらは，entitygridモデルがテキストの一貫性において要素の遷移にのみ着目しているということに言及し，例えば参照表現や対象の要素がこれまでに既に述べられている要素かどうかなどといった他の要素をモデルに組み込んでいる．Filippovaらはentitygridモデルに要素間の関係を考慮したモデルを提案し，このモデルをドイツ語の新聞記事に対して適用した結果を報告している．大域的な一貫性について，Barzilayらは隠れマルコフモデル(HMM)を採用したモデルを提案している．このモデルでは文章中の話題をHMMにおける隠れ状態と見なし，話題の一貫性を隠れ状態の遷移確率によって表現している．SoricutらやElsnerらは局所的な一貫性と大域的な一貫性を同時に考慮するモデルをそれぞれ提案している．これらのモデルはentitygridモデルとHMMを組み合わせたものである．日本語の文章に対する一貫性の評価手法には，板倉らの提案する段落の一貫性指標がある．これは段落内で用いられている単語間の意味的な関係に基づいている．これらの手法では文書中の単語の出現に着目してテキスト一貫性を評価しており，章で述べたように一貫性に影響すると考えられる，テキスト結束性に関係する表層的な特徴は考慮されていない．</section>
  <section title="Entity Gridに基づく局所的な一貫性モデル">Barzilayらは，一貫性のあるテキストではその中で述べられる要素の出現の分布には規則性があるという仮説に基づいた一貫性のモデルを提案している．また，このテキスト中の要素の分布パターンを捉えるために，entitygridと呼ばれる表現を導入している．これは，テキストを，行に文を，列に文章中の要素をそれぞれ対応させた行列として表したものである．その各項には文における要素の構文役割が入る．用いられる構文役割は主語(S)，目的語(O)，その他(X)，出現せず(-)の4種類である．図に示すテキストに対応するentitygridを表に示す．この一貫性モデルではentitygridの作成の際に共参照解析を行い，異なる表現であっても同じ要素を指すものをまとめている．例えば，図においてs_1の``BELLINDUSTRIESInc.''とs_4の``Bell''は同じ要素を指すと判定されると，それらの構文役割は表の同じ列(``BELL'')に記述される．局所的な一貫性の評価にはentitygridを基に作られた文書ベクトルを用いる．ベクトルの要素は文n-gram(n2)における構文役割の遷移確率と，構文役割の出現確率からなる．構文役割の遷移を計算する際には，文書始めと文書終わりを含んだ遷移も考慮する．この確率はentitygrid中に存在する長さnの全ての構文役割の遷移の数に対する対象の長さnの遷移列の割合である．例えば，表に示すentitygridにおいて，[S-]という遷移の確率は，長さ2の全ての遷移の数（即ち，50）に対する対象の遷移列（即ち，3）の割合から求められる（即ち，0.06）．また，テキストにおいて頻出する要素は，そのテキストの話題に関連すると考えられ，そのような要素はそうでない要素とは異なる遷移の傾向を持つという仮定から，出現頻度によってテキスト中の要素をグループに分け，それぞれのグループにおいてentitygridを作成している．連続する2文における遷移確率で構成された文書ベクトルd_1，d_2を図に示す．図中の``0''，``1''はそれぞれ文書始め，文書終わりを表す．Barzilayらは構文役割をdependencyparserを使って推定しているが，これに対して本論文では構文役割を格助詞によって決定する（表）．また，文書ベクトルの作成において，考慮する構文役割の遷移はBarzilayらの手法と同様に文3-gramまでとした．テキスト一貫性は，対象のテキストについて一貫性がある，一貫性がないといったように絶対的に評価することが困難であるため，Barzilayらはテキストの文の順番を局所的一貫性に基づいて順位付けすることで相対的に評価するモデルを提案している．テキストの順位付けにはスコア関数を導入し，その値を利用する．このスコア関数は，あるテキストd_iの文の順番を並べ替えて生成したテキストをx_ij，x_ikとし，x_ijの方がx_ikよりも一貫性があるとしたとき，[w(x_ij)&gt;w(x_ik)]という条件を満たすような関数である．このwの値は学習によって推定する．このパラメータの学習にはrankingSVMが用いられる．(x)はテキストxの一貫性に関する性質を表す素性ベクトルであり，具体的には上述のテキスト中の要素の遷移確率で構成された文書ベクトルである．モデルの評価は，テキストの文の順番を決定するというタスクを順位付け問題として定式化して行う．即ち，テキストを文の集合と見なし，それから生成できるテキストの順位付けを行う．元のテキストの順番で構成されたテキストの順位が最も高ければ，そのテキストに対する局所的な一貫性の良し悪しを正しく評価できたと見なす．しかし，実際には，同じテキストから生成された異なる文の順番を持つテキストの一貫性を比較することは困難であるため，元テキストとそのテキストから生成された異なる順番を持つテキストのペアに対して比較を行い，どの程度元のテキストの方に高い順位を割り当てることができているかで評価する．この一貫性モデルは，テキスト中の要素の遷移列のみに着目している．参照表現に関しては共参照解析を行い，異なる表現であっても同じ要素を指すものは同一の要素として扱っているが，接続表現や同義語，類義語といったテキストのまとまりに関係しているその他の明示的な特徴は利用されていない．</section>
  <section title="テキスト結束性に関わる要素と構文役割の拡張">本論文では，Barzilayらの局所的な一貫性モデルに対して，テキスト結束性に寄与する，テキストに表層的に現れる文法的要素を考慮することで，その性能の向上を図る．これにより，既存手法では``正しい一貫性を持つテキストの性質''に着目したモデルを構築していたのに対し，本手法では``正しい結束性を持ち，且つ，一貫性を保っているテキストの性質''に着目したモデルを構築できると考えられる．具体的には，章で述べたテキスト結束性に寄与する要素を，それぞれ，文書ベクトルへの素性の追加，接続関係毎の遷移確率の計算，意味的な類似性に基づく文中の要素のクラスタリングという形で，局所的な一貫性モデルに組み込む．また，構文役割について，日本語の主題表現を考慮に入れた拡張を行う．</section>
  <subsection title="接続関係毎の遷移確率の計算">本論文では文の展開において接続関係の種類毎に文中の要素の構文役割の遷移の傾向が異なるという仮説を立てる．例えば，ある時点までで主題として述べられていた要素は，話題転換後には全く出現しない，あるいは別の主題の補助的な役割として出現するということが考えられる．この仮説による特徴を捉えるために，文の接続関係毎に遷移確率を計算する．文間の関係の推定には接続表現を利用する．テキスト中の隣接する文に対して，後ろの文の接続詞の種類によって文間の関係を決定する．接続関係には市川の分類を採用し，これに基づいて接続詞を表に示すグループに分類する．表中の括弧内の数字はそのグループに属する接続詞の数である．各グループへの接続詞の対応付けは人手で行った．接続詞が存在しない場合はその2文間には連鎖型の接続関係があると見なす．文間の関係の種類毎に遷移確率を計算するため，ベクトルの素性の数は接続関係の数に比例して増加する．このことはデータのスパース性を導くと考えられるので，さらにこの8種類の分類を表に示す文脈形成の関係に基づく3種類のグループにまとめる．図に示すテキストとそのentitygrid（表）から生成される長さ2の構文役割の遷移確率のベクトルの例を示す．ここでs_1,,s_4は文であり，e_1,,e_3は文中の要素，図中の下付き文字はその要素の文中での構文役割である．文s_2の文頭に接続詞``そして''があり，この接続詞は添加型に属するため，s_1とs_2間の関係はGroup2となる．s_2とs_3間，s_3とs_4間に関してはs_3とs_4の文頭に接続詞が存在しないので連鎖型と見なしGroup3となる．遷移確率の計算は各関係毎に行う．例えば，Group3の[S-]という構文役割の遷移確率は，Group3の長さ2の全ての遷移の数（即ち，16）に対する[S-]の遷移の数（即ち，1）の割合である0.06となる．図のベクトルを図に示す．SS_G_iはGroupiにおける構文役割の遷移[SS]の遷移確率を表す．</subsection>
  <subsection title="参照表現">参照表現に関して，本論文ではその先行詞が明示的である指示表現のみを考慮する．``この''や``あの''などの指示形容詞が使われている指示表現はその先行詞が前文に現れることが多い．従って，逆に指示形容詞が出現している文の前文にその先行詞が出現していなければ，その2文間のつながりは悪いと考えることができる．このことを考慮するために，指示形容詞を含む参照表現がその先行詞を前文に含む割合を文書ベクトルの素性として追加する．対象とする指示形容詞は``この''など8種類で，割合は``指示形容詞+名詞''という表現の出現数に対する，その先行詞が前文に現れている場合の数で求める．これは参照表現が正しく機能している割合と見なすことができる．Barzilayらの手法ではgridを作成する際に共参照解析を行い，異なる表現であっても同じ要素を指す場合は同一要素と見なしている．これに対して，本論文では共参照解析は行っていない．</subsection>
  <subsection title="語彙的結束性に基づいた文中の要素のクラスタリング">Barzilayらのentitygridモデルでは遷移確率を計算する際にそれぞれの要素を独立に扱っている．そのために要素間の関係はモデルに反映されていない．この問題に対して，各要素を意味的なクラスタリングによってまとめ，得られたクラスタを1つの要素として扱うことで対応する．本論文ではクラスタリング手法として日本語語彙大系の意味体系を利用した手法と語彙的連鎖を利用した手法の2種類を考える．要素をクラスタにまとめた際，同じクラスタにまとめられる要素が1文中に複数存在すると，そのクラスタに対して複数の構文役割が存在することになる．このような場合における構文役割の扱いに対して，次の2種類を考える．構文役割の優先順位		に基づいて，クラスタに対して1つの構文役割を決定する．クラスタ中の構文役割を全て利用し，遷移は全組		合せを考える．list図にそれぞれの例を示す．図において，e_1，e_2，e_3は要素であり，c_1はe_2とe_3を含むクラスタである．手法1では，文s_1とs_2間でのc_1の遷移は[OS]のみとする．これに対して，手法2では，構文役割の全ての組合せである[OO]，[OS]，[-O]，[-S]をc_1の遷移と見なす．</subsection>
  <subsubsection title="日本語語彙大系を利用したクラスタリング">日本語語彙大系を使って，要素を同じ概念のグループにまとめる．日本語語彙大系は最大12段からなる階層的な構造を持つ意味属性の体系を持つシソーラスである．このそれぞれの意味属性をクラスタとして扱う．テキスト中に出現する各要素に対して，その要素が持つ意味属性を日本語語彙大系から検索する．このうち特定の段において同じ意味属性を有する要素を同じクラスタにまとめる．1つの要素に対して複数の意味属性が存在する場合は，その特定の段の意味属性で見た時に数の多かった意味属性をその要素の意味属性と見なす．</subsubsection>
  <subsubsection title="語彙的連鎖を利用したクラスタリング">語彙的連鎖とは意味的に関連している語の列である．この語の列をクラスタとして扱う．本論文ではMochizukiらの手法に基づいて語彙的連鎖を求める．はじめに，単語X，Y間の共起スコアはコサイン尺度(1)によって求める．ここでx_i，y_iはテキストiにおいて単語X，Yが出現する回数であり，nはコーパス中のテキストの数である．次に，2つのクラスタC_i，C_j間の類似度は式(2)によって求める．語彙的連鎖の生成アルゴリズムは1文中の要素のクラスタリングとテキスト全体の要素のクラスタリングの2ステップからなり，テキスト中の全ての文に対してこのステップを繰り返し行う．1文中の要素のクラスタリングでは，まずテキストから文を取り出し，その文中のそれぞれの要素を1クラスタと見なして，全てのクラスタのペアに対して式(2)によって類似度を計算する．類似度の最も高いペアの類似度が閾値以上であれば，そのペアをマージする．この処理をマージするペアが無くなるまで繰り返す．次に，テキスト全体のクラスタと先ほど生成した文中のクラスタの全てのペアの類似度を同様に式(2)によって計算する．類似度の最も高いペアの類似度が閾値以上であれば，そのペアをマージする．この処理をマージするペアが無くなるまで繰り返す．</subsubsection>
  <subsection title="構文役割の拡張">Barzilayらのentitygridモデルではテキストにおいて顕著な使われ方をする要素をそうでない要素と分けて遷移確率を求めている．これは顕著に表れる要素はテキストの主題を表すことが多く，そのような要素は特別な遷移傾向を持つという仮説に基づいている．主題に関しては，日本語の文章では助詞``は''を用いることでその文の主題を明示的に表すことができる．また，主題かどうかというだけでなく，述部に直接係る要素とそうでない要素では文章の展開への寄与が異なると考えられる．これらのことをモデルに組み込むために，本論文ではBarzilayらのentitygridモデルで用いられている4種類の構文役割を表に示す主題と述部要素を加えた6種類に拡張する．この構文役割の集合においては，その役割間の優先順位関係をH&gt;S&gt;O&gt;R&gt;Xとする(cf.)．</subsection>
  <section title="実験と考察">前章で述べた各要素の評価のために2種類の実験を行った．1つは文順序に関するタスクであり，もう1つは自動要約で生成された要約テキストのランキングのタスクである．実験において性能を評価するモデルと各モデルから生成される文書ベクトルの次元数を表に示す．各モデルに対して接続関係毎に遷移確率を計算してベクトルを作成した場合(+CONJ)と，それを行わなかった場合(noCONJ)の両方で実験を行った．全てのモデルにおいて頻出する要素とそうでない要素に分けてgridを作成する．その閾値はBarzilayらの手法と同様に2とした．BaselineはBarzilayらの設定に従ったモデルである．但し，本論文ではBaselineにおいても共参照解析は行わない．実験では，形態素解析にはMeCabを，係り受け解析にはCaboChataku/software/cabocha/を使用した．</section>
  <subsection title="予備実験">語彙的結束性の考慮において，日本語語彙大系を利用したクラスタリングの際に使用する意味属性の段と語彙的連鎖によるクラスタリングの際の閾値をあらかじめ決定する必要がある．本論文ではこれらの値を予備実験によって決定した．予備実験は表のSC(1st)とLC(1st)のモデルに対して，節と同じタスクを行った．使用したデータは朝日新聞コーパスの2003年の記事のうち，``人もの''というカテゴリに分類されている記事100件である．この記事の順番を無作為に並べ替えたものと元の記事を比べて元の記事の方が一貫性があると判定したペアを正解と見なし，その精度が最も良かった値を使用するパラメータとした．日本語語彙大系で用いられている意味属性体系は最大で12段あり1が最も抽象的な概念である．このうち3〜9の段に対して実験を行った．結果を表に示す．同様に，語彙的連鎖のクラスタのマージに関する閾値について，0.05から0.5まで0.05刻みで値を変えて行った実験の結果を表に示す．これらの結果から，本実験では語彙的連鎖のクラスタのマージの閾値には0.35を使用した．また，日本語語彙大系を用いたクラスタリングは語彙的連鎖のクラスタリングに比べて，精度が低いことが判明したため，以降の実験では文中の要素のクラスタリングでは語彙的連鎖によるクラスタリングについてのみ行う．</subsection>
  <subsection title="実験1: テキストの並べ替え">文順序に関するタスクでは，3章で述べた評価方法と同様にオリジナルのテキストと文の順番を並べ替えたテキストとを比較し，どちらが一貫性があるかを正しく判定できた精度でモデルの評価を行った．学習にはSVM^lightのrankingSVMモードを使用した．コストパラメータcの値については各モデル毎に予備実験で使用したデータを使って10分割交差検定を行い，最も精度が高いものを使用している．各モデルに対するcの値を表に示す．また，並べ替えテキスト中の文の順番がオリジナルのテキストの文の順番と大きく異なっていれば，一貫性の判定は容易になると考えられる．このことを検証するために，表に示す5種類の並べ替えの比較を行う．swap1はオリジナルのテキストとの差が最も小さく，randomはその差が最も大きくなる．mixはswap1，swap2，swap3の混合であり，swap3よりは差は小さい．本実験では朝日新聞コーパスの2003年分の記事から，``行政改革''，``医療''，``教育''というカテゴリに該当するもので，1記事あたり10文以上で構成されているものを使用した．データセット中に含まれる記事のカテゴリの割合は均等になるように調整している．オリジナルのテキストと比較する並べ替えテキストに関して，表に示す各並べ替えの種類のそれぞれにおいて，1つの記事に対して20個の並べ替えテキストを生成した．この比較する並べ替えのテキストの数に関して，Karamanisはセンタリング理論に基づいた手法に対して，信頼できる結果を得るために100,000個の並べ替えテキストを生成して評価を行っているが，我々はentitygridに基づいたモデルを用いており，このモデルでの精度向上を目的としているため，使用する並べ替えテキストの数はBarzilayらの実験の設定にあわせている．実験はデータセットに対して10分割交差検定を行い，テストデータ中の各ペアにおいてオリジナルのテキストの方が一貫性があると判定されたペアの割合で評価した．表に100記事，300記事に対してmixの並べ替えを行ったデータを用いた各モデルの結果を示す．``noCONJ''は各モデルにおいて接続関係毎の遷移確率の計算を行わなかった場合，``+CONJ''は接続関係毎の遷移確率の計算を行った場合を示す．表中の太字の数値は使用したデータにおいて最も良かったものを表し，斜字はベースライン（接続関係を未考慮のBaseline）を下回ったものを表す．また，右肩の記号^**(p&lt;0.01)，^*(p&lt;0.05)は符号検定においてベースラインの精度と有意な差があることを示す．全体としては，いくつかベースラインを下回っているものがあるものの，多くのモデルにおいてベースラインを有意に上回る結果を得ることができた．接続関係毎に遷移確率を計算したモデル（``+CONJ''の列）の方がそうでないモデル（``noCONJ''の列）に比べて良い結果を示している．特に各データセットにおいて接続関係のタイプを考慮したモデルが最も良い精度を得ており，文脈の展開を明示的に示す接続表現から得られる接続関係が一貫性の判定に有用であることを示している．gridから作成される文書ベクトルの素性は構文役割の遷移の組合せの数だけ存在する．従って，構文役割を拡張したモデル(SR(H))はベースラインのモデルに比べて素性の数が多くなり，データが少なかった時の影響が顕著に表れると考えられる．また，参照表現については少数の明示的な指示形容詞のみに限定したため，参照表現を考慮したモデル(REF)でもそれほど差が出なかったと考えられる．語彙的結束性に基づいたクラスタリングを行ったモデルでは良好な結果を得ることができた．本論文で提案した要素の全てを考慮したモデルは，全ての場合で最良の結果を得ることはなく語彙的結束性のみを考慮したモデルを下回った場合もあった．これは構文役割を拡張したモデルと同様に，全ての要素を考慮したモデルと語彙的結束性のみを考慮したモデルとでは文書ベクトルの次元の数が異なることが影響していると考えられる．本論文で用いている一貫性モデルではモデルの学習に必要なデータは人間が書いたテキストのみであり，学習のために特別な情報を付与する必要はない．従って，学習データの作成に必要なコストはほとんどない．そこで，データを更に増やして実験を行った．この実験ではベースラインのモデル(Baseline)，構文役割を拡張したモデル(SR(H))，全ての要素を考慮したモデル(ALL-LC(comb))，接続関係毎に遷移確率を計算したモデル(+CONJ,Baseline)と全ての要素を考慮した接続関係毎に遷移確率を計算したモデル(+CONJ,ALL-LC(comb))のみを使用した．結果を表に，そのグラフを図に示す．接続関係毎の遷移確率を考慮したモデルはそうでないモデルに比べて，データが増加するにつれて精度が向上することが明らかになった．一方，構文役割を拡張したモデルはデータを増やしていってもベースラインに比べてあまり向上は見られなかった．表に並べ替えの種類毎での結果を示す．比較するテキストの差と問題の難易度との関係については，差が一番小さいswap1では精度が最も低く，一番大きいrandomでは精度が最も高くなっており，仮説通りの結果が得られた．また，全てのデータセットにおいてBaselineと比べて本論文のモデルの方が良好な結果を得ることができた．</subsection>
  <subsection title="実験2: 要約文書の比較">節で行った実験では，あるテキストとそのテキスト中の文の順番を並べ替えたものとを比較している．このため比較する2つのテキストの単語の出現頻度分布は等しいと言える．しかし，実際にはこのような状況は稀であると考えられる．例えば，自動要約の評価においては同じ元文書から生成された要約を用いてシステムの評価を行う．元文書が同じであっても，システム毎に異なる要約が生成されることがあり，これらの単語の出現傾向は異なると考えられる．そこで，実際に自動要約システムによって生成された要約を比較し，どちらが一貫性があるかを判定するという実験を行った．実験に使用したデータはNTCIR-4のサブタスクであったTSC3(TextSummarizationChallenge3)に提出された要約である．TSC3では11のシステムが30件の元文書に対してそれぞれ長短2種類の要約を生成している．このうち実際に要約文が出力されている657件の要約を使用した．それぞれの要約には被験者による評価結果が付与されている．この評価では，被験者は15個のQualityquestionと呼ばれるテキストの質に関するチェック項目が示され，各項目毎にスコアを付ける．このQualityquestionは主に要約の読みやすさに対する質問で構成されている．本実験では特に一貫性に関係する項目のスコアのみに着目し，これらから要約の一貫性に関するスコアを計算し比較を行った．要約のスコアの決定について述べる．TSC3で用いられた15個のチェック項目のうち，付録に示す8個の項目のスコアを利用した．それぞれチェック項目のスコアは各項目の内容に該当する箇所の個数であり，qq_2〜qq_8についてはqq_1の項目に当てはまった重複文は除外して数えられている．以上より，要約Sのスコアscore(S)を以下の式によって求める．ここで，N(qq_i)はチェック項目qq_iのスコアであり，length(S)は要約Sの文数である．qq_8の回答は``矛盾している''，``どちらともいえない''，``矛盾していない''のいずれかであり，これらのスコアは順に1，0.5，0としてN(qq_8)の値とした．各スコアは文章中のおかしな箇所の個数であることから，score(S)は小さい方が良いテキスト，即ち，本実験においては一貫性が高いと考える．このscore(S)を用いて，本実験では同じテキストから生成された異なるシステムによる同じ長さの要約のペアに対し，どちらの要約が一貫性があるかを判定する．従って，タスクとしては実験1と同じものとなる．比較する要約のスコアが等しいペアは除外する．テキスト一貫性の判定を実際に利用する状況では，判定が必要なデータを訓練データに用いることはできず，別に訓練データを用意する必要がある．このことを考慮して，本実験では交差検定ではなく節の実験において作成した300記事とそのmixの並べ替えを訓練データとして用い，それによって得られたモデルを用いて判定を行った．実験に使用した学習器や各パラメータの値は節での実験と同じである．また，節の実験と同様に，比較するテキストの差による精度の違いの検証も行った．本実験ではそれぞれの要約のスコアの差が大きければ，一貫性の判定は容易になると考えられる．そこで比較する要約のペアのスコアの差を0から2.0まで0.5刻みでの範囲で分割し，それぞれでの精度を計算した．用いたテストデータ全てに対する，各モデルの精度を表に示す．表中の記号，字体の意味については前節の実験と同様である．学習データとテストデータのドメインが異なるために，前節の実験に比べて全体的な精度は低くなっているが，提案したほぼ全てのモデルにおいてベースラインよりも良い精度を得ることができた．接続関係を考慮したモデル（表中の``+CONJ''の列）とそうでないモデル（表中の``noCONJ''の列）では，最も良い精度を得られたモデルは接続関係を考慮しない場合でのものであったが，それぞれのモデルにおいての接続関係の考慮の有無による違いでは考慮した方が良い精度を示しているものが多くなっている．本実験においても，構文役割の拡張(SR(H))や参照表現の考慮(REF)を組み込んだモデルは，ほとんど改善が見られなかった．これは前節の実験結果と同様であった．語彙的結束性に基づくクラスタリングにおいても，同様にベースラインを上回る結果を得ることができた．比較した要約のスコアの差が小さければ，それらの一貫性を判定することが困難になると考えられる．そこでテストデータの各ペアのスコアの差毎の精度を求めた．その結果を表に示す．1行目のラベルの括弧の中の数字はその範囲に該当する要約ペアの数である．差が2.0より大きいペアについては，該当するペアの数が多くなかったため省略している．要約のスコアの差と精度の関係については，こちらも仮説通りスコアの差が小さければ判定は難しくなり，差が大きくなれば判定は容易であるという結果になった．本実験で用いたTSCのデータは1つの元文書に対して複数のシステム要約が存在しており，上述の計算式で求められたスコアに基づいて同じ元文書から生成された要約を順位付けすることができる．そこで要約のペアの比較ではなく，同一文書から生成された要約の順位を推定するという実験を行った．使用したモデルは前述の実験と同じ300記事とそのmixの並べ替えのデータで学習したものである．評価にはSpearmanの順位相関係数の平均を使用した．結果を表に示す．ベースラインに比べて提案したモデルに高い相関を示すものがあったが，全体的に相関は低いという結果が得られた．これは特にスコアの差が小さい場合での判定精度が影響していると考えられる．本実験結果から，ベースラインと比べると，ある程度実際にテキスト一貫性の判定を行うような設定においても本論文で提案したモデルの方が有効であることが明らかになった．しかし，その精度は高いとは言えず，改良の余地がある．</subsection>
  <section title="おわりに">本論文では接続関係，参照表現，語彙的結束性といった結束装置，また，日本語に特化した構文役割をentitygridモデルに組み込むことで，結束性を考慮したテキストの局所的な一貫性モデルを提案し，その有効性の検証を行った．実験から，提案モデルがテキスト一貫性の高いテキストの判定と自動要約によって作成されたテキストの評価の2つのタスクにおいて，オリジナルのentitygridモデルを上回るということを示した．entitygridによるテキストの一貫性モデルはテキストにおける文中の要素の遷移に着目したものである．本論文ではその要素の遷移は文脈の展開によって違う傾向を示すという仮説を立て，文脈展開の種類を明示的に示す働きを持つ接続関係に着目し，その種類毎にgridを作成するというモデルを提案した．実験の結果，接続関係を考慮したモデルの方がそうでないモデルに比べて良い結果を得ることができ，この仮説がテキストの一貫性の評価において有効であることを示した．また，その他の項目についても一貫性の評価において有効であることを示した．本論文で採用したentitygridに基づいた局所的一貫性のモデルでは，テキストを1つのベクトルとして扱うため，テキスト全体についての一貫性の判定は行えても，テキストの部分についての一貫性の評価は行えない．テキストの部分の一貫性の評価は，小論文の自動評価など教育の現場での利用において有用であると考えられる．また，例えばテキストにおいて一貫性の悪い箇所の数を用いるなどによって，テキストの部分の一貫性の評価をテキスト全体の評価に用いることも可能であると考えられる．このことから，テキスト内の部分的な単位での一貫性の評価手法の提案が今後の課題である．</section>
  <section title="スコアの計算に使用したQuality question">同一の，あるいはほぼ重複する文はいくつあるか?（ゼロ）代名詞化，指示表現化すべき箇所はいくつあるか?先行詞のない指示表現はいくつあるか?固有表現の出現位置がおかしい箇所はいくつあるか?同一事物を参照する表現の一貫性という観点から修正すべき表現はいく	つあるか?（前後の文脈も踏まえた上で）必須要素が欠如している箇所はいくつある	か?接続詞が必要・不必要な箇所はいくつあるか?時系列の関係が矛盾してないか?listdocument</section>
</root>
