<?xml version="1.0" ?>
<root>
  <jtitle>自動獲得した未知語の読み・文脈情報による仮名漢字変換</jtitle>
  <jauthor>笹田鉄郎森信介河原達也</jauthor>
  <jabstract>未知語の問題は，仮名漢字変換における重要な課題の1つである．本論文では，内容の類似したテキストと音声から未知語の読み・文脈情報をコーパスとして自動獲得し，仮名漢字変換の精度向上に利用する手法を提案する．まず，確率的な単語分割によって未知語の候補となる単語をテキストから抽出する．次に，各未知語候補の読みを複数推定して列挙する．その後，テキストに類似した内容の音声を認識させることによって正しい読みを選択する．最後に，音声認識結果を学習コーパスとみなして仮名漢字変換のモデルを構築する．自動収集されたニュース記事とニュース音声を用いた実験では，獲得した未知語の読み・文脈情報を仮名漢字変換のための学習コーパスとして用いることで，精度が向上することを確認した．</jabstract>
  <jkeywords>未知語，音声認識，仮名漢字変換</jkeywords>
  <section title="単語n-gramモデルとその応用">確率的言語モデルとは，任意の記号列に対して，その記号列がある自然言語から生成された確率を計算する枠組みを与えるためのモデルである．本節では，最も一般的な確率的言語モデルの1つである単語n-gramモデルとその応用について述べる．</section>
  <section title="はじめに">計算機の急速な普及に伴い，様々な自然言語処理システムが一般に用いられるようになっている．中でも，日本語の仮名漢字変換は最も多く利用されるシステムの1つである．仮名漢字変換の使いやすさは変換精度に大きく依存するため，常に高精度で変換を行うことが求められる．近年では，変換精度の向上とシステム保守の効率化を両立させるために，確率的言語モデルに基づく変換方式である統計的仮名漢字変換が広まりつつある．変換精度を向上させる上で問題となるのは，多くの言語処理システムと同様，未知語の取り扱いである．統計的仮名漢字変換では，文脈情報を反映するための単語n-gramモデル，入力である読みと出力である単語表記の対応を取るための仮名漢字モデルの2つのモデルによって出力文候補の生成確率を計算し，候補を確率の降順に提示するが，未知語（単語n-gramモデルの語彙に含まれない単語）を含む候補の生成はできない．この問題に対処して変換精度を向上させる一般的な方法は，仮名漢字変換の利用対象分野における未知語の読み・文脈情報を用いたモデルの改善である．仮名漢字変換の利用対象となる分野は多岐に渡っており，未知語の読み・文脈情報を含む対象分野の学習コーパスがあらかじめ利用可能であるという状況は少ない．このため，情報の付与されていない対象分野のテキストに必要な情報を付与して学習コーパスを新たに作成するということが行われる．しかしながら，未知語の中には，読みや単語境界をテキストの表層情報から推定することが困難な単語が少なからず存在する．このような場合には，対象分野の学習コーパスを作成するためにその分野についての知識を有する作業者が必要となるなど，コストの面で問題が多い．上記の問題を解決するために，本論文では，テキストと内容の類似した音声を認識することで未知語の読み・文脈情報を単語とその読みの組として自動獲得し，統計的仮名漢字変換の精度を向上させる手法を提案する．以下に手法の概略を述べる．まず，情報の付与されていない対象分野のテキストから，未知語の出現を考慮した単語分割コーパスである疑似確率的単語分割コーパスを作成し，未知語候補の抽出を行う．次に，疑似確率的単語分割コーパスから音声認識のための言語モデルを構築するとともに，未知語候補の読みを複数推定・列挙し，発音辞書を作成する．その後，言語モデルと発音辞書を用いて対象分野の音声を認識し，音声認識結果から単語と読みの組の列を獲得する．最後に，獲得した単語と読みの組の列を統計的仮名漢字変換の学習コーパスに追加して言語モデルと仮名漢字モデルを更新する．実験では，統計的仮名漢字変換のモデル構築に用いる一般分野のコーパスに，獲得した未知語の読み・文脈情報を追加し，モデルを再構築することで変換精度が向上することを確認した．本論文で提案する枠組みは，対象分野のテキストと音声の自動収集が可能であるという前提のもとで，未知語に対して頑健なモデルを構築することができるため，統計的仮名漢字変換の効率的かつ継続的な精度向上に有効である．</section>
  <subsection title="統計的仮名漢字変換">本項では，で提案されている確率的モデルを用いた統計的仮名漢字変換について述べる．日本語の仮名漢字変換システムは，計算機のキーボードからの入力記号列zを仮名漢字混じり文である文字列xに変換する．ここでは，出力を文字列xとする代わりに単語列wとし，入力記号列zに対応する候補wを以下に示す事後確率P(w|z)が大きいものから順に列挙する．最尤の変換結果wは，P(w|z)をベイズの定理により以下のように変形することで求めることができる．式()において，後半のP(w)は言語モデルであり，節で述べた単語n-gramモデルを用いることができる．前半のP(z|w)は確率的仮名漢字モデルと呼ばれ，単語列wが与えられた際の入力記号列の生成確率を表す．ここで述べている変換モデルでは出力を文字列xではなく単語列wとみなしているため，単語と入力記号列との対応関係がそれぞれ独立であると仮定することでP(z|w)は以下の式で表される．ここで，部分入力記号列z_iは単語w_iに対応する入力記号列であり，全体の入力記号列はz=zhとなる．仮名漢字モデルのパラメータ推定には，単語ごとに入力記号列が付与されたコーパスを用い，式()における確率P(z_i|w_i)の値は，以下の式によって計算される．ここでf(z_i,;w_i)は単語と読みの組の出現頻度であり，f(w_i)は単語出現頻度である．</subsection>
  <subsection title="確率的単語分割コーパス">n-gramモデルの性能はパラメータ学習のためのコーパスに大きく依存する．しかし，決定的な単語分割を行うコーパスを単語n-gramモデルのパラメータ推定に用いる場合，分割誤りによって未知語の出現頻度が0となっている可能性がある．このようなコーパスから構築される単語n-gramモデルは未知語に対する頑健性に欠けるため，本項では，確率的単語分割コーパス並びにその近似である疑似確率的単語分割コーパスの枠組みを用いてこの問題に対処する方法を述べる．</subsection>
  <subsubsection title="疑似確率的単語分割コーパス">上述の確率的単語分割コーパスを用いてn-gram確率の推定を行う場合，単語の出現頻度を計算するために多くの計算時間が必要となる．本節では，この問題に対処するために提案されている疑似確率的単語分割コーパスの枠組みについて述べる．これにより，決定的に単語分割されたコーパスを用いて確率的単語分割コーパスに近いn-gram確率を推定することができ，かつ未知語に対する頑健性を保持することができる．疑似確率的単語分割コーパスは，確率的単語分割コーパスに対して以下の処理を最初の文字から最後の文字まで(1in_r)行うことで得られる．文字x_iを出力する．乱数r_i(0r_i&lt;1)を発生させP_iと比較する．r_i&lt;P_iの場合には単語境界記号（空白）を出力し，そうでない場合には何も出力しない．これにより，確率的単語分割コーパスの特徴をある程度反映し，かつ決定的に単語分割されたコーパスを得ることができる．この処理を1回行って得られるコーパスにおいて，文字列としての出現頻度が低い単語n-gramの頻度は，確率的単語分割コーパスから期待頻度を計算した場合と大きく異なる可能性がある．近似による誤差を減らすためには，上記の手続きをM回行って得られる単語分割コーパス全てを単語n-gram頻度の計数の対象とすればよい．このコーパスを疑似確率的単語分割コーパスと呼び，Mをその倍率と呼ぶ．</subsubsection>
  <section title="未知語とその読み・文脈情報の自動獲得">本節では，仮名漢字変換の対象となる分野のテキストと音声を用いて未知語の読み・文脈情報を自動獲得し，統計的仮名漢字変換で用いられる言語モデルならびに仮名漢字モデルの性能を改善させる手法について述べる．</section>
  <subsection title="提案手法の概略">本項では提案手法の概略について述べる．図に提案手法全体の概要を示す．本研究では，人手によって読みと単語境界が付与されている一般分野のコーパスC_bがあらかじめ用意されているものとする．また，以下では一般分野のコーパスから読みを取り除いたコーパスを一般分野の単語分割コーパスと記述し，その中に存在する単語を既知語，それ以外の単語を未知語と定義する．提案手法では，以下に示す4段階の処理により，未知語の読み・文脈情報を未知語を含む単語と読みの組の列として音声認識結果から獲得し，統計的仮名漢字変換のモデルを更新する．情報の付与されていない対象分野のテキストから疑似確率的単語分割コーパスを作成し，未知語の候補となる単語（以下，未知語候補と記述する）の抽出を行う（3.2項を参照）．疑似確率的単語分割コーパスを用いて音声認識のための言語モデルを構築する．また，未知語候補の読みを複数推定し，音声認識のための発音辞書を作成する（3.3項参照）．準備した言語モデル，発音辞書，音響モデルを用いて対象分野の音声を認識し，音声認識結果から単語と読みの組の列を獲得する（3.4項を参照）．獲得した単語と読みの組の列を統計的仮名漢字変換の学習コーパスに追加して言語モデルと仮名漢字モデルを更新する（3.5項を参照）．以下では，これらの処理について詳細を述べる．</subsection>
  <subsection title="疑似確率的単語分割コーパスを用いた未知語候補の抽出">まず，獲得対象となる未知語候補を単語境界の付与されていない対象分野のテキストから抽出する．本項では，項で述べた疑似確率的単語分割コーパスを用いた未知語候補の抽出について述べる．疑似確率的単語分割コーパスは決定的に単語分割されたコーパスの集合であるが，全く同様の文であっても単語境界に揺れが存在するため，未知語の分割誤りを抑制可能である．しかしながら，テキスト中に出現する全ての部分文字列が単語になり得るという疑似確率的単語分割コーパスの性質上，低頻度の文字列は単語として適切ではないものが多い．このため，出現頻度閾値を設定して適切な未知語候補を抽出する．以下では，未知語候補「守屋」を抽出する場合を例にとり，その手続きを示す．一般分野の単語分割コーパスから単語境界確率を推定するためのモデル（項を参照）を構築し，対象分野のテキストに単語境界確率を付与する．=1.5pt単語境界確率と乱数の比較を行い，倍率Mの疑似確率的単語分割コーパスを作成する．作成した疑似確率的単語分割コーパス内に出現する単語のうち，頻度F_th以上の未知語（一般分野のコーパスに出現しない単語）を未知語候補として抽出する．次項では，未知語候補の音声認識を行うための言語モデルと発音辞書について述べる．</subsection>
  <subsection title="未知語候補を含む言語モデルと発音辞書の作成">音声認識システムを用いて未知語候補を正しい読みとともに認識するためには，未知語候補が語彙に含まれる言語モデルと発音辞書が必要である．本項では，未知語候補を考慮した言語モデルならびに発音辞書の作成方法について述べる．まず，音声認識のための言語モデルを構築する．大語彙連続音声認識システムを用いる場合には，対象分野のコーパスと一般分野のコーパスを用いて対象分野に適合した言語モデルの構築を行うことが一般的である．本研究では，項で作成した疑似確率的単語分割コーパスを一般分野の単語分割コーパスに追加し，言語モデルを構築する．次に，未知語候補の読みを複数推定し，既知語から作成された発音辞書に追加する．読みの推定は，項のn-gramモデルにおける単語wを文字とその読みの組に置き換えたn-gramモデルによって行う．以下では，未知語候補「守屋」を例にとって説明する．単語を1文字ごとに分割し，それぞれの文字について単漢字辞書から得られる読みを列挙する．各文字の読みを組み合わせ，可能性のある単語の読みを列挙する．マモヤ,マモオク,シュヤ,シュオク,モリヤ,モリオク文字と読みの組を単位とするn-gramモデルにより，単語表記からの読みの生成確率を計算する．読みが付与されている一般分野のコーパスから発音辞書を作成し，(3)で推定した未知語候補と読みの組の中から，確率の上位L個を追加する．この際，L個の未知語候補と読みの組の生成確率を反映させるため，単語の読みごとの確率を発音辞書に記述する．上記の例における「守屋」の正しい読みは「モリヤ」であるが，(3)で述べたn-gramモデルによって与えられる確率P(モリヤ|守屋)は最大とならないため，確率の比較による正しい読みの選択は難しい．次項では，本項で作成した言語モデルと発音辞書を用いた音声認識によって未知語候補の正しい読みを選択する方法について述べる．</subsection>
  <subsection title="未知語の読み・文脈情報の獲得">前項の処理で発音辞書中に列挙される未知語候補の読みの中に正しい読みが含まれている場合には，音声認識によって未知語候補を含む単語と読みの組の列が得られる．しかし，前項の処理で推定した読みの多くは誤った読みであるため，音声認識の際に似た発音の単語を取り違え，誤った読みの未知語候補を出力する可能性がある．この問題に対処するため，ここでは言語モデルならびに音響モデルの尤度を反映した事後確率から計算される信頼度を用いて，認識結果における単語の文脈上の妥当性を判定する．ある単語の信頼度CMは0から1の間の値で与えられ，大きい値であるほど信頼性が高いとみなされる．以下では，音声認識を用いて未知語の読み・文脈情報を単語とその読みの列として獲得する手順を示す．対象分野のテキストと同様の話題を扱った音声と，その音声に適合した音声認識用の音響モデルを用意する．(1)の音響モデルと，項の処理によって得られた言語モデルならびに発音辞書を用いて(1)の音声に対し音声認識を行い，単語，読み，単語信頼度の3つ組の列を出力する．音声認識結果のうち，単語信頼度がCM_th以上の単語を抽出し，連続する単語とその読みの組の列を作成する．なお，単語信頼度がCM_thより小さい単語は抽出せず，それまでに抽出された単語とその読みの列を独立した文とみなす．</subsection>
  <subsection title="統計的仮名漢字変換のためのモデル構築">仮名漢字変換のモデル性能を改善するには，対象分野の学習コーパスを大量に用意することが重要である．人手によって十分な量のコーパスを作成することはコストの面で実用的ではないため，まずテキストの読み推定を行うことによって対象分野のテキストに単語境界と読みを自動的に付与する．ここでは，項の式(1)(2)において単語wを単語と読みの組に置き換え，読み推定のためのn-gramモデルを一般分野のコーパスC_bから構築する．この結果得られるコーパスをC_nとする．一般的には，情報の付与されていない対象分野のテキストのみを大量に入手可能である，という状況が多いため，上述の読み推定システムや形態素解析器の利用によって大規模なコーパスC_nを作成し，C_bとC_nからモデルを構築することによって変換精度を向上させることが可能である．しかしながらC_nは一般分野のコーパスC_bから構築されるモデルを用いたシステムによって単語境界や読みを付与されるため，C_bの内部に出現しない未知語の情報をモデルに反映させることは難しい．この問題を解決するため，提案手法では項の処理によって獲得される，未知語を含む単語と読みの列をコーパスC_rとみなし，C_rによって未知語の読み・文脈情報をモデルに反映させ，未知語の変換精度の向上を図る．</subsection>
  <section title="評価">本節では，節で述べた提案手法の評価実験について述べる．まず，項〜項で述べた手法に従って，未知語の読み・文脈情報を単語とその読みの組の列として獲得した．その後，項で示した学習コーパスから統計的仮名漢字変換の言語モデルならびに仮名漢字モデルを構築して精度評価を行い，提案手法の有効性を検証した．</section>
  <subsection title="実験で利用するテキストと音声">本項では，実験を行う際にあらかじめ準備するデータ，ならびに実験の過程で利用するデータについて述べる．</subsection>
  <subsubsection title="テキスト">本実験において利用するテキストコーパスを以下に示す．一般分野のコーパスC_bには現代日本語書き言葉均衡コーパス(BalancedCorpusofContemporaryWrittenJapanese;BCCWJ)を用いた．BCCWJはあらかじめ単語分割がされており，各単語に読みが付与されている．ここで，BCCWJの内部に出現する全ての単語が既知語となる．対象分野のテキストとして，2007年11月2日から2008年1月8日のうち68日間のウェブニュースを自動収集したものを用いた．このウェブニューステキストには情報が付与されていないため，このテキストに対して項で示した手法を適用することで，単語分割と読みの付与を自動的に行い，コーパスC_nを作成した．また，ウェブニュースのテキストは項で述べた疑似確率的単語分割コーパスの作成に用いた．後述する項の実験により，音声認識結果C_rとして単語と読みの組の列が獲得される．C_rは，C_nと同様に仮名漢字変換のためのモデル構築に用いた．テストセットC_tとして，2008年1月9日，2008年1月10日の2日間のウェブニュースを単語分割し，読みを付与したものを用いた．以上に述べたテキストコーパスの文数，単語数，文字数を表に示す．なお，表において，対象分野のテキストに対する自動読み推定結果，ならびに音声認識結果の単語数は，各システムの出力結果から単語数を計数したものである．また，音声認識結果の出力から文境界を同定することは困難であるため，単語数と文字数のみを示す．表に，テストセットにおける未知の1-gram率（未知語率），未知の2-gram率を，単語を単位とする場合と単語と読みの組を単位とする場合のそれぞれについて示す．</subsubsection>
  <subsubsection title="音声">読みを選択するために用いる音声として，収集したウェブニュース記事と同時期に当たる2007年12月5日から2008年1月8日の間に放送された30分のニュース番組の合計17時間の音声を用いた．ここで，対象分野のテキストと音声の類似度として，音声の一部の書き起こし（2008年1月7日，8日の2日分）に対するパープレキシティを示す．後述する対象分野の疑似確率的単語分割コーパスから単語3-gramモデルを構築し，書き起こしに対するパープレキシティを求めたところ，58.5となった．これは，本実験で用いる疑似確率的単語分割コーパスから構築される音声認識用言語モデルは認識対象となる音声に対して十分な単語予測性能を持っている（対象分野の音声と対象分野のテキストが十分に似ている）ことを示している．</subsubsection>
  <subsubsection title="未知語候補の抽出">まず，項で述べた手法に従って対象分野のテキストから疑似確率的単語分割コーパスを作成し，未知語候補の抽出を行った．ここで，疑似確率的単語分割コーパスの倍率はM=10とした．また，未知語候補を決定する際の閾値は，F_th=50とした．また，対象分野のテキストの規模と最終的に獲得可能な未知語の数との関係として，表に，未知語候補のテストセットC_t中の未知語に対する再現率を示す．表では，利用するウェブニュースの日数と疑似確率的単語分割コーパスの倍率Mを変えることでテキストの規模を調節し，それぞれについて再現率を示した．また，確率的単語分割コーパスを作成せず，決定的に単語分割を行った場合の再現率についても，併せて表に示した．C_t内の未知語の集合をUW_t，疑似確率的単語分割コーパス内の未知語候補の集合をUW_cとし，コーパスCにおける単語wの出現頻度をf(C,w)とすると，再現率は[_wUW_tUW_cf(C_t,w)_wUW_tf(C_t,w)]で表される．ここで，_wUW_tf(C_t,w)=2,772である（表参照）．表から，未知語の抽出を行う場合には，決定的な単語分割を行ったコーパスではなく，疑似確率的単語分割コーパスを利用することが有効であることがわかる．</subsubsection>
  <subsubsection title="獲得した未知語と読み・文脈情報の再現率と適合率">本実験の目的は，後述する仮名漢字変換の精度評価において，音声認識結果C_rから獲得した未知語とその読み・文脈情報を利用してテストセットC_tを対象とした仮名漢字変換の変換精度を向上させることにある．C_rを用いて仮名漢字変換のモデルを構築する場合，C_tとC_rに共通して出現する未知語と読みの組，または単語を単位とする未知の2-gramが多いほど仮名漢字変換の精度が向上する．以下では，それぞれの再現率ならびに適合率を示す．まず，C_rから獲得した未知語と読みの組の再現率，適合率を示す．再現率ならびに適合率はそれぞれ[再現率=_uUU_tUU_rf(C_t,u)_uUU_tf(C_t,u),適合率=_uUU_tUU_rf(C_r,u)_uUU_tf(C_r,u)]で表される．計算の結果，再現率は31.6%，適合率は38.2%となった．次に，未知の2-gramの再現率，適合率を示す．コーパスCにおける単語2-gram(w_i-1^i)の出現頻度をf(C,w_i-1^i)，テストセットC_t内の未知の単語2-gramの集合をUB_t，音声認識結果C_r内の未知の単語2-gramの集合をUB_rとすると，再現率ならびに適合率は[再現率=_w_i-1^iUB_tUB_rf(C_t,w_i-1^i)_w_i-1^iUB_tf(C_t,w_i-1^i),適合率=_w_i-1^iUB_tUB_rf(C_r,w_i-1^i)_w_i-1^iUB_tf(C_r,w_i-1^i)]で表される．計算の結果，再現率は31.9%，適合率は25.5%となった．</subsubsection>
  <subsection title="統計的仮名漢字変換による精度評価">本項では，項で挙げた学習コーパスを用いて統計的仮名漢字変換の精度評価を行い，提案手法の有効性を検証する．</subsection>
  <subsubsection title="実験の条件">本実験では，一般分野のコーパスC_b，対象分野のテキストの自動読み推定結果C_n，音声認識結果C_rを用いて統計的仮名漢字変換のためのモデルを構築した．各コーパスの規模はの表に示した通りである．本実験では，3種類のコーパスを以下のように組み合わせて学習コーパスとし，言語モデル（単語2-gramモデル）ならびに仮名漢字モデルを構築した．C_b:ベースラインC_b+C_n:テキストのみを用いた手法（既存手法）C_b+C_n+C_r:テキストと音声に共通して現れる未知語の読み・単語文脈を反映させる手法（提案手法）統計的仮名漢字変換システム全体の精度を評価する基準として，文字単位の再現率と適合率を計算し，(1)--(3)について比較を行った．また，提案手法において未知語の読みと単語文脈を共に利用することの有効性を検証するため，(2)を基準として，C_rから言語モデル(LM)のみを更新した場合と，仮名漢字モデル(PM)のみを更新した場合についても変換精度の評価を行った．本実験における評価指標として，文字単位の再現率と適合率を用いる．それぞれの定義を以下に示す．&amp;=&amp;=align*</subsubsection>
  <subsubsection title="実験結果と考察">(1)--(3)で示した学習コーパスから構築されるモデルによる再現率，適合率を表に示す．C_bを用いる場合（ベースライン）の変換精度とC_b,C_nを用いる場合（既存手法）の変換精度を比較した結果，再現率で8.94%，適合率で11.68%の精度向上が確認された．ここでC_nとC_tは同分野のコーパスであり，C_bはC_nに比較すると小規模なコーパスであるため，この精度向上は単純に学習データの量を増やしたことに起因すると考えられる．次に，C_b,C_nを用いる場合（既存手法）の変換精度とC_b,C_n,C_rを用いる場合（提案手法）の変換精度を比較した結果，仮名漢字変換の精度は再現率で0.36%，適合率で0.48%の改善が見られた．既存手法において，コーパスC_nは対象分野の未知語を考慮しない手法で読みを付与されているため，未知語の正しい分割と読みの付与が行われず，C_bとC_nのみを用いて構築されるモデルでは未知語の誤変換が発生する．しかし，提案手法では項の実験で得られたC_rを用いて未知語の読み・文脈情報をモデルに反映させることが可能である．上記の精度増加は，項で示した未知語の読み・文脈情報の獲得の実験で獲得した未知語と読みの組，未知の2-gramの量に対応しており，より多くの未知語を獲得するほど変換精度が向上すると考えられる．また，C_rを追加することによる精度向上の要因を明らかにするため，C_bとC_nから構築したモデルによる変換精度を基準に，C_rを利用して言語モデルと仮名漢字モデルを独立に更新して精度を比較した．言語モデルのみを更新した場合は，再現率，適合率ともに0.03%の改善となり，仮名漢字モデルのみを更新した場合は，再現率で0.17%，適合率で0.27%の改善となった．言語モデルのみを更新する場合，未知語と読み（仮名漢字変換における入力記号列）との対応付けを行うことが不可能であるため，未知語周辺の文脈が変換精度の向上にほとんど寄与しない．この際，変換精度の向上に寄与する要素はC_rに現れる既知語周辺の文脈情報のみであり，かつC_nに比較してC_rの規模は非常に小さいために，精度がほぼ変化していないと考えられる．仮名漢字モデルのみを更新する場合については，一定の精度向上が観察された．しかしながら，ある読みを持つ未知語に対し，同じ読みを持つ既知語，もしくは結合の結果同じ読みとなる既知語の連続が存在するという状況では，未知語を含む変換候補の言語モデル確率は既知語を含む変換候補の確率に比較して小さくなる．言語モデルと仮名漢字モデルの両方を更新する場合（提案手法）との精度の差は，上述の言語モデル確率の差に起因する．最後に，提案手法を用いることで未知語の変換誤りが改善した例を示す．〜項において例として示した未知語（守屋）は，本実験において実際に獲得された未知語の例であり，音声認識結果C_rを用いることによって未知語の誤変換が改善されることを確認した．以上の結果より，テキストと音声から獲得される未知語の読み・文脈情報は統計的仮名漢字変換システムの精度向上に有効であることが確認された．</subsubsection>
  <section title="関連研究">第節で述べた通り，人手によって任意の分野における未知語の情報を収集することはコストの面で現実的ではない．このため，未知語に関する情報を自動獲得する研究が多く行われている．まず，形態素解析など，自動単語分割を行うシステムにおいて単語辞書に未知語を追加することを目的とした研究について述べる．文献では，ある文の自動単語分割候補におけるN-bestの相対確率を，それぞれの候補において出現する未知語の出現頻度の期待値として与える．その後，出現した未知語の中から一定の閾値より大きい出現頻度の期待値を持つ未知語を獲得している．また，単語分割の際には，未知語を構成する字種によって9種類の未知語タイプを定義し，それぞれのタイプにおける単語長の分布を考慮した未知語モデルを用いることで，未知語モデルの性能向上を図っている．形態素解析のため，品詞を考慮して未知語を獲得する研究として，文献では，コーパス中に出現する任意の部分文字列に注目し，の前後の文字から，が未知語として出現する可能性の高い品詞に属する確率を推定している．その後，出現頻度が一定値以上かつ2文字以上の文字列を単語として抽出しておき，形態素解析器にかけた結果に辞書未登録語が含まれている文字列を未知語として獲得している．日本語は分かち書きを行わない言語であるため，自動単語分割器や形態素解析器において必須となる未知語の情報は正しい単語単位である．このため，形態素解析器のための未知語獲得を行う研究では未知語の読みには言及しないことが多い．しかしながら，本研究では統計的仮名漢字変換の精度向上を目的としているため，未知語の表記ならびにその読みに関する情報を同時に獲得することが望ましい．文献では，仮名漢字変換を用いる際の入力とその変換結果から未知語の獲得と言語モデルの更新を行う手法を提案している．また，言語モデルの更新を繰り返すことで，仮名漢字変換システムの精度が徐々に向上すると報告している．ただし，ここで行われている実験はユーザによるシステムの利用を想定したシミュレーションであり，本論文で扱う自動獲得とは性質が異なる．音声認識の分野においては，未知語を原因とする認識誤りの影響を抑制するため，単語より小さい単位の語彙であるサブワードを擬似的な単語とし，未知語をサブワードの連続として認識する手法が提案されている．しかしながら，日本語の音声認識においてサブワードは基本的に仮名文字列から構成されるため，サブワードをそのまま未知語獲得に用いても仮名漢字変換への寄与は低いと考えられる．文献では，規則を用いてテキストから未知語の候補を抽出，音声認識を用いて読みを自動的に獲得し，発音辞書に追加する手法が提案されている．この手法は，テキストと音声から未知語と読みの情報を獲得する点で本研究と共通しているが，未知語候補の抽出方法と獲得する情報の粒度が本研究と異なる．本研究では，疑似確率的単語分割コーパスを用いることにより，一貫した単語単位で言語モデルと発音辞書を作成する．また，音声認識結果から未知語の読みだけではなく文脈情報を獲得し，統計的仮名漢字変換で利用する確率的言語モデル全体の性能向上を図っている．</section>
  <section title="結論">本論文では，類似した話題を扱っているテキストと音声から未知語の読み・文脈情報を単語と読みの組の列として自動獲得し，統計的仮名漢字変換の精度向上に利用する手法を提案した．自動的に収集可能なニュース記事とニュース音声を用いた実験の結果，音声認識結果から得られる単語と読みの組の列を学習コーパスとして統計的仮名漢字変換のモデルを学習することにより，システム全体の精度が向上することを確認した．以上の結果から，テキストと音声を用いることにより，仮名漢字変換システムの効率的かつ継続的な精度向上を行うことが可能であることが示された．document</section>
</root>
