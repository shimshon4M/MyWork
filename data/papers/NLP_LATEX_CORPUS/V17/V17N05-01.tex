    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline


\usepackage{ascmac}



\Volume{17}
\Number{5}
\Month{October}
\Year{2010}


\received{2009}{10}{3}
\revised{2009}{12}{15}
\rerevised{2010}{6}{29}
\accepted{2010}{7}{27}

\setcounter{page}{3}


\jtitle{注釈事例参照を用いた複数注釈者による評判情報コーパスの作成}
\jauthor{宮崎　林太郎\affiref{YNU} \and 森　　辰則\affiref{EIS}}
\jabstract{
本稿では評判情報関連タスクにおいて必要不可欠と考えられる，評判情報コーパスを人手により効率良く作成する手法について検討し，作成されたコーパスについて基礎的な分析を行う．まず，注釈付けに用いる評判情報モデルとして，項目—属性—属性値—評価の4つ組からなる2層構造モデルを提案する．
次に，複数注釈者の人手によるコーパス作成について検討する．その際に，注釈者間の注釈揺れが問題となる．
予備実験の結果，注釈者が他の注釈者と相談をせずに独自に注釈付けの判断を行った場合には注釈付けの一致率が十分でないことがわかった．
そこで，複数の注釈者間で判断に関する情報を共有するための方法として，注釈事例参照の利用を提案し，注釈事例参照を組み込んだ注釈付け支援ツールの試作を行った．
これにより，注釈付けの判断に関する情報を複数の注釈者間で緩やかに共有することができる．
評価実験によれば，注釈事例の参照機能が注釈揺れ削減に効果があることがわかった．
さらに，上記の手法を用いた評判情報コーパス作成について報告する．
また，注釈事例参照の有効性を確認した後，1万文のレビュー文書に対して10名の注釈者が注釈付けを行い，評判情報コーパスを作成した．そして，作成したコーパスについて，評判情報の各構成要素の統計的調査を行った結果，提案した2層構造モデルを用いて評判情報を捉えることが有効であることがわかった．
}
\jkeywords{評判，コーパス，注釈付け支援}

\etitle{Creation of Sentiment Corpus by Multiple Annotators with an Annotation Tool that has a Function of \\
	Referring Example Annotations}
\eauthor{Rintaro Miyazaki\affiref{YNU} \and Tatsunori Mori\affiref{EIS}} 
\eabstract{
In this paper, we investigated an effective way of creation of a sentiment corpus by using manual annotation.
Sentiment corpora are regarded as indispensable resource in related tasks of sentiment information processing.
First, we proposed a two-layered model of structure of sentiment information, each of which is a tuple of four kinds of elements, i.e.,  `item', `attribute', `value', and `evaluation'.
Second, We investigated corpus annotation by multiple annotators.
In this situation, a corpus to be annotated is divided into multiple parts, and they are assigned to multiple annotators.
Result of preliminary experiment shows that agreement of annotation among multiple annotators is not enough when annotators perform annotation individually.
We proposed utilization of example annotations in the corpus of manual annotation, and a tool for supporting manual annotation based on example annotation.
The proposed tool offers annotators with a way to moderately share the criterion of annotation by referring existing annotations that have been already performed.
Our experimental result shows that referring example annotations is effective to control discrepancy in annotation.
Third, we reported an experiment of creating a sentiment corpus by using the tool.
After confirming the effectiveness, ten annotators annotated a corpus of review text that contains of 10,000 sentences in order to create a corpus of sentiment information.
According to a statistical investigation of each element in the annotated corpus,
the proposed two-layered model is effective to analyze sentiment information in text more precisely.}
\ekeywords{sentiment, corpus, annotation with supporting tool}

\headauthor{宮崎，森}
\headtitle{注釈事例参照を用いた複数注釈者による評判情報コーパスの作成}


\affilabel{YNU}{横浜国立大学大学院環境情報学府}{
Graduate School of Environment and Information Sciences, Yokohama \mbox{National} University}
\affilabel{EIS}{横浜国立大学大学院環境情報研究院}{
Graduate School of Environment and Information Sciences, Yokohama National University}



\begin{document}
\maketitle


\section{はじめに}\label{Chapter:introduction}

近年，Webを介したユーザの情報流通が盛んになっている．それに伴い，CGM (Consumer Generated Media)が広く利用されるようになってきている．

CGMのひとつである口コミサイトには個人のユーザから寄せられた大量のレビューが蓄積されている．その中には製品の仕様や数値情報等の客観的な情報に加え，組織や個人に対する評判や，製品またはサービスに関する評判等のレビューの著者による主観的な見解が多く含まれている．また，WeblogもCGMのひとつである．Weblogにはその時々に書き手が関心を持っている事柄についての記述が存在し，その中には評判情報も多数存在している．

これらのWeb上の情報源から，評判情報を抽出し，収集することができれば，ユーザはある対象に関する特徴や評価を容易に知ることができ，商品の購入を検討する際などに意思決定支援が可能になる．また，製品を販売する企業にとっても商品開発や企業活動などに消費者の生の声を反映させることができ，消費者・企業の双方にとって，有益であると考えられる．そのため，この考えに沿って，文書中から筆者の主観的な記述を抽出し，解析する試みが行われている．

本研究の目的は評判情報抽出タスクに関する研究を推進するにあたって，必要不可欠と考えられる評判情報コーパスを効率的に，かつ精度良く作成すると共に，テキストに現れる評判情報をより精密に捉えることにある．

既存研究においても，機械学習手法における学習データや評価データに評判情報コーパスが利用されているが，そのほとんどが独自に作成された物であるために共有されることがなく，コーパスの質に言及しているものは少ない．また，コーパスの作成過程においても評価表現辞書を作成支援に用いるなど，あらかじめ用意された知識を用いているものが多い．


本研究においては「注釈者への指示が十分であれば注釈付けについて高い一致が見られる」という仮説が最初に存在した．その仮説を検証するため，注釈者へ作業前の指示を行った場合の注釈揺れの分析と注釈揺れの調査を行う．\ref{sec:予備実験1の結果}節で述べるように，注釈者間の注釈付けの一致率が十分では無いと判断されたが，注釈揺れの主要な原因の一つとして省略された要素の存在があることがわかった．
そのため，省略されている要素を注釈者が補完しながら注釈付けを行うことで注釈付けの一致率を向上できるという仮説を立てた．
\ref{sec:予備実験2の結果}節で述べるように，この仮説を検証するために行った実験から，省略の補完という手法は，ある程度効果があるものの，十分に有用であったとはいえないという結果が得られた．

そこで，たくさんの注釈事例の中から，当該文と類似する事例を検索し提示することが，注釈揺れの削減に効果があるのではないかという仮説を立てた．
この仮説に基づき，注釈事例の参照を行いながら注釈付けが可能なツールを試作した．
ツールを用いて，注釈事例を参照した場合には，注釈事例を参照しない場合に比べて，高い一致率で注釈付けを行うことが出来ると期待される．

また，評判情報のモデルについて，既存研究においては製品の様態と評価を混在した状態で扱っており，評価対象—属性—評価値の3つ組等で評判情報を捉えていた．本研究では，同一の様態に対してレビュアーにより評価が異なる場合にも評判情報を正確に捉えるために，製品の様態と評価を分離して扱うことを考える．そのために，項目—属性—属性値—評価の4つの構成要素からなる評判情報モデルを提案する．

なお，本研究で作成する評判情報コーパスの利用目的は次の3つである．

\begin{itemize}
\item
評判情報を構成要素に分けて考え，機械学習手法にて自動抽出するための学習データを作成する
\item
属性—属性値を表す様態と，その評価の出現を統計的に調査する
\item
将来的には抽出した評判情報の構成要素の組において，必ずしも評価が明示されていない場合にも，評価極性の自動推定を目指す
\end{itemize}

上記の手法により10名の注釈者が作成した1万文のコーパスについて，注釈付けされた部分を統計的に分析し，提案した評判情報モデルの特徴について実例により確認する．また，提案モデルを用いることでより正確に評判を捉えられることを示す．





\section{関連研究}
\label{sec:関連研究}

乾ら\shortcite{Inui06}は「評価を記述するもの」や「賛否の表明」は意見の下位分類に含まれるとしている．本研究でも，意見の一部として評判が存在すると考える．意見は主に主観的言明全般を指しているが，物事に対する肯定や否定を表明する評判はその中の一部と考えるからである．

評判情報に関連する研究は，レビュー中の意見記述部分や評判情報記述部分を特定する問題を扱う研究と，記述されている評判が肯定的か否定的かの極性を判断する問題を扱う研究の二つに大きく分かれる．

評判情報記述部分を特定する問題に関連する研究の一つに，文書中のある程度まとまった範囲での意見性を判定するものと，文単位での意見性判定を行うものがある．それとは別に，評判情報記述部分を特定する問題に対するアプローチの中には，評判情報の構成要素を定義し，各構成要素組を抽出しようとするものがある．

文単位での意見性判定においてはYu el al. \shortcite{Yu03}やPang et~al. \shortcite{Pang04}が評価文書中の事実文と意見文を分け，意見文を抽出している．
峠ら\shortcite{Touge05}においても文単位で意見性の判定を行っている．この研究では，文中に現れる単語が意見文になりやすい単語であるか否かを学習しWeb掲示板から意見文の抽出を行っている．
さらに，日本語における評判情報抽出に関する先駆けの研究でもある立石ら\shortcite{Tateishi01}の研究は，あらかじめ用意された評価表現辞書を用いて，対象物と評価表現を含む一定の範囲を，意見として抽出している．

評判情報の構成要素を定義し，各構成要素組を抽出しようとする研究においては，村野ら\shortcite{Nomura03}が評価文の文型パターンを整理し，その構成要素を``対象'' ``比較対象'' ``評価'' ``項目'' ``様態''としている．また，各構成要素毎に辞書を用意することで抽出を行っている．
Kobayashi et~al. \shortcite{Kobayashi07}では評判情報を``Opinion holder''，``Subject''，``Part''，``Attribute''，``Evaluation''，``Condition''，``Support''からなるものとし，対象とその属性・評価の関係を抽出している．また，構成要素組の同定に着目した研究として，
    飯田ら (飯田\ 他\ 2005)\nocite{Iida05}は
評判情報における属性—属性値の組同定問題を，照応解析における照応詞—先行詞の組同定問題に類似した問題と捉え，トーナメント手法を用いて属性—属性値対を同定している．

次に，記述されている意見の極性を判断する研究について述べる．極性を判断する単位についても文書単位，文単位など様々な範囲を対象とした研究が行われている．
Turney \shortcite{Turney02}は文書中に含まれる評価表現の出現比率から評価文書全体の評価極性を求めている．Pang et~al. \shortcite{Pang02}も文書単位での極性判断を行っており，これには機械学習手法を用いている．

文単位の極性判断としてはYu el al. \shortcite{Yu03}が，Turney \shortcite{Turney02}と同様の手法で評価文を肯定，否定，中立に分類している．

上記の研究に関連して，評判情報に関するコーパスの必要性に着目した研究も行われている．日本語の評判情報コーパスに関係する研究としては，小林ら\shortcite{kobayashi06}が，あらかじめ辞書引きにより評価値候補を与えた上での意見タグ付きコーパスの作成を行っている．この研究では，評価値候補に対する注釈者の判断はある程度一致したが，関係や根拠に対する判断の揺れは無視できるものではないことを報告している．
また，Kaji et~al. \shortcite{Kaji06}では箇条書き，表，定型文などを用いてHTML文書から評価文コーパスの自動構築を行っている．

また，意見分析に関するコーパス研究においてはWiebe et~al. \shortcite{Wiebe02}がMPQAコーパスを作成している．これは，新聞記事に対して，主観的な表現とその意見主が注釈付けされた大規模なコーパスである．
Seki et~al. \shortcite{Seki07}は日本語，中国語，英語の新聞記事に対し，文単位で意見文かどうかを注釈付けしている．また，意見文に対してその極性や意見主を注釈付けしている．



既存研究のコーパスと本研究で作成するコーパスの違いについて述べる．MPQAコーパス\shortcite{Wiebe02}においては，主観表現に対して注釈付けを行っており，この点が本研究で作成するコーパスと関連がある．評判情報を正確に捉えるには対象の項目がどのような様態かを表している表層表現に対して主観表現であることに限らず注釈付けを行う必要があるが，MPQAコーパスでは対応していない．一方で，本研究で作成したコーパスでは客観的表現にも注釈付けを行っている．
次にSekiら\shortcite{Seki07}のコーパスとの比較だが，このコーパスでは文単位で意見性の有無を注釈付けしている．評判情報の構成要素の抽出を行うためには文単位ではなく構成要素単位での注釈付けが必要であるが，これには対応していない．一方で，本研究で作成しているコーパスでは対応している．

また，Kajiら\shortcite{Kaji06}のコーパスは文書源としてWebデータを用いている点では，本研究で作成したコーパスと同じだが，注釈付けの単位は文単位であり，評判情報の構成要素の単位で注釈付けはされていない．小林ら\shortcite{kobayashi06}のコーパスも文書源はWebデータである．しかし，同論文に公表されている情報によれば注釈付けされている評価値は一語単位である．また，評価値として主観的な表現のみを注釈付けしており，客観的な値は評価値として扱っておらず，評価値に付随する根拠として扱っている．本稿では主観的な値に加え，客観的な値も属性値の一部として扱っている．小林ら\shortcite{kobayashi06}では客観的な値には注釈付けがされているわけではないため，この点が異なる．さらに，様態を表す表現も全て評価値として扱われている上，評価対象間の階層構造の注釈付けは必要性を認めながらも扱っていない．
これに対して，本研究のコーパスでは様態を表す属性値と評価を分離している．さらに，評価対象間の関係についてはオントロジー情報として記述を行う．

加えて，本研究のコーパスでは，長い表現や客観的な表現に対しても注釈付けを行っている．製品の評価に対して一語単位でのみ注釈付けを行うと，「好き」「嫌い」「良い」「悪い」などの特定の表現のみに注釈付けが行われてしまう．しかし，レビュアーがレビューを記述する際には様々な表現を用いて肯定否定を明示している．また，製品の様態についても，レビュアーは様々な様態に着目してレビューを記述している．このため，一語単位でのみ注釈を行う場合，レビュアーが着目した製品の様態を誤って注釈付けしたり，注釈付けを落としてしまうことがあると考えられる．さらに，これらの長い表現は，表現の一部の語のみに注釈付けを行っても正しい注釈にならないため，長い表現を注釈付けする必要性があると考えた．長い表現に注釈付けを行う必要性がある例を図\ref{fig:注釈付け対象となる長い表層表現の例}に示す．

\begin{figure}[t]
\input{02fig01.txt}
\caption{注釈付け対象となる長い表層表現の例}
\label{fig:注釈付け対象となる長い表層表現の例}
\end{figure}

図\ref{fig:注釈付け対象となる長い表層表現の例}の例における下線部は一語だけに注釈付けを行うことはできないが，これらは製品の様態を表す値段や，評価であり評判情報の一部となる．


注釈付け支援に関する研究では，
    野口ら (野口\ 他\ 2008)\nocite{Noguchi08}が
セグメント間の関係を注釈付けするためのアノテーションツールSLATを作成している．
また，洪ら\shortcite{Kou05}は対話コーパス作成の際に，事例参照を注釈付け作業の支援として用いており，有効性を報告している．他にも，翻訳の分野においては翻訳メモリと呼ばれる原文と訳文のデータベースを用いた翻訳支援が行われている．これも，ある種の事例参照と言える．
本研究では，Kajiら\cite{Kaji06}や小林ら\cite{kobayashi06}のコーパスのように注釈を自動的に付与せずに，注釈事例の参照を用いた評判情報コーパスの作成を行う．
注釈者が注釈付けを行う際に，あらかじめ注釈付けがなされている状態で対象の文を見てもらうと，あらかじめ付与された注釈が判断の前提となってしまうことが予想される．
あらかじめ付与された注釈が注釈者の判断に与える影響に関する実験については今後の課題とし本稿では行わない．
本研究では注釈者が判断に迷う場合に，事例を参照しつつも独自の判断の下で注釈付けを行ってもらうというアプローチを採用した．

また，評判情報のモデル化についても，従来研究においては製品の様態と評価が混在するモデルがその多くであった．本研究では，様態に対する評価がレビュアーによって異なる場合を正確に表現するために，これを分離するモデルを提案する．

本研究では製品全体やその部分について以下の2種類を様態として扱う．

\begin{itemize}
\item
具体的な値\\
例：30~cm，2~G
\item
他の製品との比較から得られる値など主観的であっても，特にその表層表現のみからでは肯定的や否定的といった評価が一意に決まらないもの\\
例：速い，静か，明るい
\end{itemize}


一方，以下に示す例のように，肯定や否定といった極性が陽に記述されている部分を評価として扱う．

\begin{itemize}
\item
陽に記述されている極性表現\\
例：大満足である，いいです，ちょっと不満
\end{itemize}




\section{評判情報の提案モデル}
\label{sec:評判情報の提案モデル}

\subsection{4つ組による評判情報モデル}
\label{sec:4つ組による評判情報モデル}

本節では，本研究で提案する評判情報モデルについて説明する．提案モデルでは，評判情報は製品やサービスに対する個人の見解やその製品がどのようなものであるかが述べられたものであるとし，4つの構成要素から成るものとする．構成要素の各項を以下に示す．

\begin{description}
\item[　　項目]
製品やサービスを構成する要素を意味する概念クラスやそのインスタンス
\item[　　属性]
項目の様態を表す観点
\item[　　属性値]
属性に対する様態の内容
\item[　　評価]
項目に対する極性を明示している主観的見解
\end{description}

提案モデルに沿った評判情報の解析例を例文1に示す．

\vspace*{0.5\baselineskip}
例文1：\underline{この製品}$_{項目}$は\underline{価格}$_{属性}$が\underline{安い}$_{属性値}$のが\underline{魅力です}$_{評価}$。
\vspace*{0.5\baselineskip}

提案モデルでは（属性，属性値）の組で表現される項目の様態が属する層と，評価の属する層との2層構造とすることで，従来の研究\shortcite{Kobayashi05-1}では混同されることが多かった対象となる項目の様態と話者の評価を分離することができる．これにより，例文2，例文3のように同一の様態に対して異なる極性の評価が記されている場合にも，評判情報を正確に捉えることが出来るようになる．

\vspace*{0.5\baselineskip}
例文2：\underline{このフィギュア}$_{項目}$は\underline{フォルム}$_{属性}$を\underline{忠実に再現している}$_{属性値}$のが\mbox{\underline{お気に入りです}$_{評価}$。}

例文3：\underline{この製品}$_{項目}$は\underline{フォルム}$_{属性}$を\underline{忠実に再現している}$_{属性値}$ために\underline{魅力が薄い}$_{評価}$。
\vspace*{0.5\baselineskip}

本研究で提案するモデルにおける評価は，主観的な表現の中でもその表現のみでいかなる文脈でも変わらない極性を示す表現である．文脈に依存して異なる極性を暗示する表現は評価としない．
提案モデルの構造を図\ref{fig:評判情報モデル概要}に示す．図\ref{fig:評判情報モデル概要}では製品の部分全体関係とその様態を表す層と，製品やその部分に関する評価の属する層を示している．この2層の関係は，様態を表す層に属する属性—属性値の組を評価の属する層にある評価の理由とし，様態を表す層に属する製品やその部分を対象に評価が記述することで表される．このように，製品の様態と評価を分離した2層構造にすることで，同一の属性—属性値の組からレビュアーにより異なる評価が与えられている場合には異なる評価への関連付けが可能となっている．
提案モデルでは，肯定・否定は評価によってのみ決定され，属性—属性値の組についてはそれが主観性を含むものであっても，製品の様態のみを表し，評価は含まれていないとして扱う．

\begin{figure}[t]
\includegraphics{17-5ia2f2.eps}
\caption{評判情報モデル概要}
\label{fig:評判情報モデル概要}
\end{figure}

また，様態を表す層では，製品の項目が部分—全体関係や上位—下位関係のような階層構造を持ち，それぞれが属性，属性値を持つことを表している．これは必ずしも階層構造の葉の部分のみが属性，属性値を持つわけではなく，上位の項目の属性—属性値の組について記述されている場合もある．さらに，下位の階層の項目が持つ属性—属性値の組を理由に上位の階層の項目を評価する場合もありえる．

項目が指示するモノが属する概念クラスは全体—部分関係や上位—下位関係といった階層構造を有する．この情報はいわゆるオントロジー（の一部）であり，必ずしも文書中に陽に現れるものではない．
しかし，製品への評価を考えた場合に，その部分の属性や評価が全体の評価の理由になっている場合が考えられる．
そのため，次の2点を目的としてオントロジーに関する情報を注釈者に記述してもらう．

\begin{itemize}
\item
注釈者が項目間の関係をどのように捉えたかを，コーパス利用者が特定できるようにする
\item
注釈者が製品をどのように捉えたかについての構造を残すことで，コーパス利用者が項目と属性の切り分けを確認できるようにする
\end{itemize}

なお，オントロジーに関する情報は文中に付与するタグとは別に記述する方法を提案する．記述されたオントロジー情報の例を図\ref{fig:オントロジー情報の記述例}に示す．

\begin{figure}[t]
\input{02fig03.txt}
\caption{オントロジー情報の記述例}
\label{fig:オントロジー情報の記述例}
\end{figure}

オントロジー情報はオントロジーの木構造に現れる各ノードを先順で記述してあり，行頭にある\verb| + |は深さを，その後ろの\verb| [ ] |の中が各階層の概念番号を表している．この概念番号はitemタグを注釈付けする際のclass属性の値と対応している．\verb|< > |の中は表層表現であり，同一概念や指示物を表す表層表現は同一の概念番号を付与している．なお，提案モデル中ではレビューで着目している製品に対応する概念が起点になっており，それより上の側には概念の上位—下位関係が，そしてそれよりも下側には概念の全体—部分関係が記されている．図\ref{fig:オントロジー情報の記述例}の例では「この圧力鍋」が起点となっている．この方法により注釈者毎にオントロジー情報を作成してもらうことを想定している．また，各注釈者が作成したオントロジー情報を1つに統合することは想定していない．

また，このモデルにおいては評価の理由となるのが属性—属性値の組であると考える．
先行研究のモデルの多くでは，評価と属性値とが区別無く扱われていた．本研究ではこれらを別々に扱う．
また，一般的には主観的な表層表現と評価には密接な関係がある．しかし，主観的な表層表現が必ずしも極性を一意に決定するわけではない．つまり，評価ではない．提案モデルでは肯定・否定・中立の判断にかかわる表層表現を評価と呼び，主観的な表現であっても評価の理由となる様態を表現しているものを属性—属性値と呼ぶ．例を以下に示す．

\vspace*{0.5\baselineskip}
例文4：\underline{ディスプレイ}$_{項目}$の\underline{画質}$_{属性}$も\underline{きれい}$_{属性値}$で\underline{いいです}$_{評価}$ね。
\vspace*{0.5\baselineskip}



なお，構成要素の各項は表層表現が文中で省略されている場合がある．特に，属性—属性値の組については片方が省略されている場合が多く存在する．例文を次に示す．

\vspace*{0.5\baselineskip}
例文5: \underline{このカメラ}$_{項目}$ は\underline{小さく}$_{属性値}$ て\underline{気に入っています}$_{評価}$。
\vspace*{0.5\baselineskip}

例文5では属性値「小さい」が単独で出現している．これは本来ならば属性として現れるべき「大きさ」や「サイズ」といった表現が省略されているものと解釈する．


\subsection{評判情報を注釈付けするためのタグセット}
\label{sec:評判情報を注釈付けするためのタグセット}

\begin{figure}[b]
\input{02fig04.txt}
\caption{評判情報構成要素のタグセット}
\label{fig:評判情報構成要素のタグセット}
\end{figure}

本研究では，前節で述べたモデルの項目をitem，属性をattribute，属性値をvalue，評価をevaluationとしてXMLのタグセットを作成した．作成したタグセットを図\ref{fig:評判情報構成要素のタグセット}に示す．itemタグは対象となる製品やその部分を表す表層表現に付与する．同様にattributeタグ，valueタグ，evaluationタグはそれぞれ，属性，属性値，評価を表す表層表現に付与する．
図\ref{fig:評判情報構成要素のタグセット}には注釈付与のためのXMLタグの要素名と属性情報を示してある．なお，各タグにはそれぞれ一意に決まる識別子をid属性として付与する．attributeタグとvalueタグは片方が省略されている場合を考え，組ごとに一意に決まる識別子をそれぞれのpair属性の値として付与する．
evaluationタグにはその評価の理由となるattribute-valueのpair属性の値をreason属性として付与する．また，評価の極性をpositive，neutral，negativeの3値でorientation属性として付与する．





\section{予備実験}
\label{sec:予備実験}

本節では予備実験の内容について述べる．本研究の目的は人手による評判情報コーパスの作成である．大規模なコーパスの作成，将来におけるコーパスの拡張を考えた場合に，複数注釈者による注釈付け作業の並列化が不可欠であると考えた．

複数注釈者による注釈付け作業を行う際には，注釈揺れが問題となる．本研究では，\ref{sec:関連研究}章で述べたように注釈付け対象となる文書に対して，事前に機械的に注釈付けすることを想定していない．注釈者に先入観を与えずに判断をしてもらう必要があると考えたためである．
さらに，あらかじめ用意された辞書等の知識を注釈付けに用いるのならば，その知識を直接抽出に用いればいいと考えたためである．本研究では，特定の表現にとらわれず，注釈者には様々な表層表現に対して注釈付けを行ってもらう．

ここで本稿では，注釈者には事前に指示を行い，それが十分ならば複数の注釈者が独立して注釈付けを行っても，注釈付けにおいて高い一致が見られるという，以下の仮説1を立てた．

\vspace*{0.5\baselineskip}
\begin{quote}
仮説1：注釈者への事前の指示が十分ならば，複数の注釈者が独立して注釈付けを行っても注釈付けの高い一致が見られる．
\end{quote}
\vspace*{0.5\baselineskip}

上記の仮説1が成立するなら，コーパスを作成するために複数の注釈者に個別に仕事を割り振り，並列作業を行うだけで十分であると言える．
仮説1を確認するため，予備実験として複数注釈者による注釈付け作業を行い，注釈者間の注釈付けの一致率を調査した．



\subsection{予備実験1の方法}
\label{sec:予備実験1の方法}

本稿では注釈付けの対象としてAmazon\footnote{http://www.amazon.co.jp}からレビュー文書を収集した．本稿の前提としては，あらゆる製品に対してレビューがあればその全てに注釈付けを行いたいと考えている．
そのため，Amazonのトップページの製品分類を元に，なるべくそれらを網羅することを考えた．

コーパスに用いるテキストをAmazonから収集した時点\footnote{2007年2月}ではAmazonのトップページにある製品分類は「本，ミュージック，DVD」「家電，エレクトロニクス」「コンピュータ，ソフトウェア」「ホーム\&キッチン」「おもちゃ，ゲーム，キッズ」「スポーツ，アウトドア」「ヘルス，ビューティー」の7種類であった．

これらに属する製品は，製品の主要部分が有形物であるものと，無形物であるものに分類できるが，これら二つに分類される製品は互いに構造が異なるため，レビューに表れる表現が異なる．
有形物のレビューにおいては，物理的な特徴に関する記述が多くなると考えられる．
一方，無形物に対してはその機能や物語に対する特徴が記述される場合が多い．
これに関連して，Turneyら\shortcite{Turney02}は，映画のレビュー分析において，映画は「出来事や俳優といった映画の要素」と，「様式や美術といった映画の形態」という二つの様相を持つ特徴があるため，自動車などのレビューと異なる特徴があると述べている．

Amazonの製品分類において我々が有形物と分類したものは「家電，エレクトロニクス」「ホーム\&キッチン」「おもちゃ，キッズ」「スポーツ，アウトドア」「ヘルス，ビューティー」「コンピュータ」である．
また，「本，ミュージック，DVD」「ソフトウェア」「ゲーム」は無形物とした．「ゲーム」を無形物としたのは，レビューの対象がボードゲームのように形を持つものではなくゲームソフトだったためである．

次に，有形物の中から，複数の機能を有しそれを実現するために自動的に動作することが多い電化製品と，自ら動作することはなく人間に道具として使われる非電化製品の2つのジャンルにさらに分類した．
Amazonの製品分類の中では「家電，エレクトロニクス」に加えて「コンピュータ，ソフトウェア」の中の「コンピュータ」を電化製品として分類した．
残りの「ホーム\&キッチン」「おもちゃ，キッズ」「スポーツ，アウトドア」「ヘルス，ビューティー」を非電化製品とした．本稿ではこれら非電化製品の中から「ホーム\&キッチン」「おもちゃ，キッズ」を注釈付けの対象とした．

無形物に対しては，ユーザが視聴，閲覧といった受動的な関わり方をするだけの映像・音楽と，操作等の能動的な関わり方をするソフトウェアの2つのジャンルにさらに分類した．
実際の製品分類の中からは，「ミュージック，DVD」を映像・音楽として分類した．また，「コンピュータ，ソフトウェア」の中の「ソフトウェア」と「おもちゃ，ゲーム，キッズ」の中の「ゲーム」をソフトウェアとして分類した．
「本」に関しては，事前の調査において，レビュー文章中に本の中の記述が引用されている場合が存在することが確認された．こうしたレビューについて，本の引用部分は評判情報の注釈付けの対象外であるので，引用部分に引用であることを示す別の注釈づけを行い，レビューの本文と分離して管理をする必要がある．
しかし，本稿の目的はレビュー文に対する注釈付けであり，引用については本稿の目的の範囲外であると考え除外した．

上記の各ジャンルについて50文，計200文を実験毎に用意し，条件を変えて次に示す予備実験1を行った．
なおitemに関しては，製品名やその部分の呼称，照応表現などに限られているため，あらかじめ別の注釈者により注釈付けを行った状態で，それ以外のタグの注釈作業を行ってもらった．同時に，item間の関係を参照できるようにitemタグを注釈付けした際に作成されたオントロジー情報を各注釈者に配布した．

\begin{description}
\item[予備実験1]
itemタグが既に付与されている文書に対して，評判情報の構成要素（すなわち，attribute，value，evaluation）を注釈者に注釈付けしてもらった．また，注釈付けの対象となるレビュー文書はあらかじめ文単位に分けてXMLファイル化し，注釈付けを行ってもらった．オントロジー情報は各注釈者が同じものを参照している．
注釈付けの際に特別なツールは利用せず，テキストエディタのみを使用してもらった．注釈を行った被験者は情報工学を専攻する学生5名であり，2名は本研究との直接の関係を持つ．
\end{description}

また，予備実験1の際に注釈者に行った作業指示を付録\ref{sec:予備実験1における注釈者への作業指示}に示す．


\subsection{予備実験1の結果}
\label{sec:予備実験1の結果}

予備実験において，attribute，value，evaluationの3要素について注釈者間の注釈付けの一致率を調べた．次に示す3つの場合を，注釈者間の注釈付けが一致したものと判定した．


\begin{itemize}
\item
完全一致
\item
部分文字列一致
\item
一方ではattributeとvalueを分けているが，他方では両方を一つのvalueとしている場合
\end{itemize}

最初に，完全一致である．これは同一箇所の全く同一の文字列に対して同一のタグが付与されている場合である．
次に，部分文字列一致である．これは完全一致ではないが，タグが付与されている両文字列に共通部分が存在する場合である．予備実験では，形態素区切りや文節区切りを明確にして注釈付けを行ったわけではないために，タグの範囲についてはわずかに異なってしまう場合がある．このような状況を許容して一致とみなすものである．

\begin{figure}[b]
\input{02fig05.txt}
\caption{完全一致と部分文字列一致の例}
\label{fig:完全一致と部分文字列一致の例}
\end{figure}

完全一致と部分文字列一致の例を図\ref{fig:完全一致と部分文字列一致の例}に示す．図\ref{fig:完全一致と部分文字列一致の例}における部分文字列一致の例では，「強さ」のattributeに対するvalueが「頑強」であるという点ではどちらの注釈者も注釈付けが一致している．しかし，程度を表す表現「それなりに」の部分をタグに含めているかどうかという点が異なっている．


最後に，一方ではattributeとvalueを分けているが，他方では両方を一つのvalueとしている場合がある．図\ref{fig:valueの中にattributeを含んでしまっている例}に示すように，attributeタグを付与するかどうかが異なっているがvalueタグを付与した表層表現は部分一致している．これは，valueタグの注釈付け範囲の細かさの違いから起こるものである．例を図\ref{fig:valueの中にattributeを含んでしまっている例}に示す．

図\ref{fig:valueの中にattributeを含んでしまっている例}の場合，注釈者Aの注釈付けが，我々が意図していた注釈付けである．
この例について考えると，注釈者Bが省略されていると考えたattributeは「操作のしやすさ」である．また，注釈者Aは「操作」の表層部分が「操作しやすさ」を意味するattributeであると認識している．この点を考えると，図\ref{fig:valueの中にattributeを含んでしまっている例}の場合は2人の注釈者が「しやすい」という点では同じ認識をしていると考えられる．
また，図\ref{fig:valueの中にattributeを含んでしまっている例}の揺れは「サ変名詞+する」の組み合わせである点が揺れの理由として挙げられる．
その間を区切るかどうかが注釈者によって分かれている．しかし，注釈揺れに対する注釈事例参照の効果の確認実験ではこの点については注釈者に指示をしていなかった．本稿では，このような場合はvalueについて部分一致しているものとして扱った．


また，一致率の評価尺度には $\kappa$ 値を用いた．$\kappa$ 値は主観が入る判定が偶然に拠らず一致する割合であり，0.41から0.60の間ならば中程度の一致，0.80を超えるとほぼ完璧な一致と考えられる．
\begin{equation}
\kappa 値=\frac{（二人の注釈者が同じ判断をしている割合）-（偶然に一致すると期待される割合）}{（1-偶然に一致すると期待される割合）}
\end{equation}

\begin{figure}[b]
\input{02fig06.txt}
\caption{valueの中にattributeを含んでしまっている例}
\label{fig:valueの中にattributeを含んでしまっている例}
\end{figure}
\begin{table}[b]
\caption{予備実験1の注釈付けの一致率（$\kappa$ 値）}
\label{tab:予備実験1の注釈付けの一致率}
\input{02table01.txt}
\end{table}



予備実験1における注釈付けの一致率を調べた結果を表\ref{tab:予備実験1の注釈付けの一致率}に示す．表\ref{tab:予備実験1の注釈付けの一致率}において注釈者2名の組（注釈者は全部で4名なので全6組）の中で最も高い $\kappa$ 値（上段）と低い $\kappa$ 値（下段）を示してある．

一致度の高い注釈者の組では $\kappa$ 値で0.6以上の値となっている部分も多数あり，ある程度の一致率となっていると考えられる．しかし，一致率の低い注釈者間では $\kappa$ 値は0.3以下となってしまっている．これは仮説1が成り立たなかった事を意味する．

次に，予備実験1で明らかになった注釈付けの揺れについて，それらが生じる場合にどのようなものがあるのかをその数とともに調査した．
まず，予備実験1において注釈付けを行った200文の内，5人の注釈者全員の注釈付けが一致した文は42文，4人の注釈者のみ一致して1人一致しなかった文は42文であった．以上についてはほぼ一致していると考え，残りの116文中に存在した注釈揺れについて調査した．

同一箇所の同一文字列に対する注釈揺れに注目すると，a)注釈者により同一箇所の同一文字列対する注釈付けの有無が異なる注釈揺れが存在する文が91文，b)同一箇所の同一文字列に対して異なるタグを付与されているために注釈揺れが存在する文が52文存在した．この52文の内，一方の注釈者がvalueタグを付与している箇所について，別の注釈者はevaluationタグを付与している文が47文存在した．

また，注釈付けを行う範囲が異なり，場合によってはタグも異なるために注釈揺れとなっている文が17文存在した．
この17文の内，c)注釈付けされた文字列の最後の文節については同じ注釈付けがなされているものが9文，d)注釈者により注釈付けの粒度が異なるために揺れが複数タグにまたがるものが8文であった．

加えて，e)一方の注釈者がevaluationタグを付与している箇所について，別の注釈者はこれを二つわけてattributeとvalueの組として捉え，attributeタグならびにvalueタグを付与しているために注釈揺れとなっている文が4文存在した．
なお，同一文中に複数の揺れがあり得るので，合計数は注釈付けが一致していないとした116文を超えている．
それぞれの注釈揺れの例を図\ref{fig:予備実験1の結果における注釈揺れ}に示す．

なお，我々のモデルでは図\ref{fig:予備実験1の結果における注釈揺れ}においては，注釈者Aのように注釈付けすることを意図している．

図\ref{fig:予備実験1の結果における注釈揺れ}の「a)同一箇所の同一文字列に対する注釈付けの有無が異なる揺れの例」について述べる．この例において，本来ならば「声」にattributeを注釈付けし，「機械的」にvalueを注釈付けするのが正しいが，注釈者Bは注釈付けを行っていない．注釈者が注釈付けを行う部分が存在すると判断するかどうかが揺れている．


次に，「b)同一箇所の同一文字列に対する注釈が異なる揺れの例」について述べる．ここでは，同一箇所の同一文字列に対してvalueとevaluationという異なるタグが付与されることで注釈が揺れている．この場合には本来ならば，「可愛い」という表現は必ずしも肯定的に使われるとは限らないので，valueタグを注釈付けするのが正しいが，注釈者Bはevaluationタグを付与している．

「c)末尾部分が同じ注釈付けをされている例」の場合には，注釈者Aと注釈者Bは共に「すばらしい」の部分は評価であると認識している．一方で，「その日の気分によって聞ける」の部分をvalueとするか，evaluationの一部とするかが異なっている．この揺れは，注釈者により注釈付けの粒度が異なるために発生すると考えられる．

「d)複数タグにまたがる注釈揺れの例」の場合，valueタグのみに注目すると部分文字列一致となっている．しかし，前のattributeタグを見ると「踊っている」をどちらのタグに含めるかが異なっている．つまり，区切りが揺れている．

\begin{figure}[t]
\input{02fig07.txt}
\caption{予備実験1の結果における注釈揺れ}
\label{fig:予備実験1の結果における注釈揺れ}
\end{figure}

「e) attribute-value組とevaluationの注釈付けが異なる例」の場合，極性を持たないvalueがattributeと組になることで，注釈者が極性を持つと判断し，evaluationとしてしまった事が原因となる揺れと考えられる．

上記の内a)，b)が最も多い．これらの注釈揺れの原因として，省略された要素の存在があるのではないかと考えた．省略された要素が注釈揺れの原因となっているのならば，注釈者が注釈を行う際に，省略されている要素を補完した上で注釈付けを行うことで，注釈付けを行おうとしている表現に対して，4つ構成要素の内のどれに当たるかを判断する際の注釈揺れを削減することが期待できる．
例えば，図\ref{fig:予備実験1の結果における注釈揺れ}のb)の例では，attributeが省略されている．この例に対して「外観」をattributeとして補うことで「可愛い」がその属性値として認識されやすくなると期待される．そこで次の仮説2を立てた．

\vspace{0.5\baselineskip}
\begin{quote}
仮説2：省略されている要素を注釈者が補完しながら注釈付けを行うことで複数注釈者間の注釈付けの一致率を向上できる．
\end{quote}
\vspace{0.5\baselineskip}

この仮説を検証するために行った実験が予備実験2である．


\subsection{予備実験2の方法}

予備実験1と同様にAmazonから収集したレビュー文200文を，itemタグが付与された状態で注釈者に配布した．
以下に示す条件で予備実験2を行った．
\begin{description}
\item[予備実験2]
itemタグが既に付与されている文書に対して，attribute-valueの組については片方の要素が省略されている場合にはその要素を補完しながら注釈付けを行ってもらった．補完作業は注釈者が想像するだけでなく，実際に省略されている要素の内容がどのようなものになるかを記述してもらった．記述の方法は\ref{sec:評判情報を注釈付けするためのタグセット}節のattributeとvalueの注釈付け規則に，省略であることを明示する属性を追加し，attributeが省略されていると注釈者が判断した場合には，attributeが省略されていると思われるvalueタグの直前にattributeタグを記述し，タグの要素として省略されていると思われる表現を注釈者に記述してもらった．同様にvalueタグが省略されていると思われる場合にはvalueが省略されていたattributeタグの直後に同様に注釈者に省略されていると思われる表層表現を記述してもらった．
用いた文書は予備実験1とは異なる．予備実験1と同様特別なツールは利用せず，テキストエディタのみを使用してもらった．注釈を行った被験者は本研究と直接の関係がある情報工学を専攻する学生2名であり，予備実験1に参加している．
\end{description}
予備実験2で作成した，省略されていた要素を補完した注釈付けの例を図\ref{fig:省略されていた要素を補完して注釈付けを行った例}に示す．
また，予備実験2で利用した作業指示を付録\ref{sec:予備実験2における注釈者への作業指示}に示す．

\begin{figure}[b]
\vspace{-1\baselineskip}
\input{02fig08.txt}
\caption{省略されていた要素を補完して注釈付けを行った例（下線部が省略を補完した部分）}
\label{fig:省略されていた要素を補完して注釈付けを行った例}
\end{figure}


\subsection{予備実験2の結果}
\label{sec:予備実験2の結果}

\begin{table}[b]
\caption{予備実験2の注釈付けの一致率（$\kappa$ 値）}
\label{tab:予備実験2の注釈付けの一致率}
\input{02table02.txt}
\end{table}

予備実験2を行った結果を表\ref{tab:予備実験2の注釈付けの一致率}に示す．
予備実験2は注釈者が2名だったため，2名の間の $\kappa$ 値のみを記してある．
なお，一致の評価については予備実験1と同じ方法を用いている．

結果を見ると，多くの場合で $\kappa$ 値が0.4を超えている．このことから，中程度の一致はしていると言える．
しかし，予備実験1の最低値と比較すれば一致率は良いが，最高値と比べると一致率が安定しているとはいえず，十分であるとは言えない．
この結果から，省略の補完という手法は，ある程度効果があるものの，十分に有用であったとはいえない．
このため仮説2自身は成立すると思われるが，その適用範囲が限定的であると考えられる．

予備実験1，2においては，各注釈者は注釈付けを行う際に，他の注釈者と相談等による情報共有をせず，それぞれが独自に注釈付けを行っている．
しかし，各注釈者が独自に注釈付けを行った場合に，省略された要素の補完を各注釈者が行っても，一致率は十分とは言えなかった．
さらなる注釈揺れの削減のためには，注釈者が完全に独立して注釈付けを行うのではなく，注釈付けを行う個別の場合について，注釈付けの判断に関する情報を共有した状態で注釈付けを行う必要があると考えられる．

そこで以下の仮説を立てる．

\vspace{0.5\baselineskip}
\begin{quote}
仮説3：注釈者が完全に独立して注釈付けを行うのではなく，注釈付けの判断に関する情報共有をすることで注釈付けの一致率を向上させることができる．
\end{quote}
\vspace{0.5\baselineskip}

仮説3を実験するための具体的な方法として，次章で注釈事例の参照について述べる．



\section{注釈事例を用いた評判情報の注釈付け}
\label{sec:注釈事例を用いた評判情報の注釈付け}

本章では注釈者が独立に注釈付けを行いつつも，判断に関する情報共有を行える手法を提案する．

\ref{sec:予備実験}章の予備実験において一致率が十分ではなかったため，仮説3を立てた．
この仮説3における注釈付けの判断に関する共有を，どのように行うかを検討した．
まず，注釈者間の話し合いを定期的に設けて，注釈揺れについて議論を行う手法を検討した．しかし，主に時間的な側面からコーパス作成作業のコストが膨大になってしまう点が問題となった．
そこで，本稿では過去の注釈事例を参照しながら注釈付けを行う手法を提案する．
そして，仮説3を検証するために，具体的な方法として次の仮説3$'$の検証を行うこととする．

\vspace{0.5\baselineskip}
\begin{quote}
仮説3$'$：複数注釈者間で注釈事例を共有し，これを参照しながら注釈付けを行うことで注釈揺れを減らすことが出来る．
\end{quote}
\vspace{0.5\baselineskip}


話し合い等により注釈者間の判断を共有しない場合には，複数の注釈者間で共有する判断材料としては注釈者に対する指示が基本となる．
あらゆる状況を網羅して想定した上で個別事例に対する指示を用意することが理想であるが，それは現実的ではない．
そこで，個別事例に対する指示を用意するかわりに，過去の注釈事例の中から注釈付け対象となる文に「似た」事例を探し出し，文単位で提示する手法を提案する．
さらに事例の中には，注釈付け作業の発注者が注釈付けを行った事例も含めることが出来るので，発注者の要求を事例として含めることも出来る．
このため，個別事例に対する指示を用意するのと同様の効果が得られるのではないかと考えた．

図\ref{fig:予備実験1の結果における注釈揺れ}に示される注釈揺れについて，注釈事例の参照を用いることによる注釈揺れの削減効果について考えてみる．
注釈付け対象となる表現については，表層表現が一致した事例を提示することが出来れば，これは当然注釈揺れの削減に繋がると考えられる．
例えば図\ref{fig:予備実験1の結果における注釈揺れ}のb)における「可愛い」やe)における「あります」などは，レビュー文に出現しやすそうな表現であるが，こういった表現に対する注釈事例を
提示できれば，注釈揺れが減らせる．

また，注釈付け対象となる表層表現が必ずしも完全に一致しなくても，類似した表現を事例で提示出来れば注釈者の判断の支援になると考えられる．
図\ref{fig:予備実験1の結果における注釈揺れ}のa)における「機械的」やd)における「目に見える」などは類似した表現が存在する可能性が高いと思われる．

さらに，注釈付けを行う対象として注目している表現の周囲の表現について見てみると，文単位で事例を提示することで，注釈付けの判断対象となる表現の周囲の表現も注釈者は参照可能となる．
この周辺の表現が事例により参照可能になることで，どこまで注釈付けの範囲とするかの揺れの削減に効果があるのではないかと考える．
例えば図\ref{fig:予備実験1の結果における注釈揺れ}のc)における注釈揺れにおいては，両方の注釈者が「すばらしい」の部分はevaluationだと判断しているが，その前の部分のどこまでが注釈付けの範囲となるかを判断する際の支援が可能になると思われる．

また，図\ref{fig:予備実験1の結果における注釈揺れ}の例にはないが，注釈付けされたコーパスの中にある，注釈付けを含まない文も事例として登録しておき，参照できるようにしておくことにより，注釈者が注釈付けを行わないという判断を支援できると考える．
すなわち，注釈者が注釈付けを行おうとしている文がそのような事例に類似しているときには，それを提示することにより注釈付けが行われていないこと注釈者が確認できるので，注釈者はあえて注釈付けを行わないという判断を下すことができる．

上記のいずれの場合においても，注釈付けを行おうとしている文に対して，複数の事例を提示する事ができる．
これにより，図\ref{fig:予備実験1の結果における注釈揺れ}のb)のような場合，レビュアーが記述した主観的な表現にどのような注釈付けがされているか示す過去の注釈事例を複数提示することで，valueとevaluationのどちらを注釈付けすればよいかの判断を支援する事が出来るのではないかと考えた．

これは，複数注釈者間で判断を緩やかに共有することを目的とするものである．注釈事例の参照により，注釈者間の話し合いに時間をかけずに，注釈揺れを減らすことが期待される．
ここでも，\ref{sec:予備実験}章冒頭で説明したように，前もって機械的な注釈付けを行うことはせず，注釈者が判断に悩む時に，事例を参照してもらうというアプローチを用いた．
一方で，注釈事例の参照の利用は，注釈者が，すでに付与されている一つの注釈可能性をみるだけでなく，複数の注釈可能性が存在しうることがわかるという効果も考えられる．この点は，事例となる文の選択が適切に働けば，注釈付けの際に有効だと思われる．



\subsection{注釈事例の提示機能を有する注釈付けツール}
\label{sec:注釈事例の提示機能を有する注釈付けツール}

本稿で我々が提案する手法は，評判情報コーパス作成に従事する注釈者へ注釈事例の提示を行うことにより，注釈揺れを削減しながら複数注釈者による注釈付けができるようにする方法である．
既存のエディタや
    注釈付けツール (野口 他 2008)\nocite{Noguchi08}では
事例の提示が行えないため，新たに注釈付けツールを試作した．図\ref{fig:注釈付けツールの画面}に作成した注釈付けツールの画面例を示す．

\begin{figure}[b]
\includegraphics{17-5ia2f9.eps}
\caption{注釈付けツールの画面}
\label{fig:注釈付けツールの画面}
\end{figure}

上段部には注釈付け対象となる文とその前後の文を表示している．注釈者は注釈付け対象となる文を順に見ていく．文中の範囲を指定し，中段部にあるタグ付与のためのボタンで注釈付けを行う．この際，下段部には編集中の文に類似した注釈付け済みの文を例示しているので，どのようなタグを注釈付けすると良さそうかを下段部の事例を参照して判断することが出来る．さらに，XMLタグの属性情報の入力を行うことにより，組となる要素の指定などを行う．

試作した注釈付けツールの特徴は，注釈付けを行おうとしている文に似た過去の事例を提示することにより，注釈者が注釈付けを行う際に参考に出来る点である．
これを実現するためには，注釈付け対象文に類似した注釈事例を事例集の中から検索する必要がある．
事例の提示においては，注釈付け対象となっている文において，注釈付けが必要となりそうな部分と類似した表現をなるべく多く含む事例を提示することが望ましい．そのために，注釈付けが必要となる部分と同一の表層表現に対して過去に注釈付けされた例の提示を行う．
本稿では類似度計算に文字bigramの一致の度合いとして定義される次式を用いた．
\begin{equation}
類似度=\frac{両文での文字bigramの一致数}{対象文の長さ+事例文の長さ}
\end{equation}

上記の式は単純なものだが，簡単な事例提示を行うだけで注釈付けの一致率が向上するのならば，事例提示の有効性が示せると考えられる．

また，本稿で用いた提示事例の類似度計算においては，事例中の各文と注釈対象文との一致を文字bigramで計算しており，既に付与されたタグの有無は考慮しない．タグを付与するべきではない文を明示的に扱ってはいないが，事例中の類似度が高い文においてタグが付与されていないものが提示されれば，間接的に「現在の対象文に対してはタグを付与するべきではない」ということが例示により示せる．

今後さらなる注釈付けの一致率向上を考えた際には，表層表現の一致だけではなく，意味的に類似した注釈事例の提示を行う等の，異なる文間の類似度を用いることが必要になると思われる．
また，本実験で使用した事例集合では確認できなかったが，事例中に非常に似かよった文が存在する場合には，簡単な類似度計算のみでは提示される注釈事例が類似した文で埋め尽くされてしまう可能性がある．今後コーパスサイズを拡大する際には，MMR \shortcite{Carbonell98}のような手法を用いて，提示事例中の類似文を除去する必要がある．

なお，現在の設定では，新たな注釈付け対象文が読み込まれる度に，事例集として指定されたファイルに含まれる文の中から注釈付け対象文との類似度が高い，上位5文を検索し表示する．
また，注釈事例の提示に併せて，注釈付け対象文に注釈付けがされていた文字列が存在する場合には，強調表示するようにした．これは注釈付けの見落としを少なくするためである．
現在の版のツールでは，提示事例中で注釈付けがなされている文字列と，注釈対象文の文字列との間で文字bigramが2つ以上連続して一致した部分については，注釈対象文中の文字を太字で強調表示している．

上記に加え，注釈者の作業を軽減するため，タグの付与作業の支援と，各タグのid属性値の自動入力が行えるように実装した．



\section{注釈揺れに対する注釈事例参照の効果の確認実験}
\label{sec:注釈揺れに対する注釈事例参照の効果の確認実験}

本節では\ref{sec:注釈事例を用いた評判情報の注釈付け}章で述べた注釈事例の参照と注釈付けツールの有効性について検証するための実験について述べる．注釈付けツールを用いない場合と用いた場合，注釈事例の参照を行った場合と行わない場合の注釈付けの一致率の変化と，予備実験1で発見された注釈揺れが，注釈事例を参照することでどのように減少するかを調査することで仮説3$'$を確認する．


\subsection{注釈揺れに対する注釈事例参照の効果の確認実験の方法}
\label{sec:注釈揺れに対する注釈事例参照の効果の確認実験の方法}


予備実験1と同様にAmazonから収集したレビュー文書，4ジャンル200文について注釈者が注釈付けを行った．
予備実験1と同様に製品についての部分—全体関係を記述したオントロジー情報があらかじめ作成してあり，itemタグがあらかじめ付与されている文書を使用した．本節で行う注釈揺れに対する注釈事例参照の効果の確認実験では，次の三つの条件で注釈者に注釈付けを行ってもらった．


\begin{description}
\item[　条件1]
ツール無し：注釈付けツールを使用しない．注釈事例の提示も行わない．
\item[　条件2]
事例無し：注釈付けツールを使用する．しかし，注釈事例の提示は行わない．
\item[　条件3]
事例有り：注釈付けツールを使用する．注釈事例の提示を行う．
\end{description}

3つの条件下での注釈付けの比較を行うため，6人の注釈者を2名ずつ3つのグループに分けて各文書について条件を変えて3回注釈付けを行ってもらった．注釈者のグループ分けと注釈付けの順番を表\ref{tab:注釈付けツールを用いた実験の手順}に示す．
また，注釈揺れに対する注釈事例参照の効果の確認実験で注釈事例として使用した文書は，予備実験の過程で注釈付けされた文書の中の一人分（200文）である．

\begin{table}[b]
\caption{注釈付けツールを用いた実験の手順}
\label{tab:注釈付けツールを用いた実験の手順}
\input{02table03.txt}
\end{table}

表\ref{tab:注釈付けツールを用いた実験の手順}のように，注釈者1から注釈者4までには「事例有り」を最後に行ってもらい，注釈者5・6には「事例有り」を最初に行ってもらった．また，注釈揺れに対する注釈事例参照の効果の確認実験で注釈を行った被験者は情報工学を専攻する学生6名である．2名（注釈者3と注釈者4）は本研究との直接の関係を持ち，すべての予備実験に参加している．他の4名は本研究と直接の関係を持たず，その内の2名（注釈者1と注釈者2）は予備実験に参加していない．
残りの2名（注釈者5と6）は予備実験に参加している．

本章の実験，すなわち「注釈揺れに対する注釈事例参照の効果の確認実験」で用いた作業指示は予備実験1の指示に加えて\ref{sec:注釈事例の提示機能を有する注釈付けツール}節で紹介した注釈付けツールの使用説明書と，上述の実験の手順である．
ここで，予備実験2に際して，追記された作業指示（補完に関するもの）は破棄していることに注意されたい．これは，予備実験2の結果，仮説2は成立するが，効果が少なかったためである．



\subsection{注釈事例の効果に関する確認の実験結果}
\label{sec:注釈事例の効果に関する確認実験の結果}

本節では，評判情報の注釈付けにおいて事例参照を用いた場合と用いなかった場合を比較した時の，複数注釈者間における一致率の変化，図\ref{fig:予備実験1の結果における注釈揺れ}における注釈揺れの変化について述べる．


\subsubsection{注釈者間の一致率}
\label{sec:注釈者間の一致率}

本節では，注釈揺れに対する注釈事例参照の効果の確認実験の結果の内，同じ条件の2名の注釈者が注釈付けした文書断片の数と，注釈付けの一致率について述べる．

最初に，各注釈者が注釈付けをした文書断片の数，すなわち，付与したタグの数を調べた．結果を表\ref{tab:各注釈者が付与したタグの数}に示す．
表\ref{tab:各注釈者が付与したタグの数}を見ると，注釈者1と2，注釈者3と4は，attributeタグとvalueタグについては3回目の注釈付けで最も多くの部分に注釈付けを行っている．このことから，注釈付けのために付与したタグの数については注釈者の学習による影響が懸念される．しかし，注釈者5・6が注釈のために付与されたvalueタグの数を見ると，3回目に行った「ツール無し」の場合が2回目に行った「事例無し」の場合に比べて減っている．この点から考えると，注釈者の学習による影響が全ての要因であるとは言えない．何回目に注釈付けを行ったかに関わらず，事例有りの多くの場合が注釈付けされたタグの数が最多である．このように注釈付けされた順序だけに因らないことを考慮すると，注釈事例の提示による注釈付け支援により，注釈者がより細かく注釈付けを行うことができたと推測される．

\begin{table}[b]
\vspace{-1\baselineskip}
\caption{各注釈者が付与したタグの数}
\label{tab:各注釈者が付与したタグの数}
\input{02table04.txt}
\end{table}


次に，注釈者間の注釈付けの一致について調べた．注釈揺れに対する注釈事例参照の効果の確認実験では\ref{sec:予備実験1の結果}節と同様に次に示す3つの場合を，注釈者間の注釈付けが一致したものと判定した．

\begin{itemize}
\item
完全一致
\item
部分文字列一致
\item
一方ではattributeとvalueを分けているが，他方では両方を一つのvalueとしている場合
\end{itemize}

上記の一致に関する判断基準に基づき，各被験者の組における注釈付けの一致率（$\kappa$ 値）をタグの種類ごとに調べた．表\ref{tab:注釈付けの一致率}に結果を示す．

\begin{table}[b]
\caption{注釈付けの一致率（$\kappa$ 値）}
\label{tab:注釈付けの一致率}
\input{02table05.txt}
\end{table}

注釈揺れに対する注釈事例参照の効果の確認実験の結果では，多くの場合で「事例有り」の場合に$\kappa$ 値が高かった．注釈者5と6におけるvalueにおいてのみ「事例無し」の結果の方がよくなっているが，これは「事例有り」の場合から先に実験を行ったグループでのことなので，注釈者が学習をしてしまった結果とも考えられる．しかし，「事例有り」から注釈付け作業を開始した注釈者の組と，「事例無し」から注釈付け作業を開始した注釈者の組の一致率に大きな違いが無い．さらに，過去に1度も予備実験に参加していない注釈者の組（注釈者1・2）を見ると，回数を重ねた2回目においても1回目と比べて安定した一致率が得られているとはいえない．しかし，注釈事例を参照した3回目においては他の組と同程度の安定した一致率が得られている．これより，注釈者が注釈付け作業を経験し学習してしまった効果よりも，事例提示を行った効果の方が大きいと考えられる．

また，事例参照の有効性については，「事例有り」から注釈付け作業を開始した注釈者の組の結果に注目したい．同じデータに対して3回の注釈付け作業を行っていながら，注釈事例の参照を行わなくなることで一致率が低下している．これは，注釈者の学習効果により一致率が高まるよりも，事例を参照しなくなったことにより注釈者が独自の判断で注釈付けを行ってしまい，一致率が低くなってしまうためと考えられる．このことからも，注釈事例の参照は一致率を安定させるために有効であると言える．
この結果，仮説3$'$は正しかったといえる．

なお，本稿で用いた事例集合が十分に参考になる情報を提示しているかということを確認するためには本来ならば，個々の注釈付けにおいて，その都度表示された事例が有効であったかという検証を行いながら，事例集合の量と質を検証することが必要である．しかし，本稿では，相対的な結果として，本稿で用いた事例集合であっても注釈揺れの削減に効果があったという提示のみとなっている．本稿で用いた事例の量が十分であるかどうかはわからないため，事例集合の量と質の検討が今後の課題として挙げられる．


\subsubsection{注釈揺れの分析}
\label{sec:注釈揺れの分析}

本節では注釈揺れについて，細かく分析を行う．
まずは，注釈付けが一致した部分がどのように変化したかを調べるために，典型的な例である，二人の注釈者が注釈付けした結果の中で，両方の注釈者が同一の文に対して完全に一致した注釈付けを行っている場合の数を調べた．ここで，「完全に一致した注釈付け」とは文中に注釈付けがなされた箇所が存在し，複数の注釈付けがあったときにはその全てが可不足なく一致している場合である．二人の注釈者が共に注釈付けを全く行わなかった文については調査外としている．
表\ref{tab:完全に一致した注釈付けが行われた文数}に結果を示す．

\begin{table}[b]
\caption{完全に一致した注釈付けが行われた文数}
\label{tab:完全に一致した注釈付けが行われた文数}
\input{02table06.txt}
\end{table}

表\ref{tab:完全に一致した注釈付けが行われた文数}においては，注釈事例を参照した場合が，注釈者間で完全に注釈付けが一致した文の数が最も多く，最も良い結果となっている．
また注釈者がどのような順番で注釈付け作業を行った場合でも，「事例有り」の時に一致した文が増えたということは仮説3$'$を裏付けるものである．

さらに，表\ref{tab:完全に一致した注釈付けが行われた文数}において，注釈者の各組について，注釈付けが完全に一致した文について分析した結果を表\ref{tab:完全に一致した注釈付けが行われた文数の変化}に示す．
表\ref{tab:完全に一致した注釈付けが行われた文数の変化}の結果を見ると注釈付けが揺れていた部分については，事例の参照を行うことで注釈揺れが改善した．なお，表\ref{tab:完全に一致した注釈付けが行われた文数の変化}中の「ツール無し」の場合に一致していなかった文の内，「事例有り」で一致した文については，同一文中にて複数種類の改善が行われたために注釈付けが一致するようになった文が存在する．このため，改善の種類の内訳について文数を合計すると，一致するようになった文数よりも多くなっている場合がある．
また，注釈事例の参照を行ったために新たに注釈付けが揺れるようになった文を見ても，注釈付けの範囲が変わったため一致しなくなった文については，完全一致だったものが部分一致になるという揺れであった．部分一致を正解とする判定においては，この揺れは一致率に影響を与えない．
以上の各点より，全体で見ると注釈事例の参照により注釈付けの一致率の向上が見られる．

次に，図\ref{fig:予備実験1の結果における注釈揺れ}に示したa)〜e)の注釈揺れが注釈事例の参照を用いることでどのように変化したかについて述べる．
まず最初に，予備実験1における図\ref{fig:予備実験1の結果における注釈揺れ}の「a)注釈付けを行うかどうかが異なる揺れ」がどのように変化したかを調べるために，一方の注釈者のみがタグを付与した部分の数をタグごとに調べた数を表\ref{tab:一方の注釈者のみが注釈付けしたタグの数}に示す．

\begin{table}[t]
\caption{完全に一致した注釈付けが行われた文数の変化}
\label{tab:完全に一致した注釈付けが行われた文数の変化}
\input{02table07.txt}
\end{table}

この表によると，実験の順番や，ツールの有無，注釈事例の有無の各条件と，一方の注釈者のみが注釈のために付与したタグの数の間には相関が見られない．しかし，表\ref{tab:各注釈者が付与したタグの数}と比較してみても，付与されたタグの数が増えた場合に一方のみが注釈付けしたタグの数が増えているというわけではないため，注釈事例の提示による悪影響は考えられない．

次に予備実験1で確認した図\ref{fig:予備実験1の結果における注釈揺れ}の「b) valueとevaluationの注釈が異なる揺れ」の変化を調べる．
「b) valueとevaluationの注釈が異なる揺れ」は同一箇所の同一文字列に対して異なるタグが付与された注釈揺れの一つである．
表\ref{tab:同一箇所の同一文字列に異なるタグが付与された数}に本章の実験，すなわち「注釈揺れに対する注釈事例参照の効果の確認実験」において同一箇所の同一文字列に対して異なるタグが付与された時のタグの違い方とその数を示す．

\begin{table}[t]
\caption{一方の注釈者のみが注釈付けしたタグの数}
\label{tab:一方の注釈者のみが注釈付けしたタグの数}
\input{02table08.txt}
\end{table}
\begin{table}[t]
\caption{同一箇所の同一文字列に異なるタグが付与された数}
\label{tab:同一箇所の同一文字列に異なるタグが付与された数}
\input{02table09.txt}
\end{table}

表\ref{tab:同一箇所の同一文字列に異なるタグが付与された数}を見ると，valueタグとevaluationタグの揺れが最も多かった．これは予備実験1の結果と同じである．注釈揺れに対する注釈事例参照の効果の確認実験によると，この問題点についても必ずしも「事例有り」の場合に揺れが減っているとは言えない．
しかし，これについても表\ref{tab:各注釈者が付与したタグの数}と比較して，「事例有り」で注釈付けされたタグ数が増えた場合に注釈揺れが増えているわけではない．

続いて，予備実験1で確認した残りの注釈揺れの事例についても調査した．図\ref{fig:予備実験1の結果における注釈揺れ}で述べた「c) 末尾部分が同じ注釈付けをされている注釈揺れ」，「d) 複数タグにまたがる注釈揺れ」，「e) attribute-value組とevaluationの注釈付けが異なる揺れ」のそれぞれの数を表\ref{tab:事例を参照した場合のc), d), e) の注釈揺れの変化}に示す．

表\ref{tab:事例を参照した場合のc), d), e) の注釈揺れの変化}を見ると，予備実験1でもそうであったように，この3種類の注釈揺れは図\ref{fig:予備実験1の結果における注釈揺れ}のa), b)の揺れに比べて少ない．しかし，注釈者1と注釈者2の結果を見ると事例の参照の効果がうかがえる．

最後に，注釈揺れに対する注釈事例参照の効果の確認実験において問題となった注釈揺れをまとめると以下のようになる．

\begin{table}[t]
\caption{事例を参照した場合の図\ref{fig:予備実験1の結果における注釈揺れ}におけるc), d), e)の注釈揺れの変化}
\label{tab:事例を参照した場合のc), d), e) の注釈揺れの変化}
\input{02table10.txt}
\end{table}

\begin{description}
\item[1)]{同一箇所の同一文字列に注釈を付与するかどうかの揺れ}

　これについては注釈者に因るところが大きく，完全に無くすことは不可能と考える．揺れを減らすために各注釈者に，なるべく細かく注釈付けを行うように依頼することとする．
なお，現在行っている事例の提示は注釈付けがなされた表層表現に注目しているが，注釈付けがなされなかった表層表現にも注目して事例の提示を行うことが今後の課題として考えられる．
\item[2)]{同一箇所の同一文字列に異なるタグが付与されている揺れ}

　特にvalueタグとevaluationタグの違いが多かった．
これについては，注釈事例を増やすことで注釈揺れを減らすことが出来ると予想される．注釈事例を増やした場合の効果として，類似した表層表現を検索・提示する際のヒット率が上がる事が考えられる．また，注釈付けの判断対象となる周囲の表現についても，事例を増やすことで事例中に表示することが可能になると予想される．このような表現は注釈者間の判断を揺れなくす材料になると考えられる．

\item[3)]{注釈付けの範囲が異なる}

　注釈付けの範囲については，表現を注釈付けに含めるか含めないかの判断が揺れている．
そのため，どの場合に含め，どの場合に含めないかを示すため，注釈付け対象となる表現の周囲の文脈を提供することで，注釈揺れの削減が期待できる．
しかし，十分な量の注釈事例が無く，事例の探索についても簡単な方法を用いている現在では，注釈付けの範囲についての規則を追加することが揺れを減らすために効果的と考える．
\end{description}

またさらに注釈揺れを減らす方法として，提案した評判情報モデルを実例に適応する際の判断の基準を洗練する等が考えられる．これは，注釈者のモデルに対する理解度の差による揺れを解消しようとするものである．これについては，注釈者の判断を確認するテスト等を行うなどの方法を今後検討する必要がある．


\section{評判情報コーパスの作成実験}
\label{sec:評判情報コーパスの作成実験}

本章では試作した注釈付けツールを用いた，評判情報コーパスの作成実験について述べる．


\subsection{評判情報コーパスの作成実験の方法}
\label{sec:評判情報コーパスの作成実験の方法}

最初に，各注釈者へ事前説明を行った．注釈者には\ref{sec:予備実験}章や\ref{sec:注釈揺れに対する注釈事例参照の効果の確認実験}章の実験と同じく\ref{sec:4つ組による評判情報モデル}節で述べた評判情報モデルについての解説をし，過去の実験で得られた注釈事例から「注釈揺れが起きた実例」と「判断が難しかった実例」を示しながら事前説明を行った．

\ref{sec:注釈揺れの分析}節の分析から，注釈付けの量については，注釈付けが必要かどうか判断に迷った場合には，その部分にはなるべく注釈付けを行うように依頼した．同様に，\ref{sec:注釈揺れの分析}節において分析した注釈付けされた文字列の最後の文節における注釈揺れ，複数タグにまたがる注釈揺れの2点に関しても，注釈付けの粒度をなるべく細かくすることを注釈者に注意した．なお，これらの説明を行う際にも，\ref{sec:注釈揺れに対する注釈事例参照の効果の確認実験}章の実験で得られた注釈事例から実例を提示して説明を行った．

また，当初から評判情報の構成要素が省略される場合としては，attributeが省略されvalueやevaluationが現れる場合か，attributeが記述されているがvalueが省略されevaluationが現れる場合か，もしくはattributeとvalueの両方が省略されevaluationのみが現れる場合が想定されていた．
しかし予備実験1の結果attributeが記述されているにもかかわらず，valueもevaluationも記述されない場合が発見された．以下に例を示す．

\vspace*{0.5\baselineskip}
例文6：この製品は値段が…
\vspace*{0.5\baselineskip}

例文6のような場合は，文として不完全である．また，評判情報という性質上，``どのような製品であるかという記述''，``レビュアーの評価''のどちらも記述されていない部分については注釈を付与する必要性が無いと考えられる．
このため，本章の実験では，最初にvalueタグもしくはevaluationタグを注釈付けする部分を探しながら注釈付けを行うように，各注釈者に指示した．また，その際にvalueとevaluationに該当する文字列がどちらも存在せずにitemやattributeのみが現れた場合には注釈付けを行わなくてもよい旨を説明した．

さらに，\ref{sec:注釈揺れの分析}節で述べた注釈揺れ3)のような注釈揺れや，\ref{sec:注釈揺れに対する注釈事例参照の効果の確認実験}章の結果では部分文字列の一致に基づく一致として扱った事例を減らすために注釈付けの規則を追加した．これは\ref{sec:注釈者間の一致率}節の分析結果等から追加したものである．この規則には，本稿で提案した評判情報のモデルで意図した注釈付けを行ってもらうための規則と，注釈の範囲に関する注釈揺れを減らすための規則がある．

前者について追加した規則と追加した理由を図\ref{fig:意図した注釈付けを行ってもらうために追加した規則}に示す．
図\ref{fig:意図した注釈付けを行ってもらうために追加した規則}は，一方の注釈者が我々が意図しない注釈付けを行ってしまったために注釈付けの範囲が揺れている例であり，実例を示しながら注釈者への指示を指示書に追加した．

\begin{figure}[b]
\input{02fig10.txt}
\caption{意図した注釈付けを行ってもらうために追加した規則}
\label{fig:意図した注釈付けを行ってもらうために追加した規則}
\end{figure}

また，後者について追加した規則を図\ref{fig:注釈の範囲に関する注釈揺れを削減するために追加した規則}に示す．
図\ref{fig:注釈の範囲に関する注釈揺れを削減するために追加した規則}の例は，評判情報の注釈付けという本来の目的においては，どちらでもよい．
一方で，注釈付けの一貫性を保つためには，注釈付けの発注者が指示を与えて，一方の注釈付けに合わせる必要がある．図\ref{fig:注釈の範囲に関する注釈揺れを削減するために追加した規則}の規則はそのためのものである．

加えてモダリティに関して追加した規則を図\ref{fig:モダリティ部分に関する規則}に示す．
図\ref{fig:モダリティ部分に関する規則}の規則はモダリティを除いた命題部分のみに注釈付けしてもらうために追加した規則である．
疑問については，その命題についてレビュアーが直接言及していないので除外した．

上記の説明を行った後に，コーパス作成に利用するレビューとは別に，次に述べる各製品ジャンルから40文ずつ，計200文のレビューをAmazonから収集し，コーパス作成に参加する注釈者に注釈付けの練習を行ってもらった．また練習の後，注釈間違いや注釈揺れについては筆者を中心とし注釈者間で指摘をし合い，注釈者間で話し合いを行い，判断の統一を試みた．

\begin{figure}[t]
\input{02fig11.txt}
\caption{注釈の範囲に関する注釈揺れを削減するために追加した規則}
\label{fig:注釈の範囲に関する注釈揺れを削減するために追加した規則}
\end{figure}
\begin{figure}[t]
\input{02fig12.txt}
\caption{モダリティ部分に関する規則}
\label{fig:モダリティ部分に関する規則}
\end{figure}

次に，注釈付けに用いた文書について述べる．注釈付けに用いた文書は，Amazonから収集したレビュー1万文である．使用した製品のジャンルは基本的に予備実験と同様であるが，非電化製品をAmazonの製品ジャンルを基に「ホーム・キッチン」，「ホビー・おもちゃ」の二つに分けて，電化製品，ホーム・キッチン，映像・音楽，ソフトウェア，ホビー・おもちゃの5ジャンルとした．それぞれのジャンルから2,000文ずつを収集した．さらに，1万文の内の1,000文（5ジャンルから200文ずつ）は事前に第一著者が注釈付けを行い，事例用コーパスとして用いた．

注釈者は情報工学を専攻する学生10名である．注釈付けは9,000文を200文程度に分割し，作業時間に余裕がある人に順次配布していく形で行った．作業量は注釈者により2,000文から200文まで様々である．

なお，過去の実験の知見を元に，本章の実験すなわち「評判情報コーパスの作成実験」における注釈者への作業指示を付録\ref{sec:評判情報コーパスの作成実験における注釈者への作業指示}に示す．


\subsection{コーパス作成実験結果}
\label{sec:コーパス作成実験結果}

\subsubsection{コーパス修正作業}
\label{sec:コーパス修正作業}

10名の注釈者によるコーパス作成を行った後，注釈者の入力ミス，同一文字列に対する注釈揺れ等の明らかに分かる誤りに関しては筆者が修正作業を行った．

最初に注釈者の入力ミス，入力忘れが判明した部分を修正した．入力ミスが確認されたタグは全部で705個，コーパス作成作業で注釈付けされた全タグの内の4.42\%であった．入力ミスの内容としては，「タグに付与する属性情報の入力忘れ」，「入力する属性項目が入れ替わってしまっている」，「注釈付けツール使用時にマウスの操作を誤ったために注釈範囲が誤っている」等が主なものであった．
以上の入力ミスは注釈付けツールのインターフェースに起因すると思われるものもあり，注釈付け作業者の使い勝手という面から注釈付けツールの改良を検討する必要性がある．

次に，同一表層表現に対し，異なるタグが注釈付けされている部分について，修正を行った．具体的には，同一表層表現に対し，異なるタグが注釈付けされている部分を確認し，正しいと考えられる注釈付けへと統一した．表\ref{tab:同一文字列の同一範囲に対する注釈揺れ}に注釈揺れの種類と数を示す．

\begin{table}[b]
\caption{同一文字列の同一範囲に対する注釈揺れ}
\label{tab:同一文字列の同一範囲に対する注釈揺れ}
\input{02table11.txt}
\end{table}

さらに，各注釈付けを確認し，事前説明に沿わない部分，明らかに一部の注釈者のみが異なるタグを付与している部分については修正をし，正しいと考えられる注釈付けに揃えた．

次に，同一文字列に対する異なるタグの中で，上記の方法によっても一方のタグに統一することができなかった部分について述べる．itemに関連する部分では，製品の特徴を表現し得る語句が名称の一部に用いられている場合が12個で最も多かった．例を以下に示す．

\vspace*{0.5\baselineskip}
例文7：少なくとも観た事のあるシリーズの中では \verb|<evaluation>| ベスト \verb|</evaluation>| です．

例文8：注目を集めた—彼女—の \verb|<item>| ベスト \verb|</item>| も初回盤で \verb|<value>| 5040円 \verb|</value>|．

例文9：決して寄せ集めではない \verb|<item>|ベストアルバム \verb|</item>|．
\vspace*{0.5\baselineskip}

例えば，「ベスト」は一般的には評価を表す表現と考えられ，その事例は例文7のようなものである．一方で，例文8における「ベスト」という表層表現は評価を表す「ベスト」ではなく，「ベストアルバム」という商品を指し示すため用いられている．つまり，例文9と同じ商品を指して入る．この場合，例文7のように評価を示す「ベスト」にはevaluationタグを，例文8のように商品の指し示す「ベスト」にはitemタグを付与した状態を正しいものとした．同様の例として「コンパクト」，「ブラック」等が挙げられる．また，今注目しているitemが別のitemと関係をもって記述されるときにはattributeとして扱われる場合がある．その場合においては，一方のタグに統一することができないものが6個あった．同様の理由でitemとvalueが同じ表層表現になっているものが4個あった．このような問題は表現が指し示す概念が多義であるために起こると考えられる．例を図\ref{fig:視点となるitemに起因する揺れの例文}に示す．


\begin{figure}[b]
\input{02fig13.txt}
\caption{視点となるitemに起因する揺れの例文}
\label{fig:視点となるitemに起因する揺れの例文}
\end{figure}
\begin{figure}[b]
\input{02fig14.txt}
\caption{サ変動詞の省略が行われているために表層表現が同じになっている例}
\label{fig:サ変動詞の省略が行われているために表層表現が同じになっている例}
\end{figure}


attributeとvalueについて，一方のタグに統一することが出来ずに残ったものに，
サ変動詞の省略が行われているために表層表現が同じになっているものがあった．例を図\ref{fig:サ変動詞の省略が行われているために表層表現が同じになっている例}に示す．他に，動詞や形容動詞が活用形により名詞と同じ表層表現になってしまったもの，「〜的」という表現等，同音異義語，言葉の意味自体がよく分からないために修正すべきではないとした部分がある．

最後に，さらに追加で行った修正について述べる．我々は作成したコーパスを教師情報とした学習型の抽出手法を用いた評判情報の構成要素の抽出を検討している．文字を単位としたチャンク同定手法を用いて，評判情報の構成要素の抽出予備実験を行ったところ，itemの抽出精度が著しく低い結果となった．評判情報コーパスの作成実験におけるコーパス作成では，「valueもevaluationも無い文には注釈付けを行わなくてもよい」と注釈者に説明したため，ある場所ではitemタグが付与されているが，別の個所に現れる同一の表層表現には付与されていない場合がった．このために学習がうまく進まなかったと考えられたため，itemに関しては全文を第一著者が見直し，追加で注釈付けを行った．修正前と修正後のitemタグの数と抽出精度を表\ref{tab:itemタグの修正前後の比較}に示す．抽出には固有表現抽出に用いられるチャンク同定手法を用いた．表に示す抽出精度は，ジャンルごとにitemの自動抽出を行った際のF値の平均である．

\begin{table}[b]
\caption{itemタグの修正前後の比較}
\label{tab:itemタグの修正前後の比較}
\input{02table12.txt}
\end{table}



\subsubsection{基礎統計}
\label{sec:基礎統計}

本節では，コーパス作成実験の結果得られたコーパスの全体的な傾向を把握するための基礎的な分析を行う．

最終結果として得られた，1万文のコーパスに注釈付けされた表現の数を表\ref{tab:注釈付けされたタグ数}に示す．

\begin{table}[b]
\caption{注釈付けされた表現の数}
\label{tab:注釈付けされたタグ数}
\input{02table13.txt}
\end{table}

表\ref{tab:注釈付けされたタグ数}をみると，ジャンルごとに注釈のために付与されたタグの数に多少の違いがある．製品のジャンルごとの特徴を見てみると，映像・音楽におけるattributeタグを付与した回数が他ジャンルに比べてわずかに少ない．一方で，valueタグについてはソフトウェアや，ホーム・キッチンよりも多くなっている．映像・音楽については製品の性質上，製品の部分の性能について細かく説明するよりも，その製品についてどう思うかという感想が述べられやすいという特徴が注釈付けの量にも現れていると考える．

\begin{table}[b]
\caption{4つ組における各要素の省略}
\label{tab:4つ組における各要素の省略}
\input{02table14.txt}
\end{table}

次に，評判情報の構成要素の組について，ある要素が省略されている場合について考察する．提案モデルでは要素の省略を認めている．各要素が省略されていた場合の組数を表\ref{tab:4つ組における各要素の省略}に示す．なお，提案モデルでは要素の1対多関係も認めており，要素の組の数を延べ数で調べた結果は9,287組であった．
表中の $\phi$ が省略されていた要素である．実験では注釈者に，まずはvalueとevaluationのどちらかを探してから注釈付けを行うように依頼した．そのため，本来ならば，item-attribute-$\phi$-$\phi$ という組は存在しないはずである．しかし，注釈者が作業中に覚書として注釈付けをした部分の消し忘れ，コーパス全体の修正作業をした際に誤って注釈付けされていたvalueを削除した際の残りである．これらについては，itemとの組は正しいので付与した情報を削除せずに残してある．
その他に，製品の様態のみを記述し，評価について言及していない部分が多数存在した．これにより，コーパス全体としてvalueタグが非常に多くなる一方で，evaluationは少ない結果となった．これはレビューを書く際にはっきりと評価を書くことを避ける傾向があるためと考えられる．

\begin{table}[t]
\caption{attribute，value，evaluationの頻出表層表現上位10個}
\label{tab:attribute，value，evaluationの頻出表層表現上位10個}
\input{02table15.txt}
\end{table}


次に，出現回数の多い表層表現に着目する．attribute，value，evaluationの各タグに頻出した表層表現の上位10位を表\ref{tab:attribute，value，evaluationの頻出表層表現上位10個}に示す．また，各製品ジャンルごとの各タグに頻出した表層表現の上位5位を表\ref{tab:各製品ジャンルにおけるattribute，value，evaluationの頻出表層表現上位5個}に示す．

各ジャンルごとに頻出している表層表現を見ると，その製品ジャンルに特徴のある表現が上位にきている．しかし，表\ref{tab:各製品ジャンルにおけるattribute，value，evaluationの頻出表層表現上位5個}で示した全コーパス中で出現回数の多い表現の中には，複数の製品ジャンルにおいて出現頻度の高い表現が多く存在する．特に，attributeに注目して見ると，「音」や「値段」のように，製品のジャンルに関わらずレビュアーがよく言及してる表現が存在していると考えられる．

evaluationについては，頻出表層表現を見ても，肯定的な意見がコーパス中に多く存在しているように見える．そこで，evaluationタグのorientation属性について，値として現れるpositive，negative，neutralの個数を調べてみた．orientation属性には，対応する評判が肯定なのか否定なのかを表す値が与えられている．結果を表\ref{tab:evaluationの極性}に示す．

表\ref{tab:evaluationの極性}を見ると，positiveが圧倒的に多くなっている．この理由の1つとしては，製品レビューという情報源そのものの特徴が挙げられる．すなわち，レビューを書く動機が，「この製品を他の人に紹介したい」や「この製品を他の人に勧めたい」といった，肯定的なものであることが多いからではないかと考えられる．


itemについても頻出する表層表現を調査した．\ref{sec:コーパス修正作業}節で述べた修正作業により注釈付けされた部分が増え，総数としてはvalueタグに次いで多くなっている．しかし，一方でレビュアーが製品名を連呼することで頻度が上がってしまうような例もあり，統計的な傾向が記述形式に拠るところが大きい．


\begin{table}[p]
\caption{各製品ジャンルにおけるattribute，value，evaluationの頻出表層表現上位5個}
\label{tab:各製品ジャンルにおけるattribute，value，evaluationの頻出表層表現上位5個}
\input{02table16.txt}
\end{table}
\begin{table}[p]
\caption{evaluationの極性}
\label{tab:evaluationの極性}
\input{02table17.txt}
\end{table}

最後に，同じvalueに対して異なる極性のevlauationが記述されている部分について調べた．\ref{sec:4つ組による評判情報モデル}節で述べた提案モデルでは，製品の同一の様態に対して評価が異なる場合を考慮し，valueとevaluationを分離している．同じ表層表現のvalueに対して極性の異なるevaluationが組になっている部分がコーパス中に存在する事を確認する．valueとevaluationを分離した提案モデルを用いたことにより，より正確に評判を捉えられた部分であり，提案モデルの有効性が示されている．
この場合のvalueとevaluationの組を表\ref{tab:同一の様態に対する異なる極性のevaluation}に示す．



\begin{table}[t]
\caption{同一の様態に対する異なる極性のevaluation}
\label{tab:同一の様態に対する異なる極性のevaluation}
\input{02table18.txt}
\end{table}

評判情報コーパスの作成実験で作成したコーパス中にも，同じvalueに対して極性の異なるevaluationが組となっている部分が存在した．上記の「高い」などはattributeが「値段」と「コストパフォーマンス」の場合であり，attributeが異なるために極性が異なっている場合もある．これは組となるattributeを考慮することで極性の違いを捉えることが出来る．一方で，同種の製品の同一valueに対して異なる極性のevalutionが付与されている場合もある．例を図\ref{fig:同種の製品の同一valueに対して異なる極性が付与されている例文}に示す．このような場合には特に，製品の様態と評価を分離する提案モデルにより評判情報をより正確に捉えることができると考えられる．

\begin{figure}[t]
\input{02fig15.txt}
\caption{同種の製品の同一valueに対して異なる極性が付与されている例文}
\label{fig:同種の製品の同一valueに対して異なる極性が付与されている例文}
\vspace{-1\baselineskip}
\end{figure}




\section{おわりに}
\label{sec:おわりに}

本稿では，製品の様態と評価を分離した評判情報のモデルを提案し，同様の様態に対する評価がレビュアーにより異なる場合にも対応可能とした．注釈付けについては，注釈事例を用いた複数注釈者の人手による評判情報コーパス作成手法を提案した．また，提案手法を用いてコーパス作成を行った．

コーパス作成おける複数注釈者間の注釈揺れについては，注釈者に指示を与えるだけでは一致率が十分ではないということがわかった．
省略されている要素の補完を行いながら注釈付けを行うことで一致率の向上は見られたが，十分とは言えなかった．
しかし，注釈事例の参照という注釈者間の緩やかな知識共有を行うことにより注釈付けの一致率が向上することが分かった．

作成したコーパスについて特徴を統計的な面から調査し，作成されたコーパス中にも，提案モデルが想定していた様態と評価の分離が必要な記述が存在したことが確認され，提案モデルにより評判情報をより正確に捉えることができた．

今後は，評判情報の抽出システム等でコーパスを利用することを考えている．コーパスを教師データとする機械学習手法による評判情報の抽出において，1万文というコーパスサイズが十分なものであるかの確認を行う必要がある．
さらに，本コーパスの公開についても検討している．これについては，Web上の文書を元データとする際の2次配布方法について，さらなる検討が必要と考えられる．
\vspace{-0.5\baselineskip}



\acknowledgment
\vspace{-0.5\baselineskip}

本研究の一部は，（独）独立行政法人情報通信研究機構の委託研究「電気通信サービスにおける情報信憑性検証技術に関する研究開発」プロジェクトの成果である．

また，本研究の一部は横浜国立大学環境情報研究院共同研究プロジェクトの援助により行った。


\vspace{-0.5\baselineskip}

\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Carbonell \BBA\ Goldstein}{Carbonell \BBA\
  Goldstein}{1998}]{Carbonell98}
Carbonell, J.\BBACOMMA\ \BBA\ Goldstein, J. \BBOP 1998\BBCP.
\newblock \BBOQ The Use of MMR, Diversity-Based Reranking for Reordering
  Documents and Producing Summaries.\BBCQ\
\newblock In {\Bem Proceedings of the 21st Annual International ACM SIGIR
  Conference on Research and Development in Information Retrieval},
  \mbox{\BPGS\ 335--336}.

\bibitem[\protect\BCAY{飯田\JBA 小林\JBA 乾\JBA 松本\JBA 立石\JBA 福島}{飯田
  \Jetal }{2005}]{Iida05}
飯田龍\JBA 小林のぞみ\JBA 乾健太郎\JBA 松本裕治\JBA 立石健二\JBA 福島俊一 \BBOP
  2005\BBCP.
\newblock 意見抽出を目的とした機械学習による属性—評価値同定.\
\newblock 自然言語処理研究会報告\ 2005-NL-165-4, 情報処理学会.

\bibitem[\protect\BCAY{乾\JBA 奥村}{乾\JBA 奥村}{2006}]{Inui06}
乾孝司\JBA 奥村学 \BBOP 2006\BBCP.
\newblock テキストを対象とした評価情報の分析に関する研究動向.\
\newblock \Jem{自然言語処理}, {\Bbf 13}  (3), \mbox{\BPGS\ 201--241}.

\bibitem[\protect\BCAY{Kaji \BBA\ Kitsuregawa}{Kaji \BBA\
  Kitsuregawa}{2006}]{Kaji06}
Kaji, N.\BBACOMMA\ \BBA\ Kitsuregawa, M. \BBOP 2006\BBCP.
\newblock \BBOQ Automatic Construction of Polarity-tagged Corpus from HTML
  Documents.\BBCQ\
\newblock In {\Bem Proceedings of the 21st International Conference on
  Computational Linguistics (COLING/ACL2006)}, \mbox{\BPGS\ 452--459}.

\bibitem[\protect\BCAY{洪\JBA 白井}{洪\JBA 白井}{2005}]{Kou05}
洪陽杓\JBA 白井清昭 \BBOP 2005\BBCP.
\newblock 対話行為タグ付きコーパスの作成支援.\
\newblock \Jem{言語処理学会第11会年次大会発表論文集}, \mbox{\BPGS\ 815--818}.
  言語処理学会.

\bibitem[\protect\BCAY{Kobayashi, Inui, \BBA\ Matsumoto}{Kobayashi
  et~al.}{2007}]{Kobayashi07}
Kobayashi, N., Inui, K., \BBA\ Matsumoto, Y. \BBOP 2007\BBCP.
\newblock \BBOQ Opinion mining from web documents: extraction and
  structurization.\BBCQ\
\newblock \Jem{人工知能学会論文誌}, \mbox{\BPGS\ 227--238}. 人工知能学会.

\bibitem[\protect\BCAY{小林\JBA 乾\JBA 松本}{小林 \Jetal }{2006}]{kobayashi06}
小林のぞみ\JBA 乾健太郎\JBA 松本裕二 \BBOP 2006\BBCP.
\newblock 意見情報の抽出／構造化のタスク使用に関する考察.\
\newblock 自然言語処理研究会報告\ 2006-NL-171-18, 情報処理学会.

\bibitem[\protect\BCAY{小林\JBA 飯田\JBA 乾\JBA 松本}{小林 \Jetal
  }{2005}]{Kobayashi05-1}
小林のぞみ\JBA 飯田龍\JBA 乾健太郎\JBA 松本裕治 \BBOP 2005\BBCP.
\newblock 照応解析手法を利用した属性-評価値対および意見性情報の抽出.\
\newblock \Jem{言語処理学会第11回年次大会発表論文集}, \mbox{\BPGS\ 436--439}.
  言語処理学会.

\bibitem[\protect\BCAY{村野\JBA 佐藤}{村野\JBA 佐藤}{2003}]{Nomura03}
村野誠治\JBA 佐藤理史 \BBOP 2003\BBCP.
\newblock 文型パターンを用いた主観的評価文の自動抽出.\
\newblock \Jem{言語処理学会第11回年次大会発表論文集}, \mbox{\BPGS\ 67--70}.
  言語処理学会.

\bibitem[\protect\BCAY{野口\JBA 三好\JBA 徳永\JBA 飯田\JBA 小町\JBA 乾}{野口
  \Jetal }{2008}]{Noguchi08}
野口正樹\JBA 三好健太\JBA 徳永健伸\JBA 飯田龍\JBA 小町守\JBA 乾健太郎 \BBOP
  2008\BBCP.
\newblock 汎用アノテーションツールSLAT.\
\newblock \Jem{言語処理学会第14会年次大会発表論文集}, \mbox{\BPGS\ 269--272}.
  言語処理学会.

\bibitem[\protect\BCAY{Pang \BBA\ Lee}{Pang \BBA\ Lee}{2004}]{Pang04}
Pang, B.\BBACOMMA\ \BBA\ Lee, L. \BBOP 2004\BBCP.
\newblock \BBOQ A Sentimental Education: Sentiment Analysis Using Subjectivity
  Summarization Based on Minimum Cuts.\BBCQ\
\newblock In {\Bem Proceedings of the 42nd Meeting of the Association for
  Computational Linguistics (ACL)}, \mbox{\BPGS\ 271--278}.

\bibitem[\protect\BCAY{Pang, Lee, \BBA\ Vaithyanathan}{Pang
  et~al.}{2002}]{Pang02}
Pang, B., Lee, L., \BBA\ Vaithyanathan, S. \BBOP 2002\BBCP.
\newblock \BBOQ Thumbs up? Sentiment Classification using Machine Learning
  Techniques.\BBCQ\
\newblock In {\Bem Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, \mbox{\BPGS\ 79--86}.

\bibitem[\protect\BCAY{Seki, Evans, Ku, Chan, Kando, \BBA\ Lin}{Seki
  et~al.}{2007}]{Seki07}
Seki, Y., Evans, D.~K., Ku, L.-W., Chan, H.-H., Kando, N., \BBA\ Lin, C.-Y.
  \BBOP 2007\BBCP.
\newblock \BBOQ Overview of Opinion Analysis Pilot Task at NTCIR-6.\BBCQ\
\newblock In {\Bem Proceedings of 6th NTCIR Workshop}, \mbox{\BPGS\ 265--278}.
  NII.

\bibitem[\protect\BCAY{立石\JBA 石黒\JBA 福島}{立石 \Jetal }{2001}]{Tateishi01}
立石健二\JBA 石黒義英\JBA 福島俊一 \BBOP 2001\BBCP.
\newblock インターネットからの評判情報検索.\
\newblock 自然言語処理研究会報告\ 2001-NL-144-11, 情報処理学会.

\bibitem[\protect\BCAY{峠\JBA 大橋\JBA 山本}{峠 \Jetal }{2005}]{Touge05}
峠泰成\JBA 大橋一輝\JBA 山本和英 \BBOP 2005\BBCP.
\newblock ドメイン特徴語の自動取得によるWeb掲示板からの意見文抽出.\
\newblock \Jem{言語処理学会第11回年次大会発表論文集}, \mbox{\BPGS\ 672--675}.
  言語処理学会.

\bibitem[\protect\BCAY{Turney}{Turney}{2002}]{Turney02}
Turney, P.~D. \BBOP 2002\BBCP.
\newblock \BBOQ Thumbs Up or Thumbs Down? Semantic Orientation Applied to
  Unsupervised Classification of Reviews.\BBCQ\
\newblock In {\Bem Proceedings of the 40th Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 417--424}.

\bibitem[\protect\BCAY{Wiebe, Breck, Buckley, Cardie, Davis, Fraser, Litman,
  Pierce, Riloff, \BBA\ Wilson}{Wiebe et~al.}{2002}]{Wiebe02}
Wiebe, J., Breck, E., Buckley, C., Cardie, C., Davis, P., Fraser, B., Litman,
  D., Pierce, D., Riloff, E., \BBA\ Wilson, T. \BBOP 2002\BBCP.
\newblock \BBOQ Final Report---MPQA: Multi-Perspective Question
  Answering.\BBCQ\
\newblock In {\Bem NRRC Summer Workshop on Multi-Perspective Question Answering
  Final Report}. NRRC.

\bibitem[\protect\BCAY{Yu \BBA\ Hatzivassiloglou}{Yu \BBA\
  Hatzivassiloglou}{2003}]{Yu03}
Yu, H.\BBACOMMA\ \BBA\ Hatzivassiloglou, V. \BBOP 2003\BBCP.
\newblock \BBOQ Towards answering opinion questions: Separating Facts from
  Opinions and Identifying the Polarity of Opinion Sentences.\BBCQ\
\newblock In {\Bem Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, \mbox{\BPGS\ 129--136}.

\end{thebibliography}


\appendix
\section{予備実験1における注釈者への作業指示}
\label{sec:予備実験1における注釈者への作業指示}

作業指示中にて四角で囲われている部分は，実際に注釈者への作業指示へ記述した文ではなく，本稿の他の部分に記述されている文言を挿入した部分である．
\begin{screen}
目的
\begin{quote}
Web上にある，製品レビューに対して，評判情報のモデル化に必要な要素に注釈（タグ）を付与し，コーパスの試作を行う．\\
今回の作業は，注釈者間におけるタグの付与の違いを調べることが目的である．
\end{quote}
結果
\begin{quote}
・タグ付けが行われたテキストデータ\\
・1ファイルごとの作業時間\\
・気になる点などがあったら記録しておく
\end{quote}
注意点
\begin{quote}
・タグの付与に迷いが生じたときに，他の人に相談をしない\\
・ファイルの中を一回見たら，途中でやめないでタグ付けを行う\\
・配布したテキストエディタを用いて注釈付けの作業を行う
\end{quote}
評判情報のモデルの説明
\begin{quote}
\fbox{
\begin{minipage}{0.9\linewidth}
\ref{sec:評判情報の提案モデル}章と同一の評判情報モデルの解説
\end{minipage}
}
\end{quote}
\end{screen}
次ページに続く

\begin{screen}
評判情報コーパスの作成手順
\begin{quote}
対象にはあらかじめitemタグが付与してあります．また，対象の階層構造を示したデータも一緒に用意してあります．\\
\end{quote}
＊注意点\\
itemタグが付与されるべきであろう場所にitemタグが付与されていないために，作業に支障をきたすような場合．
\begin{quote}
A: 階層構造はすでに存在する場合→itemタグを追加してしまってかまいません．\\
B: 階層構造にも存在しない場合→その度，質問をしてください．
\end{quote}

評判情報の構成要素がテキスト中に存在する場合には，下記の注釈付けを行ってください．
\begin{quote}
1〜3の数字は注釈付けの順番を意味するものではありません．
\end{quote}

1: 属性にタグを付与
\begin{verbatim}<attribute id="a01" pair="p01" target="c01">属性</attribute>\end{verbatim}
id: a01, a02…のようにidをつける．\\
pair: p01, p02…のように属性—属性値組を示すための番号をつける．組になる属性値にも同じ番号をつける．\\
target: 属性を有する \verb|<item>| のclassを指定．複数指定の場合はスペースで区切って列挙．\\
\\
2: 属性値にタグを付与
\begin{verbatim}<value id="v01" pair="p01" target="c01">属性値</value>\end{verbatim}
id: v01, v02…のようにidをつける．\\
pair: \verb|<attribute>| のpairを参照．\\
target: \verb|<attribute>| のtargetを参照．\\
3: 評価にタグを付与
\begin{verbatim}<evaluation id="e01" target="c01" reason="p01" orientation="positive">評価</evaluation>\end{verbatim}
id: e01, e02…のようにidをつける．\\
target: \verb|<evaluation>| が評価している \verb|<item>| のclassを指定する．\\
reason: \verb|<evaluation>| の理由となる \verb|<attribute>-<value>| のpairの値を指定する．複数指定する場合にはスペースで区切って列挙．
\end{screen}


\section{予備実験2における注釈者への作業指示}
\label{sec:予備実験2における注釈者への作業指示}

予備実験2で利用した作業指示は付録\ref{sec:予備実験1における注釈者への作業指示}に以下の各項目を作業指示の末尾に追加したものである．

\begin{screen}
attribute-valueの組については片方の要素が省略されている場合にはその要素を補完する
\begin{quote}
省略されている要素の内容がどのようなものになるかを以下の方法で記述する\\
　attributeが省略されている場合にはattributeが省略されていると思われるvalueタグの直前にattributeタグを記述する\\
　valueタグが省略されている場合にはvalueが省略されていると思われるattributeタグの直後にvalueタグを記述する\\
\end{quote}
省略されていた要素を補完して注釈付けを行った例（下線部が省略を補完した部分）\\
\verb|<item id="i11" class="c2">|このソフト\verb|</item>|は\underline{{\ttfamily\symbol{"3C}attribute id="a101" pair="p101"}}\linebreak
\underline{\mbox{\ttfamily target="c2" abbr="1"\symbol{"3E} 重さ \symbol{"3C}/attribute\symbol{"3E}}}\verb|<value id="v101" pair= "p101" target=|\linebreak
\verb|"c2">| 軽く \verb|</value>| て \verb|<evaluation id="e101" target="c2" readon="p101">| 気に入っている \verb|</evaluation>|．
\end{screen}


\section{評判情報コーパスの作成実験における注釈者への作業指示}
\label{sec:評判情報コーパスの作成実験における注釈者への作業指示}

評判情報コーパスの作成実験における注釈者の作業指示は付録\ref{sec:予備実験1における注釈者への作業指示}に以下の変更と追加を行ったものである．
作業指示中にて四角で囲われている部分は，実際に注釈者への作業指示に記述した文ではなく，本稿の他の部分に記述されている文言を挿入した部分である．

・予備実験1の作業指示から変更した点
\begin{screen}
目的
\begin{quote}
今回の作業は，今後利用する本コーパスの作成である．\\
注釈揺れの分析を行うための作業ではない
\end{quote}
\end{screen}
次ページに続く

\begin{screen}
注意点
\begin{quote}
タグの付与に迷いが生じたときに，注釈者間のみで相談して判断を決めずに，第一著者へ訪ねること．\\
注釈付けツールを用いて注釈付けを行うこと．\\
注釈付けの粒度をなるべく細かくすること．とくにattributeとvalueの粒度に注意すること．\\
\fbox{
	\begin{minipage}{0.9\linewidth}
図\ref{fig:valueの中にattributeを含んでしまっている例}をここに挿入
	\end{minipage}
}
\end{quote}
注釈付け対象データの配布について\\
　200文の注釈付けが終わった注釈者へ次の200文を配布する．
\end{screen}
上述の注意点について補足説明をする．
注釈揺れの分析を目的とした実験ではないので，作業者からから発注者へ質問があった場合は，発注者が質問とその回答を全注釈者へ連絡している．\\

・予備実験1の作業指示から追加した点
\begin{screen}
注釈付けの際の規則の追加
\begin{quote}
\fbox{
	\begin{minipage}{0.9\linewidth}
図\ref{fig:意図した注釈付けを行ってもらうために追加した規則}，図\ref{fig:注釈の範囲に関する注釈揺れを削減するために追加した規則}と図\ref{fig:モダリティ部分に関する規則}をここに挿入
	\end{minipage}
}
\end{quote}
注釈付けの順番について
\begin{quote}
最初にvalueタグ，もしくはevaluationタグを注釈付けする部分を探しながら注釈付けを行う．\\
value，evaluationに該当する文字列がどちらも存在せずに，itemやattributeのみが現れた場合には注釈付けを行わなくてもよい．
\end{quote}
注釈揺れの事例の提示
\begin{quote}
\begin{verbatim}
注釈付けが必要な場所には忘れずに注釈付けを行ってください
例のような場合には注釈付けを行ってください
例：
○：<value>機械的</value>な<attribute>声</attribute>です
×：機械的な声です
\end{verbatim}
\end{quote}
\end{screen}
次ページへ続く

\begin{screen}
\begin{quote}
評価はその表現のみで肯定否定がいかなる場合でも決定できる表現です\\
例のようなvalueだけでは肯定否定は決定できません
\begin{verbatim}
例：
○：届いたときは<value>可愛い</value>と思わずつぶやきました
×届いたときは<evaluation>可愛い</evaluation>と思わずつぶやきました

○：<item>画面</item>の<attribute>色</attribute>は<value>きれい</value>
×：<item>画面</item>の<attribute>色</attribute>は<evaluation>きれい</evaluation>

○：<attribute>色</attribute>が<value>はっきり出て</value>いて<value>見やすい</value>
×：<attribute>色</attribute>が<value>はっきり出て</value>いて<evaluation>見やすい</evaluation>

○：<value>使いやすい</value>です。
×：<evaluation>使いやすい</evaluation>です。
\end{verbatim}
\vspace{2\baselineskip}

例のようなevaluationはその表現のみで肯定否定が決定できるので評価として扱い\linebreak
ます
\begin{verbatim}
例：
○：<item>シール</item>の<attribute>品質</attribute>は<evaluation>かなり悪い</evaluation>
×：<item>シール</item>の<attribute>品質</attribute>は<value>かなり悪い</value>

○：<attribute>内容</attribute>は<evaluation>良い</evaluation>だけに<evaluation>残念</evaluation>
×：<attribute>内容</attribute>は<value>良い</value>だけに<evaluation>残念</evaluation>
\end{verbatim}
\end{quote}
\end{screen}
次ページへ続く
\begin{screen}
\setlength{\baselineskip}{16pt}
\begin{quote}
様態を表す値が属性値で観点しか述べていない部分は属性です\\
例の場合はattributeとして注釈付けしてください
\begin{verbatim}
例：
○：購入の決め手としては<attribute>大きさ</attribute>と<attribute>デザイン</attribute>が挙げられます。
×：購入の決め手としては<value>大きさ</value>と<attribute>デザイン</attribute>が挙げられます。

○：その<attribute>シンプルさ</attribute>に<evaluation>感心してしまいます</evaluation>。
×：その<value>シンプルさ</value>に<evaluation>感心してしまいます</evaluation>。


注釈付けはなるべく細かく行ってください
例：
○：<value>その日の気分によって聞ける</value>のが<evaluation>すばらしい</evaluation>
×：<evaluation>その日の気分によって聞けるのがすばらしい</evaluation>

○：<value>熱を持ってしまい</value>とてもではないですが<value>手では持てなくなる</value>
×：<value>熱を持ってしまい、とてもではないですが手では持てなくなる</value>


属性値は様態の内容なので，観点は属性に含めてください．
例：
○：<attribute>茶葉が踊っている</attribute>のが<value>目に見える</value>
×：<attribute>茶葉</attribute>が<value>踊っているのが目に見える</value>

○：<attribute>操作が慣れるまで</attribute><value>ほんの少しかかった</value>
×：<attribute>操作</attribute><value>慣れるまでほんの少しかかった</value>
\end{verbatim}
\end{quote}
\end{screen}
次ページへ続く
\clearpage

\begin{screen}
\begin{quote}
attribute-value組はそのものがどのようなモノであるかを表すだけであり，その組に対する肯定・否定は人によって異なります
\begin{verbatim}
例：
○：<attribute>落ち着き</attribute>が<value>あります</value>
×：<evaluation>落ち着きがあります</evaluation>

○：<item>このディスプレイ</item>は<attribute>解像度</attribute>が<value>高い</value>
×：<item>このディスプレイ</item>は<evaluation>解像度が高い</evaluation>


特に属性は省略されている場合があります。省略を想定しながら注釈付けしてください
例の場合は「サイズ」という属性が省略していると考えられます
例：
○：<item>画面</item><value>大きい</value>
×：<attribute>画面</attribute><value>大きい</value>
\end{verbatim}
\end{quote}
\end{screen}

上記の作業指示に加えて，別紙にて注釈付けツールの使用説明書を配布．






\begin{biography}
\bioauthor{宮崎　林太郎}{
2002年神奈川大学理学部情報科学科卒業．2004年同大学大学院理学研究科情報科学専攻博士課程前期修了．現在，横浜国立大学大学院環境情報学府情報メディア環境学専攻博士課程後期在学中．自然言語処理に関する研究に従事．
}
\bioauthor{森　　辰則}{
1986年横浜国立大学工学部情報工学科卒業．
1991年同大学大学院工学研究科博士課程後期修了．
工学博士．
同年，同大学工学部助手着任．
同講師，同助教授を経て，現在，同大学大学院環境情報研究院教授．
この間，1998年2月より11月までStanford大学CSLI客員研究員．
自然言語処理，情報検索，情報抽出などの研究に従事．
言語処理学会，情報処理学会，人工知能学会，ACM各会員．
}
\end{biography}




\biodate



\end{document}
