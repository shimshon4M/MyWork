<?xml version="1.0" ?>
<root>
  <title/>
  <author/>
  <jkeywords/>
  <subsubsection title="">*Gloss:ATR--Full,ATR--SyntaxtaggedversionsATR--Fullinitalics;ATR--Syntaxinboldface;tagscommontobothinboldface:</subsubsection>
  <section title="Introduction: Building On The Successes To Date In Part--Of--Speech Tagging">Part--of--speechtagging---usingcomputerstoautomaticallyassociatethewordsofatextwiththeirgrammaticalpartsofspeech---hasbeenoneofthesuccessstoriesoftheNaturalLanguageProcessingfieldtodate.ComputershaveequalledhumanaccuracyattaggingtheWallStreetJournal,BrownCorpus,AssociatedPress,andCanadianHansardcorpora,usingtherudimentary,45--tagUPennTagset,andstripped--downversionsofthefullerCLAWStagset.Butwhatwilltheabilitytotagwiththeserelativelylow--leveltagsetsdoforcomplexapplicationssuchasmachinetranslation,sophisticateddocument--searching,andopen--vocabularyspeechrecognition?Thelogicalnextmoveforpart--of--speechtaggingistobuildonitssuccessesandundertakemorecomplexandchallengingtaggingtasks.Threedirectionsforexpansionseemindicated:(1)tagusingmuchmoredetailedtagsets,includingalarge-scalesemanticclassificationaswellasmoresyntacticdetail;(2)testperformanceontreebankswhichreflectthehugegamutofdomains,styles,functions,andusagesfoundamongreal--worldapplications;and(3)understandthemagnitudeoftheunknown--wordandunknown--tagproblems,thenovercomethem.Onewaytoconfrontalltheseproblemsistotagusingthe700,000--wordATR/LancasterTreebankofAmericanEnglish.Dividedintoroughly950documentsoflength30--3600words,thistreebankachievesahighdegreeofdocumentvariationalongmanydifferentscales---documentlength,subjectarea,style,pointofview,etc.(SeeTable1fortitlesofninetypicaldocuments.)TextistaggedandparsedusingtheATREnglishGrammar(2720differenttags).Eachverb,noun,adjectiveandadverbtagincludesoneofabout60semanticcategoriesintendedforanyStandardAmericanEnglishtextinanydomain.Eventhesyntax--onlyversionofthetagsethas443differenttags.(Compare45,76,and163tagsforthetagsetsusedin.)Theunknown--wordandunknown--tagproblemsarequantifiedbelowandturnouttobemuchmoreseverethanonemighthavethought.Unknown--tagdifficultiesaresufficientlyacuteinATR/Lancaster--Treebanktestsetstoformaspurtosolvingtheproblem.</section>
  <section title="Real--World Part--Of--Speech Tagging">InSection2,wedocumenttheproblemsoftaggingwithlarger,moresophisticatedtagsets(2.1),andoftaggingunknownwordsandwordsoccurringwithagiventagforthefirsttimeintestdata(2.2),andshowwhyitisimportanttosolvetheseproblems.Section3describesthesolutionweareattempting,usingdecision--treemodellinganddiscardingthenotionofadictionaryentirely(3.1);andpresentsexperimentalresultsandfutureresearchplans(3.2).</section>
  <subsection title="Tag Using Tagsets Of Increased Size And Complexity">Thissubsectionseekstoconveya``feel''fortheincreasinglevelsofdetailofthetagsetsutilizedsofarintaggingwork---includingthenewATRtagsets.Then,specificcasesarediscussedofsyntacticdetailscapturedintheATRtagsetbutnotintagsetsusedforpriortaggingexperiments,anditisshownwhythesedetailsmatter.</subsection>
  <subsubsection title="Exemplifying The Tagsets Used So Far">Tables2displayaportionofa1989WallStreetJournalarticleentitled,``EnserchTenderOfferResults'',taggedusingfirstthefull2720--tagATRtagset(ATR--Full);thenthe443--tagsyntax--onlyversionoftheATRtagset(ATR--Syntax);thenthe163--tagmapped--downversionoftheCLAWStagsetwhichwasusedin;thenfinallythe45--tagUPenntagsetusedin.(SeeappendixforglossesofATR--Full,ATR--Syntax,mapped--downCLAWS,andUPenntaggedversions.)</subsubsection>
  <subsubsection title="Expanded Syntactic Detail: The ATR--Syntax Tagset">TheATR--SyntaxtagsetisarevisedandexpandedversionoftheCLAWStagset.ThreeareasofATR--Syntax'sincreasedsyntacticdetailvis--a--vispreviously--utilizedtagsetsarenowdiscussed.DittoTagsForMultiwordLexicalUnitsTheCLAWStagsetfeaturesso--calleddittotagsformultiwordlexicalunits.Forinstance,``well_NN121being_NN122''isatwo--wordnoun,``in_II31response_II32to_II33''athree-wordpreposition.ManymoredittotagsarecontainedinATR--SyntaxthaninCLAWS,with276ofthe443ATR--Syntaxtagsbeingdittotags.AllCLAWSdittotagsaremappedoutofboththeandexperiments,sothatnopublishedexperimentshaveappearedtodatewithtagsetsfeaturingdittotags.In,the``dittoendings''aredropped,sothate.g.``well_NN121being_NN122''becomes``well_NN1being_NN1''.Itisnotclearhowdittotagswerehandledin;inanycase,thefullmapped--down76--tagtagsetisexhibitedin,andnodittotagsareincluded.Whatistheadvantageofmarkingcertainmultiwordlexicalunits,andwhyisitmoreusefultohaveexplicitdittotagsthanmapped--downonesasin?Oneanswerconcernswhathappenswhenonerunsaparserontaggedtext.Briefly,tagginge.g.``in_II31response_II32to_II33'',tellstheparsertotreatthethreewordsasasinglepreposition,andsotoignorepossiblebreakdownslike:``Henodded(inresponse)(toshowhewasfollowing)'',ofthethesentencecontainingthephrasewhensotagged.Thiscanturnouttobeasignificantaidtoparsingaccuracy,ifdittotagsappearfrequentlyincorrectly--taggedtext,sincelargenumbersofmistakenparsesareeliminatedwhichmightotherwisebeconsideredcorrectbytheparser.Droppingthe``ditto''sequencemarkers,i.e.mappingtheaboveto``in_IIresponse_IIto_II'',aswasdonein,goespart--waytowardstheabovegoal,inthatitpreventsparsingmistakesliketheoneabove.Butitdoesnothingtoblockerrorssuchaspartitioningthephrase,``thecommentshemadeinresponsetothisquestion''asifitwereoftheform,``theoptionshechosefromamong(inthiscase)''or,``theoptionhechosefrom(among(inthiscase)fivepossibilities)'',etc.Anextremelyfrequentandpotentiallyhavoc--wreakingditto--tagscenariooccurswhereamultiwordadverboccursattheendofasentence,especiallyalongsentence.Locutionslike,``as_RR21well_RR21'',``a_RR21lot_RR22'',``by_RR31and_RR32large_RR33''arecommoninthisposition.Ifwedenaturethedittotagsintoaseriesoftwoorthreeadverbs,thenumberofotherwise--preventablespuriousparsesnowopentoanunsuspectingparsercanbehuge.Evenamongshortsentencestherearemanyvariations:He(paid(5000precisely)(whollywillingly));(He(paid(5000precisely)unhesitatingly)sometimes);(He(spentmoney(terriblyfreely))always);etc.Digit--BasedAndNumber--Word--BasedLexicalUnits:Price,Time,Etc.Amongthe276dittotagsintheATRtagset,170arefordigit--basedornumber--word--basedlexicalunits,e.g.MPRICE31,MTIMEWORD22,MZIP21.Inaddition,thesetofstandard(non--ditto--tag)ATRtagscontains21othertagsforsingle--wordlexicalunitsofthistype.All191ofthesetagsareidenticalfortheATR--FullandATR--Syntaxtagsets.Thatis,inboth,afullpanoplyoftagsforprices,times,zipcodes,andthelike,isincluded,alongwithavarietyoftagsfor``justplainnumbers'',e.g.``fifty_MCWORD21three_MCWORD22'',``1_MC1'',``next_MDWORD'',``325--92_MC-MC''(e.g.a325--92vote).Therationalehereisthatitisfeasibleforataggertolearntodemarcatemultiwordprice,time,zipcode,etc.,expressions,andthatspecifyingtheinternalstructureoftheseexpressionsisprobablyoflesserutilityingeneral.Whatisquiteimportantistolocatetheboundariesofthesewordstrings,whichoftenincludehighlyfrequentwordswhichifnotrenderedharmlessinthisfashion,mightencouragesignificantnumbersofmisparses.Forinstance,the``a''of``ahundredfifty'',the``the''of``Tuesdaythe19th'',andthe``bits''of``twobits'',needtobeidentifiedasoccurringinsidenumericallexicalitems,iftheyarenottosowconfusion.Arethesetags``syntactic''?Merelytoposethisquestionsuggestsaneedforatleasttenyearsof``Wittgensteiniantherapy''.Ifanyonewishes,wecanchangethename``ATR--Syntaxtagset''to``ATR--Syntax--With--Some--Semanticstagset''.Thepointaboutnumbers,prices,times,etc.,isthatinmanykindsofdocument,theyaredevilishlyfrequent.Henceonecouldconceiveofusesforataggerwhichaccuratelyassignsthisclassoftag,withinapplicationssuchasdocumentscanningandinformationretrieval,amongotherplaces.Verbalvs.OrdinaryAdjectivesAndNounsArguablyaproblemwiththetagsetswhichhavebeenusedsofarinlarge--scaletaggingexperiments,hasbeenthelackofanadequatetreatmentofverbal(asopposedtoordinary)andnouns(forms1,5,9ofTable3;contrastforms2,6,10).andgerundialnounsvs.adjectives,nouns.CLAWSconflatesforms1and2;5and6;and9and10.UPennconflates5and6.Itassignstwodifferenttagsto1and2,andto9and10;however,thetagchosenfor1isalsothetagfor3,4,7,8;andthetagchosenfor9isalsothetagfor11and12.Incontrast,theATRtagsetsfeaturedifferenttagsforcases1and2;5and6;and9and10;thetagforcase1differsfromalloftags2--12;andthetagforcase9differsfromallothercases1--12.ThusATRcan,buttheothertagsetscannot,distinguishbetween``ofaretiring_JJVVGemployee''and``ofaretiring_JJnature'';between``aforced_JJVVNmarch''and``aforced_JJsmile'';andbetween``Hogcalling_NVVGisadyingart''and``Billhasfoundhiscalling_NN1''.Further,bothsensesofChomsky'ssentence``Flyingplanescanbedangerous''receivethesametaggingbyUPenn,butnotbyATR(norbyCLAWS).Further,UPenntagsidenticallyallthreesensesofe.g.``Singinglessonscanbefun.''Inpractice,theUPennWSJTreebankapparentlyfailstoconsistentlycaptureanypatternsover-edand-ingadjectivesandnouns.ThereisonlymildcorrespondancebetweenthetaggingdecisionsprescribedfortheseformsintheUPennTaggingGuidelines(1995edition;contactsparnum@unagi.cis.upenn.edu),andthoseactuallymadeintheWSJTreebank.Whatisrelativelypatternlesslabelling.Forinstance,ina14,900--wordsampleoflatest--version(2.00)WSJTreebank,takenfromthreewidelyseparatedplacesinthecorpus,only93of159-edand-ingadjectivesandnouns(58%)werecorrectlylabelledwithrespecttotheTaggingGuidelines.Whydoesthismatter?Oneplaceitmattersisinmachinetranslation.Itmakessensethatcases1and9shouldbetranslateddifferentlyfromcases2and10,sincetheformercanbethoughtofasreflecting``regularlexicalprocesses'',whereasthelatteraretheresultof``lexicalization'',hencehighlyidiosyncratic.Itwouldbeabsurd,inaprocessascomplexastranslation,toclaimthat``formxinEnglishistranslatedviaformyinFrench''.Butwhatwedofindisatendencytotranslatethetwoformsusingadifferentgamutofstructures.InformantworkinFrench,Japanese,andKoreansuggestsatendencytotranslatecase--1forms(JJVVGs)viaparticiples,andcase--2forms(JJsendingin--ing,often``lexicalized'')withadjectives.Further,oneauthorconductedaninformaltestusingthe1986CanadianHansardFrench/Englishdatabase,inwhich10JJVVGsand10JJsendingin-ingwereselectedatrandomfromtheATRTreebank.Thefirst``adjectival''occurrenceofeachofthesewordsinthe1986Hansardswaslocated,alongwithitsFrenchtranslation.Thestructuraltypesofthetranslationswerenotedandtabulated.The``translationprofile''whichemergedofthe-ing--formJJswasverydifferentfromthatoftheJJVVGs.Whereasin4cases,theJJsweretranslatedviaunambiguousadjectives,thisneveroccurredfortheJJVVGs.Inbothcases,3wordsweretranslatedviapresentparticiples(-ingforms);butotherthanthat,theentireprofilewastotallydifferentforthetwocases.</subsubsection>
  <subsection title="Confront The Unknown--Word And --Tag Problems">Weknowofnoattemptstodatetoquantifytheunknown--wordandunknown--tagproblems(viz.,thewordtobetagged(a)hasneverbeenencounteredinthetrainingcorpus(unknown--word);or(b)isinthetrainingcorpus,butnotwiththetagwhichitneedstobeassignedinthecaseathand(unknown--tag).)Table4showsthefindingsofadetailedexplorationoftheunknown--wordprobleminvolvingtheATRTreebankandtheUPennWSJTreebank.ItjusthappensthattheUPennWSJandATRvocabularieseachhave75%coverageoftheother.(I.e.75%ofthedifferentwords(types)occurringinATRfigureonthelistoftypesoccurringintheUPennWSJTreebank.)Wetookgreatcaretomakethecomparisonasmeaningfulaspossible,by(a)mappingallwordstolowercasebeforecomparingthetwowordlists;(b)omittingconsiderationofplainnumbersanddigitsequences,digit--basedwordsexceptmeaningfuloneslike9--foot,``non--words''ofmanystripes(e.g.black@itl.atr.co.jp,hellooooooo);and(c)compensatingforany``tokenization''differencesbetweenthetwotreebanks(e.g.UPennconverts``500''into``500'',whileATRleavesitasis).Still,forvariousreasons,wecanonlyguaranteethefirsttwofigurescitedtowithin5%.Wewereevenmorecarefulincalculatingthecoverageforrunningwords.I.e.whatpercentofallthewordoccurrences(tokens)intheUPennWSJTreebank(over1million)figureonthelistoftypesintheATRTreebank?Andvice--versa.Hereouranswer,94%,isestimatedtowithin1%.Andhereagain,itjusthappenedthatthesameanswerappliedinbothdirections.Thus,ifoneselectsawordatrandomfrom,say,theUPennWSJTreebank,thechancesare94in100thatitisinthelistofwordsoccurringintheATRTreebank.Sofar,theunknown--wordproblemmayappearfairlyharmless.However,afurtherfindingremains.WecalculatedthedistributionofunknownwordsamongsentencesintheATRTreebank.I.e.wecalculatedthepercentageofATR--TreebanksentenceswithinwhichoneormorewordsareunknowntotheUPennWSJTreebank.(Toensurethatthenon--coveredwordswere``realwords'',wealsoremovedfromconsiderationinthistestalllastnamesandnamesofcities.Thisrepresentsadecisionthate.g.``Martin''and``Nevada''are``words'',whereas,say,``Hogsbristle''and``Oshkosh''arenot.)Thatpercentage,estimatedtowithin1%,was69%!Thatis,about3ofevery10ATR--Treebanksentencesarenot``covered''bytheUPennWSJTreebank!Thissuggeststhatinreal--worldtagging,theunknown--wordproblemisaseriousone.Further,wetestedthecoverageprovidedbya``dictionary'',inamoreconventionalsenseofthetermthantheoneoftenusedintaggingresearch.Thatis,wetestedthesentence--wisecoverageoftheATRTreebank,bytheCUVOALD92Dictionary,anexpanded,computer--usableversion,containinginflectedforms,etc.,oftheOxfordAdvancedLearner'sDictionaryOfCurrentEnglishAgainweomittedalllastandcitynames,andagainweverifiedcarefullythatonly``realwords''werecountedinthecomparisonprocess.Resultswerethat60%ofATR--TreebanksentenceswerecoveredbyCUVOALD92.Finally,evenwhenweusedboththeUPenn--WSJTreebankandtheCUVOALD92Dictionary,coverageofATR--Treebanksentenceswasstillonly80%.Oneinfivesentencesisnotcoveredusingthis``dictionary''.Wehavecarriedoutasimilaranalysisoftheunknown--tagproblem;ourresultsareshowninFigure1,whichshowsthepercentageofsentencesintheATRandUPenntestcorporawithoneormorewordshavingtagsnotusedinthetrainingset,asafunctionoftraining--setvocabularysize.Theincidenceofthisphenomenonisnon--trivialevenfortheUPennWSJTreebank;aboutafifthofATRSyntaxtestsentencescontainoneormoreunknowntags,andthefirgureisalmosthalfforATRFull.</subsection>
  <section title="The Non--Dictionary">Wehaveattemptedtotagusingamore--detailedtagset,onacomprehensivetreebank,andtoconfronttheunknown--wordandunknown--tagissues.Whattoolsdidweuse,andhowfardidweget?WecallourapproachtheNon--Dictionary,ordictionarylesstagger.Ourtaggerdoesnotusea``dictionary''inthesenseofalistofallwordsinatrainingcorpus,togetherwiththevarioustagswithwhicheachwordofthetrainingcorpusisassociatedonceormore.Nordoesituseanonlinedictionary,suchasCUVOALD2(see2.2)orofanyothersort.Whythrowawaythedictionary?Giventhemagnitudeoftheunknown--wordandunknown--tagproblems,well--developedmeansarenecessaryanywayofdealingwiththesecasesofdictionaryfailure.Moregenerally,thewider--rangingthetreebankbeingtagged,andthelargerandmoredetailedthetagsetemployed,themorequixoticitistothinkthattheuniverseoftagscanbelistedforagivenword:``pumpkin''becomesanadjectivewhenitislistedasthecolorofasweaterintheL.L.Beancatalog;``The''and``An''turnouttobefirstnamesinatextdiscussingtheteachingofEnglishAsASecondLanguageinSoutheastAsia;``As''showsupasapluralpropernoun,onthesportspage,asthenameofabaseballteam.Itdoesnotfollowthatthedictionaryisahindrance;butbypushingadictionarylessapproachasfaraspossible,wecanconcentrateonunknown--wordand--tagissues,andlaterfactorinadictionaryifwewish.So,weineffectconsidereverywordfortaggingtobeanunknownword.Insteadofaskingwhichtagshavebeenseenforthewordbeingtagged---inourtrainingset,inanonlinedictionary,orineitherplace---weaskabout:partsofwords(sometimesformalaffixes,sometimesnot);certain``wholewords'';thewordssurroundingthewordbeingtagged;characteristicsoftheoverallsentence;tags(orfeaturesoftags)whichthetaggerhasalreadyassigned;etc.Weattempttocapture``trends''inataggedtreebank,trendswhichhavetodowithgroupsofwordsbutwhicharemuchmorevariedandsubtlethanthetendencyofspecificpart-of--speechtrigramstooccur,orofagivenwordtohavebeentaggedacertainwayacertainpercentofthetime.exploitsomewhatsimilartrends,but,inthefirstcase,adifferentmodelingapproachisused,andinthesecondcase,whileasimilarmodeltooursisused,crucially,(a)adictionaryisemployed,(b)onlyself--organizedquestionsareaskedofthedata(seebelow),and(c)asimplertagset(mapped--downCLAWS)isemployed.Sofarthequestionswehaveutilizedaremainlyaimedatdoingsyntactictagging.Weareatwork,however,onmanyadditionalquestionsforuseinsyntactic--plus--semantictagging.Wegeneratequestionsbothbyhandandviaself--organizedmethods,andweapplythesequestionstoourtrainingdatabymeansofstatisticaldecisiontrees.Theoutcomeofthetaggingprocessisessentiallyaprobabilitydistributionforeachtagsequenceforasentence,overalltagsinthetagset.</section>
  <subsection title="The Model"/>
  <subsubsection title="Mutuatl Information (MI) Bits">Inadditiontoaskingaboutaffixes,capitalization,etc.ofwordsinisolation,wecanaskwhetheragivenwordisamemberofaparticularclassofwords.Wedefinewordclassesusingtheself--organizingapproachof---automaticclusteringonlarge,untaggedcorpora,inthiscase20,000,000wordsofWall--Street--Journaltext.Weassigneachofthe70,000mostfrequentwordsinthisdatabasetoitsownclass,theniterativelymergethetwoclasseswhicharemostoftenusedinsimilarsituations.Specifically,ifc_irepresentstheithclass,themutualinformationofclassbigrampairsis:Wefindthepairofclasseswhosemergerintoasingleclasswillleastdecreasethemutualinformation.Bykeepingtrackoftheorderinwhichclassesaremerged,wecandefineabinarytreewhichspansalllevelsofdetailfromoneclassperwordtoasingleclassforallwords.Thebinarytreeisequivalenttoasetwhoseelementisapairofawordandthecorrespondingbitstring.ThisbitsstringforeachwordiscalledMIbits.Whentheseclassesareutilizedforconstructingadecision--treetaggingmodel(seebelow),thedecisiontreecandeterminewhatlevelofdetailtoexploit.Ifweweretorelyonlyorevenmostlyonwordclasses,whetherself--organizedormanually--created,and,crucially,iftherewerealsoatransparentrelationshipbetweenword--classmembershipandtagassignment,thenourapproachwouldberightfullyaccusedofutilizinganinversedictionary.However,itisnotthecasethatinformationexclusivelyinvolvingwordclassesdoesmostoftheworkinourapproach.Anditisalsonotthecasethatthereisanydirectlinkup,inmanycases,betweenthemembershipofawordinoneofourclasses,andanyparticulartagorsetoftags.Therefore,wearenotemployingadictionaryinadisguisedmanner,asmightperhapsbethoughtprimafacie.</subsubsection>
  <subsubsection title="Decision Trees">Decisiontreesareaformalizationofthegameof``20questions''.Themodelconsistsofatree--structuredsetofquestions,withaprobabilitydistributionassociatedwitheachleafofthetree.Toestimateaconditionaldistributionusingthetree,followapathfromtheroottoaleafbasedonanswerstothequestionsateachnode.Theleaf'sassociateddistributionistheestimator.Trainingadecisiontreemodelrequirestwosteps:first,pickingaquestiontoaskateachnode;andsecond,determiningaprobabilitydistributionforeachleaf,usingthedistributionofeventsinthetrainingsetwhichreacheachnode.Asdiscussedin,ateachnodewechoosefromamongallpossiblequestions(thatis,allpossiblebitsdescribingthecurrentwordanditscontext)thatquestionwhichmaximizesentropyreduction.Toavoidovertraining,weuseatypeofbackoffsmoothingtoestimateprobabilitydistributions.Ifp(tag|n)representsthesampledistributionoftagsinthetrainingdatawhichreachthenoden,wedefinethesmoothedprobabilityp(tag|n)=_np(tag|n)+		(1-_n)p(tag|parent(n)),whichinterpolateslinearlybetweenthesampledistributionatnodenandthesmootheddistributionatn'sparentnode.Thevalueoflambdaischosentooptimizeperformanceona``smoothing''datasetwhichisdistinctfromboththetrainingandtestsets.Assigningatagisatwo--stageprocess.First,adecisiontreeassignsoneof20``generalizedparts--of--speech''(GPOS's)tothewordbasedonalargesetofword(--part)andcontextquestions.Second,aseparatedecisiontreeassignsatagtothewordbasedonanadditionallargesetofword(--part)andcontextquestionsaswellasitspredictedGPOS.Inthissecondstage,thereisaseparatedecisiontreeforeachGPOS.Breakingtheprocessupthiswayallowsustoconcentrateondifferentwordcharacteristicsanddifferentaspectsofthecontextfordifferentclassesoftag.Inotherwords,weuseseparatemodelsforpredictingthedetailsofnountags,verbtags,adjectivetags,etc.</subsubsection>
  <subsubsection title="The Tagging Process">Taggingproceedsfromlefttoright,withthegoalofmaximizingthejointprobabilityofthetagsequencefortheentiresentence.Thatis,wefindthesetoftagst_1,t_2,...,t_N,wheret_iisthepredictedtagfortheithwordoftheNwordsentencew_1w_2...w_N,whichmaximizesP&amp;&amp;p(t_1,t_2,...t_N|w_1,w_2,...w_N)&amp;=&amp;_i=1^Np(t_i|w_1,...,w_N,t_1,...,t_i-1)eqnarrayDecisiontreesareusedtoextractrelevantfeaturesfromtheconditionsinthesedistributions.NotethatwehavenotinvokedtheMarkovassumptionhere---thepredictedtagforeventhelastwordofthesentencecan,inprinciple,dependonthefirstwordanditspredictedtag.Whetherthisdependenceinfactshowsupinourmodelsdependsonwhetherthedecisiontreesfindittobeimportantforthetrainingset.Ifwerepresentthedeterministicprocessofusingtheanswerstocontext-dependentquestionstofindaleafinthetreeas:andtheprobabilitydistributionassociatedwithleafLasp_L,thenthedecisiontreesapproximatetherequiredconditionaldistributionsbyandthefunctionoursearchproceduretriestomaximizeis,Onefinaltechnicalityisthat,asstatedinthelastsubsection,wesplitthetaggingprocessintotwoparts,firstassigningaGPOSusingonedecisiontree,thenatagusingaseparatedecisiontreespecializedforthepredictedGPOS.Thusinpractice,theGPOSpredictionusestheconditionsabove,whiletagpredictionusestheseconditionsplustheGPOSpredictedforthecurrentword.Whenthefirstwordofasentenceisconsidered,thecontextconsistsofthewordsandtheirarrangementinthesentence.ThedecisiontreepredictstheprobabilityofeachGPOSforthiswordinthiscontext.Next,foreachpredicted``generalizedpart--of--speech'',theappropriatedecisiontreeisusedtoevaluatetheprobabilityofeachpossibletag.Asearchoverthisspacedeterminestheoverallrankingforeachtag.Then,thenextwordisconsidered.Relevantquestionsnowincludeboththetag-independentquestionsusedforthefirstwordofthesentence,andquestionswhichdependonthetagofthefirstword.Foreachdifferenttagassignedtothefirstword,asetofGPOS'sandthenasetoftagsarepredicted.Asearchoverthespaceoffirst--and--second--wordtag--pairsdeterminesoverallranking.Thisprocedurecontinuesuntileverywordinthesentencehasbeentagged.Ouroverallchoiceofthe``best''tagforeachwordisintendedtomaximizethejointprobabilityoftheentiresetoftags.Thismeanswemustevaluatetheprobabilityforasetoftagsequenceswhichgrowsexponentiallywiththelengthofthesentence.Wecaneitherexhaustivelyenumerateandscoreallthecases(whichisreasonableforasmalltagsetsuchasUPenn),oruseastackdecoderalgorithmtosearchthroughthemostprobablecandidates(asisnecessaryfortheATR--Fulltagset).</subsubsection>
  <subsubsection title="Example Questions">Hereisasamplingofdecision--treequestionscreatedbyourteamgrammarian.Mostofthemareusefulonbothtiersofthetaggingprocess,i.e.tier1,whereGPOSispredicted,aswellasintier2,wheretherestofthetagispredicted.ContextQuestions:(1)Forthewordbeingtagged:(a)positionwithinsentence;(b)quadrantofsentence;(2)Finalwordofsentence:(a)questionmark;(b)periodorexclamationpoint;(3)Anywhereinsentence:(a)by(b)than;(4)Forwordsequencesincludingwordbeingtagged:(a)Specificditto--tagwords;(b)AnyoflargelistoflikelycontextsforparticulartagorGPOS;(c)Anyoflistoflikelycontextsforparticularwordusedinparticularsense---thisformanywordswhichshareasemanticidentity.WordQuestions:(askedofallwordswithintwopositionsofthewordbeingtagged,plustheworditself):(1)Howmanyletterslong(2)Contains``at--sign''(foremailaddresses,etc.)(3)anykindofdeterminer,article,pronoun;(4)endsinprobableadjectivesuffix,yetnotonexceptionlist;(5)adjectivein--wide(complexsetofconditions:eithertheword``wide'';orwordendingin--wide,andhavingeitherahyperbolicprefix,oranumberindigitsorwordsasasubstring);(6)onlistofwords,signallingstartofsubjectnounphrase(andnotonexceptionlist);(7)has``time--adverb''prefix;(8)containshyphenatedprepositionas``midstring'';(9)onlistofsynonymsfor``remember'';(10)containsnameofwildanimal.</subsubsection>
  <subsection title="Experimental Results">ThefocusoftheresearchbeingreportedhereistaggingwiththeATRtagsets,ontheATR/LancasterTreebank.Asapointofreferenceforourresults,however,wehavealsotaggedtheonepublicly--availablecorpus,theUPennWall-Street--JournalTreebank,forwhichthereareresultsutilizingvarioustaggingapproaches.sloppyparUPenntrainingandtestingsetsusedconsistofrandomsentencesfromtheUPennWSJTreebank(1,072,755wordsoftraining,133,293smoothing,49,624testingdata).Therandom--documentsetsconsistofrandomly--selecteddocumentsfromtheATRTreebank(319,903wordsoftraining,38,667smoothing,60,667testingdata).ATRrandom--sentencesetsconsistofrandomly--selectedsentencesfromtheATRTreebank(388,058wordsoftraining,43,189smoothing,12,150testingdata).Clearly,therandom--documentsetsrepresentafairerapproximationofreal--worldtaggingtasks.Obviously,itishardertotagwiththeATR--FulltagsetthanwiththeUPenntagset,buthowmuchharder?Wehavetriedtoquantifytheinherentdifficultyofthevarioustasksforcomparison.Table~displaystheresultsofa``trivialtagger'',whichusesthemostfrequentlyseentagforeachknownword,andthemostfrequentoveralltagforeveryunknownword.Thisprovidesaconvenientbaselineforjudgingthedifficultyofthetaggingtasks.ThefirstcolumnofTable~givesthetaggingaccuracyforthistrivialtagger;thesecondandthirdshowtheperplexityofthetrainingandtestingdatawithrespecttothismodel.Weinterpretthedifferencebetweenperplexitiesforthetrainingandtestingsetstomeanthatwearestillinadata--limitedregime.Inotherwords,theestimatesdifferinthecaseofATR--SyntaxandATR--Fullbecausethesamplesizesarenotlargeenoughtoprovidestableestimates,whereasforUPenntheyare.Asafinalmeansofcomparingtaggingdifficultyamongthethreetagsets,wedisplayFigure~,whichshowsrelativefrequencyofwordswithNtags,foreachofthetagsets.ThelargestnumberoftagsforasinglewordintheUPenntrainingsetis7,accountingfor0.1%oftherunningwords.Bycontrast,21.9%oftherunningwordsintheATR--Syntaxtrainingsetand33.5%oftherunningwordsintheATR--Fulltrainingsethavemorethan7tags.ThemaximumforATR--Syntaxis19tags(1.9%ofrunningwords;8.3%forATR--Full).ResultsareshowninTable~,inseveralcategories:For``%correct''thesetiseverywordinthetestset;forKWT,onlyknownwords---thosewordswhichalsoappearedinthetrainingset;forKWKT,onlyknownwordswithknowntags;forKWUT,onlyknownwordswithanunknowntag;forUW,onlyunknownwords.Theresultsindicatethatourmethodsworkreasonablywellonunknownwords,andunknowntagsforknownwords,althoughnotonunknowntagsfortheATR--Fulltagset.Todate,oureffortshavelargelyconcentratedontheATRsyntaxtagset;weexpectthatworkonquestionssuitableforthesemanticpartsoftheATRtagsetwillimproveperformancethere.Alltheresultsshownhereusethemutualinformationbitsdescribedin.AsshowninTable~,wehavefoundthatincorporatingthesebitsyieldsastatisticallysignificantimprovement,eventhoughthevocabularytheyuseisspecifictotheWSJcorpus.Ourplansforfurtherresearchincludeexploringmethodsoffactoring``dictionary''information(i.e.tagdistributionbywordintrainingdata)intoourmodels;manualquestion--creationforATR--Full,whileimprovingATR--Syntaxquestions;andpossiblyclusteringamuchlargerdatasetforimprovedMIquestions.</subsection>
  <section title="Appendix"/>
</root>
