<?xml version="1.0" ?>
<root>
  <title>確率的クラスタリングを用いた文書連想検索</title>
  <author>岩山真徳永健伸</author>
  <jabstract>本論文では，指定した文書と類似する文書を検索する文書連想検索のための確率的クラスタリングHBC(HierarchicalBayesianClustering)を提案する．文書連想検索を実現する際の問題点は，類似文書の検索に時間がかかることである．単純な網羅検索では，比較対象の大きさNに比例したO(N)の検索時間を要する．本論文では，クラスタ検索と呼ばれる検索手法を用いることでこの問題を解決する．クラスタ検索では，通常，クラスタリングによりクラスタの二分木をあらかじめ構築しておき，その上でトップダウンに二分木検索を行うため，検索時間をO(_2N)に抑えることができる．ところが，従来のクラスタ検索では，検索時に使う距離尺度とクラスタリング時に使う距離尺度が直接関係ないため，単純な二分木検索では十分な検索精度が得られなかった．それに対しHBCは，クラスタリングの対象文書を自己検索した際の精度を最大化するため，検索により適したクラスタリングである．実験では，「現代用語の基礎知識」を用いて，HBCを用いたクラスタ検索がWard法を用いた従来のクラスタ検索よりも優れていることを実証する．また，「WallStreetJournal」を用いて，HBCを用いたクラスタ検索が網羅検索に比べノイズ頑健性に優れていることを実証する．</jabstract>
  <jkeywords>文書検索,クラスタ検索，文書クラスタリング，文書分類</jkeywords>
  <section title="P(C|d) の推定法">まず，「存在する全てのターム~から一つを乱数抽出したとき，それがtと等しい」という事象を``T=t''とする．P(C|d)を可能な全ての``T=t''で条件付けするとP(C|d)&amp;=&amp;_tP(C|d,T=t)P(t|d)&amp;&amp;_T=tP(C|T=t)P(T=t|d).eqnarrayとなる．ここでの近似は，T=tが与えられたという条件下でのCとdの条件付き独立性の仮定による~．ベイズの定理を用いると，()は以下のようになる．ここで，各々の要素確率を以下のように推定する．P(T=t|C):Cにおけるtの相対頻度．P(T=t|d):dにおけるtの相対頻度．P(T=t):与えられた文書集合全体におけるtの相対頻度．P(C):本論文では定数として扱った．</section>
  <section title="はじめに">文書検索では，検索対象の文書集合が大きくなるにつれ，高速/高精度な検索が困難になる．例えば，AltaVista~に代表されるインターネット上のキーワード検索エンジンでは，検索時に入力されるキーワード数が極端に少ないため~，1)望んた文書が検索されない(再現率の問題)，2)望まない文書が大量に検索される(適合率の問題)，といった問題が生じている．そのため，要求拡張(queryexpansion)~，関連度フィードバック(relevancefeedback)~などの手法が提案されてきた．これらの手法はいずれも，要求となるキーワード集合を拡張したり洗練したりすることで，ユーザの検索意図を明確かつ正確なものに導いていく．これに対し，検索時にキーワード集合ではなく文書それ自身を入力し，入力文書と類似する文書を検索する方法が考えられる~．この検索方法を文書連想検索と呼ぶ．文書連想検索が有効なのは，検索要求と関連する文書を我々が既に持っているという状況や，キーワード検索の途中で関連する文書を一つでも見つけたという状況である．また，論文，特許など，我々自身が書いた文書もそのまま検索入力として利用できる．文書連想検索を使うことにより，適切なキーワード集合を選択することなしに，関連する文書を見つけることができる．文書連想検索を実現する際の問題点は，類似文書の検索に時間がかかることである．単純な網羅検索では，検索対象の大きさNに比例したO(N)の時間を要する．そこで本論文では，クラスタ検索~と呼ばれる検索方法を用いる．クラスタ検索では，通常，クラスタリングによりクラスタの二分木をあらかじめ構築しておき~，その上でトップダウンに二分木検索を行う．よって，検索時間は平均O(_2N)に抑えられる．ところが，クラスタ検索に関する従来の研究~では，単純な二分木検索では十分な検索精度が得られないという問題があった．その理由の一つは，クラスタリング時と検索時に異なる距離尺度を用いていたことである．ほとんどの研究では，クラスタリングの手法として単一リンク法，Ward法などを用いていたが，これらの手法は，後の検索で使われる尺度(例えば，TFIDF法や確率)とは直接関係のない尺度でクラスタの二分木を構築していく．これに対し本論文では，クラスタリングの対象文書それぞれを自己検索した際の精度を最大化していく確率的クラスタリングを提案する．よって本クラスタリング法は，検索に適した手法であると言える．実際に，クラスタ検索に本クラスタリング法を用いた場合，単純な二分木検索でも十分な検索精度を得ることができる．検索速度が速い点に加え，クラスタ検索には幾つかの利点がある．クラスタ検索が提案されたそもそもの理由は，「密接に関連した文書群は，同じ検索要求に対する関連性も同等に高い」というクラスタ仮説~である．通常のキーワード検索では，検索要求と単一文書を厳密なキーワード符合に基づいて比較するため，キーワードの表記の異なりにより関連する文書をとり逃すこともあるが，クラスタ検索では，検索要求を意味的にまとまった文書集合(クラスタ仮説で言うところの「密接に関連した文書群」)と比較するため，この問題も起りにくくなる．クラスタ仮説は，特に検索精度の向上という点において実験的に検証されていない仮説であったが，近年，Hearst等により，キーワード検索で検索した文書集合を絞りこむという状況で，その有効性が実証されている~．本論文では，クラスタ検索が検索対象に含まれているノイズの影響を受けにくいこと(ノイズ頑健性)に注目し，本論文で提案するクラスタ検索が網羅検索に比べ優れていることを実証する．以下，~節では，クラスタ検索について説明する．~節では，本論文で提案する確率的クラスタリングについて説明する．~節では，本論文で提案したクラスタ検索の有効性を調べるために行なった幾つかの実験について述べる．</section>
  <section title="クラスタ検索">クラスタ検索に限らず，文書対文書の比較を行うには，まず文書間の距離を定義する必要がある．本論文では，条件付き確率P(C|d)を用い，文書dから文書集合Cへの方向性のある類似性を定義する．ある文書集合を検索する際は，dが入力文書(検索要求)となり，Cがこれから検索しようとする文書集合の部分集合となる．最も極端な例が網羅検索であり，Cは文書集合の各文書それ自身になる(図~~(a)参照)．一方，クラスタ検索では，Cは何らかの指針により自動/人手で作られたクラスタである．P(C|d)を推定する方法は幾つか提案されているが~，本論文ではIwayama等の推定法~を用いることにする．付録~にP(C|d)の推定法を記す．図~~(b)が典型的なクラスタ検索を図式化したものである．本論文で扱うクラスタ検索では，文書集合を二分木として自動的に構成し(このステップをクラスタリングまたは訓練と呼ぶ)，検索要求を各クラスタ(ノード)と比較することによって，検索要求と類似する文書を指定した数だけとりだす(このステップを検索またはテストと呼ぶ)．最も単純な検索法は二分木検索であり(図~~(b)参照)，クラスタ木の根からトップダウンに木をたどり，指定した数の文書を含むクラスタを探す．木をたどる際は，各ノードでそれぞれの子ノードについてP(C|d)を計算し，どちらに進むかを決定する．二分木検索は，平均O(_2N)の検索時間しか必要とせず，網羅検索(O(N))に比べ高速な検索が可能である．一般に，網羅検索はその検索コストのため大規模な文書集合の検索/ランキングには適用しづらい．事実，現実に運用されている検索システムのほとんどは，ランク付きの検索出力が提供されていないか，提供されていても近似計算~である場合が多い．連想検索のように検索要求が長い場合は，ランク付けの計算に検索要求の全情報を使わないこともある~．検索コストを軽減する効果的な方法は，キーワードから文書への逆インデクス(invertedfile)~を使い，検索要求に含まれているキーワードを全く含まない文書を検索対象から除外することである~．残った文書集合を網羅検索することで計算量も幾分軽減できる．しかし，逆インデクスの導入は問題の本質的解決ではなく，原理的には依然としてO(N)の検索コストが必要である．figure*クラスタ木上をトップダウンに二分木検索する方法とは逆に，葉からボトムアップにクラスタ木を検索する方法もある．この検索法はボトムアップクラスタ検索と呼ばれ，二分木検索よりも精度的に有効であることが実証されている~．ところが，ボトムアップクラスタ検索では，まず検索の出発点となる葉ノードを決める必要がある．既に何らかの方法で出発点がわかっている場合はよいが，そうでない場合はゼロからこのノードを見つけるため，網羅検索に近い計算量が必要となる．本論文では，その簡素さと高速性のため，トップダウンな二分木検索を使うことにする．また，二分木検索にも，ビーム幅内を並行して検索する，検索の出発ノードを葉に近いノードにするなど様々な拡張が考えられるが，本論文では，断わりのない限り単純な二分木検索に限ることにする．</section>
  <section title="確率的クラスタリング(HBC)">クラスタ検索におけるクラスタリングの目的は，検索を行った際に高い精度を与えるようなクラスタ木を構築することである．不適切なクラスタ木は，検索要求に対して関連の低い文書を出力してしまう．特に，クラスタ木の根に近い部分は，与えられたほとんどの文書集合を含むため漠然性が高く，二分木検索もこの部分での比較で誤りを起しやすい．従来のクラスタ検索において二分木検索の精度が悪かったのは主にこの理由である．以下では，二分木検索でも高い精度を与えるような確率的クラスタリングを提案する．核となるアイデアは，クラスタリング(訓練)にも検索(テスト)にも前節で説明した確率P(C|d)を用いることである．まず，クラスタリングで使う尺度として自己再現率(selfrecall)を定義する．あるクラスタCに関する自己再現率SR(C)を以下のように定義する．自己再現率は，クラスタ内の各文書が自分自身を含むクラスタを見つけることができる確率，と解釈することができる．あるクラスタCにとって，SR(C)の値が大きいということは，C内の各文書を検索入力とした時，それらがCを見つける確率が高いということである．文書集合Dがクラスタの集合C_1,C_2,に分割されているとすると，その文書集合Dに対する自己再現率は以下のように定義できる．これは，文書集合全体に関する自己検索の精度に関連する．ここまでで，クラスタリングの目的は「文書集合Dが与えられた時，SR(D)が最大となる分割を見付けること」と詳細化できる．ただし，通常は山登り法になどにより局所的な最大分割を求めることが多い．例えば，SR(D)を評価関数として非階層的クラスタリングアルゴリズム~を適用すると，文書集合を平坦なグループに分割することができる．また，文書集合Dに対して階層的な二分クラスタ木を構築するには，以下に示す凝集型アルゴリズムを適用すればよい．初期クラスタ集合を，	D内の各文書それ自身のみからなるクラスタの集合とする．マージによりSR(D)の増分が最大になるような	クラスタのペアを見つけ実際にマージする．残りのクラスタの数が1でなければステップ2に戻る．以上のアルゴリズムを階層的ベイズクラスタリング(HBC:HierarchicalBayesianClustering)と呼ぶ．HBCの詳細については，を参照されたい．そこでは，HBCと従来のクラスタリング手法との比較実験も行われている．また，付録~にHBCの形式的な記述を示す．従来のクラスタ検索における実験では，二分木検索に関して否定的な結果がでていた．考えられる理由は，クラスタリング(訓練)と検索(テスト)で異なった尺度(原理)を用いていたことである．従来の実験では，単一リンク法やWard法をクラスタリングの方法として用いていたが，これらの方法は，検索に使う尺度とは直接関係のない尺度を使いクラスタ木を構築している．例えば単一リンク法では，二つのクラスタ間の距離として，それらのクラスタを構成する要素(文書)間の最も近い距離を使う．よって，クラスタ内の他の構成要素の情報は無視されてしまう．また，構成要素(文書)とクラスタ全体との関係が考慮されていない．検索で用いるのは文書とクラスタとの距離である．これらの欠点は，完全リンク法や平均リンク法にもあてはまる．Ward法は，群内誤差の平方和によりクラスタ間の距離を計算するため，上記の欠点はない．しかし，群内誤差の平方和は，検索時に用いる距離尺度とは直接関係がない．それに対しHBCは，文書集合が与えられると，それらを自己検索した時の精度(具体的には自己再現率)を最大化するようなクラスタ木を構築する．つまり，訓練例に対する検索精度の最大化を行っているため，クラスタ検索という用途に直接関連した手法である．次節では，HBCをクラスタ検索に用いた場合の有効性を実験により検証する．なお，単一リンク法やWard法も統計解析という元々の用途には有効な手法である．</section>
  <section title="実験"/>
  <subsection title="実験方式とデータについて">実験では，連想検索の精度を評価するためにトピック割り付けを行った．トピック割り付けとは，あらかじめ定義されたトピックの中から1個以上のトピックを文書に割り付けるタスクである．例えば，ある文書にx,y,zという3個のトピックが付いているとする．これらの正解トピックは，通常，専門家によって割り付けられる．そして，自動的な方法により，同じ文書にx,wという2個のトピックが割り付けられたとする．ここで，xという1つのトピックのみが3個の正解トピックから再現されたという意味で，再現率(recall)は1/3となる．また，xという1つのトピックのみが，自動的に割り付けられた2個のトピックのなかで正解であったという意味で，適合率(precision)は1/2となる．自動的なトピック割り付け法としては，k-NN法(k-NearestNeighborclassifiers)~を用いた．k-NN法では，ある文書dにトピックを割り付ける際，あらかじめ専門家によりトピックが割り付けられている文書集合(訓練データ)の中からdに近いものをk個検索する．この検索法に，文書連想検索の手法(網羅検索，クラスタ検索)を用い比較した．検索したk個の訓練データには既にトピックが付いているため，それぞれのトピックを重み付きで集計し，あるしきい値以上になるトピックをdに割り付ける．重みとしては，dと各々の訓練データとの距離(条件付き確率)を用いた．ここで，dに割り付けられるべき正解トピックが既にわかっているため，再現率/適合率が計算できる．また，自動割り付けにおけるしきい値を変化させることで，再現率/適合率のトレードオフ曲線が描ける．実験データには，「現代用語の基礎知識(92年版)~(GK)」と「WallStreetJournal~(WSJ)」を用いた．それぞれの特徴は以下のとおりである．これら二つのデータセットには，日本語と英語という大きな相違点の他に，以下の特筆すべき相違点がある．GKの各文書が単一のトピックしか持たないのに対し，WSJは複数(平均1.94個)のトピックを持つ．GKは，文書長，および各トピックが持つ文書数が比較的均一なデータセットであるのに対し，WSJは非均一なデータセットである．GKには各トピックを担当する編集者が存在し，その編集者が担当トピックの辞書見出しを管理しているからである.それに加え，GKでは，短い辞書見出し，辞書見出し数が少ないトピックを上記の方法により強制的に除去している．よって，WSJに比べ，GKはよりノイズの少ないデータセットであると言える．逆の視点から見ると，WSJはより現実データに近いと言える．実験の前処理として，まず，文書表現として用いるタームを抽出する必要がある．両データセットとも，名詞と未知語をタームとして用いた．タガーとして，GKではJUMAN~を，WSJではXeroxPart-of-SpeechTagger~を用いた．WSJに関しては，ispell~を用いて語尾処理を行ない，単語の原形のみ用いた．また，トピック割り付けを行うには，データセットを訓練データとテストデータに分割する必要がある．GKは文書数が少ないため，4分割のクロスバリデーションを行った．WSJでは，'89/7/25から'89/9/29までの5,820記事を訓練データとして，'89/10/2から'89/11/2までの3,087記事をテストデータとして使った．</subsection>
  <subsection title="従来のクラスタ検索との比較">まず，比較的ノイズの少ないGKを用いて，HBCを用いたクラスタ検索と従来から行われていたクラスタ検索を比較する．従来法としては，クラスタリングにWard法~を，検索に確率モデルを用いた．よって，両者はクラスタリングの手法のみが異なる．また，比較対象として，網羅検索による実験も行った．網羅検索における文書間の距離尺度には，クラスタ検索と同じ確率モデルを用いた．以上はk-NN法によるトピック割り付けであるが，この他にトピック割り付けの代表的な方法(以下，トピック検索法と呼ぶ)も比較対象として実験に用いた．トピック検索法では，まず，各トピック毎にそのトピックが割り付けられている文書を集め，トピックを表現する文書集合とする．次に，トピックを割り当てようとする文書と，各トピックを表現している文書集合との間の距離を計算して，距離が近いトピックを文書に割り当てる．距離尺度としては，上記手法と同じ確率モデルを用いた．GKでは，割り当てられるべきトピックが一つであるため，実験に用いた手法でも，上位1位のトピックを割り付け，それが正解となっている割合で精度を測定した．実験結果を図~に示す．図中，X軸は，k-NN法でいうところのk，つまり，判定に用いた訓練データ数である．図~から，kが極端に小さくない場合，網羅検索の精度が最も良いことがわかる．また，HBCを用いたクラスタ検索も，網羅検索の精度曲線を良く近似している．このことから，検索に要する速度などを考えると，HBCを用いたクラスタ検索は速度/精度の点でバランスの取れた手法であると言える．逆に，Ward法を用いたクラスタ検索が与える精度曲線は，網羅検索の精度曲線とは極端に異なり，特にkが300以下での精度が非常に悪くなっている．興味深いのは，網羅検索，二つのクラスタ検索共に，kが大きくなるにつれトピック検索法が与える精度に収束していく点である．ただし，HBCを用いたクラスタ検索，網羅検索が，kを適当に設定するとトピック検索法を上回るのに対し，Ward法を用いたクラスタ検索は，常にトピック検索法を下回る．以上の実験結果から，HBCを用いたクラスタ検索法は，従来のクラスタ検索よりも有効であることが確認できた．次節では，ノイズを含むより実データに近いWSJを用いて，HBCを用いたクラスタ検索と網羅検索との違いを詳しく調べる．</subsection>
  <subsection title="クラスタ検索のノイズ頑健性">クラスタ検索は，網羅検索と比べると汎化能力という点で優れている．クラスタ検索は訓練データを一般化したクラスタ集合を扱うためである．網羅検索は訓練データそれ自体を扱うため，訓練データ中に存在するノイズの影響を受けやすい．前節のGKによる実験では，この点が確かめられなかったが，これはGKがノイズの少ない均一なデータセットであることによる．本節では，WSJを使って，データセット中に存在するノイズがトピック割り付け(すなわち連想検索)に及ぼす影響を調べる．WSJの各文書には複数のトピックが割り付けられているため，前述の再現率/適合率で評価を行った．トピック割り付け戦略としては以下の3種類を用い比較した．従来行なわれた実験~では，比例配分割り付けの優位性が確認されている．しかし，比例配分割り付けを行うには，あらかじめ十分な数のテストデータがそろっている必要がある．よって，比例配分割り付けは，バッチ的な割り付け処理の局面では有効であるが，オンライン(リアルタイム)で割り付けを行なうような状況に適用することはできない．図~~~にそれぞれの割り付け戦略による実験結果を示す．ここでは，HBCによるクラスタ検索と網羅検索を比較している．また，ベースラインとして，トピック検索法による結果も示した．Y軸のbreakevenとは，再現率/適合率トレードオフ曲線において，再現率と適合率が等しくなる点の値である．X軸は，前節と同じくk-NN法におけるkの値である．図~~~から，まず，他の二つの割り付け戦略に比べ，比例配分割り付けが優れていることがわかる．また，比例配分割り付けでは，網羅検索，クラスタ検索共に，トピック検索と同程度の精度である．更に，両者共にk-NN法のkによる影響をあまり強く受けていない．よって，比例配分割り付けは，検索の手法に対して安定した割り付け戦略であると言える．ところが，前述したように，比例配分割り付けはバッチ処理に限られるという制限がある．定数割り付け，確率的割り付けでは，網羅検索，クラスタ検索共に，ベースラインのトピック検索を大きく上回っている．これは，k-NN法の優位性を示している．ここで注目して欲しいのは，k-NN法でも，網羅検索の精度曲線がkの値に大きく影響を受けている点である．特に，最大breakevenを与えるkの範囲が非常に狭く，それよりkの値が大きくなると，breakevenが急激に低下している．これは，訓練データ中に存在するノイズの影響を強く受けていることを意味している．一方，クラスタ検索の精度曲線はkに依存せず安定している．つまり，最大breakevenを与えるkの範囲が広いため，微妙なパラメータ(k)設定を行う必要がない．これは，クラスタリングという汎化操作により，訓練データ中のノイズの影響があらわれにくくなっていることを意味している．以上から，HBCを用いたクラスタ検索は，網羅検索に比べノイズ頑健性に優れていると言える．</subsection>
  <section title="おわりに">本論文では，文書連想検索のための新しいクラスタ検索法を提案した．提案したクラスタ検索では，与えられた文書集合を自己検索した時の精度を最大化する確率的クラスタリングを用いている．よって，本クラスタリング手法は，従来のクラスタ検索で用いられていたクラスタリング手法に比べると，検索に密接に関連した手法であると言える．「現代用語の基礎知識」「WallStreetJournal」を用いた実験の結果，従来のクラスタ検索に対する本手法の優位性が確認できた．また，網羅検索に対しては，本手法がノイズ頑健性という点で優れていることが確認できた．以下，問題点と今後の課題を挙げる．</section>
  <section title="階層的ベイズクラスタリング(Hierarchical Bayesian Clustering)">100mm=12pt`;=3000Input:D=d_1,d_2,,d_N:asetofNdocuments;Initialize:M_0=C_1,C_2,,C_N:asetofclusters;C_i=d_ifor1iNcalculateSR(C_i)for1iNcalculateSR(C_iC_j)for1i&lt;jNfork=1toN-1do(C_x,C_y)=_C_x,C_y	SR(C_xC_y)	SR(C_x)SR(C_y)M_k=M_k-1-C_x,C_y+C_xC_ycalculateSR(C_xC_z)	forallC_zM_kwherezxFunctionSR(C)return_dCP(C|d)minipagedocument</section>
</root>
