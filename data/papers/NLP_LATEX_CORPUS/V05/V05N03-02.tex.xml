<?xml version="1.0" ?>
<root>
  <title>ProbabilisticGLRParsing:ANewFormalizationandItsImpactonParsingPerformance</title>
  <author>INUIKentaro^,VirachSORNLERTLAMVANICH^,Hozumi^andTOKUNAGATakenobu^~~DepartmentofArtificialIntelligenceKyushuInstituteofTechnologyinui@ai.kyutech.ac.jp</author>
  <section title="">*AcknowledgmentTheauthorswouldliketothankthereviewersfortheirsuggestivecomments.TheywouldalsoliketothankUEKIMasahiroandSHIRAIKiyoaki(TokyoInstituteofTechnology)fortheirfruitfuldiscussionontheformalizationoftheproposedmodel.Finally,theywouldliketothankTimothyBaldwin(TokyoInstituteofTechnology)forhishelpinwritingthispaper.</section>
  <section title="Introduction">Theincreasingavailabilityoftextcorporahasencouragedresearcherstoexplorestatisticalapproachesforvarioustasksinnaturallanguageprocessing.Statisticalparsingisoneoftheseapproaches.Instatisticalparsing,oneofthemoststraightforwardmethodologiesistogeneralizecontext-freegrammarsbyassociatingaprobabilitywitheachruleinproducingprobabilisticcontext-freegrammars(PCFGs).However,asmanyresearchershavealreadypointedout,PCFGsarenotquiteadequateforstatisticalparsingduetotheirinabilitytoencapsulatecontextofparsederivation.ProbabilisticGLRparsingisoneexistingstatisticalparsingmethodologywhichtakescontextintoaccounttoagreaterdegreethanPCFG-basedparsing.SeveralattemptshavebeenmadetoincorporateprobabilityintogeneralizedLR(GLR)parsing~.Forexample,WrightandWrigleyproposedanalgorithmtodistributeprobabilitiesoriginallyassociatedwithCFGrulestoLRparsingactions,insuchawaythattheresultingmodelisequivalenttotheoriginalPCFG~.Perhaps,themostnaivewayofcouplingaPCFGmodelwiththeGLRparsingframeworkwouldbetoassigntheprobabilityassociatedwitheachCFGruletothereduceactionsforthatrule.WrightandWrigleyexpandedonthisgeneralmethodologybydistributingprobabilitiestoshiftactionsaswellasreduceactions,sothattheparsercanpruneimprobableparsederivationsaftershiftactionsaswellasreduceactions.ThiscanbeadvantageousparticularlywhenoneconsidersapplyingaGLRparserto,forexample,continuousspeechrecognition.However,sincetheirprincipalconcernwasincompilingPCFGsintotheGLRparsingframework,theirlanguagemodelstillfailedtocapturecontext-sensitivityoflanguages.Suetal.proposedawayofintroducingprobabilisticdistributionintotheshift-reduceparsingframework~.UnlikeWrightandWrigley'swork,thegoalofthisresearchwastheconstructionofamodelthatcapturescontext.Theirmodeldistributesprobabilitiestostacktransitionsbetweentwoshiftactions,andassociatesaprobabilitywitheachparsederivation,givenbytheproductoftheprobabilityofeachchangeincludedinthederivation.Further,theyalsodescribedanalgorithmtohandlethismodelwithintheGLRparsingframework,gainingparseefficiency.However,sincetheirprobabilisticmodelinitselfisnotintimatelycoupledwiththeGLRparsingalgorithm,theirmodelneedsanadditionalcomplexalgorithmfortraining.Ontheotherhand,BriscoeandCarrollproposedthedistributionofprobabilitiesdirectlytoeachactioninanLRtable~.Theirmodelovercomesthedrawbackofderivationalcontext-insensitivityofPCFGsbyestimatingtheprobabilityofeachLRparsingactionaccordingtoitsleft(i.e.LRparsestate)andrightcontext(i.e.nextinputsymbol).Theprobabilityofeachparsederivationiscomputedastheproductoftheprobabilityassignedtoeachactionincludedinthederivation.UnliketheapproachofSuetal.,thismakesiteasytoimplementcontext-sensitiveprobabilisticparsingbyslightlyextendingGLRparsers,andtheprobabilisticparameterscanbeeasilytrainedsimplybycountingthefrequencyofapplicationofeachactioninparsingthetrainingsentences.Furthermore,theirmodelisexpectedtobeabletoallowtheparsertopruneimprobableparsederivationsatanequivalentlyfine-grainedlevelasthatofWrightandWrigley'sstatisticalparser,sinceitassignsprobabilitiestobothshiftandreduceactions.However,inasfaraswehavetestedtheperformanceofBriscoeandCarroll'smodel(model,hereafter)inourpreliminaryexperiments,itseemsthat,inmanycases,itdoesnotsignificantlyimproveontheperformanceofthePCFGmodel,andfurthermore,intheworstcase,itcanbeevenlesseffectivethanthePCFGmodel~.Accordingtoouranalysis,theseseemtobetheresults,principally,ofthemethodusedfornormalizingprobabilitiesintheirmodel,whichmaynotbeprobabilisticallywell-founded.Infact,BriscoeandCarrollhavenotexplicitlypresentedanyformalizationoftheirmodel.ThislineofreasoningledustoconsideranewformalizationofprobabilisticGLR(PGLR)parsing.Inthispaper,weproposeanewlyformalizedPGLRlanguagemodelforstatisticalparsing,whichhasthefollowingadvantages:Itprovidesprobabilisticallywell-foundeddistributions.Itcapturescontextofparsederivation.ItcanbetrainedsimplybycountingthefrequencyofeachLRparsingaction.Itallowstheparsertopruneimprobableparsederivations,evenaftershiftactions.ThefocusofthispaperisontheformalandqualitativeaspectsofourPGLRmodelratherthantheempiricalquantitativeevaluationofthemodel.Large-scaledexperimentsfortheempiricalevaluationiscurrentlybeingconducted.Inourpreliminaryexperiments,wehavesofarbeenachievingpromisingresults,someofwhichisreportedelsewhere~.Inwhatfollows,wefirstpresentournewformalizationofPGLRparsing(PGLR).Wethenreviewmodelaccordingtoourformalization,demonstratingthatmodelmaynotbeprobabilisticallywell-foundedthroughtheuseofsimpleexamples(BC-model).Wefinallydiscusshowourrefinementisexpectedtoinfluenceparsingperformancethroughafurtherexample(example).</section>
  <section title="A PGLR Language Model">SupposewehaveaCFGanditscorrespondingLRtable.Letandbethenonterminalandterminalalphabets,respectively,oftheCFG.Further,letandbethesetsofLRparsestatesandparsingactionsappearingintheLRtable,respectively.Foreachstates,theLRtablespecifiesaset(s)ofpossiblenextinputsymbols.Further,foreachcouplingofastatesandinputsymboll(s),thetablespecifiesasetofpossibleparsingactions:(s,l).Eachactionaiseitherashiftactionorreduceaction.Letandbethesetofshiftandreduceactions,respectively,suchthat=(isaspecialactiondenotingthecompletionofparsing).Aswithmoststatisticalparsingframeworks,givenaninputsentence,weranktheparsetreecandidatesaccordingtotheprobabilitiesoftheparsederivationsthatgeneratethosetrees.InLRparsing,eachparsederivationcanberegardedasacompletesequenceoftransitionsbetweenLRparsestacks,whichwedescribeindetailbelow.Thus,inthefollowing,weusethetermsparsetree,parsederivation,andcompletestacktransitionsequenceinterchangeably.GivenaninputwordsequenceW=w_1w_n,weestimatethedistributionovertheparsetreecandidatesasfollows:P(|W)=P()P(W|)eqnarrayThefirstscalingfactorisaconstantthatisindependentof,andthusdoesnotneedtobeconsideredinrankingparsetrees.ThesecondfactorP(T)isthedistributionoverallthepossibletrees,i.e.completestacktransitionsequences,thatcanbederivedfromagivengrammar,suchthat,forbeingtheinfinitesetofallpossiblecompletestacktransitionsequences:WeestimatethissyntacticdistributionP()usingaPGLRmodel.ThethirdfactorP(W|T)isthedistributionoflexicalderivationsfromT,whereeachterminalsymbolofTisassumedtobeapartofspeechsymbol.Moststatisticalparsingframeworksestimatethisdistributionbyassumingthattheprobabilityofthei-thwordw_iofWdependsonlyonitscorrespondingterminalsymbol(i.e.partofspeech)l_i.Sincel_iisuniquelyspecifiedbyforeachi,weobtainequationP(W|T):wherenisthelengthofW.OnecouldtakerichercontextinestimatingthelexicaldistributionP(W|).Forexample,weproposetoincorporatethestatisticsofwordcollocationsintothislexicalderivationmodelelsewhere~.However,thisissueisbeyondthescopeofthispaper.AstacktransitionsequencecanbedescribedasT-def:where_iisthei-thstack,whosestack-topstateisdenotedby(_i),andl_i((_i-1))anda_i((_i-1),l_i)are,respectively,aninputsymbolandaparsingactionchosenat_i-1.Aparsederivationcompletesifl_n=anda_n=.Wesaystacktransitionsequenceiscompleteifl_n=,a_n=,and_n=,whereisadummysymboldenotingthestackwhenparsingiscompleted.Hereafter,weconsistentlyrefertoanLRparsestateasastate/andanLRparsestackasastack.And,unlessdefinedexplicitly,s_idenotesthestack-topstateofthei-thstack_i,i.e.s_i=(_i).TheprobabilityofacompletestacktransitionsequencecanbedecomposedasinT1:P()&amp;=&amp;P(_0,l_1,a_1,_1,,_n-1,l_n,a_n,_n)&amp;=&amp;P(_0)_i=1^nP(l_i,a_i,_i|_0,l_1,a_1,_1,,l_i-1,a_i-1,_i-1)eqnarrayHereweassumethat_icontainsalltheinformationofitsprecedingparsederivationthathasanyeffectontheprobabilityofthenexttransition,namely:ThisassumptionsimplifiesequationT1to:Now,weshowhowweestimateeachtransitionprobabilityP(l_i,a_i,_i|_i-1),whichcanbedecomposedasinSt0:Tobeginwith,weestimatethefirstfactorP(l_i|_i-1)asfollows:Next,weestimatethesecondfactorP(a_i|_i-1,l_i)relyingontheanalogousassumptionthatonlythecurrentstack-topstates_i-1andinputsymboll_ihaveanyeffectontheprobabilityofthenextactiona_i:whereFinally,giventhecurrentstack_i-1andactiona_i,thenextstack_icanbeuniquelydetermined:Equationst0canbederivedfromtheLRparsingalgorithm;namely,givenaninputsymboll_i+1((_i))andanactiona_i+1((_i),l_i+1),thenext(derived)stack(_i,a_i+1)(=_i+1)canalwaysbeuniquelydeterminedasfollows:Ifthecurrentactiona_i+1isashiftactionforaninputsymboll_i+1,thentheparserconsumesl_i+1,pushingl_i+1ontothestack,andthenpushesthenextstates_i+1,whichisuniquelyspecifiedbytheLRtable,ontothestack.Ifthecurrentactiona_i+1isareductionbyaruleA,theparserderivesthenextstackasfollows.Theparserfirstpops||grammaticalsymbolstogetherwith||statesymbolsoffthestack,where||isthelengthof.Inthisway,thestack-topstates_jisexposed.TheparserthenpushesAands_i+1ontothestack,withs_i+1beingtheentryspecifiedintheLRgototablefors_jandA.Alltheseoperationsareexecuteddeterministically.Asshowninequationsl1andl2,theprobabilityP(l_i|_i-1)shouldbeestimateddifferentlydependingonwhetherthepreviousactiona_i-1isashiftactionorareduceaction.Fortunately,giventhecurrentstack-topstates_i-1,itisalwayspossibletodeterminewhetherthepreviousactiona_i-1wasashiftorreduction.Thus,wedividethesetofLRparsestatesintotwosubsets:,whichisthesetcontainings_0andallthestatesreachedimmediatelyafterapplyingashiftaction,and,whichisthesetofstatesreachedimmediatelyafterapplyingareduceaction:&amp;&amp;s_0s|a,:;s=((,a))&amp;&amp;s|a,:;s=((,a))&amp;&amp;=and=eqnarraywheres_0istheinitialstate.SeeAppendixAforabriefproofofthemutualexclusivenessbetweenand.EquationsSt0throughSr-defcanbesummarizedas:Sinceandaremutuallyexclusive,wecanassignasingleprobabilisticparametertoeachactioninanLRtable,accordingtoequationSt2.Tobemorespecific,foreachstates,weassociateaprobabilityp(a)witheachactiona(s,l)(forl(s)),wherep(a)=P(l,a|s)suchthat:Ontheotherhand,foreachstates,weassociateaprobabilityp(a)witheachactiona(s,l)(forl(s)),wherep(a)=P(a|s,l)suchthat:ThroughassigningprobabilitiestoactionsinanLRtableinthisway,wecanestimatetheprobabilityofastacktransitionsequenceasgiveninT-defbycomputingtheproductoftheprobabilitiesassociatedwithalltheactionsincludedin:Beforeclosingthissection,wedescribetheadvantagesofourPGLRmodel.Ourmodelinheritssomeofitsadvantagesfrommodel.First,themodelcapturescontextasinequationa1:theprobabilisticdistributionofeachparsingactiondependsonbothitsleftcontext(i.e.LRparsestate)andrightcontext(i.e.inputsymbol).Weelaboratethisthroughanexampleinexample.Second,sincetheprobabilityofeachparsederivationcanbeestimatedsimplyastheproductoftheprobabilitiesassociatedwithalltheactionsinthatderivation,wecaneasilyimplementaprobabilisticLRparserthroughasimpleextensiontotheoriginalLRparser.Wecanalsoeasilytrainthemodel,asweneedonlycountthefrequencyofapplicationofeachactioningeneratingcorrectparsederivationsforeachentryinthetrainingcorpus.Third,bothmodelandourmodelareexpectedtobeabletoallowtheparsertopruneimprobableparsederivationsatanequivalentlyfine-grainedlevelasthatforWrightandWrigley'sstatisticalparser,sincethesetwomodelsassignprobabilitiestobothshiftandreduceactions.Furthermore,sinceourmodelassignsasingleprobabilisticparametertoeachactioninanLRtablesimilarlyto,thealgorithmproposedbyCarrollandBriscoe~forefficientunpackingofpackedparseforestswithprobabilityannotationscanbeequallyapplicabletoourmodel.Finally,althoughnotexplicitlypointedoutbyBriscoeandCarroll,itshouldalsobenotedthatPCFGsgiveglobalpreferenceoverstructuresbutdonotsufficientlyreflectlocalbigramstatisticsofterminalsymbols,whereasbothmodelandourPGLRmodelreflectthesetypesofpreferencesimultaneously.P(l_i|s_i-1)inequationl1isamodelthatpredictsthenextterminalsymboll_iforthecurrentleftcontexts_i-1.Inthiscaseofs_i-1,sinces_i-1uniquelyspecifiesthepreviousterminalsymboll_i-1,P(l_i|s_i-1)=P(l_i|s_i-1,l_i-1),whichisaslightlymorecontext-sensitiveversionofthebigrammodelofterminalsymbolsP(l_i|l_i-1).ThisfeatureisexpectedtobesignificantparticularlywhenoneattemptstointegratesyntacticparsingwithmorphologicalanalysisintheGLRparsingframework(e.g.),sincethebigrammodelofterminalsymbolshasbeenempiricallyproventobeeffectiveinmorphologicalanalysis.Besidestheseadvantages,whichareallsharedwithmodel,ourmodelovercomesthedrawbackofmodel;namely,ourmodelisbasedonaprobabilisticallywell-foundedformalization,whichisexpectedtoimprovetheparsingperformance.Wediscussthisissueintheremainingsections.</section>
  <section title="Comparison with Briscoe and Carroll's Model">Inthissection,webrieflyreviewmodel,andmakeaqualitativecomparisonbetweentheirmodelandours.Inourmodel,weconsidertheprobabilitiesoftransitionsbetweenstacksasgiveninequationT2,whereasBriscoeandCarrollconsidertheprobabilitiesoftransitionsbetweenLRparsestates/asbelow:P()&amp;=&amp;_i=1^nP(l_i,a_i,s_i|s_i-1)&amp;=&amp;_i=1^nP(l_i,a_i|s_i-1)P(s_i|s_i-1,l_i,a_i)eqnarrayBriscoeandCarrollinitiallyassociateaprobabilityp(a)witheachactiona(s,l)(fors,l(s))inanLRtable,wherep(a)correspondstothefirstfactorinBriscoe-T1:suchthat:Inthismodel,theprobabilityassociatedwitheachactionisnormalizedinthesamemannerforanystate.However,asdiscussedintheprevioussection,theprobabilityassignedtoanactionshouldbenormalizeddifferentlydependingonwhetherthestateassociatedwiththeactionisofclassorasinequationssum-a1andsum-a2.Withoutthistreatment,probabilityP(l_i|s_i-1)inequationl1couldbeincorrectlyduplicatedforasingleterminalsymbol,whichwouldmakeitdifficulttogiveprobabilisticallywell-foundedsemanticstotheoverallscore.Asaconsequence,in,theprobabilitiesofallthecompleteparsederivationsmaynotsumuptoone,whichwouldbeinconsistentwiththedefinitionofP()(seeequationTset0).Toillustratethis,letusconsidergrammarG1asfollows.Thisgrammarallowsonlytwoderivationsasshownintrees1.Supposethatwehavetree(a)withfrequencym,and(b)withfrequencyninthetrainingset.Trainingmodelandourmodelwiththesetrees,weobtainthemodelsasshowninLR-table1,where,foreachLRparsestate,eachbracketedvalueinthetopofeachrowdenotesthenumberofoccurrencesoftheactionassociatedwithit,andthenumbersinthemiddleandbottomofeachrowdenotetheprobabilisticparametersofmodelandourmodel,respectively.Giventhissetting,theprobabilityofeachtreeintrees1iscomputedasfollows(seetrees1,whereeachcirclednumberdenotestheLRparsestatereachedafterparsinghasproceededfromtheleft-mostcornertothelocationofthatnumber):&amp;&amp;P_B&amp;C(tree(a))=1mm+nmm+n1=(mm+n)^2&amp;&amp;P_B&amp;C(tree(b))=1nm+nnm+n1=(nm+n)^2&amp;&amp;P_PGLR(tree(a))=1mm+n11=mm+n&amp;&amp;P_PGLR(tree(b))=1nm+n11=nm+neqnarraywhereB&amp;CdenotesmodelandPGLRdenotesourmodel.Thiscomputationshowsthatourmodelcorrectlyfitsthedistributionofthetrainingset,withthesumoftheprobabilitiesbeingone.Inthecaseofmodel,ontheotherhand,thesumofthesetwoprobabilitiesissmallerthanone.Thereasoncanbedescribedasfollows.Aftershiftingtheleft-mostinputsymbolx,whichleadstheprocesstostate1,themodelpredictsthenextinputsymbolaseitheruorv,andchoosesthereduceactionineachcase,reachingstate4.Sofar,bothmodelandourmodelbehaveinthesamemanner.Instate4,however,modelrepredictsthenextinputsymbolu(or),despiteitalreadyhavingbeendeterminedinstate1.Thisduplicationmakestheprobabilityofeachtreesmallerthanwhatitshouldbe.Inourmodel,ontheotherhand,theprobabilitiesinstate4,whichisofclass,arenormalizedforeachinputsymbol,andthusthepredictionoftheinputsymbolisnotduplicated.BriscoeandCarrollarealsorequiredtoincludethesecondfactorP(s_i|s_i-1,l_i,a_i)inBriscoe-T1sincethisfactordoesnotalwayscomputetoone.Infact,ifwehaveonlytheinformationofthecurrentstack-topstates_i-1andapplyareduceactioninthatstate,thenextstates_iisnotalwaysuniquelydetermined.Forthisreason,BriscoeandCarrollfurthersubdivideprobabilitiesassignedtoreduceactionsaccordingtothestack-topstatesexposedimmediatelyafterthepopoperationsassociatedwiththosereduceactions.Contrastively,inourmodel,giventhecurrentstack,thenextstackafterapplyinganyactioncanbeuniquelydeterminedasinst0,andthuswedonotneedtosubdividetheprobabilityforanyreduceaction.Toillustratethis,letustakeanothersimpleexampleingrammarG2asgivenbelow,withallthepossiblederivationsshownintrees2.Further,theLRtableisshowninLR-table2.Letuscomputeagaintheprobabilityofeachtreeforthetwomodels:&amp;&amp;P_B&amp;C(tree(a))=mm+n1mm+n1=(mm+n)^2&amp;&amp;P_B&amp;C(tree(b))=nm+n1nm+n1=(nm+n)^2&amp;&amp;P_PGLR(tree(a))=mm+n111=mm+n&amp;&amp;P_PGLR(tree(b))=nm+n111=nm+neqnarrayInmodel,theprobabilityassignedtothereduceactioninstate3withthenextinputsymbolbeingissubdividedaccordingtowhetherthestateexposedbythepopoperationisstate1or2(seeLR-table2).Thismakestheprobabilityofeachtreesmallerthanwhatitshouldbe.Theaboveexamplesillustratethat,inmodel,theprobabilitiesofallthepossibleparsetreesmaynotnecessarilysumuptoone,duetothelackofprobabilisticallywell-foundednormalization,whichwouldbeinconsistentwiththedefinitionofP(T)(seeequationTset0).Inourmodel,ontheotherhand,theprobabilitiesofalltheparsetreesareguaranteedtoalwayssumtoone.ThisflawincanbeconsideredtoberelatedtoBriscoeandCarroll'sclaimthattheirmodeltendstofavorparsetreesinvolvingfewergrammarrules,almostregardlessofthetrainingdata.Inmodel,stacktransitionsequencesinvolvingmorereduceactionstendtobeassignedmuchlowerprobabilitiesforthetworeasonsmentionedabove:(a)theprobabilitiesassignedtoactionsfollowingreduceactionstendtobelowerthanwhattheyshouldbe,sincemodelrepredictsthenextinputsymbolsimmediatelyafterreduceactions,(b)theprobabilitiesassignedtoreduceactionstendtobelowerthanwhattheyshouldbe,sincetheyarefurthersubdividedaccordingtothestack-topstatesexposedbythestack-popoperations.Therefore,giventhefactthatstacktransitionsequencesinvolvingfewerreduceactionscorrespondtoparsetreesinvolvingfewergrammarrules,itistobeexpectedthattendstostronglypreferparsetreesinvolvingfewergrammarrules.Tosolvethisproblem,BriscoeandCarrollproposedcalculatingthegeometricmeanoftheprobabilitiesoftheactionsinvolvedineachstacktransitionsequence.However,thissolutionmakestheirmodelevenfurtherremovedfromaprobabilisticallywell-foundedmodel.Inourmodel,ontheotherhand,anybiastowardshorterderivationsisexpectedtobemuchweaker,andthuswedonotrequirethecalculationofthegeometricmean.Onemaywondertowhatextentthesedifferencesmatterforpracticalstatisticalparsing.Althoughthisissueneedstobeexploredthroughlarge-scaledempiricalevaluation,itmustbestillworthwhiletoconsidersomelikelycaseswherethedifferencediscussedherewillinfluenceparsingperformance.Wediscusssuchacasethroughafurtherexampleinthenextsection.</section>
  <section title="Expected Impact on Parsing Performance">Inthissection,wefirstdemonstratethroughanexamplehowmodelandourmodel,whichweclassasGLR-basedmodelshere,capturesrichercontextthanthePCFGmodel.Wethenreturntotheissueraisedattheendoftheprevioussection.SupposewehavegrammarG3asfollows:Further,letusassumethatwetrainthePCFGmodel,model,andourPGLRmodel,respectively,usingatrainingsetasshownintrees3,wheretrees(a)and(b)aretheparsetreesforinputsentenceW_1=,and(c)and(d)arethoseforW_2=.LR-table3showstheLRtableforgrammarG3,withthetrainedparameters.Accordingtothetrainingdataintrees3,wherethesquare-bracketedvaluebeloweachtreedenotesthenumberofoccurrencesofthattree,rightbranching(i.e.tree(a))ispreferredforinputsentenceW_1,whereasleftbranching(i.e.tree(d))ispreferredforinputsentenceW_2.ItiseasytoseethatthePCFGmodeldoesnotsuccessfullylearnthesepreferencesforeitherofthesentences,sincealltheparsetreesproducedforeachsentenceinvolvethesamesetofgrammarrules.UnlikethePCFGmodel,boththeGLR-basedmodelscanlearnthesepreferencesinthefollowingway.IntheLRparsingprocessforsentenceW_1,thepointwheretheparsermustchoosebetweenparsetrees(a)and(b)isinstate5,whichisreachedafterthereductionoftheleft-mostxintoS(seetrees3).Instate5,iftheshiftactionischosen,parsetree(a)isderived,while,ifthereduceactionischosen,(b)isderived.Thus,thepreferencefor(a)to(b)isreflectedinthedistributionovertheshift-reduceconflictinthisstate.LR-table3showsthatbothmodelandourmodelcorrectlyprefertheshiftactioninstate5withthenextinputsymbolbeing.ForinputsentenceW_2,ontheotherhand,theleftbranchingtree(d)ispreferred.Thispreferenceisalsoreflectedinthedistributionovertheshift-reduceconflictinthestatereachedafterthereductionoftheleft-mostxintoS,but,thistime,therelevantstateisstate6insteadofstate5.AccordingtoLR-table3,state6withthenextinputsymbolbeingxcorrectlyprefersthereduceaction,whichderivestheleft-branchingtree(d).Insum,thedifferentpreferencesforW_1andW_2arereflectedseparatelyinthedistributionsassignedtothedifferentstates(i.e.states5and6).Asillustratedinthisexample,foreachparsingchoicepoint,theLRparsestateassociatedwithitcanprovideacontextforspecifyingthepreferenceforthatparsechoice.ThisfeatureoftheGLR-basedmodelsenablesustotakerichercontextintoaccountthanthePCFGmodel.Furthermore,althoughnotexplicitlydemonstratedintheaboveexample,itshouldalsobenotedthattheGLR-basedmodelsaresensitivetothenextinputsymbolasshownina1inPGLR.Now,letusseehowtheprobabilitiesassignedtoLRparsingactionsarereflectedintheprobabilityofeachparsetree.result3showstheoveralldistributionsprovidedbythePCFGmodel,model,andourmodel,respectively,tothetreesintrees3,wedidnotapplythisoperationwhencomputingtheprobabilitiesinresult3,togivethereaderasenseofthedifferencebetweentheprobabilitiesgivenbyandourmodel.Notethat,inourexample,sincethenumberofstatetransitionsinvolvedineachparsetreeisalwaysthesameforanygivensentence,takingthegeometricmeanwouldnotchangethepreferenceorder..Accordingtothetable,ourmodelaccuratelylearnsthedistributionofthetrainingdata,whereasmodeldoesnotfitthetrainingdataverywell.Inparticular,forsentenceW_1,itgoesasfarasincorrectlypreferringparsetree(b).Thisoccursduetothelackofwell-foundednormalizationofprobabilitiesasdiscussedinBC-model.Asmentionedabove,modelcorrectlypreferstheshiftactioninstate5,asdoesourmodel.However,fortherestoftheparsingprocess,associatesaconsiderablyhigherprobabilitytotheprocessfromstate4through3and7to4,whichderivestree(b),thantheprocessfrom3through7and5to4,whichderivestree(a),since,intheirmodel,theformerprocessisinappropriatelysupportedbytheoccurrenceoftree(d).Forexample,inbothparsingprocessesfor(b)and(d),thepopoperationassociatedwiththereductioninstate3exposesstate4,andmodelthusassignsaninappropriatelyhighprobabilitytothisreduction,comparedtothereductioninstate3fortree(a).Ofcourse,asfarasvariousapproximationsaremadeinconstructingaprobabilisticmodelsimilartobothmodelandourmodel,itisalwaysthecasethatthemodelmaynotfitthetrainingdatapreciselyduetotheinsufficiencyofthemodel'scomplexity.Analogousto,ourmodeldoesnotalwaysfitthetrainingdatapreciselyduetotheindependenceassumptionssuchasequationsst-supset,l1,etc.However,itshouldbenotedthat,asillustratedbytheaboveexample,thereisalikelihoodthatmodelnotfittingthetrainingdataisduenotonlytotheinsufficiencyofcomplexity,butalsotothelackofwell-foundednormalization.</section>
  <section title="Conclusion">Inthispaper,wenewlypresentedaformalizationofprobabilisticLRparsing.Ourmodelinginheritssomeofitsfeaturesfrom.Namely,itcapturesderivationalcontexttoagreaterdegreethenthePCFGmodel,andnaturallyintegrateslocalbigramstatisticsofterminalsymbolsandglobalpreferenceoverstructuresofparsetrees.Furthermore,sincethemodelistightlycoupledwithGLRparsing,itcanbeeasilyimplementedandtrained.Inheritingtheseadvantages,ourformalizationadditionallyovercomesanimportantdrawbackof:thelackofwell-foundednormalizationofprobabilities.Wedemonstratedthroughexamplesthatthisrefinementisexpectedtoimproveparsingperformance.Thoseexamplesmayseemtoberelativelyartificialandforced.However,inourpreliminaryexperiments,weareachievingsomepromisingresults,whichsupportourclaim(see~forpreliminaryresults).Wearenowplanningtoconductfurtherlarge-scaledexperiments.ItshouldalsobenotedthatourmodelingisequallyapplicabletobothCLRtablesandLALRtables.SinceitisahighlyempiricalissuewhetheritisbettertouseCLR-basedmodelsorLALR-basedmodels,itmaybeinterestingtomakeexperimentalcomparisonsbetweenthesetwotypes(foraqualitativecomparison,see~).Otherapproachestocontext-sensitivestatisticalparsinghavealsobeenproposed,suchas.Weneedtomaketheoreticalandempiricalcomparisonsbetweenthesemodelsandours.Thesignificanceofintroducinglexicalsensitivityintolanguagemodelsshouldalsonotbeunderestimated.Infact,severalattemptstouselexicallysensitivemodelsalreadyexist:e.g.~.Ourfutureresearchwillalsobedirectedtowardsthisarea,theinitialfindingsofwhicharereportedin.</section>
</root>
