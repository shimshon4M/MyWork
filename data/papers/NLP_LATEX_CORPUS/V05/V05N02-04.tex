\documentstyle[epsf,jnlpbbl]{jnlp_j}

\def\Dder{}                            

\def\Ider{}              

\def\Nsum#1{}                      

\def\Bdma#1{}                

\def\Stri#1#2{} 

\def\Conc#1#2{}       

\def\argmax{}           

\def\argmin{}           

\def\hs{}

\def\therefore{}

\def\because{}


\def\MC#1#2#3{}

\setcounter{page}{75}
\setcounter{巻数}{5}
\setcounter{号数}{2}
\setcounter{年}{1998}
\setcounter{月}{4}
\受付{1997}{8}{1}
\再受付{1997}{9}{30}
\採録{1997}{10}{24}

\setcounter{secnumdepth}{2}
\begin{document}


\title{形態素クラスタリングによる形態素解析精度の向上}
\etitle{An Improvement of a Morphological Analysis \\ by a Morpheme Clustering}

\author{森 信介\affiref{KUEE} \and 長尾 眞\affiref{KUEE}}
\eauthor{Shinsuke Mori\affiref{KUEE} \and Makoto Nagao\affiref{KUEE}} 

\headauthor{森 信介・長尾 眞}
\headtitle{形態素クラスタリングによる形態素解析精度の向上}

\affilabel{KUEE}{京都大学工学研究科 電子通信工学専攻}
          {Department of Electrical Engineering, Kyoto University}



\jabstract{
  本論文では，形態素クラスタリングと未知語モデルの改良による確率的形態素解析器の精
  度向上を提案する．形態素クラスタリングとしては，形態素$n$-gramモデルをクロスエン
  トロピーを基準としてクラス$n$-gramモデルに改良する方法を提案する．未知語モデルの
  改良としては，確率モデルの枠組の中で学習コーパス以外の辞書などで与えられる形態素
  を追加する方法を提案する．bi-gramモデルを実装しEDRコーパスを用いて実験を行なった
  結果，形態素解析の精度の向上が観測された．両方の改良を行なったモデルによる形態素
  解析実験の結果の精度は，先行研究として報告されている品詞tri-gramモデルの精度を上
  回った．これは，我々のモデルが形態素解析の精度という点で優れていることを示す結果
  である．これらの実験に加えて，品詞体系と品詞間の接続表を文法の専門家が作成した形
  態素解析器との精度比較の実験を行なった．この結果，確率的形態素解析器の誤りは文法
  の専門家による形態素解析器の誤りに対して有意に少なかった．形態素解析における確率
  的な手法は，このような人間の言語直感に基づく形態素解析器と比較して，現時点で精度
  がより高いという長所に加えて，今後のさらなる改良にも組織的取り組みが可能であると
  いう点で有利である．
}

\eabstract{
  This paper proposes improving a stochastic Japanese morphological analyzer
  through a morpheme clustering and an amelioration of the unknown word model.  As
  a morpheme clustering, we propose a method which ameliorates a morpheme-based
  $n$-gram model into a class-based $n$-gram model with cross entropy criterion.
  As an amelioration of the unknown word model, we propose a method to incorporate
  a given morpheme set, such as dictionary, into it.  As the result of experiments
  on the EDR corpus, we observed improvements of the accuracy. The analyzer
  adopting both methods marked a higher accuracy than an anteriorly reported
  part-of-speech-based tri-gram model. This result tells us that our morphological
  analyzer is better than the previous one in terms of accuracy.  In addition to
  these experiments, we compared our analyzer with a grammarian's intuition-based
  analyser. The experimental results have shown the error rate of the stochastic
  analyzer was meaningfully smaller than that of the heuristic analyzer. The
  stochastic approach to Japanese morphological analysis is of great advantage to
  the ad-hoc method in higher accuracy, as well as in facility of further
  organized improvements.
}



\jkeywords{形態素解析，$n$-gramモデル，コーパス，クラスタリング，未知語}
\ekeywords{morphological analysis, $n$-gram model, corpus, clustering, unknown word}





\maketitle



\section{まえがき}

日本語には単語間に明示的な区切りがないので，入力文を単語に分割し，品詞を付加する形態
素解析は日本語処理における基本的な処理である．このような視点から，今日までに多くの形
態素解析器が人間の言語直観に基づき作成されている．一方，英語の品詞タグ付けではいくつ
かのコーパスに基づく方法が提案され，非常に高い精度を報告している
\cite{Grammatical.Category.Disambiguation.by.Statistical.Optimization,
A.Stochastic.Parts.Program.and.Noun.Phrase.Parser.for.Unrestricted.Text,
A.Simple.Rule-Based.Part.of.Speech.Tagger,
A.Practical.Part-of-Speech.Tagger,
Automatic.Stochastic.Tagging.of.Natural.Language.Texts,
Equations.for.Part-of-Speech.Tagging,
Parsing.the.LOB.corpus,
Coping.with.Ambiguity.and.Unknown.Words.through.Probabilistic.Models,
Tagging.English.Text.with.a.Probabilistic.Model,
Some.Advances.in.Transformation-Based.Part.of.Speech.Tagging,
Automatic.Stochastic.Tagging.of.Natural.Language.Texts,
Transformation-Based.Error-Driven.Learning.and.Natural.Language.Processing:.A.Case.Study.in.Part-of-Speech.Tagging,
Automatic.Ambiguity.Resolution.in.Natural.Language.Processing}．今日，多くの研究者が
，英語の品詞タグ付けに関してはコーパスに基づく手法が従来のヒューリスティックルールに
基づく手法より優れていると考えるに至っている．

日本語の形態素解析に対しては，コーパスに基づく手法が従来のルールに基づく手法より優れ
ていると考えるには至っていないようである．これは，コーパスに基づく形態素解析の研究に
は，ある程度の規模の形態素解析済みのコーパスが必要であり，日本語においてはこのような
コーパスが最近になってようやく簡単に入手可能になったことを考えると極めて自然である．
実際，コーパスに基づく形態素解析に関しては現在までのところ少数の報告がなされているの
みである
\cite{確率的形態素解析,
A.Stochastic.Japanese.Morphological.Analyzer.Using.a.Forward-DP.Backward-A*.N-Best.Search.Algorithm,
EDRコーパスを用いた確率的日本語形態素解析,
HMMによる日本語形態素解析システムのパラメータ学習}．これらの研究で用いられているモデ
ルはすべてマルコフモデル($n$-gramモデル)であり，状態に対応する単位という観点から以下
のように分けられる．
\begin{itemize}
\item 単語(列)が状態に対応する\cite{確率的形態素解析}．
\item 品詞(列)が状態に対応する
  \cite{A.Stochastic.Japanese.Morphological.Analyzer.Using.a.Forward-DP.Backward-A*.N-Best.Search.Algorithm,
  EDRコーパスを用いた確率的日本語形態素解析,
  HMMによる日本語形態素解析システムのパラメータ学習}
\end{itemize}
確率的言語モデルという観点からは，単語を単位とすることは過度の特殊化であり，品詞を単
位とすることは過度の一般化である．これらは，未知コーパスの予測力を低下させ，形態素解
析の精度を下げる原因になっていると考えられる．

我々は，この問題に対処するために，予測力を最大にするという観点よって算出したクラスと
呼ばれる単語のグループを一つの状態に対応させ，基礎となる確率言語モデルを改良し，結果
として形態素解析の精度を向上する方法を提案する．確率言語モデルとしてのクラス$n$-gram
モデルは，最適なクラス分類を求める方法(以下，クラスタリングと呼ぶ)とともに
すでに提案されている\cite{Class-Based.n-gram.Models.of.Natural.Language,
On.Structuring.Probabilistic.Dependences.in.Stochastic.Language.Modeling,
Improved.Clustering.Techniques.for.Class-Based.Statistical.Language.Modelling}．しか
し，これらの文献で報告されている実験では，クラスタリング結果を用いたクラス$n$-gramモ
デルの予測力は必ずしも向上していない．これらに対して，文献(提出中)では削除補間
\cite{Interpolated.estimation.of.Markov.source.parameters.from.sparse.data}を応用し
たクラスタリング規準とそれを用いたクラスタリングアルゴリズムを提案し，クラス$n$-gram
モデルの予測力が有意に向上したことを報告している．本論文では，この方法を応用すること
で得られるクラス$n$-gramモデルを基礎にした確率的形態素解析器による解析精度の向上につ
いて報告する．また，未知語モデルに確率モデルの条件を逸脱することなく外部辞書を追加す
る方法を提案し，この結果として得られる未知語モデルを備えた確率的形態素解析器による解
析精度の向上ついても報告する．さらに，上述の改良の両方を施した確率的形態素解析器と品
詞体系と品詞間の接続表を文法の専門家が作成した形態素解析器との解析精度の比較を行なっ
た結果について述べる．







\section{確率的形態素解析}

日本語に対する形態素解析とは，日本語の文(文字列)を入力とし，これを表記と品詞の直積と
して定義される形態素に分割する処理である．この節では，これを実現する手法の一つとして
の確率的形態素解析とその基礎となる確率言語モデルと解の探索方法について述べる．



\subsection{形態素解析の問題の定義}

日本語の形態素解析は，日本語のアルファベット${\cal X}$のクリーネ閉包に属する文
$\Bdma{x} \in {\cal X}^{*}$を入力として，これを表記${\cal W} = {\cal X}^{*}$と品詞
${\cal T}$の直積として定義される形態素${\cal M} = \{(w, t)|w \in {\cal W} \wedge t
\in {\cal T}\}$の列$\Bdma{m}$に分解して出力することと定義できる．このとき，出力される
形態素列の表記の連接は，入力のアルファベット列に等しくなければならない．つまり，入力
のアルファベット列(長さ$l$)を$\Bdma {x} = \Conc{x}{l}$とし，出力の形態素列(要素数$h$)
を$\Bdma{m}=\Conc{m} {h}$とすると以下の式が成り立つ必要がある．ただし，$w(m)$は形態素
$m$の表記を表し，$\Bdma{w}(\Bdma{m})$は形態素の連接$\Bdma{m}$の表記の連接を表わすもの
とする．
\begin{equation}
  \label{equation:condition}
  \Bdma{w}(\Bdma{m}) = w(m_{1}) w(m_{2}) \cdots w(m_{h}) = \Conc{x}{l} = \Bdma{x}
\end{equation}
一般に，これを満たす解は一意ではない．形態素解析の問題は，可能な解の中から人間の判断
(正解)に最も近いと推測される形態素列(単語分割と品詞割り当て)を選択し出力することであ
る．この選択の基準としては，文法の専門家が自身の言語直観を頼りにした規則に基づく方法
と大量の正解例(形態素解析済みコーパス)からの推定を規準にする方法がある．以下では，後
者の一つである確率的形態素解析について説明する．



\subsection{確率的形態素解析}

確率的形態素解析器は，品詞という概念を内包する確率的言語モデルを基にして，与えられた
文字列$\Bdma{x}$に対する確率最大の形態素列$\hat{\Bdma{m}}$を計算し出力する．これは，
以下の式で表される．
\begin{displaymath}
  \hat{\Bdma{m}} = \argmax_{\Bdma{w}(\Bdma{m}) = \Bdma{x}}P(\Bdma{m})
\end{displaymath}
この式の最後の$P(\Bdma{m})$が品詞という概念を内包する確率的言語モデルである．

このような確率的言語モデルには様々なものが考えられる．これらの良否の尺度としては，ク
ロスエントロピーが一般的である．これは，確率的言語モデルを$M$とし，テストコーパスを
${\cal S} = \{\Stri{s}{k}\}$とすると以下の式で与えられる\footnote{式の分母の$+1$は文
末記号に対応する．これは，$s_{x},s_{y}$と$s_{x}s_{y}$を区別するために必要である．}．
ただし，$|s|$は文$s$の長さ(文字数)を表わす．
\begin{displaymath}
  H(M,{\cal S}) = -\frac{\sum_{i=1}^{k}\log M(s_{i})}{\sum_{i=1}^{k}(|s_{i}|+1)}
\end{displaymath}
この値は，コーパス${\cal S}$をモデル$M$で符合化した時の文字あたりの平均符合長の下限
であり，${\cal S}$として無作為に抽出された十分多数の文を選択すれば，複数のモデルの良
否を比較するための尺度となる．定義から明らかなように，この値がより小さいほうがより良
い言語モデルである．クロスエントロピーの意味で良い言語モデルを用いる方が形態素解析の
精度が良いと考えられる．


\subsubsection{形態素$n$-gramモデル} 

確率的言語モデル$P(\Bdma{m})$は，形態素を一つずつ予測することを仮定すると，以下のよ
うに書き換えられる．
\begin{eqnarray}
  \label{eqnarray:P(m)}
  P(\Bdma{m}) & = & P(\Conc{m}{h+1}) \nonumber \\
              & = & \prod_{i=1}^{h+1}P(m_{i}|\Conc{m}{i-1})
\end{eqnarray}
ここで$m_{h+1}$は，文末に対応する特別な記号である．これを導入することによって，すべ
ての可能な形態素列に対する確率の和が1となることが保証される
\cite{Syntactic.Methods.in.Pattern.Recognition}．

式(\ref{eqnarray:P(m)})は，ある時点$i$での形態素$m_{i}$の出現確率は最初の時点から時
点$i-1$までの全ての形態素に依存することを表しているが，実装の簡便さなどを考慮して，
時点$i-k$から時点$i-1$までの連続する$k$個の形態素の履歴にのみ依存する$k$重マルコフ過
程であると仮定する．この仮定は，以下の式で表される近似である．
\begin{eqnarray*}
  P(m_{i}|\Conc{m}{i-1}) & \approx & P(m_{i}|m_{i-k}m_{i-k+1} \cdots m_{i-1})
\end{eqnarray*}
ここで$m_{j}\;(j \leq 0)$は，文頭に対応する特別な記号である．これを導入することによ
って式が簡便になる．

一般に，確率$P(m_{i}|m_{i-k}m_{i-k+1} \cdots m_{i-1})$の値はコーパスから最尤推定する
ことで得られる．これは，$N(\Bdma{m})$を形態素列$\Bdma{m}$のコーパスにおける頻度とし
て，以下の式で与えられる．
\begin{eqnarray*}
  P(m_{i}|m_{i-k}m_{i-k+1} \cdots m_{i-1}) & = &
  \frac{N(m_{i-k}m_{i-k+1} \cdots m_{i})}{N(m_{i-k}m_{i-k+1} \cdots m_{i-1})} \\
  & = & \frac{N(m_{i-k}m_{i-k+1} \cdots m_{i})}{\sum_{m}N(m_{i-k}m_{i-k+1} \cdots m_{i-1}m)}
\end{eqnarray*}
このように，このモデルは連続する$n=k+1$個の形態素列の頻度に基づいているので，形態素
$n$-gramモデルと呼ばれる．

形態素$n$-gramモデルにおいて場合に問題となるのは，状態に対応する形態素(既知形態素)の
選択である．一般的には，頻度の高い形態素を既知形態素とすることで高い予測力が実現でき
る．しかし，どのような形態素の集合を選択したとしても，テストコーパスに出現する可能性
のあるすべての形態素が既知形態素であることは望めない．このため，未知形態素の扱いが避
けられない問題となる．この問題に対処するため，未知形態素に対応する特別な記号を用意し
，既知の形態素以外はこの記号から次節で述べる未知語モデルにより与えられる確率で生成さ
れることとする．未知形態素に対応する特別な記号は，かならずしも唯一である必要はなく，
品詞などの情報を用いて区別される複数の記号であっても良い．我々の目的は形態素解析であ
るから未知形態素であっても品詞の推定が可能でなければならない．よって，各品詞に対して
未知形態素に対応する記号を設ける．

以上に述べた形態素$n$-gramモデル$M_{m}$による，形態素列の出現確率は以下の式で表される
．ただし${\cal M}_{in}$は既知形態素の集合を表わし，$t$は$m_{i}$の品詞を表わす．また，
${\tt UM}_{t}$は品詞$t$に属する未知形態素に対応する特別な記号である．
\begin{equation}
  \label{equation:morph_n-gram1}
  M_{m}(\Conc{m}{h}) = \prod_{i=1}^{h+1} P_{m}(m_{i}|m_{i-k} \cdots m_{i-2}m_{i-1})
\end{equation}
\begin{eqnarray}
  \label{equation:morph_n-gram2}
  \lefteqn{P_{m}(m_{i}|m_{i-k} \cdots m_{i-2}m_{i-1})} \nonumber \\
  & = & \left\{\begin{array}{lccl}
          P(m_{i}|m_{i-k} \cdots m_{i-2}m_{i-1})
            & & \mbox{if} & m_{i} \in {\cal M}_{in} \\
          P({\tt UM}_{t}|m_{i-k} \cdots m_{i-2}m_{i-1})M_{x,t}(m_{i})
            & & \mbox{if} & m_{i} \not \in {\cal M}_{in} \\
        \end{array}\right.
\end{eqnarray}
この式の中の$M_{x,t}$は，次項で述べる未知語モデルであり，品詞が$t$であることを条件と
して，引数で与えられる文字列の生成確率を値とする．

確率値の最尤推定においては，まず既知形態素集合を定義し，学習コーパスの未知形態素を未
知形態素に対応する特別な記号に置き換えて頻度を計数する．


\subsubsection{未知語モデル} 

未知語モデルは，表記から確率値への写像として定義され，既知形態素以外のあらゆる形態素
の表記を0より大きい確率で生成し，この確率をすべての表記に渡って合計すると1以下になる
必要がある．このような条件を満たすモデルの一つとして，文字$n$-gramモデルがある．日本
語の表記に用いられる文字は有限と考えられるので，形態素$n$-gramモデルのときの未知形態
素のような問題は起こらない．しかし，形態素$n$-gramモデルの場合と同様に，文字を既知文
字と未知文字に分類し，未知文字はこれを表わす特別な記号から生成されるものとすることも
できる．文字の使用頻度には大きな偏りがあることが予測されるので，これらを一つのグルー
プとみなすことで，モデルが改善されると考えられる．文字集合は有限であるから，未知形態
素モデルの場合と異なり，各未知文字の生成確率を等確率とすることができる．このようにし
て構成される未知語モデルは以下の式で表わされる．ただし${\cal X}_{in,t}$は品詞が$t$で
ある未知語モデルの既知文字の集合を表わし，${\tt UX}_{t}$は品詞$t$の未知語モデルの未知
文字に対応する特別な記号である．また，$w(m) = \Conc{x}{h}$としている．
\begin{eqnarray}
  \label{equation:ukwmodel0}
  M_{x,t}(w(m)) & = & M_{x,t}(\Conc{x}{h}) \\
  \label{equation:ukwmodel1}
                  & = & \prod_{i=1}^{h+1} P_{x,t}(x_{i}|x_{i-k} \cdots x_{i-2}x_{i-1})
\end{eqnarray}
\begin{eqnarray}
  \label{equation:ukwmodel2}
  \lefteqn{P_{x,t}(x_{i}|x_{i-k} \cdots x_{i-2}x_{i-1})} \nonumber \\
  & = & \left\{\begin{array}{lccl}
          P(x_{i}|x_{i-k} \cdots x_{i-2}x_{i-1})
            & & \mbox{if} & x_{i} \in {\cal X}_{in,t} \\
          P({\tt UX}_{t}|x_{i-k} \cdots x_{i-2}x_{i-1})\frac{1}{|{\cal X}-{\cal X}_{in,t}|}
            & & \mbox{if} & x_{i} \not \in {\cal X}_{in,t} \\
        \end{array}\right.
\end{eqnarray}
この式の中の$x_{j}\;(j \leq 0)$は，語頭に対応する便宜的な記号である．また，$x_{h+1}$
は，語末に対応する特別な記号であり，形態素に対するモデルの場合と同様に，すべての可能
な文字列に対する確率の和が1となるために導入されている．

以上で説明した未知語モデルは，未知文字を等確率で生成するモジュールを「未知文字モデル
」と考えると，形態素$n$-gramモデルと相似の構造である．文字$n$-gramモデルの確率値は，
形態素$n$-gramモデルの場合と同様に，既知文字を定義した後，未知形態素の実例における文
字列の頻度から推定される．


\subsubsection{低頻度事象への対処} 

上述したように，形態素$n$-gramモデルのパラメータ推定には，出現頻度を基にした最尤推定
が用いられる．しかし，対象とする事象の頻度が低い場合には，推定値の信頼性は低くなると
いう問題がある．この問題に対処する方法として，補間と呼ばれる方法が用いられる
\cite{Principles.of.Lexical.Language.Modeling.for.Speech.Recognition}．これは，次の
式で表されるように，より信頼性が高いことが期待される，より低次のマルコフモデルの遷移
確率を一定の割合で足し合わせるという操作を施すことを言う．
\begin{equation}
  \label{equation:m-inter}
  P'(m_{i}|m_{i-k}m_{i-k+1} \cdots m_{i-1})
  = \sum_{j=0}^{k}\lambda_{j}P(m_{i}|m_{i-j}m_{i-j+1} \cdots m_{i-1})
\end{equation}
\begin{displaymath}
  ただし \; 0 \leq \lambda_{j} \leq 1, \; \sum_{j=0}^{k}\lambda_{j} = 1
\end{displaymath}
係数$\lambda$の値は，確率値$P$の推定に用いられるコーパスとは別に用意された比較的小さ
いコーパスを用いて最尤推定される．この方法では，確率値の推定に用いることができるコー
パスの大きさが小さくなり，推定値の信頼性が少しではあるが低下するという問題がある．こ
れに対処する方法として削除補間
\cite{Interpolated.estimation.of.Markov.source.parameters.from.sparse.data}と呼ばれ
る方法がある．これは，パラメータ推定のためのコーパスを$k$個に分割し，$k-1$個の部分で
確率値を推定し，残りの部分で補間の係数を推定するということを全ての組合せ($k$通り)に
渡って行ない，その平均値をとるという方法である．


\subsubsection{解の探索アルゴリズム} 

形態素$n$-gramモデルによる形態素解析器は，入力として文字列$\Bdma{x}$を受けとり，式
(\ref{equation:morph_n-gram1})(\ref{equation:morph_n-gram2})
(\ref{equation:ukwmodel1})(\ref{equation:ukwmodel2})(\ref{equation:m-inter})を用いて
計算される確率が最大の形態素列$\hat{\Bdma{m}}$を式(\ref{equation:condition})で表わさ
れる条件の下で計算し出力する．解の探索には動的計画法を用いることができ，入力の文字数
$n$に対して計算時間のオーダーが$O(n)$となるアルゴリズムが提案されている
\cite{The.Use.of.One-Stage.Dynamic.Programming.Algorithm.for.Connected.Word.Recognition}
\cite{A.Stochastic.Japanese.Morphological.Analyzer.Using.a.Forward-DP.Backward-A*.N-Best.Search.Algorithm}
．









\section{未知語モデルの改良}

この章では，確率的形態素解析の精度を向上させる方法として，未知語モデルに外部辞書を付
加する方法を提案する．これは，確率的言語モデルの予測力を改善する方法であり，確率的形
態素解析の精度向上を直接の目的としているわけではないが，確率的言語モデルの予測力の改
善は，結果としてそれに基づく確率的形態素解析器の解析精度を向上させる．また，予測力の
高い未知語モデルを推定するための未知形態素の実例の収集方法についても述べる．



\subsection{外部辞書の付加}

前章で述べた未知語モデル$M_{x,t}$は，未知形態素だけでなく既知形態素の表記も0より大き
い確率で生成する可能性がある．この場合には，以下の式が示すように，未知形態素の生成確
率の合計は1未満となる．以下の説明では品詞$t$を省略してある．また，形態素の集合を表わ
す記号${\cal M}_{in}$をその表記の集合を表わすとしている．
\begin{eqnarray*}
  &                 &
      \sum_{m \in {\cal X}^{*}-{\cal M}_{in}} M_{x}(m) + \sum_{m \in {\cal M}_{in}}
                                  M_{x}(m) = \sum_{m \in {\cal X}^{*}} M_{x}(m) = 1 \\
  & \Leftrightarrow &
      \sum_{m \in {\cal X}^{*}-{\cal M}_{in}} M_{x}(m)
                                         = 1 - \sum_{m \in {\cal M}_{in}} M_{x}(m) < 1
                        \;\;\; (\because M_{x}(m) > 0, \; \exists m \in {\cal M}_{in})
\end{eqnarray*}
これは，言語モデルとしての条件を満たしてはいるが，クロスエントロピーという点で改善の余
地がある．つまり，既知形態素の生成確率を何らかの方法で未知形態素に分配することで，未知
形態素の生成確率が大きくなり，テストコーパスにそのような未知形態素が出現した場合に，テ
ストコーパスの出現確率が大きくなる．

既知形態素の生成確率の分配には，様々な方法が考えられるが，以下の式が表すように，すべ
ての未知形態素にその生成確率に比例して分配する方法が一般的であろう．
\begin{eqnarray}
  \label{equation:ukwmodel3}
  \lefteqn{M_{x}^{\prime}(\Conc{x}{h})} \nonumber \\
  & = & \left\{\begin{array}{lccl}
        0 & & \mbox{if} & m \in {\cal M}_{in} \\
        \frac{1}{1-\sum_{m \in {\cal M}_{in}}M_{x}(m)}M_{x}(\Conc{x}{h})
          & & \mbox{if} & m \not\in {\cal M}_{in} \\
        \end{array}\right.
\end{eqnarray}

これに対して我々は，辞書の見出し語などとして与えられる形態素の部分集合に等しく配分す
ることを提案する．つまり，ある形態素の集合が与えられたとして，ここから既知形態素を除
いた集合を${\cal M}_{ex}$ (${\cal M}_{ex}\cap{\cal M}_{in}=\phi$)として，この要素の
生成確率を文字$n$-gramモデルによる確率と既知形態素の生成確率の合計を${\cal M}_{ex}$
の要素数で割った値の和とする．
\begin{equation}
  \label{equation:ukwmodel4}
  M_{x}^{\prime}(m)
  = M_{x}(m)+\frac{1}{|{\cal M}_{ex}|}\sum_{m \in {\cal M}_{k}}M_{x}(m)
  \;\;\; (m \in {\cal M}_{ex})
\end{equation}
これは，既知形態素の生成確率を，学習コーパスには現れないが辞書などから形態素であると
考えられる文字列に優先的に分配し，それらの生成確率を相対的に高くすることを意味する．
このような文字列の集合を外部辞書と呼ぶ．形態素解析が目的なので，外部辞書には文字列の
ほかにその品詞が記述されている必要がある．この方法により，確率言語モデルの枠内で，コ
ーパスから推定された確率言語モデルに辞書などの異なる情報源の情報を付加できる．

以上に述べた外部辞書を備えた未知語モデル$M_{x}^{\prime}$による文字列$m =\Conc{x}{h}$
の出現確率は以下の式で表される．
\begin{eqnarray*}
  \lefteqn{M_{x}^{\prime}(\Conc{x}{h})} \\
  & = & \left\{\begin{array}{lccl}
        0 
          & & \mbox{if} & m \in {\cal M}_{in} \\
        M_{x}(\Conc{x}{h})+\frac{1}{|{\cal M}_{ex}|}\sum_{m \in {\cal M}_{in}}M_{x}(m)
          & & \mbox{if} & m \in {\cal M}_{ex} \\
        M_{x}(\Conc{x}{h})
          & & \mbox{if} & m \not\in {\cal M}_{in} \wedge m \not\in {\cal M}_{ex} \\
        \end{array}\right.
\end{eqnarray*}
これを式(\ref{equation:ukwmodel0})の代わりに用いる未知語モデルを外部辞書を備えた未知
語モデルと呼ぶ．



\subsection{未知形態素の実例の収集方法}

文字$n$-gramモデルの確率値は，形態素$n$-gramモデルの場合と同様に，アルファベットを定
義してから，未知形態素の実例における文字列の頻度から推定される．未知形態素の実例の収
集の方法としては，学習コーパスに含まれるすべての形態素とすることや，学習コーパスにお
ける頻度が1である形態素とする\cite{単語頻度の期待値に基づく未知語の自動収集}などが考
えられる．我々は，削除補間法を応用した以下の方法を提案する．
\begin{quote}
  学習コーパスを$k$個の部分コーパスに分割し，$i$番目の部分コーパスの未知形態素の実例
  を，$i$番目の部分コーパス以外を学習コーパスとし$i$番目の部分コーパスをテストコーパ
  スと見た場合の未知形態素とする．
\end{quote}
我々が提案する方法は，削除補間法を応用して，実際のテストコーパスにおける未知形態素と
類似した実例を得ているので，他の方法よりも優れていると予測される．実際に，予備実験と
してこれらの方法を実装し，予測力という規準で比較した．その結果，我々が提案する方法が
最良であった．したがって，実験にはこの方法を用いた．







\section{形態素クラスタリング}

この章では，形態素$n$-gramモデルの一般化の一つであるクラス$n$-gramモデルを説明し，文
献(提出中)を応用して形態素解析のためのクラスを自動的に学習する方法を提案する．前章と
同様に，確率的言語モデルの予測力の改善を目的としているが，学習されたクラス$n$-gramモ
デルに基づく確率的形態素解析器の解析精度は，形態素$n$-gramモデルや人間の言語直観によ
る品詞をクラスとした場合の品詞$n$-gramモデルに基づく確率的形態素解析器の解析精度より
高くなると考えられる．



\subsection{クラス$n$-gramモデル}

クラス$n$-gramモデル\cite{Class-Based.n-gram.Models.of.Natural.Language}では，あらか
じめ形態素をクラスと呼ばれるグループに分類しておき，先行するクラスの列を直前の事象と
みなして分類する．このモデルでは，次の形態素を直接予測するのではなく，次のクラスを予
測した上で次の形態素を予測する．以下の式で，${\cal C}_{in}$は既知形態素に対応するク
ラスであり，これを品詞とすれば，品詞$n$-gramモデルとなる．
\begin{equation}
  \label{equation:class_n-gram1}
  P(\Bdma{m}) = \prod_{i=1}^{h+1}P_{c}(m_{i}|c_{i-k}c_{i-k+1}\cdots c_{i-1})
\end{equation}
\begin{eqnarray}
  \label{equation:class_n-gram2}
  \lefteqn{P_{c}(m_{i}|c_{i-k} \cdots c_{i-2}c_{i-1})} \nonumber \\
  & = & \left\{\begin{array}{lccl}
          P(c_{i}|c_{i-k} \cdots c_{i-2}c_{i-1})P(m_{i}|c_{i})
            & & \mbox{if} & \exists c_{i} \in {\cal C}_{in},\; m_{i} \in c_{i} \\
          P({\tt UM}_{t}|c_{i-k} \cdots c_{i-2}c_{i-1})M_{x,t}(m_{i})
            & & \mbox{if} & \forall c_{i} \in {\cal C}_{in},\; m_{i} \not \in c_{i} \\
        \end{array}\right.
\end{eqnarray}
この式の中の$c_{j}\;(j \leq 0)$は，文頭に対応する特別な記号である．これを導入するこ
とによって式が簡便になる．また，$c_{h+1}$は，語末に対応する特別な記号であり，これを
導入することによって，すべての可能な文字列に対する確率の和が1となる
\cite{Syntactic.Methods.in.Pattern.Recognition}．

形態素に基づくモデルの場合と同様に，確率$P(c_{i}|c_{i-k}c_{i-k+1} \cdots c_{i-1})$の
値および，確率$P(m_{i}|c_{i})$の値は，コーパスから最尤推定することで得られる．
\begin{eqnarray*}
  P(c_{i}|c_{i-k}c_{i-k+1} \cdots c_{i-1}) & = &
        \frac{N(c_{i-k}c_{i-k+1} \cdots c_{i})}{N(c_{i-k}c_{i-k+1} \cdots c_{i-1})} \\
                            P(m_{i}|c_{i}) & = & \frac{N(m_{i},c_{i})}{N(c_{i})}
\end{eqnarray*}
この式において，クラスを品詞とすれば品詞$n$-gramモデルが得られ，形態素からクラスへの
写像が全単射であれば，形態素$n$-gramモデルと等価になることが分かる．また，これをマル
コフモデルと考えると，状態はクラスに対応する．

形態素$n$-gramモデルと同様に，データスパースネスの問題に対処する方法として，補間を用
いることができる\cite{Class-Based.n-gram.Models.of.Natural.Language}．これは，以下の
ように式(\ref{equation:m-inter})において形態素$m$をクラス$c$と読み変えれることで容易
に得られる．
\begin{equation}
  \label{equation:c-inter}
  P'(c_{i}|c_{i-k}c_{i-k+1} \cdots c_{i-1})
  = \sum_{j=0}^{k}\lambda_{j}P(c_{i}|c_{i-j}c_{i-j+1} \cdots c_{i-1})
\end{equation}
\begin{displaymath}
  ただし \; 0 \leq \lambda_{j} \leq 1, \; \sum_{j=0}^{k}\lambda_{j} = 1
\end{displaymath}



\subsection{形態素クラスタリング}

確率言語モデルの形態素クラスタリングの課題は，クロスエントロピーが最も低くなる形態素
とクラス(図\ref{figure:concept}の中の$c_{1},c_{2},\cdots,c_{x}$)の対応関係を算出する
ことである．このようなクラスを用いて構築されたクラス$n$-gramモデルに基づく確率的形態
素解析器の解析精度は，品詞$n$-gramモデルや形態素$n$-gramモデルに基づく確率的形態素解
析器の解析精度よりも高くなることが期待される．従って，形態素クラスタリングの目的関数
は，削除補間を応用することでクロスエントロピーを模擬すると考えられる以下のような値と
した．
\begin{equation}
  \label{equation:criterion}
  \overline{H} = \frac{1}{k}\sum_{i=1}^{k} H(M_{i},{\cal S}_{i})
\end{equation}
ここで，$M_{i}$は$i$番目以外の$k-1$の部分コーパスから推定された確率言語モデルであり
，${\cal S}_{i}$は$i$番目の部分コーパス(文の列)を表す．ここで問題としているのは，確
率的言語モデルとしてクラス$n$-gramモデルを用いた場合の形態素のクラスタリングである．
この場合，コーパスは一定であり，確率的言語モデル$M$は形態素とクラスの関係$F$にのみ依
存する．従って，上式の平均クロスエントロピーは，形態素とクラスの関係の関数とみなすこ
とができる．この値がより小さいほうが，未知のコーパスに対してより良い言語モデルである
ことが予測される．よって，クラスタリングの目的は，式(\ref{equation:criterion})で定義
される平均クロスエントロピーを最小化する形態素とクラスの関係を求めることである．

\input{figure:concept.tex}

形態素とクラスの対応関係としては，ある形態素が一定の確率で複数のクラスに属するという
確率的な関係も考えられるが，解空間が広大になるので，本研究では形態素は唯一のクラスに
属することを仮定した．よって，クラスの集合は形態素の集合の直和分割となる．形態素とク
ラスの対応関係$F$は，${\cal M},{\cal C}$をそれぞれ形態素の集合とクラスの集合とすると
，関数$f : {\cal M} \mapsto {\cal C} \;(= 2^{\cal M})$を用いて表すことができ，この関
数は以下の条件を満たす\footnote{$f$の値は形態素の集合である(例: $f(m_{1}) = \{m_{1},
m_ {2}, m_{3}\}$)．}．
\begin{displaymath}
  M = \bigcup_{m \in M} f(m)  
\end{displaymath}
\begin{displaymath}
  \forall m \in M \; に対し \; m \in f(m)
\end{displaymath}
\begin{displaymath}
  f(m_{1}) \not = f(m_{2}) \Rightarrow f(m_{1}) \cap f(m_{2}) = \phi  
\end{displaymath}
解探索のアルゴリズム中で用いるために，形態素とクラスの対応関係に対して，以下の関数を
定義する．
\begin{itemize}
\item $move : F \times M \times C \mapsto F$ \\
  $move(f,m,c)$は，形態素とクラスの関係$f$に対して形態素$m$をクラス$c$に移動した結果
  得られる形態素とクラスの関係を返す．
\end{itemize}

クラスタリングの解空間はあらゆる可能な形態素とクラスの対応関係である．しかし，この数
はある程度の大きさの語彙数に対しては非常に大きいため，これら全てに対して平均クロスエ
ントロピーを計算し，これを最小化するクラス関係を選択するということは，計算量という観
点から不可能である．平均クロスエントロピーの値はクラス関係の一部分の変更が全体に影響
するという性質をもっているので，分割統治法や動的計画法を用いることもできない．以上の
ことから，我々は最適解を求めることを諦め，貪欲アルゴリズムを用いることにした．このア
ルゴリズムは以下の通りである(図\ref{figure:clustering}参照)．なお，$\overline{H}$は
式(\ref{equation:criterion})で与えられる平均クロスエントロピーでり，$t(m)$や$t(c)$は
形態素$m$やクラス$c$の品詞を表わす．同一の品詞である形態素に対してのみ併合を試みるの
で，結果としてどのクラスも同一の品詞の形態素のみを要素に持つことに注意しなければなら
ない．
\begin{center}
  \begin{tabular}{|l|}
    \hline $M$を頻度の降順に並べ$\Stri{m}{n}$ とする \\
    {\bf foreach} $i$ ($1, 2, \cdots, n$) \\
    \hs $c_{i} := \{m_{i}\}$ \\
    \hs $f(m_{i}) := c_{i}$ \\
    {\bf foreach} $i$ ($2, 3, \cdots, n$) \\
    \hs $c := \argmin_{c \in \{t(c) = t(m_{i})|\;\Stri{c}{i-1}\}}\overline{H}(move(f, m_{i}, c))$ \\
    \hs {\bf if} ($\overline{H}(move(f, m_{i}, c)) < \overline{H}(f)$) {\bf then} \\
    \hs\hs $f := move(f, m_{i}, c)$ \\
    \hline
  \end{tabular}
\end{center}

\input{figure:clustering}

計算量は，二番目の{\bf foreach}での繰り返しの回数は単語数$|W|$に比例し，{\bf argmin}
での繰り返しの回数はクラス数$|C|$に比例するので，全体で$O(|W|\cdot|C|)$である．クラ 
ス数$|C|$は，全ての単語が独立したクラスに分けられる場合に最大($|C|=|W|$)となり，全て 
の単語が同一のクラスとなる場合に最小($|C|=1$)となる．従って，初期化における全体の計 
算量は，最良の場合が$O(|W|)$であり，最悪の場合が$O(|W|^{2})$である．ただし，単語の並 
べ替えや一番目の{\bf foreach}の計算量は係数が非常に小さいと考えられるので，考慮に入 
れていない．次節で述べる実験の結果では，頻度の高い形態素を対象とする段階では多くの形
態素がクラスに併合されずクラス数は形態素数に比例し最悪の場合に近い挙動を示したが，頻
度の低い形態素を対象とする段階ではほとんどの形態素がクラスに併合されてクラス数はほと
んど一定となり最良の場合に近い挙動を示した．頻度の低い形態素が多数を占めるので，計算
量は実際にはかなり線形に近いと考えられる．

頻度の高い形態素から移動を試みることとしているのは，頻度の高い形態素の移動のほうがパ
ープレキシティに与える影響が大きいと考えられるので，早い段階での移動が後の移動によっ
て影響されにくく，収束がより速くなると考えたためである．

上述のアルゴリズムによって得られたクラス分類からさらに探索を進めてより良いクラス分類
が得られるかを試みることができる．このアルゴリズムとして，さらに形態素の移動を試みる
こと\cite{On.Structuring.Probabilistic.Dependences.in.Stochastic.Language.Modeling}
やクラスの併合を試みること\cite{Class-Based.n-gram.Models.of.Natural.Language}が考え
られる．我々は，これらのアルゴリズムを小さなコーパスに対する予備実験で適用してみたが
，必要となる計算時間が膨大である割にはクロスエントロピーの改善が小さかった．よって，
次章では，上述のアルゴリズムによる実験結果について述べる．







\section{実験結果とその評価}

前節で述べた方法の有効性を確かめるため，以下の点を明らかにするための実験を行った．
\begin{enumerate}
\item 外部辞書による解析精度の向上
\item 形態素クラスタリングによる解析精度の向上
\end{enumerate}
以下では，まず形態素解析精度の評価基準について述べ，実験の条件を明確にし，上述の実験
の結果を提示し評価する．また，文法の専門家による形態素解析器との解析精度の比較を行な
った結果について述べる．なお以下では，「クラス$n$-gramモデル」などの言語モデルを表す
表現を，文脈から明らかな場合には，その言語モデルに基づく形態素解析器を表すためにも用
いる．



\subsection{評価基準}

我々が用いた評価基準は，\cite{EDRコーパスを用いた確率的日本語形態素解析}で用いられた
再現率と適合率であり，次のように定義される．EDRコーパスに含まれる形態素数を$N_{EDR}$，
解析結果に含まれる形態素数を$N_{SYS}$，分割と品詞の両方が一致した形態素数を$N_{COR}$
とすると，再現率は$N_{COR}/N_{EDR}$と定義され，適合率は$N_{COR}/N_{SYS}$と定義される．
例として，コーパスの内容と解析結果が以下のような場合を考える．
\begin{description}
\item[コーパス] \ \\
  \begin{tabular}{l}
    外交(名詞) \ 政策(名詞) \ で(助動詞) \ は(助詞) \ な(形容詞) \ い(形容詞語尾)
  \end{tabular}
\item[解析結果] \ \\
  \begin{tabular}{l}
    外交政策(名詞) \ で(助詞) \ は(助詞) \ な(形容詞) \ い(形容詞語尾)
  \end{tabular}
\end{description}
この場合，分割と品詞の両方が一致した形態素は「は(助詞)」と「な(形容詞)」と「い(形容詞
語尾)」であるので，$N_{COR}= 3$となる．また，コーパスには6つの形態素が含まれ，解析結
果には5つの形態素が含まれているので，$N_ {EDR}=6,\,N_{SYS}=5$である．よって，再現率は
$N_{COR}/N_{EDR}=3/6$となり，適合率は$N_{COR}/N_{SYS}= 3/5$となる．



\subsection{実験の条件}

実験にはEDRコーパス\cite{EDR.電子化辞書仕様説明書}を用いた．まず，これを10個に分割し
，この内の9個を学習コーパスとし，残りの1個をテストコーパスとした．前章で述べたように
，クラス関数の推定では，この9個の学習コーパスのうちの8つから$n$-gramモデルを推定し，
残りの1つのコーパスに対してクロスエントロピーを求めるということを9通り行なって得られ
る平均クロスエントロピーを評価規準とする．それぞれのコーパスに含まれる文と形態素と文
字の数(のべ)は表\ref{table:corpus}の通りである．既知形態素は，2個以上の学習コーパス
に現れる59,956個の形態素とした．形態素bi-gramモデルは，これらに対応する状態の他に，
各品詞の未知語に対応する状態(15個)と文区切り(文末と文頭)に対応する状態を持つ．同様に
，クラスbi-gramモデルは，既知形態素をクラスタリングすることで得られるクラスに対応す
る状態と，各品詞の未知語に対応する状態と文区切りに対応する状態を持つ．

\input{table:corpus.tex}

形態素bi-gramモデルとクラスbi-gramモデルを比較するために，これらを同じ学習コーパスか
ら構成し，同じテストコーパスに対してパープレキシティや形態素解析の精度を計算した．そ
れぞれの言語モデルの構成の手順は以下の通りである．
\begin{itemize}
\item 形態素bi-gramモデル
  \begin{enumerate}
  \item 削除補間により式(\ref{equation:m-inter})の補間の係数を推定
  \item すべての学習コーパスを対象に形態素bi-gramと形態素uni-gramを計数
  \end{enumerate}
\item クラスbi-gramモデル
  \begin{enumerate}
  \item 削除補間により式(\ref{equation:m-inter})の補間の係数を推定
  \item 前章で述べた方法($k=9$)でクラス関数を推定
  \item 削除補間により式(\ref{equation:c-inter})の補間の係数を推定
  \item すべての学習コーパスを対象にクラスbi-gramとクラスuni-gramを計数
  \end{enumerate}
\end{itemize}
未知語モデルは共通であり，各品詞(15個)に対して形態素bi-gramモデルと同様の手順で構成
される．本実験では行なっていないが，文字に対するクラスタリングを行ない，これをクラス
bi-gramモデルとすることも可能である．外部辞書の形態素集合は，EDR日本語単語辞書
\cite{EDR.電子化辞書仕様説明書}の見出し語から既知形態素を除いた形態素集合と学習コー
パスには出現するが既知形態素とならなかった形態素集合(分割された学習コーパスの1個にの
み現れた形態素)の和集合とした．

\input{table:cluster.tex}

品詞毎の形態素数とクラスタリングの結果得られたクラスの数を表\ref{table:cluster}に掲
げた．平均要素数は，形態素数をクラス数で割った値である．この値は，内容語において高く
，機能語において低いことが観測される．このことから，品詞$n$-gramモデルにおいては機能
語を一般化し過ぎており，形態素$n$-gramモデルにおいては内容語を特殊化し過ぎているとい
うことが分かる．

なお，対象となる59,956の形態素をクラスタリングするのに要した時間は，SPARC Station
20 (150MHz)で約4日であった．



\subsection{外部辞書と形態素クラスタリングによる精度向上の評価}

図\ref{figure:result}は，形態素クラスタリングの結果を用いたクラスbi-gramモデルの，外
部辞書を持つ場合と持たない場合の，クロスエントロピーと形態素解析の精度である．このグ
ラフから次のようなことが分かる．まず，学習コーパスの大きさと解析精度の関係であるが，
解析精度は，コーパスの大きさに対して単調に増加している．しかし，コーパスがある程度大
きくなるとこの増加量は小さくなっている．このことは，さらなる精度向上を達成するために
は，学習コーパスを増やすという単純な方法は，コーパスの作成コストを考えると，得策では
ないということを意味する．次に，外部辞書を付加することによる解析精度の向上であるが，
クロスエントロピーの減少から予測される通り，外部辞書を付加することにより解析精度が向
上した．グラフから分かるように，学習コーパスの大きさが小さい方が，外部辞書を付加する
ことによる効果が大きい．この理由は，学習コーパスが大きくなると，外部辞書の元となる辞
書などに記述されている形態素の大部分が学習コーパスに含まれることになり，テストコーパ
スに含まれる未知形態素の割合が減少することであると考えられる．この議論から，確率的形
態素解析器を用いて学習コーパスと異なる分野の文を解析する場合には，未知形態素となるで
あろうその分野特有の用語(表記と品詞)を収集しておき，これを外部辞書として付加すること
でかなりの精度の向上が望めると考えられる．分野特有の用語の収集方法としては，その分野
の専門用語辞書などを直接用いることや，その分野の大量の文例から$n$-gram統計を用いて抽
出し品詞を推定すること\cite{nグラム統計によるコーパスからの未知語抽出}などが考えられ
る．

表\ref{table:result}は，外部辞書を備えない場合と備えた場合の，形態素bi-gramモデルと
クラスbi-gramモデルによるクロスエントロピーと形態素解析の精度である．また，先行研究
との比較のため，外部辞書を備えていない場合の品詞tri-gramモデルによるクロスエントロピ
ーも表中に記載している．この結果から，外部辞書の有無に関わらず，我々が提案する方法に
よって得られる単語のクラス分類を用いることで，形態素解析の精度が再現率と適合率の双方
で向上していることが分かる．これは，クロスエントロピーの減少から予測される通りの結果
である．このように，確率モデルを用いた言語の解析では，クロスエントロピーが減少するよ
うにモデルを改善することで，自然に形態素解析などの解析精度が向上することが見込まれる
．ただし，このクロスエントロピーと解析精度の関係は，単調であることが解析的に導出でき
るような確固たる関係ではないことに注意しなければならない．クロスエントロピーと解析精
度の関係が逆になっている例(上述の関係の反例)として，表\ref{table:result}の中の「形態
素bi-gram+外部辞書」と「クラスbi-gram」のエントロピーと適合率が挙げられる．

\input{table:result.tex}

文献\cite{EDRコーパスを用いた確率的日本語形態素解析}では，品詞tri-gramモデルを用いた
形態素解析をについて述べている．この文献では，我々が今回用いた評価規準と全く同じ評価
規準ではなく，単語分割のみや読みも含めた再現率と適合率を報告している．このような評価
の一つとして72,000文で学習した品詞tri-gramモデルの単語分割の精度として90.6\%の再現率
と91.7\%の適合率を報告している．このモデルとの比較を可能にするために，約47,000の学習
コーパスで学習した「クラスbi-gram+外部辞書」の単語分割の精度を計算した．この結果，再
現率は94.8\%であり，適合率は94.9\%であり，学習コーパスが少し小さいにもかかわらず品詞
tri-gramモデルの結果を双方で上回っている．解析精度に関しては全ての条件が同じというわ
けではないので単純な比較は適切ではないが，この結果は，本手法の優位性を実験的に示すと
考えられる．また，クロスエントロピー(表\ref{table:result}参照)の差は十分有意であると
考えられるので，この点からも本手法の形態素解析の精度という点での優位性が十分予測され
る．しかし，より長い文脈から次の品詞を予測しているという品詞tri-gramモデルの良い点も
無視できない．この点を採り入れて，形態素tri-gramモデルに対して形態素クラスタリングを
実行し，その結果を用いてクラスtri-gramモデルを構築すれば，クロスエントロピーがさらに
下がり，形態素解析の精度も上がると考えられる．ただし，実用とするためには，遷移表や解
探索のための表が大きくなることによる記憶域の増大と可能な組合せの増加による解探索に必
要な時間が増加するという問題にも注意を払う必要がある．

\input{figure:result.tex}



\subsection{文法の専門家による形態素解析器との比較}

我々は，上述の実験に加えて，文法の専門家による形態素解析器と確率的形態素解析器を解析
精度という点で比較するという実験を行なった．この際に最大の問題となるのは評価基準であ
る．確率的形態素解析器の解析精度の比較は容易に行なえる．つまり，我々が上述した実験で
行なったように，同一の学習コーパスと同一のテストコーパスを用いた解析結果の再現率と適
合率を比較すればよい．これは英文における単語の品詞推定の精度の比較にも用いられる標準
的な方法である(英語では単語区切りに曖昧性がないので再現率と適合率は同じ値になる)．し
かし，文法の専門家による形態素解析器の解析精度の比較は一般に容易ではない．これは，そ
れぞれの文法の専門家によって形態素の定義(品詞体系や単語区切り)に違いがあり，正解とな
るべき形態素解析結果を共有できないことに起因する．その結果，形態素解析器の評価として
は，あるいくつかの文の解析結果を文法の専門家も含めた形態素解析器の製作者が観察するこ
とで計算される値が用いられる．また，テストは最後に一回だけ行なわれるのではなく，テス
トの結果を見て形態素解析器を修正するということもあり，完全なオープンテストになってい
ないこともある．このようなテストの結果得られる精度は，客観性に欠けるので，おおよその
目安としてのみ意味があり，複数の形態素解析器の比較に用いることはできない．この問題は
，文法の専門家による形態素解析器と確率的形態素解析器の解析精度の比較を行なう際にも現
れる．

上述の問題を解決する方法として，同じ文法基準(品詞体系や単語区切)を持つ形態素解析済み
コーパスと文法の専門家による形態素解析器を用いることが考えられる．これが，本研究で我
々が選択した解決方法である．具体的には，京都大学で開発された文法の専門家による形態素
解析器JUMAN \cite{日本語形態素解析システムjuman使用説明書.version.3.2}とその解析結果
を人手で修正したコーパス\cite{京都大学テキストコーパス・プロジェクト}を用いた．つま
り，コーパスを学習コーパスとテストコーパスに分割し(表\ref{table:corpus-juman})，学習
コーパスから構成した確率的形態素解析器(外部辞書を備えたクラスbi-gramモデル)とJUMANを
用いてテストコーパスを解析した結果を，テストコーパスにあらかじめ付与されている正解と
比較して，それぞれの再現率と適合率を計算した．なお，外部辞書の形態素集合は，学習コー
パスには出現するが既知形態素とならなかった形態素集合である．表
\ref{table:result-juman}はこの結果である．この表から，テストコーパスにおいては，確率
的形態素解析器の誤りが文法の専門家による形態素解析器の誤りに対して25\%程度少ないこと
が分かる．この実験で使用した解析済みコーパスがJUMANの出力の訂正であることや，コーパ
スの訂正の過程で訂正結果を参考にしてJUMANを改良していることを考えると学習コーパスで
の比較が適切かも知れない．この場合は，確率的形態素解析器の解析精度は表
\ref{table:result-juman}に示されるように圧倒的に良い．未知語モデルを文字クラスタリン
グしたクラス$n$-gramモデルとすることや，外部辞書の源としてJUMANの辞書や別のコーパス
をJUMANで解析した結果から得られる学習コーパスに現れない高頻度の形態素を用いることで
，確率的形態素解析器の精度はさらに向上すると考えられる．

\input{table:corpus-juman}
\input{table:result-juman}

本実験で比較の対象とした文法の専門家による形態素解析器は，初版の完成から10年弱の期間
を経ており，この間に莫大な人的資源を投入し様々な改良が施されている．一方，我々の確率
的形態素解析器がパラメータ推定に用いた学習コーパスは8,584文であり，これを作成する費
用はそれほど高くはない．これは，確率的形態素解析器が，文法の専門家による形態素解析器
に対して優位である点の一つである．現状での学習コーパスの大きさは$10^{5.56}$文字と比
較的小規模であり，図\ref{figure:result}のEDRコーパスにおける学習コーパスの大きさと解
析精度の関係から，コーパスを増量し確率言語モデルを再学習するということを繰り返すこと
で，この品詞体系でのより高精度の形態素解析器が容易に実現できると予測される．これと並
行して確率言語モデルの改善を行なうことも重要である．以下に，より良い確率的形態素解析
器を実現するための指針をまとめる．
\begin{itemize}
\item 解析済みコーパスの保守と増量
  \begin{description}
  \item[コーパスの修正] \ \\
    人手による修正を受けた解析済みコーパスにも誤りはあり，さらなる修正が必要である．
    確率的形態素解析器の出力との比較は，これらの誤りを指摘する上で有効であろう．
  \item[コーパスの増量] \ \\
    すでに指摘したように，学習コーパスは多ければ多いほど良い．新たな文に正解を付加す
    るときには，人手による修正を受けたコーパスを全て用いて，最も良い言語モデルを学習
    し，その結果得られる確率的形態素解析器による解析結果を修正することで，人手による
    修正のコストを最小限に抑える必要がある．
  \item[品詞体系の変更] \ \\
    形態素解析器の出力を用いた研究や開発の過程で，品詞体系の変更が要求されることがあ
    る．例えば，京都大学テキストコーパス\cite{京都大学テキストコーパス・プロジェクト}
    では，「みんな/名詞」と「みんな/副詞」を区別していない．このような区別が必要にな
    れば，まず解析済みコーパスの一部をこの区別を加えて修正し，これと残りのコーパスで
    問題となる形態素が出現しないコーパスから形態素解析器を学習し，問題となる形態素が
    出現する文を曖昧な部分以外を固定して解析し直すことで，人手による修正のコストを最
    小限に抑えることができる．
  \end{description}
\item 確率的言語モデルの改良 \\
  確率言語モデルの改善方法は，本論文で提案した形態素クラスタリング以外にも提案されて
  る．これらは，未知語モデルにも適用できる．
  \begin{description}
  \item[可変記憶長マルコフモデル] \ \\
    $n$-gramモデルでの単語予測は固定長の文脈を条件部にもつが，これを先行する単語に応
    じて変化させる\cite{Part.of.Speech.Tagging.Using.a.Variable.Memory.Markov.Model}
    \cite{文脈木を利用した形態素解析}．
  \item[キャッシュモデル] \ \\
    直前のいくつかの単語の分布(キャッシュ)を用いて$n$-gramモデルのパラメータを動的に
    変化させる\cite{A.Cache-Based.Natural.Language.Model.for.Speech.Recognition}．
  \item[複数のモデルの補間] \ \\
    複数のクラス$n$-gramモデルを補間したモデルを用いる
    \cite{Improving.Statistical.Language.Model.Performance.with.Automatically.Generated.Word.Hierarchies}
    ．
  \end{description}
  これらの改良をうまく組み合わせることで言語モデルの予測力が向上し，結果としてより高
  い精度の形態素解析器が実現できる．
\item 解探索のアルゴリズムやデータ構造の改良 \\
  これによる解析速度や記憶容量の改良は，解析精度の向上にはつながらないが，実用とする
  上で重要である．解探索のアルゴリズムやデータ構造は，モデルのクラスに依存する点に注
  意しなければならない．
\end{itemize}
これらの改善は独立に行なえるので，組織的な取り組みが可能になる．このように，高い精度
を実現するための方法論が確立していることが確率的手法の最大の利点であろう．







\section{むすび}

本論文では，形態素クラスタリングと外部辞書の付加による確率的形態素解析器の精度向上に
ついて述べた．形態素クラスタリングとしては，形態素$n$-gramモデルをクロスエントロピー
を基準としてクラス$n$-gramモデルに改良する方法を提案した．bi-gramモデルを実装しEDRコ
ーパスを用いて実験を行なった結果，形態素解析の精度の向上が観測された．また，未知語モ
デルに外部辞書を付加する方法を提案した．同様の実験を行なった結果，形態素解析の精度の
向上が観測された．これは，学習コーパスとは異なる性質を持つ分野の形態素解析器や解析済
みコーパスを作成するのに特に有効であろう．両方の改良を行なったモデルによる形態素解析
実験の結果の精度は，先行研究として報告されている品詞tri-gramモデルの精度を上回った．
これは，我々のモデルが形態素解析の精度という点で優れていることを示す結果である．これ
らの実験に加えて，人間の言語直感に基づく形態素解析器との精度比較の実験を行なった．こ
の結果，確率的形態素解析器の誤りは文法家による形態素解析器の誤りに対して25\%程度少な
かった．形態素解析における確率的な手法は，人間の言語直感に基づく形態素解析器と比較し
て，現時点で精度がより高いという長所に加えて，今後のさらなる改良にも組織的取り組みが
可能であるという点で有利である．







\section*{謝辞}

本研究を進めるに過程で，示唆に富んだコメントを頂いた日本アイ・ビー・エムの西村雅史氏
と伊東伸泰氏に心から感謝する．また，本論文で報告している研究は文部省科学研究費補助金
(課題番号00093069)の助成を受けている．ここに感謝の意を表する．





\bibliographystyle{jnlpbbl}
\bibliography{myplain,main}


\include{biogr}


\end{document}
