\documentstyle[nlpbbl,epsbox]{jnlp_e}

\setcounter{page}{1}
\setcounter{巻数}{5}
\setcounter{号数}{3}
\setcounter{年}{1998}
\setcounter{月}{7}
\受付{}{}{}
\再受付{}{}{}
\採録{}{}{}

\setcounter{secnumdepth}{2}

\title{}
\author{}
\jkeywords{}

\etitle{An Affective-Similarity-Based Method \\ for Comprehending Attributional Metaphors}

\eauthor{Akira Utsumi\affiref{Titech} \and
         Koichi Hori\affiref{TokyoUniv} \and
         Setsuo Ohsuga\affiref{Waseda}}

\headauthor{Utsumi,~A.~et~al.}
\headtitle{Comprehending Attributional Metaphors}

\affilabel{Titech}
          {Tokyo Institute of Technology, 
           Department of Computational Intelligence and Systems Science}
          {Tokyo Institute of Technology, 
           Department of Computational Intelligence and Systems Science}
\affilabel{TokyoUniv}
          {The University of Tokyo, Interdisciplinary Course on Advanced Science and Technology}
          {The University of Tokyo, Interdisciplinary Course on Advanced Science and Technology}
\affilabel{Waseda}
          {Waseda University, Department of Information and Computer Science}
          {Waseda University, Department of Information and Computer Science}

\eabstract{
This paper proposes a new computational method for 
comprehending attributional metaphors.
The proposed method generates deeper interpretations of metaphors 
than other methods through the process of figurative mapping that transfers 
affectively similar features of the source concept onto the target concept.
Any features are placed on a common two-dimensional space 
revealed in the domain of psychology, and 
similarity of two features is calculated as a distance between them in
the space.
A computational model of metaphor comprehension based on the method 
has been implemented in a computer program called {\sfi PROMIME} 
(\underline{PRO}totype system of \underline{M}etaphor 
\underline{I}nterpreter with \underline{ME}taphorical mapping).
Comparison between the {\sfi PROMIME} system's output and human interpretation
shows that the performance of the proposed method is satisfactory.
}

\ekeywords{Metaphor Comprehension, Computational Model, Feature Mapping}


\newlength{\minipagelist}\setlength{\minipagelist}{120mm}
\newenvironment{slist}{}{}
\newfont{\sfb}{cmssbx10}
\newfont{\sfi}{cmssi10}
\newcommand{\SNAME}{}

\begin{document}

\maketitle

\section{Introduction} \label{sec:intro}
Many studies in the domains of computational linguistics 
\cite{Weiner84,Fass91,Martin92} and artificial intelligence
\cite{Falkenhainer86,Indurkhya87,IJCAI91} have recently given much 
attention to the mechanism of metaphor comprehension.
Metaphor can throw new light on the studies of intelligent human activities
such as thought, memory, and language.
This paper focuses on attributional metaphors, 
metaphors whose interpretations are characterized by 
attributes/features of the constituent concepts \cite{Gentner88}.

However, previous computational studies of metaphors have ignored or disregarded an
important phenomenon in comprehending metaphors, 
{\it metaphorical transfer of salient features} \cite{Tourangeau82,Tourangeau91,Becker97}.
For example, consider the following metaphors.
\begin{slist}
  \sitem Mary's cheeks are apples. \label{sentence:apple}
  \sitem John's mind is ice. \label{sentence:ice}
  \sitem Susan's smile is a southern breeze. \label{sentence:breeze}
\end{slist}
In interpreting the first metaphor (\ref{sentence:apple}), some salient features of
the source concept (i.e., the vehicle) ``apples'' --- e.g., red, round, hard --- 
are transferred to the target concept (i.e., the tenor) ``Mary's cheeks''.
As a result of the transfer, these salient features of ``Mary's cheeks''
are highlighted. Yet this is not a complete interpretation of the metaphor.  
We will also imagine that Mary has fresh skin on her cheeks, Mary is healthy, and so on.
It indicates that the salient features of apples are not
only transferred to Mary's cheeks, but also mapped onto metaphorically
corresponding attributes of Mary's cheeks such as 
``healthiness'' and ``freshness''.
This phenomenon is more easily observed in the metaphor (\ref{sentence:ice}).
Two constituent concepts --- ``John's mind'' and ``ice'' --- 
of the metaphor share few features, and even the shared features 
such as ``cold'' are shared only metaphorically \cite{Tourangeau82}. 
The features that are not shared by the two concepts but highlighted by the metaphor 
--- e.g., cool, severe, gloomy --- 
are derived from different but metaphorically similar features of the source concept.
The metaphor (\ref{sentence:breeze}) is one extreme example of this phenomenon:
although ``Susan's smile'' cannot share any salient features of ``southern breeze'',
we can easily interpret this metaphor as ``Susan's smile is pleasantly surprising
and thrilling.''
In recent years, a psychological study has strongly supported a crucial
role that this kind of metaphorical mapping plays in comprehending and
evaluating metaphors. For example, 
\citeA{Tourangeau91} showed that shared features, which
characterize both the source concept and the target concept, do not always
dominate the interpretation of a metaphor, but that {\it emergent
features}, which do not characterize either, can play a central role.

The purpose of this paper is to propose a computational model of
metaphor comprehension that can deal with mappings of metaphorically
similar features onto the target concept.  The key notion of our model
is a multidimensional affective structure that many researchers,
e.g., \citeA{Osgood80} and \citeA{Kusumi88}, have revealed in many
psychological experiments.  
This structure can capture
affective similarities which should be included in the interpretations
of attributional metaphors \cite{Kusumi87}, 
and it is used for constructing metaphorical correspondences of features 
\cite{Tourangeau82,Weiner85}.
Our model uses a spatial representation of features and a mechanism
for making correspondences between metaphorically similar features on
different dimensions.
We call it an {\it affective-similarity-based mapping (ASM) method}.

This paper is organized as follows. Section\,\ref{sec:mapping}
describes why and how metaphorical correspondences of features are
constructed in comprehending attributional metaphors.
A basic idea of the ASM method is also presented.
Section\,\ref{sec:metaphor} gives a computational model (algorithm) 
of comprehending attributional metaphors using the ASM method 
and describes a computer program \SNAME\/ based upon this model. 
Section\,\ref{sec:psycho} describes our experimental method for evaluating 
our metaphor comprehension algorithm.
In the experiment we examined how close the system's generated interpretation is 
to human interpretation, and its result shows that our method is psychologically plausible.
To our knowledge, no computational model of metaphor has been ever
directly validated or quantitatively evaluated by such experiments.
Section\,\ref{sec:discussion} is a discussion of 
various aspects of our model along with its advantages and
limitations, and Section\,\ref{sec:conclusion} concludes this paper.

\section{Constructing Metaphorical Correspondences of Features} \label{sec:mapping}
To establish metaphorical correspondences in the non-overlapping
domains of source and target concepts, we must consider the
following two issues:
\begin{itemize}
\item decomposing many constituent words representing a concept's features into
  conceptually primitive features
\item constructing literal and figurative correspondences between these primitive
  features.
\end{itemize}

The first issue reflects the need to discriminate between a conceptual level
and a lexical level. Primitive features can be seen as basic units 
on which metaphorical correspondences are constructed.  
The reason why we discriminate between two levels is
that confusion between these two levels leads to the neglect of
mapping of metaphorically related features in comprehending metaphors.
For example, the meanings of the word ``cold'' modifying ``ice'' and ``mind''
(i.e., ``being a low temperature'' and ``marked by a lack of the warmth of normal human
emotion'') in the metaphor (\ref{sentence:ice}) are different but metaphorically related.
If the two levels are confused, 
the difference and the similarity between two meanings cannot be made clear.
We have thus analyzed about 800 Japanese adjectives and 
decomposed their meanings into approximately 400 conceptually 
primitive features \cite{Utsumi93}.  

The other issue to consider, which is a central topic of this paper, is
the mechanism for metaphorical mapping of features. This mechanism must be
able to find which features of the target concept are metaphorically
similar to salient features of the source concept.  For this purpose,
we must explain what kind of similarities govern the interpretation
process for attributional metaphors and how they are processed.

The former question was recently addressed by \citeA{Kusumi87}: he
examined the effects of affective and categorical similarities between
the constituent concepts of attributional metaphors, and showed that
affective similarity between source and target concepts influences
sentence comprehensibility and aptness of metaphors.
\footnote{
  In general, concepts are characterized by two kinds of features:
  affective features and categorical features. Affective features
  characterize a prototypical exemplar of a concept. Therefore not every
  instance of the concept has these features. On the other hand,
  categorical features give an encyclopaedic definition of a
  concept. For example, the concept ``wolf'' has affective features
  ``being vicious, dangerous, fierce, etc.'' and categorical features
  ``being animal, mammal, etc.'' In comprehending the metaphor 
  ``Man is a wolf'', the features preferentially mapped to 
  the concept ``man'' are not categorical features but 
  affective features of ``wolf''.}
The affective similarity includes not only the similarity based on
shared features, but also the similarity which emerges from figurative
correspondences of features.  The preferential selection of affective
features in figurative language
is also pointed out by \citeA{Weiner85} from a computational point of view.

Concerning the question of how affective similarities are processed,
many psycholinguistic studies have tried to reveal the structure 
underlying affective similarity 
as an intrinsic basis of cross-modal equivalence of dimensions 
that appears in many domains of human cognition
\cite{Asch55,Osgood57,Osgood80,Kusumi88}.
For example, \citeA{Asch55} showed that for many languages
many human personality traits are described with words or phrases that 
have origins in the sensory vocabularies of those languages.
\citeA{Osgood57} and \citeA{Osgood80} have found a structure underlying the affective 
similarity as a fundamental characteristic of our perceptual cognition.
This structure consists of three factors/dimensions 
--- factors of evaluation (E), activity (A) and potency (P) ---, 
and they applied these factors to evaluation of 
affective similarity between concepts (meanings). 
Their approach is known as the semantic differential method (SD method).
\citeA{Kusumi88} lent support to the plausibility of Osgood et al's 
multidimensional structure through psychological experiments. 
He revealed two-dimensional configurations of the adjectives for 
nine modality-denoting nouns (touch, taste, smell, color, 
sound, memory, mood, idea, personality), and showed that 
two independently rated properties, pleasantness and intensity, of each
configuration provided a common structure across the nine modalities.
Also, the property of pleasantness corresponds to the factor of ``evaluation (E)'' 
in the SD method and the property of intensity corresponds 
to the factors of ``activity (A)'' and ``potency (P)''.
Kusumi's result indicates that affective similarity is strongly based on these dimensions. 

\begin{figure}[t]
\begin{center}
  \makeatletter\ifDS@epsbox
  \epsfile{file=Fig/affective.epsf,height=6cm}
  \else
  \mbox{\psfig{figure=Fig/affective.epsf,height=6cm}}
  \fi\makeatother
\end{center}
\caption{An example of the two-dimensional space based on the common affective structure}
\label{fig:space}
\end{figure}

Our affective-similarity-based mapping method (ASM method) for constructing
metaphorical correspondences is based on this common structure.
Each attribute has its own two-dimensional space whose dimensions represent
pleasantness (pleasant---unpleasant) and intensity (intense---subdued).
Each dimension is divided into 7 degrees from $-3$ to $3$, and 
every feature is placed at one of 49 rectangles (lattice points) in
the two-dimensional space of its attribute. 
\footnote{
  We claim neither that the number of divisions ``7'' is psychologically plausible
  nor that the points of the space should be denoted by integers between $3\sim-3$.}
As an example, the two-dimensional spaces of color, taste and temperature are shown in
Figure\,\ref{fig:space}.  
The degree of affective similarity of two features 
{\tt\#}$A$ and {\tt\#}$B$ is calculated using a normalized 
distance between {\tt\#}$A$ and {\tt\#}$B$ whose coordinates are
$(a_1,a_2),(b_1,b_2)$ in the common two-dimensional space.
The similarity measure is given by
\begin{equation}
  similarity(\mbox{\tt\#}A,\mbox{\tt\#}B) = 
  1 - \frac{\sqrt{(a_1 - b_1)^2 + (a_2 - b_2)^2}}{6\sqrt{2}} \label{eqn:distance}
\end{equation}
For example, when a feature {\tt\#}$C$ in an attribute X is mapped onto
another attribute Y whose possible features are {\tt\#}$D_i$,
the nearest feature (denoted by {\tt\#}$D_{min}$) among all {\tt\#}$D_i$ 
is selected as a metaphorically corresponding feature of {\tt\#}$C$.
As a result of the mapping, {\tt\#}$D_{min}$ is highlighted.

\section{Comprehending Attributional Metaphors by Computer}\label{sec:metaphor}
\subsection{A computational model of attributional metaphors} \label{subsec:metaphor-model}
We provide an algorithm that embodies our comprehension model of attributional metaphors. 
Figure\,\ref{fig:algo} gives the algorithm for comprehending attributional
metaphors. 
The algorithm takes as input the source concept ${\cal C}^S$ and the target concept
${\cal C}^T$ of a given metaphor that will be interpreted
and produces the modified target concept ${\cal C}^{T/S}$.
The comprehension process is divided into the following three sub-processes:
\begin{enumerate}
  \renewcommand{\theenumi}{}
  \renewcommand{\labelenumi}{}
\item selecting salient properties of a source concept (line\,2 of Figure\,\ref{fig:algo});
\item finding the properties of a target concept that literally or
  metaphorically correspond to the selected properties of the source concept
  (lines\,3 and 4); and
\item modifying the properties of the target concept (line\,5).
\end{enumerate}
The first process (a) selects salient properties by calculating their
degrees of salience. These salient features (elements of $S_0$)
are not only transferred to the target concept, 
but also used for constructing metaphorical 
correspondences in the second process (b).
The second process (b) constructs literal and figurative correspondences 
between features by the ASM method and generates mappable properties ($S_1 \cup S_2$)
for the target concept.
The last process (c) highlights and downplays the target properties 
using mappable properties obtained by the process (b). 
As a result of the comprehension process
we obtain a new concept that represents the target concept viewed from the source concept.

\begin{figure}[t]
  \vspace*{-2mm}
  \begin{center}\begin{minipage}[c]{100mm}
  \subsubsection*{{\it ComprehendMetaphors\/}$({\cal C}^S,{\cal C}^T,{\cal C}^{T/S})$}
    \small
    \begin{enumerate}
      \renewcommand{\theenumi}{}
      \renewcommand{\labelenumi}{}
      \addtolength{\itemsep}{-\parsep}
      \setlength{\labelsep}{-6ex}
    \item $S_0 \leftarrow \phi$; $~S_1 \leftarrow \phi$; $~S_2 \leftarrow \phi$;
      $~{\cal C}^T_1 \leftarrow \phi$; $~{\cal C}^T_2 \leftarrow \phi$;
    \item {\it SelectSalient\/}$({\cal C}^S,S_0)$;
    \item {\it FindLiteral\/}$({\cal C}^T,S_0,S_1,{\cal C}^T_1,{\cal C}^T_2)$;
    \item {\it ASM\/}$(S_0,{\cal C}^T_2,S_2)$;
    \item {\it ModifyTarget\/}$({\cal C}^T,S_1,S_2,{\cal C}^{T/S})$;
    \end{enumerate}
    \end{minipage}\end{center}
  \caption{Metaphor comprehension algorithm} \label{fig:algo}
\end{figure}

The comprehension process in this study relies mainly upon how source and
target concepts are structured and represented.
Hence, before detailing the comprehension process, we must define our
representation of concepts.
In this paper, we use a probabilistic concept as our concept
representation form. This representation is seen in the domain of
cognitive psychology as the prototype representation of a concept
\cite{Rosch75} with probabilistic values \cite{Smith88,Iwayama90}.
Formally, a {\it concept\/} $\cal C$ is represented as a set of {\it properties},
i.e., ${\cal C}=\{P_1,P_2,\,\cdots\,P_n\}$.
Each property $P_{i}$ consists of an {\it attribute} $a_i$ and its probabilized value 
set $V_i$ of possible values $v_{ij}$ for that attribute, 
with each value assigned a probability $p_{ij}$:
\begin{eqnarray*}
 P_i & = & a_i:V_i \\
 V_i & = & \{ ~v_{ij}:p_{ij}~|~v_{ij} \in {\cal V}_{i} \subseteq \Omega(a_i),~p_{ij} \in [0,1]~ \}
\end{eqnarray*}
where ${\cal V}_{i}$ is a set of all possible (empirically observable) values 
for $a_i$ of the concept, $\Omega(a_i)$ is a sample space of values for $a_i$, 
and $\sum_{j=1}^{|V_i|} p_{ij} = 1$.
The probability $p_{ij}$ attached to each value can be regarded as 
the ratio of judging the value $v_{ij}$ typical of the property $P_i$ 
of the concept ${\cal C}$. 
The value with the highest probability in $V_i$, denoted by $v^{*}_i$, 
is called {\it the most probable value}, and the pair of an
attribute and its most probable value, denoted by $a_i:v^{*}_i$, 
is called {\it a feature}.
(We also call the pair of $a_i$ and one of possible values for $a_i$ a possible feature.)
A concept also includes {\it the distinctiveness\/} of each property,
whose value is denoted by $d_i$. 
The distinctiveness $d_i$ corresponds to Smith et al.'s\citeyear{Smith88} diagnosticity 
and \citeauthor{Iwayama90}'s\citeyear{Iwayama90} difference of property; 
it reflects how useful the property is in discriminating instances of 
the concept from instances of similar concepts.
In the remainder of this paper, the source concept and its components
are denoted by adding the superscript `$S$' like $P^S_i$, and
the target concept and its components by the superscript `$T$' like $P^T_j$.

\begin{figure}[t]
  \small
  \begin{center}
    $\left[~~
    \begin{tabular}[c]{l@{~:~}lc}
      color & \{ red\,:\,0.95,~ green\,:\,0.05 \} & 0.90\\
      shape & \{ round\,:\,1.00 \} & 0.60 \\
      taste & \{ sour-sweet\,:\,0.60,~ sweet\,:\,0.30,~ sour\,:\,0.10\} & 0.60 \\
      texture & \{ smooth\,:\,0.80,~ rough\,:\,0.20 \} & 0.50 \\
      juiciness & \{ juicy\,:\,1.00 \} & 0.40 \\
      smell & \{  fragrant\,:\,0.80,~ sweet\,:\,0.20 \} & 0.30 \\
      hardness & \{ hard\,:\,0.90,~ soft\,:\,0.10 \} & 0.15 \\
      size & \{  \} & --- \\
    \end{tabular}
    ~~\right]$ \\[.5\baselineskip]
    (a)~ the concept of {\it apple}\\[\baselineskip]
    $\left[~
    \begin{tabular}[c]{l@{~:~}lc}
      color & \{ red\,:\,0.70,~ pale\,:\,0.20,~ yellow\,:\,0.10 \} & 0.80 \\
      texture & \{ smooth\,:\,0.60,~ rough\,:\,0.40 \} & 0.50 \\
      hardness & \{ soft\,:\,0.90,~ hard\,:\,0.10 \} & 0.30 \\
      shape & \{ round\,:\,0.9,~ ngular\,:\,0.10 \} & 0.20 \\
      freshness & \{ fresh\,:\,0.50,~ old\,:\,0.50 \} & --- \\
      healthiness & \{ healthy\,:\,0.50,~ unhealthy\,:\,0.50 \} & --- \\
    \end{tabular}
    ~\right]$ \\[.7\baselineskip]
    (b)~ the concept of {\it cheek}
  \end{center}
  \caption{Probabilistic representations of the concepts {\it apple} and {\it cheek}}
  \label{fig:apple}
\end{figure}

As an example, the representations of the concepts ``apple'' and ``cheek''
are shown in Figure\,\ref{fig:apple}.  In this figure, for example, 
``color'' is the attribute $a_i$ and 
the set within curly brackets is the probabilized value set $V_i$ 
where each real number is the probability $p_{ij}$ of the value $v_{ij}$. 
The real number $0.90$ written on the right side of the set
denotes the distinctiveness $d_i$ of that property.
The most probable value $v^{*}_i$ of the attribute ``color'' is ``red'' and therefore
``color:red'' is the feature of apple.
The empty probabilized value set (e.g., size of ``apple'') in Figure\,\ref{fig:apple}
means that every possible value for that attribute has equal probability
(formally ${\cal V}_i = \Omega(a_i)$ and $\forall j~ p_{ij}=1/|{\cal V}_i|$).
In such cases, the attribute has no most probable value and thus 
the distinctiveness of the property is not defined.
Note that in Figure\,\ref{fig:apple} it is assumed that 
``healthiness'' is one of the attributes of the concept ``cheek'' 
for the sake of simplicity. 
Strictly speaking, the attribute ``healthiness'' 
is not in the concept ``cheek'', but is inherited from its parent concepts
like ``person''.

\begin{figure}[p]
  \small
  \paragraph*{{\it SelectSalient\/}$({\cal C}^S,S_0)$}
  \small
  \begin{enumerate}
    \renewcommand{\theenumi}{}
    \renewcommand{\labelenumi}{}
    \addtolength{\itemsep}{-\parsep}
    \setlength{\labelsep}{-4ex}
  \item {\bf for each} $P^S_i=a^S_i\!\!:\!V^S_i$ ~{\bf in}~ ${\cal C}^S$ {\bf do}
  \item \hspace*{4ex} {\bf if} $salience(P^S_i) \geq C_{sl}$ ~{\bf then}~
    $S_0 \leftarrow S_0 \cup \{\,(a^S_i\!:\!v^{*S}_i,\, salience(P^S_i))\,\}$ 
  \item {\bf end}
  \end{enumerate}
  \newcounter{buf}
  \setcounter{buf}{\theenumi}
  \vspace*{-\baselineskip}
  \paragraph*{{\it FindLiteral\/}$({\cal C}^T,S_0,S_1,{\cal C}^T_1,{\cal C}^T_2)$}
      \small
      \begin{enumerate}
        \setcounter{enumi}{\thebuf}
        \renewcommand{\theenumi}{}
        \renewcommand{\labelenumi}{}
        \addtolength{\itemsep}{-\parsep}
        \setlength{\labelsep}{-4ex}
      \item {\bf for each} $(a^S_i\!:\!v^{*S}_i,\,salience(P^S_i))$ ~{\bf in}~ $S_0$ ~{\bf do}
      \item \hspace*{4ex} {\bf if} $\exists\, P^T_j \,(= a^T_j\!\!:\!V^T_j)\, 
        \in {\cal C}^T$ such that $a^T_j = a^S_i$ and ${\cal V}^T_j \ni v^{*S}_i$ ~{\bf then}
      \item \hspace*{8ex} $S_1 \leftarrow S_1 \cup \{\,(a^S_i\!:\!v^{*S}_i,\,salience(P^S_i))\,\}$
      \item \hspace*{8ex} ${\cal C}^T_1 \leftarrow {\cal C}^T_1 \cup \{ P^T_j \}$
      \item {\bf end}
      \item ${\cal C}^T_2 \leftarrow {\cal C}^T - {\cal C}^T_1$
      \end{enumerate}
  \vspace*{-\baselineskip}
  \setcounter{buf}{\theenumi}
  \paragraph*{{\it ASM\/}$(S_0,{\cal C}^T_2,S_2)$}
      \begin{enumerate}
        \setcounter{enumi}{\thebuf}
        \renewcommand{\theenumi}{}
        \renewcommand{\labelenumi}{}
        \addtolength{\itemsep}{-\parsep}
        \setlength{\labelsep}{-4ex}
      \item {\bf for each} $P^T_i = a^T_i\!\!:\!V^T_i$ ~{\bf in}~ ${\cal C}^T_2$ ~{\bf do}
      \item \hspace*{4ex} {\bf for each} $k$ ~{\bf do}~ $\mbox{count}[k] \leftarrow 0$ ~{\bf end}
      \item \hspace*{4ex} {\bf for each} $(a^S_j\!:\!v^{*S}_j,\, salience(P_j))$ ~{\bf in}~ 
        $S_0$ ~{\bf do}
      \item \hspace*{8ex} {\bf for each} $v^T_{ik}$ ~{\bf in}~ ${\cal V}^T_i$ ~{\bf do}~
        $d_{ijk} \leftarrow similarity(a^S_j\!:\!v^{*S}_j,\,a^T_i\!\!:\!v^T_{ik})$ ~{\bf end} 
      \item \hspace*{8ex} {\bf if} $\exists\,l$ 
        such that $\forall k \neq l~~d_{ijl} > d_{ijk}$ ~{\bf then} 
      \item \hspace*{12ex} {\bf if} count$[l] = 0$ ~{\bf then}
      \item \hspace*{16ex} $S_2 \leftarrow S_2 \cup \{\,(a^T_i\!\!:\!v^T_{il},\,
        salience(P_j) \times d_{ijl})\,\}$
      \item \hspace*{12ex} {\bf else}
      \item \hspace*{16ex} $S_2 \leftarrow (S_2 - \{\,(a^T_i\!\!:\!v^T_{il},\,q_{il})\,\}) \,\cup\,
        \{\,(a^T_i\!\!:\!v^T_{il},\,q_{il} + salience(P_j) \times d_{ijl})\,\}$
      \item \hspace*{12ex} $\mbox{count}[l] \leftarrow \mbox{count}[l] + 1$
      \item \hspace*{4ex} {\bf end}
      \item \hspace*{4ex} {\bf for each} $(a^T_i\!:\!v^T_{ik},\,q_{ik})$ ~{\bf in}~ $S_2$ ~{\bf do}
      \item \hspace*{8ex} 
        $S_2 \leftarrow (S_2 - \{(a^T_i\!:\!v^T_{ik},\,q_{ik})\}) \cup
        \{\,(a^T_i\!:\!v^T_{ik},\,\displaystyle\frac{q_{ik}}{\mbox{count}[k]})\,\}$ 
      \item \hspace*{4ex} {\bf end}
      \item {\bf end}
      \end{enumerate}
  \vspace*{-\baselineskip}
  \setcounter{buf}{\theenumi}
  \paragraph*{{\it ModifyTarget\/}$({\cal C}^T,S_1,S_2,{\cal C}^{T/S})$}
      \small
      \begin{enumerate}
        \setcounter{enumi}{\thebuf}
        \renewcommand{\theenumi}{}
        \renewcommand{\labelenumi}{}
        \addtolength{\itemsep}{-\parsep}
        \setlength{\labelsep}{-4ex}
      \item $S \leftarrow S_1 \cup S_2$
      \item {\bf for each} $(a_i\!:\!v_{ij},\,q_{ij})$ ~{\bf in}~ $S$ ~{\bf do}~
        {\bf if} $q_{ij} < C_{pref}$ ~{\bf then}~
        $S \leftarrow S - \{\,(a_i\!:\!v_{ij},\,q_{ij})\,\}$ ~{\bf end}
      \item {\bf for each} $P^T_i = a^T_i\!\!:\!V^T_i$ ~{\bf in}~ ${\cal C}^T$ ~{\bf do}
      \item \hspace*{4ex} $Q_i\leftarrow\{\,(a_j\!:\!v_{jk},\,q_{jk}) \in S ~|~ a_j = a^T_i\,\}$
      \item \hspace*{4ex} {\bf if} $Q_i \neq \phi$ and $\exists (a_j\!:\!v_{jl},\,q_{jl}) \in Q_i$
        such that $\forall k \neq l~~ q_{jl} > q_{jk}$ ~{\bf then}
      \item \hspace*{8ex} $P^{T/S}_i \leftarrow a^T_i\!:\!\{v_{jl}\!:\!1.0\}$
      \item \hspace*{4ex} {\bf else}
      \item \hspace*{8ex} $P^{T/S}_i \leftarrow P^T_i$
      \item {\bf end}
      \end{enumerate}
  \caption{Four subroutines of metaphor comprehension algorithm}
  \label{fig:subalgo}
\end{figure}

\begin{table}[t]
  \caption{A list of variables and constants in the algorithm} \label{tbl:notation}
  \begin{tabular}[t]{lp{48mm}}
   ${\cal C}^S$ & Source concept \\ ${\cal C}^T$ & Target concept \\
   ${\cal C}^{T/S}$ & Modified target concept viewed \newline from the source concept\\
   $P^S_i$, $P^T_i$ & Properties of ${\cal C}^S$, ${\cal C}^T$ \\
   $a^S_i$, $a^T_i$ & Attributes of ${\cal C}^S$, ${\cal C}^T$ \\
   $V^S_i$, $V^T_i$ & Value set of $a^S_i$, $a^T_i$ \\
   ${\cal V}^S_i$, ${\cal V}^T_i$ & Set of possible values for $a^S_i$, $a^T_i$\\
   $v^S_{ij}$, $v^T_{ij}$ & Values of $a^S_i$, $a^T_i$ \\
   $p^S_{ij}$, $p^T_{ij}$ & Probabilities of $v^S_{ij}$, $v^T_{ij}$ \\
   $v^{*S}_i$, $v^{*T}_i$ & The most probable value of $a^S_i$, $a^T_i$ \\
   $d^S_i$, $d^T_i$ & Distinctiveness of $P^S_i$, $P^T_i$ \\
   $S_0$ & Set of salient features of ${\cal C}^S$ 
  \end{tabular}
  \begin{tabular}[t]{lp{58mm}}
   $S_1$ & Set of transferable features in $S_0$ \\
   $S_2$ & 
   Set of candidate features that are meta\-phorically related to the features in $S_0$ \\
   ${\cal C}^T_1$ &
   Set of properties of ${\cal C}^T$ that literally correspond to salient features in $S_1$ \\
   ${\cal C}^T_2$ & Set of properties of ${\cal C}^T$ that do not literally
   correspond to any salient features in $S_1$ \\
   $C_{sl}$ & Threshold of saliency \\ $C_{pref}$ & Threshold of preference \\
   $Q_i$ & Set of candidate features for $a^T_i$ \\
   $q_{ij}$ & Degree of preference of a candi\-date feature $a_i\!:\!v_{ij}$
  \end{tabular}
\end{table}

Throughout the algorithm, it is important that
the degree of preference is attached to each of the possible features that
the algorithm selects as candidate for features of ${\cal C}^{T/S}$. 
We also call these features {\it candidate features}, and
use the following data structure:\\
\centerline{$(\, \mbox{attribute}\!:\!\mbox{value},\, \mbox{the degree of preference}\,)$}\\
The degree of preference, which is a real number ranging from 0 to 1, expresses
how preferably the feature is mapped onto the target.

Let us now explain, in detail, how the algorithm of Figure\,\ref{fig:algo} applies
step by step to the metaphor (\ref{sentence:apple})
``Mary's cheeks are apples'' in Sections\,\ref{subsec:salient}-\ref{subsec:modify}.
Figure\,\ref{fig:subalgo} gives four subroutines of the algorithm 
and Table\,\ref{tbl:notation} lists the variables and constants used in the algorithm.

\begin{figure}[t]
  \vspace*{-1mm}\small
  \begin{center}
    $\begin{array}{l}
      salience(\mbox{color:\{red:0.95, green:0.05\}}) = 0.90 \cdot (1-0.29) = 0.64 \\
      salience(\mbox{shape:\{round:1.0\}}) = 0.60 \cdot (1-0) = 0.60 \\
      salience(\mbox{taste:\{sour-sweet:0.60, sweet:0.30, sour:0.10\}}) = 
      0.60 \cdot  (1-0.82) = 0.11 \\
      salience(\mbox{texture:\{smooth:0.80, rough:0.20\}}) = 0.50 \cdot (1-0.72) = 0.14 \\
      salience(\mbox{juiciness:\{juicy:1.0\}}) = 0.40 \cdot (1-0) = 0.40 \\
      salience(\mbox{smell:\{fragrant:0.80, sweet:0.20\}} = 0.30 \cdot (1-0.72) = 0.08 \\
      salience(\mbox{hardness:\{hard:0.90, soft:0.10\}}) = 0.15 \cdot (1-0.47) = 0.08 
    \end{array}$\\[.5\baselineskip]
    (a)~ the result of calculating the degree of salience \\[\baselineskip]
    $S_0 ~=~ \left\{
    \begin{array}{lll}
      (\mbox{color:red},\,0.64), & 
      (\mbox{shape:round},\,0.60), & 
      (\mbox{juiciness:juicy},\,0.40), \\
      (\mbox{texture:smooth},\,0.14), &
      (\mbox{taste:sour-sweet},\,0.11) &
    \end{array}
    \right \}$\\[.5\baselineskip]
    (b)~ the output of the algorithm {\it SelectSalient} \\[\baselineskip]
    \begin{tabular}{l}
      $S_1 = \{ ~(\mbox{color:red},\,0.64),~ (\mbox{shape:round},\,0.60),~
      (\mbox{texture:smooth},\,0.14)~ \}$ \\[1mm]
      ${\cal C}^T_1 = \left\{
      \begin{array}{ll}
        \mbox{color:\{red:0.70, pale:0.20, yellow:0.10\}},&
        \hspace*{-2ex}\mbox{shape:\{round:0.90, angular:0.10\}},\\
        \mbox{texture:\{smooth:0.60, rough:0.40\}}&
      \end{array}\right\}$ \\[1mm]
      ${\cal C}^T_2 = 
      \left\{
        \begin{array}{ll}
          \mbox{hardness:\{soft:0.90, hard:0.10\}},&
          \hspace*{-12ex}\mbox{freshness:\{fresh:0.50, old:0.50\}},\\
          \mbox{healthiness:\{healthy:0.50, unhealthy:0.50\}} &
        \end{array}\right\}$ \end{tabular}\\[.5\baselineskip]
    (c)~ the output of the algorithm {\it FindLiteral} \\[\baselineskip]
    $S_2 ~=~ \left\{
    \begin{array}{l}
      (\mbox{hardness:soft},\,0.40),~~ (\mbox{hardness:hard},\,0.10),~~
      (\mbox{healthiness:healthy},\,0.32), \\ (\mbox{healthiness:unhealthy},\,0.08),~~
      (\mbox{freshness:fresh},\,0.34),~~ (\mbox{freshness:old},\,0.32)
    \end{array}
    \right \}$\\[.5\baselineskip]
    (d)~ the output of the algorithm {\it ASM} \\[\baselineskip]
    ${\cal C}^{T/S} = \left[~
    \begin{tabular}[c]{l@{~:~}lc}
      color & \{ red\,:\,1.00 \} & 0.80 \\
      texture & \{ smooth\,:\,1.00 \} & 0.50 \\
      hardness & \{ soft\,:\,1.00 \} & 0.30 \\
      shape & \{ round\,:\,1.00 \} & 0.20 \\
      freshness & \{ fresh\,:\,1.00 \} & --- \\
      healthiness & \{ healthy\,:\,1.00 \} & --- \\
    \end{tabular}~\right]$\\[.7\baselineskip]
    (e)~ the output of the algorithm {\it ModifyTarget}
    (the concept {\it Mary's cheeks viewed from apples})
  \end{center}
  \caption{The process of comprehension of the metaphor (\protect\ref{sentence:apple})}
  \label{fig:example}
\end{figure}

\subsection{Selecting salient properties} \label{subsec:salient}
The algorithm {\it SelectSalient\/} of Figure\,\ref{fig:subalgo} 
calculates the degrees of salience $salience(P^S_i)$ of source properties and 
selects properties whose degree of salience exceeds or is equal to
a threshold $C_{sl}$. These selected features are stored in $S_0$ where 
their degrees of salience are used for their degrees of preference.
In order to calculate the degree of salience, the algorithm uses the following
equation originally proposed by \citeA{Iwayama90}:
\begin{eqnarray}
  &&salience(P^S_i) = d^S_{i} \times (1 - H_{i}) \label{eqn:salience} \\[.5\baselineskip]
  &&H_{i} = \cases{
    \frac{\sum_{j=1}^{|V^S_i|} -p^S_{ij}\log_{2}p^S_{ij}}
    {\log_{2} |V^S_i|} & ($|V^S_i| \geq 2$) \cr
    ~~0 & ($|V^S_i| = 1$)} \label{eqn:AIP}
\end{eqnarray}
Equation\,(\ref{eqn:AIP}) denotes the ``entropy'' of the value set $V^S_i$ in
information theory. Equation\,(\ref{eqn:salience}) means that the
greater the distinctiveness of a property, the more salient it is,
and the smaller the entropy of a property, the more salient it is.
The degree of salience of properties with no most probable value is 0.
Note that the distinctiveness of a property is assumed to be fixed and
given in advance for the sake of simplicity, 
although \citeauthor{Iwayama90}'s\citeyear{Iwayama90}
original study includes a method for calculating the difference of
properties.

In comprehending the metaphor (\ref{sentence:apple}), 
the source concept ${\cal C}^S$ and the target concept ${\cal C}^T$
are ``apples'' and  ``Mary's cheeks'' shown in Figure\,\ref{fig:apple}.
The result of calculating $salience(P^S_i)$ by Equations\,(\ref{eqn:salience})
and (\ref{eqn:AIP}) is shown in Figure\,\ref{fig:example}\,(a).
If we assume $C_{sl}=0.1$, among seven properties
two properties are dropped at line\,2 of Figure\,\ref{fig:subalgo} 
because of their low salience. 
Thus the algorithm outputs the set $S_0$ shown in Figure\,\ref{fig:example}\,(b).

\subsection{Finding mappable features}
The algorithm {\it FindLiteral\/} takes as input the two sets ${\cal C}^T$ and $S_0$
and finds the literally transferable features of the source concept 
from salient ones (elements of $S_0$) at line\,5 of Figure\,\ref{fig:subalgo}.
These transferable features are stored in $S_1$ at line\,6.
Intuitively, if the attribute $a^S_i$ is possessed by the target concept and 
its value $v^{*S}_i$ is included in the value set for that attribute of
the target, the feature $a^S_i\!:\!v^{*S}_i$ is found to be literally transferable.
In particular, the second condition for being literally transferable 
(i.e., inclusion in the value set ${\cal V}^T_j$) says that 
empirically unobservable values should not be highlighted in the target properties,
though salient in the source properties.
In other words, empirically observable features of the target concept impose 
a constraint on metaphor interpretation in order to avoid many arbitrary mappings of features. 
\footnote{
  For example, in interpreting the metaphor ``Mary's cheeks are brown apples''
  the algorithm does not select the salient feature ``color:brown'' as literally 
  transferable one since the value set for color of ``Mary's cheeks'' does not include ``brown''.
  In this case, which value is highlighted for color is determined by the ASM algorithm.}
This condition is also applied to selection of metaphorically mappable features.
Also, lines\,7 and 9 divide ${\cal C}^T$ into two sets ${\cal C}^T_1$ and ${\cal C}^T_2$.
Since the features in $S_1$ cannot be mapped onto any properties in ${\cal C}^T_2$,
mappable features for these properties should be searched for by the ASM method.

The algorithm {\it ASM\/} of Figure\,\ref{fig:subalgo} 
takes as input the two sets $S_0$ and ${\cal C}^T_2$,
finds the mappable features which are metaphorically 
related to the salient features of the source concept (i.e., elements in $S_0$)
by the ASM method,
and it produces a set $S_2$ of metaphorically mappable features 
for the properties in ${\cal C}^T_2$.
Line\,13 of the algorithm {\it ASM\/} calculates the degree of similarity $d_{ijk}$
of each salient feature $a^S_j\!:\!v^{*S}_j$ of the source concept to 
all empirically observable features $a^T_i\!:\!v_{ik}$ for each attribute
$a^T_i$ in ${\cal C}^T_2$ using Equation\,(\ref{eqn:distance}). 
Line\,14 then selects the most similar feature among possible ones
as a metaphorically mappable feature (candidate feature), 
and it is stored in $S_2$ by lines\,15-19. 
The degree of preference for the feature is high
to the extent that its degree of similarity is high and 
it does not exceed the source feature's salience.
When $S_2$ already includes the same feature $a^T_i\!\!:\!v^T_{il}$
(i.e., count$[l]>0$), its degree of preference
is added at line\,18 and then averaged by line\,22.

In the case of the metaphor (\ref{sentence:apple}), 
since the concept ``Mary's cheeks'' has neither ``juiciness'' nor ``taste'', 
the other three properties are selected as literally transferable properties 
at line\,5 of the algorithm {\it FindLiteral}.
Thus lines\,6-9 obtain the three sets shown in Figure\,\ref{fig:example}\,(c).
The algorithm {\it ASM\/} then
decides which features for the attributes ``hardness'',
``freshness'' and ``healthiness'' in ${\cal C}^T_2$ 
are the most metaphorically related to each salient feature in $S_0$. 
For example, let us consider the case that line\,10 of the algorithm {\it ASM\/}
processes the property healthiness:\{healthy:0.50, unhealthy:0.50\}.
When $a_j$ is color at line\,12, since the degree of similarity between ``color:red'' 
and ``healthiness:healthy'' (0.76) is higher than that between 
``color:red'' and ``healthiness:unhealthy'' (0.67), 
line\,14 selects ``healthiness:healthy''
as the most metaphorically mappable feature, as illustrated in Figure\,\ref{fig:ASM}.
\begin{figure}[t]
  \begin{center}
    \makeatletter\ifDS@epsbox
    \epsfile{file=Fig/ASM.epsf,scale=0.52}
    \else
    \mbox{\psfig{figure=Fig/ASM.epsf,width=12.5cm}}
    \fi\makeatother
  \end{center}
  \caption{The process of affective-similarity-based mapping}
  \label{fig:ASM}
\end{figure}
Its degree of preference is calculated as 
$salience(\mbox{color:\{red:0.95,green:0.05\}}) \times similarity(\mbox{color:red},
\mbox{healthiness:healthy})) = 0.64 \cdot 0.76 = 0.49$
and the candidate feature (healthiness:healthy, 0.49) is added to $S_2$ by line\,16.
When $a_j$ is juiciness or texture, line\,14 also selects ``healthiness:healthy'' and 
line\,18 replaces (healthiness:healthy, 0.49) by (healthiness:healthy, 0.96)
in which the degree of preference is given by $0.49+0.40\cdot(1.0-0.17)+0.14\cdot(1.0-0.0)$.
After that, its value of preference becomes $0.96/3=0.32$ at line\,22
since three salient features of the source concept select
the feature ``healthiness:healthy''.
In the same way, only one feature ``taste:sour-sweet'' selects ``healthiness:unhealthy'' 
as shown in Figure\,\ref{fig:ASM}, and (healthiness:unhealthy, 0.08) is added to $S_2$.
The same process is done for the other two attributes ``hardness'' and ``freshness''
and as a result, the algorithm {\it ASM\/} obtains the set $S_2$ 
in Figure\,\ref{fig:example}\,(d).

\subsection{Modifying the target concept} \label{subsec:modify}
The algorithm {\it ModifyTarget\/} receives three sets ${\cal C}^T$,
$S_1$, $S_2$, and produces the modified target concept ${\cal C}^{T/S}$.
Before modifying the target, line\,26 checks
 whether the degree of preference for each candidate feature in $S=S_1 \cup
S_2$ exceeds a threshold $C_{pref}$. Any features whose preference values
are less than the threshold are removed from $S$.
Then, the target properties are modified at lines\,27-30: 
if $S$ includes some features that are mappable to a property $P^T_i$
(i.e., $Q_i$, a set of candidate features whose attribute is $a^T_i$, is not empty),
the feature with the maximum preference among them is mapped onto $a^T_i$.
As a result, line\,30 highlights the corresponding value of $P^T_i$ 
by changing its probability to 1
and also downplays other values by changing their probabilities to 0.

In comprehending (\ref{sentence:apple}), assuming $C_{pref} = 0.10$,
one candidate feature ``healthiness:\ unhealthy'' is removed from $S$ at line\,26.
Out of them, six features are transferred to the target concept;
``freshness:old'' and ``hardness:hard'' are not transferred
because other features of the same attributes included in $S$
``freshness:fresh'' and ``hardness:soft'' have greater preference.
As a result, the algorithm produces the modified concept ${\cal C}^{T/S}$
``Mary's cheeks viewed from apples'' shown in Figure\,\ref{fig:example}\,(e)
as an interpretation of the metaphor (\ref{sentence:apple}).

\begin{figure}[t]
  \begin{center}
    \makeatletter\ifDS@epsbox
    \epsfile{file=Fig/knowledge.epsf,scale=0.4}
    \else
    \mbox{\psfig{figure=Fig/knowledge.epsf,width=12.5cm}}
    \fi\makeatother
    
  \end{center}
  \caption{\SNAME's internal representation of concepts}
  \label{fig:knowledge}
\end{figure}

\subsection{{\sfb PROMIME}: A prototype system based on our model} \label{sec:system}
The computational model of comprehending attributional metaphors
proposed in the preceding sections has been implemented in a computer
program called \SNAME\/ consisting of approximately 3,000 lines of C code. 
The \SNAME\/ system processes attributional metaphors 
written in Japanese and displays probabilistic representations
of their modified concepts.  The reader should note that this system
can analyze only Japanese sentences now, but it does not process any
information peculiar to Japanese sentences. Hence the program can be
easily modified to interpret English sentences.

The knowledge representation of concepts used in \SNAME\/ has a
frame-based structure on the basis of the definition of a concept.
Each concept is linked to its possible attributes with their
probabilities, and each attribute is represented as a two-dimensional
space along with its possible values. 
\SNAME\/ has the knowledge of 36 concepts and 487 features.
Figure\,\ref{fig:knowledge} illustrates
\SNAME's internal representation of the concepts ``apple'' and
``cheek''. As shown in Figure\,\ref{fig:knowledge},
concepts are hierarchically structured in the \SNAME\/ system and 
this taxonomic structure enables the system to inherit several attributes.

\SNAME\/ receives a Japanese sentence
--- e.g., ``{\it Mary no hoo wa ringo da}'',
Japanese version of the metaphor (\ref{sentence:apple}) ---,
and decomposes the sentence into the source concept 
(e.g., {\it ringo} (apples)) and the target concept 
(e.g., {\it Mary no hoo} (Mary's cheeks)) 
by a simple parser.
After constructing the representations of the source and the target
concepts, \SNAME\/ interprets the metaphor according to the
comprehension algorithm for attributional metaphors described in
Sections\,\ref{subsec:metaphor-model}-\ref{subsec:modify}. 

\section{Testing the System} \label{sec:psycho}
A test of the metaphor comprehension algorithm (and especially the ASM method)
described in this section is to examine to what degree the system's performance 
on metaphor comprehension can approach human performance.
In order to test the system, we collected data needed by the \SNAME\/ system 
through two experimental sessions, collected human interpretations of 
attributional metaphors by a psychological experiment, generated interpretations
of the same metaphors by the \SNAME\/ system, 
and then compared the system's interpretations with human interpretations.
All the experimental procedures were carried out in Japanese 
although materials and results are presented in English in the
following description of this paper.
We also add italicized Japanese expressions in parentheses.

\subsection{Metaphors used for the test} \label{subsec:material}
The metaphors used for testing the algorithm are 20 attributional metaphors
of the form ``X is Y'' ({\it X wa Y da}). 
They are generated by combining 10 Japanese noun concepts ---
sea ({\it umi}), fire({\it hi}), stone ({\it ishi}), ice ({\it koori}), 
cloud ({\it kumo}), wave ({\it nami}), flower ({\it hana}), dog ({\it inu}), 
glass ({\it garasu}), mirror ({\it kagami}) ---
used as a source concept (Y) with two Japanese nouns ---
personality ({\it seikaku}), love ({\it ai}) ---
as a target concept (X).
The 10 nouns used as the source are taken from a list of nouns 
that are most frequently used as source concepts of Japanese literary 
metaphors collected in the dictionary of metaphors \cite{Nakamura77}. 
The two nouns used as the target concept are very suitable for 
testing the validity of the ASM method for the following reasons:
1) since they are neutral concepts, interpretations of the metaphors 
generated by them directly reflect the performance of the ASM method, 
2) they can be modified by various features, and 
3) the metaphors generated by them are easy for subjects to evaluate.

\subsection{Overall test procedure} \label{subsec:test}
In order to generate interpretations of metaphors by \SNAME, 
we must give the following data:
\begin{enumerate}
  \renewcommand{\theenumi}{}
  \renewcommand{\labelenumi}{}
\item source concept ${\cal C}^S$ (the 10 nouns) --- \\[-.5ex]
  \hspace*{3ex}property $P_i$ (attribute $a_i$, its probabilized value set $V_i$), 
  distinctiveness $d_i$
\item target concept ${\cal C}^T$ (the two nouns)
\item two-dimensional configurations for their attributes.
\end{enumerate}
Data\,1 (source concepts) and 2 (target concepts) 
were obtained by the following experimental procedure.
For Data\,1, 14 human subjects (Japanese graduate students)
were asked to generate their own list of features 
possessed by each of the 10 noun concepts listed above, and
to rate the typicality of each listed feature.
The ratings were made on a 3-point scale 
($3=$ extremely typical, $2=$ quite typical, $1=$ slightly typical).
For Data\,2, the same subjects were asked to write down 
their own list of features for the two noun concept and 
the 20 attributional metaphors described in Section\,\ref{subsec:material}.
The metaphors were also presented in simile form ``Y-like X'' 
to comprehend metaphors more easily.
\footnote{
  Although similes differ from metaphors in that they contain an explicit 
  comparative term such as ``like'', their interpretation processes are 
  highly similar \cite{Reynolds80}. Thus we can safely say that 
  the result of interpretation is not affected by this difference.}
The order of these materials was randomly determined for each subject. 
The subjects were not screened from each other, 
but widely separated in their seating arrangement.
The instructions were similar to those used by \citeA{Rosch75}.
From the result of the lists and their ratings, 
we then estimated which properties are observed in the source and the target concepts.
For the source, we also estimated the probabilities of attribute values and
the degrees of distinctiveness.
The estimation results of the 10 source concepts is shown in Table\,\ref{tbl:concepts} 
in Appendix\,A.
Further details of the estimation procedure are also described in Appendix\,A.
The result of the two target concept was that 
subjects judged that the concepts ``personality'' and ``love'' 
need 35 and 19 possible properties for interpreting the metaphors, respectively.
All these properties are listed in Table\,\ref{tbl:metaphor-free} of Appendix\,A.

All generated features were rated by another group of 24 subjects 
in order to get the two-dimensional configurations.
More precisely, the materials used were 137 Japanese adjectives that name
generated features and each adjective was paired with the neutral noun
denoting its attribute, such as {\it akai iro} (red color) or 
{\it hiroi basho} (broad space).
The subjects were asked to rate 137 adjective-noun phrases on 
the following two 7-point semantic differential scales.
\begin{center}
  \footnotesize
  \begin{tabular}{l|p{5mm}|p{5mm}|p{5mm}|p{5mm}|p{5mm}|p{5mm}|p{5mm}|l}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{extremely} & \multicolumn{1}{c}{quite} & \multicolumn{1}{c}{slightly} & \multicolumn{1}{c}{neither} & \multicolumn{1}{c}{slightly} & \multicolumn{1}{c}{quite} & \multicolumn{1}{c}{extremely} & \\ \cline{2-8}
    pleasant & & \multicolumn{1}{c|}{$\bigcirc$} & & & & & & unpleasant \\ \cline{2-8}
    intense & & & & & \multicolumn{1}{c|}{$\bigcirc$} & & & subdued \\ \cline{2-8}
  \end{tabular}
  \vspace*{.5\baselineskip}
\end{center}
Before rating, the subjects were instructed that they can easily evaluate the
degree of intensity by regarding this scale as the degree of activeness of the whole phrase.
For each phrase, we calculated the average ratings of two scales.
These real values were used as data for the two-dimensional
configurations of the attributes in the \SNAME\/ system.

Then, we corrected human interpretations through a psychological experiment.
Before the experiment, 
we removed from the materials for evaluation of the algorithm
attributional metaphors in which 
more than 40\% of the features mentioned by the subjects were eliminated
by the preprocessing for Data\,1 and 2.
By this selection, we selected 15 metaphors as the materials.
Removed metaphors are: 
``Love is the waves''(60.0\%), ``Love is
a dog''(51.1\%), ``X's personality is a mirror''(50.0\%), ``X's personality is
a dog''(45.2\%), and ``Love is a mirror''(41.9\%). 
It seems reasonable to suppose that these five sentences, in which a large
percentage of the mentioned features are eliminated, are anomalies, not metaphors.
These 15 metaphors were rated on 7-point semantic differential scales by 24 human subjects.
Each scale for rating consists of properties generated by the procedure for Data\,2.
Thus each ``personality'' metaphor has 35 scales to rate and 
each ``love'' metaphor has 19 scales.
Then we calculated the average ratings of all properties for the 15 metaphors, 
and picked up properties that were statistically significant ($p<.05$) by a t-test.
As a result, 86 properties out of 413
(35 properties $\times$ 8 metaphors + 19 properties $\times$ 7 metaphors)
for the 15 metaphors were selected as significant.
For each metaphor, these significant properties constitute a new concept ${\cal C}^{T/S}$ 
that resulted from subjects' interpretation, which is listed in 
Table\,\ref{tbl:significance} in Appendix\,B.
Further details of the experiment are described in Appendix\,B.

Finally, we made a computer experiment in which 
the \SNAME\/ system interpreted the 15 metaphors and generated 
15 new concepts ${\cal C}^{T/S}$.
The date given to the system are 
attribute-value representation of 10 noun concepts in Table\,\ref{tbl:concepts},
properties of two noun concepts in Table\,\ref{tbl:metaphor-free},
and two-dimensional configurations of the attributes for interpreting the 15 metaphors.
It must be noted that since values (features) in \SNAME\/ are
represented by conceptual primitives, the correspondence between two
different meanings expressed by one adjective 
are not literally but figuratively constructed by the ASM method.
Furthermore, in order to provide empirical evidence of the performance of the ASM method, 
we made a comparison between the \SNAME\/ system and a random system in which 
the algorithm {\it ASM\/} at line\,4 of Figure\,\ref{fig:algo}
is replaced by a random algorithm.
A random algorithm first creates candidate features (elements in $S_2$)
by randomly choosing one value for each attribute in ${\cal C}^T_2$, and then 
attaches to the created features the degree of preference randomly taken from 
a population with the distribution of \SNAME's generated preference for each $C_{sl}$.

\subsection{Evaluation of the {\sfb PROMIME} system}

\begin{table}[t]
  \caption{Correlation table for evaluation} \label{tbl:matrix}
  \begin{center}
    \small
    \begin{tabular}{|l|c|c|} \hline
      & Significant ($p<.05$) & Not significant\\ \hline
      Generated by the system & $a$ & $b$ \\ \hline
      Not generated by the system & $c$ & $d$ \\ \hline\hline
      Total & $86$ & $327(=413-86)$\\ \hline
    \end{tabular}
  \end{center}
\end{table}

To evaluate the performance of our algorithm, 
we use the following measures:
{\small
\[
\begin{array}{lll}
  \displaystyle
  \mbox{Recall} ~=~ \frac{a}{a+c} \cdot 100 ~(\%), & 
  \displaystyle
  \mbox{Precision} ~=~ \frac{a}{a+b} \cdot 100 ~(\%), &
  \displaystyle
  \mbox{Fallout} ~=~ \frac{b}{b+d} \cdot 100 ~(\%). \\
\end{array}
\]}
The value $a$ represents the number of significant properties whose features
are generated by the \SNAME\/ system or a random system 
(i.e., the number of correct acceptances), and
$c$ the number of significant properties whose features are not generated 
by the system (i.e., the number of false rejections). 
Likewise the value $b$ represents the number of non-significant properties whose possible features are generated by the system (i.e., the number of false acceptances), and 
$d$ the number of non-significant properties no possible features of which 
are generated by the system (i.e., the number of correct rejections).
Thus when a significant property $P_i$ has a feature $a_i:v^{*}_i$ but
the system produced another (possible) feature for that property, we counted it as $c$.
Table\,\ref{tbl:matrix} represents 
the correlation between the properties in metaphorical interpretations
produced by \SNAME\/ and those independently derived from the subjects as a matrix.
An algorithm with perfect performance has 100\% recall and precision, and 0\% fallout.
Generally, however, recall is inversely related to precision:
decreasing the number of false rejections $c$ increases the recall but
decreases precision.

\begin{table}[t]
  \caption{Recall, precision and fallout of the \SNAME\/ system and the random algorithm}
  \label{tbl:result}
  \begin{center}\small
    \begin{tabular}{|cc|cc|cc|cc|}\hline
      && \multicolumn{2}{c|}{Recall} & \multicolumn{2}{c|}{Precision} & \multicolumn{2}{c|}{Fallout}\\ \cline{3-8}
      \raisebox{1ex}[0pt]{$C_{sl}$} & \raisebox{1ex}[0pt]{$C_{pref}$} & 
      \SNAME & Random & \SNAME & Random & \SNAME & Random \\ \hline\hline
      0.0 & 0.0 & 70.93 & 49.98 (0) & 15.72 & 11.63 (0) & --- & --- \\
      0.0 & 0.1 & 66.28 & 45.98 (1) & 16.10 & 11.81 (0) & 90.83 & 90.22 (9460)\\
      0.0 & 0.2 & 60.47 & 37.92 (0) & 17.99 & 12.09 (0) & 72.48 & 72.44 (6394)\\
      0.0 & 0.3 & 24.42 & 12.38 (0) & 24.71 & 14.08 (8) & 19.57 & 19.80 (6254) \\ \hline\hline
      0.1 & 0.0 & 73.26 & 50.01 (0) & 16.15 & 11.60 (0) & --- & --- \\
      0.1 & 0.1 & 70.93 & 49.74 (0) & 15.72 & 11.60 (0) & 100.00 & 99.53 (10000) \\
      0.1 & 0.2 & 61.63 & 39.87 (0) & 17.21 & 11.91 (0) & 77.98 & 77.49 (9806) \\
      0.1 & 0.3 & 39.54 & 24.86 (2) & 18.38 & 12.31 (4) & 46.18 & 46.28 (5290) \\ \hline\hline
      0.2 & 0.0 & 70.93 & 46.55 (0) & 16.99 & 11.80 (0) & --- & --- \\
      0.2 & 0.1 & 70.93 & 46.55 (0) & 16.99 & 11.80 (0) & 91.13 & 91.13 (6385)\\
      0.2 & 0.2 & 70.93 & 46.55 (0) & 16.99 & 11.80 (0) & 91.13 & 91.13 (6385)\\
      0.2 & 0.5 & 44.19 & 20.77 (0) & 24.84 & 13.04 (0) & 35.17 & 36.18 (1170)\\ \hline
    \end{tabular}
  \end{center}
  Note: Each value within parentheses represents the number of occurrences in 10,000 trials
  that a random algorithm gets better recall/precision/fallout than the \SNAME\/ system.
\end{table}

The results of the comparison between the \SNAME\/ system and the random system 
are shown in Table\,\ref{tbl:result}.
In the table, the values of the three measures of the \SNAME\/ system and of
the random system are presented for 12 pairs of $C_{sl}$ and $C_{pref}$. 
All values of the random algorithm are the average scores over 10,000 trials.
Note that values of fallout for $C_{pref}=0.0$ make no sense since
the system does not reject any possible features at line\,26 of the algorithm {\it ModifyTarget}.
We have made the following observations on the evaluation results.
\begin{enumerate}
  \renewcommand{\theenumi}{}
  \renewcommand{\labelenumi}{}
  \addtolength{\itemsep}{-\parsep}
\item Recall and precision of the \SNAME\/ system are much higher 
  than those of a random algorithm for all $C_{sl}$ and $C_{pref}$.
  Also, while precision of a random algorithm is steady, 
  there is a tendency for precision of the system to increase as $C_{pref}$ increases.
  All these suggest that the \SNAME\/ system can attach higher 
  preference to significant features,
  and thus the system's performance on correct acceptance is satisfactory.
  Furthermore, the probability that the random algorithm gets an interpretation 
  closer to the human interpretation than the system's 
  is extremely small for these two metrics (only a few occurrences in 10,000 trials). 
  This shows that the system's scores are not close to the scores of the human judges 
  simply by chance.

\item When $C_{pref}$ is low (0.0 or 0.1), 
  the system achieves the highest recall at $C_{sl}=0.1$.
  This indicates an important role of low salience features:
  selection of metaphorically similar features in the ASM algorithm is not
  affected only by highly salient properties of the source concept, but
  interaction between properties of low and high salience leads to 
  more appropriate selection.
  However we note that when properties of very low salience are used for selection, 
  the system's performance becomes worse.

\item Fallout of the system does not differ from that of a random algorithm.
  This suggests that \SNAME\/'s performance on correct rejection of features 
  is much lower, in other words, the system does not have a sufficient ability to 
  attach lower preference to many properties that were not statistically significant.
\end{enumerate}

To sum up, the \SNAME\/ system's performance is significantly better than random performance
for recall and precision, but for fallout the system did not yield a satisfactory performance.
However, we still believe that the result of fallout does not weaken the validity of our method.
From the nature of metaphorical interpretation, 
exclusion of non-significant properties from interpretations of metaphors may not 
necessarily be a reasonable strategy.
In other words, we cannot draw a clear distinction of properties 
that must not be included in the metaphorically modified concept
since interpretations of metaphors are more divergent and less fixed 
than those of literal expressions.
It must also be noted that the ASM method is not a complete 
technique for comprehending metaphors.
For a complete interpretation of metaphors a hybrid model with various kinds of
knowledge may be required, which will be discussed in Section\,\ref{sec:discussion}.

\section{Discussion} \label{sec:discussion}
\subsection{Primitive Relations and Similarity Factor} \label{subsec:factor}
In the earlier sections, 
the two-dimensional affective structure is the only knowledge used for 
assessing the degree of similarity between different features in the ASM algorithm,
and we have shown that the ASM algorithm can yield plausible interpretations of
attributional metaphors.
Nevertheless, in order to get higher performance, especially for fallout,
we can consider utilizing some explicit knowledge called {\it primitive relations\/}
on the basis of the empirical observations:
(a) in cross-modal modifications of adjectives 
there is a tendency for phrases to be more acceptable 
when the adjectives denoting lower-modal features are combined 
with the nouns denoting higher-modal contents 
(e.g., ``dark voice'' is more easily understood than ``loud color'')
\cite{Kusumi88}; and 
(b) features representing different senses of one adjective
are more related than that representing different senses of 
different adjectives.
A primitive relation ``{\tt\#}$B$$\Rightarrow${\tt\#}$T$''
consists of a base primitive {\tt\#}$B$ on an attribute $a^B$
and a target primitive {\tt\#}$T$ on a different attribute $a^T$,
and it means that a feature $a^B\!:\!B$ is metaphorically mappable into
$a^T\!:\!T$.
For example, when the relation ``{\tt\#}{\it green\/}$\Rightarrow${\tt\#}{\it inexperienced\/}''
is applied to the metaphor ``Peter is a green apple'',
we can interpret it as ``Peter is an inexperienced guy''.

In order to utilize such primitive relations, 
the ASM method can be extended in such a way that 
line\,13 in the algorithm {\it ASM\/} of Figure\,\ref{fig:subalgo} is replaced by 
\begin{center}
  \small
  $d_{ijk} \leftarrow f(\alpha(a^S_j\!:\!v^{*S}_j,\,a^T_i\!\!:\!v^T_{ik}) 
  \times similarity(a^S_j\!:\!v^{*S}_j,\,a^T_i\!\!:\!v^T_{ik}))$ where 
  $f(x) = \cases{ 1 & ($x \geq 1$) \cr x & (otherwise) \cr }$
\end{center}
using similarity factor $\alpha$ attached to each primitive relation.
Primitive relations whose similarity factor is greater than 1 represent
positive relations, but primitive relations whose similarity factor is less than 1
represent negative relations that a base primitive is metaphorically 
dissimilar to a target primitive.
When $a^S_j\!:\!v^{*S}_j$ does not bear a primitive relation to $a^T_i\!\!:\!v^T_{ik}$,
we assume $\alpha(a^S_j\!:\!v^{*S}_j,\,a^T_i\!\!:\!v^T_{ik})=1$.
These primitive relations can capture some of conventional metaphors such as 
\citeauthor{Lakoff80}'s\citeyear[page 58]{Lakoff80} notion of orientational metaphorical concepts
(e.g., ``HAPPY IS UP'').
The use of negative relations can also reduce false acceptance of properties/features,
and consequently we expect it can improve the system's performance for fallout and precision.

\subsection{Related work} \label{subsec:work}
In this section, in order to clarify the originality of our study,
we compare our approach to related work offering a viewpoint 
on the metaphoric nature of feature mapping.

First we compare our study with other studies on the comprehension of
attributional metaphors \cite{Ortony79,Weiner84,Iwayama90,Weber91}.
Although the details of each model differ, they all share a
common framework in which concepts are represented as prototype-like
structures and some of their features/properties are selected to be
transferred to the target concept. 
However, most of these models have no methods for 
{\it evoking\/} features that metaphorically
relate to salient features of the source concept. 
The ability to construct both literal and figurative
correspondences is the main advantage of our model.  
\citeauthor{Weber91}'s\citeyear{Weber91} model of metaphorical adjective-noun 
combinations uses two methods for constructing figurative correspondences:
direct value transference and scalar correspondence.
The direct value transference method uses 
the explicit knowledge of the empirically observed relations between atttibute values,
and thus corresponds to 
our inference method based on primitive relations mentioned in Section\,\ref{subsec:factor}.
The scalar correspondence method exploits the scalar nature of many properties; 
quantitative properties such as size, weight, and density 
tend to impose a natural scalar ordering on their values. 
Thus Weber's scalar correspondence method can be seen as a scalar version of the ASM
method. However, we would like to emphasize that the advantages of our ASM method are that
(a) the ASM method can apply to many more features, especially the affective
features, that play an important role in comprehending metaphors; and
(b) the ASM method is founded on affective-similarity-based structures, for which
there is independent psychological evidence.

Secondly, the same argument can be done about computational studies 
\cite{Falkenhainer86,Indurkhya87,Fass91,Martin92}
of relational metaphors whose interpretations 
are characterized by relational/structural similarities of concepts.
These models permit no correspondences between different but similar predicates, 
and this constraint seems to be too strong to explain how metaphors are interpreted.

Finally, we must mention a phenomenon which seems to be explained in the ASM approach: 
the interaction among correlated features in a concept. 
\citeA{Medin88} demonstrated that in comprehending an adjective-noun combination,
features/attributes directly modified by the adjective affected
their correlated features/attributes. For example, in interpreting
the phrase ``green apple'', not only does the value of the attribute
``color'' change to the feature ``green'' from the most probable value ``red''
of apple, but also the value of the attribute ``taste'' may change to ``sour'' 
from ``sour-sweet''.  This kind of indirect change
can be explained as follows: the feature ``green'' is
not only transferred to ``apple'', but also metaphorically mapped onto
the attribute ``taste'' of ``apple''. 
It remains an unsettled question whether these emergent features 
result from the figurative mapping of
the adjective's features or result from the interaction between the
correlated attributes in a target concept.

\subsection{Limitations of the ASM method} \label{sec:limitations}
It is worth discussing one of crucial limitations of the ASM method as a guide 
for future work.
There is a problem of relational metaphors as opposed to attributional metaphors.  
Our modeling considered only attributional
metaphors, in other words, those cases where interpretations of
metaphors are dominated mainly by features/attributes. 
\citeA{Gentner88} suggest that people seek relational 
interpretations of metaphors and prefer metaphors for which such
interpretations can be found, though we do not necessarily agree with
this suggestion. This limitation of our model arises from its
representation of concepts and the mechanism for metaphorical mapping.

Concerning the representational issue, the attribute-value
representation consisting of sets of features is not at all sufficient
for dealing with relational metaphors.  However, it is also true that
the existing approaches to relational metaphors described in Section\,\ref{subsec:work} 
cannot deal with the metaphoric nature of 
feature mapping that plays an important role in understanding and appreciating
attributional metaphors.  Hence a hybrid model with various kinds of
knowledge is required to overcome this difficulty.  One of
possibilities is \citeauthor{Lakoff87}'s\citeyear{Lakoff87} model of hybrid knowledge
organization called {\it idealized cognitive models}. Each
cognitive model is composed of four kinds of knowledge structure: 
propositional structure, image-schematic structure, metaphoric mappings, 
and metonymic mappings. Among these, the propositional structure covers
the feature-based and the relational representations of its concept
and the metaphoric mappings correspond to explicit knowledge about
conventional metaphors.  This knowledge structure is potentially rich
enough to model complete interpretations in any kind of metaphor.

Concerning the issue of the mechanism for metaphorical mapping, 
any complete interpretation of 
metaphors requires a certain mechanism for analogical reasoning (e.g.,
\citeauthor{Gentner83}'s\citeyear{Gentner83} structure mapping theory). 
At the same time, any mechanism of analogical reasoning requires a certain method for
constructing figurative correspondences between metaphorically similar
predicates as \citeA{Suwa91} have argued.  Although the ASM method
proposed in this paper cannot support the analogical reasoning for
relational metaphors, it might be useful for constructing figurative
correspondences in analogical reasoning.

To sum up, any computational model for comprehending any kind of
metaphors should have a well-structured organization of various kinds
of knowledge including both features (attributes) and predicates
(relations), and an effective method for constructing both literal and
figurative correspondences of features and relations between concepts.

\section{Concluding Remarks} \label{sec:conclusion}
In this paper, we have proposed the affective-similarity-based method
for constructing figurative correspondences between features 
in the non-overlapping domains of constituent concepts of metaphors,
and an algorithm for comprehending attributional metaphors.

This paper is devoted to the metaphoric nature of feature
mappings in comprehending attributional metaphors, which is the
original contribution of this paper.  A metaphor is an effective way
of describing an unknown or incompletely known object 
as another widely known object.  Thus,
emergent features that cannot be shared by the source and the target
are essential to metaphor. The shared feature approach cannot
account for this essential phenomenon of a metaphor because they
assume that the target's features are given.  Affective similarity
is an important source of metaphorically evoked features and
characterizes a metaphor. 

Another significant point we have addressed in this paper is the wide
application of psychological results to computational studies.  
Our claim on the importance of the process of constructing metaphorical 
correspondences is psychologically supported by many notable studies
\cite{Osgood80,Tourangeau82,Kusumi88,Tourangeau91}.
The two-dimensional affective structure upon which the ASM method is based 
also exploits the psychological results. 
Furthermore, our computational model of metaphor is psychologically validated 
by our experimental results in a direct fashion; 
interpretations of metaphors generated by the system are significantly close 
to human interpretations.
Our algorithm proposed in this paper is the first computational model of metaphor
directly supported by psychological results and evaluated by quantitative analysis.

We are extending our metaphor comprehension algorithm and the ASM method 
to cover wider metaphors, considering problems discussed in Section\,\ref{sec:discussion}.


\begin{thebibliography}{}

\bibitem[\protect\BCAY{Asch}{Asch}{1955}]{Asch55}
Asch, S. \BBOP 1955\BBCP.
\newblock \BBOQ On the use of metaphor in the description of persons\BBCQ\
\newblock In Werner, H.\BED, {\Bem On Expressive Language}. Worcester: Clark
  University Press.

\bibitem[\protect\BCAY{Becker}{Becker}{1997}]{Becker97}
Becker, A. \BBOP 1997\BBCP.
\newblock \BBOQ Emergent and common features influence metaphor
  interpretation\BBCQ\
\newblock {\Bem Metaphor and Symbol}, {\Bem 12\/}(4), 243--259.

\bibitem[\protect\BCAY{Falkenhainer, Forbus, \BBA\ Gentner}{Falkenhainer
  et~al.}{1986}]{Falkenhainer86}
Falkenhainer, B., Forbus, K., \BBA\ Gentner, D. \BBOP 1986\BBCP.
\newblock \BBOQ The structure-mapping engine: algorithm and examples\BBCQ\
\newblock {\Bem Artificial Intelligence}, {\Bem 41}, 1--63.

\bibitem[\protect\BCAY{Fass}{Fass}{1991}]{Fass91}
Fass, D. \BBOP 1991\BBCP.
\newblock \BBOQ Met*: A method for discriminating metonymy and metaphor by
  computer\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bem 17}, 49--90.

\bibitem[\protect\BCAY{Fass, Hinkelman, \BBA\ Martin}{Fass
  et~al.}{1991}]{IJCAI91}
Fass, D., Hinkelman, E., \BBA\ Martin, J.\BEDS. \BBOP 1991\BBCP.
\newblock {\Bem Proceedings of the IJCAI Workshop on Computational Approaches
  to Non-Literal Language: Metaphor, Metonymy, Idioms, Speech Acts,
  Implicature}.

\bibitem[\protect\BCAY{Gentner}{Gentner}{1983}]{Gentner83}
Gentner, D. \BBOP 1983\BBCP.
\newblock \BBOQ Structure mapping: a theoretical framework for analogy\BBCQ\
\newblock {\Bem Cognitive Science}, {\Bem 7}, 155--170.

\bibitem[\protect\BCAY{Gentner \BBA\ Clement}{Gentner \BBA\
  Clement}{1988}]{Gentner88}
Gentner, D.\BBACOMMA\  \BBA\ Clement, C. \BBOP 1988\BBCP.
\newblock \BBOQ Evidence for relational selectivity in the interpretation of
  analogy and metaphor\BBCQ\
\newblock In Bower, G.\BED, {\Bem The Psychology of Learning and Motivation,
  Vol.22}. NewYork: Academic Press.

\bibitem[\protect\BCAY{Indurkhya}{Indurkhya}{1987}]{Indurkhya87}
Indurkhya, B. \BBOP 1987\BBCP.
\newblock \BBOQ Approximate semantic transference: A computational theory of
  metaphors and analogies\BBCQ\
\newblock {\Bem Cognitive Science}, {\Bem 11}, 445--480.

\bibitem[\protect\BCAY{Iwayama, Tokunaga, \BBA\ Tanaka}{Iwayama
  et~al.}{1990}]{Iwayama90}
Iwayama, M., Tokunaga, T., \BBA\ Tanaka, H. \BBOP 1990\BBCP.
\newblock \BBOQ A method of calculating the measure of salience in
  understanding metaphors\BBCQ\
\newblock In {\Bem Proceedings of the Eighth National Conference on Artificial
  Intelligence}, \BPGS\ 298--303.

\bibitem[\protect\BCAY{Kusumi}{Kusumi}{1987}]{Kusumi87}
Kusumi, T. \BBOP 1987\BBCP.
\newblock \BBOQ Effects of categorical dissimilarity and affective similarity
  between constituent words on metaphor appreciation\BBCQ\
\newblock {\Bem Journal of Psycholinguistic Research}, {\Bem 16}, 577--595.

\bibitem[\protect\BCAY{Kusumi}{Kusumi}{1988}]{Kusumi88}
Kusumi, T. \BBOP 1988\BBCP.
\newblock \BBOQ Comprehension of synesthetic expressions: Cross-modal
  modifications of sense adjectives\BBCQ\
\newblock {\Bem The Japanese Journal of Psychology}, {\Bem 58}, 373--380.
\newblock (in Japanese).

\bibitem[\protect\BCAY{Lakoff}{Lakoff}{1987}]{Lakoff87}
Lakoff, G. \BBOP 1987\BBCP.
\newblock {\Bem Women, Fire, and Dangerous Things: What Categories Reveal about
  the Mind}.
\newblock Chicago: University of Chicago Press.

\bibitem[\protect\BCAY{Lakoff \BBA\ Johnson}{Lakoff \BBA\
  Johnson}{1980}]{Lakoff80}
Lakoff, G.\BBACOMMA\  \BBA\ Johnson, M. \BBOP 1980\BBCP.
\newblock {\Bem Metaphors We Live By}.
\newblock Chicago: The University of Chicago Press.

\bibitem[\protect\BCAY{Martin}{Martin}{1992}]{Martin92}
Martin, J. \BBOP 1992\BBCP.
\newblock \BBOQ Computer understanding of conventional metaphoric
  language\BBCQ\
\newblock {\Bem Cognitive Science}, {\Bem 16}, 233--270.

\bibitem[\protect\BCAY{Medin \BBA\ Shoben}{Medin \BBA\ Shoben}{1988}]{Medin88}
Medin, D.\BBACOMMA\  \BBA\ Shoben, E. \BBOP 1988\BBCP.
\newblock \BBOQ Context and structure in conceptual combination\BBCQ\
\newblock {\Bem Cognitive Psychology}, {\Bem 20}, 158--190.

\bibitem[\protect\BCAY{Nakamura}{Nakamura}{1977}]{Nakamura77}
Nakamura, A. \BBOP 1977\BBCP.
\newblock {\Bem Hiyu Hyogen Jiten (Japanese dictionary of metaphorical
  expressions)}.
\newblock Tokyo: Kadokawa Shoten.
\newblock (in Japanese).

\bibitem[\protect\BCAY{{National Language Research Institute}}{{National
  Language Research Institute}}{1964}]{Bunrui}
{National Language Research Institute}\BED. \BBOP 1964\BBCP.
\newblock {\Bem Bunrui Goi Hyo (Word List by Semantic Principles)}.
\newblock Tokyo: Shuei Shuppan.
\newblock (in Japanese).

\bibitem[\protect\BCAY{Ortony}{Ortony}{1979}]{Ortony79}
Ortony, A. \BBOP 1979\BBCP.
\newblock \BBOQ Beyond literal similarity\BBCQ\
\newblock {\Bem Psychological Review}, {\Bem 86}, 161--180.

\bibitem[\protect\BCAY{Osgood}{Osgood}{1980}]{Osgood80}
Osgood, C. \BBOP 1980\BBCP.
\newblock \BBOQ The cognitive dynamics of synesthesia and metaphor\BBCQ\
\newblock In Honeck, R.\BBACOMMA\  \BBA\ Hoffman, R.\BEDS, {\Bem Cognition and
  Figurative Language}. Hillsdale, N.J.: Lawrence Erlbaum Associates.

\bibitem[\protect\BCAY{Osgood, Suci, \BBA\ Tannenbaum}{Osgood
  et~al.}{1957}]{Osgood57}
Osgood, C., Suci, G., \BBA\ Tannenbaum, P. \BBOP 1957\BBCP.
\newblock {\Bem The Measurement of Meaning}.
\newblock Urbana: University of Illinois Press.

\bibitem[\protect\BCAY{Reynolds \BBA\ Ortony}{Reynolds \BBA\
  Ortony}{1980}]{Reynolds80}
Reynolds, R.\BBACOMMA\  \BBA\ Ortony, A. \BBOP 1980\BBCP.
\newblock \BBOQ Some issues in the measurement of children's comprehension of
  metaphorical language\BBCQ\
\newblock {\Bem Child Development}, {\Bem 51}, 1110--1119.

\bibitem[\protect\BCAY{Rosch \BBA\ Mervis}{Rosch \BBA\ Mervis}{1975}]{Rosch75}
Rosch, E.\BBACOMMA\  \BBA\ Mervis, C. \BBOP 1975\BBCP.
\newblock \BBOQ Family resemblances: studies in the internal structure of
  categories\BBCQ\
\newblock {\Bem Cognitive Psychology}, {\Bem 7}, 573--605.

\bibitem[\protect\BCAY{Smith, Osherson, Rips, \BBA\ Keane}{Smith
  et~al.}{1988}]{Smith88}
Smith, E., Osherson, D., Rips, L., \BBA\ Keane, M. \BBOP 1988\BBCP.
\newblock \BBOQ Combining prototypes: A selective modification model\BBCQ\
\newblock {\Bem Cognitive Science}, {\Bem 12}, 485--527.

\bibitem[\protect\BCAY{Suwa \BBA\ Motoda}{Suwa \BBA\ Motoda}{1991}]{Suwa91}
Suwa, M.\BBACOMMA\  \BBA\ Motoda, H. \BBOP 1991\BBCP.
\newblock \BBOQ Learning metaphorical relationship between concepts based on
  semantic representation using abstract primitives\BBCQ.
\newblock In Fass et~al. \citeyear{IJCAI91}, \BPGS\ 123--131.

\bibitem[\protect\BCAY{Tourangeau \BBA\ Rips}{Tourangeau \BBA\
  Rips}{1991}]{Tourangeau91}
Tourangeau, R.\BBACOMMA\  \BBA\ Rips, L. \BBOP 1991\BBCP.
\newblock \BBOQ Interpreting and evaluating metaphors\BBCQ\
\newblock {\Bem Journal of Memory and Language}, {\Bem 30}, 452--472.

\bibitem[\protect\BCAY{Tourangeau \BBA\ Sternberg}{Tourangeau \BBA\
  Sternberg}{1982}]{Tourangeau82}
Tourangeau, R.\BBACOMMA\  \BBA\ Sternberg, R. \BBOP 1982\BBCP.
\newblock \BBOQ Understanding and appreciating metaphors\BBCQ\
\newblock {\Bem Cognition}, {\Bem 11}, 203--244.

\bibitem[\protect\BCAY{Utsumi, Hori, \BBA\ Ohsuga}{Utsumi
  et~al.}{1988}]{Utsumi93}
Utsumi, A., Hori, K., \BBA\ Ohsuga, S. \BBOP 1988\BBCP.
\newblock \BBOQ Meaning representation of adjectives for natural language
  processing\BBCQ\
\newblock {\Bem Journal of Japanese Society of Artificial Intelligence}, {\Bem
  8}, 192--200.
\newblock (in Japanese).

\bibitem[\protect\BCAY{Weber}{Weber}{1991}]{Weber91}
Weber, S. \BBOP 1991\BBCP.
\newblock \BBOQ A connectionist model of literal and figurative adjective noun
  combinations\BBCQ.
\newblock In Fass et~al. \citeyear{IJCAI91}, \BPGS\ 151--160.

\bibitem[\protect\BCAY{Weiner}{Weiner}{1984}]{Weiner84}
Weiner, E. \BBOP 1984\BBCP.
\newblock \BBOQ A knowledge representation approach to understanding
  metaphors\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bem 10\/}(1), 1--14.

\bibitem[\protect\BCAY{Weiner}{Weiner}{1985}]{Weiner85}
Weiner, E. \BBOP 1985\BBCP.
\newblock \BBOQ Solving the containment problem for figurative language\BBCQ\
\newblock {\Bem International Journal of Man-Machine Studies}, {\Bem 23},
  527--537.

\end{thebibliography}


\section*{Appendix\,A\hspace*{2ex}Estimation of the Concepts}
\paragraph{\it Preprosessing:}
First, for each noun, all features mentioned by subjects, excluding
illegible descriptions, were listed. Then two judges (who were not
subjects) inspected the resulting set of listed features and indicated
cases in which a feature was clearly and obviously false or inadequate
to characterize the noun concept. These features were deleted from the
lists.  The judges also indicated any features that intuitively seemed
to be the same values, or different values of the same attribute.  
If there was an agreement between the judges, these features were 
regarded as one feature or different values of the same attribute.  
When multiple features were classified into one feature,
one of the judges named this feature by consulting a thesaurus for
Japanese words \cite{Bunrui}. The number of votes for the new combined
feature was the sum of votes of the classified features.  
In all other cases, attributes of these features were regarded as different.  
(By these criteria 20\% and 31\% of the listed features for the source concepts
and the target concepts were deleted, respectively.)  
Furthermore, any feature that was mentioned by only one subject was 
eliminated from the list of selected features. 

\begin{table}[t]
  \caption{An estimation result of 10 noun concepts}
  \label{tbl:concepts}
  \footnotesize
  \begin{tabular}{l@{}l} \hline
    Concepts & \multicolumn{1}{c}{Properties (Distinctiveness)}\\ \hline
    Fire & temperature:\{hot:1.00\} (0.98), color:\{red:0.80,blue:0.10,yellow:0.10\} (0.36),\\
    & lightness:\{bright:1.00\} (0.26), severeness:\{severe:1.00\} (0.19),\\
    & fearfulness:\{fearful:1.00\} (0.12), safeness:\{dangerous:1.00\} (0.10),\\
    & movement:\{flickering:1.00\} (0.05)\\
    Ice & temperature:\{cold:1.00\} (0.93), texture:\{smooth:1.00\} (0.21),
    hardness:\{hard:1.00\} (0.21),\\
    & sharpness:\{sharp:1.00\} (0.17), beauty:\{beautiful:1.00\} (0.12), \\
    & transparency:\{transparent:1.00\} (0.12), taste:\{good:1.00\} (0.10), \\
    & color:\{white:0.67,light-blue:0.33\} (0.05), brittleness:\{brittle:1.00\} (0.05) \\
    Sea & color:\{blue:1.00\} (0.93), width:\{broad:1.00\} (0.83), depth:\{deep:1.00\} (0.83), \\
    & size:\{big:1.00\} (0.29), temperature:\{cold:1.00\} (0.19), taste:\{salty:1.00\} (0.14),\\
    & lightness:\{bright:1.00\} (0.12), beauty:\{beautiful:1.00\} (0.05)\\
    Stone & hardness:\{hard:0.93,soft:0.07\} (0.91), weight:\{heavy:1.00\} (0.26), \\
    & shape:\{round:0.70,rough:0.30\} (0.17), color:\{grey:0.75,white:0.25\} (0.12), \\
    & temperature:\{cold:0.67,hot:0.33\} (0.05), size:\{big:0.67,small:0.33\} (0.02)\\
    Cloud & color:\{white:0.86,grey:0.14\} (0.69), weight:\{light:1.00\} (0.24),
    touch:\{fleecy:1.00\} (0.19), \\
    & size:\{big:1.00\} (0.17), lightness:\{dark:1.00\} (0.17), 
    height:\{high:0.67,low:0.33\} (0.14), \\ & movement:\{dynamic:1.00\} (0.12)\\
    Flower & beauty:\{beautiful:1.00\} (0.86), smell:\{fragrant:1.00\} (0.31),
    size:\{small:1.00\} (0.14),\\
    & color:\{red:0.50,white:0.33,yellow:0.17\} (0.14), lightness:\{light:1.00\} (0.12)\\
    Glass & brittleness:\{brittle:1.00\} (0.43), transparency:\{transparent:1.00\} (0.36),\\
    & sharpness:\{sharp:1.00\} (0.36), hardness:\{hard:1.00\} (0.26), \\
    & temperature:\{cold:1.00\} (0.26), safeness:\{dangerous:1.00\} (0.10),\\
    & price:\{expensive:1.00\} (0.05), shape:\{flat:0.50,square:0.50\} (0.00),\\
    & lightness:\{light:0.50. dark:0.50\} (0.00)\\
    Wave & severeness:\{severe:0.62,calm:0.38\} (0.41), color:\{white:0.80,blue:0.20\} (0.18),\\
    & height:\{high:1.00\} (0.18), temperature:\{cold:1.00\} (0.10),
    size:\{big:0.75,small:0.25\} (0.07)\\
    Mirror & lightness:\{bright:1.00\} (0.50), hardness:\{hard:1.00\} (0.17),\\
    & temperature:\{cold:1.00\} (0.12), beauty:\{beautiful:1.00\} (0.12),\\
    & transparency:\{transparent:1.00\} (0.07), shape:\{round:0.50,flat:0.50\} (0.00)\\
    Dog & loveliness:\{cute:1.00\} (0.52), sound:\{loud:1.00\} (0.29), \\
    & size:\{big:0.50,small:0.50\} (0.00), cleverness:\{clever:0.50,foolish:0.50\} (0.00)\\
    \hline
  \end{tabular}
\end{table}

\paragraph{\it Estimation of the probability and the distinctiveness:}
The probability $p_{ij}$ of each value $v_{ij}$ for an attribute $a_i$
was calculated by (the number of votes of that value $v_{ij}$)$/$
(the sum of votes of any values belonging to the attribute $a_i$).
For example, as a typical value for the attribute ``color'' 
of the concept ``fire,'' 8, 1, and 1 subjects mentioned ``red,''
``blue,'' and ``yellow'' respectively.  The probabilities of the three
values are $0.8$, $0.1$, and $0.1$.
For the distinctiveness, we first calculated the average typicality ratings of all properties.
If only two values are listed for an attribute, one value's votes are 
assumed to be positive ones and another value's votes are assumed to be
negative ones.  When there are more than two listed values for the attribute, 
votes of the most probable value are assumed to be positive votes, 
and other values' votes are negative ones.  
The distinctiveness of a property is calculated by 
$\left|\mbox{the average typicality rating of that attribute}\right|/3.0$.
If all votes are positive, the probability of that value becomes 1.0, 
regardless of the degree of its ratings. 
However, if positive ratings are all ones, then the distinctiveness of 
that property is $1.0/3.0=0.33$.
This implies that although the property has the most probable value with its probability of 1.0, 
it is a less distinctive property of the concept.

\begin{table}[t]
  \caption{Properties of two noun concepts listed by the subjects}
  \label{tbl:metaphor-free}
  \footnotesize
  \begin{tabular}{l@{~~~}l} \hline
    \multicolumn{1}{c}{Concepts} & \multicolumn{1}{c}{Properties} \\ \hline 
    Personality &  probity:\{honest, dishonest\}, 
    obstinacy:\{obstinate, irresolute\},\\
    & obedience:\{obedient, disobedient\},
    nervousness:\{nervous, frank\}, \\
    & severity:\{severe, indulgent\}, 
    cheerfulness:\{cheerful, gloomy\},\\
    & eagerness:\{eager, listless\},
    kindness:\{warm, cold\},\\
    & temper:\{short-tempered, leisurely\},
    activeness:\{active, passive\},\\
    & tolerance:\{tolerant, intolerant\},
    will:\{strong-will, weak-will\},\\
    & delicateness:\{delicate, impudent\},
    seriousness:\{serious, unserious\},\\
    & moderateness:\{moderate, rough\},
    aggressiveness:\{aggressive, defensive\},\\
    & intelligence:\{clever, foolish\},
    thoughtfulness:\{thoughtful, thoughtless\},\\
    & showiness:\{showy, humble\},
    generosity:\{generous, stingy\},\\
    & excitability:\{violent, calm\},
    bravery:\{brave, cowardly\},\\
    & passion:\{passionate, passionless\},
    capriciousness:\{capricious, uncapricious\},\\
    & likableness:\{likable, dislikable\},
    toughness:\{tough, fragile\},\\
    & patience:\{patient, impatient\},
    carefulness:\{careful, careless\},\\
    & cleanliness:\{clean, dirty\},
     freedom:\{independent, dependent\},\\
    & vagueness:\{vague, clear\},
    beauty:\{beautiful, ugly\},\\
    & pureness:\{pure, impure\},
    reliability:\{reliable, unreliable\},\\
    & conservativeness:\{conservative, progressive\}\\
    Love & beauty:\{beautiful, ugly\}, heaviness:\{heavy, light\}, safety:\{safe, dangerous\}, \\
    & eternity:\{temporal, eternal\}, happiness:\{happy, unhappy\}, pureness:\{pure, impure\},\\
    & closeness:\{close, slight\}, sweetness:\{sweet, painful\}, maturity:\{mature, immature\},\\
    & breadth:\{broad, narrow\}, stability:\{stable, unstable\}, fragility:\{fragile, strong\},\\
    & cheerfulness:\{cheerful, gloomy\}, vagueness:\{vague, clear\}, warmth:\{warm, cold\}, \\
    & passion:\{passionate, passionless\}, severity:\{severe, unsevere\}, \\
    & showiness:\{showy, humble\}, blindness:\{blind, not-blind\}\\ \hline
  \end{tabular}
\end{table}

\section*{Appendix\,B\hspace*{2ex} Experiment of human interpretation}
\paragraph{\it Method} 
24 Japanese graduate students served as volunteer subjects. 
None of the subjects was familiar with the ASM method prior to the experiment.
They participated in this experiment after the rating task for two-dimentional
configurations.
The materials used were the 15 attributional metaphors described in 
Section\,\ref{subsec:test}.
Each subject was given a booklet that consisted of a page of
instructions followed by 15 additional pages, each of the latter
containing one of the 15 metaphors and their properties.
They were also presented in simile form ``Y-like X.'' 
The order of instances was randomly determined for each
subject.  For each metaphor, the subjects were asked to rate 
each listed properties on a 7-point scale at their own pace. 
For example, in the 7-point scale of ``probity: honest---dishonest,'' 
$3$ means extremely honest, $-3$ means extremely dishonest, and $0$ means neither. 
As a control, they were also asked to rate 35 properties of the concept 
``personality'' and 19 ones of the concept ``love'' 
when they are not modified by these metaphors.
The same instruction as in the rating task for two-dimentional 
configurations was given to the subjects.

\begin{table}[t]
  \caption{Significant features of 15 metaphors}\label{tbl:significance}
  \footnotesize
  \begin{tabular}{ll@{\extracolsep{\fill}}} \hline
    \multicolumn{1}{c}{Metaphors} & \multicolumn{1}{c}{Significant Features} \\
    \hline 
    X's personality is fire & passionate, short-tempered, aggressive, eager, 
    violent, active, \\
    & impatient, severe \\
    X's personarity is ice & cold, nervous, severe, gloomy, careful \\
    X's personarity is the sea & tolerant, leisurely, thoughtful, moderate, serious, pure,
    obedient*,\\ & generous* \\
    X's personarity is a stone & obstinate, strong-will, serious, severe, 
    careful, gloomy, cold* \\
    X's personarity is a cloud & independent, vague, capricious, moderate, tolerant, pure** \\
    X's personarity is a flower~~ & cheerful, showy, warm, 
    beautiful, likable, indulgent, honest* \\
    X's personarity is glass & delicate, severe, cold, gloomy, pure*, honest*, cowardly** \\
    X's personarity is the waves & violent, capricious, vague, tough, short-tempered, cold** \\
    Love is fire & passionate, dangerous, blind, temporary\\
    Love is ice & cold, dangerous, unhappy, passionless** \\
    Love is the sea & broad, close, beautiful, pure, eternal*, warm* \\
    Love is a stone & strong, humble \\
    Love is a cloud & vague, beautiful, light*, pure*, unstable* \\
    Love is a flower & beautiful, showy, cheerful, sweet, pure*, fragile* \\
    Love is glass & dangerous, cold, beautiful, fragile, pure* \\ \hline
  \end{tabular}
\end{table}

\paragraph{\it Results}
First, since one subject's ratings were incomplete (some properties were not rated), 
they were deleted from the list of ratings.
We then calculated a $t$-value of each property for the 15 metaphors by 
$t=|\mu_1-\mu_2|/\sqrt{V/n}$
where $\mu_1=\sum_{i=1}^{n}X_i/n$ is the average rating of the property for metaphors,
$\mu_2=\sum_{i=1}^{n}Y_i/n$ the average rating of the property when it is not modified,
$V=\sum_{i=1}^n\{(X_i-Y_i)-(\mu_1-\mu_2)\}^2/(n-1)$, 
and $n$ the number of subjects (in this case, $n=23$).
Then we picked up properties whose $t$-values were more than $t_{22}(0.05)=2.074$.
As a result, 86 properties of 413 ones were selected as significant. 
These significant values of the 15 metaphors are listed in Table\,\ref{tbl:significance}.
The order of values in each item of the table is determined by their
$t$ values. Unmarked values are significant ($p<.001$), values
marked with a single asterisk are less significant ($p<.01$), and
values marked with two asterisks are least significant ($p<
.05$). For example, Table\,\ref{tbl:significance} shows that the
personality expressed in the metaphor ``X's personality is glass'' is
delicate, severe, cold, gloomy ($p<.001$), pure, honest ($p<.01$), and
cowardly ($p<.05$).

\begin{biography}

\biotitle{}

\bioauthor{Akira Utsumi}
{
Akira Utsumi received B.Eng. degree in reaction chemistry,
and M.Eng. and Dr.Eng. degrees in information engineering 
from the University of Tokyo, Japan, in 1988, 1990, and 1993, respectively.
From 1993 to 1996, he was a research associate at Tokyo Institute of Technology.
Since 1996, he has been an assistant professor in the Department of
Computational Intelligence and Systems Science, Tokyo Institute of Technology, Japan.
His research areas include 
computational linguistics, cognitive science,
artificial intelligence, and pragmatics.
His current work focuses on exploring figurative language 
(especially, irony and metaphor) from both computational and pragmatic viewpoints.
He is a member of ACL, AAAI, IPSJ, JSAI, JCSS, ANLP, and JASS.
}

\bioauthor{Koichi Hori}
{
Koichi Hori received B.Eng, M.Eng, and
Dr.Eng. degrees in electronic engineering from the University of
Tokyo, Japan, in 1979, 1981, and 1984, respectively.
In 1984, he joined National Institute of Japanese Literature, Japan,
where he developed AI systems for literature studies. Since 1988, he
has been with the University of Tokyo, Japan. He is currently 
a professor with Interdisciplinary Course on Advanced
Science and Technology, University of Tokyo.
From September 1989 to January 1990, he also held a visiting position
at University of Compiegne, France. His current research interest
includes AI technology for supporting human creative activities,
cognitive engineering, and Intelligent CAD systems.
Professor Hori is a member of IEEE, ACM, IEICE, IPSJ, JSAI, JSSST, and
JCSS.}

\bioauthor{Setsuo Ohsuga}
{
Setsuo Ohsuga is currently a professor of the Department of Information
and Computer Science at Waseda University, Japan.
He has been professor and director of Research Center for Advanced
Science and Technology (RCAST) at the University of Tokyo.
He has also been the president of the Japanese Society for
Artificial Intelligence. He graduated the University of Tokyo in 1957.
From 1957 to 1961 he worked in Fuji Precision Machinery (the present
Nissan Motors). In 1961 he moved to the University of Tokyo and
received Ph.D. in 1966. He became an associate professor in 1967 and 
a professor in 1981. 
His research interests are; artificial intelligence, knowledge information
processing, databases and CAD.
He has received awards for his researches four times from the
Academic Societies in Japan. He is a member of the editorial boards
of 5 international scientific journals.}

\bioreceived{Received}
\biorevised{Revised}
\bioaccepted{Accepted}
\end{biography}

\end{document}
