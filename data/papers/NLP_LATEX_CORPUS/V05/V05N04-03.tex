
\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setlength{\parindent}{10pt}

\setcounter{page}{35}
\setcounter{巻数}{5}
\setcounter{号数}{4}
\setcounter{年}{1998}
\setcounter{月}{9}
\受付{1995}{5}{6}
\再受付{1995}{7}{8}
\採録{1995}{9}{10}

\setcounter{secnumdepth}{3}

\title{文書走査を用いた複合名詞解析}
\author{久光 徹\affiref{HARL} \and 新田 義彦\affiref{NUECO}}

\headauthor{久光 徹・新田 義彦}

\headtitle{文書走査を用いた複合名詞解析}

\affilabel{HARL}{(株)日立製作所 基礎研究所}
{Advanced Research Laboratory, Hitachi Ltd.}
\affilabel{NUECO}{日本大学理工学部}
{College of Science and Technology, Nihon University}

\jabstract{複合名詞は文書の内容を凝縮できる程の情報を担うことができるため重要語となりやすく，しばしば文書内容を理解する上での鍵となる．このため，複合名詞解析（＝その構成要素間の掛かり受け解析）は，機械翻訳にとどまらず，情報抽出や情報検索の高度化にも貢献すると期待されている．しかし，複合名詞は単なる名詞の連鎖に過ぎないため構文上の手掛かりが無く，人手で構成したルールや，シソーラスに記述された概念の共起尤度等を用いて解析する方法が提案されてきた．しかし，新聞記事などの未登録語が頻出する開いた大規模テキストを扱う場合は想定されてこなかったため，そのような場合には頑健性の点で問題が生じる．
本論文は，大量の電子化文書が高速に処理可能な昨今の状況を念頭に置き，シソーラス等の予め固定されたデータを用いるのではなく，文書中から直接文字列レベルの共起情報を抽出するだけで，高い精度で複合名詞解析が可能なことを示す．まず，与えられた複合名詞を暫定的に形態素解析し，得られた構成単語の共起情報を複数のテンプレートを用いて抽出する．共起情報を抽出する段階で，語の出現状況から，複合名詞内の短い複合名詞や，誤って過分割された略称等の未登録語を検出すると同時に，これらの共起情報を抽出することにより，未登録語に対する頑健性が達成される．これに加えて，共起情報が不足する場合のヒューリスティクスに関して検討を加え，文書から直接得られる共起情報と若干のルールを併用することにより，高精度な複合名詞解析が達成できた．
新聞記事から抽出した長さ5, 6, 7, 8の複合名詞各100個を対象に実験を行った結果，新聞1年分を\break
用いて，それぞれ90，86，84，84個の正解が得られた．}

\jkeywords{複合名詞解析，コーパス，頑健性}

\etitle{Analysis of Japanese Compound Nouns by \\
Direct Text Scanning}
\eauthor{Toru Hisamitsu \affiref{HARL} \and Yoshihiko Nitta\affiref{NUECO}} 

\eabstract{
Compound nouns tend to be important words because a compound noun conveys a lot of information which can even summarize a document. Therefore the analysis of compound nouns can contribute to machine translation, information extraction, or information retrieval. 
	Since compound nouns lack syntactic clues, existing methods have utilized manually written rules and thesauri in order to analyze word dependency structure in compound nouns. Consequently the methods lack robustness in treating open corpora such as newspaper articles which contain a number of unregistered words. 
	This paper presents a thesaurus-free corpus-based approach which scans a corpus with a set of templates and extracts co-occurrence data of the nouns which construct the compound noun. Unregistered words such as abbreviations and short compound nouns are detected in the process of template-matching and the co-occurrence data of the newly found words are additionally extracted, which leads to the robustness and high accuracy of the analysis. 
	The accuracy of the method was evaluated using 400 compound nouns of length 5, 6, 7, and 8. The numbers of the correct analysis were 90, 86, 84, and 84 in 100 compound nouns of length 5, 6, 7, and 8 respectively.
}

\ekeywords{compound noun analysis, corpus-based NLP, robustness}

\begin{document}
\maketitle


\section{はじめに}\label{はじめに}
\subsection{複合名詞解析とは}\label{複合名詞解析とは}
複合名詞とは，名詞の列であって，全体で文法的に一つの名詞として振る舞うものを指す．そして，複合名詞解析とは，複合名詞を構成する名詞の間の依存関係を尤度の高い順に導出することである．

複合名詞は情報をコンパクトに伝達できるため重要な役割を果たしており，簡潔な表現が要求される新聞記事等ではとりわけ多用される．そして，記事中の重要語から構成される複合名詞は，記事内容を凝縮することさえ可能である．例えば，「改正大店法施行」という見出しは，「改正された大店法（＝大規模小売店舗法）が施行される」ことを述べた記事の内容を一つの名詞に縮約したものである．そして，このことを理解するためには，｛大店法，改正，施行｝が掛かり受けの構成要素となる単位であることと，これら3単語間に[[大店法 改正] 施行]という依存関係があることを理解する必要がある．

複合名詞解析の確立は，機械翻訳のみでなく，インデキシングやフィルタリングを通して，情報抽出・情報検索等の高度化に貢献することが期待される．

\subsection{従来の手法}\label{従来の手法}
日本語の複合名詞解析の枠組みは，基本的に，

\begin{itemize}
 \item[(1)] 入力された文字列を形態素解析により構成単語列に分解する．
 \item[(2)] 構成単語列間の可能な依存構造の中から尤度の高いものを選択する．
\end{itemize}
の二つの過程からなり，この限りでは通常の掛かり受け解析と同一である．
異なる点は，品詞情報だけでは解析の手がかりとならないため，品詞以外の情報を利用せざるを得ない点である．

品詞以外の手がかりを導入する方法としては，まず人手により記述したルールを主体とする手法が用いられ，大規模なコーパスが利用可能になるにつれ，コーパスから自動的に抽出した知識を利用する手法が主流となってきた．

第一の段階である語分割の過程は，通常の形態素解析の一環でもあるが，特に複合名詞の分割を意識して行われたものとして，長尾らの研究 \cite{長尾1978} がある．そこでは，各漢字の接頭辞・接尾辞らしさを利用したルールに基づく複合名詞の分割法が提案され\break
ており，例えば長さ8の複合名詞の分割精度は84.9\%と報告されている．複合名詞の構造決定に\break
ついては述べられていないが，長さ3, 4, 5, 6の複合名詞について深さ2までの構造が人手で調べられている．それによれば，調べられた240個の長さ5の複合名詞については接辞を含んだ構\break
造が完全に示されており，その59\%は左分岐構造をとっている．

その後宮崎により、数詞の処理，固有名詞処理，動詞の格パターンと名詞の意味を用いた掛かり受け判定等に関する14種類のルールを導入する等、ルールを精緻化し，更に，「分割数が少なく掛かり受け数が多い分割ほど優先する」等のヒューリスティクスを導入することにより，未登録語が無いという条件の下で，99.8\%の精度で複合語の分割を行う手法が提案された \cite{宮崎1984}．

コーパスに基づく統計的な手法では，分かち書きの一般的な手法として確率文節文法に基づく形態素解析が提案され \cite{松延1986}，ついで漢字複合語の分割に特化して，短単\break
位造語モデル（漢字複合語の基本単位を，長さ2の語基の前後に長さ1の接頭辞・接尾辞がそれ\break
ぞれ0個以上連接したものとする）と呼ばれるマルコフモデルに基づく漢字複合語分割手法が提案された\cite{武田1987}．確率パラメータは，技術論文の抄録から抽出した長さ2，3，4の連続漢字列を用いて繰り返し法により推定し，頻出語について正解パターンを与える等の改良により，97\%の分割精度を達成している（全体の平均文字長は不明）．

次の段階である分割された単語の間の掛かり受けの解析についても，ルールに基づく枠組みと，コーパスに基づく枠組み双方で研究されてきた．前者の枠組みとして，宮崎は語分割に関する研究を発展させ，掛かり受けルールの拡充とこれらの適用順序の考慮により，限定された領域については，未知語を含まない平均語基数3.4の複合名詞167個について94.6\%の精度を達成している\cite{宮崎1993}．なお，英語圏でのルールに基づく研究としてはFinin \cite{Finin1980}，McDonald \cite{McDonald1982}，Isabelle \cite{Isabelle1984}等の研究があるが，シソーラス等の知識に基づくルールを用いる点は同様である．

ルールに基づく手法の利点は，対象領域を特化した場合，人手による精密なルールの記述が可能となるため，高精度な解析が可能になることである．しかし，ルール作成・維持にコストがかかることと，一般に移植性に劣る点で，大規模で開いたテキストの取り扱いには向かないといえる．

コーパスに基づく手法では，人手によるルール作成・メンテナンスのコストは削減できるが，名詞間の共起のしやすさを評価するために，単語間の共起情報を獲得する必要がある．しかし，共起情報の信頼性と獲得量が両立するデータ獲得手法の実現は容易ではなく，さまざまな研究が行われている．

一般には，共起情報を抽出する対象として，何らかの固定したトレーニングコーパスを用意し，適当な共起条件に基づいて自動的に名詞対を取り出す．そのままでは一般に名詞対のデータが不足するので，観測されない名詞対の掛かり受け尤度を仮想的に得るため，名詞をシソーラス上の概念や，共起解析により自動的に生成したクラスタに写像し，観測された名詞間の共起を，そのようなクラス間共起として評価する．例えば，西野は共起単語ベクトルを用いて名詞をクラスタリングし，名詞間の掛かり受けの尤度をクラス間の掛かり受け尤度として捉えた \cite{西野1988}．小林は分類語彙表 \cite{林1966}中の概念を利用して，名詞間の掛かり受けの尤度を概念間の掛かり受け尤度により評価した \cite{小林1996}．

これらを掛かり受け解析に適用するためには，一般に，複合名詞の掛かり受け構造を
二分木で記述し，統計的に求めた名詞間の掛かり受けのしやすさを，掛かり受け構造
の各分岐における主辞間の掛かり受けのしやすさとみなし，それらの積算によって掛
かり受け構造全体の確からしさを評価する手法が取られる．
西野の手法では，平均4.2文字の複合名詞について73.6\%の精度で正しい掛かり受け構造が特定できたと報告されている．
小林は，名詞間の距離に関するヒューリスティクスと併用することにより，シソーラ
ス未登録語を含まない，例えば長さ6文字の複合名詞について，73\%の解析精度を得て
いる．なお英語圏では，Lauerが小林とほとんど同じ枠組みで3語からなる複合名詞解
析の研究を行っており \cite{Lauer1995}，Rogetのシソーラス（1911年版）を用いて，
Gloria's encyclopedia に出現する，シソーラス未登録語を含まない3語よりなる複合名詞について，81\%の解析精度を得ている．
（ただし，小林，Lauerとも，概念間の共起尤度に加え，主辞間の距離や左分岐構造を優先するヒューリスティクスを併用している）．

以上を総括すると，従来のコーパスに基づく複合名詞解析の枠組みは，固定したトレーニングコーパスを用い，クラス間共起という形で間接的に名詞の共起情報を抽出することにより，掛かり受け構造の推定を行っていたといえる．

この場合に生じる問題は，クラスへの所属が不明な単語を扱うことができないことである．例えば新聞記事のような開いたデータを扱う場合には，形態素解析辞書への未登録単語が頻出するばかりでなく（この場合，形態素解析の段階で誤りが発生するため，正解は得られない），形態素解析辞書へ登録されていてもシソーラスに登録されていない単語が出現する可能性があり，解析の際には問題となる．実際，我々が実験に用いた400個の複合名詞中，形態素解析用の辞書または分類語彙表に登録されていない単語を含むものは120個に上った（うち形態素解析辞書未登録語は48個）．

未登録語の問題は，未登録語の語境界，品詞，所属クラスを正しく推定することができれば解決可能であるが，現時点では，これらについて確立した手法は無い．特に，語の所属クラス推定のためには，与えられたコーパス中でのその語の出現環境を得ることが必要となるため，なんらかの形でコンテクストの参照が必要となる．すなわち，あらかじめ固定したデータのみを用いて解析を行う枠組みでは，開いたコーパスを扱うには限界がある．

\subsection{本論文の目的}\label{本論文の目的}
本論文では，「あらかじめ固定されたデータのみを用いて解析する」という従来の枠組に対して，「必要な情報をオン・デマンドで対象コーパスから取得しながら解析する」という枠組を提唱し，その枠組における複合名詞解析の能力を検証する．文字インデキシングされた大規模なコーパスを主記憶内に置くことが仮想的ではない現在，本論文で提示する枠組には検討の価値があると考える．

十分な大きさのコーパスの任意の場所を参照できれば，複合名詞に含まれる辞書未登録語の発見や，それらを含めた複合名詞を構成する諸単語に関する，様々な共起情報が取得できると思われるが，実際に我々は，テンプレートを用いたパターン照合によりこれらが実現できることを示す．このような手法においては，未登録語の発見はパターン照合の問題へ統合されるうえ，発見された未登録語の共起情報を文字列のレベルで直接参照するため，クラス推定の問題も生じない．

データスパースネスの問題については，テンプレートの拡充による共起情報抽出能力の強化と，複合名詞を構成する単語対のうち，一部の共起情報しか観測されない場合に，それらをできるだけ尊重して掛かり受け構造を選択するためのヒューリスティクスを整備する．これらにより，シソーラス等の知識源に依存せず，純粋に表層情報のみを利用した場合の解析精度の一つの限界を目指す．

本論文では，長さ5，6，7，8の複合名詞各100個，計400個について，新聞2ヵ月分，1年分\break
を用いて実験を行い，提案する枠組みで，高い精度の複合名詞解析が可能なことを示す．複合名詞解析の精度評価に関しては，パターン照合による未登録語の発見やヒューリスティクスの寄与も明らかにする．

\subsection{本論文の構成}\label{本論文の構成}
以下{\bf \ref{複合名詞解析の構成}節}では，複合名詞解析の構成の概略を述べ，{\bf \ref{従来手法と問題点の分析}節}では，クラス間共起を用いる手法のうち，クラスとしてシソーラス上の概念を用いる「概念依存法」の概括と，その問題点を整理する．{\bf \ref{文書走査による複合名詞解析}節}では提案手法の詳細を示し，共起データ抽出と構造解析について例を用いて述べる．{\bf \ref{実験結果}節}では，{\bf \ref{文書走査による複合名詞解析}節}で述べた複合名詞の解析実験の結果について示す．{\bf \ref{本論文の目的}}で述べた分析の他，ベースラインとの比較等を行う．最後に，今後の課題について述べる．

\section{複合名詞解析の構成}\label{複合名詞解析の構成}
既に述べたように，複合名詞解析の基本要素は：\\
(1)\ 入力された文字列を形態素解析により構成単語列に分解する．\\
(2)\ 構成単語列間の依存構造のうち尤度の高いものを選択する．\\
の2点である．本節ではこれらの項目について述べる．

\subsection{形態素解析}\label{形態素解析}
複合名詞は，まず形態素解析器により名詞，接辞等の列に分解される．我々はルールベースの形態素解析器 \cite{久光1994}を用いたが，複合名詞解析の前処理として位置付けた場合，若干の調整が必要であった．例えば，「構造解析」のように長さ2の語基2個からなる複合名詞や，「解決策」，「担当者」のように，長さ2のサ変名詞に接辞が付加した複合語が登録されていると，本来捉えるべき内部構造が得られなくなることがある\footnote{例えば，「構造解析」が登録されていた場合，(((複合 - 語) - 構造) - 解析) のような内部構造は得られなくなる．}．したがって，語基や接辞である「構造」，「解析」，「担当」，「解決」，「策」，「者」等は辞書に残す一方で，長単位のエントリは削除しておく必要がある．

このような手順を経たうえで，試料として選んだ400個の複合名詞（長さ5，6，7，8のもの100個ずつ）に関して，最小コストかつ最小分割数の解のみ（複数個ある場合はそのすべて）を形態素解析結果として用いた．

解析の対象となる複合名詞の形態素解析の精度に関しては，形態素解析が出力する解の平均個数が1.2個で，正しい解が含まれるものは，複合名詞400個中352個であった．残りの 48個について，46個は，「住専」，「大店法」のような略語や，姓，名のような未登録語が過分割される誤り（「住・専」のように）であり，2例は単語境界を捉えられない誤りであった．これらの解は，誤りがある場合もそのまま，共起情報抽出部に渡される．

参考までに，固有名詞，略号等の出現単語をすべて辞書登録した場合，複合名詞1個ごとの解の平均個数は1.1個，解候補に正解を含まないものは4例であった．

\subsection{複合名詞解析規則}\label{複合名詞解析規則}
形態素解析の結果得られる名詞の連鎖を複合名詞に組み上げるため，2分木を基本とするCFG\break
ルールと，各ルールに付随する属性計算ルールを用いた．名詞（句）と名詞（句）の連鎖により名詞句ができることを示す最も基本的なルールは，以下の3つである：

\vspace*{1mm}
\begin{tabular}{clll}
\hbox to 10mm {\hfil} & \it NP & $\rightarrow$ & \it NP NP \\
\hbox to 10mm {\hfil} & \it NP & $\rightarrow$ & \it N 	   \\
\hbox to 10mm {\hfil} & \it N  & $\rightarrow$ & \it{w} \rm{(}\it{w}は単語\rm{)} 
\end{tabular}

\vspace*{1mm}
\noindent
これに，接頭辞(\it{PREFIX}\rm{)}に関するルール，接尾辞(\it{SUFFIX}\rm{)}に関するルール：

\vspace*{1mm}
\begin{tabular}{clll}
\hbox to 10mm {\hfil} & \it N & $\rightarrow$ & \it PREFIX N \\
\hbox to 10mm {\hfil} & \it N & $\rightarrow$ & \it N SUFFIX 
\end{tabular}

\vspace*{1mm}
\noindent
等を追加することにより，標準的な二分木モデルのためのルール群が得られる．

ここで，各ルールに出現する非終端記号には，属性 "$head$", "$cost$" を付与し，それぞれ，そのノード全体を代表する名詞である主辞と，積算されたコストを記録する．第一のルールの左辺・右辺の非終端記号を添字で区別したルール：

\begin{tabular}{clll}
\hbox to 10mm {\hfil} & \it $NP_L$ & $\rightarrow$ & \it $NP_{R1}\ \ NP_{R2}$
\end{tabular}

\noindent
を用いて各属性値の伝搬について一般的に記述すれば次のようになる：

\vspace*{-8mm}
\begin{eqnarray*}
NP_{L}{\bullet}head &=& H(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head),\\
\vspace*{-3mm}
NP_{L}{\bullet}cost &=& C(NP_{R1}{\bullet}head, NP_{R1}{\bullet}cost, NP_{R2}{\bullet}head, NP_{R2}{\bullet}cost).
\end{eqnarray*}

\vspace*{-2mm}
\noindent
ここで$NP_{X}{\bullet}Y$は$NP_X$の属性$Y$の属性値を表す．$NP_{R1}$と$NP_{R2}$の親ノードとなる$NP_L$の主\break
辞は$NP_{R1}$と$NP_{R2}$の主辞から計算され，$NP_L$を親とする部分木のコストは，その子ノード達\break
の属性値からボトムアップで定められる．$H$と$C$の定め方によりさまざまな尤度付けが定式化できる．

主辞の定め方については，二つの名詞が複合して名詞を構成するとき，日本語では一般に後置される名詞が全体の主要部となる（すなわち，$H(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head) = NP_{R2}{\bullet}head$）．しかし，いくつかの例外があり，それらについては後述する．


\section{従来手法と問題点の分析}\label{従来手法と問題点の分析}
本節では，小林・Lauerの概念依存モデルを{\bf \ref{複合名詞解析規則}}の枠組みを用いて表現し，改良すべき点を整理する．

\subsection{概念依存モデルの実現}\label{概念依存モデルの実現}
小林が示した概念依存モデルと同等の尤度付けは，次の関数$C$によるスコアの最大化問題として実現できる：
\vspace{-0.3cm}
\begin{eqnarray*}
 \lefteqn{C(NP_{R1}{\bullet}head, NP_{R1}{\bullet}cost, NP_{R2}{\bullet}head, NP_{R2}{\bullet}cost) = }\\
 & & NP_{R1}{\bullet}cost + NP_{R2}{\bullet}cost + {\Delta}(NP_{R1}{\bullet}head + NP_{R2}{\bullet}head),\\
 \lefteqn{{\Delta}(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head) = }\\
 & & \log \frac{RF(class(NP_{R1}{\bullet}head), class(NP_{R2}{\bullet}head)}{RF(class(NP_{R1}{\bullet}head), \ast){\times}RF(\ast, class(NP_{R2}{\bullet}head)}.\\
\end{eqnarray*}

\vspace{-0.3cm}
ここで，$class(x)$は，主辞$x$の分類語彙表中の意味分類，$RF(a,b)$は，あらかじめ用意された意味分類の2項組データベース（後で述べる単語の共起データベースから生成される）中で，意味分類$a$と$b$がこの順序で共起する相対頻度，"$\ast$"は，任意の意味分類を表す．

主辞については，二つの名詞が複合して名詞を構成するとき，後置される名詞を全体の主辞としている\footnote{接尾辞が語基に後接する場合，語基を主辞とするほうが良いであろうと示唆している．}．

この手法を用いた複合名詞解析の精度は，6文字漢字複合名詞で61\%，数値表現に関するテンプレートと，主辞間の依存距離を加味した場合，6文字漢字複合名詞で73\%と報告されている\cite{小林1996}．

\vspace{-2mm}
\subsection{課題の整理}\label{課題の整理}
\vspace{-1mm}
従来法の問題点を整理し，取り組むべき課題を整理すると，以下の3点となる．
\vspace{-2mm}
\subsubsection{共起情報獲得手法の拡充}\label{共起情報獲得手法の拡充}
自明な問題としては，形態素解析用辞書またはシソーラスに登録されていない単語が出現した場合，概念共起法では取り扱いが困難なことである．既に述べたように，このような未登録語\break
は，我々が実験用に無作為抽出した400個の複合語サンプル中，120個に現れており，そのうち46個の形態素解析辞書未登録語に関しては，始めの形態素解析の段階で失敗してしまう．従って，このような事実を考慮した共起情報の獲得方法を考えねばならない．

2単語の「共起」を数える場合，共起するとみなす条件の強さによりさまざまな立場がある．英語圏の研究では，緩やかな共起を認めるものとして，注目する二単語が特定の長さの単語列の中にともに出現する回数を計るワードウィンドウ法\cite{Yarowsky1992}が，強い条件を課すものとして，注目する2名詞が非名詞に両側から挟まれる形で出現する回数を計る方法\cite{Pustejovsky1993}があり，Lauer は先に述べた研究において，後者の手法の優位性を示した\cite{Lauer1995}．これらを語境界が明示されない日本語コーパスに適用するためには，語境界の同定を含む何らかの工夫が必要である．

西野の手法では，名詞のクラスタリングをするために単語間の共起回数を数える際，上記の中間的な手法を取っている．すなわち，2単語がトレーニングセットに含まれる連続漢字文字列中で掛かり受けの可能性がある位置に現れたとき，両者は1回共起したとする．この場合，共起\break
の観測を連続漢字文字列中に限定することによる量的な問題と，掛かり受けの可能性が0でない名詞対をすべて1回共起したとみなすことにより生じる共起源の品質低下の問題が懸念される．

小林は，単語共起データを得るために，より厳しい制限を課している．すなわち，あらかじ\break
め獲得されている16万の4文字漢字列を用い\cite{田中1992}，これを2文字ずつに分割して得られ\break
る2文字漢字列の双方が辞書にある場合，これを単語の共起と認める．小林の方法では，これを概念共起に変換するため，上記単語対の双方がシソーラス中でそれぞれ唯一の概念に対応する場合のみ，両概念が1回共起したと数える．したがって，共起データの品質は高いと思われるが，4文字漢字列という限定と，曖昧性無くシソーラスに登録されているという限定が加わる\break
ため，共起を数える条件はかなり厳しい．このため，「の」で結ばれて出現する2文字の名詞対も共起したとはみなされないし，「住専」や「大店法」のように，辞書・シソーラス共に未登録の単語を含む複合語には対応できない．

例えば「改正大店法施行」の場合は，「改正/SN・大/ADJ・店/N・法/N・施行/SN」と過分割されてしまい，意味の有る依存構造は得られない\footnote{観測された分割誤りはほとんどすべてが過分割誤りであるため，以下では実際的な効果と問題の簡易化のため，未登録語による分割誤りのタイプとして，過分割誤りのみを想定している．}．従って，実際のデータを扱うためには，シソーラスを用いないだけでなく，上記のような解析誤りも前提とした枠組みが必要である．ここで，「住専」，「大店法」等が掛かり受けの単位となるまとまりであることは，多くの場合，文書の他の部分におけるこれら文字列の出現状況から推定できるため，それを利用することが考えられる．

我々は，シソーラスを介さずに，ノイズの少ない文字列レベルの共起情報をできるだけ多く収集するため，日本語の特性を生かしたテンプレートを各種用意し，それらを用いて共起情報を得ることにした．過分割された未登録語の発見は，これらのテンプレート中に自然に組み入れられる．

\subsubsection{短い複合語の問題}\label{短い複合語の問題}
「住専」，「大店法」のような未登録語だけでなく，主辞の選択においても，単語自
体の情報を用いないと困難が生じることがありうる．
例えば，「危険物」は，「危険」と「物」の意味的な組み合わせで全体の意味を構成
できるため，
辞書に「危険物」が登録されていないことは自然であり，
「危険物」が「危険」＋「物」と分解されることは，形態素解析として失敗ではない．

しかし，「危険物」が部分複合語として含まれる複合語の掛かり受け構造を調べる場合，「危険物」を「危険」と「物」に分解したままで扱い，全体の主辞を「物」とすると，「危険物」の共起情報が適切に捉えられない恐れが多分にある．

そこで，係り受けを判断する際には「危険物」全体の共起関係を利用することが必要となってくる．しかし，「危険物」のような単語すべてをあらかじめシソーラスに登録しておくことは困難であるから，「住専」のような，通常の未登録語の問題と同様，これらの部分複合語を概念共起モデルで扱うことは困難となる．

これに対し，文書中の他の部分で「危険物」が独立して出現することが発見できた場合，「危険物」自体を掛かり受け単位とみて，その共起情報を取得することにすれば，シソーラスに関する制約は回避できる．

以下では，複合語中で，他の単語との掛かり受けを考えるときに考慮すべき部分を，便宜上「主辞」と呼ぶことにする．
\subsubsection{主辞の選択}\label{主辞の選択}
{\bf \ref{短い複合語の問題}}では，短い複合語を扱う場合の辞書登録の問題とともに，主辞の選択について述べたが，単に後置される名詞を主辞とすれば良いと言えない場合として，人名，地名等の固有名詞を含む場合がある．固有名詞は，登録語も含めて，同サンプル中約29\%の複合名詞に出現したので，これらを扱う場合の主辞計算ルールも考察する必要がある．

\section{文書走査による複合名詞解析}\label{文書走査による複合名詞解析}
本節では，{\bf \ref{課題の整理}}で述べた問題を解決するための手法を提案する\footnote{報告者らが以前提案した手法\cite{Hisamitsu1996}を精密化したものである．}．提案手法では，辞書とテンプレートを組み合わせて，与えられた複合名詞に含まれる名詞の共起情報を必要に応じて表層的に抽出する．その際，コーパスに応じた動的なデータ獲得を行うことが特徴である．すなわち，テンプレート照合のキーとして，初期の形態素解析の結果得られる単語を用いるだけでなく，テンプレートによるデータ抽出時に，辞書照合と文字列比較の組み合わせにより，初期の形態素解析で過分割されていた未登録語や，部分複合語の検出を行い，これらの共起情報を追加獲得する．そして，必要に応じて形態素解析結果の修正などをした後，掛かり受け解析を行う．

提案する手法は，固定されたシソーラスを用いず，発見された未登録語や部分複合語に対応して，必要に応じて柔軟に共起情報を取得することができるため，頑健性に優れている．以下では，提案手法を「文書走査法」と称する．

\subsection{共起データ獲得法}\label{共起データ獲得法}
{\bf \ref{共起情報獲得手法の拡充}}において名詞A，Bの共起を数えるいくつかの手法について述べたが，文書走作法では，\break
2単語A，Bがフィラーとなるテンプレートを用いて単語Aに関する共起単語群を抽出するため，「名詞A，Bが共起する」ことを，「A，Bが同時にあるテンプレートのフィラーとなる」こと\break
と定義する．テンプレートは，2単語の隣接を含み，小林の方法の拡張になっている．

以下，文書走査法の共起単語獲得手順を例を用いながら示す：

\newlength{\originalparindent}
\originalparindent=\parindent
\settowidth{\leftskip}{(1)\ }
\settowidth{\parindent}{(1)\ }
\parindent=-\parindent
(1)\ 与えられた複合語を形態素解析し，結果（複数可）を分割結果リストに記録する．同時に，得られた候補単語を字面レベルでリストKEY\_LISTに記録する．ここで，KEY\_LISTは，共起情報抽出の対象となる単語（テンプレートでAの位置をしめる単語）を格納する．

\settowidth{\parindent}{例)\ }
\parindent=-\parindent
例)\ 「改正大店法施行」の場合，初期解析結果により唯一の解が得られ，分割結果リストは｛「改正/SN・大/Adj・店/N・法/N・施行/SN」｝，KEY\_LISTは｛改正，大，店，法，施行｝となる．

\settowidth{\leftskip}{(2)\ }
\settowidth{\parindent}{(2)\ }
\parindent=-\parindent
(2)\ KEY\_LIST中の先頭の文字列の共起文字列をテンプレートを用いて抽出する．その過程で，共起情報抽出の対象となっている単語と，分割結果リスト中での隣接単語（1個または2個）を連結した文字列が，

\settowidth{\leftskip}{(2)\ (I)\ }
\settowidth{\parindent}{(I)\ }
\parindent=-\parindent
(I)\ 形態素解析の単位となるべき未登録語と判断されたとき：

\settowidth{\leftskip}{(2)\ (I)\ }
\noindent
\rightskip = 15mm
連結された文字列をWORD\_LISTとKEY\_LISTの両方に追加する．ここでWORD\_LISTは，新たに発見された単語を格納する（新たに発見された単語の品詞については後述）．

\settowidth{\leftskip}{(2)\ (I)\ }
\settowidth{\parindent}{(II)\ }
\parindent=-\parindent
(II)\ 掛かり受けの単位となるべき主辞と判断されたとき：

\settowidth{\leftskip}{(2)\ (I)\ }
\noindent
\rightskip = 15mm
上記連結した文字列を，KEY\_LISTに追加する．

\settowidth{\leftskip}{(2)\ }
\noindent
ここで，(I), (II)の判断の根拠となるルールについては，{\bf \ref{連続漢字文字列中から共起情報を取り出すもの}}で{\bf フィルタリング規則}として詳述する．

\settowidth{\parindent}{例)\ }
\parindent=-\parindent
例)\ 「改正大店法施行」の場合，「大店法」を新たに形態素解析の単位となるべき未登録語とみなし，WORD\_LISTとKEY\_LISTに追加する．

\settowidth{\leftskip}{(3)\ }
\settowidth{\parindent}{(3)\ }
\parindent=-\parindent
(3)\ 共起情報を獲得し終えた要素は，KEY\_LISTから除去する．

\settowidth{\leftskip}{(4)\ }
\settowidth{\parindent}{(4)\ }
\parindent=-\parindent
(4)\ KEY\_LIST が空でなければ(2)に戻る．

\settowidth{\leftskip}{(5)\ }
\settowidth{\parindent}{(5)\ }
\parindent=-\parindent
(5)\ WORD\_LISTの要素を元の形態素解析辞書と併用して，複合名詞を再解析し，分割結果リストを更新する．

\settowidth{\parindent}{例)\ }
\parindent=-\parindent
例)\ 「改正大店法施行」の場合，再解析の結果，唯一の解「改正/SN・大店法/N・施行/SN」が得られ，分割結果リストは｛「改正/SN・大店法/N・施行/SN」｝となる．

\settowidth{\leftskip}{(6)\ }
\settowidth{\parindent}{(6)\ }
\parindent=-\parindent
(6)\ 文法と共起情報を用いて，最尤掛かり受け構造を求める．

\parindent=\originalparindent
\leftskip=0mm
\rightskip=0mm

\subsection{テンプレートの説明}\label{テンプレートの説明}
本節では，{\bf \ref{共起データ獲得法}}で述べたテンプレートについて説明する．
{\bf 図\ref{fig:templates}}は2つの文字列A，Bの共起を抽出するためのテンプレー
ト群である．A は共起関係を調べる対象となる単語，B は漢字文字列，Dは，空白，記
号，“の”以外の平仮名等のいずれかであるとする（D中から“の”を除くのは，例え
ば「AのBのC」中から「AのB」，「BのC」だけを抜き出すと，
誤った掛かり受け\break
を獲得することが多いためである）．

テンプレートは，連続漢字文字列中から共起情報を取り出すもの（{\bf 図\ref{fig:templates}}(A)）と，平仮名を含む文字列中から共起情報を取り出すもの（それ以外）の二種類に分かれる．

\begin{figure}[tbp]
  \begin{center}
    \leavevmode
    \epsfile{file=templates.epsf,scale=0.8}
   \vspace{3mm}
  \end{center}
  \caption{用いたテンプレートの例}
  \label{fig:templates}
\end{figure}

\subsubsection{連続漢字文字列中から共起情報を取り出すもの}\label{連続漢字文字列中から共起情報を取り出すもの}
テンプレート群{\bf 図\ref{fig:templates}}(A)は，2つの名詞が，連続漢字文字列内に共起する例を獲得する．Aが長さ1の単語の場合，Bは長さ2以下の漢字文字列，Aが長さ2以上の単語の場合，Bは長さ3\break
以下の漢字文字列とする．ここでBの長さの制限は，掛かり受けの単位を2文字以下の基本単語（いわゆる短単位），またはそれに接辞が付加されたものとしたためで，文字数3はこれから従う．この制限を除くと，Aと共起する文字列として2語以上からなる複合語が混入するため，共起データの品質が著しく劣化する．

連続漢字文字列からの共起情報抽出は，語内の単語境界が示されていないため次に述べるフィルタリング規則を補助的に用いる：

\noindent
{\bf フィルタリング規則}

\noindent
「{\bf 図\ref{fig:templates}}(A)に属するテンプレートにより発見されたABおよびBAについては：

\settowidth{\leftskip}{(I)\ }
\settowidth{\parindent}{(I)\ }
\parindent=-\parindent
(I)\ 文字列ABが解析すべき複合語内に部分文字列として含まれており，AB(BA)の始端と終端が，初期分割の解における形態素境界と一致し、かつ

\settowidth{\leftskip}{(I)\ (a)\ }
\settowidth{\parindent}{(a)\ }
\parindent=-\parindent
(a)\ AB(BA)の長さが2であり，かつ連結した文字列としてAB(BA)が辞書に登録されていない

\vspace*{-5mm}
\begin{center}
または，
\end{center}
\vspace*{-3mm}

\settowidth{\leftskip}{(I)\ (b)\ }
\settowidth{\parindent}{(b)\ }
\parindent=-\parindent
(b)\ AB(BA)の長さが3であり，Bも文字列の連結AB(BA)も辞書登録されておらず，辞書登録された2単語A'，B' (ただしA'≠A) を用いてAB＝A'B' (BA＝B'A')と分割でき\break
ない

\vspace*{-5mm}
\begin{center}
または，
\end{center}
\vspace*{-3mm}

\settowidth{\leftskip}{(I)\ (c)\ }
\settowidth{\parindent}{(c)\ }
\parindent=-\parindent
(c)\ AB(BA)の長さが3であり，A(B)がサ変名詞でなく，Aが接頭(尾)辞またはBが接尾(頭)辞であり，文字列の連結AB(BA)が辞書登録されておらず，辞書登録された2単語A'，B' (ただしA'≠ A) を用いてAB＝A'B' (BA ＝B'A')と分割できない

\settowidth{\leftskip}{(I)\ }
\noindent
ならば，C=AB(BA)を新たに単語とみなし（品詞はNまたはSNとする．SNはCがサ変化\break
接辞で終わる場合），WORD\_LIST と KEY\_LIST に加える．

\settowidth{\leftskip}{(I)\ (d)\ }
\settowidth{\parindent}{(d)\ }
\parindent=-\parindent
(d)\ \ (b), (c)以外でAB(BA)の長さが3の場合は，A(B)がサ変名詞でなく，B(A)の長さが1\break
ならば，主辞としてAB(BA)を KEY\_LIST に加える．

\settowidth{\leftskip}{(II)\ }
\settowidth{\parindent}{(II)\ }
\parindent=-\parindent
(II)\ それ以外の場合：\\
AB(BA)の長さが3以上で，Bが辞書登録されており，2単語A'，B' (ただしA'≠ A）を用\break
いてAB＝A'B' (BA＝B'A') と分割できない場合，AB(BA)を複合語とみなし，AとBが\break
複合語内で共起したとする．

\parindent=\originalparindent
\leftskip=0mm
例えば，「住専」，「大店法」，「簡素化」等が，ひらがなや括弧に挟まれる形で文中の他の部分に出現しているとき，「住/N・専/ KJ・問題/N」（KJは単漢字）の"住"を対象とする共起単語抽出過程からは，I-(a)に従い「住専/N」が得られる．同様に，「改正/SN・大/Adj・店/N・法/N・施行/SN」の"大"を対象とする共起単語抽出過程からは，I-(b)に従い「大店法」が，「簡素/Adj・化/Suffix・手続/SN」の"簡素"を対象とする共起単語抽出過程からは，I-(c)に従い「簡素化/SN」が，新たに単語とみなされ，WORD\_LIST と KEY\_LIST に加えられる．

\subsubsection{平仮名を含む文字列から共起情報を取り出すもの}\label{平仮名を含む文字列から共起情報を取り出すもの}
1-(B)以降のテンプレート群においては，Aの長さに関わり無く，Bは長さ3以下の漢字文字列とする．

テンプレート群1-(B)は，２つの名詞が，助詞「の」を挟んで共起する例を獲得するためのテンプレートである．

テンプレート群1-(C)は，形容詞，形容動詞と，それが修飾する単語の例を獲得するテンプレートである．

テンプレート群1-(D)は，サ変動詞と，そのガ格，ニ格，ヲ格となる名詞の例を獲得するテンプレートである．

テンプレート群1-(E)は，サ変動詞と，それに連体修飾される名詞の例を獲得するテンプレートである．

テンプレート群1-(F)は，並列関係をとる名詞の例を獲得するテンプレートである．

テンプレート群1-(G)は，「〜についての〜」という関係にある二つの名詞の例を獲得するテンプレートである．

\subsection{例}\label{例}
「改正大店法施行」の解析の場合，初期の形態素解析において，5つの単語からなる唯一の解「改正/SN・大/Adj・店/N・法/N・施行/SN」を得る．第1の単語「改正」については，「改正中」（1-(A)），「法律の改正」（1-(B)），「法を改正する」（1-(D)），「改正された大店法」（1-(E)）等が獲得される（「大店法」はこの段階で既に「改正」に対する共起文字列として取り上げられている）．

第2の単語「大」からは，「大店法」が単語として WORD\_LIST に登録され（1-(A)＋フィルタリング規則I-(b)），「大きな変化」（1-(C)）等が共起例として獲得される．

第3の単語「店」，第4の単語「法」については，「大」と同様に，「店の管理」（1-(B)），「法を改正」（1-(D)）等が得られる．

第4の単語「施行」については，「早期施行」（1-(A)），「施行を決定」（1-(D)），「大店法の施行」（1-(B)）等が獲得される．

最後に，新たに発見された単語“大店法”をキーとして検索を実施し，「反大店法」（1-(A)）等を得る．

{\bf 図\ref{fig:DBexample}}(A)，(B)に，上記の5つのキーに基づいて発見されたパターンと，これらを単語の共起対ごとに頻度情報とともに整理した例をまとめた．参考のため，(B)には，各対の共起パターン\break
の種類を付記したが，最終的に回数の計数時には共起の種類を区別していない．
\begin{figure}[tbp]
  \begin{center}
    \leavevmode
    \epsfile{file=DBexample.epsf,scale=0.8}
  \end{center}
  \caption{発見された共起データの例}
  \label{fig:DBexample}
\end{figure}

\subsection{尤度判定と主辞の選択}\label{尤度判定と主辞の選択}
複合名詞の掛かり受け構造の選択は，共起情報に基づくスコア付けと，共起情報が足りない場合に用いるヒューリスティクスを組み合わせて行う．

\subsubsection{主辞同士の尤度計算}\label{主辞同士の尤度計算}
最尤掛かり受け構造の計算は，{\bf \ref{複合名詞解析規則}}の枠組を用いて，以下
の関数$C$によるコスト最小化問題と\break
して実現される：


\vspace{-0.5cm}

\begin{eqnarray*}
 \lefteqn{C(NP_{R1}{\bullet}head, NP_{R1}{\bullet}cost, NP_{R2}{\bullet}head, NP_{R2}{\bullet}cost) =} \\
 & & NP_{R1}{\bullet}cost + NP_{R2}{\bullet}cost + {\Delta}(NP_{R1}{\bullet}head + NP_{R2}{\bullet}head),\\
\lefteqn{{\Delta}(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head) =} \\
 & & \displaystyle -\log(\frac{Freq(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head)}{Freq(NP_{R1}{\bullet}head){\times}Freq(NP_{R2}{\bullet}head)}).\\
\end{eqnarray*}

\vspace{-0.5cm}

ここで，$Freq(x, y)$は，主辞 $x, y$ が何等かのテンプレート中に $A=x, B=y$ または $A=y, B=x$ として共起した回数，$Freq(x)$ は，主辞 $x$ が何等かのテンプレート中に $A=x$ または $B=x$ として現われた回数，$Freq(y)$は，主辞 $y$ が何等かのテンプレート中に $A=y$ または $B=y$ として現われた回数を表わす\footnote{テンプレートのフィラーとなる順序は考慮していない．「簡素な手続き」，「手続の簡素さ」や，能動態と受動態の区別を無視したためである．}．$x，y$ の値は文字列である．

上記のコストを用いてコストの低い順から依存木を選出することは，名詞句をまとめあげるごとに計算される主辞同士の相互情報量\cite{Church1990}を依存木全体で積算した値が大きな順に依存木を選び出すのと同等である．実際，テンプレートで2名詞A，B間の共起が\break
観測できるすべての位置の数を$N_{total}$としたとき，相互情報量を用いる場合，$log$ の内側は，
\begin{center}
$\displaystyle \frac{N_{total}{\times}Freq(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head)}{Freq(NP_{R1}{\bullet}head){\times}Freq(NP_{R2}{\bullet}head)}$
\end{center}
\noindent
とすべきであるが，この値が大きくなることと，
\begin{center}
$\displaystyle \log(\frac{Freq(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head)}{Freq(NP_{R1}{\bullet}head){\times}Freq(NP_{R2}{\bullet}head)})$
\end{center}
\noindent
が大きくなること，すなわち，正値のコスト：
\begin{center}
$\displaystyle -\log(\frac{Freq(NP_{R1}{\bullet}head, NP_{R2}{\bullet}head)}{Freq(NP_{R1}{\bullet}head){\times}Freq(NP_{R2}{\bullet}head)})$
\end{center}
\noindent
が小さくなることは同値である．文書走査法では，オンデマンドで共起情報を抽出するためコスト計算時に $N_{total}$ が不明であるが，分割数の等しい解同士のコストを比較する場合には $N_{total}$ は順序に影響を与えず，しかも比較は最小分割数の解同士で行われるため，$N_{total}$ は無視できる．

\subsubsection{主辞の選択における注意}\label{主辞の選択における注意}
先にも述べたように，二つの名詞（句）を一つの名詞句に組み上げるとき，一般には後置される名詞句の主辞を全体の主辞とする．最も典型的な場合，

\begin{tabular}{clll}
\hbox to 10mm {\hfil} & \it NP & $\rightarrow$ & \it $NP_1\ NP_2$
\end{tabular}

\noindent
において，典型的な場合，例えば右辺の$NP_{i}$の主辞がそれぞれ長さ2の普通名詞であるような場合，左辺の$NP$の主辞は，$NP_2$の主辞である．しかし，{\bf \ref{複合名詞解析の構成}}節で述べたように，新たな主辞を合成したり，$NP_1$の主辞を選択する方が望ましい場合がある．以下，そのような場合について述べる．

\noindent
{\bf 短い複合語}

\noindent
長さが3の短い複合語に関しては，新たな主辞を合成した方が良い場合がある．例えば，以下の例：

\begin{tabular}{cllll}
\hbox to 10mm {\hfil} & (1) & 新工場 & $\rightarrow$ & 新/Adj＋工場/N\\
\hbox to 10mm {\hfil} & (2) & 危険物 & $\rightarrow$ & 危険/Adj＋物/N
\end{tabular}

\noindent
のうち，(1)は，右辺の2単語の長さが，順に1，2である．これに対して，(2)では，右辺の2単語の長さが，順に2，1となる．一般に(2)のように，2語目の長さが短い場合，2語目を全体\break
の主辞とするとあまり共起情報が得られないことが多い（例えば，「物」のような抽象的な名詞が直接用いられることはまれである）．我々は，このような場合，部分依存構造としては[危険 物]を二単語間の依存関係として認めつつ，左辺$NP$全体の主辞として，「危険物」自体を用いる\break
ことした．そのために，$NP_1, NP_2$から$NP$を構成するとき，主辞を合成するルールを追加する\footnote{右辺第1項がサ変名詞の場合は，このような主辞の合成は行わない．}．このような合成された主辞に関しては，{\bf \ref{連続漢字文字列中から共起情報を取り出すもの}}のルールにより，共起情報が抽出されることに注意されたい．

\noindent
{\bf 人名}

\noindent
「会長/N・山田/PN・太郎/PN・氏/Suffix・引退/SN」中の「山田/PN・太郎/PN・氏/Suffix」のようなパターンがある場合\footnote{我々の辞書は，固有名詞に，「人名」や，「姓」，「名」等の細分を持たない．この細分があれば，解析精度はより向上するであろう．}，この部分の掛かり受け構造は[[山田\ 太郎]\ 氏]で，その主辞は「山田」と考えるのが自然であろう．このとき，「山田会長」のような共起関係が他の場所で観測されれば，部分構造[会長\ [[山田\ 太郎]\ 氏]]が得られる．さらに，このような構造に関しては，その主辞は役職名である「会長」とするのが自然と思われる．

実際は，役職名を定義してルール化することは行わなかったが，人名部分をまとめる処理は，掛かり受け解析の前処理として行った（{\bf \ref{人名の場合}}を参照）．

\subsection{データ不足に対応するためのヒューリスティクスの整備}\label{データ不足に対応するためのヒューリスティクスの整備}
データ不足に対処するための方策として，テンプレートの拡充とともに，複合名詞を構成する単語対のうち，一部の共起情報しか観測されない場合に用いるヒューリスティクスを整備した．基本的な方針は，{\bf 観測された共起例をできるだけ尊重して掛かり受け構造を選択する}ことである．

まず，問題を整理するため，「共起データが不足する」ことを次のように定義する：

\leftskip = 10mm
\rightskip = 10mm
\noindent
ある依存構造に対して，そこに現れるすべての掛かり受け対に対してコーパス中で共起関係が観測されている場合，その依存構造は「共起例によって完全に覆われている」と定義する．ある複合名詞に対し，共起例によって完全に覆われた依存構造が存在しない場合，「その複合名詞に関する共起データが不足している」と定義する．

\leftskip = 0mm
\rightskip = 0mm
ある複合名詞について共起データが不足する場合は，大きく分けて三種類であった．すなわち，数詞を含む場合，固有名詞を含む場合，その他一般の単語からなる場合である．以下，この三つの場合についてそれぞれ述べる．

\vspace*{-2mm}

\subsubsection{数表現}\label{数表現}
「合計約二十五万円」のように数値を含む表現の場合，通常の形態素解析を行うと「合計/SN・約/Prefix・二/Num・十/Num・五/Num・万/Num・円/Suffix」となる（Numは数詞を表す）．このような数字の列を含む結果をそのまま共起解析に渡しても，数字列が長いと{\bf \ref{テンプレートの説明}}で定義されたテンプレートでは有効な共起関係は得られないうえ，数字部分の内部構造を考えること自体無意味である．

我々は，宮崎や小林と同様に，数値表現は前処理によって対処した．すなわち，まず数値部\break
分をまとめ，「円」，「人」，「年」等の数詞接尾辞，「約」等の数詞接頭辞を付加することにより，「約二十五万円」の部分を，予め[[約 二十五万] 円]のような名詞句としてまとめる処理を行った（この処理により，金額，日時，等がすべて正しく処理された）．この後に，必要ならば{\bf \ref{一般の場合}}で述べるルールを適用する．

\vspace*{-3mm}
\subsubsection{人名の場合}\label{人名の場合}
{\bf \ref{主辞の選択における注意}}で述べたように，人名の場合，低頻度であったり，他の単語（職名や「氏」など）と結合\break
して，漢字列の途中に現われることが多く，{\bf \ref{テンプレートの説明}}のテンプレートでは共起情報が得られないことが多い．このため，「$固有名詞_1$＋$固有名詞_2$＋氏」を$固有名詞_1$を主辞とする名詞句 [[$固有名詞_1$\ $固有名詞_2$]\ 氏] としてまとめたうえで，{\bf \ref{一般の場合}}を適用する．ここで，$固有名詞_1$は姓，$固有名詞_2$は名と想定しているが，我々の辞書には固有名詞の細分がないため，単に固有名詞としている．

\vspace*{-3mm}
\subsubsection{一般の場合}\label{一般の場合}
ある複合名詞に対し共起例が不足する場合でも，主要な単語同士の掛かり受けは観測されていることは多く，このような情報を優先して評価することは効果的であると考えられる．我々は，この考え方をルールの形に整理し，共起例が不足する複合名詞の解析については，唯一の解が選択できるまで次のルールを順に適用することにより対応した：

\settowidth{\leftskip}{(1)\ }
\settowidth{\parindent}{(1)\ }
\parindent=-\parindent
(1)\ なるべく多くの共起情報を利用している依存構造を優先する．

\settowidth{\leftskip}{(2)\ }
\settowidth{\parindent}{(2)\ }
\parindent=-\parindent
(2)\ 共起情報が存在しない対については大きな定正値コスト（$>>1$）を与えた上で，コストが小さくなる依存構造を優先する．

\settowidth{\leftskip}{(3)\ }
\settowidth{\parindent}{(3)\ }
\parindent=-\parindent
(3)\ 共起情報が得られている終端の名詞対を結ぶ依存木上の距離（経過する最小ノード数）の和が少ないものを優先する．

\settowidth{\leftskip}{(4)\ }
\settowidth{\parindent}{(4)\ }
\parindent=-\parindent
(4)\ 依存関係にある名詞の，複合名詞内での位置の間の距離の和が少ないものを優先する．

\parindent=\originalparindent
\leftskip=0mm

背景となる考え方は，{\bf なるべく多くの観測例を反映させた上で，最小コストの構造を選ぶこと}（ルール1, 2)と，{\bf 観測された共起ペアはなるべく小さな部分木のなかでまとめること}（ルール3）の二点である．後者は，長い固有名詞が，部分的な固有名詞の連鎖として合成される場合を想定している．

すべての名詞対の間に共起関係が観測されないときは，(4)により最左導出優先戦略の解が得られるが，これはLauerが3単語の場合に用いたベースライン「左分岐優先」\cite{Lauer1995}を拡\break
充したものにあたる．これは言語学で指摘されている「日本語においては左分岐構造が優位である」\cite{奥津1978}という点の反映でもある．

ルールの適用例として，{\bf 図\ref{fig:heuristics}}(a)の例は，5個の名詞のうち，1番目と3番目，4番目と5番目の名詞のみに共起関係が観測された場合である．ルールを(1)$\rightarrow$(2)$\rightarrow$(3)の順で適用することにより，観測された例を優先させ，しかも，観測された共起ペアをはじめになるべく小さな部分木のなかでまとめている(I)が選ばれる．もし，{\bf 図\ref{fig:heuristics}}(b)のように，共起関係が一切観測されなかった場合，(4)に従って依存構造(III)が選ばれる．ここで，各ノードに付与された記号はそれ\break
ぞれの主辞を表わし，実線は共起例が観測された依存関係，破線はそうでない依存関係を表す（具体例は，{\bf \ref{解析例}}を参照）．

\begin{figure}[tbp]
  \begin{center}
    \leavevmode
    \epsfile{file=heuristics.epsf,scale=0.77}
  \end{center}
  \caption{ヒューリスティクスの適用例}
  \label{fig:heuristics}
\end{figure}

\section{実験結果}\label{実験結果}
以上に述べた手法を用いて，新聞記事から抽出した長さ5文字から8文字までの漢字だけから\break
なる複合名詞各100個，計400個について実験を行った．

\subsection{実験に用いた資料}\label{実験に用いた資料}
実験に用いたのは，日経新聞1992年の記事であり，対象とした複合名詞は，1月，2月
の記事\break
約27,000（文字数にして約700万文字）から連続漢字列を無作為に抽出した．最
初に抽出した400個のうち，34個は，
複合名詞ではない，または，依存構造が一意に判断不能のいずれかであったため，
解が一意的に定まるもののみになるまで無作為抽出を追加した．

\subsection{ベースライン}\label{ベースライン}
本論文では，提案手法の位置付けを示すためにベースラインと比較した．比較の対象としたベースラインは，テンプレートにより新たに発見された単語を追加して形態素解析結果を修正した後，人名と数表現部分は前処理し，共起情報抽出の過程で発見された長さ3の短い複合語はその部分でまとめたうえで，最左導出優先戦略を適用したものであり，最左導出優先戦略に文書走査法の特性を反映させて強化したものである．また，このベースラインは実際に扱った例における最頻掛かり受け構造を反映している．このベースラインとの比較により，共起情報やヒューリスティクスの効果を見ることができる．

\subsection{コーパスサイズの影響}\label{コーパスサイズの影響}
コーパスサイズの影響を調べるため，1月，2月の2月分の記事中から共起データを抽出した場合と，1年分全体から共起データを抽出した場合のそれぞれについて解析精度を調べた．

\subsection{結果}\label{結果}
{\bf 表\ref{表：文字数と精度}}は，提案方式については2つのコーパスサイズを含む4つの場合について，文字数ごとの\break
解析精度を評価したものである．

未知語が無い場合に表層的な共起データとヒューリスティクスで達成できる精度の上限を見積もるため，未登録語すべてを辞書に追加したうえで，どの程度の精度が得られるかを示したのが最下段の数値である．

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|c|} \hline
複合名詞の構成文字数 & 5 & 6 & 7 & 8 \\ \hline \hline
ベースライン & 81 & 72 & 65 & 53 \\ \hline
\parbox{10zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{center}
文書走査法\\
(新聞記事2ヶ月分)
\end{center}
\vspace*{-2mm}
} & 88 & 83 & 80 & 75 \\ \hline
\parbox{10zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{center}
文書走査法\\
(新聞記事1年分)
\end{center}
\vspace*{-2mm}
} & 90 & 86 & 84 & 84 \\ \hline
\parbox{11.5zw}{
\vspace*{-2mm}
\baselineskip 11pt
\hspace*{-3mm}
\begin{center}
文書走査法\\
(すべての未登録語を\\
\ \ 与え、新聞記事1年分)
\end{center}
\vspace*{-2mm}
} & 94 & 92 & 91 & 89 \\ \hline
\end{tabular}
\end{center}
\caption{複合名詞の文字数と解析精度}
\label{表：文字数と精度}
\end{table}

\noindent
\ref{表：単語数と精度}は，表\ref{表：文字数と精度}の内容を，掛かり受けに関わる単語数ごとに評価しなおしたものである．3行目以降の各行の数字は，正しく解析できた数を表す．単語数が2の場合，間違いが生じるのは未登録語などが正しく認識できない場合である．


\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|} \hline
複合名詞の構成単語数 & 2 & 3 & 4 & 5 & 6\\ \hline \hline
\parbox{10zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{center}
各構成単語数ごとの\\
複合名詞の数
\end{center}
\vspace*{-2mm}
} & 46 & 201 & 130 & 21 & 2 \\ \hline
ベースライン & 42 & 138 & 82 & 9 & 0 \\ \hline
\parbox{10zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{center}
文書走査法\\
(新聞記事2ヶ月分)
\end{center}
\vspace*{-2mm}
} & 42 & 176 & 91 & 16 & 1 \\ \hline
\parbox{10zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{center}
文書走査法\\
(新聞記事1年分)
\end{center}
\vspace*{-2mm}
} & 42 & 177 & 108 & 16 & 1 \\ \hline
\parbox{11.5zw}{
\vspace*{-2mm}
\baselineskip 11pt
\hspace*{-3mm}
\begin{center}
文書走査法\\
(すべての未登録語を\\
\ \ 与え、新聞記事1年分)
\end{center}
\vspace*{-2mm}
} & 46 & 191 & 112 & 16 & 1 \\ \hline
\end{tabular}
\end{center}
\caption{複合名詞の構成単語数と解析精度}
\label{表：単語数と精度}
\end{table}

ここで，単語数については，数字部分は前処理により1語と判定している．また，掛かり受け構造の正誤を判定する上で，掛かり受け構造を担う最小単位として，「大店法」のような略語系のものは，これ以上細分しないものを正解としている．獲得した単語の品詞については，現状では固有名詞の同定を行っていないため，固有名詞を文字列として獲得でき，その掛かり受けが正しく認識できても，正解とはしていない．例えば，「二子山」は普通名詞として認識され，「二子山親方」は[二子山 親方]と解析できるが，「二子山」を固有名として認識できないため誤りとしている（このようなケースは，新聞記事1年分を用いた文書走査法の場合，16例あった）．

{\bf 表\ref{表：文字数とヒューリスティクス利用数}}には，新聞記事1年分を用いた文書走査法において，共起例が不足した場合にヒューリス\break
ティクスを用いた例の総数とそれによる正解の総数を，複合名詞の長さごとに示した．{\bf 表\ref{表：単語数とヒューリスティクス利用数}}は，これを単語数ごとに調べたものである．

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|c|} \hline
複合名詞の構成文字数 & 5 & 6 & 7 & 8 \\ \hline \hline
\parbox{19zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{flushleft}
掛かり受けに関するヒューリスティクスを\\
用いた場合の数
\end{flushleft}
\vspace*{-2mm}
} & 15 & 29 & 47 & 45 \\ \hline
\parbox{19zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{flushleft}
掛かり受けに関するヒューリスティクスを\\
用いて解析に成功した場合の数
\end{flushleft}
\vspace*{-2mm}
} & 12(2) & 26(2) & 39(1) & 34(1) \\ \hline
\end{tabular}\\
{\footnotesize *括弧内は，単語間の共起が観測できず，最左分岐戦略が適用されたものの数}

\end{center}
\caption{複合名詞の長さごとのヒューリスティクスの利用状況}
\label{表：文字数とヒューリスティクス利用数}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{|c|c|c|c|c|} \hline
複合名詞の構成単語数 & 3 & 4 & 5 & 6 \\ \hline \hline
\parbox{19zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{flushleft}
掛かり受けに関するヒューリスティクスを\\
用いた場合の数
\end{flushleft}
\vspace*{-2mm}
} & 57 & 69 & 9 & 1 \\ \hline
\parbox{19zw}{
\vspace*{-2mm}
\baselineskip 11pt
\begin{flushleft}
掛かり受けに関するヒューリスティクスを\\
用いて解析に成功した場合の数
\end{flushleft}
\vspace*{-2mm}
} & 49(3) & 54(2) & 7(1) & 1 \\ \hline
\end{tabular}

{\footnotesize *括弧内は，単語間の共起が観測できず，最左分岐戦略が適用されたものの数}

\end{center}
\caption{複合名詞の構成単語数ごとのヒューリスティクスの利用状況}
\label{表：単語数とヒューリスティクス利用数}
\end{table}

\subsection{解析例}\label{解析例}
解析が成功した例と，失敗した例をいくつか示す．

\subsubsection{成功例}\label{成功例}

\noindent
・全体を覆う共起例がある場合．

\settowidth{\leftskip}{・}
\noindent
[[改正\ 大店法]\ 施行]

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
………"大店法"は，単語として獲得された．

\settowidth{\leftskip}{・}
\noindent
[[[土地\ 区画]\ 整理]\ 事業]]

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
………"整理"と"事業"は，「事業を整理する」という形の共起しか得られなかったが，解析は正しい．

\settowidth{\leftskip}{・}
\noindent
[[国内\ [独占\ 販売]]\ 契約]

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
………"独占"と"販売"，"国内"と"販売"，"販売"と"契約"の共起がそれぞれ強く観察され，全体として正しく解析された．

\settowidth{\leftskip}{・}
\settowidth{\parindent}{・}
\parindent=-\parindent
・共起例が不足した場合のヒューリスティクスにより，正しい解析がえられた例：

\settowidth{\leftskip}{・}
\noindent
[第二\ [湾岸\ 道路]]

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
……… "湾岸道路"が単独で観察された．この部分をまとめることにより，正解が得られた．

\settowidth{\leftskip}{・}
\noindent
[県\ [[環境\ 保全]\ 協会]]

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
……… "県"と"協会"，"環境"と"保全"の共起がそれぞれ単独で観察された．これらを優先する解釈により正解が得られた．

\settowidth{\leftskip}{・}
\settowidth{\parindent}{・}
\parindent=-\parindent
・前処理により，解が一意に絞られる例

\settowidth{\leftskip}{・}
\noindent
[同 [百二十七万 人]]

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
……… "百二十七万"は数字としてまとめられ，[百二十七万 人]までが「数字＋接辞」とし\break
て前処理される．

\parindent=\originalparindent
\leftskip=0mm

\subsubsection{失敗例}\label{失敗例}

\settowidth{\leftskip}{・}
\settowidth{\parindent}{・}
\parindent=-\parindent
・全体を覆う共起例があっても間違いを生じる例

\settowidth{\leftskip}{・}
\noindent
[発売 [開始 以来]]（正解は[[発売 開始] 以来]）

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
……… "発売"と"開始"，"発売"と"以来"，"開始"と"以来"のすべての対が観察されたが，"発売"と"以来"の共起が強く，これに解釈が引っ張られた．

\settowidth{\leftskip}{・}
\settowidth{\parindent}{・}
\parindent=-\parindent
・共起例が不足で，ヒューリスティクスにより間違いを生じる例

\settowidth{\leftskip}{・}
\noindent
[酸素 [[製造 装置] 開発]]（正解は[[[酸素 製造] 装置] 開発]）

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
……… "酸素"と"製造"という共起が観察されず，観察された"製造装置"，"装置開発"等の共起を優先する解釈に引っ張られた．

\settowidth{\leftskip}{・}
\settowidth{\parindent}{・}
\parindent=-\parindent
・未登録固有名詞により間違いが生じる例

\settowidth{\leftskip}{・}
\noindent
[[[小宮 路] 清行] 社長]　（正解は，[[小宮路 清行] 社長]）

\settowidth{\leftskip}{・[[改正……}
\settowidth{\parindent}{………\ }
\parindent=-\parindent
……… "小宮路"が"小宮/PN"+"路/N"と分解され回復できなかった．

\parindent=\originalparindent
\leftskip=0mm

\subsection{未登録語を含む複合名詞について}\label{未登録語を含む複合名詞について}
未登録語に関しては，400個の複合名詞中，形態素解析辞書未登録語を含むものが46個，分類語彙表未登録語を含むものが117個，どちらか一方を含むものが120個あったが，これらのう\break
ち85個は正しく解析された．

形態素解析用辞書に登録されていない未登録語のうち，25個は共起例抽出の段階で正
しく獲得され，
それらを含む複合名詞のうち18個は正しく解析された．
その他単語境界のみを正しく獲得した未登録語は16個あった．

正しく獲得できなかった未登録語の例は，次の通り：

\noindent
・単語境界は検出できたが，品詞が誤り：

\settowidth{\leftskip}{・単語}
\noindent
渚園（固有名詞．施設名），李鵬（人名），小和田（人名）

\leftskip=0mm

\noindent
・単語境界も検出できない：

\settowidth{\leftskip}{・単語}
\noindent
車駕之古祉（地名），日豊（「日豊本線」に出現），欽用（人名．「上条欽用氏」に出現）

\leftskip=0mm

\section{考察}\label{考察}
ベースラインは，数字部分や短い複合語をまとめたうえで，基本的には最左導出優先戦略をとっているが，その精度は，{\bf 表\ref{表：単語数と精度}}から，3単語で約69\%であり，日本語と英語の違いにも関わらず，Lauerの「3単語65\%」\cite{Lauer1995}というベースライン精度と類似している．

提案手法は{\bf 表\ref{表：文字数と精度}}，{\bf 表\ref{表：単語数と精度}}のどちらで見てもベースラインを大きく上回っており，共起情報を用いることによる効果があきらかとなっている．また，コーパスサイズ拡大の有効性も示されており，実験した範囲では，コーパスサイズの拡大により正解は増加しても，新たな間違いが発生することはなかった．これは，新聞記事1，2月分と通年分で比較したため，文書の同質性・関連性が比較的保たれたためと思われる．

共起例が不足する場合に用いたヒューリスティクスは，例えば，3単語からなる複合名詞の28\%に適用され，その86\%（49例）に正解を与えている．これらの中で，共起例が全く見つからず，単なる最左導出優先戦略で出力されたものは3例に過ぎず，この傾向は4語，5語の場合も変わらない．したがって，実際に観測された共起関係をできるだけ優先するという考え方が有効であることがわかる．

{\bf \ref{未登録語を含む複合名詞について}}で述べたように，400個の複合名詞のうち形態素解析辞書またはシソーラス未登録語を含むものは120個であった．これはクラス間共起を用いる手法を用いる場合には障害となるが，提\break
案手法は表層情報しか用いないため，形態素解析さえ成功すれば問題とはならず，これらのうち70\%を正しく解析できた．特に，形態素解析の過分割誤りで生じた誤りのうち18例は，未登録語を獲得してこれを修正した上で正解を得ており，提案手法がクラス間共起を用いる方法に比べて頑健であることを示している．

本論文で提示した未登録語や短い部分複合語の発見手法は，文字種，長さ，出現環境のみを用いた単純な手法であるが，略称や部分複合語の発見には効果的であった．固有名詞を除いて，複合語中にのみ出現し，他に単独で現れない名詞は少ないこと，特に重要な未登録語は単独で出現しやすく，略称系の未登録語は一般的に重要度が高いこと，等の理由で，単純な手法でも効果が得られたものと思われる．

\section{おわりに}\label{おわりに}
本論文では，新聞記事に現われる複合名詞内の掛かり受け構造を決定するために，コーパス中を複数個のテンプレートを用いて走査し，複合名詞構成単語間の共起情報を抽出し，複合名詞の解析を行う手法について述べた．

構成単語の出現環境と辞書引きの結果から，共起データ収集と同時に，略称，短い複合語，固有名詞の一部等の未登録語を検出し，それらの共起情報も追加探索することにより，未登録語に対しても頑健かつ高精度な複合名詞解析が実現できた．

また，共起例が十分に得られなかった場合のため，観察された共起例をなるべく有効に利用するヒューリスティクスを提案し，その効果が示された．

解析精度においては，それ自体かなり高精度である，ベースラインとして用いた最左導出法に基づく手法を大きく上回り，長さ8の複合名詞についても80\%以上の精度で解析できることがわかった．

提案した手法は，テンプレートマッチしか用いないため，頑健性，簡便性，移植性において優れている．

今後の課題としては，以下のことが挙げられる．

\noindent
{\bf 人名等の推定}

単語境界が正しく獲得された未登録名詞であって，品詞が正しく判定されなかった16個の固有名詞のうち8個は人名であった．これらは，役職名や，「氏」のような周囲の手がかり語を用いることにより推定可能であると考えられる．このような部分については，ルールに基づく手法を取り入れてゆくことが効果的と思われる．

\noindent
{\bf 解析の効率}

本研究では，表層情報のみを用いて達成できる手法の能力評価が目的であったため，データ抽出を含めた解析速度は考慮していない．共起情報の抽出は，ディスク上の新聞1年分のテキストファイルの線形探索を用いており，掛かり受けの解析は，共起情報が発見されなかった主辞の間の掛かり受けのコストを仮想的な高い価に設定することにより，発見された単語共起対が最も多く用いられている掛かり受け構造中で，最小コストを持つものをまず導出し，その中から必要に応じてヒューリスティクスを用いて最尤解を選出することで行った．実験の範囲では，最尤解の選択は，共起情報抽出に比べて無視できる程度の時間しかかからなかった．

共起情報抽出の高速化のためには，テキストに文字インデックスを付与してメモリ上に置き，テンプレートマッチを並列化し，共起データを再利用するなどの工夫が考えられ，1桁から2桁の高速化は可能と見積もれる．従って，今回の実験に用いた程度の複合名詞であれば，「文書走査法」の枠組みでも必ずしもリアルタイムの解析を逸脱しない．

掛かり受け構造の導出には，ボトムアップ・チャート法を用いた．文字列の長さを$n$として，チャートの作成自体は${\rm O}(n^3)$で完了するが，最小コスト解の中からさらにヒューリスティクスを用いて最尤解を選択する場合，現在のままでは，複合名詞の長さの指数関数で個数が増大する可能な掛かり受け構造間の比較が必要なため，問題となる．

コスト計算に掛かり受けの距離等を含めることにより，ヒューリスティクスまで考慮しながら$n$の多項式時間でチャートを作成することも可能であるため，これを実装する必要がある．

\noindent
{\bf 言い替え表現}

単語の共起頻度を記録する際に用いたテンプレートの種類は，掛かり受け解析には現
在利用していない．ある依存構造が選ばれた場合，
用いられたテンプレートを参照して，
複合名詞を通常の文に言い替えられる可能性がある．言い替え手法の研究は，言語生成に関係する興味深い問題である．　

\noindent
{\bf 形態素解析における未知語検出・クラス間共起法との統合}

形態素解析の研究の進展により，形態素解析部単独で「住専」のような未登録語を高精度に推定可能となった場合，これをただちに未登録語の発見に利用することができる．

クラス間共起法との統合については，文書走査による共起情報抽において構成単語同士の共起例が十分に得られない場合に，クラス間共起法に切り替えることが考えうる(Lauerによれば，十分に共起情報がある場合，クラスを介すより，直接単語共起を用いた方が精度が良い\cite{Lauer1995}．実際，我々の例では，ヒューリスティクスが必要ない場合の4単語からなる複合名詞の解析精度は約88\%であった)．

このとき，複合語構成単語中にクラス所属不明語が存在する場合，それらの所属クラスを推定する必要があるため，それらの単語の出現環境を調べる必要がある．このためには，文書走査法の自然な拡張として，テンプレートを用いて，それらの単語の出現環境を単語ベクトルとして抽出し，これらのベクトルと，あらかじめ用意された，クラスを特徴付けるベクトルの比較により，単語の所属クラスを推定することが考えられる．そして，各単語の所属が推定できた時点で，クラス間共起モデルを利用する．クラス間共起でも共起情報が不足するときは，例えば今回提案したヒューリスティクスを用いて最尤解を決定すれば良い．組み合わせは他にも考えられるため，さまざまな方法を比較する必要がある．

\noindent
{\bf 他の課題への適用}

テンプレートによる表層的なデータ収集のみで，かなり困難とされてきた複合名詞解
析が高精度で達成できることは，例えば構文解析の曖昧性解消問題等にも同様の手法
が応用できることを示唆している．
今後は，文書走査法の，そのようなタスクへの適用を図りたい．

\vspace{-0.5cm}



\bibliographystyle{jnlpbbl}
\bibliography{v05n4_03}

\begin{biography}
\biotitle{略歴}
\bioauthor{久光 徹}{
1984年東京大学理学部数学科卒業．
1986年同大学院修士課程修了．
同年より(株)日立製作所\ 基礎研究所に勤務．自然言語処理の研究に従事．現在に至る．1995年1月より1年間Sheffield大学客員研究員．情報処理学会，電子情報通信学会，言語処理学会，ACL各会員．}
\bioauthor{新田 義彦}{
1969年東京大学理学部数学科卒業．
同年より(株)日立製作所中央研究所に勤務．1974年より同システム開発研究所に勤務．1985年より同基礎研究所に勤務．この間1976〜1977年スタンフォード大学工学部OR学科(M.S.)．形式言語，情報検索，機械翻訳，自然言語理解の研究に従事．1995年より日本大学経済学部教授（理工学部兼任教授）．日本ソフトウェア科学会，ACM，ACL各会員．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}
\end{document}


