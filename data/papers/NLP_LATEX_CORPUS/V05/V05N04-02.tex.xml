<?xml version="1.0" ?>
<root>
  <title/>
  <author/>
  <jkeywords/>
  <section title="Introduction">Bunsetsu,whichiscomprisedofacontentwordwithorwithoutbeingfollowedbyastringoffunctionwords,isaconvenientunitfordependencystructureanalysisofJapanese.SincetherearenospacesindicatingbunsetsuboundariesintheorthographicwritingofJapanese,asentencemustbesegmentedintobunsetsu'spriortodependencystructureanalysis.Accordingtotheelementarydefinitionofbunsetsu,(NagaoEd.1984,p.12),suchsegmentationmightlooksimple.Thereare,inreality,manyfactorsthatcomplicatetheproblem.Forexample,Chinesecharacterscanbeconcatenatedtoformacompoundword.Somenounsandverbshavefunctionsdifferentfromtheiroriginalones.Forexample,thenoun``yoru''(``night'')functionsalsoasanadverb,andtheverb``aru''(``exist'')functionsalsoasaformalverb,butsomesystemsofpartsofspeechdonotdistinguishbetweencommonnounandtemporalnoun,orbetweenverbandformalverb.Also,therearemanyidiomaticusagesofmorphemeconcatenations.Allthesematterscausedifficultiesindetectingbunsetsuboundaries.Moreover,thereisnosystemofpartsofspeechinJapanesethathasreceivedageneralconsensus.Thissituationgivesrisetoanotherobstacletoestablishingastandardmethodofbunsetsusegmentation.Therehavebeentwoapproachestothebunsetsusegmentationproblem:onebasedonanautomatonrepresentingadefinitionofbunsetsu,(FujioandMatsumoto1997),andtheotherbasedonasetofhandicraftrules,(Suzuki1996).Intheformerapproach,onehastogiveadefinitionofbunsetsumanually.Thelatterinvolveshandiworkingettingknowledgeaboutbunsetsuboundaries.Thusbothapproacheshaveproblemsinkeepingconsistency,coverageandoptimalityofmanuallyobtainedknowledge.Whenthesystemofpartsofspeechand/orthetaskdomainarechanged,onehastorepeatthewholemanualprocesstogetnewknowledge,whichisratherlaborious.Thispaperproposesamethodofbunsetsusegmentationusingaclassificationtree,bywhichknowledgeaboutbunsetsuboundariesisautomaticallyacquiredfromasmallamountoftrainingdata(about30to100sentences)(ZhangandOzeki1997).Itcanadaptquicklytoanewsystemofpartsofspeech,andalsotoanewtaskdomainwithouttheneedforchangingthealgorithm.Section2reviewstheclassificationtreetechniquebriefly.Section3givesanaccountofhowtoapplytheclassificationtreetechniquetothebunsetsusegmentationproblem.Section4describesexperimentsonanATRcorpus,includinggenerationandevaluationofaclassificationtree,togetherwithcomparisonsoftheproposedmethodwithasimplerule-basedmethodandtheBayesdecisionrule.Section5isdevotedtothedescriptionofexperimentsonanEDRcorpuswithdetailederroranalysisoneachleafofthegeneratedtree.Section6summarizestheresults,andsuggestssomedirectionsforfurtherimprovement.</section>
  <section title="Classification Tree">Aclassificationtreeisabinarytreethatclassifiesobjectsintoclasses,(Breimanetal.1984,SafavianandLandgrebe1991).Thistechniquehasbeenwellstudiedinsuchfieldsaspatternrecognitionandmachinelearning.Throughanautomaticgenerationofaclassificationtree,onecanrapidlyacquireunderlyingregularitiesinalargeamountofdata,whicharedifficultorevenimpossibleforahumantocapturebyintuition.TheprocessofclassificationbyatreeisshowninFig.1.Associatedwitheachnon-terminalnodeofaclassificationtreeisatest.Ifanobjectpassesatest,itreaches``yes''child-node;otherwise``no''child-node.Theprocessisrepeateduntiltheobjectreachessometerminalnodeorleaf,whichhasbeenassignedtoaclasslabel.Onlytwoclasses,c_1andc_2,willbeconsideredhere.Inordertogrowaclassificationtreefromtheroot,objectswithclasslabels,ortrainingobjects,arenecessary.Alsoafinitesetoftestsmustbepreparedbasedonproblem-specificknowledge.Supposethatatreehasbeengrowntosomesize.Itconsistsofthreekindsofnodes:non-terminalnodes,leaves,andactivenodesyettobeprocessed.Lettbeanactivenode,andL(t)thenumberoftrainingobjectsthatreacht,amongwhichthenumberofobjectsbelongingtoc_iisdenotedasL_i(t)(i=1,2).Thentheimpurityoft,Giniindex,(Gelfand,Ravishankar,andDelp1991),isdefinedasI(t)=L_1(t)L(t)L_2(t)L(t).displaymathBecauseoftheconstraintL_1(t)/L(t)+L_2(t)/L(t)=1,I(t)attainsthemaximumvalueof1/4(=1/21/2)whenL_1(t)/L(t)=L_2(t)/L(t)=1/2.IftheimpurityislowerthanaprescribedthresholdI_0,thentisdecidedtobealeaf.Otherwiseallthetestsaretriedexhaustively.Bymeansofatest,thetrainingobjectsthatreachtaredividedintothosethatreachthe``yes''child-nodet_yesandthosethatreachthe``no''child-nodet_no.LetL(t_x)denotethenumberoftrainingobjectsthatreachchild-nodet_x,wherexequals``yes''or``no''.ThenthetestthatmaximizesthereductionofimpurityI(t)=I(t)-L(t_yes)L(t)I(t_yes)-L(t_no)L(t)I(t_no)displaymathisselectedasthetestassociatedwitht,andnewactivenodes,t_yesandt_no,areappendedundert.Ifthereisnotestthatreducestheimpurityoft,thentisdecidedtobealeaf.Withtherootastheinitialactivenode,theaboveprocedureisrecursivelyiterateduntilalltheactivenodesareturnedintonon-terminalnodesorleaves.Aleaftisassignedtoclasslabelc_iifthemajorityoftrainingobjectsthatreachtbelongtoclassc_i(i=1,2).</section>
  <section title="Application of Classification Trees to Bunsetsu Segmentation">Bymorphologicalanalysis,asentenceissegmentedintomorphemes.Theattributevaluesofeachmorphemesuchasthepartofspeechandtheorthographicexpressionarealsoobtained.Anobjecttobeclassifiedhereisapairofconsecutivemorphemes(leftmorphemeandrightmorpheme,henceforth)inasentencewiththeirattributevalues.Thepurposeofclassificationistodecidewhethertheboundarybetweentwoconsecutivemorphemes(boundaryinfocus,henceforth)isabunsetsuboundary;thisisaclassificationproblemfortwoclasses.AsentenceconsistingofNmorphemesyieldsN-1objects.Amongtheattributesofamorpheme,thepartofspeechisconsideredtobemostimportant.Insomecases,however,thepartofspeechalonedoesnotprovideenoughinformationforbunsetsuboundarydetection.Letustake``niaru''and``tearu''asexamples.Theboundarybetween``ni''and``aru''shouldbeabunsetsuboundarybecausethis``aru''functionsasaverb,whereastheboundarybetween``te''and``aru''shouldnotbeabunsetsuboundarybecausethis``aru''functionsasaformalverb.Somesystemsofpartsofspeech,however,donotdistinguishbetweenverbandformalverb.Bysuchasystembothof``niaru''and``tearu''aretaggedas``particleverb'',whichhasnoinformationaboutthedistinctionbetweentheabovetwocases.Thereforetheorthographicexpressionisemployedasanothertestattributeforsomerangeofmorphemesthatareselectedbyapreliminaryexperiment.Alsothewildcard``*''isintroducedasasymboltomatchanyattributevalues.Letpos_ibeapartofspeech,andW(pos_i)thesetoforthographicexpressions,including``*'',ofmorphemesthatbelongtopos_iandareselectedbythepreliminaryexperiment.Thenthesetofthepairsofpos_ianditsorthographicexpressionsisdenotedaspos_iW(pos_i).LetSbethesetofallsuchpairsplus(*,,*):S=[_ipos_iW(pos_i)](*,,*).displaymathThenSSisemployedasthesetoftests(classificationrules)inthiswork.Atesttakestheform(pos_1,e_1)(pos_2,*),forexample.Anobjectwillpassthistestifthepartofspeechoftheleftmorphemeequalspos_1,itsorthographicexpressionequalse_1,andthepartofspeechoftherightmorphemeequalspos_2.Intheprocessofgrowingaclassificationtree,anactivenodetisdecidedtobealeafiftheconditionI(t)I_0issatisfied,orifthereisnotestthatreducestheimpurityoft.Sincethemaximumvalueoftheimpurityis1/4asstatedintheprevioussection,thethresholdI_0issetatavaluebetween0and1/4.AthresholdvalueI_00allowssomeamountofimpuritylowerthanI_0toremainatleaves,therebycontrollingtheover-growthoftheclassificationtree.</section>
  <section title="Experiments on  ATR Corpus">Bytheproceduredescribedabove,classificationtreesforbunsetsusegmentationweregeneratedandevaluatedonanATRcorpus,(Abeetal.1990).TheATRcorpuscontains503sentencestakenfromnewspapers,magazines,andetc.Thesentencesarelabeledwiththebunsetsuboundary,andthemorphemesarelabeledwiththepartofspeech.Forthesakeofopenexperiments,randomlyselected100sentenceswereusedasevaluationdata,whichhad1298objects,andtheremaining403sentencesastrainingdata,fromwhichtrainingdataofdifferentsizesweredefinedasinTable1.Theattributeusedfortestherewasthepartofspeechonly;theorthographicexpressionwasnotusedbecausetheATRcorpus'spartofspeechsystemdistinguishesformalverbsandverbs.Thereare25partsofspeechintheATRcorpus.4.1\\OptimumValuefortheThreshold$I_0$flushleftThethresholdI_0controlsthegrowthofatreeinthetrainingstage.AsmallervalueofI_0willproducemoreleaves,resultinginfinerclassificationofthetrainingobjects.However,thereisapossibilitythattoofineclassificationofthetrainingobjectscausesover-fitting,therebygivinganadverseeffectongeneralizationpowerofthegeneratedtree.InordertodecidetheoptimalvalueofI_0,classificationtreesweregeneratedwithvariousvaluesofI_0rangingfrom10^-5to0.24,andfortrainingdataofdifferentsizes:5,50,and403sentences.Table2showstheerrorratesofthegeneratedtreesfortheevaluationdata.Asfarasthisexperimentshows,asmallervalueofI_0givesabetterresultforanytrainingdatasize.AlthoughwecannotdrawageneralconclusionimmediatelyfromthisresultthattheoptimalvalueofI_0isalways0,wetentativelysetI_0at0inthefollowingexperiments.Thismeansthatanactivenodeistobesplitintochild-nodesaslongasthereisatestthatreducestheimpurityofthenode.4.2\\GenerationandEvaluationofaClassificationTreeflushleftAsanillustration,wetakeupaclassificationtreegeneratedbytrainingdataofthelargestsize,403sentences.Thetreeisformedwith77nodes,inwhich39areleaves.ApartofthetreeneartherootisillustratedinFig.2.Therewasatendencythatthetestsrelatedtopartsofspeechwithhigherfrequenciesappearedinthenodesclosertotheroot.Thusitcanbesaidthatanefficientorderoftestswasrealizedautomatically.Table3showstheclassificationresultofthetreeontheevaluationdata.ThesymbolYsignifiesthattheboundaryinfocusisabunsetsuboundary,andNsignifiesthatisnot.Thearrowdenotestheclassificationoperationbythetree.So,|YN|meansthenumberofbunsetsuboundarieswhichwerenotjudgedasboundaries.93%oftheerrorswereofthetypeYN.Itwasfoundthatmostoftheerrorsofthistypecamefromtheboundariesbetweencommonnouns.Thegeneratedtreedecidedaboundarybetweencommonnounsnottobeabunsetsuboundary.However,manyofthefirstcommonnounsinsuchboundarieswereinfactthosethatfunctionedasadverbs,andthiskindofobjectswerelabeledasbunsetsuboundariesinthecorpus.Thus,thecoarsenessofsub-categorizationofnounwasapartofthecausesoftheerrors.4.3\\ComparisonwithaRule-BasedMethodflushleftItwillbemeaningfultocomparetheperformanceoftheproposedmethodwiththatofarule-basedmethod.Thebasicstructureofabunsetsucanbedefinedbyusingthefourcategories(prefix,suffix,contentword,functionword)asfollows(NagaoEd.1984,p.12):[([Prefix](ContentWord)[Suffix])^*[FunctionWord]^*,]where``[]''denotesthattheitemisoptional,and``*''denotesthattheitemappearsonceormorethanonce.Basedonthisdefinition,wehaveconstructedasimple,basicruleforbunsetsusegmentationasshowninTable4.Theboundarybetweencontentwordsmayormaynotbeabunsetsuboundary.Therefore,tworuleswereconsidered:RuleImakesabunsetsuboundarybetweencontentwords,andRuleIIdoesnot.ofthepartsofspeechofATRcorpuswasassignedtooneofthefourcategories(NagaoEd.1984,p.92),andbunsetsusegmentationexperimentswerecarriedoutusingthesameevaluationdataasin4.2.Theaccuracyof95.9%forRuleIand91.1%forRuleIIwereobtained.SinceRuleIgaveabetterresultthanRuleII,theperformanceofRuleIwascomparedwiththatoftheclassificationtreemethod.Fig.3showsthatwhenthetrainingdatasizeislargerthanabout20sentences,theclassificationtreemethodoutperformstherule-basedmethod.Thesuperiorityoftheclassificationtreemethodismoreevidentwhenthetrainingdatasizeislarger.4.4\\ComparisonwiththeBayesDecisionRuleflushleftItwillalsobeofinteresttocomparetheperformanceoftheclassificationtreemethodwiththatofapurelystatisticallearninganddecisionmethod.Forsuchamethod,wetakeuptheBayesdecisionrulehere.TheBayesdecisionruleiswellknownforitsminimumerrorproperty,(Fukunaga1990).Thatis,iftheclassconditionalprobabilitydistributionofobjectstobeclassifiedandtheaprioriclassprobabilitydistributionareknownexactly,thenitispossibletoclassifyobjectswithsmallererrorsthananyothermethods.However,thoseprobabilitydistributionsarenotknowningeneral,andhavetobeestimatedfromtrainingdata.Thus,itispossiblethatothermethodsoutperformtheBayesdecisionruledespiteitsoptimumpropertyintheidealcase.TheBayesdecisionruleforbunsetsusegmentationisimplementedinthefollowingway.Let(pos_1,pos_2)beaboundaryinfocusofwhichtheleftandrightmorphemeshavepartsofspeech,pos_1andpos_2,respectively.ThusP(Y|pos_1,pos_2)denotestheprobabilitythattheboundary(pos_1,pos_2)isabunsetsuboundary.TheprobabilityP(Y|pos_1,pos_2)canbeestimatedfromtheco-occurrencecountas:[P(Y|pos_1,pos_2)Count[(pos_1,pos_2)isaboundary]Count[(pos_1,pos_2)],]whereCount[X]denotesthenumberofoccurrencesoftheeventXinthetrainingdata.Inthesameway,P(N|pos_1,pos_2),theprobabilitythattheboundary(pos_1,pos_2)isnotabunsetsuboundary,canbeestimated.Theboundary(pos_1,pos_2)isdecidedtobeabunsetsuboundaryifandonlyif[P(Y|pos_1,pos_2)P(N|pos_1,pos_2).]TheamountoftrainingdatatoestimatetheprobabilitydistributionswasvariedaccordingtoTable1.WetriedtwodifferentwaystodealwiththecaseCount[(pos_1,pos_2)]=0:onethatmakesabunsetsuboundarybetweensuchpos_1andpos_2,andtheotherthatdoesnot.Becausetheformergaveabetterperformancethanthelatterwhenthetrainingdatasizewaslargerthan50sentences,theresultusingtheformerwascomparedwiththatoftheclassificationtreemethod.Fig.3showsthatforanytrainingdatasize,theclassificationtreemethodoutperformstheBayesdecisionrule.Thesuperiorityoftheclassificationtreemethodbecomesmoreremarkableasthetrainingdatasizedecreases.Trainingdataof30sentencesisenoughtoachievetheerrorrateof2.4%;forthattrainingdatasize,theerrorrateoftheBayesdecisionruleis5.5%.Thisshowsthattheclassificationtreemethodhasastrongpowerofgeneralizingtheknowledgebeyondthetrainingdatasothatunseendatacanbeclassifiedwithhighaccuracy.InordertocheckthestatisticalsignificanceoftheperformancedifferencebetweentheclassificationtreemethodandtheBayesdecisionrule,theaposterioriprobabilitymethod,(Ozeki1997)wasemployed.Inthismethod,thesuperiorityofonemethodtotheotherismeasuredbytheaposterioriprobabilityoftheeventthatthetrueclassificationrateofonemethodishigherthanthatoftheother,giventheclassificationresultsofthetwomethods.Itutilizes,notonlythenumberofobjectsclassifiedcorrectlybyeachmethod,butalsothenumberofobjectsclassifiedcorrectlybybothmethods.TheresultsareshowninTable5.ThisconfirmsthattheclassificationtreemethodissurelysuperiortotheBayesdecisionrule,andthatthesuperioritybecomesmoreprominentwhenthetrainingdatasizebecomessmaller.OneproblemoftheBayesdecisionruleisthatitisvulnerabletothesparsenessoftrainingdata;whenCount[(pos_1,pos_2)]isequalto0orcloseto0,theestimationofP(Y/N|pos_1,_2)becomesimpossibleorunreliable.Variousmethodstoalleviatethisproblemareconceivable.Forexample,wecouldestimateP(Y/N|pos_1,pos_2)withP(Y/N|pos_1,*)+(1-)P(Y/N|*,pos_2),whereisasuitablychosenweight.Itiseasytoshowthatwhen=1/2,thislinearinterpolationmethodisequivalenttoadecisionmethodbasedoncomparisonofthefourprobabilitiesP(Y/N|pos_1,*)andP(Y/N|*,pos_2).Wecouldalsouseacoarserclassificationofthesetofallthe(pos_1,pos_2)toreplaceP(Y/N|pos_1,pos_2)withP(Y/N|(pos_1,pos_2)),where(pos_1,pos_2)istheclasstowhich(pos_1,pos_2)belongs.AllthesemethodsmightimprovetheperformanceoftheBayesdecisionrule.However,itisdifficulttodecidewhichoneshouldserveasabaseline.ForthisreasonwehavecomparedtheproposedmethodwiththeBayesdecisionruleinitsmostprimitiveform,andlefttheproblemofitsimprovementuntouched.</section>
  <section title="Experiments on  EDR Corpus">Inordertoseetheinfluenceofdifferentsystemsofpartsofspeechanddifferentsentencematerialsontheresultsofclassificationtree,experimentsonanEDRcorpus,(EDR1996)werealsocarriedout.5.1\\LabelsandPartsofSpeechinEDRCorpusflushleftTheEDRcorpushasnolabelsindicatingbunsetsuboundaries.Instead,ithasdetailedinformationaboutthesyntacticstructureofsentences.Byutilizingthisinformationandthedefinitionofbunsetsu,(NagaoEd.1984,p.12),400sentenceswerelabeledwiththebunsetsuboundary.Then6984objectsfortrainingwereextractedfromrandomlyselected200sentences,and7110objectsforevaluationfromtherest.Thesub-categorizationofnounintheEDRcorpusseemedtoocoarseforthepresentpurpose.Thereforeitwasaugmentedbyusingthesemanticidentifier,whichwascommontothecorpusandthedictionary.Theresultingnumberofpartsofspeechwas19,inwhichnounwassub-categorizedintocommonnoun,propernoun,numerals,temporalnounandformalnoun.IntheEDRcorpus,sub-categorizationofparticleiscoarserthanthatintheATRcorpus.Moreover,thereisnosuchpartofspeechasformalverb,whichisemployedasapartofspeechintheATRcorpus.Althoughalargeportionofboundariesbetweenparticlesandverbsarebunsetsuboundaries,quiteafewofthemarenot.Theboundarybetweenaparticleandaverbthatfunctionsasaformalverb,forexample,isnotabunsetsuboundary.Therefore,aswasexplainedinSection3,thetestoftheform(particle,,)(verb,,)hasnopowertodistinguishbetweenabunsetsuboundaryandanonbunsetsuboundary;thepartofspeechinformationalone,especiallyforboundariesrelatedtoparticlesandverbs,isnotenoughforbunsetsusegmentation.Forthatreason,theorthographicexpressionwasalsousedasanattributefortesttogetherwiththepartofspeech.Inthisexperimenttheorthographicexpressionsofmorphemes,``aru''(``exist''),``iru''(``exist''),``kuru''(``come'')forverb,``nai''(``not'')foradjective,and``te'',``de''forparticle,wereselected.5.2\\ExperimentalResultflushleftAclassificationtreewith175nodeswasgeneratedinthisexperiment.Itwasfoundthatsegmentationrulesrelatedtotheorthographicexpressionsemployedwereextracted.Forexample,theboundarybetweenaparticleandaverbwasdecidednottobeabunsetsuboundaryiftheorthographicexpressionoftheparticleequals``de''andthatoftheverbequals``aru''.ItwasobservedthatthetreegeneratedontheEDRcorpus(EDRtree,henceforth)acquirednewsegmentationrulesthatwerenotacquiredinthetreegeneratedontheATRcorpus(ATRtree,henceforth):Theboundarybetweenatemporalnounandacommonnounwasdecidedtobeabunsetsuboundary,whileitwasnotbytheATRtree.(BecausetheATRcorpushasnosuchpartofspeechastemporalnoun,itmakesnodistinctionbetweenatemporalnounandacommonnoun.)Theboundarybetweenanauxiliaryverbandacommonnounwasdecidedtobeabunsetsuboundary,andtheboundarybetweenanauxiliaryverbandaformalnounwasnot.TheATRcorpusmakesnodistinctionbetweenacommonnounandaformalnoun.Theboundarybetweenaparticleandacommonnounwasdecidedtobeabunsetsuboundary,andtheboundarybetweenaparticleandaformalnounwasnot.TheATRcorpusmakesnodistinctionbetweenacommonnounandaformalnoun.Theboundarybetweentwocommonnounswasdecidedtobeabunsetsuboundary,andtheboundarybetweentwopropernounswasnot,whileneitherwasdecidedtobeabunsetsuboundarybytheATRtree.(TheATRcorpusdoesnotcontainenoughamountofdataforextractingsuchasegmentationrule.)TheEDRtreeacquired12rulesrelatedtosymbols,whiletheATRtreeacquirednosuchrules.(Therewerenooccurrencesofsymbolsalthoughithasacategory``symbol''asapartofspeechintheATRcorpus.)Thus,theclassificationtreeextractedthenewsegmentationrulesexploitingthesub-categorizationofnounandanincreasedamountoftrainingmaterialsavailableintheEDRcorpus.Inthiswayaclassificationtreecanadapttoanewsystemofpartsofspeechandanewtaskdomain.The200sentencesoftheevaluationdataweresegmentedbythetree,andtheclassificationresultwasobtainedasinTable6.5.3\\ErrorAnalysisonLeavesflushleftItisnotedthattheaccuracyof96.2%inTable6isalittlelowerthanthatfortheATRcorpusinTable3.Inordertofindoutthecausesoferrors,everyleaftoftheEDRtreewasexaminedindetailbymeasuringthreequantities:thelocalerrorrate,i.e.theerrorrateatleaft,definedas[LER(t)=NumberofevaluationobjectsmisclassifiedattNumberofevaluationobjectsthatreacht,]thenumberoftrainingobjectsthatreacht(NTO(t)),andtheimpurityoftonthetrainingobjects(IMP(t)).Fig.4andFig.5arescatterplotsofLER(t)versusNTO(t),andLER(t)versusIMP(t),respectively.Fig.4showsthataleafformedwithasmallernumberoftrainingobjectsislikelytohaveahigherlocalerrorrate.Fig.5indicatesthataleafwithgreaterimpurityontrainingobjectstendstohaveahigherlocalerrorrate.ThepointIMP=0isanexception.Atthispointthelocalerrorratesdistributefrom0to100%.TheblackmarksinFig.4showtheleaveswithIMP=0.Asseenhere,aleafwithIMP=0isveryreliableaslongasthereareenoughnumberoftrainingobjectsreachingthatleaf.However,leavesformedwithlessthan30trainingobjectsareunreliableandthelocalerrorratesbecomeunpredictable.Theseresultsleadtoaconclusionthattheclassificationaccuracyofaleafisaffectedbyboththenumberoftrainingobjectsreachingtheleafandtheimpurityoftheleafonthetrainingobjects.ItwasfoundthatintheEDRtreetherewerequiteanumberofleavesformedwithsmallnumberoftrainingobjectsorwithhighimpurity.Itwasjustattheseleavesthatmanyoftheerrorsoccurred.Thehighimpurityremainedbecausetherewasnotestthatcouldreduceit.Theinformationcarriedintwoconsecutivemorphemesandtheattributevaluestestedinthisexperimentcouldnotmakefurtherreductiononimpurity.Soonesolutiontothisproblemwouldbetowidenthewindowsizeandtestalongermorphemesequence,andtotestmoreattributevalues.Therewere,infact,somecaseswheretestingmorethantwomorphemesandaddingsomeotherorthographicexpressions,suchas``oku''(``put'')and''iku''(``go''),wouldimprovetheresult.Someleaveswithhighimpurity,however,obviouslyresultedfrommislabelinginthecorpus.Aleafformedwithverysmallnumberoftrainingobjectswasoftenaresultofmislabelinginthecorpusorrareexceptions.</section>
  <section title="Conclusion">Abunsetsusegmentationmethodusingaclassificationtreewasproposed.Ithasbeenshownthatlinguisticknowledgeaboutbunsetsuboundariescanbeacquiredautomaticallybythismethod.Itcanadaptquicklytoanewsystemofpartsofspeechandalsotoanewtaskdomain.Anefficientorderoftestsisautomaticallyrealizedunderthecriterionofmaximumimpurityreduction.Alltheseareadvantagesoftheproposedmethodoverconventionalhandicraftmethods.Theclassificationaccuracyof98.9%wasachievedfortheATRcorpus,and96.2%fortheEDRcorpus.Theperformanceoftheproposedmethodwascomparedwitharule-basedmethodandtheBayesdecisionrule.Theclassificationtreemethodoutperformedtherule-basedmethodwhenthetrainingdatasizewaslargerthanabout20sentences,andthesuperioritywasmoreprominentwhenthetrainingdatasizewaslarger.TheclassificationtreemethodoutperformedtheBayesdecisionruleoverthewholerangeoftrainingdatasizes,andthesuperioritywasmoreprominentwhenthetrainingdatasizewassmaller.Trainingdataofaslittleas30sentenceswasenoughtoachieve2.4%errorrate,whereasintheBayesdecisionruletheerrorratewas5.5%forthesametrainingdata.Thisfactisagoodevidencethatthemethodhasastrongpowerofgeneralizingtheknowledgebeyondthetrainingdata.Furthermore,theknowledgeacquiredbytheclassificationtreemethodiseasiertointerpretandmorecompacttostorethanthatacquiredbytheBayesdecisionrule.Erroranalysiswasconductedbyevaluatingthelocalerrorrates.Fromthisanalysisithasbeenmadeclearthataleafformedwithasmallernumberoftrainingobjectsislikelytohaveahigherlocalerrorrate.Inordertopreventtheformationofaleafwithasmallnumberoftrainingobjects,thecontrolmethodforgrowingaclassificationtreemustbeimproved.ThethresholdI_0isaparameterintendedtocontrolthegrowthofatree,butitdidnotworkintheseexperiments.Whenthesetoftestsbecomeslarger,over-growthmayoccur.Insuchacase,thethresholdI_0mayfunctiontocontroltheover-growthoftheclassificationtree.Anothersolutiontotheover-growthproblemmaybetoincorporateanotherquantity,thenumberoftrainingobjectsthatreachanactivenode,intothestoppingconditiontocontrolthesplittingofthenode.Anotherconclusionfromtheerroranalysisisthataleafwithhigherimpurityonthetrainingobjectsisalsolikelytocauseahigherlocalerrorrate.Onaleafwithhighimpurity,thedifferencebetweenthemajorityandtheminorityissmall,whichmakestheselectedclasslabelunreliable.Inordertofurtherreducetheimpurity,newtestinginformationisnecessary.Testingamorphemesequencelongerthantwomorphemesisonesuchpossibility.Anothersolutionmaybetoimprovethesetoforthographicexpressionsfortheattributevalues.Thereforeitisdesirabletodevelopamethodforautomaticacquisitionofmorphemeswhoseorthographicexpressionsareeffectiveinbunsetsuboundarydetection.authorsaregratefultotheanonymousrefereesforthedetailedandconstructivecommentswhichwereusefultoimprovethepaper.document</section>
</root>
