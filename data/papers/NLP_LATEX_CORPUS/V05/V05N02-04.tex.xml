<?xml version="1.0" ?>
<root>
  <title>形態素クラスタリングによる形態素解析精度の向上</title>
  <author>森信介長尾眞</author>
  <jabstract>本論文では，形態素クラスタリングと未知語モデルの改良による確率的形態素解析器の精度向上を提案する．形態素クラスタリングとしては，形態素n-gramモデルをクロスエントロピーを基準としてクラスn-gramモデルに改良する方法を提案する．未知語モデルの改良としては，確率モデルの枠組の中で学習コーパス以外の辞書などで与えられる形態素を追加する方法を提案する．bi-gramモデルを実装しEDRコーパスを用いて実験を行なった結果，形態素解析の精度の向上が観測された．両方の改良を行なったモデルによる形態素解析実験の結果の精度は，先行研究として報告されている品詞tri-gramモデルの精度を上回った．これは，我々のモデルが形態素解析の精度という点で優れていることを示す結果である．これらの実験に加えて，品詞体系と品詞間の接続表を文法の専門家が作成した形態素解析器との精度比較の実験を行なった．この結果，確率的形態素解析器の誤りは文法の専門家による形態素解析器の誤りに対して有意に少なかった．形態素解析における確率的な手法は，このような人間の言語直感に基づく形態素解析器と比較して，現時点で精度がより高いという長所に加えて，今後のさらなる改良にも組織的取り組みが可能であるという点で有利である．</jabstract>
  <jkeywords>形態素解析，n-gramモデル，コーパス，クラスタリング，未知語</jkeywords>
  <subsubsection title="形態素n-gramモデル">確率的言語モデルP(m)は，形態素を一つずつ予測することを仮定すると，以下のように書き換えられる．P(m)&amp;=&amp;P(mh+1)&amp;=&amp;_i=1^h+1P(m_i|mi-1)eqnarrayここでm_h+1は，文末に対応する特別な記号である．これを導入することによって，すべての可能な形態素列に対する確率の和が1となることが保証される．式()は，ある時点iでの形態素m_iの出現確率は最初の時点から時点i-1までの全ての形態素に依存することを表しているが，実装の簡便さなどを考慮して，時点i-kから時点i-1までの連続するk個の形態素の履歴にのみ依存するk重マルコフ過程であると仮定する．この仮定は，以下の式で表される近似である．P(m_i|mi-1)&amp;&amp;P(m_i|m_i-km_i-k+1m_i-1)eqnarray*ここでm_j;(j0)は，文頭に対応する特別な記号である．これを導入することによって式が簡便になる．一般に，確率P(m_i|m_i-km_i-k+1m_i-1)の値はコーパスから最尤推定することで得られる．これは，N(m)を形態素列mのコーパスにおける頻度として，以下の式で与えられる．P(m_i|m_i-km_i-k+1m_i-1)&amp;=&amp;N(m_i-km_i-k+1m_i)N(m_i-km_i-k+1m_i-1)&amp;=&amp;N(m_i-km_i-k+1m_i)_mN(m_i-km_i-k+1m_i-1m)eqnarray*このように，このモデルは連続するn=k+1個の形態素列の頻度に基づいているので，形態素n-gramモデルと呼ばれる．形態素n-gramモデルにおいて場合に問題となるのは，状態に対応する形態素(既知形態素)の選択である．一般的には，頻度の高い形態素を既知形態素とすることで高い予測力が実現できる．しかし，どのような形態素の集合を選択したとしても，テストコーパスに出現する可能性のあるすべての形態素が既知形態素であることは望めない．このため，未知形態素の扱いが避けられない問題となる．この問題に対処するため，未知形態素に対応する特別な記号を用意し，既知の形態素以外はこの記号から次節で述べる未知語モデルにより与えられる確率で生成されることとする．未知形態素に対応する特別な記号は，かならずしも唯一である必要はなく，品詞などの情報を用いて区別される複数の記号であっても良い．我々の目的は形態素解析であるから未知形態素であっても品詞の推定が可能でなければならない．よって，各品詞に対して未知形態素に対応する記号を設ける．以上に述べた形態素n-gramモデルM_mによる，形態素列の出現確率は以下の式で表される．ただしM_inは既知形態素の集合を表わし，tはm_iの品詞を表わす．また，UM_tは品詞tに属する未知形態素に対応する特別な記号である．P_m(m_i|m_i-km_i-2m_i-1)&amp;=&amp;.eqnarrayこの式の中のM_x,tは，次項で述べる未知語モデルであり，品詞がtであることを条件として，引数で与えられる文字列の生成確率を値とする．確率値の最尤推定においては，まず既知形態素集合を定義し，学習コーパスの未知形態素を未知形態素に対応する特別な記号に置き換えて頻度を計数する．</subsubsection>
  <section title="まえがき">日本語には単語間に明示的な区切りがないので，入力文を単語に分割し，品詞を付加する形態素解析は日本語処理における基本的な処理である．このような視点から，今日までに多くの形態素解析器が人間の言語直観に基づき作成されている．一方，英語の品詞タグ付けではいくつかのコーパスに基づく方法が提案され，非常に高い精度を報告している．今日，多くの研究者が，英語の品詞タグ付けに関してはコーパスに基づく手法が従来のヒューリスティックルールに基づく手法より優れていると考えるに至っている．日本語の形態素解析に対しては，コーパスに基づく手法が従来のルールに基づく手法より優れていると考えるには至っていないようである．これは，コーパスに基づく形態素解析の研究には，ある程度の規模の形態素解析済みのコーパスが必要であり，日本語においてはこのようなコーパスが最近になってようやく簡単に入手可能になったことを考えると極めて自然である．実際，コーパスに基づく形態素解析に関しては現在までのところ少数の報告がなされているのみである．これらの研究で用いられているモデルはすべてマルコフモデル(n-gramモデル)であり，状態に対応する単位という観点から以下のように分けられる．単語(列)が状態に対応する．品詞(列)が状態に対応する確率的言語モデルという観点からは，単語を単位とすることは過度の特殊化であり，品詞を単位とすることは過度の一般化である．これらは，未知コーパスの予測力を低下させ，形態素解析の精度を下げる原因になっていると考えられる．我々は，この問題に対処するために，予測力を最大にするという観点よって算出したクラスと呼ばれる単語のグループを一つの状態に対応させ，基礎となる確率言語モデルを改良し，結果として形態素解析の精度を向上する方法を提案する．確率言語モデルとしてのクラスn-gramモデルは，最適なクラス分類を求める方法(以下，クラスタリングと呼ぶ)とともにすでに提案されている．しかし，これらの文献で報告されている実験では，クラスタリング結果を用いたクラスn-gramモデルの予測力は必ずしも向上していない．これらに対して，文献(提出中)では削除補間を応用したクラスタリング規準とそれを用いたクラスタリングアルゴリズムを提案し，クラスn-gramモデルの予測力が有意に向上したことを報告している．本論文では，この方法を応用することで得られるクラスn-gramモデルを基礎にした確率的形態素解析器による解析精度の向上について報告する．また，未知語モデルに確率モデルの条件を逸脱することなく外部辞書を追加する方法を提案し，この結果として得られる未知語モデルを備えた確率的形態素解析器による解析精度の向上ついても報告する．さらに，上述の改良の両方を施した確率的形態素解析器と品詞体系と品詞間の接続表を文法の専門家が作成した形態素解析器との解析精度の比較を行なった結果について述べる．</section>
  <section title="確率的形態素解析">日本語に対する形態素解析とは，日本語の文(文字列)を入力とし，これを表記と品詞の直積として定義される形態素に分割する処理である．この節では，これを実現する手法の一つとしての確率的形態素解析とその基礎となる確率言語モデルと解の探索方法について述べる．</section>
  <subsection title="形態素解析の問題の定義">日本語の形態素解析は，日本語のアルファベットXのクリーネ閉包に属する文xX^*を入力として，これを表記W=X^*と品詞Tの直積として定義される形態素M=(w,t)|wWtTの列mに分解して出力することと定義できる．このとき，出力される形態素列の表記の連接は，入力のアルファベット列に等しくなければならない．つまり，入力のアルファベット列(長さl)をx=xlとし，出力の形態素列(要素数h)をm=mhとすると以下の式が成り立つ必要がある．ただし，w(m)は形態素mの表記を表し，w(m)は形態素の連接mの表記の連接を表わすものとする．一般に，これを満たす解は一意ではない．形態素解析の問題は，可能な解の中から人間の判断(正解)に最も近いと推測される形態素列(単語分割と品詞割り当て)を選択し出力することである．この選択の基準としては，文法の専門家が自身の言語直観を頼りにした規則に基づく方法と大量の正解例(形態素解析済みコーパス)からの推定を規準にする方法がある．以下では，後者の一つである確率的形態素解析について説明する．</subsection>
  <subsubsection title="未知語モデル">未知語モデルは，表記から確率値への写像として定義され，既知形態素以外のあらゆる形態素の表記を0より大きい確率で生成し，この確率をすべての表記に渡って合計すると1以下になる必要がある．このような条件を満たすモデルの一つとして，文字n-gramモデルがある．日本語の表記に用いられる文字は有限と考えられるので，形態素n-gramモデルのときの未知形態素のような問題は起こらない．しかし，形態素n-gramモデルの場合と同様に，文字を既知文字と未知文字に分類し，未知文字はこれを表わす特別な記号から生成されるものとすることもできる．文字の使用頻度には大きな偏りがあることが予測されるので，これらを一つのグループとみなすことで，モデルが改善されると考えられる．文字集合は有限であるから，未知形態素モデルの場合と異なり，各未知文字の生成確率を等確率とすることができる．このようにして構成される未知語モデルは以下の式で表わされる．ただしX_in,tは品詞がtである未知語モデルの既知文字の集合を表わし，UX_tは品詞tの未知語モデルの未知文字に対応する特別な記号である．また，w(m)=xhとしている．M_x,t(w(m))&amp;=&amp;M_x,t(xh)&amp;=&amp;_i=1^h+1P_x,t(x_i|x_i-kx_i-2x_i-1)eqnarrayP_x,t(x_i|x_i-kx_i-2x_i-1)&amp;=&amp;.eqnarrayこの式の中のx_j;(j0)は，語頭に対応する便宜的な記号である．また，x_h+1は，語末に対応する特別な記号であり，形態素に対するモデルの場合と同様に，すべての可能な文字列に対する確率の和が1となるために導入されている．以上で説明した未知語モデルは，未知文字を等確率で生成するモジュールを「未知文字モデル」と考えると，形態素n-gramモデルと相似の構造である．文字n-gramモデルの確率値は，形態素n-gramモデルの場合と同様に，既知文字を定義した後，未知形態素の実例における文字列の頻度から推定される．</subsubsection>
  <subsubsection title="低頻度事象への対処">上述したように，形態素n-gramモデルのパラメータ推定には，出現頻度を基にした最尤推定が用いられる．しかし，対象とする事象の頻度が低い場合には，推定値の信頼性は低くなるという問題がある．この問題に対処する方法として，補間と呼ばれる方法が用いられる．これは，次の式で表されるように，より信頼性が高いことが期待される，より低次のマルコフモデルの遷移確率を一定の割合で足し合わせるという操作を施すことを言う．ただし;0_j1,;_j=0^k_j=1displaymath係数の値は，確率値Pの推定に用いられるコーパスとは別に用意された比較的小さいコーパスを用いて最尤推定される．この方法では，確率値の推定に用いることができるコーパスの大きさが小さくなり，推定値の信頼性が少しではあるが低下するという問題がある．これに対処する方法として削除補間と呼ばれる方法がある．これは，パラメータ推定のためのコーパスをk個に分割し，k-1個の部分で確率値を推定し，残りの部分で補間の係数を推定するということを全ての組合せ(k通り)に渡って行ない，その平均値をとるという方法である．</subsubsection>
  <subsubsection title="解の探索アルゴリズム">形態素n-gramモデルによる形態素解析器は，入力として文字列xを受けとり，式()()()()()を用いて計算される確率が最大の形態素列mを式()で表わされる条件の下で計算し出力する．解の探索には動的計画法を用いることができ，入力の文字数nに対して計算時間のオーダーがO(n)となるアルゴリズムが提案されている．</subsubsection>
  <section title="未知語モデルの改良">この章では，確率的形態素解析の精度を向上させる方法として，未知語モデルに外部辞書を付加する方法を提案する．これは，確率的言語モデルの予測力を改善する方法であり，確率的形態素解析の精度向上を直接の目的としているわけではないが，確率的言語モデルの予測力の改善は，結果としてそれに基づく確率的形態素解析器の解析精度を向上させる．また，予測力の高い未知語モデルを推定するための未知形態素の実例の収集方法についても述べる．</section>
  <subsection title="外部辞書の付加">前章で述べた未知語モデルM_x,tは，未知形態素だけでなく既知形態素の表記も0より大きい確率で生成する可能性がある．この場合には，以下の式が示すように，未知形態素の生成確率の合計は1未満となる．以下の説明では品詞tを省略してある．また，形態素の集合を表わす記号M_inをその表記の集合を表わすとしている．&amp;&amp;_mX^*-M_inM_x(m)+_mM_inM_x(m)=_mX^*M_x(m)=1&amp;&amp;_mX^*-M_inM_x(m)=1-_mM_inM_x(m)&lt;1;;;(M_x(m)&gt;0,;mM_in)eqnarray*これは，言語モデルとしての条件を満たしてはいるが，クロスエントロピーという点で改善の余地がある．つまり，既知形態素の生成確率を何らかの方法で未知形態素に分配することで，未知形態素の生成確率が大きくなり，テストコーパスにそのような未知形態素が出現した場合に，テストコーパスの出現確率が大きくなる．既知形態素の生成確率の分配には，様々な方法が考えられるが，以下の式が表すように，すべての未知形態素にその生成確率に比例して分配する方法が一般的であろう．M_x^(xh)&amp;=&amp;.eqnarrayこれに対して我々は，辞書の見出し語などとして与えられる形態素の部分集合に等しく配分することを提案する．つまり，ある形態素の集合が与えられたとして，ここから既知形態素を除いた集合をM_ex(M_exM_in=)として，この要素の生成確率を文字n-gramモデルによる確率と既知形態素の生成確率の合計をM_exの要素数で割った値の和とする．これは，既知形態素の生成確率を，学習コーパスには現れないが辞書などから形態素であると考えられる文字列に優先的に分配し，それらの生成確率を相対的に高くすることを意味する．このような文字列の集合を外部辞書と呼ぶ．形態素解析が目的なので，外部辞書には文字列のほかにその品詞が記述されている必要がある．この方法により，確率言語モデルの枠内で，コーパスから推定された確率言語モデルに辞書などの異なる情報源の情報を付加できる．以上に述べた外部辞書を備えた未知語モデルM_x^による文字列m=xhの出現確率は以下の式で表される．M_x^(xh)&amp;=&amp;.eqnarray*これを式()の代わりに用いる未知語モデルを外部辞書を備えた未知語モデルと呼ぶ．</subsection>
  <subsection title="未知形態素の実例の収集方法">文字n-gramモデルの確率値は，形態素n-gramモデルの場合と同様に，アルファベットを定義してから，未知形態素の実例における文字列の頻度から推定される．未知形態素の実例の収集の方法としては，学習コーパスに含まれるすべての形態素とすることや，学習コーパスにおける頻度が1である形態素とするなどが考えられる．我々は，削除補間法を応用した以下の方法を提案する．我々が提案する方法は，削除補間法を応用して，実際のテストコーパスにおける未知形態素と類似した実例を得ているので，他の方法よりも優れていると予測される．実際に，予備実験としてこれらの方法を実装し，予測力という規準で比較した．その結果，我々が提案する方法が最良であった．したがって，実験にはこの方法を用いた．</subsection>
  <section title="形態素クラスタリング">この章では，形態素n-gramモデルの一般化の一つであるクラスn-gramモデルを説明し，文献(提出中)を応用して形態素解析のためのクラスを自動的に学習する方法を提案する．前章と同様に，確率的言語モデルの予測力の改善を目的としているが，学習されたクラスn-gramモデルに基づく確率的形態素解析器の解析精度は，形態素n-gramモデルや人間の言語直観による品詞をクラスとした場合の品詞n-gramモデルに基づく確率的形態素解析器の解析精度より高くなると考えられる．</section>
  <section title="実験結果とその評価">前節で述べた方法の有効性を確かめるため，以下の点を明らかにするための実験を行った．外部辞書による解析精度の向上形態素クラスタリングによる解析精度の向上以下では，まず形態素解析精度の評価基準について述べ，実験の条件を明確にし，上述の実験の結果を提示し評価する．また，文法の専門家による形態素解析器との解析精度の比較を行なった結果について述べる．なお以下では，「クラスn-gramモデル」などの言語モデルを表す表現を，文脈から明らかな場合には，その言語モデルに基づく形態素解析器を表すためにも用いる．</section>
  <subsection title="評価基準">我々が用いた評価基準は，で用いられた再現率と適合率であり，次のように定義される．EDRコーパスに含まれる形態素数をN_EDR，解析結果に含まれる形態素数をN_SYS，分割と品詞の両方が一致した形態素数をN_CORとすると，再現率はN_COR/N_EDRと定義され，適合率はN_COR/N_SYSと定義される．例として，コーパスの内容と解析結果が以下のような場合を考える．この場合，分割と品詞の両方が一致した形態素は「は(助詞)」と「な(形容詞)」と「い(形容詞語尾)」であるので，N_COR=3となる．また，コーパスには6つの形態素が含まれ，解析結果には5つの形態素が含まれているので，N_EDR=6,,N_SYS=5である．よって，再現率はN_COR/N_EDR=3/6となり，適合率はN_COR/N_SYS=3/5となる．</subsection>
  <subsection title="実験の条件">実験にはEDRコーパスを用いた．まず，これを10個に分割し，この内の9個を学習コーパスとし，残りの1個をテストコーパスとした．前章で述べたように，クラス関数の推定では，この9個の学習コーパスのうちの8つからn-gramモデルを推定し，残りの1つのコーパスに対してクロスエントロピーを求めるということを9通り行なって得られる平均クロスエントロピーを評価規準とする．それぞれのコーパスに含まれる文と形態素と文字の数(のべ)は表の通りである．既知形態素は，2個以上の学習コーパスに現れる59,956個の形態素とした．形態素bi-gramモデルは，これらに対応する状態の他に，各品詞の未知語に対応する状態(15個)と文区切り(文末と文頭)に対応する状態を持つ．同様に，クラスbi-gramモデルは，既知形態素をクラスタリングすることで得られるクラスに対応する状態と，各品詞の未知語に対応する状態と文区切りに対応する状態を持つ．形態素bi-gramモデルとクラスbi-gramモデルを比較するために，これらを同じ学習コーパスから構成し，同じテストコーパスに対してパープレキシティや形態素解析の精度を計算した．それぞれの言語モデルの構成の手順は以下の通りである．形態素bi-gramモデル削除補間により式()の補間の係数を推定すべての学習コーパスを対象に形態素bi-gramと形態素uni-gramを計数クラスbi-gramモデル削除補間により式()の補間の係数を推定前章で述べた方法(k=9)でクラス関数を推定削除補間により式()の補間の係数を推定すべての学習コーパスを対象にクラスbi-gramとクラスuni-gramを計数未知語モデルは共通であり，各品詞(15個)に対して形態素bi-gramモデルと同様の手順で構成される．本実験では行なっていないが，文字に対するクラスタリングを行ない，これをクラスbi-gramモデルとすることも可能である．外部辞書の形態素集合は，EDR日本語単語辞書の見出し語から既知形態素を除いた形態素集合と学習コーパスには出現するが既知形態素とならなかった形態素集合(分割された学習コーパスの1個にのみ現れた形態素)の和集合とした．品詞毎の形態素数とクラスタリングの結果得られたクラスの数を表に掲げた．平均要素数は，形態素数をクラス数で割った値である．この値は，内容語において高く，機能語において低いことが観測される．このことから，品詞n-gramモデルにおいては機能語を一般化し過ぎており，形態素n-gramモデルにおいては内容語を特殊化し過ぎているということが分かる．なお，対象となる59,956の形態素をクラスタリングするのに要した時間は，SPARCStation20(150MHz)で約4日であった．</subsection>
  <subsection title="外部辞書と形態素クラスタリングによる精度向上の評価">図は，形態素クラスタリングの結果を用いたクラスbi-gramモデルの，外部辞書を持つ場合と持たない場合の，クロスエントロピーと形態素解析の精度である．このグラフから次のようなことが分かる．まず，学習コーパスの大きさと解析精度の関係であるが，解析精度は，コーパスの大きさに対して単調に増加している．しかし，コーパスがある程度大きくなるとこの増加量は小さくなっている．このことは，さらなる精度向上を達成するためには，学習コーパスを増やすという単純な方法は，コーパスの作成コストを考えると，得策ではないということを意味する．次に，外部辞書を付加することによる解析精度の向上であるが，クロスエントロピーの減少から予測される通り，外部辞書を付加することにより解析精度が向上した．グラフから分かるように，学習コーパスの大きさが小さい方が，外部辞書を付加することによる効果が大きい．この理由は，学習コーパスが大きくなると，外部辞書の元となる辞書などに記述されている形態素の大部分が学習コーパスに含まれることになり，テストコーパスに含まれる未知形態素の割合が減少することであると考えられる．この議論から，確率的形態素解析器を用いて学習コーパスと異なる分野の文を解析する場合には，未知形態素となるであろうその分野特有の用語(表記と品詞)を収集しておき，これを外部辞書として付加することでかなりの精度の向上が望めると考えられる．分野特有の用語の収集方法としては，その分野の専門用語辞書などを直接用いることや，その分野の大量の文例からn-gram統計を用いて抽出し品詞を推定することなどが考えられる．表は，外部辞書を備えない場合と備えた場合の，形態素bi-gramモデルとクラスbi-gramモデルによるクロスエントロピーと形態素解析の精度である．また，先行研究との比較のため，外部辞書を備えていない場合の品詞tri-gramモデルによるクロスエントロピーも表中に記載している．この結果から，外部辞書の有無に関わらず，我々が提案する方法によって得られる単語のクラス分類を用いることで，形態素解析の精度が再現率と適合率の双方で向上していることが分かる．これは，クロスエントロピーの減少から予測される通りの結果である．このように，確率モデルを用いた言語の解析では，クロスエントロピーが減少するようにモデルを改善することで，自然に形態素解析などの解析精度が向上することが見込まれる．ただし，このクロスエントロピーと解析精度の関係は，単調であることが解析的に導出できるような確固たる関係ではないことに注意しなければならない．クロスエントロピーと解析精度の関係が逆になっている例(上述の関係の反例)として，表の中の「形態素bi-gram+外部辞書」と「クラスbi-gram」のエントロピーと適合率が挙げられる．文献では，品詞tri-gramモデルを用いた形態素解析をについて述べている．この文献では，我々が今回用いた評価規準と全く同じ評価規準ではなく，単語分割のみや読みも含めた再現率と適合率を報告している．このような評価の一つとして72,000文で学習した品詞tri-gramモデルの単語分割の精度として90.6%の再現率と91.7%の適合率を報告している．このモデルとの比較を可能にするために，約47,000の学習コーパスで学習した「クラスbi-gram+外部辞書」の単語分割の精度を計算した．この結果，再現率は94.8%であり，適合率は94.9%であり，学習コーパスが少し小さいにもかかわらず品詞tri-gramモデルの結果を双方で上回っている．解析精度に関しては全ての条件が同じというわけではないので単純な比較は適切ではないが，この結果は，本手法の優位性を実験的に示すと考えられる．また，クロスエントロピー(表参照)の差は十分有意であると考えられるので，この点からも本手法の形態素解析の精度という点での優位性が十分予測される．しかし，より長い文脈から次の品詞を予測しているという品詞tri-gramモデルの良い点も無視できない．この点を採り入れて，形態素tri-gramモデルに対して形態素クラスタリングを実行し，その結果を用いてクラスtri-gramモデルを構築すれば，クロスエントロピーがさらに下がり，形態素解析の精度も上がると考えられる．ただし，実用とするためには，遷移表や解探索のための表が大きくなることによる記憶域の増大と可能な組合せの増加による解探索に必要な時間が増加するという問題にも注意を払う必要がある．</subsection>
  <subsection title="文法の専門家による形態素解析器との比較">我々は，上述の実験に加えて，文法の専門家による形態素解析器と確率的形態素解析器を解析精度という点で比較するという実験を行なった．この際に最大の問題となるのは評価基準である．確率的形態素解析器の解析精度の比較は容易に行なえる．つまり，我々が上述した実験で行なったように，同一の学習コーパスと同一のテストコーパスを用いた解析結果の再現率と適合率を比較すればよい．これは英文における単語の品詞推定の精度の比較にも用いられる標準的な方法である(英語では単語区切りに曖昧性がないので再現率と適合率は同じ値になる)．しかし，文法の専門家による形態素解析器の解析精度の比較は一般に容易ではない．これは，それぞれの文法の専門家によって形態素の定義(品詞体系や単語区切り)に違いがあり，正解となるべき形態素解析結果を共有できないことに起因する．その結果，形態素解析器の評価としては，あるいくつかの文の解析結果を文法の専門家も含めた形態素解析器の製作者が観察することで計算される値が用いられる．また，テストは最後に一回だけ行なわれるのではなく，テストの結果を見て形態素解析器を修正するということもあり，完全なオープンテストになっていないこともある．このようなテストの結果得られる精度は，客観性に欠けるので，おおよその目安としてのみ意味があり，複数の形態素解析器の比較に用いることはできない．この問題は，文法の専門家による形態素解析器と確率的形態素解析器の解析精度の比較を行なう際にも現れる．上述の問題を解決する方法として，同じ文法基準(品詞体系や単語区切)を持つ形態素解析済みコーパスと文法の専門家による形態素解析器を用いることが考えられる．これが，本研究で我々が選択した解決方法である．具体的には，京都大学で開発された文法の専門家による形態素解析器JUMANとその解析結果を人手で修正したコーパスを用いた．つまり，コーパスを学習コーパスとテストコーパスに分割し(表)，学習コーパスから構成した確率的形態素解析器(外部辞書を備えたクラスbi-gramモデル)とJUMANを用いてテストコーパスを解析した結果を，テストコーパスにあらかじめ付与されている正解と比較して，それぞれの再現率と適合率を計算した．なお，外部辞書の形態素集合は，学習コーパスには出現するが既知形態素とならなかった形態素集合である．表はこの結果である．この表から，テストコーパスにおいては，確率的形態素解析器の誤りが文法の専門家による形態素解析器の誤りに対して25%程度少ないことが分かる．この実験で使用した解析済みコーパスがJUMANの出力の訂正であることや，コーパスの訂正の過程で訂正結果を参考にしてJUMANを改良していることを考えると学習コーパスでの比較が適切かも知れない．この場合は，確率的形態素解析器の解析精度は表に示されるように圧倒的に良い．未知語モデルを文字クラスタリングしたクラスn-gramモデルとすることや，外部辞書の源としてJUMANの辞書や別のコーパスをJUMANで解析した結果から得られる学習コーパスに現れない高頻度の形態素を用いることで，確率的形態素解析器の精度はさらに向上すると考えられる．本実験で比較の対象とした文法の専門家による形態素解析器は，初版の完成から10年弱の期間を経ており，この間に莫大な人的資源を投入し様々な改良が施されている．一方，我々の確率的形態素解析器がパラメータ推定に用いた学習コーパスは8,584文であり，これを作成する費用はそれほど高くはない．これは，確率的形態素解析器が，文法の専門家による形態素解析器に対して優位である点の一つである．現状での学習コーパスの大きさは10^5.56文字と比較的小規模であり，図のEDRコーパスにおける学習コーパスの大きさと解析精度の関係から，コーパスを増量し確率言語モデルを再学習するということを繰り返すことで，この品詞体系でのより高精度の形態素解析器が容易に実現できると予測される．これと並行して確率言語モデルの改善を行なうことも重要である．以下に，より良い確率的形態素解析器を実現するための指針をまとめる．解析済みコーパスの保守と増量確率的言語モデルの改良確率言語モデルの改善方法は，本論文で提案した形態素クラスタリング以外にも提案されてる．これらは，未知語モデルにも適用できる．これらの改良をうまく組み合わせることで言語モデルの予測力が向上し，結果としてより高い精度の形態素解析器が実現できる．解探索のアルゴリズムやデータ構造の改良これによる解析速度や記憶容量の改良は，解析精度の向上にはつながらないが，実用とする上で重要である．解探索のアルゴリズムやデータ構造は，モデルのクラスに依存する点に注意しなければならない．これらの改善は独立に行なえるので，組織的な取り組みが可能になる．このように，高い精度を実現するための方法論が確立していることが確率的手法の最大の利点であろう．</subsection>
  <section title="むすび">本論文では，形態素クラスタリングと外部辞書の付加による確率的形態素解析器の精度向上について述べた．形態素クラスタリングとしては，形態素n-gramモデルをクロスエントロピーを基準としてクラスn-gramモデルに改良する方法を提案した．bi-gramモデルを実装しEDRコーパスを用いて実験を行なった結果，形態素解析の精度の向上が観測された．また，未知語モデルに外部辞書を付加する方法を提案した．同様の実験を行なった結果，形態素解析の精度の向上が観測された．これは，学習コーパスとは異なる性質を持つ分野の形態素解析器や解析済みコーパスを作成するのに特に有効であろう．両方の改良を行なったモデルによる形態素解析実験の結果の精度は，先行研究として報告されている品詞tri-gramモデルの精度を上回った．これは，我々のモデルが形態素解析の精度という点で優れていることを示す結果である．これらの実験に加えて，人間の言語直感に基づく形態素解析器との精度比較の実験を行なった．この結果，確率的形態素解析器の誤りは文法家による形態素解析器の誤りに対して25%程度少なかった．形態素解析における確率的な手法は，人間の言語直感に基づく形態素解析器と比較して，現時点で精度がより高いという長所に加えて，今後のさらなる改良にも組織的取り組みが可能であるという点で有利である．</section>
</root>
