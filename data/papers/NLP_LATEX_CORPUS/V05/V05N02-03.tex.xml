<?xml version="1.0" ?>
<root>
  <title/>
  <author/>
  <jkeywords/>
  <section title="Introduction">IdentificationoftherightsenseofawordinasentenceiscrucialtoanysuccessfulNaturalLanguageProcessingsystem.Thesamewordcanhavedifferentmeaningsindifferentcontexts.ThetaskofWordSenseDisambiguationistodeterminethecorrectsenseofawordinagivencontext.Consider,forexample,thefollowingsentences:*2cm(a)Thecentralbankraisedtheinterestrate.*2cm(b)Johnhasnointerestinbiology.wordinteresthasadifferentmeaningineachofthesesentences.Insentence(a)itreferstoafinancialpercentage,whilein(b)toJohn'sstateofmind.Asinotherexamples,theintendedmeaningdependsonthewordswhichco-occurwiththeambiguousword,ontheirsemanticrelationsandonourknowledgeabouttheco-occurringconcepts.Inmostcasesthecorrectwordsensecanbeidentifiedusingonlythewordsco-occurringinthesamesentence.However,veryoftenwealsoneedtousethecontextofwordsthatappearoutsidethegivensentence.Forthisreasonwedistinguishtwotypesofcontexts:thesententialcontextandthediscoursecontext.Thesententialcontextisgivenbythewordswhichco-occurwiththewordinasentenceandbytheirrelationstothisword,whilethediscoursecontextisgivenbythewordsoutsidethesentenceandtheirrelationstotheword.Theproblemthatariseshereisthatmostoftheco-occurringwordsarealsopolysemous,andunlessdisambiguatedtheycannotfullycontributetotheprocessofdisambiguation.Thesensesofthesewords,however,alsodependonthesenseofthedisambiguatedwordandthereforethereisareciprocaldependencywhichwewilltrytoresolvebythealgorithmdescribedinthispaper.</section>
  <section title="The Task Specification"/>
  <subsection title="Sense definitions">Dictionariesdifferwidelyinthenumberofsensedistinctionstheydraw;pocketdictionariesofferfew,andunabridgeddictionariesoffermanyalternativesenses.Forourwork,weusedthewordsensedefinitionsasgiveninWordNet,whichiscomparabletoagoodprinteddictionaryinitscoverageanddistinctionofsenses.Itprovidesaboutthesamesemanticgranularityasagooddeskdictionary.SinceWordNetonlyprovidesdefinitionsforcontentwords(nouns,verbs,adjectivesandadverbs),weareonlyconcernedwithidentifyingthecorrectsensesofthecontentwords.</subsection>
  <subsection title="Training and Testing Sentences">Bothforthetrainingandforthetestingofouralgorithm,weusedthesyntacticallyanalysedsentencesoftheBrownCorpus,whichhavebeenmanuallysemanticallytaggedintosemanticconcordancefiles(SemCor).Thesefilescombine103passagesoftheBrownCorpuswiththeWordNetlexicaldatabaseinsuchawaythateverycontentwordinthetextcarriesbothasyntactictagandasemantictagpointingtotheappropriatesenseofthatwordinWordNet.PassagesintheBrownCorpusareapproximately2,000wordslong,andeachcontainsapproximately1,000contentwords.Thefactthatthesentencesarealsosyntacticallyanalysed,enablesastraightforwardextractionofrelationsamongthewords.Werandomlyselected15filesfortesting,alwaysremovingeachtestedfilefromthecorpus,usingtheremaining102filesfortraining,thusavoidingthetrainingonthetestingdata.</subsection>
  <subsection title="Sense distribution">TheportionofBrownCorpusweusedcontained23,934differentcontentwords,addinguptoatotalof106,755contentwords.Thepercentagesofthenouns,verbs,adjectivesandadverbsinthesemanticallytaggedcorpus,togetherwiththeiraveragenumberofWordNetsenses,aregiveninTable1.Althoughmostofthewordsinadictionaryaremonosemous,itisthepolysemouswordsthatoccurmostfrequentlyinspeechandtext.Forexample,over80%ofwordsinWordNetaremonosemous,butalmost78%ofthecontentwordsinthetestedcorpushadmorethanonesense,acountynamenotfoundinWordNet,isredefinedinSemCorintolocation.BecauselemmalocationhasfoursensesinWordNet,itsambiguitywascountedasfour.WeextractedallsuchredefinitionsfromSemCor,whosecoverageinWordNetisalmostperfect.,asshowninTable2.Itisgenerallyrecognisedthatsystemsforautomaticwordsensedisambiguationshouldbeevaluatedagainstthenullhypothesis.suggestthattheappropriatebasisforcomparisonwouldbeasystemthatassumesthateachwordisbeingusedinitsmostfrequentlyoccurringsense.Theyestimatethatthemostfrequentsensewouldbecorrect75%ofthetime,whichtheyproposeasalowerboundaryforautomaticwordsensedisambiguationperformance.TheWordNetlexicaldatabasecontainsthewordsensesorderedaccordingtotheirfrequency.However,itdoesnotprovideinformationonhowfrequentlyeachsenseoccurs.Usingthesemanticconcordancefiles,wedeterminedthefrequenciesofeachsensenumberoccurringintheusedcorpus.AsTable3suggests,assigningthemostfrequentsense(asdefinedbyWordNet)toeverycontentwordintheusedcorpuswouldresultinanaccuracyof75.2%.Ouraimistocreateawordsensedisambiguationsystemforidentifyingthecorrectsensesofallcontentwordsinagivensentence,withanaccuracyhigherthanwouldbeachievedsolelybyauseofthemostfrequentsense.</subsection>
  <section title="General Word Sense Disambiguation">TheaimofthesystemdescribedhereistotakeanysyntacticallyanalysedsentenceontheinputandassigneachofitscontentwordsapointertoanappropriatesenseinWordNet.Becausethewordsinasentenceareboundbytheirsyntacticrelations,alltheword'ssensesaredeterminedbytheirmostprobablecombinationinallthesyntacticrelationsderivedfromtheparsestructureofthegivensentence.Itisassumedherethateachphrasehasonecentralconstituent(head),andallotherconstituentsinthephrasemodifythehead(modifiers).Itisalsoassumedthatthereisnorelationbetweenthemodifiers.Therelationsareexplicitlypresentintheparsetree,whereheadwordspropagateupthroughthetree,eachparentreceivingitsheadwordfromitshead-child.Everysyntacticrelationcanbealsoviewedasasemanticrelationshipbetweentheconceptsrepresentedbytheparticipatingwords.Consider,forexample,thesentence(1)whosesyntacticstructureisgiveninFigure1.Eachwordintheabovesentenceisboundbyanumberofsyntacticrelationswhichdeterminethecorrectsenseoftheword.Forexample,thesenseoftheverbproducedisconstrainedbythesubject-verbrelationwiththenouninvestigation,bytheverb-objectrelationwiththenounevidenceandbythesubordinateclauserelationwiththeverbsaid.Similarly,theverbsaidisconstrainedbyitsrelationswiththewordsJury,Fridayandproduced;thesenseofthenouninvestigationisconstrainedbytherelationwiththeheadofitsprepositionalphrase-election,andbythesubject-verbrelationwiththeverbproduced,andsoon.Thekeytoextractionoftherelationsisthatanyphrasecanbesubstitutedbythecorrespondingtreehead-word(linksmarkedboldinFigure1).Todeterminethetreehead-wordweusedasetofrulessimilartothatdescribedbyandalsousedby,whichwemodifiedinthefollowingway:Theheadofaprepositionalphrase(PP-&gt;INNP)wassubstitutedbyafunctionthenameofwhichcorrespondstothepreposition,anditssoleargumentcorrespondstotheheadofthenounphraseNP.headofasubordinateclausewaschangedtoafunctionnamedaftertheheadofthefirstelementinthesubordinateclause(usually'that'ora'NULL'element)anditssoleargumentcorrespondstotheheadofitssecondelement(usuallyheadofasentence).Becauseweassumedthattherelationswithinthesamephraseareindependent,alltherelationsarebetweenthemodifierconstituentsandtheheadofaphraseonly.Thisisnotnecessarilytrueinsomesituations,butforthesakeofsimplicitywetookthelibertytoassumeso.Acompletelistofapplicablerelationsforsentence(1)isgivenin(2).,thesyntacticstructuresoftheBrownCorpussentencesdonotdistinguishtheinternalstructureofthenounphrasesand,therefore,twonounphrasesoftheexamplesentence(1)arerathersimplifiedintheactualcorpus,leadingtoaslightlydifferentsetofrelations(3):Eachoftheextractedsyntacticrelationshasacertainprobabilityforeachcombinationofthesensesofitsarguments.Thisprobabilityisderivedfromtheprobabilityofthesemanticrelationofeachcombinationofthesensecandidatesoftherelatedcontentwords.Therefore,theapproachdescribedhereconsistsoftwophases:1.learningthesemanticrelations,and2.disambiguationthroughtheprobabilityevaluationofrelations.Section4describesthelearningphase,Section5theprocessofdisambiguation.</section>
  <section title="Learning">Atfirst,everycontentwordineverysentenceinthetrainingsetwastaggedbyanappropriatepointertoasenseinWordNet.ThesepointerswereextractedfromSemCor.Ifseveralwordsinaphraseformedacollocation,onlythephrase-headwasassignedatag.Forexample,becausetheadjectiveprimaryinprimaryelectionisnottaggedseparatelyinthesemanticconcordancefile,thisadjectiveremaineduntagged,whilethenounelectionreceivedatagcorrespondingtotheWordNetsenseofthecollocationprimary_election.Secondly,usingtheparsetreesofallthecorpussentences,allthesyntacticrelationspresentinthetrainingcorpuswereextractedandconvertedintothefollowingform:PNTisthephraseparentnon-terminal,MNTthemodifiernon-terminal,HNTtheheadnon-terminal,MSthesemanticcontent(seebelow)ofthemodifierconstituent,HSthesemanticcontentoftheheadconstituentandRPtherelativepositionofthemodifierandthehead(RP=1indicatesthatthemodifierprecedesthehead,whileforRP=2theheadprecedesthemodifier).Relationsinvolvingnon-contentmodifierswereignored.SynsetsofthewordsnotpresentinWordNetweresubstitutedbythewordsthemselves.ThesemanticcontentwaseitheraWordNetsenseidentificator(synset)or,inthecaseofprepositionalandsubordinatephrases,afunctionofthepreposition(oranullelement)andthesenseidentificatorofthesecondphraseconstituent.hasshowntheimportanceofwordsensedisambiguationfortheresolutionofaprepositionalphraseattachmentambiguity.Theprepositionisaparticularlyimportantelementindecidingtheattachmentofprepositionalphrases.Therefore,assumingprepositionsarealsoveryimportantforspecifyingtherelationbetweenthephraseheadandtheheadofthenounphrasewhichfollowsthepreposition,wehaveimplementedthisfunctionalexception.Forexample,inthecaseofaprepositionalphrasetakenfromtheBrownCorpusstructure*2cm[NP,[DT,an],[NN,investigation],*2cm*2cm[PP,[IN,of],*2cm*2cm*2cm[NP,[NP,['NNP',Atlanta]],*2cm*2cm*2cm[POS,_s],*2cm*2cm*2cm[JJ,recent],*2cm*2cm*2cm[JJ,primary],*2cm*2cm*2cm[NN,election]]]],extractedrelationswererel(NP,NN,PP,103935809,of(100103176),1)forNP-&gt;NNPP,andrel(NP,NP,NN,105608324,100103176,1)andrel(NP,JJ,NN,300610062,100103176,1)forNP-&gt;NPPOSJJJJNN,where103935809istheWordNetsynsetoftheappropriatesenseofthenouninvestigation,100103176thesynsetofprimary_election,and105608324thesynsetforAtlanta.Wehavefurthercollapsedallthenon-terminalsthatbelongtothesamesyntacticcategoryintothesamegroup,i.e.theBrownCorpuspart-of-speechtagsNN,NNS,NNP,NNPSwerecollapsedintoNOUN;VB,VBD,VBG,VBN,VBP,VBZintoVERB;JJ,JJRandJJSintoADJandRB,RBRandRBSintoADV.Also,inordertoavoidtheincorrectextractionofrelationswithverbsinthepassivevoice,wehaveconvertedallpassiveverbphrasesintoanappropriateactivevoice,e.g.theincorrectsubject-verbrelationinwasreplacedbyacorrespondingverb-objectrelationDuringthelearningphaseweextracted76,426relations,32,949withRP=1and43,477withRP=2.Thefollowingtableshowsafewofthemostcommontypesofextractedrelations:</section>
  <section title="Disambiguation Algorithm">Asmentionedabove,weassumedthatallthecontentwordsinasentenceareboundbyanumberofsyntacticrelations.Everycontentwordcanhaveseveralmeanings,buteachofthesemeaningshasadifferentprobability,whichisgivenbythesetofsemanticrelationsinwhichthewordparticipates.Becauseeveryrelationhastwoarguments(headanditsmodifier),theprobabilityofeachsensealsodependsontheprobabilityofthesenseoftheotherparticipantintherelation.Thetaskistoselectsuchacombinationofsensesforallthecontentwords,thattheoverallrelationalprobabilityismaximal.If,foranygivensentence,wehadextractedNsyntacticrelationsRi,theoverallrelationalprobabilityforthecombinationofsensesXwouldbe:wherep(R_i|X)istheprobabilityofthei-threlationgiventhecombinationofsensesX.Ifweconsider,thatanaveragewordsenseambiguityintheusedcorpusis5.8senses,asentencewith10contentwordswouldhave5.8^10possiblesensecombinations,leadingtoacombinatorialexplosionofover43,080,420overallprobabilitycombinations,whichisnotfeasible.Also,withaverysmalltrainingcorpus,itisnotpossibletoestimatethesenseprobabilitiesveryaccurately.Therefore,wehaveoptedforahierarchicaldisambiguationapproachbasedonsimilaritymeasuresbetweenthetestedandthetrainingrelations,whichwewilldescribeinSection5.2.Atfirst,however,wewilldescribethepartoftheprobabilisticmodelwhichassignsprobabilityestimatestotheindividualsensecombinationsbasedonthesemanticrelationsacquiredinthelearningphase.</section>
  <subsection title="Relational Probability Estimate">Consider,forexample,thesyntacticrelationbetweenaheadnounanditsadjectivalmodifierderivedfromNP-&gt;JJNN.LetusassumethatthenumberofsensesinWordNetiskfortheadjectiveandlforthenoun.Thenumberofpossiblesensecombinationsisthereforem=k*l.Theprobabilityestimateofasensecombination(i,j)intherelationR,whereiisthesenseofthemodifier(adjectiveinthisexample)andjisthesenseofthehead(nouninthisexample),iscalculatedasfollows:wherefR(i,j)isascoreofco-occurrencesofamodifiersensexwithaheadwordsensey,amongthesamesemanticrelationsRextractedduringthelearningphase.Pleasenote,thatbecausefR(i,j)isnotacountbutratherascoreofco-occurrences(definedbelow),pR(i,j)isnotarealprobabilitybutratheritsapproximation.Becausetheoccurrencecountisreplacedbyasimilarityscore,thesparsedataproblemofasmalltrainingcorpusissubstantiallyreduced.Thescoreofco-occurrencesisdefinedasasumofhitsofsimilarpairs,whereahitisamultiplicationofthesimilaritymeasures,sim(i,x)andsim(j,y),betweenbothparticipants,i.e.:wherex,y\inR;risthenumberofrelationsofthesametype(fortheaboveexampleR=rel(NP,ADJ,NOUN,x,y,1))foundinthetrainingcorpus.Toemphasisethesense-restrictingcontributionofeachexamplefound,everypair(x,y)isrestrictedtocontributingtoonlyonesensecombination(i,j):everyexamplepair(x,y)contributesonlytosuchacombinationforwhichsim(i,x)*sim(j,y)ismaximal.fR(i,j)representsasumofallhitsinthetrainingcorpusforthesensecombination(i,j).Becausethesimilaritymeasure(seebelow)hasavaluebetween0and1andeachhitisamultiplicationoftwosimilarities,itsvalueisalsobetween0and1.Thereasonwhyweusedamultiplicationofsimilaritieswastoeliminatethecontributionsofexamplesinwhichoneparticipantbelongedtoacompletelydifferentsemanticclass.Forexample,thetrainingpairnewairport,makesnocontributiontotheprobabilityestimateofanysensecombinationofnewmanagement,becausenoneofthetwosensesofthenounmanagement(grouporhumanactivity)belongstothesamesemanticclassasairport(entity).Ontheotherhand,newairportwouldcontributetotheprobabilityestimateofthesensecombinationofmodernbuildingbecauseonesenseoftheadjectivemodernissynonymoustoonesenseoftheadjectivenew,andonesenseofthenounbuildingbelongstothesameconceptualclass(entity)asthenounairport.Thesituationisanalogousforallotherrelations.Thereasonwhyweusedacountmodifiedbythesemanticdistances,ratherthanacountofexactmatchesonly,wastoavoidsituationswherenomatchwouldbefoundduetothesparsedata,aproblemofmanysmalltrainingcorpora.Everysemanticrelationcanberepresentedbyarelationalmatrix,whichisamatrixwhosefirstcoordinaterepresentsthesenseofthemodifier,thesecondcoordinaterepresentsthesenseoftheheadandthevalueatthecoordinateposition(i,j)istheestimateoftheprobabilityofthesensecombination(i,j)computedby(6).Anexampleofarelationalmatrixforanadjective-nounrelationmodernbuildingbasedontwotrainingexamples(newairportandclassicalmusic)isgiveninFigure3.Naturally,themoretheexamples,themorefieldsofthematrixgetfilled.Thetrainingexampleshaveanaccumulativeeffectonthematrix,becausethesenseprobabilitiesinthematrixarecalculatedasasumof'similaritybasedfrequencyscores'ofallexamples(7)dividedbythesumofallmatrixentries,(6).Themostlikelysensecombinationscoresthehighestvalueinthematrix.Eachsemanticrelationhasitsownmatrix.ThewayalltherelationsarecombinedisdescribedinSection5.2.</subsection>
  <subsubsection title="Semantic Similarity">Webasethedefinitionofthesemanticsimilaritybetweentwoconceptsontheirsemanticdistance,asfollows:Thesemanticdistancesd(a,b)issquaredintheaboveformulainordertogiveabiggerweighttoclosermatches.Becausesd(a,b)&lt;0,1&gt;,alsothesim(a,b)&lt;0,1&gt;.Thesimilarityofidenticalconceptsis1andthesimilarityoftwoconceptswhichdonothaveacommonancestorinthesemantichierarchyis0.</subsubsection>
  <subsubsection title="Semantic Distance">.SemanticDistanceforNounsandVerbsAsinwedefinethesemanticdistancebetweentwosensesofnounsandverbsintheWordNethierarchyastheaveragelengthofthepathofeachsensetoitsnearestcommonancestordividedbyitsdepthinthehierarchy:Ifaandbhavenocommonancestor,sd(a,b)=1.SeeFigure2foranexample.Ifanyoftheparticipantsinthesemanticdistancecalculationisafunction(derivedfromaprepositionalphraseorsubordinateclause),thedistanceisequaltothedistanceofthefunctionargumentsforthesamefunctor,orequals1fordifferentfunctors.Forexample,*2cmsd(of(sense1),of(sense2))=sd(sense1,sense2),while*2cmsd(of(sense1),about(sense2))=1,nomatterwhatsense1andsense2are.BecauseonlynounsandverbsformahierarchyinWordNet,whereasadjectivesandadverbsdonot,wehavetotreatthelatterdifferently..SemanticDistanceforAdjectivesThesemanticcontributionofadjectivesissecondaryto,anddependenton,theheadnounstheymodify.seemstohavebeenthefirstlinguisttopointoutexplicitlythatmanyadjectivestakeondifferentmeaningswhentheymodifydifferentnouns.WordNetdividesadjectivesintotwomajorclasses:descriptiveandrelational.Descriptiveadjectivesascribetotheirheadnounsvaluesoftypicallybipolarattributesandconsequentlyareorganisedintermsofantonymyandsimilarityofmeaning(synonymy).Descriptiveadjectivesthatdonothavedirectantonymsaresaidtohaveindirectantonymsbyvirtueoftheirsemanticsimilaritytoadjectivesthatdohavedirectantonyms.Relationaladjectivesareassumedtobestylisticvariantsofmodifyingnounsandsoarecross-referencedtothenounfiles.Adjectivesandtheirantonymy,thesalientfeatureofdescriptiveadjectives,exhibitamutualityofassociation(goodassociateswithbad,longwithshort,etc.).Thismutualityseemstobeacquiredasaconsequenceofco-occurrenceofadjective-antonymypairsinthesamesentences.Sinceadjectivesandtheirantonymsusuallymodifythesamenoun,wecanusethisinformationincalculatingtheprobabilitiesofsemanticrelationswhichinvolveadjectives.BecauseWordNetcontainsthepointersbetweenadjectives,theirsynonymy,antonymyandsimilaradjectives,wedefinesemanticdistancefordescriptiveadjectivesinthefollowingway:*1cmsd(a,b)=0forthesameadjectivalsynsets(incl.synonymy)*1cmsd(a,b)=0forthesynsetsinantonymyrelations,i.e.forant(a,b)*1cmsd(a,b)=0.5forthesynsetsinthesamesimilaritycluster*1cmsd(a,b)=0.5ifabelongstothesamesimilarityclusterascand*3.5cmbistheantonymyofc(indirectantonymy)*1cmsd(a,b)=1forallothersynsetsInthecaseofrelationaladjectives,whichpertaintoanounwhosemodifyingfunctiontheytake(atomicbomb=atombomb),wecalculatethesemanticsimilarityasasimilarityofthenounstheypertainto.If,forexample,wearetocalculatethesemanticdistancebetweentheadjectivesatomicandchemical,asinatomicbombandchemicalweapons,wefirstaccessthepertinentinformationinWordNetandcalculatethedistanceasadistancebetweencorrespondingsensesofthenounatomandthenounchemical.C.SemanticDistanceforAdverbsTheonlytworelationsinWordNetthatinvolveadverbsaresynonymyandantonymy.Wethereforedefinesemanticdistancebetweentwoadverbialsynsetsas:*2cmsd(a,b)=0forthesamesynsets(incl.synonymy).*2cmsd(a,b)=0forthesynsetsinantonymyrelationant(a,b)*2cmsd(a,b)=1forallothersynsets</subsubsection>
  <subsection title="Hierarchical Disambiguation">Thissectiondescribesthemainpartofthealgorithm,i.e.thedisambiguationprocessbasedontheoverallprobabilityestimateofsententialrelations.Aswehaveoutlinedabove,forcomputationalreasons,itisnotfeasibletoevaluateoverallprobabilitiesforallthesensecombinations.Instead,wetakeadvantageofthehierarchicalstructureofeachsentenceandarriveattheoptimumcombinationofitswordsenses,inaprocesswhichhastwoparts:1.bottom-uppropagationoftheheadwordsensescoresand2.top-downdisambiguation.Theheadwordspropagatefromtheleavesoftheparsetreetotheirtopmostparentsandateachlevelofthetreeparticipateinsemanticrelationswiththeirmodifiers.Therelationwitheachmodifierthuschangesthelikelinessofeachsenseoftheheadword.Similarly,thelikelinessofeachsenseofeverymodifierischangedbythesemanticrelationwiththehead(accordingtoourassumptionthattherearenorelationsbetweenmodifierswithinaphrase,eachmodifierparticipatesonlyintherelationwithitshead).Becausethelikelinessofeachsenseoftheheadistobefurthermodifiedathigherlevelsofthetree,westorethelikelinessofeachsenseofthemodifierinamatrix,whereeachlinerepresentsavectorofthesensescoresofthemodifiercorrespondingtoonesenseofthehead.Thismatrixwillbeusedtodeterminethesenseofamodifieronceitsgoverningheadwordsensehasbeenidentified.Aswewilldescribebelow,thematrixiscalculatedasaproductoftherelationalmatrixofthemodifieranditshead,andofthepropagatedsensescoresofthemodifier.Theheadspropagateupthetreeuntiltherootwhichrepresentsthemainheadofthesentenceisreached.Attherootofthetreewedisambiguatethemainheadofthesentencebychoosingitssensewhichcorrespondstothehighestvalueamongitssensescores,i.e.wechoosethesensewiththehighestlikeliness.Thisisplausible,becausebythetimethetreerootisreached,allthesemanticrelationsofthesentencehavebeentakenintoaccount,andhaveparticipatedinthecalculationofthesensescoresofthemainhead.Undertheassumptionthattherearenorelationsbetweenmodifiers,thesensescoresofthemainheadwordthusapproximatetheprobabilitiesoftheheadwordsensesandserveasanintermediatetoapproximatethehighestoverallsensecombinationprobabilityofthesentence'swordsasgivenby(5).Oncethemainheadhasbeendisambiguated,itssensetravelsdownthehierarchyandfacilitatesthedisambiguationofotherwords,basedontheirpreviouslystoredsensescorematrices.Thedisambiguationterminatesafteralltheleaveshavebeenreachedandallthewordsofthesentencedisambiguated.Theprocessisdescribedindetailbelow.</subsection>
  <subsubsection title="Bottom-up head word sense score propagation">Incompliancewithourassumptionthatallthesemanticrelationsareonlybetweenaheadwordanditsmodifiersatanysyntacticlevel,themodifiersdonotparticipateinanyrelationwithanelementoutsidetheirparentphrase.AsdepictedintheexampleinFigure1,itisonlytheheadwordconceptsthatpropagatethroughtheparsetreeandthatparticipateinsemanticrelationswithconceptsonotherlevelsoftheparsetree.Themodifiers(whichareheadsthemselvesatlowertreelevels),however,playanimportantroleinconstrainingthehead-wordsenses.Thenumberofrelationsderivedateachlevelofthetreedependsonthenumberofconceptsthatmodifythehead.Eachoftheserelationscontributestothescoreofeachsenseoftheheadword.WedefinethesensescorevectorofawordwasavectorofscoresofeachWordNetsenseofthewordw.Theinitialsensescorevectorofthewordwisgivenbyitscontextuallyindependentsensedistributioninthewholetrainingcorpus.Becausethetrainingcorpusisrelativelysmall,andbecauseitalwaysexcludesthetestedfile,anappropriatesenseofthewordwmaynotbepresentinitatall.Therefore,eachsenseiofthewordwisalwaysgivenanon-zeroinitialscorep_i(w)(9a):wherecount(w)_iisthenumberofoccurrencesofthesenseiofthewordwintheentiretrainingcorpus,andnisthenumberofdifferentWordNetsensesofthewordw.Thesensescorevectorsofheadwordspropagateupthetree.Ateachlevel,theyaremodifiedbyallthesemanticrelationswiththeirmodifierswhichoccuratthatlevel.Also,thesensescorevectorsofheadwordsareusedtocalculatethematricesofthesensescorevectorsofthemodifiers.Thisisdoneasfollows:LetH=$\bf[h1,h2,...,hk]bethesensescorevectoroftheheadwordh.LetT=[R1,R2,...Rn]beasetofrelationsbetweentheheadwordhanditsmodifiers.ForeachsemanticrelationRi\inTbetweentheheadwordhandamodifiermiwithsensescorevectorMi=[oi1,oi2,...oil],do:Using(6),calculatetherelationalmatrixRi(m,h)oftherelationRiForeachoi\inMimultiplyalltheelementsoftheRi(m,h)forwhichm=oibyoi,yieldingQi-thesensescorematrixofthemodifiermiThenewsensescorevectoroftheheadwordhisnowG=$\bf[g1,g2,...,gk],whereL_j/LrepresentsthescoreoftheheadwordsensejbasedonthematricesQcalculatedinthestep1.,i.e.:wherexi(j,u)\inQiandmax(xi(j,u))isthehighestscoreinthelineofthematrixQiwhichcorrespondstotheheadwordsensej.nisthenumberofmodifiersoftheheadwordhatthecurrenttreelevel,andwherekisthenumberofsensesoftheheadwordh.Thereasonwhyg_j(10)iscalculatedasasumofthebestscores(11),ratherthanbyusingthetraditionalmaximumlikelihoodestimate,istominimisetheeffectofthesparsedataproblem.Imagine,forexample,thephraseVP-&gt;VBNPPP,wheretheheadverbVBisintheobjectrelationwiththeheadofthenounphraseNPandalsointhemodifyingrelationwiththeheadoftheprepositionalphrasePP.LetusalsoassumethatthecorrectsenseoftheverbVBisa.Eveniftheverb-objectrelationprovidedastrongselectionalsupportforthesensea,iftherewasnoexampleinthetrainingsetforthesecondrelation(betweenVBandPP)whichwouldscoreahitforthesensea,multiplyingthescoresofthatsensederivedfromthefirstandfromthesecondrelationrespectively,wouldgainazeroprobabilityforthissenseandthuspreventitscorrectassignment.Althoughsuchasituationisquiteunlikelybecauseoftheuseofthesemanticdistanceinthehitscoring(7),weexperimentallyverifiedthataddingthescoresratherthattheirmultiplicationprovidesslightlybetterresults.Duringtheimplementationofthealgorithmwetestedseveralmodifications,includingthetraditionalsmoothingtechniques.Mostofthemethodsprovidedsimilarormarginallyworseresults,rangingfrom79.1%accuratesensetagsformultiplication,to79.4%ofaccuratesensetagsforaddition(seefurtherdiscussionintheEvaluationsection).Theproblemwithtraditionalsmoothingtechniques,e.g.flooring,isthatthesearedesignedfordomainswhichdealwithrealprobabilities,ratherthanwithscoresasinourcase.Althoughtheinitialscorevectors(9a)containgoodapproximationsofthecontextuallyindependentprobabilitiesofeachsenseofthegivenword,aftertheirfirstpropagationthroughthebottom-upphase,theseprobabilitiesarereplacedbyscoresorsenseevaluationsbasedontheproductsofthesemanticdistancestothesamplesinthetrainingcorpus.Thissubstantiallyreducesthesparsedataproblem,becauseinsteadofcountingexactword-pairoccurrences,webasethescoreestimateonthesemanticdistancemeasure.Therefore,foralmosteveryword-pairthereisanon-zerosensecombinationscore.Thiscanbeviewasakindofsmoothingoverthesparsedata.ThenewlycreatedheadwordsensescorevectorGpropagatesupwardsintheparsetreeandthesameprocessrepeatsatthenextsyntacticlevel.Notethatatthehigherlevel,dependingontheheadextractionrulesdescribedinsection3,therolesmaybechangedandtheformerheadwordmaybecomeamodifierofanewhead(andparticipateintheabovecalculationasamodifier).Theprocessrepeatsitselfuntiltherootofthetreeisreached.Thewordsensescorevectorwhichhasreachedtheroot,representsavectorofscoresofthesensesofthemainheadwordofthesentence(verbsaidintheexampleinFigure1),whichisbasedonthewholesyntacticstructureofthatsentence.Thesensewiththehighestscoreisselectedandthesentenceheaddisambiguated.</subsubsection>
  <subsubsection title="Top-down Disambiguation">Havingascertainedthesenseofthesentencehead,theprocessoftop-downdisambiguationbegins.Thetop-downdisambiguationalgorithm,whichstartswiththesentencehead,canbedescribedrecursivelyasfollows:Letlbethesenseoftheheadwordhontheinput.LetM=[m1,m2,...,mx]bethesetofthemodifiersoftheheadwordh.Foreverymodifiermi\inM,do:InthesensescorematrixQiofthemodifiermi(calculatedinstep1.2ofthebottom-upphase)findalltheelementsx(ki,l),wherelisthesenseoftheheadhAssignthemodifiermisuchasensek=kiforwhichthevaluex(ki,l)ismaximum.Inthecaseofadraw,choosethesensewhichislistedasmorefrequentinWordNet.Ifthemodifiermihasdescendantsintheparsetree,callthesamealgorithmagainwithmibeingtheheadandkbeingitssense,elseend.Thedisambiguationofthemodifiers(whichbecomeheadsatlowerlevelsoftheparsetree),isbasedsolelyonthoselinesoftheirsensescorematriceswhichcorrespondtothesenseoftheheadtheyareinrelationwith.Thisispossiblebecauseofourassumptionthatthemodifiersarerelatedonlytotheirheadwords,andthatthereisnorelationamongthemodifiersthemselves.Towhatextentthisassumptionholdsinreallifesentences,however,hasyettobeinvestigated.</subsubsection>
  <section title="DISCOURSE CONTEXT">Theobjectiveofanyhumancommunicationistoconveymeaning.Thisobjectivewouldbeobliteratedifwecouldnotidentifythesensesoftheusedwords.Animportantfactorindoingsoisthecontextinwhichthewordsoccur.Thiscontextconsistsofthephysical,psychologicalandculturalenvironmentoftheparticipantsinthecommunication.Thesentencesofnaturallanguagearestructuredsothatthelistener(orreader)understandstheconveyedmessagewithoutdoubts.Ifthecontextinwhichamessageoccursdoesnotprovidesufficientcluesforthelistenertounderstand,thespeakermaychoosetospecifythemeaningintheprecedingsentences.pointedoutthatthesenseofatargetwordishighlyconsistentwithinanygivendocument(onesenseperdiscourse).Becauseouralgorithmdoesnotconsiderthecontextgivenbytheprecedingsentences,wehaveconductedthefollowingexperimenttoseetowhatextentthediscoursecontextcouldimprovetheperformanceoftheword-sensedisambiguation:Usingthesemanticconcordancefiles,wehavecountedtheoccurrencesofcontentwordswhichpreviouslyappearinthesamediscoursefile.Theexperimentindicatedthatthe&quot;onesenseperdiscourse&quot;hypothesisworksfairlywellfornouns,however,theevidenceismuchweakerforverbs,adverbsandadjectives.Table5showsthenumbersofcontentwordswhichappearpreviouslyinthesamediscoursewiththesamemeaning(samesynset),andthosewhichappearpreviouslywithadifferentmeaning.Theexperimentalsoconfirmedourexpectationthattheratioofwordswiththesamesensetothosewithadifferentsense,dependsonthedistanceofsentencesinwhichthesamewordsappear(distance1indicatesthatthesamewordappearedintheprevioussentence,distance2thatthesamewordwaspresent2sentencesbefore,etc.).Wehavemodifiedthedisambiguationalgorithmtomakeuseoftheinformationgainedbytheaboveexperimentinthefollowingway:Allthedisambiguatedwordsandtheirsensesarestored.Thewordsofalltheinputsentencesarefirstcomparedwiththesetofthesestoredword-sensepairs.Ifthesamewordisfoundintheset,theinitialsensescoreassignedtoitby(9a)ismodifiedusingTable5,sothatthesense,whichhasbeenpreviouslyassignedtotheword,getshigherpriority.Thecalculationoftheinitialsensescore(9a)isthusreplacedby(9b):wheree(POS,SN)istheprobabilitythatthewordwithsyntacticcategoryPOSwhichalreadyoccurredSNsentencesbefore,hasthesamesenseasitspreviousoccurrence.If,forexample,thesamenounhasoccurredintheprevioussentence(SN=1)whereitwasassignedsensen,theprobabilityofsensenofthesamenouninthecurrentsentenceismultipliedbye(NOUN,1)=3,039/(3,039+103)=0.967,whilealltheprobabilitiesofitsremainingsensesaremultipliedby1-0.967=0.033.Ifnomatchisfound,i.e.thewordhasnotpreviouslyoccurredinthediscourse,e(POS,SN)issetto1forallsenses.</section>
  <section title="EVALUATION">Toevaluatethealgorithm,werandomlyselected15files(withatotalof18,413contentwordstaggedinSemCor)fromthesetof103filesofthesensetaggedsectionoftheBrownCorpus.Eachtestedfilewasremovedfromthesetandtheremaining102fileswereusedforlearning(Chapter4).Everysenseassignedbythehierarchicaldisambiguationalgorithm(Chapter5)wascomparedwiththesensefromthecorrespondingsemanticconcordancefile.Table6showstheachievedaccuracycomparedwiththeaccuracywhichwouldbeachievedbyasimpleuseofthemostfrequentsense.Astheabovetableshows,theaccuracyofthewordsensedisambiguationachievedbyourmethodwasbetterthanusingthefirstsenseforalllexicalcategories.Inspiteofaverysmalltrainingcorpus,theoverallwordsenseaccuracyexceeds80%.Toourknowledge,thereisnocurrentmethodwhichattemptstoidentifythesensesofallwordsinwholesentences,sowecannotmakeapracticalcomparison.Aninterestingaspectoftheresultwastherelativelysmallcontributionofthediscoursecontexttotheoverallaccuracy.Aswasexpected,thediscoursecontexthadarelativelyhighercontributiontotheaccuracyofnounsandadjectives,thantoverbsandadverbs.Thisisbecausenounsandadjectivesmoreoftensharethesamesenseinmultipleoccurrenceswithinthesamediscourse,thanverbsandadverbs(Table5).Itispossibletofurtherimprovethediscoursecontextaccuracycontributionbysearchingtheprecedingsentences,notonlyforsamewordsbutalsoforwordsexpressingsemanticallycloseconcepts.If,forexample,onesentencecontainsthenouncar,disambiguatedtoits'vehicle'sense,andoneofthesubsequentsentencesincludestheasyetambiguousnountrain,wefeelthatthesemanticsimilaritybetweenthetwoshouldbeincorporatedintheestimateoftheinitialsenseprobability(9b)ofthenountrain.Anotherimprovementcouldbemadebytheuseofthesemanticrelationsextractedfromthepreviouslylocatedsentencesinthesamediscourse.Inthelearningprocess,onlythesentencesfromotherfilesareusedinordertoavoidlearningonthetesteddata.Webelieve,however,thatinanynaturaldiscourse,itisnotmerelythepresenceofentitiesthatestablishesacontext,butalsorelationsamongthem.If,forexample,awordw1isinsemanticrelationrwithwordw2inonesentence(r(w1,w2)),andawordw3isthesamerelationwithwordw4inoneofthesubsequentsentences(r(w3,w4)),wehypothesisethattheuseofthesemanticsimilarityoftheargumentswouldyieldafurtherincreaseofaccuracy.Anotherwaytoimprovetheaccuracywouldbetoconsidereachdiscoursefileasawhole,where,notonlypreceding,butalsosubsequentsentencesinfluencetheprobabilitiesofwordsenses.Thiswould,however,requirethethoroughinvestigationofmanydiscoursecontextphenomena,andtheimplementationofamuchmorecomplexprobabilisticmodel,whichisbeyondthescopeofthiswork.Therelativelylowaccuracyinthecaseofverbsistobeattributedtothefactthatverbsarenaturallymoredifficulttodisambiguateandhaveonaveragemoresenses(Table1).suggestthatsomewordsarehardertodisambiguatethanothers,buttheystatethattheoverallaccuracyisafunctionofthedifficulty,ratherthanbeingstrictlyafunctionofthenumberofsenses.Inanycase,however,webelievethatdisambiguationofverbsinvolvestheneedofmorecomplicatedinferenceswithgeneralknowledge,andthisisnotpossibletosubstitutebyasmalltrainingcorpus.Ashasbeenalreadyimpliedbymanyresearchersetc.,determiningthecorrectsenseofawordinvolvessubtlehumanjudgements.TheWordNetlexicalhierarchy,whosesensedefinitionshavebeenusedinthiswork,containsmanysensesandchoosingtherightoneforagivenwordinagivencontextisnotalwayseasyevenforhumanannotators.Thesemanticconcordancefiles,whichwereusedforlearningandevaluation,weretaggedmanually.ThemanualtaggingrequiredtheannotatortoexamineeachwordofthetextinitscontextandtodecidewhichWordNetsenseiscorrect.Inmanysituations,webelieve,thedecisionwasnottheonlyonepossible.Differentannotatorscouldchoosedifferentsensesinthesamesituations.Thisisparticularlytrueforverbs,thesensesofwhich,wefeel,aredividedtoofinelyinWordNet,makingitpossibleforseveralcandidatestofitthegivencontext.TheevaluationresultsgiveninTable6arebasedonexactmatchesbetweentheautomaticallydeterminedsenseandthecorrespondingsenseinthesemanticconcordance.Ifthesensewasdifferent,itwascountedasanerror,evenwhentheautomatictagwasplausible.Becauseitwasnotwithinourcapacitytomanuallycomparethesenseerrorsintheentiretestedset,wehaveconductedasmallerexperimentlimitedonlytoonefile.Usingthegeneraldisambiguationalgorithm,asensewasassignedtoeverycontentwordinthefile.Everyword,whosesensewasdifferentfromthesenseinthesemanticconcordance,wasmanuallyreviewedandcountedcorrectiftheautomaticallyassignedsensewasalsopossible.Table7showstheresults.Ithastobenoted,however,thatthisevaluationinvolvedsubjectivejudgementsandshouldbethereforeconsideredonlyinformatively.Sincewehavetriedtoerronthesideofaccuracystrictnesswhenconsideringpossiblesensecandidates,theaccuracycouldpossiblebeevenhigher.However,furtherresearchneedstobedoneinthisarea.Thegeneraldisambiguationalgorithmdescribedinthispaperiseasytoimplementandcomputationallyverysimple.Becausethenumberofsemanticrelationsinasentenceandtheambiguityofitswordsrepresentaconstantfactor,thecomputationalcomplexityofthealgorithmgrowslinearlywiththesizeofthetrainingcorpus.Thesparsedataproblemofasmalltrainingcorpusiscompensatedforbytheuseofsemanticsimilarity.Webelievethatmoretrainingdatawouldprovideanevenhigheraccuracy,butduetothelackofothersemanticallytaggedcorpora,wecannottesttheperformanceonmoredata.Thebiggestadvantageofthemethodisthatallthewordsinasentenceareconsideredasonesetofinter-relatedconcepts.Theutilisationofthesyntactictreemakesthemethodextremelyusefulforintegrationwithaprobabilisticsyntacticanalyserintoapowerfulnaturallanguageprocessingsystem.</section>
  <section title="Related Work">ThevastmajorityofworkonWordSenseDisambiguationfocusesontheidentificationofthecorrectsensesofcontent(open-class)words,particularlynouns.Mostofthemethodsattempttoidentifythewordsensebycomparingthecontextinwhichthewordappearswiththecontextofthesamewordinexamplesituations.Acquisitionoftheseexamplesituationsconstitutesthebottleneckofallexample-basedmethods.Someresearcherstriedtogetaroundtheexampleacquisitionproblembybuildinglargeexpertsystemsbyhandand/orfocusonlimiteddomains.Otherssuchashaveturnedtomachinereadabledictionariesinthehopethattheymightprovideawayoutoftheknowledgeacquisitionbottleneck.Anothergroupofresearchershavearguedthattheknowledgeonsensescanbegainedbyusingtworatherthanonelanguage.Thisapproachisverypromising.However,itcouldbearguedthatthree,four,fivelanguagesarebetterthantwo.Forexample,boththeEnglishnouninterestandtheFrenchequivalentinteretaresimilarlyambiguousinbothlanguages,sotheuseofequivalentexamplesfromoneother(especiallysimilar)languagedoesnotalwayssolvetheproblem.gaveanexcellentanalysisofthedisambiguationtechniquebasedontheCanadianHansards,acorpuswithparallelEnglishandFrenchtext.Usingacontextof+/-fiftywords,theyhaveachievedadisambiguationperformancefrom86to90%fordisambiguatingtwoequiprobablesensesofsix'difficult'nouns.Thebiggestgroupofresearchersturnstohand-annotatedcorpora,thestrategywehavealsoadopted.Earlierattempts,suchasusedmanuallycreatedrulestoperformwordsensedisambiguation,whilemorerecentworkusesvarioussortsofstatisticalprocessing.Thebiggestchallengeofthestatisticalapproachesisintheselectionandprobabilisticcombinationofcontextualfeatures.presenttechniquesforidentifyingoptimalfeaturetoperformdisambiguation.NaiveBayesclassifierhasbeenfoundtoperformwellfor.Recently,aconsiderableamountofattentionhasbeengiventomaximumentropymodels,whichhavebeenusedtoexpresstheinteractionsamongmultiplecontextualfeatures.Everymodel,however,which,likeours,isbasedonmaximumlikelihoodestimate(MLE),hastodealwithsparsedataproblem.BecausenosystematicstudyofinteractionsamongthemultiplevariablesinMLEhasbeencarriedout,researchersmodifytheMLEbaselinetosuitthespecificneedsoftheirdomains.combinetheprobabilitiesfromlocalcontextwithprobabilitiesfromentiretrainingcorpusinaninterpolationprocedurebasedontheBetafunction.proposesequentialsearchtofindthebestmodelofinteractionsofmultiplefeatures.integratemultiplefeatures(part-of-speech,surroundingwords,localcollocationsandverb-objectsyntacticrelation)inaspecificheuristicformulatodisambiguatesensesof121mostcommonnounsand70mostcommonverbs.Similarlytoourmethod,theyuseWordNetsensedefinitions,buttheirtrainingcorpushasbeenmanuallyannotatedtobeusedonlywiththeseselectedwords.NgandLeetestedthemethodon7,119occurrencesoftheselectednounsandverbsthatoccurredin50textfilesoftheBrownCorpus(BC)and14,139occurrencesinWallStreetJournal(WSJ).Testingonlythesepolysemouswordstheyreportanaverageaccuracy54.0and68.6percent,forBCandWSJ,respectively.Similarlytoourwork,alsochallengethefine-grainednessofWordNet,buttheirworkislimitedtonounsonly.reportcoverage86.2%,precision71.2%andrecall61.4%fornounsinfourrandomlyselectedsemanticconcordancefiles.Fromamongthemethodsbasedonsemanticdistance,useasimilarsemanticdistancemeasurefortwoconceptsinWordNet,buttheyalsofocusonselectedgroupofnounsonly.useaninterestingiterativealgorithmandattempttosolvethesparsedatabottleneckbyusingagradedmeasureofcontextualsimilarity.Theyachieve90.5,92.5,94.8and92.3percentaccuracyindistinguishingbetweentwosensesofthenoundrug,sentence,suitandplayer,respectively.,whosetrainingcorpusforthenoundrugwas9timesbiggerthanthatofKarovandEdelman,reports91.4%correctperformanceimprovedtoimpressive93.9%whenusingthe&quot;onesenseperdiscourse&quot;constraint.Thesemethods,however,focusononlytwosensesofaverylimitednumberofnounsandthereforearenotcomparablewithourapproach.Allexistingmethodsfacetheproblemofdefiningcontextandselectingappropriatecontextualfeaturesfromit.Mostofthemethodsuseawindowofsurroundingwordswithoutconsideringthesyntacticrelationsamongthem.Ourmethod,ontheotherhand,exploresthesyntacticstructureofthesentenceandestimatestheprobabilityofeachwordsenseasaproductofallthesemanticrelationsinthesentence.tookasimilarapproachincombiningtheprobabilitiesofdependenciesbetweenheadwordsingrammarrulesofaparsetreetoachievestatisticalparsing.BecauseCollinsalsoexploitsbigramdependenciesinawholesentence,ourmethodwouldbeparticularlysuitabletobeintegratedwithinastatisticalparserofthiskind.</section>
  <section title="Conclusion">Thispaperpresentsanewgeneralapproachtowordsensedisambiguation.Unlikemostoftheexistingmethods,itidentifiesthesensesofallcontentwordsinasentencebasedonanestimationoftheoverallprobabilityofallsemanticrelationsinthatsentence.Byusingthesemanticdistancemeasure,ourmethodreducesthesparsedataproblemsincethetrainingexamplesandtheircontextsdonothavetomatchthedisambiguatedwordsexactly.Allthesemanticrelationsinasentencearecombinedaccordingtothesyntacticstructureofthesentence,whichmakesthemethodparticularlysuitableforintegrationwithastatisticalparserintoapowerfulNaturalLanguageProcessingsystem.Themethodisdesignedtoworkwithanytypeofcommontextandiscapableofdistinguishingamongmanywordsenses.Ithasaverywidescopeofapplicabilityandisnotlimitedtoonlyonepart-of-speech.Althoughthetestingresultsexhibitrelativelyhighdisambiguationaccuracy,thereisstillspaceforfurtherimprovement.Inthefirstplace,themethodrequiresasemanticallytaggedtrainingcorpus.However,webelievethatahugeamountofuntaggeddatawouldallowforanunsupervisedmodificationofthealgorithm.Therelationalprobabilities,insteadofbeingbasedondisambiguatedsensesoftrainingexamples,couldbebasedonsuchaselectionoftrainingsenseswhichwouldbesemanticallynearesttothegiventestedpair.Thealgorithmwouldbenaturallymorecomplicated,however,thiswouldavoidtheneedofmanualtagging.Towhatextenttheamountofdatawouldsubstitutethesemantictagsremainsyettobetested.Anotherweakpointofourmethodisinitspooruseofdiscoursecontext.Semanticallycloseconceptsinsurroundingsentences,theirrelations(includingcross-categoryrelations)andtheirinfluenceontheprobabilitybiasofwordsenses,needstobeinvestigatedmorethoroughly.Moreover,weassumedthatthereisnodependencyamongthesemanticrelationsbetweenphraseheadsandtheirmodifiers.Thisisnotnecessarilytrue,butitsubstantiallysimplifiedthealgorithm.Also,webelievethatmoreaccuratehandlingofthescoresderivedfrommultiplecontextualfeaturesispossibleanditremainsanobjectiveofourfurtherresearch.document</section>
</root>
