<?xml version="1.0" ?>
<root>
  <title>最大エントロピーモデルに基づく形態素解析---未知語の問題の解決策---</title>
  <author>内元清貴関根聡井佐原均</author>
  <jabstract>形態素解析は日本語解析の重要な基本技術の一つとして認識されている．形態素解析の形態素とは，単語や接辞など，文法上，最小の単位となる要素のことであり，形態素解析とは，与えられた文を形態素の並びに分解し，それぞれの形態素に対し文法的属性(品詞や活用など)を決定する処理のことである．近年，形態素解析において重要な課題となっているのは，辞書に登録されていない，あるいは学習コーパスに現れないが形態素となり得る単語(未知語)をどのように扱うかということである．この未知語の問題に対処するため，これまで大きく二つの方法がとられてきた．一つは未知語を自動獲得し辞書に登録する方法であり，もう一つは未知語でも解析できるようなモデルを作成する方法である．ここで，前者の方法で獲得した単語を辞書に登録し，後者のモデルにその辞書を利用できるような仕組みを取り入れることができれば，両者の利点を生かすことができると考えられる．本論文では，最大エントロピー(ME)モデルに基づく形態素解析の手法を提案する．この手法では，辞書の情報を学習する機構を容易に組み込めるだけでなく，字種や字種変化などの情報を用いてコーパスから未知語の性質を学習することもできる．我々はこの手法により未知語の問題が克服される可能性が高いと考えている．京大コーパスを用いた実験では，再現率95.80%，適合率95.09%の精度が得られた．</jabstract>
  <jkeywords>形態素解析，最大エントロピー(M.E.)モデル，未知語，辞書</jkeywords>
  <section title="はじめに">形態素解析は日本語解析の重要な基本技術の一つとして認識されている．形態素解析の形態素とは，単語や接辞など，文法上，最小の単位となる要素のことであり，形態素解析とは，与えられた文を形態素の並びに分解し，それぞれの形態素に対し文法的属性(品詞や活用など)を決定する処理のことである．近年，形態素解析において重要な課題となっているのは，辞書に登録されていない，あるいは学習コーパスに現れないが形態素となり得る単語(未知語)をどのように扱うかということである．この未知語の問題に対処するため，これまで大きく二つの方法がとられてきた．一つは未知語を自動獲得し辞書に登録する方法(例えばなど)であり，もう一つは未知語でも解析できるようなモデルを作成する方法(例えばなど)である．ここで，前者の方法で獲得した単語を辞書に登録し，後者のモデルにその辞書を利用できるような仕組みを取り入れることができれば，両者の利点を生かすことができると考えられる．森らはn-gramモデルに外部辞書を追加する方法を提案している．ある文字列が辞書に登録されている場合にその文字列が形態素となる確率を割り増しするような方法である．しかし，わずかな精度向上に留まっていることから，n-gramモデルでは辞書の情報を利用する仕組みを容易に組み込むのは難しいのではないかと考えられる．本論文では，最大エントロピー(ME)モデルに基づく形態素解析の手法を提案する．この手法では，辞書の情報を学習する機構を容易に組み込めるだけでなく，字種や字種変化などの情報を用いてコーパスから未知語の性質を学習することもできる．ここで辞書の情報とは，辞書に登録されている語が複数の品詞をとり得る場合にどの品詞を選択するべきかといった情報を意味する．京大コーパスを用いた実験では，再現率95.80%，適合率95.09%の精度が得られた．本論文では，辞書の情報を用いない場合，未知語の性質を学習しない場合についても実験し，それぞれの精度に及ぼす影響についても考察する．</section>
  <section title="形態素モデル">この章では形態素としての尤もらしさを計算するモデルについて述べる．我々はこのモデルをMEモデルとして実装した．テストコーパスが与えられたとき，そのコーパスの各文を形態素解析するという問題は文を構成する各文字列に二つのタグのうち一つ，つまり，形態素であるかないかを示す「1」か「0」を割り当てる問題に置き換えることができる．さらに，形態素である場合には文法的属性を付与するために「1」を文法的属性の数だけ分割する．すると，文法的属性の数がn個のとき，各文字列に「0」から「n」までのうちいずれかのタグを割り当てる問題に置き換えることになる．形態素解析の問題において，このn+1個のタグはMEモデルを定式化するときに「未来(futures)」空間を形成する．ここで，未来空間とは学習モデルにおける分類先に対応する．MEモデルでは他の類似したモデルと同様に，可能性のある未来空間Fにおける任意のfと可能性のある履歴空間Hにおけるすべてのhに対して確率分布P(f|h)を計算することができる．ここで，MEモデルにおける「履歴(history)」とは未来空間においてどこに分類するかという判断を下す根拠となるデータのことである．形態素解析の問題における確率分布は次の式で表すことができる．P(f|h_t)=P(f|テストコーパスから関係tに関して導出可能な情報)eqnarray*これは，テストコーパスからある関係tに関して導出可能な情報が得られたときにfの確率が求まることを示している．MEモデルにおける確率分布P(f|h)の計算は「素性(features)」の集合，つまり，未来を予測する助けとなる情報に依存する．この情報は素性関数として定義され，近年の計算言語学の研究で用いられてきた他の多くのMEモデルと同様に我々のモデルでも，履歴と未来を引き数とし0か1を返す2値関数として定義する．以下にその一例をあげる．g(h,f)&amp;=&amp;.eqnarrayここで，「has(h,x)」は履歴hに素性xが観測されるときに真を返す2値関数である．我々の場合，素性としては辞書の情報とともに，未知語の性質を学習できるように，着目している文字列の長さや文字種，その文字列が辞書にあるかどうか，連接する形態素の文法的属性，文字種の変化などを用いる．詳しくは~章で述べる．素性集合と学習データが与えられたとき，エントロピーを最大にするという操作によりモデルが生成される．このモデルではすべての素性g_iに対しパラメータ_iが関係付けられ，モデルは次のような条件付き確率として表される．P(f|h)&amp;=&amp;_i_i^g_i(h,f)Z_(h)Z_(h)&amp;=&amp;_f_i_i^g_i(h,f)eqnarrayパラメータを推定する際には，学習コーパスにおけるすべての素性g_iに対し，MEモデルから計算されるg_iの期待値がg_iの経験的期待値と等しくなるようにする．つまり，以下の式を成り立たせるようなパラメータを推定する．_h,fP(h,f)g_i(h,f)=_hP(h)_fP_ME(f|h)g_i(h,f)eqnarrayここで，Pは経験的確率分布であり，P_MEはMEモデルとして推定される確率分布である．形態素に付与するべき文法的属性がn個あると仮定する．文法的属性としては品詞と文節区切りを考える．品詞がm個の場合，その各々についてその品詞を付与した形態素の左側が文節区切りであるかないかを考慮し，文法的属性の数はn=2mとする．文字列が与えられたとき，その文字列が形態素であり，かつi(1in)番目の文法的属性を持つとしたときの尤もらしさを確率値として求めるモデルを形態素モデルと呼ぶ．このモデルは式()を用いて表される．ここで，fは0からnまでの値をとる．一文が与えられたとき，一文全体で確率の積が最大になるよう形態素に分割し文法的属性を付与する．最適解の探索にはビタビアルゴリズムを用いる．N-best解の探索には文献の方法を用いる．</section>
  <section title="実験と考察"/>
  <subsection title="実験の条件">品詞体系はJUMANのものを仮定した．品詞は細分類まで考慮すると全部で53種類ある．これに文節区切りを考慮すると推定するべき文法的属性の数は倍の106種類となる．活用型，活用形は品詞が決まれば表記からほぼ一意に決めることができるので，モデルから確率的に推定することはしない．したがって，式()のfは0から106までの107個の値をとるものとする．実験には，京大コーパス(Version2)を用いた．学習には1月1日と1月3日から8日までの7日分(7,958文)，試験には1月9日の1日分(1,246文)を用いた．一文が与えられると，5文字以下のすべての文字列および5文字を越えるが辞書に登録されている文字列に対して，その文字列が形態素であるかないか，形態素である場合にはその文法的属性が何かを推定する．5文字以下のすべての文字列としたのは，5文字を越えるような形態素は大抵，複合語あるいはカタカナ語であり，辞書に登録されていなければ，ほとんどの場合形態素ではないためである．複合語は辞書に登録されているもの以外は5文字以下の文字列に分割できると仮定する．また，カタカナ連続は辞書に登録されていない場合，ひとまとまりにして「未定義語(大分類)，カタカナ(細分類)」という品詞を持つものとして辞書に登録されていたものとして扱う．ビタビアルゴリズムを用いて最適解を探索する際には，JUMANで定義されている連接規則を満たさなければならないという制約を加えた．章に述べたモデルでは，各文字列に対し品詞を付与する際，すべての品詞候補(53種類)のうち一文全体の確率を最大にするものが選ばれる．このとき，必ずしも辞書に記述されている品詞が選ばれるとは限らない．そこで，辞書に登録されている文字列については，その文字列に付与可能な品詞がすべて辞書に記述されていると仮定し，各文字列に対し品詞を付与する際には，辞書に記述されている品詞の中から選択するという制約を加える．[htbp]table*次に，実験に用いた素性を表~にあげる．ここで素性とは，各素性名に対し素性値を展開したもののことである．各々の素性は式()の素性関数g_i(h,f)のiに対応する．素性番号は便宜上設けたものであり，各素性名に対応している．例えば，素性番号，素性名，素性値がそれぞれ「13」，「品詞(-1)(Major)」，「動詞」である素性および，「3」，「辞書(0)(Major)」，「形容詞」である素性に対応する素性関数はそれぞれ，式()および以下の式のように表わされる．なお，式中では添字のiは省略している．g(h,f)&amp;=&amp;.eqnarray*これらの式および表~で素性名に使われている「(0)」「(-1)」という表記はそれぞれ，着目している文字列，その文字列の左に連接する一形態素を意味する．素性関数としては，素性とfutureの組が学習コーパスで3回以上観測されたもののみを用いた．結果として実験に用いた素性は8,525個であった．以下で，表~の各素性名，素性値について説明する．(文字列)学習コーパスに形態素として現れた文字列のうち，頻度5以上のもの(長さ)文字列の長さ(文字種)文字の種類．「(頭)」「(末尾)」はそれぞれ文字列の先頭と末尾の文字を表す．文字列ではなく一文字の場合はともに同じ文字を指すものとする．「文字種(0)(変化)」は先頭と末尾の文字の変化を表す．「文字種(-1)(変化)」は左に連接する一形態素の末尾文字の文字種から着目している文字列の先頭文字の文字種への変化を表す．例えば，左に連接する一形態素が「先生」，着目している文字が「に」の場合，素性値は「漢字平仮名」と表す．(辞書)JUMANの辞書を用いる．この辞書に登録されている異なり形態素数は約20万個である．Major，MinorはそれぞれJUMANの品詞大分類と細分類に対応する．Major&amp;MinorはMajorとMinorの可能な組み合わせである．着目している文字列が辞書に登録されている場合，辞書に記述されている品詞の情報を素性として利用する．複数の品詞を持つものとして登録されている場合にはそれぞれを素性として用いたときに形態素モデルから推定される確率が一文全体で最大となるものを採用する．その文字列が，連語辞書に登録されている形態素列の一番左の形態素の文字列である場合には，その文字列が連語の先頭の形態素であるという情報を付加したものを素性として利用する．この場合，素性値としては「連語」という表記が付加されているものを用いる．連語については文献に詳しい説明がある．未知語の性質を学習するために，学習コーパスにおいて各文字列に対し辞書引きをしたときに一回しか引かれなかったものは辞書になかったものとして学習する．今回の実験ではそのような語の数は20,317個であった．ちなみに，辞書引きされた語の延べ数は1,964,829個，異なり語の総数は60,908個であった．このような学習方法をとることによって，辞書が充実すればその情報を反映できるとともに，辞書に依存し過ぎることなく未知語にも対処できると考えている．(品詞)Major，MinorはそれぞれJUMANの品詞大分類と細分類に対応(活用)Major，MinorはそれぞれJUMANの活用型，活用形に対応(文節区切り)形態素の左側に文節区切りがあるかないか</subsection>
  <subsection title="実験結果と考察">パラメータの推定にはImprovedIterativeScaling(IIS)アルゴリズムを用いた．計算マシンとしてSunEnterprise450(400MHz，SunOSRelease5.6Version)を用いたところ，推定に要した時間は二日程度であった．形態素解析の結果を表~に示す．ここで，再現率はコーパス中の全形態素に対して区切りと品詞(大分類のみ)を正しく推定できたものの割合を，適合率はシステムが推定した全形態素に対して区切りと品詞(大分類のみ)を正しく推定できたものの割合を求めたものである．表中のFというのはF-measureのことで，以下の定義式により計算した．F-measure&amp;=&amp;2再現率適合率再現率+適合率eqnarray*表の各行にはそれぞれ，~節で述べた手法およびJUMANによる精度をあげた．JUMANは単独では辞書に登録されていないカタカナ語に対し「未定義語」という品詞を付与するため，それによる誤りが多くなる．ルールベースの構文解析システムKNPは，JUMANに複数解の出力を許しその出力を入力とすると，構文解析の過程で品詞の曖昧性を解消し，未定義語も何らかの品詞に置き換えることができる．そこで，JUMANとKNPで解析した結果も評価した．表には+KNPと表記した．表~にあげた形態素区切りと品詞大分類に対する推定精度は，我々の手法ではJUMAN+KNPよりも3%程度低かった．その原因として学習コーパスの量，素性，コーパスにおける形態素の揺れなどが考えられる．今回用いた学習コーパスは約8,000文と少なく，素性については文献などで用いられているような組み合せの素性に相当するものはあまり用いていない．利用可能なマシンのメモリ容量の都合上，今回は学習コーパスの量，素性の数ともにこれ以上増やすのは困難であったが，いずれ可能になるだろう．次に形態素の揺れについてであるが，これは実験に用いた京大コーパスがJUMAN+KNPの解析結果を人手で修正したものであるということに起因していると思われる．このことはJUMAN+KNPの出力の評価に有利に働いている．例えば，最後が「者」で終わる形態素はテストコーパス中に153個あり，すべてJUMAN+KNPの出力と同じであった．このうち我々のシステムの誤りは3個(約2%)であった．コーパスには「生産(名詞)者(接尾辞)」と「消費者(名詞)」の違いなどの揺れがあり，このように区切りに一貫性のない場合，過学習にならないように学習するのは難しい．揺れに関してはコーパス全体を通して他にも同様な例がいくつかある．例えば，「芸術家(名詞)」と「工芸(名詞)家(接尾辞)」，「警視庁(名詞)」と「検察(名詞)庁(名詞)」，「現実的(形容詞)」と「理想(名詞)的(接尾辞)」などがそうである．この揺れの問題を解決するためには，コーパス修正の研究がより活発に行なわれる必要がある．一つの方法として，我々のモデルを用いる方法が考えられる．学習したモデルを用いて学習コーパス中の各形態素の確率を再推定し，確率の低い部分に一貫性を欠いたものがある可能性が高いと推測する方法である．今後，この方法を試してみたい．</subsection>
  <subsection title="素性と精度">辞書の情報，未知語の性質は，我々が実験で用いた素性に反映されている．表~にあげた素性のうち，「文字列」「辞書」の素性が辞書の情報を，「長さ」「文字種」の素性が未知語の性質を反映する．表~の右欄には，それぞれの素性を削除したときの解析精度と削除したことによる精度の増減を示した．ほとんどの素性が精度向上に貢献しており，特に辞書情報の貢献度が高いことが分かる．逆に辞書が解析結果に悪い影響を及ぼす例もある．例えば，「／海／に／かけた／ロマンは／，／」「／荒波／に／負け／ない心／と／」(「／」は形態素区切り)といった形態素区切りが出力として得られることがある．これは，漢字を使った表記「ロマン派」「内心」に加えて平仮名を使った表記「ロマンは」と「ない心」も名詞として辞書に登録されていたために生じた誤りである．このような間違いをなくすためには，不自然な表記を辞書に登録しないようにする，あるいは，辞書の表記に使われる文字種の性質を学習する必要がある．学習の際，一回しか辞書引きされなかった語は辞書に登録されていなかったものとして扱った．このようにしたのは，テストコーパスを解析するときには未知語が多くなると予想されるため，学習の際にもそれと同じ状況に少しでも近付けようとしたためである．ところが，実験後，学習コーパス，テストコーパスにおける未知語の割合を調べたところ，辞書に登録されていなかった語の数(見出し語の異なり数)の異なり形態素数に対する割合は，学習コーパスで26.6%(3,859/14,493)，テストコーパスで17.7%(901/5,093)であり，テストコーパスにおける未知語の割合の方が学習コーパスにおける割合より少ないことが分かった．ちなみに，未知語の大部分は数詞およびカタカナで表記された名詞が占めていた．そこで，辞書に登録されていた場合には辞書引きの頻度に関わりなくその情報をすべて学習に用いることにすると，精度は再現率95.78%，適合率95.38%，F-measure95.58ポイントとなった．これは表~にあげた精度よりわずかに良い結果である．今回の実験では学習コーパスより未知語の割合が少ないコーパスに対して実験したためこのような結果となったが，本手法を学習コーパスよりも未知語の割合が多い分野に適用するときには我々がとった学習手法は有効ではないかと考えている．その有効性を調べることは今後の課題である．</subsection>
  <subsection title="学習コーパスと精度">この節では，学習コーパスと解析精度の関係について考察する．図~に学習コーパスとテストコーパスのそれぞれを解析した場合の学習コーパスの量と解析精度の関係をあげる．図の横軸は学習コーパスの文数，縦軸はF-measureを表す．学習コーパスの解析には基本的に京大コーパスの1月1日の一日分を用いた．学習曲線(図~)を見ると，わずかではあるが増加する傾向にある．したがって，学習コーパスの量が増えればもう少し精度の向上が期待できそうである．[htbp]figure*</subsection>
  <subsection title="未知語と精度">我々の手法は，未知語に対しても前後の形態素のつながりから形態素と認定でき，適切な品詞を付与することができる．例えば，「漱石」や「露伴」はJUMANの辞書には登録されていないため，JUMAN+KNPでは「漱(名詞)石(名詞)」「露(副詞)伴(名詞)」のように解析されるのに対し，我々のシステムではどちらも正しく名詞であると解析される．この場合は，細分類も正しく人名であると解析できた．このような固有名詞などは未知語になることが多い．そこで，未知語(辞書にも素性にもなかった語)に対する再現率を調査した．結果を表~にあげる．表には品詞細分類まで正しい場合に正解とするという基準で求めた再現率もあげた．この基準で求めた我々の手法の精度はJUMAN+KNPに比べて10%程度良かった．この結果は我々のモデルでは未知語，特に固有名詞や人名，組織名，地名に関する語に対する学習が比較的にできていることを示していると考えて良いだろう．さらに，固有表現に関する情報を素性として利用した場合の実験を行なった．ここで固有表現とは，人名，組織名，地名など特定の事物を示す表現のことである．これらの表現は特に未知語になりやすい．固有表現に関する情報は，固有表現にSGML形式のタグを付与したコーパスから抽出した．このようなコーパスとしては，CRL(郵政省通信総合研究所)固有表現データ，IREX-NE予備試験トレーニングデータ，IREX-NE予備試験データ，IREX-NE本試験逮捕トレーニングデータなど(合計約12,000文)がある．これをJUMANを用いて形態素解析した結果から，固有表現を構成する形態素あるいは固有表現の前後の形態素の文字列として5回以上出現したもの2,279個を抽出し，素性として追加した．実験結果を表~の二行目(本手法+NE)にあげる．未知語に対する再現率は表~に本手法としてあげた精度より約2%良くなっている．テストコーパスに対する精度は再現率95.93%，適合率95.12%，F-measure95.52ポイントであった．これは表~にあげた本手法の精度よりもわずかに良い．これらの結果から，未知語になりやすい文字列を選択して素性として利用すると全体の精度が良くなるだけでなく，未知語に対する再現率も良くなることが分かる．</subsection>
  <section title="関連研究">実験で比較として用いたJUMANはルールベースのシステムであり，形態素に品詞を付与するときにかかるコスト(品詞コスト)と形態素を連接するときにかかるコスト(連接コスト)の和が一文全体で最小となるように形態素区切りと品詞を決める．それぞれのコストは予め人手により設定する必要がある．一方，我々の手法は学習に基づくシステムであり，JUMANの品詞コストと連接コストに相当するものを一つの確率値として表し，その確率値を計算するためのモデルをコーパスから統計的に学習する．大きな違いは，ルールベースと統計ベースという点だけでなく，JUMANが未知語を一文字からなる名詞と既知語に分割して出力するのに対し，我々の手法は，未知語に対しても前後の形態素のつながりから形態素と認定でき，適切な品詞を付与することができる点にもある．日本語では，我々の手法の他にも統計モデルに基づく方法がこれまでにいくつか提案されている．HMMや可変記憶長マルコフモデル(VariableMemoryMarkovModel,VMM)に基づく方法ではF-measureで約96ポイントの精度が得られている．これは我々の手法よりも良い精度であるが，これらの手法では未知語に対する扱いがあまり考慮されていない．未知語は一文字からなる名詞と既知語に分割して出力される．春野らは着目している形態素と一つ前の形態素の情報，つまり2gramの情報を用いたときに，94%程度の再現率が得られ，3gramあるいはそれ以上の情報を用いたときに96%程度の再現率が得られたと報告している．我々は2gramの情報のみで96%程度の再現率を得ていることを考慮すると，3gram以上の情報を用いることにより，より良い精度が得られることが期待できる．3gram以上の情報を用いることは今後の課題である．節で述べたように，未知語の問題に対処するため，これまで大きく二つの方法がとられてきた．一つは未知語を自動獲得し辞書に登録する方法(例えばなど)であり，もう一つは未知語でも解析できるようなモデルを作成する方法(例えばなど)である．永田は未知語のモデルを提案し，未知語に対し約40%の再現率が得られたと報告している．我々の方法では表~に示したように，最大で，形態素区切りと品詞大分類を推定したときに79.52%，形態素区切りと品詞細分類を推定したときに42.15%の精度を得ることができた．我々の手法の精度は永田の手法に比べて品詞細分類を推定したときでもわずかに良い．永田は我々とは異なるコーパス(EDRコーパス)を用いており，直接精度を比較することは難しいが，京大コーパスとEDRコーパスでは品詞体系と形態素の定義が似ていることから，この結果は我々の手法を評価するのに十分な材料の一つになると考えている．森らは辞書情報を用いるモデルを提案した．彼らはEDRコーパスを用いたときにF-measureで約92ポイント，京大コーパスを用いたときにF-measureで約95ポイントの精度を得ている．彼らが辞書情報を用いて得た精度向上はF-measureで約0.2ポイントであるのに対し，我々の手法では辞書情報を用いることにより，F-measureで約1.7ポイント精度が向上した．森らが京大コーパスを用いて得た約95ポイントの精度は，我々の精度とほぼ同程度である．しかし，彼らは学習コーパスに現れた形態素の文字列の情報をすべて用いているため，我々の実験に比べて未知語が少ない状況で実験していたものと思われる．英語では，品詞タグ付けの手法として，HMM，可変記憶長マルコフモデル，決定木モデル，MEモデル，神経回路網モデル，誤り主導の変換に基づく学習などに基づく方法やこれらのうちいくつかのモデルを組み合せた方法などがこれまでに提案されてきた．それぞれ高い精度が得られているが，これらの方法では大規模な語彙情報を利用することは難しい．一方，我々の提案したモデルは，辞書引きをする仕組みが素性の一つとして組み込まれているため，大規模な語彙情報も辞書情報として利用することができる．さらに，未知語の性質も学習することができる．そのため，我々のモデルを英語の品詞タグ付けに用いればより良い精度が得られる可能性が高いと考えている．</section>
  <section title="まとめ">本論文では次の二つの特徴をもつモデルをMEモデルとして実装した形態素解析の手法を提案した．(1)学習コーパスからだけでなく辞書から得られる情報も用いる．(2)形態素となる文字列だけでなく形態素とはならない文字列の性質も学習することによって，未知語も形態素として推定でき，同時にその文法的属性も推定できる．実験により，辞書の精度に及ぼす影響の大きさ，および，我々の手法が，固有名詞，人名，組織名，地名など未知語になりやすいものに対して比較的に推定精度がよいことが分かった．さらに，固有表現を構成するような文字列を抽出し素性として利用すると，精度，特に未知語に対する再現率が良くなる(約2%)ことが分かった．今後の課題としては以下の三点をあげておきたい．学習に用いる情報について．一つ前の形態素の情報だけでなく，二つから四つくらい前の形態素の情報を利用するとともに，組み合わせの素性を増やす．コーパスについて．コーパスの量を増やすとともに，コーパス修正の研究を活発に進める．また，異なるコーパスについても実験する．辞書について．今回実験に用いた辞書は既存の辞書であったが，今後，自動獲得した辞書を利用したときにどの程度精度の違いがあるかについて調査したい．また，文法体系が変わったときにその体系に合うように辞書情報を変換する技術を開発したい．謝辞flushleft本研究の評価にあたり，評価ツールを提供して下さった京都大学の黒橋禎夫講師に心から感謝の意を表する．document</section>
</root>
