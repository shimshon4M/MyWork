<?xml version="1.0" ?>
<root>
  <title>決定リストを弱学習器としたアダブーストによる日本語単語分割</title>
  <author>新納浩幸</author>
  <jabstract>本論文では決定リストを弱学習器としたアダブーストによる日本語単語分割法を提案する．日本語単語分割は，入力文の各文字の間に単語区切りを置くか置かないかの問題とみなすことで，分類問題として定式化できる．この分類問題を決定リストを利用して解くことで単語分割が行える．ここでは決定リストで利用する属性に辞書情報を含めない．そのためここでの単語分割は未知語の問題を受けないという長所がある．更に単語分割を分類問題として解く場合，近年研究の盛んなアダブーストの手法を適用できる．アダブーストを用いることで，決定リストの精度を高めることができる．実験では，京大コーパス（約4万文）を利用して決定リストを作成した．この決定リストによる単語分割の正解率は97.52%であった．この値は、同じ訓練データから構築したtri-gramモデルに基づく単語分割法での正解率92.76%を大きく上回った．またアダブーストを利用することで精度が98.49%にまで向上させることができた．また作成した単語分割システムは未知語の検出能力が高いことも確認できた．</jabstract>
  <jkeywords>単語分割，分類問題，決定リスト，アダブースト</jkeywords>
  <section title="はじめに">本論文では日本語単語分割を分類問題とみなし，決定リストを利用してその問題を解く．このアプローチは文字ベースの手法の一種となり，未知語の問題を受けないという長所がある．また分類問題ととらえることで，ブースティングの手法が適用できる．その結果，単独の決定リストを利用するよりも，さらに精度を向上させることができる．日本語形態素解析は，日本語情報処理において必須の要素技術であり，その重要性は明らかである．日本語形態素解析は単語分割と分割された単語への品詞付与という２つのタスクをもつ．正しい単語分割からは英語の品詞タガーなどの技術を利用して，高精度に品詞付与ができるために，日本語形態素解析の本質的に困難な部分は単語分割である．特に未知語の問題が深刻である．未知語の問題とは，辞書に登録されていない単語の出現によりその単語とその単語の前後での単語分割が誤るという問題である．未知語の問題に対処する一つの方法として，文字ベースの単語分割手法がある．文字ベースの手法とは，辞書を使わずに，各文字間に単語境界が存在するかどうかを判定することで単語分割を行う手法である．従来，文字ベースの手法としては，文字ベースのHMM(HiddenMarkovModel)が提案されている．文字ベースのHMMは，状態として文字間に単語境界が存在する（状態１）としない（状態０）の２つを設定し，状態間を遷移するときに各文字が出力されるモデルである．単語分割は遷移した状態列を推定することで行える．文字ベースのHMMでは状態aから状態bに移るときに文字cを出力する確率を訓練データから得る．本質的にこの確率の精度が単語分割の精度を左右する．通常その確率を計算するためにtri-gramモデルを利用するが，常識的に考えても，前2文字から次の文字を予測することは難しく，文字ベースのHMM単独ではそれほどの精度は期待できない．このため，様々な工夫を付加する必要がある．本論文では単語分割をHMMによりモデル化して解くのではなく，分類問題として定式化して解く．先ほども述べたように，日本語単語分割は，各文字間に単語境界が存在する（クラス(+1)）か存在しない（クラス(-1)）かを判定する問題であり，これは分類問題に他ならない．分類問題を解くために設定する属性として，辞書情報を使わないことで，文字ベースの単語分割手法と同様未知語の問題を受けない．また分類問題として見なすことで，n-gramモデルでは利用の困難であった様々な属性を判定の材料として利用可能になる．さらに，分類問題は機械学習や統計学で活発に研究されている問題であり，それらの研究成果を直接利用することができる．本論文では単語分割を分類問題と見なし，分類問題に対する帰納学習手法の一つである決定リストを用いて，その問題を解く．さらに，近年，機械学習の研究分野では弱学習器を組み合わせて強学習器をつくるブースティングの研究が盛んである．ここではその代表的な手法であるアダブーストを本問題に対して適用する．実験では，タグつきのコーパスである京大コーパス（約４万文）を訓練データとして，決定リストを作成した．その決定リストを利用した単語分割は，同じデータから学習させた文字tri-gramモデルに基づく単語分割法（文字ベースのHMMの一種）よりも高い精度を示した．さらに，アダブーストを利用することで，単独の決定リストよりも高い精度を得ることができた．また本手法の未知語の検出率が高いことも確認した．</section>
  <section title="決定リストによる単語分割"/>
  <subsection title="単語分割と分類問題">(n)文字からなる入力文を(s=c_1c_2c_n)（各(c_i)は文字を表す）とすると，日本語単語分割は文字(c_i)と(c_i+1)の間（(b_i)と名付ける）に単語境界がある((+1))かない((-1))かを与えることによって行える。つまり(b_i)（(i=1,2,,n-1)）に(+1)か(-1)を与える分類問題としてとらえられる.例えば，「太郎は海でアイスクリームを食べた。」という文に対しては，のように各文字間にクラス(+1)あるいは(-1)を付与し，(+1)の部分を単語境界に置き換えることにより単語分割が行える．[htbp]Wordsegmentationbyclassassignmentfigure*分類問題を解く手法は様々なものがある．どの手法が優れているかは問題に依存するために一概には言えない．本論文では決定リストを利用して上記の分類問題を解く．</subsection>
  <subsection title="決定リストの構築">決定リストは帰納学習手法の一種であり，正解付きの訓練データから，分類規則を学習する．決定リストの場合，分類規則は証拠とクラスの組の順序付きの表となる．ここで証拠とは属性とその属性の値の組である．実際の分類はリストの上位のものから順に，その証拠があるかどうかを調べ，その証拠があれば，それに対応するクラスを出力する．決定リストの作成は概ね以下の手順による．</subsection>
  <subsection title="属性の設定">各文字間(b_i)がどのクラスに属するかを判断する材料が属性である．本論文では(b_i)の属性として，の7種類を用意した．6，7番目の属性として，字種の情報を利用している形になっている．ここでは字種を大分類と細分類の二つの観点から分類した．字種の大分類は6番目の属性，字種の細分類は7番目の属性で利用した．字種の大分類はに示した9種類である．字種の細分類は大分類の平仮名の部分をその文字自身にしたものである．また注意として，本論文の決定リストでは(default)の証拠を導入していない．決定リストでは通常(default)という証拠を設けて，それ以下の判別力の証拠は表には入れない．(default)は文脈上の証拠が決定リストに存在しない場合の処理ととらえられるが，ここでは大分類の字種の情報が必ずヒットするので，(default)の証拠を含める必要がない．6番目の属性からの証拠の最下位のものが，決定リストの最下位の証拠となる．</subsection>
  <subsection title="利用例">決定リストの利用例を示す．例えば「太郎は海でアイスクリームを食べた。」という入力文の5番目の文字``で''と6番目の文字``ア''の間，つまり(b_5)にクラス(+1)あるいは(-1)を与えてみる．(b_5)の持つ証拠は以下の7種である．後述する実験で得られた決定リストを用いると，各証拠の分類クラスと判別力は以下の通りである．表の中で``--''の記号のものは，決定リスト中にその証拠がないことをあらわす．また本来ならば，決定リスト中の順位を求めなければならないが，ここでは相対的な順位関係だけが必要であり，順位の値自体は必要でない．判別力の最も大きなものが最上位の順位になるはずである．この場合，証拠((att_7,&quot;でカ&quot;))が最も大きな判別力を持つので，この証拠の分類クラス+1が判定結果となる．つまり(b_5)には単語境界を置くと判定する．</subsection>
  <section title="アダブーストの利用">精度の低い分類規則を組み合わせて精度の高い分類規則を得る方式をブースティングという．アダブーストはブースティング方式の一つであり，現在まで多くの理論的検証と実験的実証から有効性が示されている．アダブーストのアルゴリズムをに示す．分類クラス(の(Y))をここでは(+1,-1)の2値とする．また訓練データを((x_1,y_1),(x_2,y_2),,(x_m,y_m))で表す．ここで各(x_i)はデータを表し，(y_i)はデータ(x_i)のクラスである．具体的に(y_i)は(+1)あるいは(-1)の値である．この訓練データに対して，分類問題に対する学習アルゴリズム，例えば，決定木や決定リストなどを適用して，分類規則(h_1)を学習する．得られた分類規則(h_1)を訓練データに適用すると，(h_1)によって各(x_i)の判定クラスが得られる．今，(x_i)の実際のクラス(y_i)は与えられているので，分類規則(h_1)が各(x_i)に対して正しい判定を行ったかどうかを調べられる．これによって不正解のデータを集め，それら不正解のデータに対してある重みを付加して，訓練データ((x_1,y_1),(x_2,y_2),,(x_m,y_m))を再構成する．そしてこの再構成された訓練データに対して，再び学習アルゴリズムを適用して，分類規則(h_2)を学習する．これを(T)回繰り返す．この繰り返しによって，(T)組の分類規則(h_1,h_2,,h_T)が得られる．実際の判定は入力データに対して各分類規則が出力するクラスの重み付き多数決により行われる．例えば，(T=3)とし，入力データ(x)に対して，分類器(h_1)による判定クラスが(+1)，(h_2)による判定クラスが(-1)，(h_3)による判定クラスが(+1)であり，各重みが1，2.0，2.2であった場合，重み付き多数決の結果は(+1.2)である．最終的な判定クラスは総和の符合により求まる．この例の場合，符合は正であるので，(+1)が判定クラスになる．アダブーストのポイントは不正解のデータに課す重みの与え方である．概略，得られた分類規則の誤り確率（における(_t))が小さいほど重みが大きくなるように設定している．[htbp]AdaBoostfigure*本論文では．分類問題に対する学習アルゴリズムを決定リストに設定する．不正解データに与える重みをどのように反映させるかが問題である．ここでは，重みを頻度として与えることにした．例えば，「太郎が東京へ行く。」という文に以下のように単語境界``/''が置かれたものが訓練データである．太郎/が/東京/へ/行く/。verbatim今，4番目の文字``東''と5番目の文字``京''の間，つまり(b_4)に対する証拠は以下の通りである．``東''と``京''の間には，単語境界がないので，クラスは(-1)である．そして，決定リスト作成のstep2で示したように，以下の証拠の頻度に1が足される．この頻度に加算される1という数値に重みを反映させる．例えば，決定リスト(h_k)により上記例文の4番目の文字``東''と5番目の文字``京''の間の判定クラスが(+1)と判定された場合，この判定は不正解である．そこで次の決定リスト(h_k+1)を作成するときに，上記の７つの各証拠の頻度に1ではなく，重み自身を加える．つまり決定リストを作成する際には各訓練データには重みがついているとして，その重みが決定リスト作成のstep2で各証拠と正解の組に付加する数値とする．のアルゴリズムでは正規化するために重みの総和が１になっているが，ここでは重みの最小値が１となるようにして計算を簡単にした．このため最初の決定リストを作成する際の各訓練データの重みは１であり，２回目では正解のデータの重みは１で変化せず，不正解の部分の重みが大きくなる．</section>
  <section title="実験"/>
  <subsection title="文字 n-gram モデルに基づく単語分割法との比較">ここでは決定リストを利用した単語分割の有効性を示すために，文字n-gramモデルに基づく単語分割法との比較を行う．文字n-gramモデルに基づく単語分割法では，概略，単語境界を付与した訓練データにおいて，単語境界の記号自体も一つの特殊文字として考えて，ある文字列の後に単語境界が生じる確率あるいは生じない確率を文字n-gramモデルに基づいて計算する．最終的にはViterbiアルゴリズムなどの動的計画法を利用して，文字列の出現確率が最大になるように単語境界のあるなしの列を決定する．これは文字ベースのHMMにおいて，遷移確率やシンボル出力確率をある確率モデルに基づいて計算したものと同等である．訓練データとしては京大コーパス(約4万文)を利用した．京大コーパスは人手でタグをつけたコーパスであり，正解付きの訓練データとして利用できる．京大コーパスの中から950117.KNPというファイルに納められた1,234文をテストデータとした．結果，訓練データは京大コーパスからテストデータを除いた35,717文である．テストデータ1,234文の中には，単語境界を置くか置かないかを判定する位置が56,411個所存在する．この56,411個所に対して正しいクラスを付与できた割合を正解率とする．訓練データから文字tri-gram確率を求めるためにCMU-CambridgeToolkitを利用した．スムージングの手法としてはWitten-Belldiscountingを用い，カットオフは頻度0と設定した．文字tri-gram確率からtri-gramモデルに基づく単語分割法を実装したシステムを作成し，テストデータに対して単語分割を行った．結果，56,411個所の判定位置について，52,328個所で正しい判定を行い，4,083個所で誤った判定を行った．つまり正解率は92.76%であった．次に上記の訓練データを利用して本論文で提案した決定リストを作成した．頻度7以下の証拠は間引いた．作成できた決定リストの大きさは136,114であった．この決定リストによりテストデータに対して単語分割を行った．結果として，56,411個所の判定位置について，55,015個所で正しい判定を行い，1,396個所で誤った判定を行った．つまり正解率は97.52%であった．この値はtri-gramモデルに基づく単語分割法の正解率92.76%を大きく上回っており，本手法の有効性が示せた．</subsection>
  <subsection title="ブースティングの効果">前述したアダブーストにより，決定リストのブースティングを行った．ブースティングの回数を横軸に，テストデータに対する正解率%を縦軸にしたグラフがである．[htbp]Precisionbyboostingfigure*からわかるように，ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって判別した結果が最も優れていた．そのとき56,411個所の判定位置について，55,560個所で正しい判定を行い，851個所で誤った判定を行った．つまり正解率は98.49%まで向上した．</subsection>
  <subsection title="未知語の検出">ブースティングにより3組の決定リストを作成し，それらの重み付き多数決によって各文字間に単語境界の有無を判定する手法（以下これを本手法と呼ぶ）が，本実験において，どの程度の未知語を検出できたか調べる．前述した訓練データ35,717文とテストデータ1,234文の正確な単語分割結果から，それぞれに含まれている単語文字列を取り出した．ここでいう単語文字列とは，単純に単語分割された分割要素の文字列のことである．つまり用言の活用語尾が異なるものも，異なる単語文字列として取り出すことに注意する．結果，訓練データには914,392個（41,890種類）の単語文字列，テストデータには32,764個（6,479種類）の単語文字列が存在した．そしてテストデータには含まれるが，訓練データには含まれない単語文字列が1,024個（832種類）存在した．この1,024個（832種類）の単語文字列が本実験における未知語となる．結論から述べると，本手法によりこの1,024個（832種類）の未知語の中で，正しく検出できたものは688個（562種類），つまり個数で67.2%，種類数で67.5%の検出率であった．検出できた未知語の中には，字種区切りのような単純なヒューリスティクスから検出できるものも存在するので，本手法の未知語検出が，実質どの程度の有用性があるのかを示すために，対象の未知語を以下のように9タイプに分類した．上記9タイプの未知語の本手法による検出結果をに示す．同時に通常のシステムで想定できる検出結果も示す．に示すように通常のシステムの検出率は39.6%であり，本システムの検出率67.2%と大きく差がある．これは本システムの未知語の検出能力の高さを示している．また通常のシステムにより検出できるとした未知語のタイプ(1),(3),(4),(5),(7)に対して，本手法の検出率は83.3%であり，通常のシステムにより検出できる未知語の多くは本システムでも検出できると考えられる．</subsection>
  <section title="考察">本手法での判別の出力は2値であり，判別に使った判別力の値自体は利用されていない．テストデータに対して判別力の値による正解率を調べるために，以下の調査を行った．テストデータには56,411個所の判定位置があるが，0以上1未満の間の判別力で判定された位置は83個所であり，その正解率は57.83%であった．同様にして，1以上2未満の間，2以上3未満の間という具合いに順に調べていった結果を示したものがである．このグラフからもわかるように，判別に利用した判別力が小さいほど誤る確率が高くなる．このような判別力の値を利用して，さらに誤りを減らせる工夫も可能であろう．また本論文では分類問題の解法として決定リストを利用したが，他の手法，例えば，決定木や最大エントロピー法の利用も可能である．ただし本論文で利用した属性にあたるものを，それらの手法では単純には利用できない．決定木を利用する場合，属性の数は7種類であり問題ないが，bi-gramあるいはtri-gramにあたる属性の値の種類数が非常に多い．このため決定木の各ノードから出る枝の数が膨大になり，現実的には決定木を作成できない．また最大エントロピー法では素性の設定と素性パラメータの算出が必要となる．素性は本論文で述べた証拠自体となるため，素性の種類は頻度7で間引いて約14万弱である．最大エントロピー法で利用できる素性の数は現実的には，数万が限度であるために，最大エントロピー法の利用も現実的には無理がある．文字ベースの手法を利用する場合には，bi-gramやtri-gramなどの情報を直接利用できる決定リストは現実的に有効な選択である．本論文では単語分割を分類問題としてみなして解決した．分類問題とみなした場合，精度に関わる最も大きな要因は属性の選択である．アダブーストを利用するという枠組みでは，属性の設定はさらに考慮すべきである．ブースティングは弱学習アルゴリズムに対して利用できる．具体的には精度が50%を越えるようなアルゴリズムであれば適用できる．つまり作成できた決定木などの分類器自体の精度はそれほど高い必要はない．属性をうまく考慮して決定リストの精度を上げるよりも，作成される決定リストの精度は低いが，ブースティングにより精度が増してゆくような属性を設定するアプローチも有望である．いくつかの実験を行った結果，以下の点が確認できた．属性を増やす，間引きの頻度を調整する，などの工夫を入れて決定リストの精度を上げた場合，ブースティングでは精度が上がらなかった．属性を単純化して決定リストの精度を若干下げた場合，ブースティングによって精度は上がるが本実験で行った結果以上には精度は上がらなかった．結論的には本論文で設定した属性の情報を利用する上では，本論文で示した値程度が限界に近いと感じられた．分類誤りの原因を追求すると，訓練データに現れない表現あるいは頻度の低い表現の部分で分類が誤っている．これは未知語の問題そのものであり，未知語への対処が単語分割の中心の課題と言える．この解決策は3つ考えられる．1つ目は規則の一般化を精度良く行うことである．例えば文字クラスなどの導入などが考えられる．2つ目は別リソースの利用である．例えば辞書の利用である．単語分割に本手法の分類手法と辞書による最長一致法を利用することも考えられる．3つ目は訓練データの拡充である．事例ベースの手法は訓練データつまり事例を大規模化することで精度が上がる．ただし大規模な正解付きの訓練データが用意できない現状では，正解のない訓練データをどう使うかが鍵となる．１つ目のアプローチ以外は，未知語の検出に対して理論的な保証がない．しかしだからといって，単語分割を文字ベースの手法によって解くことに意味がないわけではない．辞書に基づいた分割では数値表現や字種区切りが有効になるような未知語しか解析できず，解析できる未知語が限定されている．このような未知語の多くは，実験に示したように，本手法でもその多くを検出できる．さらに文字ベースの手法では，その他のタイプの未知語も検出できる場合が多々あるが，辞書に基づいた分割では確実に検出できない．この違いは大きい．最後に本手法のアプローチは解析が決定的になるという長所もあることを付記しておく．通常の形態素解析システムも現実的にはほぼ文字数に比例した時間で解析が行えるので，決定的であるということはそれほど大きな長所ではない．ただし理論的に線形時間での解析を保証できることには意味がある．</section>
  <section title="おわりに">本論文では日本語単語分割を分類問題とみなし，決定リストを利用してその問題を解いた．本手法は未知語の問題を受けないという長所がある．実験では，文字ベースのn-gramモデルに基づく単語分割法との比較を行い，決定リストによる単語分割の方が優れていることを示した．また分類問題ととらえることで，ブースティングの手法を適用できることも示した．アダブーストを利用することによって，単独の決定リストよりもさらに精度を向上させることができた．未知語の検出能力も高かった．訓練データにない表現をどのようにカバーしてゆくかが今後の課題である．</section>
</root>
