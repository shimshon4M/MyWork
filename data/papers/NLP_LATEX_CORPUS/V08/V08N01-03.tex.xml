<?xml version="1.0" ?>
<root>
  <author>亀谷由隆森高志	佐藤泰介</author>
  <title>WFSTに基づく確率文脈自由文法およびその\\	拡張文法の高速EM学習法亀谷由隆・森高志・佐藤泰介</title>
  <jabstract>現在，統計的言語モデルの一クラスとして確率文脈自由文法(PCFG)が広く知られている．また，括弧なしコーパスからPCFGを訓練する方法としてInside-Outside(I-O)アルゴリズムが知られてきた．I-OアルゴリズムはPCFG用に効率化を施したEM(expectation-maximization)アルゴリズムだが，依然その計算速度に問題があることが知られている．本論文では，文法構造があらかじめ与えられていることを前提に，訓練過程を構文解析とEM学習に分離した高速EM学習法を提案する．その中間データ構造にパーザが生成するWFST(well-formedsubstringtable)を用いる．例えば，一般化LRパーザを用いると事前コンパイル・ボトムアップ探索による効率性，およびChomsky標準形を要求しないという一般性を引き継ぐことができる．一方EM学習では，WFSTのコンパクトさを利用して効率的なパラメタ推定が行なわれる．推定結果はI-Oアルゴリズムで得られるものと一致する．更に，文脈依存性を取り入れたPCFGの拡張モデルに対する多項式オーダのEM学習法を示す．また，ATR対話コーパスを用いて実験を行ない，訓練時間が大幅に短縮されていることを確認した．</jabstract>
  <jkeywords>確率文脈自由文法，EMアルゴリズム，	Inside-Outsideアルゴリズム，WFST</jkeywords>
  <subsection title="">*謝辞実験に用いたATRコーパス，日本語文法の改訂版は，東京工業大学田中・徳永研究室のご厚意により提供頂きました．記して感謝致します．また，同研究室白井清昭助手には上記コーパス・文法に関する情報やテキスト処理プログラムの提供，文献紹介など貴重なご助力を頂きました．重ねて感謝申し上げます．また，東京工業大学佐藤泰介研究室の上田展久氏には文献紹介を含め，数多くの有益なコメントを頂きました．感謝致します．なお，本研究の一部は平成11年度科学研究費補助金特定領域研究(A)「発見科学」の補助を受けています．</subsection>
  <section title="はじめに">現在，統計的言語モデルの一クラスとして確率文脈自由文法（probabilisticcontext-freegrammar;以下PCFG）が広く知られている．PCFGは文脈自由文法（context-freegrammar;以下CFG）の生成規則に確率パラメタが付与されたものと見ることができ，それらのパラメタによって生成される文の確率が規定される．しかし，すべてのパラメタを人手で付けるのはコストと客観性の点で問題がある．そこで，計算機によるコーパスからのPCFGのパラメタ推定，すなわちPCFGの訓練(training)が広く行なわれている．現在，構造つきコーパス中の規則出現の相対頻度に基づきPCFGを訓練する方法（以下，相対頻度法と呼ぶ）が広く行なわれているが，我々はより安価な訓練データとして，分かち書きされている（形態素解析済みの）括弧なしコーパスを用いる．括弧なしコーパスからのPCFGの訓練法としては，Inside-Outsideアルゴリズムが広く知られている（以下,I-Oアルゴリズムと略す）．I-OアルゴリズムはCYK(Cocke-Younger-Kasami)パーザで用いられる三角行列の上に構築された，PCFG用のEM(expectation-maximization)アルゴリズムと特徴づけることができる．I-Oアルゴリズムは多項式オーダのEMアルゴリズムであり，効率的とされているが，訓練コーパスの文の長さに対し3乗の計算時間を要するため，大規模な文法・コーパスからの訓練は困難であった．また，基になるCFGがChomsky標準形でなければならないという制約をもっている．一方，本論文では，PCFGの文法構造（基になるCFG）が所与であるときの効率的なEM学習法を提案する．提案手法はwell-formedsubstringtable（以下WFST）と呼ばれるデータ構造を利用しており，全体の訓練過程を次の2段階に分離してPCFGを訓練する．WFSTは構文解析途中の部分的な解析結果（部分構文木）を格納するデータ構造の総称であり~，パーザはWFSTを参照することにより再計算を防いでいる．また，最終的にWFSTに格納されている部分構文木を組み合わせて構文木を出力する．表~に各構文解析手法におけるWFSTを掲げる．なお，Fujisakiらも文法が所与であるとして，上の2段階でPCFGを訓練する方法を提案しているが，その方法ではWFSTは活用されていない．提案手法の特長は従来法であるI-Oアルゴリズムの一般化と高速化が同時に実現された点，すなわち点にある．先述したように，I-OアルゴリズムはCYK法のWFSTである三角行列を利用して効率的に訓練を行なう手法と捉えることができ，提案手法のCYK法とgEMアルゴリズムを組み合わせた場合がI-Oアルゴリズムに対応する．一方，提案手法でEarleyパーザや一般化LR（以下GLR）パーザと組み合わせる場合，文法構造にChomsky標準形を前提としないため，本手法はI-Oアルゴリズムの一般化となっている（特長1）．加えて，本論文ではStolckeの確率的Earleyパーザや，PereiraとSchabesによって提案された括弧なしコーパスからの学習法も提案手法の枠組で扱うことができることを示す．また，特長2が得られるのは，提案手法ではがWFSTというコンパクトなデータ構造のみを走査するためである．そして，LR表へのコンパイル・ボトムアップ解析といった特長により実用的には最も効率的とされる一般化LR法~（以下GLR法）を利用できる点も訓練時間の軽減に効果があると考えられる．そして特長3は提案手法の汎用性を示すものであり，本論文では北らの規則バイグラムモデルの多項式オーダのEMアルゴリズムを提示する．本論文の構成は次の通りである．まず節~でPCFG，CYKパーザ，I-Oアルゴリズム，およびそれらの関連事項の導入を行なう．I-Oアルゴリズムと対比させるため，提案手法をCYKパーザとアルゴリズムの組合せを対象にした場合を節~で記述した．特長2を検証するため，GLRパーザとgEMアルゴリズムを組み合わせた場合の訓練時間をATR対話コーパス(SLDB)を用いて計測した．その結果を節~に示す．また，特長3を具体的に示すため，節~ではPCFGの拡張文法に対する多項式オーダのEMアルゴリズムを提示する．最後に節~で関連研究について述べ，特長1について考察する．本論文で用いる例文法，例文，およびそれらに基づく構文解析結果の多くはのもの，もしくはそれに手を加えたものである．以降ではA,B,を非終端記号を表すメタ記号，a,b,を終端記号を表すメタ記号，を一つの終端または非終端記号を表すメタ記号，,,を空列もしくは終端記号または非終端記号から成る記号列を表すメタ記号とする．空列はと書く．一方，一部の図を除き，具体的な文法記号をS,NP,などタイプライタ書体で表す．また，y_nを第n要素とするリストをy_1,y_2,で表現する．またリストY=,y,であるとき，yYと書く．集合Xの要素数，記号列に含まれる記号数，リストYの要素数をそれぞれ|X|,||,|Y|で表す．これらはどれも見た目は同じだが文脈で違いを判断できる．</section>
  <subsection title="準備">提案手法を記述する前に形式化を行なう．=1Nについて以下をおこなう．まず，__(_)(),V__(_)()=@;;_と定める．そして，V_の要素を_k@_k_1_k_2_k_M_	k&lt;k_1,k_2,,k_Mを満たすように並べた_1,_2,,_|V_|をO_とする．また，次を導入する．_(A(d,d'))&amp;&amp;		E	|		.	eqnarray_はコーパス中の文_の構文木のいずれかに現れる部分木の親子対の集合である．同様にV_は_の構文木のいずれかに現れる部分木ラベルの集合である．O_はV_の要素を_中の半順序関係（親子関係）@を満たすように順序づけたものである．O_の第一要素_1は必ずS(0,n_)になる．_は部分木と規則の論理的な関係を表現する．例えば，[_(A(d,d'))=	;		AB_1C_1,;B_1(d,d''_1),;C_1(d''_1,d'),;		AB_2C_2,;B_2(d,d''_2),;C_2(d''_2,d')	;]に対しては，「_に対して部分木A(d,d')を作るためには，規則AB_1C_1を適用し，部分木B_1(d,d''_1)と部分木C_1(d''_1,d')を作る，もしくは規則AB_2C_2を適用し，部分木B_2(d,d''_2)と部分木C_2(d''_2,d')を作る，のいずれかである（他の場合はあり得ない）」と解釈する．O_と_は次節で説明する支持グラフを構成する．例として，図~のCFGG1と_=急いで,走る,一郎,を,見たに対して図~の2つの構文木t1,t2を考える．各々に対応する適用規則列を_1,_2とおくと，(_)=_1,_2である．このとき_は	_&amp;=&amp;(_1)(_2)		&amp;=&amp;		;S(0,5)@PP(0,4)V(4,5),;			PP(0,4)@NP(0,3)P(3,4),;			NP(0,3)@VP(0,2)N(2,3),		&amp;&amp;VP(0,2)@ADV(0,1)V(1,2),;			V(4,5)@見た(4,5),;			P(3,4)@を(3,4),;			N(2,3)@一郎(2,3),		&amp;&amp;V(1,2)@走る(1,2),;			ADV(0,1)@急いで(0,1);		&amp;&amp;;		;S(0,5)@ADV(0,1)VP(1,5),;			ADV(0,1)@急いで(0,1),;			VP(1,5)@PP(1,4)V(4,5),		&amp;&amp;			PP(1,4)@NP(1,3)P(3,4),;			NP(1,3)@V(1,2)N(2,3),;			V(1,2)@走る(1,2),		&amp;&amp;			N(2,3)@一郎(2,3),;			P(3,4)@を(3,4),;			V(4,5)@見た(4,5);eqnarray*となる．また，O_は一意には決まらないが，どの場合でも第一要素は必ずS(0,5)になる点に注意する．例えば下のようなO_が考えられる．[	]また_をO_の順に示す．[=4pt]small</subsection>
  <subsection title="確率文脈自由文法">はじめに，文脈自由文法Gを4つ組,,R,Sで定義する．ただし，は非終端記号の集合，は終端記号の集合，Rは規則の集合，Sは開始記号(S)である．R中の各規則rはAの形をしており，記号列'中に非終端記号Aが出現するとき，Aをに置き換えることが可能であることを表す．我々は常に最左の非終端記号を置き換えるように規則を適用する（最左導出に固定する）．規則rの適用により記号列がに置き換えられるときrと書く．このような置き換えを0回以上行なってからが得られるとき，と書く．特に，置換えが1回以上であることを強調する場合はと書く．Sから導出可能な非終端記号列を文と呼ぶ．CFGGにおける文の集合をGの言語と呼び，L_Gと書く．そして，Gに基づくPCFGをG()で表す．逆にGを「PCFGG()の文法構造」と呼ぶ．は|R|次元ベクトルであり，以降パラメタと呼ぶ．の各要素は(r)で参照され，0(r)1,;	_:(A)R(A)=1が成り立つとする(A,;rR)．PCFGでは「適用する規則は他に影響を受けずに選択される」と仮定される．従って_0r_1_1r_2_2	r_3r_K_Kにおける規則の適用列=r_1,r_2,,r_Kの出現確率P(|)はと計算される．また，(r,)を適用規則列中に規則rが出現する数とすると，と書くこともできる．Sを実現する適用規則列すべてから成る集合を()とおく．文は適用規則列から一意に定まるので，文と適用規則列の同時分布P(,|)に関しが成り立つ．式~より開始記号Sからが導出される確率P(|)は次のように求まる：パラメタが文脈より明らかなときはP(,|),P(,|)を各々P(,),P(,)と書く．先述した規則適用の独立性に加え，以降で考えるPCFGG()は次を満たすとする．G()は整合的である．すなわち	_L_GP(|)=1が成り立つ．右辺がである規則（規則）や	AAとなるようなAが存在しない．ChiとZemanは，2番目の条件を満たす文法構造Gと有限長の文から成る括弧なしコーパスが与えられたとき，I-Oアルゴリズムで得られる訓練パラメタ^の下でのPCFGG(^)が整合的であることを示した~．</subsection>
  <subsection title="コーパス・構文木">平文=w_1w_2w_nL_Gに対して個々のw_jは単語である(n&gt;0,j=1n)．に対して単語位置d=0nを与える．0dd'nについてdとd'の間にある部分単語列w_d+1w_d'を_d,d'と書く（=_0,nである）．また，（部分）単語列w_dw_d'をリストw_d,,w_d'で表すことがある．L_Gに対して，の構文木はSの導出過程を木構造で表現したものである．我々は導出戦略を最左導出に固定しているので，Sの適用規則列からの構文木tが一意に決まり，逆も真である．従ってP(t)=P()が成り立つ．先に我々は対象とするPCFGが規則をもたないこと，AAという導出が起こらないと仮定した．この仮定より，の構文木tの部分構文木（以下，部分木）t'はその根ノードの非終端記号Aと葉ノードを構成する部分単語列の開始／終了位置の対(d,d')によって一意に定まるので，以降，我々は部分木t'をラベルA(d,d')で参照する．の構文木tは，葉ノードを除くtの部分木ラベルから成る集合(t)（tのラベル集合と呼ぶ）と同一視できる．また，(d,d')は一つの括弧づけに相当する．(t)(d,d')A(d,d')(t)と定め，tの括弧集合と呼ぶ．また，A_1_2_Mの展開によって得られた_1,_2,,_Mを根とする部分木_m(d_m-1,d_m)を考える（図~）．このときA(d_0,d_M)@_m(d_m-1,d_m)なる部分木に関する半順序関係@を導入する(m=1M)．この関係を以降では「A(d_0,d_M)は_m(d_m-1,d_m)の親である」，また逆に「_m(d_m-1,d_m)はA(d_0,d_M)の子である」などということがある．そして親A(d_0,d_M)とその子をすべてまとめてと表し，これを「部分木の親子対」と呼ぶことにする．構文木t中に出現する部分木の親子対をすべて集めた集合を(t)で表す．構文木tに対応する適用規則列に対して(),(),()をそれぞれ(t),(t),(t)と同一視する．PCFGの訓練用のコーパスとして我々は(1)構造つきコーパス(labeledcorpus)，(2)完全括弧つきコーパス(fullybracketedcorpus)，(3)部分括弧つきコーパス(partiallybracketedcorpus)，(4)括弧なしコーパス(unbracketedcorpus)の4つを考える．我々は訓練法として最尤推定法(maximumlikelihoodestimation)を考えており，N文を含むコーパスc_1,c_2,,c_NはPCFGG()に基づく独立なN回のサンプリング導出の結果であると仮定する．_,_を回目のサンプリングで得られた平文および適用規則列とすると(=1N)，が構造つきコーパスのときc_=_,(_),完全括弧つきコーパスのときc_=_,(_),部分括弧つきコーパスのときc_=_,_,括弧なしコーパスのときc_=_となる(_L_G,(_),_(_))．_の部分単語列を^()_d,d'とおき(0d&lt;d'n_)，_のd番目の単語をw^()_dとおく．ただしn_|_|である．</subsection>
  <subsection title="CYKパーザ">CYKパーザはChomsky標準形であるCFGに適用可能なパーザである．我々は括弧なしコーパス中の文_に対してn_n_の三角行列T^()を用意する(n_=|_|)．d行d'列の要素T_d,d'には部分単語列_d,d'に対する解析結果が格納される．CYKパーザを実現する手続きCYK-Parserを図~に示す．対角要素から順に部分木を組み上げ（行~--），T_0,n_にS(0,n_)@;が含まれていたら解析が成功したものとし，含まれていなかったら失敗したものとする（行~）．解析が成功したらT_0,n_に含まれるS(0,n_)@;から順に部分木の親子対を辿って構文木が取り出される．図~に示したCFGG1において文=急いで,走る,一郎,を,見たに対する三角行列を図~に示す．図~の○印のついた部分木の親子から図~の構文木t1が取り出され，●印のついた部分木の親子からt2が取り出される．</subsection>
  <subsection title="Inside-Outside アルゴリズム">先にも述べたように，我々はPCFGのパラメタをコーパス=c_1,c_2,,c_Nから最尤推定法に基づき訓練することを考えている．が構造つきコーパスの場合，相対頻度法で得られる各規則rの相対出現頻度が最尤推定値となるので，これをrの訓練パラメタ^(r)とすればよい．しかし，構造つきコーパスの作成コストを考えると，より安価な括弧なしコーパスしか利用できない場合が十分考えられる．括弧なしコーパスでは構文構造が明らかでないため，相対頻度法が適用できず，代わりにI-OアルゴリズムというPCFGに特化された形のEMアルゴリズムが広く知られている．I-Oアルゴリズムは，括弧なしコーパス=_1,_2,,_Nが与えられたときに尤度_=1^NP(_)あるいはその対数_=1^NP(_)（対数尤度）を局所的に最大にする^を見つける．つまりI-Oアルゴリズムもまた最尤推定法である．をはじめとする多くの文献の記述では，文法構造Gのうち規則集合Rを明示的に与えず，終端記号集合と非終端記号集合を与えた場合を考えている．提案手法との対比のため，本節ではRを明示的に与えた場合のI-Oアルゴリズムを記述する．とのみを与えた場合のI-Oアルゴリズムは（以下ではと略すことがある）を考え，規則集合をR=(,)として与えた場合と同一である．ただし，いずれの場合でもRはChomsky標準形でなければならない．では規則集合Rを含めた学習を目的にI-Oアルゴリズムを使用しているが，我々はパラメタの学習に焦点を絞る．I-Oアルゴリズムの中心は内側確率P(A_d,d'^())と外側確率P(S_0,d^()A_d',n_^())という2つの確率値の計算である(=1N,A,0d&lt;d'n_)．各確率値を配列変数_d,d'^()[A],_d,d'^()[A]に格納する．これらの配列変数はCYKアルゴリズムで用いた三角行列T_d,d'中に設けられているものとする．^()_0,n_=_より_0,n_^()[S]に文_の生起確率P(S_)が格納される点に注意する．内側確率と外側確率を計算する手続きGet-Beta,Get-Alphaを図~に示す．記述を簡単にするため，配列変数_d,d'^()[]および_d,d'^()[]は手続きが呼び出される度に0に初期化されるものとする．Get-BetaはCYKパーザにおいて部分木を組み上げるのと同じように，三角行列の対角要素から出発し，右上隅_0,n_^()[]に至るまで段階的に内側確率を計算していく．また，逆にGet-Alphaでは右上隅_0,n_^()[]から対角要素に向かって外側確率を計算する．このように内側・外側確率は動的計画法(dynamicprogramming)に基づき，一方向に従って計算が進められる．内側・外側確率を計算し終ったら，コーパスが与えられた下での規則ABC,Aaの適用回数の条件つき期待値（以下，期待適用回数という）が次のように計算される:[ABC]&amp;:=&amp;	_=1^N		1_0,n_^()[S]		_k=2^n__d=0^n_-k_k'=1^k-1		(ABC)		_d,d+k^()[A]		_d,d+k'^()[B]		_d+k',d+k^()[C]	,[Aa]&amp;:=&amp;			_=1^N				1_0,n_^()[S]			_d=0^n_-1(Aa)_d,d+1^()[A].	eqnarray更に，上で計算された期待値からパラメタ(A)が更新（再推定）される:I-Oアルゴリズムでは，まずを適当な値に初期化し，次いで手続きGet-Beta,Get-Alphaおよび式~,~,~によってを更新する．そして，このように更新を繰り返すと対数尤度_=1^NP(_)=	_=1^N_0,n_^()[S]が単調増加しながら最終的には収束する．収束したら，そのときのパラメタの値を最終的な推定値としてI-Oアルゴリズムは終了する．ここで，I-Oアルゴリズムの計算量を考える．収束までのパラメタ更新回数は初期値に依存するため，事前には分からない．従って1回のパラメタ更新に必要な計算量をI-Oアルゴリズムの計算量とする．非終端記号集合,終端記号集合を固定した場合の最悪計算量を測る場合にはR=(,)の場合を考えればよい．訓練コーパスに対して最長の文の長さをLとする．手続きGet-Beta,Get-Beta（図~）中のfor,foreachループとの引数に注目すれば，I-Oアルゴリズムの最悪計算量はO(||^3L^3)であることが容易に分かる．</subsection>
  <subsection title="Inside-Outside アルゴリズムに関する考察">アルゴリズム中で最もコストが高いのは，Get-Beta行~における内側確率の計算，Get-Alpha行~--における外側確率の計算である．Get-Beta行~において図~(1)という状況すべてを考慮して内側確率が計算される．一方，Get-Alphaの行~--における右辺第1項，第2項ではそれぞれ図~(2),(3)という状況がすべて考慮されている．考えられるすべての状況について計算をすすめるという意味でI-Oアルゴリズムの動作は仮説駆動（トップダウン）型パーザの動作と同じである．一般に仮説駆動型は入力文_の情報とは無関係に計算をすすめるために効率が悪いとされている．文法構造が与えられていてもI-Oアルゴリズムの計算速度が低いのは，仮説駆動型であることが原因であると考えられる．そもそもI-Oアルゴリズムはという規則rの期待適用回数[r]の計算をから得られる手続きGet-Beta,Get-Alphaおよび式~,~によって効率化したものである~．ただし，節~で定めたように(r,)は規則列に出現する規則rの数である．式~で，r=(ABC)とおいたとき，I-Oアルゴリズムでは(ABC)	_all;P(_,)を次のように計算する（添字の_,^()は省略）．&amp;&amp;(ABC)	_		P(,)	&amp;&amp;=(ABC)		_				P(,)	&amp;&amp;=(ABC)		_d,k,k'		_				P(,)		&amp;&amp;=(ABC)		_d,k,k'			P(S_0,dA_d+k,n)			(ABC)	&amp;&amp;			P(B_d,d+k')			P(C_d+k',d+k)	&amp;&amp;=		_d,k,k'			P(S_0,dA_d+k,n)			P(B_d,d+k')			P(C_d+k',d+k)eqnarray式~の変形は入力文や実際の構文木t()とは無関係に行なわれており，I-Oアルゴリズムが仮説駆動型であるというのはこの点に由来する．それに対し，式~より式~を下の式~に変形し，構文木情報を直接利用する方法を考える．はパーザを利用することによって事前に獲得しておく．また，式~はFujisakiらの計算方法に他ならない．式~を用いればI-Oアルゴリズムのようにと無関係な部分を計算することはなくなる．ただし，一般に|()|は文長||に対して指数オーダになってしまうため，これをそのまま計算するのは現実的ではない．提案手法ではI-Oアルゴリズムのように再計算を防ぐ仕組みを取り入れ，パーザのもつWFSTを利用して式~を効率的に計算する．従って，提案手法をFujisakiらの方法とI-Oアルゴリズム双方の長所を取り入れた方法と見ることもできる．</subsection>
  <section title="提案手法">提案手法の概要を図~に示す．入力として確率文脈文法G()の文法構造,,R,Sと括弧なしコーパスが与えられるものとする．そして訓練パラメタを出力として返す．提案手法において，我々は全体の訓練過程を構文解析とEM学習に分離する．はじめに我々はパーザで中の各文_をすべて解析する．すると(_)を細切れにした，しかし(_)と等価な構文情報O_,_がパーザのWFSTに格納されているので，これらを抽出する．O_,_を表現するデータ構造を支持グラフと呼ぶ．次に，支持グラフに基づきgEMアルゴリズムを動作させを得る．図~のCFGG1と文_=急いで,走る,一郎,を,見たの例を考えると，支持グラフは図~において○印と●印がついた部分木の親子から得られる．この例から分かるように，文法によってはアルゴリズムで参照する支持グラフは三角行列全体に比べて非常に小さくなる可能性があり，その場合は三角行列全体を走査しなければならない-Oアルゴリズムに比べ大幅な速度向上が得られる（提案手法の特長2）．</section>
  <subsection title="支持グラフ">O_,_という組を支持グラフ_というデータ構造で捉えるとgEMアルゴリズムが理解しやすくなる．「グラフィカルEM」の名もここに由来する．まず，前節で示したO_,_の例に対応する支持グラフを図~(a)に示す．支持グラフ_は再帰遷移ネットワーク（recursivetransitionnetwork;以下RTN）に似た構造をもつ非循環有向グラフ(DAG)であり，共通の辺をもたない部分グラフ_(),_()の集まりから成る（ただしO_）．各_()は「の部分支持グラフ」と呼ばれ，=A(d,d')が付与されている．また，_()は開始ノード，終了ノードと呼ばれる2つの特殊なノードをもち（図~では各々start,endと書かれている），各E_()に対して開始ノード，Eの各要素（規則Aまたは部分木ラベルA(d,d')）が付与されたノード，終了ノードが一列に連結されている．複数のノードに同じ規則または部分木ラベルが付与されることもある点に注意する．有向辺はすべて開始ノードから終了ノードに向かっている．開始ノードから終了ノードに至るパスを局所パスと呼び，これもEで参照する．局所パスにおいて，規則Aが付与されたノードを基本ノード，部分木ラベルA(d,d')が付与されたノードを中間ノードと呼び，各々図~のように○と◎で表す．支持グラフは次の特徴をもつ．	支持グラフ_に対してRTNのように再帰的な巡回を	行なうことができる．	複数の巡回パスの一部が共有される．	部分支持グラフ_()=,()	のE_()に対して，どの'=A(d,d')Eに	ついても@'が成り立つ．	一つの局所パス中に存在する基本ノードと中間ノードの数に制限がない．1つ目の特徴である再帰的な巡回は次のようにして行なわれる．S(0,n_)の開始ノードから出発し，辺に沿って各ノードを訪問していくが，途中に中間ノード=A(d,d')があったら，が付与された部分支持グラフの開始ノードにジャンプする．そして終了ノードに至ったらジャンプ元のノードに戻る．これを再帰的に繰り返し，S(0,n_)の終了ノードに至ったら一回の巡回を終了する．分岐がある場合はその中のどれかを選ぶ．このような巡回の途中で中間ノードに付与される部分木ラベルを集めると_の構文木いずれか一つのラベル集合が得られる．また，局所パス中のノードの順序を図~のようにして，巡回中に基本ノードに付与されている規則を順に集めると_の最左導出における適用規則列(_)が一つ得られる．再帰的巡回を全通り行なえば(_)中の適用規則列をすべて見つけることができる．この考えは後に記述するgEMアルゴリズムの正当性を示すときに用いる（付録~）．図~~(b)に再帰的巡回の例を示す．2つ目の特徴が得られるのは，ある再帰的巡回において，同じ部分木ラベル=A(d,d')が付与されたノードでは同じ部分支持グラフ_()にジャンプするためである．このような共有構造により支持グラフのサイズが圧縮され，我々はgEMアルゴリズムを支持グラフの上で動作させることによって効率的な確率計算を実現する．例えば，図~(a)においてV(4,5)が付与されたノード（印）では同じ部分支持グラフ_(V(4,5))にジャンプする．3つ目の特徴は，規則およびサイクルAAが存在しないという仮定と，O_,_の定義から明らかであり，「@'であるとき，'の部分支持グラフ_(')中のノードはを参照しない」と言い替えることもできる．この事実に基づき，I-Oアルゴリズムの内側・外側確率計算における動的計画法（節~）の考えを一般化したものがgEMアルゴリズムに導入されている．また，4つ目の特徴は支持グラフの構造の一般性を示しているが，gEMアルゴリズムはこの一般性を保持するように記述される．</subsection>
  <subsection title="支持グラフの獲得">次に，支持グラフO_,_をパーザがもつWFSTから効率的に抽出する方法を説明する．O_はV_の要素を_における半順序関係@を満たすように全順序に並べたものである．一般に，半順序関係の全順序関係への変換はトポロジカルソーティングによって実現される．従って，我々はトポロジカルソーティングの考えに基づきO_を獲得する．また，ソーティングの途中で_が計算できる．以上を実現する支持グラフ抽出ルーチンExtract-CYKを図~（上）に示す．ただし，そのサブルーチンは利用するパーザのWFSTの形式に特化したものを用意する．図~（下）にCYK用サブルーチンVisit-CYKを示す．我々は大域的にスタック(U),スタックUにオブジェクトxをpushするPushStack(x,U),スタックUをpopして，popされたオブジェクトを返すPopStack(U)の3つを用意する．Uとフラグ[]を用意し，再帰的手続きVisit-CYKで三角行列（CYKのWFST）の右上隅から部分木A(d,d')を次々に訪問する（Extract-CYK行~）．そして訪問が終ったら，部分木のラベルをスタックUに積む（Visit-CYK行~）．また，訪問の途中で_を記録していく（Visit-CYK	行~,~）．フラグ[]に訪問したことを記録し，一度訪問した部分木には行かない（Visit-CYK行~,--）．最後にスタックUに積んであった部分木ラベルを順に取り出せば（Extract-CYK行~--），それがO_になっている．GLRパーザのWFSTである共有圧縮統語森は_を木（森）構造で捉えたものと見ることができる．GLRパーザは文法構造にChomsky標準形を要求しないので，Visit-CYKよりも一般的な形で記述する必要があるが，スタックU,フラグ[]を用いる点や再帰手続きになる点など基本手続きはVisit-CYKと変わらない．また，支持グラフ抽出ルーチンの動作はパーザ備え付けの構文木出力ルーチンや構文木数え上げルーチンによく似ている．従って，支持グラフ抽出ルーチンを実装するときにはこれらのルーチンを基にすればよい．</subsection>
  <subsection title="グラフィカルEMアルゴリズム">提案手法によるPCFG訓練のメインルーチンLearn-PCFGは図~のようになる．2つのサブルーチンCYK-ParserとExtract-CYKは先に説明した．本節ではgEMアルゴリズムを実現する手続きGraphical-EMを記述する．I-Oアルゴリズムと同様，gEMアルゴリズムでも内側・外側確率という2つの確率値の計算が中心になる．各O_の内側確率，外側確率の値は[,],[,]という配列変数に格納される．これは各部分支持グラフ_()=,_()によって保持される．また，_()は各局所パスE_()ごとに配列変数[,,E]をもつ．また，配列変数[A]に規則Aの期待適用回数が格納される．Graphical-EMは内側確率を計算するGet-Inside-Probs,外側確率と規則の期待適用回数を同時に計算するGet-Expectationsという2つのサブルーチンをもつ．Graphical-EMを図~に示す．Graphical-EMでは，はじめにすべてのパラメタを初期化する（行~）．そして，Get-Inside-Probs,Get-Expectations,パラメタの更新（行~--）をこの順に繰り返す．対数尤度が収束したら（行~），その時点でのパラメタ値を推定値^として終了する．[,S(0,n_)]に文_の生起確率P(_)が格納されており，対数尤度の計算にはこの値を使う（行~,~）．図~にサブルーチンGet-Inside-Probs,Get-Expectationsを示す．また，図~は支持グラフ上における各々の計算イメージである．Get-Inside-Probsにおける内側確率[,]の計算はO_の最後尾の部分支持グラフから順に行なう．_kの部分支持グラフ	_(_k)=_k,_(_k)(k=1|O_|)の各局所パスE_(_k)ではパス中の各ノードの確率積を計算し，[,_k,E]に格納する（行~--,図~(1)）．その際，基本ノードAに対してパラメタ(A)を乗じ，中間ノード'に対して内側確率[,']を乗じるとおくと必ずk&lt;k'であることと，の計算はO_の最後尾から順に行なわれることから，[,']は参照されるとき既に計算済みになっている点に注意する．（図~(2)）．最後に[,_k,E]の和によって[_k]を計算する（行~,図~(3)）．一方，Get-ExpectationsではGet-Inside-Probsとは逆にO_の先頭の部分支持グラフから順に計算を進める．はじめに配列変数とを初期化する．特に外側確率[,]についてO_の先頭要素_1=S(0,n_)のみを1,他は0にする点に注意する（行~--）．次に，あるk=1|O_|について_kの部分支持グラフ_(_k)の局所パスEを考える（行~）．更に，行~で外側確率が書き換えられる'Eを考える．また，行~の式で[,']に加算されるのは，Eにおける'の局所的な外側確率（パスEに現れる'以外のノードの確率積）と'の親部分木_kの外側確率[,_k]の積であるとおくと，支持グラフの3つ目の特徴より必ずk&lt;k'が成り立つので，'はO_では常に_kより後ろに現れる．逆にいえばk''=k|O_|なる部分支持グラフ_(_k'')では[,_k]の値は書き換えられることはなく，従って行~の式の右辺に現れる[,_k]は既に計算済みである．（図~(4)）．また，行~において，基本ノードAに対しては局所パスの確率[,_k,E]と親部分木_kの外側確率[,_k]の積を文_の生起確率P(_)で割って行~のように，すべての=1NについてP(_|)&gt;0となるに初期化しているので，以降の更新が行なわれてもP(_|)=0となることはない．この事実は，gEMアルゴリズムにおける[r]の更新値とFujisakiらの方法（式~）における[r]の更新値が等しいと仮定したとき（これは付録~で直観的に証明される），以下のように帰納的に証明される:まずm回目の更新後のパラメタ^(m)の下でP(_|^(m))&gt;0が成り立つとする．すると，ある(_)に対してP(|^(m))&gt;0が成り立つ．そしてこのに出現する任意の規則rについて，(r,)&gt;0が成り立つことと式~より，^(m)の下で[r]&gt;0となる．するとGraphical-EM行~により更新後のパラメータ^(m+1)(r)&gt;0が保たれる．従って同じに対してP(|^(m+1))&gt;0が成り立ち，これよりP(_|^(m+1))&gt;0もまた成り立つ．以上でP(_|^(m))&gt;0P(_|^(m+1))&gt;0が言えたので，パラメタをP(_|^(0))&gt;0なる^(0)に初期化すれば，以降の更新m=1,2,では必ずP(_|^(m))&gt;0である．（証明終）また，P(_|)&gt;0とするために，現実的にはすべての規則rRについて(r)&gt;0となるを選べば十分である．[A]に足し込む（図~(5)）．こうして[A]の内容を書き換えていくと，Get-Expectationsの終了時には[A]にAの期待適用回数が格納されている．gEMアルゴリズムの計算は支持グラフの1つ目の特徴である支持グラフ_の再帰的巡回（節~）に基づいて正当化される．それを付録~で示す．一般に，EMアルゴリズムは尤度関数の山登りを行なうため局所的な最尤推定しか保証しない．従って訓練されたパラメタの質は初期パラメタ値に依存する．LariとYoungはHMMを利用して初期パラメタ値を与える方法を提案している~．最も簡便な解決法としては，初期パラメタをランダムに設定することとEMアルゴリズムを動作させることをh回繰り返し，その中で収束時の対数尤度が最も高かった回の収束パラメタ値を訓練パラメタ値とする．この方法を以降では簡単に再出発法と呼ぶ．</subsection>
  <subsection title="予測構文木の計算">いったんパラメタ^が訓練されたら，括弧なしであるテストコーパスの各文_に対して^_	_all;P(|_)=	_all;P(,_)=	_(_)P()なる^_を計算することができる．^_に対応する構文木t^_を予測構文木（以下，単に予測木）という．この予測木t^_によって入力文_に対する構文的曖昧性が解消される．ただし，|(_)|は指数オーダなので，ここでも支持グラフに基づいてt^_を計算する．予測木t^_を計算する手続きPredictおよびそのサブルーチンConstruct-Treeを図~に示す．Predictはテストコーパス=_1,_2,,_Nを受けとり，各_に対する予測木中の部分木ラベルの集合(t^_)を^_に格納する．Predictでは，はじめにパーザ，支持グラフ抽出ルーチン，内側確率計算ルーチンGet-Inside-Probsの3つを走らせる（行~）．次に，Get-Inside-Probsが計算した確率値[,,E]を参照しながら，[,]に最も確率の高いの局所パスを記録する（行~）．再帰手続きConstruct-Treeでは，支持グラフ_の再帰的巡回に基づき，[,]中のラベルA(d,d')を^_に追加する（行~）ことで予測木を構築する．[,]に複数の局所パス候補を格納するように拡張すれば，生起確率上位n個の予測木が獲得できる．</subsection>
  <subsection title="計算量">節~のI-Oアルゴリズムの計算量評価で述べたように，収束までのパラメタ更新回数は初期値に依存するため，1回のパラメタ更新に要する計算量をgEMアルゴリズムの計算量とする．手続きGraphical-EMではrepeatループ内の計算量をはかればよい．まず，各=1NについてO_=_1^(),	_2^(),,^()_|O_|とおく．Graphical-EMに呼び出されるGet-Inside-Probsはその内部処理においてk=1|O_|について|_(_k^())|の要素を一回ずつ訪れることから，_num&amp;&amp;	_=1N		_k=1^|O_||_(_k^())|	_maxsize&amp;&amp;	_E:;=1N,;k=1|O_|,;			E_(_k^())		|E|	eqnarrayを導入すると，手続きGet-Inside-Probsの計算量はO(_num_maxsizeN)である．同様に手続きGet-ExpectationsにおいてもO(_num_maxsizeN)の計算量を要する．I-Oアルゴリズムの計算量評価と同様，訓練コーパスに対して最長の文の長さをLとし，非終端記号集合,終端記号集合を固定する．我々はChomsky標準形を満たす文法に対する最悪計算量を考える．そのために，まずChomsky標準形を満たす最大のPCFGとして節~式~で導入した規則集合を考える．このとき，A,0d,d'L,d+2d'なるA,d,d'について下が成り立つ（d'=d+1の場合は無視できる）：|O_|=|A(d,d')A,;0d&lt;d'L|=O(||L^2)かつ|_()|=O(||^2L)が成り立ち，定義より_num=O(||^3L^3)となる．同様に定義より_maxsize=3=O(1)である．また，(A)の更新に要する計算量はO(||)だが，||=O(||^3)なので無視できる．以上より手続きGraphical-EMのrepeatループ内の計算量はO(||^3L^3N)である．以上よりgEMアルゴリズムの最悪計算量はI-Oアルゴリズムと同じO(||^3L^3N)である．Chomsky標準形を仮定したとき，CYKパーザCYK-Parserと支持グラフ抽出ルーチンExtract-CYKの最悪計算量はEMの一更新ステップの最悪計算量と同じO(||^3L^3N)である．ただ，EMアルゴリズムでは更新ステップを数10から数100回繰り返すのが通常なのでExtract-CYKが訓練全体に占める割合は小さい．同様にChomsky標準形を仮定したとき，一つの文に対する生起確率計算，予測木の計算いずれの計算量もO(||^3L^3)である(N=1)．また，式~の形をした部分木の親子対を構成要素とするWFSTをもつパーザ（例えばCYKやGLR）では，抽出されるO_,_は全く同じになるので，提案手法の計算量は組み合わせたパーザによる差はない．Earleyパーザを用いた場合に関する評価は付録~に示す．</subsection>
  <section title="訓練時間に関する実験">我々は現実的な文法に対してはI-Oアルゴリズムに比べてEM学習が大幅に高速化される（提案手法の特長2）ことを示すため，ATR対話コーパス(SLDB)でパラメタ推定に要する計算時間（訓練時間と呼ぶ）を計測した．対象PCFGの元になるCFGは860規則から成る，田中らが開発した音声認識用日本語文法~に手が加えられたものである．以降ではこのCFGをで参照する．ATR対話コーパスもこの文法に対応して手が加えられている．は品詞を細分化したカテゴリを終端記号としたCFGであり，非終端記号数173,終端記号数441である．ATR対話コーパス中の文では，（実際の単語ではなく）上記カテゴリの列を対象とした．文長は平均9.97,最短2,最長49である．また，の規則集合はChomsky標準形ではないので，GLRパーザとの組合せを採用した．本論文の実験ではが与えられた場合の訓練時間を提案手法とI-Oアルゴリズムの間で比較する．ただし，I-Oアルゴリズムにおいては節~で記述したものを用い，そこで参照される規則集合Rには，全ての終端・非終端記号の組合せから成るChomsky標準形の規則集合ではなく，の規則集合を用いる点に注意する．我々は文長Lを変化させたときにパラメタを一回更新するのに要する計算時間（更新時間と呼ぶ）が変化する様子を比較する．まず，我々はATRコーパスの中で文長L-1とLの文をグループ化し，各々から無作為に取り出した100文を_Lとする(L=2,4,26)．そして，各_Lを一つの訓練コーパスとし，各々に対して更新時間を計測する．I-OアルゴリズムはChomsky標準形でしか動作しないので，あらかじめをChomsky標準形に変換した．その結果860規則が2,308規則（非終端記号数210,終端記号数441）の文法になった．更新時間を計測した結果を図~左に示す．縦軸が更新時間(sec)，横軸Lが使用した訓練コーパス_Lを表す．``Inside-Outside''はI-Oアルゴリズムの更新時間，``IOwithpruning''はで説明されている，I-Oアルゴリズムの外側確率の計算において無駄な計算部分を枝刈りするように改良したものである．これを以下では枝刈り版I-Oアルゴリズムと呼ぶ．``GraphicalEM''はgEMアルゴリズムの更新時間を示す．また，変化の様子を見やすくするために，図~左の縦軸を拡大，縮小したものをそれぞれ図~中央，図~右に示す．図~中央においてgEMアルゴリズムの更新時間は見にくいため省略した．図~左のグラフから分かるように，gEMアルゴリズムはI-Oアルゴリズムやその枝刈り版に比べてはるかに高速な計算が行なわれていることが分かる．また，図~中央のグラフから分かるようにI-Oアルゴリズムは理論値どおりL^3の曲線を描く．枝刈り版I-Oアルゴリズムは枝刈りした分高速であるものの，仮説駆動型である（LLの三角行列の全要素を走査する）点は変わらないので，枝刈りが最も効率良く行なわれた場合でもL^2を下回ることはない．収束まで数100回の更新を要すること，および再出発法を採用することを考慮すると，L=20を越える訓練コーパス_Lに対してI-Oアルゴリズムおよびその枝刈り版を収束するまで動作させるのは現実的ではない．それに対し，提案手法ではL=2,4,,26の範囲ではLに対してほぼ線形に計算できており（図~右），最悪計算量O(||^3L^3)とは大きな差があることが分かった．これは文法の制約により，WFSTに格納される部分木の数が抑えられたためと考えられる．ATRコーパスにおける文長平均9.97に近いL=10ではI-Oアルゴリズムに対しておよそ1,000倍（枝刈り版に対してはおよそ700倍）の速度向上が得られた．良質なパラメタを得る目的で再出発法（節~）を採用すると，訓練時間の内訳は()&amp;=&amp;	()+()	&amp;&amp;+;(),()&amp;=&amp;()()		().eqnarray*となる．先に述べた文長毎の訓練コーパス_L(L=2,4,,26)を使って，訓練時間の内訳（構文解析時間，支持グラフ抽出時間，gEM実行時間）を計測した．その結果を図~に示す．横軸がL,縦軸が処理時間(sec)である．図~（左）は再出発なし(h=1)の場合，図~（右）は再出発回数h=10の場合である．また，収束までの更新回数はコーパス_Lによって異なるため，ここでは100に固定した．構文解析時間(``Parsing'')，支持グラフ抽出時間(``Supportgraph'')，gEM実行時間(``GraphicalEM'')はいずれも文長Lに対してほぼ線形になっていることが分かる．更に図~（右）より，再出発法を採用した場合は構文解析時間と支持グラフ抽出時間が訓練時間全体に占める割合は非常に小さい．構文解析と支持グラフ抽出は再出発の度に繰り返す必要がないからである．構文解析と支持グラフ抽出をgEMアルゴリズムの前処理と捉えれば，わずかな前処理（図~）で大きな速度向上（図~）が得られているということができ，構文解析とEM学習を分離したメリットが現れている．</section>
  <section title="PCFGの拡張文法のEM学習">これまでPCFGに文脈依存性を採り入れたモデル（PCFGの拡張文法と呼ぶ）が数多く提案されているが，Charniakらの疑似確率文脈依存文法(pseudoprobabilisticcontext-sensitivegrammars)を除けばEMアルゴリズムを具体的に記述した文献は見当たらない．本節では，提案手法がPCFGの拡張文法に対する多項式オーダのEMアルゴリズムを包含する（提案手法の特長3）ことを示すため，一例としてKitaらの規則バイグラムモデルを取り上げ，その多項式オーダのEMアルゴリズムを導出する．</section>
  <subsection title="規則バイグラムモデルとそのEMアルゴリズム">まず，我々はPCFGのときと同様に導出戦略は最左導出に固定する．規則バイグラムモデルでは，節~で述べたPCFGの「規則選択は他と独立」という仮定の代わりに，「規則選択は直前の選択のみに依存する」という仮定をおく．従って，規則バイグラムモデルではPCFGでは扱えなかった文脈依存性も若干考慮できる．この仮定の下で適用規則列の出現確率はと計算される．#は境界を表すマーカ，(rr')は各規則rRに付与されるパラメタである(r'R#)．各A,rR#に対し_:(A)R(Ar)=1が成り立つ．で示された，括弧なしコーパス=_1,,_Nに基づく(r_k|r_k-1)の推定式は式~のとおりである．適用規則列に対して，(r,r';)はにおいてr'がrの直後に出現する頻度を表す．定義より明らかに_r'R(r,r';)=(r;)が成り立つ．ところが式~,~から類推できるように，EMアルゴリズムの考えに基づく更新式は次のようになる(m=1,2,)．つまり式~は相対頻度法，EMアルゴリズムのいずれにもなっていない．&amp;&amp;	^(m+1)(r_k|r_k-1):=	&amp;&amp;(					_=1^N							_(_)					P(|^(m))(r_k-1,r_k;)			P(_|^(m))			)	/	(			_=1^N							_(_)					P(|^(m))					(r_k-1;)			P(_|^(m))		)	.eqnarray式~の更新式により（局所）最尤推定は実現されるが，これまで述べてきたように一般に|()|は文長||に対して指数オーダになるため，式~は現実時間で計算できない．一方，提案手法に基づき，式~と等価な規則バイグラムモデルの多項式オーダのEMアルゴリズムを導出することができる．次節でアルゴリズムを記述するが，その前にいくつかの記号を導入する．まず，次のような文の最左導出列を考える:を考える．式~においてrはAを展開する直前に適用された規則，r'は導出A_d,d'で用いられた最後の規則である．rとr'を考慮した，_d,d'を統治する部分木ラベルをA(d,d'|r,r')で表す．また，式~においてr'を(A,d,d';)で参照し，rの次に適用された規則r''をArで参照する．前節で述べた(A|r)の確率でArが適用される．また，の構文木中の部分木A(d,d')を導出するとき最後に使われた規則の集合を(A,d,d';)	_()(A,d,d';)と定める．</subsection>
  <subsection title="グラフィカルEMアルゴリズムの適用">ここではCYKパーザと組み合わせた場合の規則バイグラムモデルのEM学習法を示す．規則バイグラムモデルを対象にする場合，パーザに新たな変更を加える必要はない．また，gEMアルゴリズムもその汎用性により，対象とする確率値の意味が変わるだけで制御構造に変化はない．従って，我々は支持グラフ抽出ルーチンを変更するだけである．例えば，図~のt2にでは次のような関係_が得られる．[]節~で示したPCFGの場合に比べて，部分木ラベルA(d,d')が，その導出直前に適用された規則と自身の導出において最後に適用された規則の組（``''記号の後ろ）によって細分化されており，この細分化によって文脈依存性が表現される．規則バイグラム用の支持グラフ抽出ルーチンExtract-CYK-RBとそのサブルーチンVisit-CYK-RBをそれぞれ図~,図~に示す．Visit-CYK-RB(,r,A,d,d')は_の構文木中の部分木A(d,d')を訪問し，大域的配列変数[A(d,d')]に(A,d,d';_)を格納する再帰手続きである．後はgEMアルゴリズム（手続きGraphical-EM,Get-Inside-Probs,Get-Expectations）においてA,(A),[A]を各々Ar,(A|r),[A|r]といった規則バイグラム用の確率値，期待値に書き換え，Graphical-EM行~--とGet-Expectations行~のforeachループに``foreachrR''ループを重ねるだけでよい．次に，規則バイグラム用EMアルゴリズムの最悪計算量を評価する．を考えたとき，最悪計算量はO(||^12L^3N)となるBCr,;B(d,d''|ABC,r''),;C(d'',d'|r'',r')			;|		.	]となるようなA(d,d'|r,r')がO_中に出現する(=1N)．|_()|=O(||^2L|R|)であるのは明らかである．また，O_はA(d,d'|r,r');|;	A,;0d&lt;d'L,;r,r'Rの部分集合を並べたものであるから，|O_|=O(||L^2|R|^2)となる．定義より_num=O(||^3L^3|R|^3),_maxsize=O(1)であり，さらに最悪の場合R=を考えるとgEMアルゴリズムの計算量はO(||^3L^3||^3N)=O(||^12L^3N)となる．．これは非常に大きなオーダであるが，文長Lに対して3乗のオーダである点はI-Oアルゴリズムと変わらない．また，節~の実験結果はPCFGに対する現実の計算時間と最悪時の計算時間O(||^3L^3)に大きな差があることを示しており，これは規則バイグラムモデルでも成り立つと考えられる．実際森らは，節~の実験で用いたCFGに対し本節で述べた方法を適用した結果，規則バイグラムのEM学習におけるパラメタ更新時間がPCFG（図~右）の1.5倍程度で収まることを報告している．</subsection>
  <section title="関連研究">まず，MagermanらのPearlおよびその後継であるPicky,またStolckeの確率的Earleyパーザをはじめ，確率的パーザが多く提案されている．しかし，それらの多くは文法構造Gとパラメタが与えられていることを前提としており，Stolckeを除けばPCFG（もしくはその拡張文法）のEM学習について具体的に記述しているものは少ない．Chomsky標準形でないPCFGの訓練法としては，Kupiecの方法~と先述のStolckeの確率的Earleyパーザによる訓練が挙げられる．Kupiecの方法はPCFGを再帰遷移ネットワークと捉え，拡張したtrellis図に基づき訓練を行なうものである．しかし，仮説駆動型である点はI-Oアルゴリズムと変わらない．また，提案手法で用いるWFSTは，CFGに基づく構文解析にとって本質的なデータ構造であることから，本手法はtrellis図に基づくの方法よりも簡潔で理解しやすいものと考える．一方，規則やサイクルAAが存在しないに対して，Stolckeの方法は我々の枠組でEarleyパーザとアルゴリズムを組み合わせた場合と等価である．すなわち，このようなPCFGに対して我々の枠組はStolckeの方法の一般化になっている．Stolckeの方法との対応づけを付録~に示す．また，StolckeはPCFGの拡張文法については言及していない．規則やサイクルAAをもつPCFGに対する訓練法を考えるのは今後の課題であるが，提案手法は現段階においても充分実用的である．PerairaとSchabesは部分もしくは完全括弧コーパスからPCFGの文法構造を学習する方法を提案し，学習された文法構造とパラメタの質が括弧なしコーパスからの学習に比べ大きく向上することを実験的に示した~．我々の枠組でも，括弧づけされた文に対し，括弧の制約を満たす構文木のみを出力する機能をもつパーザを用意すれば，支持グラフ抽出ルーチン，gEMアルゴリズムに何の変更も加えることなく括弧つきコーパスからの訓練が可能になる．変更の必要がないのは，我々が最終的な構文木情報（すなわちWFST）のみを参照するためである．また，完全に括弧づけされた訓練コーパスに対しアルゴリズムの計算量はPereiraとSchabesの方法と同じオーダO(||^3LN)であることも容易に分かる|	=O(|||_|)=O(||L)である．また，式~において，(_)に一致するd'は高々1つであるから，すべての=1Nについて|_(A(d,d'))|=O(||^2)である．従って，式~より_num=O(||^3L)である．前の議論と同様に_maxsize=O(1)であるから，gEMアルゴリズムにおいて一回のパラメタ更新に要する計算量はO(||^3LN)である．．本論文の手法は文法構造(CFG)が与えられていることを前提としているが，人間が精密な文法を記述するのに多くの手間を費やすことを考えると，文法構造の自動学習は重要な課題である．先述したように，LariとYoungは非終端記号集合と終端記号集合をあらかじめ定めた上で先述した(,)を考え，I-Oアルゴリズムを走らせ，推定後にパラメタ値が小さい規則を除去する方法を提案した~．また，先述したPereira&amp;Schabesの学習法~も括弧づけコーパスからの文法学習と捉えることができる．しかし，一般にEMアルゴリズムは局所的な最尤推定値しか保証しないため，学習される文法の質はパラメタの初期値に大きく依存し，文法学習を困難にしている．それに対し，HMMでは逐次状態分割(SSS)法~やモデル選択規準に基づくHMMの構造探索法~のように，パラメタ訓練と構造探索を分離し，これらを交互に繰り返して良質なモデル構造を得る方法が提案されている．どちらの手法もパラメタ訓練ステップではモデル（文法）構造が与えられるので，上記手法をPCFGの構造学習に一般化したとき，本論文で示した高速化が有効に働くものと期待する．本論文で示したgEMアルゴリズムは最小モデル意味論の確率的一般化である分布意味論~に基づく確率的な論理プログラミング言語PRISM~における高速EM学習のために提案されたものである~．そこではOLDT探索~とgEMアルゴリズムを連結するが，本論文の手法はPCFGおよびその拡張文法用にをパーザに置き換えて特殊化を図ったものである．OLDT探索を構文解析に用いることも可能だが，OLDT探索はトップダウン（仮説駆動）探索であるので，LR表へのコンパイル・ボトムアップ探索を利用するGLRパーザの方が現実文法ではより高速である．得られる支持グラフはまったく同じなのでgEMアルゴリズムの計算時間は変わらない．</section>
  <section title="まとめ">文法構造が与えられていることを前提に，確率文脈自由文法(PCFG)を括弧なしコーパスから訓練するための一般的な枠組を提案し，従来法であるInside-Outsideアルゴリズムの一般化と（現実文法における）高速化を同時に実現した．提案手法ではPCFGの訓練過程を構文解析とEM学習を分離し，パーザが記録するWFSTから訓練文と関係のある部分木構造のみを抽出してからEM学習することにより，仮説駆動型であった-Outsideアルゴリズムの計算効率上の欠点を克服した．また，従来知られてきた構文解析の高速化技術がPCFGの訓練にそのまま反映される．更に，提案手法を実装し，ATR対話コーパスにおける訓練時間を計測したところ，Inside-Outsideアルゴリズムに比べコーパス平均文長においておよそ1,000倍の速度向上が得られることを確認した．また，提案手法の一般性に基づき，文脈依存性を考慮したPCFGの拡張文法（北らの規則バイグラムモデル）の多項式オーダのEMアルゴリズムを導出した．加えて，確率EarleyパーザによるStolckeのEM学習法やPereiraとSchabesらによる部分括弧つきコーパスからの学習法も提案手法の枠組で扱えることを示し，提案手法がCFGに基づく確率言語モデルの訓練手法を広くカバーしていることを明らかにした．今後の課題としては，PCFGの拡張文法を用いた実験や文法構造の学習，また支持グラフとgEMアルゴリズムの一般性を利用して，Inuiらによって再定式化された確率GLRモデル~の効率的なEMアルゴリズムの導出を試みるのも興味深い．</section>
  <section title="グラフィカルEMアルゴリズムの正当化">本節ではFujisakiらの方法，I-Oアルゴリズム，gEMアルゴリズムに同じ初期パラメタを与えたとき，収束条件を同一にすればパラメタが同一の値に収束することを示す．これによりgEMアルゴリズムが正当化される．具体的にはgEMアルゴリズムが計算する[A],すなわち規則(A)Rの期待適用回数がFujisakiらの方法，およびI-Oアルゴリズムで得られるものと一致することを示せばよい．また，節~で見たように，Fujisakiらの方法とI-Oアルゴリズムが計算する[A]は一致するので，ここではFujisakiらの方法とgEMアルゴリズムで計算される[A]を調べれば十分である．はじめに，我々はgEMアルゴリズムの計算は支持グラフの1つ目の特徴である支持グラフ_の再帰的巡回を考える．そして，以下ではの部分支持グラフの開始（終了）ノードを「の開始（終了）ノード」と呼ぶことにする．節~で述べたように，我々は巡回中に基本ノードに付与されている規則を集めることにする．まず，_中に出現するAが付与された基本ノードの一つvに注目する．vはの部分支持グラフに含まれているとし，vが属する局所パスをEとおく．その状況を図~に示す．そして，S(0,n_)の開始ノードから出発してvを通過するような再帰的巡回を全通り行ない，そこで集められた規則列の集合を(v,_)とおく（明らかに(v,_)(_)である）．の開始ノードからEに沿っての終了ノードに至る巡回によって得られる部分規則列を_1とおく．またO_の先頭であるS(0,n_)の開始ノードから出発し，が付与された中間ノードu（図~）に至る巡回，およびuからS(0,n_)の終了ノードに至る巡回によって得られた部分規則列をそれぞれ_0,_2とおく．そして，このような_1すべてから成る集合を(v,_)とおき，可能な_0,_2の組_0,_2から成る集合を(v,_)とする．すると，先に定義した(v,_)は(v,_)と(v,_)の直積と同一視できる．以上の定義と，PCFGにおける規則適用に関する独立性の仮定より，_'(v,_)P(')&amp;=&amp;__0,_1,_2(v,_)P(_0,_1,_2)&amp;=&amp;__1(v,_)__0,_2(v,_)P(_1)P(_0,_2)&amp;=&amp;(__1(v,_)P(_1))(__0,_2(v,_)P(_0,_2))eqnarray*が成り立つ．手続きGet-Inside-Probsにおけるとの計算を再帰的に追えば，手続き終了時に[,,E]=__1(v,_)P(_1)となることは明らか．また，手続きGet-Expectationsのの計算を追えば，[,]=__0,_2(v,_)P(_0,_2)であることが分かる．よって[,][,,E]=_'(v,_)P(')となる．これよりGet-Expectations行~で[A]に足し込まれる値は1P(_)_'(v,_)P(')に等しい．Aが付与された他の基本ノードについても同じ作業が行なわれ，さらにこれを=1Nで繰り返すので，最終的に[A]は次のように計算される：ところで，S(0,n_)の開始ノードから出発する一つの再帰的巡回を考え，そこで集められた規則列をとする．そのとき，この巡回においてAが付与された基本ノードを通過する回数は(A,)である．従ってこの(_)について，和_v:;A;is;attached;_'(v,_)ではが(A,)回重複して数え上げられている．よって式~はFujisakiらの計算式（式~）と同値になる．以上と本節冒頭に述べた注意より，Fujisakiらの方法，I-Oアルゴリズム，gEMアルゴリズムに同じ初期パラメタを与えたとき，収束条件を同一にすればパラメタは同じ値に収束する．</section>
  <section title="Stolcke の方法との対応">本節ではStolckeが提案した確率的Earleyパーザを用いるPCFGの訓練法~と提案手法においてEarleyパーザとgEMアルゴリズムを組み合わせた場合を簡単に対応づける．はじめに確率的Earleyパーザを簡単に記述する．</section>
  <subsection title="確率的 Earley パーザ">Earleyパーザは入力文_の各単語位置をアイテム集合（Earleyチャート）I_に基づいて構文解析を行なう．各アイテムは``d'dA.''の形をしており，(i)現在のポインタの位置がd'（_0,d'^()=w_1^()w_d'^()が解析済み）であること，(ii)非終端記号Aが統治する部分単語列が位置dから始まること，(iii)Aの展開は規則Aを用いて進められ，ドットの場所まで展開されていること，を表す．確率的Earleyパーザでは，Earleyパーザに確率的な拡張が施されており，各アイテムに内側確率d'dA.が式~のように付与される（式中のはd'dA.の略記）．内側確率d'dA.はアイテムddA.から始まり，d'dA.に至る経路の確率和である．内側確率は次の3つの操作に従って計算される．EM学習においては更にアイテムd'dA.の外側確率d'dA.を考慮する．この確率は(i)初期アイテム00.Sから出発し，(ii)_0,d^()を生成し，(iii)あるについて_dA.を通り，(iv)_d'A.から出発して_d',n_^()を生成し，(v)最終アイテムn_0S.で終わるような経路の確率和である．ただし，アイテムn_0S.のみ:=1と初期化し，それ以外は:=0としておく．すべての内側確率と外側確率を計算し終ったら，規則Aの期待適用回数を次のように求め，後はI-Oアルゴリズムの式~と同様にパラメタを更新する．</subsection>
  <subsection title="対応する支持グラフ">図~のメインルーチンLearn-PCFGにおける支持グラフ抽出ルーチンExtract-CYKをEarleyパーザ用の支持グラフ抽出ルーチンExtract-Earley（図~）に置き換える．そのサブルーチンVisit-Earleyを図~に示す．gEMアルゴリズムは汎用であるため，手続きを特に変更する必要はない．Extract-EarleyはEarleyパーザの構文木出力ルーチンに基づいて記述されており，支持グラフ_=O_,_を生成する．_は次のような形をしている．_(ddB.)&amp;=&amp;B	_(d'dAw_d'^().)&amp;=&amp;			(d'-1)dA.w_d'^()	_(d'dAB.)&amp;=&amp;															(d''dA.B),;						(d'd''B.)							&amp;&amp;|;					dd''&lt;d',					(d'd''B.)I_					eqnarray式~の部分支持グラフに対するgEMアルゴリズムの内側確率の計算が確率的EarleyパーザのPrediction操作に対応する．同様に式~に対するgEMアルゴリズムの内側確率計算がScanning操作に対応する．さらに，式~に対するgEMアルゴリズムの内側確率計算がCompletionに，外側確率計算がReversecompletion操作に各々対応する．そして，式~の部分支持グラフでの期待値計算が式~に対応する．この場合のgEMアルゴリズムの計算量としては，式~の形の_をもつ部分支持グラフに対する部分が効いてくる．Chomsky標準形を満たす文法に対しては，このような部分支持グラフのノード数は可能な規則および単語位置d,d',d''の組合せ数O(|R|L^3)となる（Rは規則集合，Lはコーパス中の最大文長）．R=のときgEMアルゴリズムの最悪計算量はStolckeの確率的Earleyパーザのものと同じくO(||^3L^3)となる．また，Chomsky標準形を満たさない場合を考え，規則右辺の最大記号数をmとおく．提案手法において，式~のような部分木の親子対を構成要素とするWFSTをもつパーザ（GLRなど）を用いた場合の計算量はO(L^m+1)となるが，Earleyパーザを用いた場合の計算量はの確率的Earleyパーザと同じく，mによらずO(L^3)になる．ただ，GLRはLR表への事前コンパイル・ボトムアップ計算等の好ましい性質を持っており，対象とする文法の特徴に応じてパーザを使い分けることが重要と思われる．document</subsection>
</root>
