<?xml version="1.0" ?>
<root>
  <title/>
  <author>パウルミヒャエル隅田英一郎</author>
  <jkeywords>照応解析,機械学習,優先度</jkeywords>
  <jabstract/>
  <section title="">*AcknowledgmentTheauthorswouldliketothankKadogawa-ShotenforprovidinguswithRuigo-Shin-Jiten.document</section>
  <section title="Introduction">CoreferenceinformationisrelevantfornumerousNLPsystems.Ourinterestinanaphoraresolutionisbasedonthedemandformachinetranslationsystemstobeabletotranslateanaphoricexpressionsinagreementwiththemorphosyntacticcharacteristicsofthereferredobjectinordertopreventcontextualmisinterpretations.Sofarvariousapproachestoanaphoraresolutionhavebeenproposed.Inthispaperamachinelearningapproach(decisiontree)iscombinedwithapreferenceselectionmethodbasedonthefrequencyinformationofnon-/coreferentialpairstaggedinthecorpusaswellascountinganddistancefeatureswithinthecurrentdiscourse.Theadvantageofmachinelearningapproachesisthattheyresultinmodularanaphoraresolutionsystemsautomaticallytrainablefromacorpuswithnooronlyaminimalamountofhumanintervention.Inthecaseofdecisiontrees,wedohavetoprovideinformationaboutpossibleantecedentindicators(syntactic,semantic,andpragmaticfeatures)containedinthecorpus,buttherelevanceoffeaturesfortheresolutiontaskisextractedautomaticallyfromthetrainingdata.Themachinelearningapproachesusingdecisiontreesproposedsofarhavefocusedonpreferenceselectioncriteriadirectlyderivedfromthedecisiontreeresults.Theworkdescribedinutilizedadecisiontreecapableofjudgingwhichoneoftwogivenanaphor-antecedentpairsis``better''.Duetothelackofastrongassumptionon``transitivity'',however,thissortingalgorithmismorelikeagreedyheuristicsearchasitmaybeunabletofindthe``best''solution.Thepreferenceselectionforasingleantecedentinisbasedonthemaximizationofconfidencevaluesreturnedfromapruneddecisiontreeforgivenanaphor-candidatepairs.However,relationsbetweensingleattributescannotbeobtainedautomaticallywithinthedecisiontreelearningphase.Moreover,theseconfidencevaluesdonottakeintoaccountanycontextualinformationfromthediscoursethedecisiontreeisappliedto.Thepreferenceselectioninourapproachisbasedonthecombinationofstatisticalfrequencyinformationaswellasdistanceandcountingfeaturesinthediscourse.Therefore,ourdecisiontreeisnotapplieddirectlytothetaskofpreferenceselection,butaimsattheeliminationofirrelevantcandidatesbasedontheknowledgeobtainedfromthetrainingdata.Thedecisiontreeistrainedonsyntactic(lexicalwordattributes),semantic,andprimitivediscourse(distance,countingfeatures)informationanddeterminesthecoreferentialrelationbetweenananaphorandantecedentcandidatesinthegivencontext.Irrelevantantecedentcandidatesarefilteredout,achievinganoisereductionforthepreferenceselectionalgorithm.Apreferencevalueisassignedtoeachpotentialanaphor-candidatepairdependingontheproportionofnon-/coreferentialoccurrencesofthepairinthetrainingcorpus(frequencyratio),therelativepositionofbothelementsinthediscourse(distance),andthenumberofpreviousoccurrencesinthediscourse(count).Thecandidatewiththemaximalpreferencevalueisresolvedastheantecedentoftheanaphoricexpression.</section>
  <section title="Corpus-based anaphora resolution">Inthissectionweintroduceanewapproachtoanaphoraresolutionbasedoncoreferentialpropertiesautomaticallyextractedfromatrainingcorpus.Thecorrectantecedentsofanaphoricexpressions(A)aretaggedinourannotatedcorpus.Antecedentcandidates(C)areallnounsprecedingtheanaphoridentifiedaccordingtopart-of-speechtags.Inthefirststep,thedecisiontreefilteristrainedonthelinguistic,discourse,andcoreferenceinformationannotatedinthetrainingcorpus,whichisdescribedinSection~.TheresolutionsysteminFigure~appliesthecoreferencefilter(cf.Section~)toallanaphor-candidatepairs(A_i+C_ij)foundinthehistory.Thereducedset(A_i+C_ik)consistsofallpotentialcandidatesandformstheinputofthepreferencealgorithm,whichselectsthemostsalientanaphor-candidatepair(A_i+C_ip)asdescribedinSection~.PreliminaryexperimentsareconductedandtheperformanceofoursystemisevaluatedinSection~.[-0.5em]</section>
  <subsection title="Tagged corpus">Forourexperimentsweuse500Japanesespoken-languagedialoguesannotatedwithcoreferentialtagsoutoftheATR-ITLSpeechandLanguageDatabase.Theyinclude1745pronominalannotations,wherebytheanaphoricexpressionsusedinourexperimentsarelimitedtothosereferringtonominalantecedents.Besidestheanaphortype,wealsoincludemorphosyntacticinformationlikestemformandinflectionattributesforeachsurfacewordaswellassemanticcodesforcontentwordsinthiscorpus.Intheexampledialoguebetweenahotelreceptionist(r)andacustomer(c)listedinFigure~,anaphoraaremarkedwithabox,whereasallunderlinednounsprecedingtherespectiveanaphorformthelistofpossiblecandidates.Thepropernoun(r1)``シティホテル[CityHotel]''istaggedastheantecedentofthepronoun(c1)``そちら[there]''.Accordingtothetaggingguidelinesusedforourcorpus,ananaphorictagreferstothemostrecentantecedentfoundinthedialogue.However,thisantecedentmightalsorefertoapreviousone,e.g.,(r3)``こちら[here]''refersto(c1)''そちら[there]'',whichrefersto(r1)''シティホテル[CityHotel]''.Thus,thetransitiveclosurebetweentheanaphoraandthefirstmentionoftheantecedentinthehistorydefinesthesetofpositiveexamples,whereasthenominalcandidatesoutsidethetransitiveclosureareconsiderednegativeexamplesforcoreferentialrelationships.Inourexamplethesetsconsistofthefollowingexamples.Thedifficultyofourresolutiontaskcanbeverifiedaccordingtotheaveragenumberofantecedentcandidates,i.e.thesumofpositiveandnegativeexamples,foragivenpronoun.Inourcorpus,theaveragenumberis36.7(こちら:41.0,そちら:28.8,etc.).Table~summarizesthecorpusannotationsforanaphoricexpressionsandantecedentcandidatesoftheexampledialoguegiveninFigure~.5ptTheyconsistoftagsforauniqueidentifierforeachmorpheme(ID),thesurfaceword(word),thestemform(stem),thepart-of-speech(pos),thesemanticcode(sem),andtheantecedent(ant).Theexpression``''denotesthesemanticclassassignedtotherespectiveword.``[]''givestheEnglishequivalentoftherespectiveJapaneseexpression.Theantecedentstaggedinourcorpusconsistofeithersinglenounsorcompoundnouns,i.e.asequenceofsinglenouns.Thetagsusedtomarkcoreferentialrelationships(ant)consistofarange(startID,endID)ofmorphologicalidentifiers.startIDistheIDofthefirstmorphemeinthetaggedsequenceofsinglenouns,whereasendIDistheIDofthelastmorphemeofthissequence.Forexample,acoreferentialreferencetowardsthecompoundnoun「田中弘子」[HirokoTanaka]giveninTable~wouldbespecifiedasant=(6,7).Inthecaseofasinglenoun,startIDandendIDareidentical.BasedonthecorpusannotationsillustratedinTable~,wecanobtainadditionalstatisticalinformationdescribingthecharacteristicsoftheunderlyingdata.First,weextractthefrequencyinformationofcoreferentialanaphor-antecedentpairs(freq^+)andnon-referentialpairs(freq^-)fromthetrainingdata.freq^+denotesthenumberoftimestheanaphor-candidatepairistaggedcoreferentially,whereasfreq^-isthenumberoftimestheanaphor-candidatepairdoesnotoccurcoreferentialinthetrainingcorpus.InTable~someexamplesaregivenforsurfaceform(word)andsemanticcode(sem)combinations.2ptMoreover,eachdialogueissubdividedintoutterancesconsistingofoneormorechunksdividedbyconjunctions.Therefore,distancefeaturesareavailableontheutterance(d_uttr),chunk(d_chunk),candidate(d_cand),andmorpheme(d_morph)levels.Forexample,thedistancevaluesforthepronoun(r3)``こちら[here]''andtheantecedent(r1)''シティホテル[CityHotel]''aswellasthoseforthemostrecentcandidate(r3)``十日[10^th]''inoursampledialoginFigure~aregiveninTable~.10ptAdditionalstatisticscanbeextractedfromthedialoguebycountingtheoccurrencesofcandidatefeaturesinthepreviousdiscourse.Table~liststhevaluesofthecountingfeatureforthestemform(c_stem),thepart-of-speech(c_pos),andthesemanticcode(c_sem)oftherespectivecandidates.*8mm10pt</subsection>
  <subsection title="Coreference analysis">Theresolutionofanaphoricexpressionsisimportantinnumerousnaturallanguageprocessingapplicationsandhasbeenintensivelystudiedinthepast.Variousfeaturesindicatingcoreferentialrelationshipshavealreadybeenproposed.Butmostofthepreviousapproachesmakeuseofquitesophisticatedlinguisticknowledge,suchas,forexample,dependencystructuresordiscoursemarkers.Therichnessofthisknowledge,however,hasitsdrawbackswithrespecttothescalabilityofaresolutionsystemtonewtasksordifferentlanguages.Therefore,weareproposingatrainableresolutionapproachusingshallowinformation,i.e.,syntacticandsemanticwordattributesaswellasprimitivediscourseinformationextractedfromthemorphologicalanalysisoftheinpututterances.TolearnthecoreferentialrelationshipsfromourcorpuswehavechosenaC4.5-likemachinelearningalgorithm.Thesetofattributesusedforthedecisiontreelearningconsistsofdiscreteandcontinuousvaluesextractedfromthetrainingcorpus(cf.Section~).Twodecisiontreeclassesareusedtodeterminewhetherthereisacoreferentialrelationshipornot(cf.Section~).Duringouranaphoraresolutionalgorithm,thelearneddecisiontreeisappliedtoallpossibleanaphor-candidatepairs(cf.Section~).Ifthecoreferentialrelationshipcanbeverified,therespectivecandidateistakenintofurtherconsiderationbytheresolutionalgorithm.Otherwise,thecandidateisjudgedasunrelatedanddeletedfromthelistofpotentialcandidates,thusachievinganoisereductionforthepreferenceselectionschemedescribedinSection~.</subsection>
  <subsubsection title="Training attributes">ForthelearningofthedecisiontreeweusethewordattributesandthediscourseinformationdescribedinTable~.5ptAccordingtothecategory,wedistinguishattributesconcerningthestemformofspecificcontentwords,thesemanticclassificationofwordsandtheirpart-of-speechaswellasinflectionalattributes.Moreover,informationaboutsyntacticalmarkerslikeparticlesorsentenceconjunctionsaswellasdiscourseinformationaboutdistanceandnumberofoccurrencesareusedforthedeterminationofcoreferentialrelationships.Fortheresolutionofpronouns,wehavetochecknotonlywhichanaphoricexpressionsareinvolved,butalsotheexistenceofothercontentwords,like,forexample,thesentencepredicate,areverifiedfortherespectiveinputsentence.Forthesemanticclassificationofcontentwords,weusetheRuigo-Shin-Jiten,a3-layeredsemantichierarchydistinguishing1000semanticclasses.Wedistinguish33parts-of-speechforverbs(e.g.,本動詞,助動詞,判定詞),nominalexpressions(e.g.,普通名詞,代名詞),adjectives(e.g.,形容詞,数詞)andfunctionalwords(e.g.,格助詞,接続詞).InJapanese,thegrammaticalroleofspecificcontentwordsismarkedaccordingtoparticlessucceedingtheexpression.Wedistinguishcaseparticle(e.g.,は,が,を,に),conjunctionparticle(e.g.,と,や),compoundparticle(e.g.,の,と言う),andadverbialparticle(e.g.,とか,など).Moreover,theexistenceofspecificconjunctions(e.g.,ながら,ので)aswellastheconjugationformofthesentencepredicateisverifiedforthedeterminationofcoreferentialrelationships.TheattributesextractedfromtherespectivediscoursearedescribedinmoredetailinSection~.InourexperimentsdescribedinSection~,weuseinformationabouttheoccurrenceofspecificcontentwordsanditsdistanceinthediscourse.[-0.5em]deflistscopeofaspecificattributeisnotlimitedtothespecifiedexpression,e.g.,theanaphor,butcanalsobeappliedtoprecedingorsucceedingexpressionsusingthekeywordslistedbelow.checkallelementsprecedingthespecifiedexpression,e.g.,``Whichsemanticclassesareassignedtothecontentwordprecedingthesentencepredicate?''(:predicate:backward:semcode)checkthemostrecentcontentwordprecedingthespecifiedexpression,e.g.,``Isthecandidatemodifiedbyaverbalphrase?''(:candidate:latest-cont(:pos&quot;本動詞&quot;))checktheelementdirectlyprecedingthespecifiedexpression,e.g.,``Isthecandidatepartofacompoundnounphrase?''(:candidate:latest(&quot;と&quot;&quot;並立助詞&quot;))checktheattributeofthespecifiedexpression,e.g.,``Isそちらthestemformoftheanaphor?''(:anaphor:here(&quot;そちら&quot;&quot;代名詞&quot;))checktheelementdirectlysucceedingthespecifiedexpression,e.g.,``Istheanaphormarkedasthesubject?''(:anaphor:next(&quot;が&quot;&quot;格助詞&quot;))checkthenextcontentwordsucceedingthespecifiedexpression,e.g.,``Howoftendidthecontentwordsucceedingtheanaphoroccurredpreviously?''(:anaphor:next-cont:count)checkallelementssucceedingthespecifiedexpression,e.g.,``Doestheutterancecontainsaspecificconjunction?''(:predicate:forward(&quot;ながら&quot;&quot;接続詞&quot;))[-0.5em]deflistthetrainingofthedecisiontreeweprovidethecompletesetofattributesdescribedabove.Besidestheseattributes,variouscoreferenceindicatorshavebeenproposedinpreviousresolutionsystemswhicharenotincludedinourapproachbecausetheyrequireamoresophisticatedlinguisticanalysisoftheinputdata.Theseinformationsourcesincludestructuralparsingoftheinputsentence,semanticconstraintsonverbcaseandverbalsemanticattributes,theanalysisofdiscoursemarkeraswellastopicandfocusinformation.*-0.25em</subsubsection>
  <subsubsection title="Learning phase">Duringtheiterativeanalysisofeachdialog,anaphoricexpressionsareidentifiedaccordingtotheassignedcoreferencetags.Previouslymentionednounsareconsideredaspossibleantecedentcandidates.Questionsareappliedtoeachanaphor-candidatepairbyeithermatchingspecifiedexpressionsintherespectiveutterances(discretevalues)orcalculatingattributevaluesinthegivencontext(continuousvalues).Wedistinguishfourgroupsofquestionsetsagainstwhichtheseattributesaretested:unaryfeaturesoftheanaphor(e.g.,lexicalwordattributes,grammaticalrolemarker)unaryfeaturesofthecandidatefeaturesofexpressionsotherthantheanaphorandthecandidateintherespectiveutterances(e.g.,modifyingconstituents,sentencepredicate)featuresconcerninganaphorandcandidatealike(e.g.,attributeagreement,relativedistance)Theapplicationofthefourquestionsetstoeachanaphor-candidatepairyieldsasingleattributevectorclassifyingthecharacteristicsofthegivenreference.Inthecaseofantecedents,thisvectorisassignedtothecoreferenceclass,whereasvectorsofthenon-antecedentcandidatesformaseparateclassdeterminingthenon-referentialrelationship.Theamountofattributevectorsforalltrainingsamplesformstheinputofthelearningmethod.Byoptimizingtheentropyvalueforeachsubset,theautomaticclassifieralgorithmproducesadecisiontreerankingimportantattributeshigherinthetreeinordertoachieveanearlydecisionabouttheclassificationofthespecifiedinput.*-0.25em</subsubsection>
  <subsubsection title="Application phase">Duringanaphoraresolution,thedecisiontreeisusedasamoduledeterminingthecoreferentialpropertyofeachanaphor-candidatepair(cf.Figure~).Foreachanaphoricexpression,acandidatelist,i.e.,alistofthenominalcandidatesprecedingtheanaphorelementinthecurrentdiscourse,iscreated.Thedecisiontreefilteristhensuccessivelyappliedtoallanaphor-candidatepairs.Startingwiththetopnodeofthedecisiontree,thequestionassignedtothisnodeistestedagainsttheinput,i.e.,therespectiveanaphor-candidateattributevector.Dependingonthetruthvalueofthequestion,theproceduredescendstotherespectivesub-branch.Theverificationprocedureiscontinueduntilaleafcontainingtheclassificationresult(coreferencevs.no-relation)isreached(cf.Figure~).Ifthedecisiontreeapplicationresultsintheno-relationclass,thecandidateiseliminatedfromthelistofpotentialantecedentsformingtheinputofthepreferenceselectionalgorithm.</subsubsection>
  <subsection title="Preference selection">Theprimaryorderofcandidatesisgivenbytheirworddistancefromtheanaphoricexpression.Astraightforwardpreferencestrategywecouldchooseistheselectionofthemostrecentcandidateastheantecedent,i.e.,thefirstelementofthecandidatelist.However,theexperimentalresultsdescribedinSection~showthatitisnotsufficienttorelyonlyonsingleindicatorslikerecencyinordertodeterminethesaliencyofpotentialanaphor-candidatepairs.Weproposeapreferenceselectionscheme(Section~)whichisbasedonthecombinationofstatisticalinformationabouttheratioofcoreferentialoccurrencesextractedfromourtrainingcorpus(Section~),discourseinformationaboutthenumberofcandidateoccurrencesinthecurrentconversation(Section~),andrecencyinformation(Section~).</subsection>
  <subsubsection title="Frequency ratio">Anexaminationofourcorpusindicatesthatsimilaritiestoreferencesinourtrainingdatamightbeusefulfortheidentificationofthoseantecedents.Themorefrequentlyananaphor-candidatepairistaggedcoreferentialinthetrainingcorpus,themorelikelyisacoreferentialrelationshipforthispair.Inordertomeasurethesimilarityoftheinputdatatothoseofthetrainingcorpus,wedefinetheratioofagivenanaphor-candidatepairbasedonthefrequencyinformationdescribedinSection~asfollows:*-1em1ptratio&amp;=&amp;.[-0.5em]eqnarray*Thevalueofratioisintherangeof[-1,+1],wherebyratio=-1isthecaseofexclusivenon-referentialrelationshipsandratio=+1isthecaseofexclusivecoreferentialrelationships.Inorderforreferentialpairsoccurringinthetrainingcorpuswithratio=0tobepreferredtothosewithoutfrequencyinformation,weslightlydecreasetheratiovalueofthelatterbyafactorof.TheratiovaluesofthesamplefrequencydatagiveninTable~aresummarizedinTable~.5ptThedomaindependencyofthissaliencyfeaturecanbevariedaccordingtotheselectionofthefrequencytypeusedforthecalculationoftheratiovalue.Themostdomain-specificfrequencyinformationisgivenbythewordform.Lessspecificisthefrequencyinformationofstemforms.Incontrast,thefrequencyratioofsemanticclassesandparts-of-speecharemoregeneral.AccordingtotheexperimentalresultsdescribedinSection~weareusingthefrequencyinformationofthestemformsoftheanaphor-candidatepairastheratiovalue.</subsubsection>
  <subsubsection title="Count">Otherimportantindicatorsforthedeterminationofsaliencycanbeobtainedfromthecontextinwhichtherespectiveanaphor-candidatepairoccurs.Thelargerthenumberofpreviousoccurrencesoftherespectivecandidateinthecurrentconversation,themorelikelythecandidatewillbereferredto.Similartoratio,wecoulddefinevarioustypesofcountfeaturesinfluencingthedegreeofgeneralityofthisfeature.However,inthecaseofshortconversations,thecountvalueofspecificwordformswillbealmostthesame(i.e.,closetozero)formostofthecandidates.Amoremeaningfuldistinctioncanbeachievedbyrelyingonthesemanticclassificationoftherespectiveelements.Therefore,wedefinethecountfeatureasthenumberofnounsNwiththesamesemanticcodeasthecandidate.TheutilizationofdifferentcounttypesisevaluatedinSection~.*-1em</subsubsection>
  <subsubsection title="Distance">Eveniftherecencyinformationprovestobeinsufficientasasingleindicatorforsaliency,thedistancefeatureplaysacrucialroleinourselectionmethod.Thesmallerthedistancebetweentheanaphorandthecandidateis,themorelikelyisacoreferentialrelationship.AsmentionedinSection~recencycanbemeasuredonvariousgranularity(utterance,chunk,candidate,morph)levels.However,measuringthedistanceaccordingtoutterancesorchunks,wemightendupwithmultiplecandidatesinthesamechunk,thusnotbeingabletomakeareliabledistinction.Ontheotherhand,thenumberofmorphemesbetweentheanaphorandthecandidatedependsonthelengthoftheutterances,whichmightvarydependingonthedomain.Therefore,wedefinethedistfeatureasthenumberofnounsoccurringbetweentheanaphorandthecandidate.TheutilizationofdifferentdisttypesisevaluatedinSection~.*-1em</subsubsection>
  <subsubsection title="Saliency measure">Giventhesaliencyindicatorsdescribedintheprevioussections,wewillpreferthoseanaphor-candidatepairswiththefeatures:*-0.1emHowever,theexaminationofourcorpusrevealsthatfrequentlyoccurringcandidateswhicharementionedatthebeginningoftheconversation(i.e.,largeratio/count+largedist)aswellasrarelyoccurringcandidatesmentionedinthelastutterance(i.e.,smallratio/count+smalldist)aretaggedasantecedents,thusleadingtoaconflictconcerningtheproposedsaliencyindicators.Asasolutiontothisproblem,wedefinethepreferencevalueprefbydividingtheratioandthecountvaluesbythedistvalue,thusenablinganappropriatedecisionforconflictingcandidates.pref&amp;=&amp;ratio+countdisteqnarray*Theprefvalueiscalculatedforeachcandidateandthelistofpotentialcandidatesissortedtowardsthemaximizationofthepreferencefactor.Thefirstelementischosenastheantecedent.Theprecedenceorderbetweencandidateswiththesameprefvaluecontinuestoremainsoandthusafinaldecisionismadeinthecaseofadraw.</subsubsection>
  <section title="Evaluation">InordertoprovethefeasibilityofourapproachwecomparethefourpreferenceselectionmethodslistedinFigure~.(1)TheMRCmethodselectsthemostrecentcandidateastheantecedentofananaphoricexpressionandshowsthebaselineperformanceofthetask.Thenecessityofthefilterandpreferenceselectioncomponentsisshownbycomparing(2)thedecisiontreefilterschemeDT,(i.e.,selectthefirstelementofthefilteredcandidatelist)and(3)preferenceschemePREF,(i.e.,sortthefullcandidatelistandselectthefirstelement)against(4)ourcombinedmethodDT+PREF,(i.e.,sortthefilteredcandidatelistandselectthefirstelement).Five-waycross-validationexperimentsareconductedfortheresolutionof1745pronominalinputsamples.Theperformanceofthesystemiscalculatedbythepercentage(%)ofcorrectlyresolvedantecedents.AsdescribedonSection~theantecedentstaggedinourcorpusconsistofeithersinglenounsorcompoundnouns,i.e.asequenceofsinglenouns.However,thesystemselectsonlyasinglenounfromthelistofantecedentcandidates.Inthecasethatthetaggedantecedentisacompoundnoun,thecorrectnessofthecoreferenceanalysisisjudgedaccordingtowhethertheselectedcandidateiscontainedinthesetoftaggedsinglenounsornot.Forexample,inthecaseofacoreferentialreferencetowardsthecompoundnoun「田中弘子」[HirokoTanaka]giveninTable~,theselectionofboth,「田中[6]」and「弘子[7]」,wouldbejudgedascorrect.</section>
  <subsection title="Resolution method">Weusevariednumbersofdialogues(50-400)forthetrainingofthedecisiontreeandtheextractionoffrequencyinformationfromthecorpus.Opentestsareconductedon100non-trainingdialogueswhereasclosedtestsusethetrainingdataitselfforevaluation.TheresultsofthefourdifferentpreferenceselectionmethodsareshowninFigure~.ThebaselineMRC,succeedsinresolvingonly57.1%.ThebestperformanceofPREF,appliedtotheopendatais74%.DT,performsonlyslightlybetterresultinginanaccuracyof74.5%.Aside-effectofDT,isthefilteringoutofcorrectantecedents.Inourexperiments,7.9%ofcorrectantecedentsareclassifiedasnon-coreferential.Therefore,wemightconcludethatthedecisiontreeisnotmuchhelpfortheidentificationofthemostsalientantecedentcandidate.However,duetonoisereduction,whereasthefiltermechanismusedinDT,stillimproves.ThisisduetothefactthatPREF,assignsapreferencevaluetoallpossiblecandidatesinthediscoursehistory,regardlessofwhetheracoreferentialrelationshipexistsornot.Incontrast,thedecisiontreefilterreducesthenumberofpossiblecandidatesby22%.Moreover,thenumberoftrivialselectioncases(onlyonecandidate)increasesfrom0.9%(allcandidates)to4.2%(filter;closedtest:21%).Onaverage,twocandidatesareskippedinthehistorytoselectthecorrectantecedent.,theutilizationofthedecisiontreefilterincombinationwiththestatisticalpreferenceselectionprovestobeeffective.Thecombinationofbothmethodsachievesasuccessrateof76.6%.Therefore,DT+PREF,gainsarelativeimprovementof2.6%(closed:10.1%)abovePREF,and2.1%(closed:2.3%)aboveDT.</subsection>
  <subsection title="Data balance">However,thecontinuousimprovementofthedecisiontreefilteraccordingtothetrainingsizeaswellasthelargenumberofantecedentsfilteredoutintheopentest(OUT)impliesalackoftrainingdatafortheidentificationofpotentialcandidates.Moreover,anexaminationofthetrainingcorpusrevealsanimbalanceofcoreferentialanaphor-antecedentpairstowardsunrelatedpairs.Inordertoovercometheseproblems,weartificiallyincreasetheamountoftrainingdatabyrepeatingtaggedanaphor-antecedentpairsN*dbtimes,wheredbistheaverageofthenumberofnegativeexamplesdividedbythenumberofpositiveexamplesforeachtaggedanaphor.Figure~showstheinfluenceofincreasingthedatabalancefactorNversusthesystemperformance.RetrainingthesamecoreferentialrelationshipmorefrequentlyhasonlyasmallimpactontheperformanceoftheDT,method,butitsignificantlydecreasesthenumberofantecedentsfilteredoutfrom10.5%to7.6%,resultinginanimprovementofthepreferenceselectionmethodwhenusedincombinationwiththedecisiontreefilter.ThebestperformanceoftheDT+PREF,methodisachievedforthebalancefactorofN=10,whereasalargerNdoesnotimprovethesystemperformancefurther.*-5mm</subsection>
  <section title="Feature dependency">Inordertobeabletoimprovetheperformancedescribedabove,itisnecessarytogointotheparticularsabouttheimportanceofthefeaturesutilizedfortheidentificationofcoreferentialrelationshipsaswellastheassignmentofpreferencevalues.Forthetaskofcoreferentialanalysis,wecancategorizetheutilizedfeaturesetsintothefollowinggroups:Moreover,wedistinguishfourgroupsaccordingtowhichelementinthediscourse(:ana,:cand,:agree,:sen)thefeaturesareappliedtoandfouradditionalgroupsspecifyingthelocationsoftheseelements(:backward,:latest,:next,:forward).Theassignmentofsaliencyvaluesisbasedoninformationabouthowoftenagivenanaphorcandidatepairistaggedcoreferentialvs.non-referentialinthetrainingcorpus(:ratio)aswellastheabsolutepositionandrelativedistance(:pdist).Moreover,wetakeintoaccounthowoftentherespectiveelementshavealreadybeenmentionedinthediscourse(:pcount).</section>
  <subsection title="Investigation of coreferential analysis by feature omission">Theimportanceofafeatureisverifiedbyretrainingthedecisiontreefilterwithoutusingtherespectivefeatureinformationandcomparingitsperformancewiththe:allmethodusingthecompletesetoffeatures.TheresultsforopenandclosedtestsarelistedinFigure~.Themostimportantfeatureisthe:semfeature,whoseomissionleadstoaperformancedropof3.1%intheopentest.Thedescriptivepowerofthisfeatureisindicatedbytheincreaseinaccuracyfortheclosedtestwhen:semisomitted,i.e.,theusageofsemanticinformationleadstoageneralizationthatishelpfulfortheidentificationofunseendata,buthasitsdrawbacksintheclassificationofthetrainingsamples.Theomissionof:conjleadsonlytoasmalldropintheopentestperformance,buttheclosedtestresultis1%belowthe:allmethod.Thefeatures:distand:countmaynotseemtobeusefulforthetaskofcoreferentialanalysisandmightleadonetoconsidereliminatingthemfromthesetoftrainingfeatures.However,thisinformationprovestobeveryimportantforthepreferenceselectiontaskasdescribedinmoredetailinSection~.Concerningtheelementstowhichthefeaturesareapplied,thebiggestperformancedropof3.1%isseenwhenanyinformationabouttheanaphor(:ana)itselfisomitted.Intheopentest,only71.6%oftheantecedentscanberesolvedcorrectly,whereastheclosedtestperformancegoesdown1.6%to89.8%.</subsection>
  <subsection title="Feature distribution inside the decision tree">Additionalinformationabouttheimportanceofeachfeaturecanberetrievedbylookingathowoftenthefeatureisused(quantity)andwhereitsusageislocatedinthedecisiontree(quality).</subsection>
  <subsubsection title="Quantity">Figure~describesthenumberoftreenodesusingaspecificfeaturewithindecisiontreestrainedwithavariednumberofdialogues.Again,thesemanticfeature:semisthemostimportantone,asitisthefeaturemostfrequentlyusedwithinadecisiontree.Lessfrequentarethefeatures:wordand:hdist,followedby:pos,:dist,and:count.Moreover,notonlyisinformationaboutthecoreferentialelementsthemselvesimportantfortheidentificationofcoreferentialrelationships,butwhatalsoprovetobequitehelpfularethefeaturesofelementsdirectlysucceedingthecoreferentialexpressions(:next).Comparingthedecisiontreesfordifferentdatabalancefactors,wefindthatanartificialincreaseofthetrainingdataleadstoaquantitativeincreaseofthe:semfeatureusageuptoaspecificlevel,withstagnationforadatabalancefactorofN&gt;10.Additionally,theincreasingnumberofnodesaddressingfeaturesofelementsdirectlypreceding(:latest)andsucceeding(:forward)thecoreferentialelementsindicatesafocusshifttowardslocalconstraintsaroundtheseconstituents.Furthermore,thequantitativeimportanceoffeatureswithcontinuousvalues(:hdist,:dist,:count)decreases,becausenonewinformationisprovidedforthelearningprocedure.</subsubsection>
  <subsubsection title="Quality">Foraninvestigationofthefeaturelocationsdescribedbelow,weextractedthepositionsoftherespectivenodeswithinadecisiontree.Thedistributionofthemostimportantquantitativefeatures:sem,:hdist,and:wordislistedinFigure~.Themostimportantqualitativefeature:hdistislocatedatthetop-levelofthedecisiontree.Interestingly,thisnodedetermineswhethertheantecedentcandidateisthefirstorsecondcandidateinthediscoursehistory,thusdistinguishinglongrangereferencesfrommorerecentones.Incontrast,therelativedistancefeature:distismainlyusedonlowerlevels(level11to35)toidentifythecorrectantecedentwithinashortrange(1to3utterancesapart).Concerningthequalitativeimportance,:hdistisfollowedby:semand:wordonlevels2and4.However,themostfrequentfeature:sem(levels2-44)isutilizedonalmostalllevelstodeterminecoreferentialrelationships.Incontrast,thefeatures:hdist(level4-15),:pos(levels5-20),and:count(levels5-25)aremainlyappliedonmediumlevels,whereasthefeature:wordisalsousedforthepurposeofdisambiguationonlowerlevels.Moreover,thedecisiontreelevels1-3areidenticalforthetrainingsize250-400,thusrepresentinggeneralattributestobecheckedfortheidentificationofthecorrectantecedentinthistask.Theinvestigationonthefeatureimportanceinthissectionsuggeststhatitisnotsufficienttosimplyprovideinformationtaggedinourtrainingcorpusforthedecisiontreelearning,butaselectionofappropriatelearningfeaturesbeforehandcanpositivelyaffectthecoverageofthedecisiontreeperformance.</subsubsection>
  <subsection title="Investigation of preference selection by feature type">ThepreferenceselectionschemedescribedinSection~usesstatisticalinformationaboutthefrequencyratioofanaphor-can-didatepairsaswellasdistanceandcountfeaturesextractedfromthediscourseinordertoselectthemostsalientantecedentcandidate.However,forallofthesefeatures,wecanextractdifferenttypesasdescribedinSection~.Inthissectionwewillinvestigatethedependencyofthesystemperformancetodifferenttypesofsaliencyfeatures.FortheevaluationofoursystemdescribedinSection~,weusedthetypesresultinginthebestperformance.Thosearemarkedwith``^*''inthedescriptionsbelow.</subsection>
  <subsection title="Investigation of preference selection by feature omission">Inourapproach,thedistanceandcountinginformationdonotplayacrucialrolefortheidentificationofpotentialcandidatesduringdecisiontreefiltering,buttheyareveryimportantforthedeterminationofthepreferencevalueforeachantecedentcandidate.Thepreferenceselectionmethodisbasedonthedependencybetweenthedistance(:pdist)andcounting(:pcount)valuesofthegivenanaphor-candidatepairinthecontextoftherespectivediscourse.Additionally,weusestatisticalknowledgeaboutthefrequencyofcoreferentialandnon-referentialpairsextractedfromthetrainingcorpus(:ratio).TherelativeimportanceofeachfactorisshowninTable~.2ptWecomparetheperformanceoftheexperimentsdescribedinSection~(all)tothosemethodsthatrelyonlyonfrequency(only-freq)orcounting(only-count)informationmethod.aswellastopreferenceschemesthatdonotusecounting(no-count),frequency(no-freq),ordistance(no-dist)information.Mostofthelistedmethodsperformsignificantlyworsethantheallapproachtakingintoaccountallthreesaliencyindicators.Relyingonlyonfrequencyinformationachievesanaccuracyofaround64.5%(closed:92.3%)regardlessofwhetherthefiltermechanismisused(DT+PREF,)ornot(PREF,).UsingonlycountinginformationdecreasestheperformanceofthePREF,methodto33.7%foropenaswellasclosedtestdata.Thus,frequencyinformationoncoreferentialrelationshipsdoesappeartobemorerelevantfortheidentificationofpotentialcandidatesoverthecountingoffeatureswithinthecurrentdiscourse.Eventhecombinationofbothfeatures(no-distmethod)doesnothaveapositiveimpactonthepreferenceselection.Thereasonforthisisthatthelargerthecountfactoris,thelatertherespectivecandidateoccursinthediscoursehistory,thusemphasizingtheselectionofmorerecentcandidates.Moreover,thecountfactorisnotmuchhelpfortheresolutionofanaphoraoccurringearlyinthediscourseduetothemissedmentioningofprevioussimilarexpressions.Incontrast,duetothelargeamountoflongrangereferencestowardsdialogue-initialcandidatescontainedinourtaggedcorpus,thefrequencyinformationtendstoprefercandidatesoccurringearlierinthediscourse.Inordertofindametricsthattakesintoaccountrecentcandidatesrarelyoccurringcoreferentiallyaswellasdialogue-initialelementsoccurringfrequentlycoreferentially,wedividethesaliencyvaluebasedonthefrequencyandcountinformationbythedistancefactor.Theapplicationofthenewmetricstothecountinformation(no-freq)improvestheperformanceoftheonly-countschemeby25%,butthemetricsisstillinsufficientasasaliencymeasure.However,thisdoesnotmeanthatthecountinformationiscompletelyunimportantfordeterminingsaliency.Evenifthecombinationofthefrequencyanddistanceinformation(no-count)performsaswellastheallmethodforthepreferenceselectionappliedtoallcandidates(PREF,),theadditionalcountinformationgainsanimprovementwhenappliedtopotentialcandidatesonly(DT+PREF,).Therefore,theeffectivenessofourapproachisnotonlybasedontheusageofsingleantecedentindicatorsextractedfromthecorpus,butalsoonthecombinationofthesefeaturesfortheselectionofthemostpreferablecandidateinthecontextofthegivendiscourse.</subsection>
  <section title="Related research">Duetothecharacteristicsoftheunderlyingdatausedinourexperiments,acomparisoninvolvingabsolutenumberstopreviousapproachesgivesuslittlepracticaluse.However,thedifficultyofourtaskliesinfrequentlongrangereferences.Resolvingpronounsinourdatacorpustothemostrecentcandidateachievesasuccessrateofonly57.1%(cf.~Section~).Whereasknowledge-basedsystemslikeandcombiningmultipleresolutionstrategiesareexpensiveinthecostofhumaneffortduringdevelopmentandhavealimitedabilitytoscaletonewdomains,morerecentknowledge-poorapproacheslikeandaddresstheproblemwithoutsophisticatedlinguisticknowledge.Similartothem,wedonotuseanysentenceparsingorstructuralanalysis,butsimplyrelyonmorphosyntacticandsemanticwordinformation.Moreover,cluesregardingthegrammaticalfunctionofexpressionsareusedinthecenteringtheoryofandmorespecificallyforJapanesein.Incontrasttothem,thegrammaticalrolemarkersofcandidatesseemtobelessimportantforourtask,becausetherespectivequestionsappearmainlyonlowerlevelsofthedecisiontree.Rule-basedempiricalapproachestodeterminethemostsalientreferentareutilizedinand.Thesekindsofmanuallydefinedscoringheuristics,however,involveaconsiderableamountofhumaninterventionwhichisavoidedinmachinelearningapproaches.AsbrieflynotedinSection~,thelearningapproachesdescribedinanddifferfromourworkaccordingtotheusageofthedecisiontreeintheresolutiontask.In,adecisiontreeistrainedonasmallnumberoffeaturesconcerninganaphortype,grammaticalfunction,recency,morphosyntacticagreementandsubsumingconcepts.Giventwoanaphor-candidatepairs,thesystemjudgeswhichis``better''.However,duetothelackofastrongassumptionon``transitivity'',thissortingalgorithmmaybeunabletofindthe``best''solution.Basedondiscoursemarkersextractedfromlexical,syntactic,andsemanticprocessing,theapproachofusesunaryandbinaryattributes(lexical,syntactic,semantic,position,matchingcategory,topic)duringdecisiontreetraining.Theconfidencevaluesreturnedfromthepruneddecisiontreeareutilizedasasaliencymeasureforeachanaphor-candidatepairinordertoselectasingleantecedent.However,weusedependencyfactorsforpreferenceselectionwhichcannotbelearnedautomaticallybecauseoftheindependentlearningofspecificfeaturesduringdecisiontreetraining.Therefore,ourdecisiontreeisnotapplieddirectlytothetaskofpreferenceselection,butonlyusedasafiltertoreducethenumberofpotentialcandidatesforpreferenceselection.Inadditiontosaliencepreference,astatisticallymodeledlexicalpreferenceisexploitedinbycomparingtheconditionalprobabilitiesofco-occurrencepatternsgiventheoccurrenceofcandidates.Experiments,however,arecarriedoutoncomputermanualtextswithmainlyintra-sententialreferences.Thiskindofdataisalsocharacterizedbytheavoidanceofdisambiguitiesandonlyshortdiscourseunits,whichprohibitsalmostanylong-rangereferences.Incontrasttothisresearch,ourresultsshowthatthedistancefactorinadditiontocorpus-basedfrequencyinformationisquiterelevantfortheselectionofthemostsalientcandidateinourtask.</section>
  <section title="Conclusion">Inthispaperweproposedacorpus-basedanaphoraresolutionmethodcombininganautomaticlearningalgorithmforcoreferentialrelationshipswithstatisticalpreferenceselection.Weprovedtheapplicabilityofourapproachtopronounresolution,achievingaresolutionaccuracyof76.6%forJapanesepronouns.Inordertoovercomethelimitationofsparsedataforthetaskofcoreferentialanalysis,weartificiallyincreasedthenumberoftrainingsamplesbyrepeatingpositiveexamples.Asaresult,thefocusofthefeatureselectionshiftedtowardsconstraintsconcerningnon-anaphoricelementsdirectlypreceding/succeedingthecoreferentialexpressions,suggestingthatapreprocessfortheselectionofappropriatefeaturesforthedecisiontreelearningisnecessarytoobtaintheoptimalperformanceforcoreferentialanalysis.Theseparationofthecoreferentialanalysisandpreferenceselectionprovesquiteeffective.Thedecisiontreefiltereliminatesnon-coreferentialcandidatesfromthediscoursehistory.Thisnoisereductionincreasestheeffectivenessofthepreferenceselectionmethod,whichisnotonlybasedontheusageofsingleantecedentindicatorsextractedfromthecorpus,butalsoonthecombinationofstatisticalanddiscoursefeaturesfortheselectionofthemostpreferablecandidateinthegivencontext.Oursystemdoesnotuseanykindofparsertoidentifycompoundnouns,butweareonlyrelyingonthemorphologicalanalysisofourinputsentence.Therefore,thesystemselectsonlyasinglenounastheantecedent.Onefutureextensionofoursystemwillbetheincorporationofaparsertoobtainadditionalinformationaboutthesentencestructurewhichwillenablethehandlingofcompoundnounsinourframework.Thisapproachisalsonotlimitedtotheresolutionofpronominalanaphora.Wearegoingtoapplythisapproachtoothertypesofanaphoricreference,likeellipsisandnominalresolution,too.Preliminaryexperimentsonellipsisresolutionhavealsoshownpromisingresults.However,thefiltermechanismproposedinthispaperisautomaticallytrainedfromthetrainingcorpususingthesameattributesforallanaphoricexpressions.But,comparingattributesetsusedfortheresolutionofpronominalanaphoratothoseofotheranaphoricexpressions,like,forexample,ellipsisresolution,wecanfindadiscrepancywhichindicatesadependencyoftheattributeimportanceontheresolutiontask.Inaddition,notonlytheattributetype,butalsothescopeofspecificattributevaluescaninfluencetheperformanceofthesystem.Forexample,introducesalocalityassumptionwhichrestrictsthereferencescopeaccordingtotheanaphortype.Therefore,task-orientedextensionsofourgeneralapproachmightbenecessarytoimprovetheresolutionperformanceforspecificapplications.Moreover,investigationsintothefeasibilityofourapproachforlanguagesotherthanJapanese,e.g.,theEnglishMUCcorpus,willenableustocomparethisapproachmorepreciselytowardsrelatedresearch.Additionally,weplantoincorporatethisapproachintomulti-lingualmachinetranslation,whichwillenableustohandleavarietyofreferentialrelationsinordertoimprovethetranslationquality.</section>
</root>
