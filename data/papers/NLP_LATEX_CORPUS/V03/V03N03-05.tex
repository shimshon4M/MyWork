



\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{83}
\setcounter{巻数}{3}
\setcounter{号数}{3}
\setcounter{年}{1996}
\setcounter{月}{7}
\受付{1995}{9}{5}
\採録{1995}{11}{28}

\setcounter{secnumdepth}{2}

\title{開発者の視点からの機械翻訳システムの技術的評価\\
　　---テストセットを用いた品質評価法--- }
\author{井佐原 均 \and 内野 一 \and 
荻野 紫穂 \and 奥西 稔幸 \and 
木下 聡 \and 柴田 昇吾 \and  
杉尾 俊之 \and 高山 泰博 \and 
土井 伸一 \and 永野 正 \and 
成田 真澄 \and 野村 浩郷}

\headauthor{井佐原 均 他}
\headtitle{開発者の視点からの機械翻訳システムの技術的評価}

\jabstract{
機械翻訳システムの開発者がシステムの技術的評価を翻訳品質に注目して客観的
に行う手法を開発した。
評価過程の客観性と評価結果の解釈の客観性を維持するために、本手法では単な
る評価用例文集ではなく、システムの出力を評価するための設
問と、その設問がどのような言語現象を対象としているかについての解説とを各例文に付
与したテストセットを用いている。各例文は基本的な言語現象と現在の機械翻訳
システムにおいて処理が困難である言語現象のそれぞれを出来る限り網羅するよ
うに収集された。
今回、英日機械翻訳システム、日英機械翻訳システムのそれぞれについての評価
用テストセットを作成した。これらを用いて商用の
機械翻訳システムでの評価実験を繰り返すことにより、機械翻訳システムの能力の差異を提
示できることが示された。
}

\jkeywords{機械翻訳，品質評価，コーパス}

\etitle{Technical Evaluation of MT Systems \\
from the Developer's Point of View: \\
Exploiting Test-Sets for Quality Evaluation}

\eauthor{Hitoshi Isahara\hspace*{-0.4em}\and Hajime Uchino\hspace*{-0.4em}\and
 Shiho Ogino\hspace*{-0.4em}\and Toshiyuki Okunishi\hspace*{-0.4em}\and 
Satoshi Kinoshita\hspace*{-0.4em}\and Shogo Shibata\hspace*{-0.4em}\and 
Toshiyuki Sugio\hspace*{-0.4em}\and Yasuhiro Takayama\hspace*{-0.4em}\and 
Shin'ichi Doi\hspace*{-0.4em}\and Tadashi Nagano\hspace*{-0.4em}\and 
Masumi Narita\hspace*{-0.4em}\and Hirosato Nomura} 

\eabstract{
This paper describes a method of evaluating quality for developers of
machine translation systems to easily check imperfections in their own
systems.  
Our method employs test-sets in which example sentences, their model
translations, yes/no questions for evaluating the system output, similar
examples (if any), and grammatical explanations have been systematically
aligned.  The example sentences have been collected focusing on wide
coverage of both basic linguistic phenomena and linguistic phenomena
problematic to MT systems. 
The questions in the test-sets are designed to clarify the evaluation
viewpoints.  Given the system outputs for each example sentence in
question, the system developer needs only to answer the question
assigned to the example sentence.  This judgment does not vary among
evaluators, thus enabling an objective evaluation.
}

\ekeywords{Machine Translation, Quality Evaluation, Corpus}

\begin{document}
\maketitle


\section{はじめに}
\footnotetext{井佐原 均, Hitoshi Isahara, 郵政省通信総合研究所 関西先端研究センター, Kansai Advanced Research Center, Communications Research Laboratory, MPT}
\footnotetext{内野 一, Hajime Uchino, 日本電信電話株式会社 ＮＴＴコミュニケーション科学研究所, NTT Communication Science Laboratories, Nippon Telegraph and Telephone}
\footnotetext{荻野 紫穂, Shiho Ogino, 日本アイ・ビー・エム株式会社 東京基礎研究所, IBM Research, Tokyo Research Laboratory, Nihon IBM}
\footnotetext{奥西 稔幸, Toshiyuki Okunishi, シャープ株式会社 情報システム事業本部情報商品開発研究所, Information Systems Product Development Laboratories, Information Systems Group, Sharp Corp.}
\footnotetext{木下 聡, Satoshi Kinoshita, 株式会社東芝 研究開発センター情報・通信システム研究所, Research and Development Center, Communication and Information Systems Research Laboratories, Toshiba}
\footnotetext{柴田 昇吾, Shogo Shibata, キヤノン株式会社 情報メディア研究所, Media Technology Laboratory, CANON INC.}
\footnotetext{杉尾 俊之, Toshiyuki Sugio, 沖電気工業株式会社 研究開発本部関西総合研究所, Research and Development Group, Kansai Laboratory, Oki Electric Industry Co., Ltd.,}
\footnotetext{高山 泰博,  Yasuhiro Takayama, 三菱電機株式会社 情報技術総合研究所, Information Technology R\&D Center, Mitsubishi Electric Corp.}
\footnotetext{土井 伸一, Shin'ichi Doi,日本電気株式会社情報メディア研究所, Information Technology Research Laboratories, NEC Corp.}
\footnotetext{永野 正, Tadashi Nagano,松下電器産業株式会社 ＡＶ＆ＣＣ開発センター東京情報システム研究所, ICSC, Matsushita Electric Industrial Co., Ltd.}
\footnotetext{成田 真澄, Masumi Narita,株式会社リコー 情報通信研究所, Information and Communication R\&D Center, Ricoh Co., Ltd.}
\footnotetext{野村 浩郷, Hirosato Nomura, 九州工業大学 情報工学部 知能情報工学科, Department of Artificial Intelligence, Kyushu Institute of Technology}

機械翻訳システムの長い歴史の中で、システム評価は常に大きな
課題の一つであった。システムの研究開発が健全に進むためには、
客観的かつ正確な評価法が必要となる。このため、ユーザの立場か
ら評価を行うもの、開発者の立場から評価を行うもの、また、技
術的側面から評価を行うもの、経済的側面から評価を行うものと、
多くの研究者によって様々な視点からの評価法が検討されてきた。
これらの検討に基づいて、(社)日本電子工業振興協会によって一
連の機械翻訳システム評価基準が開発されてきた(野村・井佐原 1992,
Nomura and Isahara 1992a,  
Nomura and Isahara 1992b, 日本電子工業振興協会 1993)。
本稿で提案する機械翻訳システムの評価法は、システムの
改良を続ける開発者の立場から、機械翻訳システムの技術面を翻
訳品質に注目して評価するものである。

機械翻訳システムの訳文の品質面での評価に関しては、従来から
のいわゆるＡＬＰＡＣレポート型の評価法に加えて、近年、いくつ
かの提案がなされている。ある程度まとまった文章を翻訳し、そこ
から得られる理解の度合を評価しようとするものとして、ＡＲＰＡ
による機械翻訳システム評価(White et al 1994)や、ＴＯＥＦＬの
テストを用いる方法(Tomita 1992)が提案されているが、これらは
システム間の現時点での性能の比較評価には用いることが出来ても、
評価結果を直接システム改良に結び付けることは困難である。

これに対し、個別の例文を収集することにより評価用の例文集を
作成し、その各例文の翻訳結果を評価し、対応する言語現象の処理
能力を判定しようとする提案がいくつかなされている。これらのう
ちには、単に文を集めるのみで、その後の例文の利用法(評価過程)
は個別の評価者に任せようというものから、本稿で提案するように、
客観的評価のためにさまざまな情報を付加しようというものまで、
いくつかの段階がある。

わが国においては、(社)日本電子工業振興協会が既に昭和６０
年に機械翻訳例文資料として、翻訳における曖昧性に関する問題点
に着目して、英文および和文を収集分類し公開している(日本電子工業振興協会
1985)。
また同協会は昭和６２年度に、機械翻訳シス 
テムの技術レベルを評価するために、文の複雑さの定量化、文の複
雑さや文体の定性的特徴の抽出、標準的例文の収集を行なった
(日本電子工業振興協会 1988, 石崎・井佐原 1988)。

この他、英語を話す人間と日本語を話す人間との間にある言語理
解法の違い(言い替えると、日本語と英語の発想法の違い)に注目
して日本語の言語表現を分類し、それらの表現の翻訳能力を評価す
る試験文集を作成するもの(池原・小倉 1990, 池原 他 1994)
や、言語学
的観点から日本語および英語の言語表現の構造に注目し、その表現
上の構造的特性を的確に表すような試験文集を作成すること
(成田 1988)が提案されてきた。後者は、個々の言語現象に対する翻訳の
可否を示すことの必要性から、一定の内容の文の言い換えなどによ
って日本語および英語の言語表現と翻訳能力の関係を言語学者の立
場から評価することを提案している。

本稿で論じる機械翻訳システム評価用テストセットは、以上のよ
うな、ＡＬＰＡＣレポート以来の品質評価に関する研究を踏まえて、
誰でも客観的かつ実用的な評価を行なえる評価法の確立を目指し作
成したものである。次節以下では、テストセットを用いた評価法の
全体を流れる基本的な考え方、英日機械翻訳用テストセット、日英
機械翻訳用テストセットについて、順次説明していく。

\section{テストセットを用いた機械翻訳システムの品質評価法}

\subsection{本評価法の利点}

これまで、機械翻訳システムの品質評価法として種々の方法が提
案されているが、それらの方法に関しては一貫して客観的評価が困
難であるという指摘が行なわれてきた。本稿ではまず、従来までの
評価法と比べての本評価法の利点を、以下の二つの客観性に基づい
て検討する。\\

\noindent \hspace*{1cm}(1) 評価過程が客観的であること\\
\noindent \hspace*{1cm}(2) 評価結果の判断が客観的に行なえること\\


たとえば、ＡＬＰＡＣレポート等に代表される評価法は、評価の
軸として「忠実度」「理解容易度」といった、その解釈が評価者の
主観的判断に依存する基準を採用している。その結果、評価結果が
評価者によって大きく異なってしまうという問題があり、(１)の
客観性を満たしていない。この評価のばらつきは不完全な翻訳結果
を評価する際に特に顕著に現れるが、現実の機械翻訳システムを評
価し、開発過程にフィードバックする際には、翻訳に成功した場合
よりも失敗した場合についての検討が重要である。

この種の評価法においては評価結果は数値で表現されているため、
ある意味では、(２)の客観性を満たしているともいえよう。しか
しながら開発者にとっては、自己のシステムが、どの言語現象をど
の原因によって処理できなかったのかを判断することが特に重要で
あり、言語現象が複雑に絡みあった文の翻訳結果を単純に得点化す
るだけでは有効とはいえない。システム改良に用いるためにその評
価結果を解釈しようとする場合には主観的な判断に頼らざるを得な
いので、実用的にはこの評価法は(２)の客観性を満たしていると
はいえない。

一方、我々の開発した評価法においては、これら二つの客観性は
共に保たれている。ここでは、単にそれに答えるだけで、システム
開発者が自己のシステムの性能評価を行なえるように作られた yes/no 
設問を各例文に付加することにより、翻訳結果を評価する手続きを
明確化した。評価過程で必要とされる手順は単純な yes/no 疑問文に
答えることだけであり、誰でも機械翻訳システムを同様に評価する
ことが出来る。不完全な翻訳文に対しても、評価者によって評価が
大幅に変わるということはない。

さらに、各例文には翻訳処理と言語現象との関係を表す解説が付
加されており、これにより、システム開発者はなぜ自己のシステム
が問題の言語現象を正しく解析できないのかを知ることが出来る。
すなわち、我々のテストセットに基づく評価結果を用いて、機械翻
訳システムの改良法を決定することが出来る。

機械翻訳システムの評価に関しては、既に述べたように、評価す
べき言語現象を含む文を集めた評価用例文集の作成という試みもな
されている(成田 1988, 池原・小倉 1990, 池原 他 1994)。

このような例
文集を用いれば、もしシステムが、ある例文を正しく翻訳できない
と評価された場合には、システム開発者はただちにその例文が問題
としている言語現象をそのシステムが処理できないということが分
かる。この点において、この手法もまた(２)の客観性を保持して
いる。しかしながら、この手法には以下の二つの問題がある。\\


\begin{itemize}
\item 例文の翻訳結果を評価する手順が明示されていない。
\item 評価結果から機械翻訳システムの不備な点を見つけ出す過程が評価者の言語直観に頼っている。\\
\end{itemize}


例文を集めただけのもの(テストスゥィート(Test Suite))では、
個々のシステムの ad hoc な評価は可能であっても、評価法としては
確立しない。明確に記述された手続きにしたがって、誰でも同じよ
うに機械翻訳システムを評価できることが必要である。この目的の
ために各例文に設問や訳出例を付与しているということを明確にす
る意味で、我々の評価法においては「テストセット(Test Set)」という
名称を用いている。

また、評価結果を機械翻訳システムの改良に用いるためには、さ
まざまな言語現象を単に羅列しておくだけでは不十分である。文法
体系の中での各言語現象の位置づけを明確にしておくことも必要で
ある。

このような考察のもと、我々は上で述べた評価過程の客観性と結
果の判断の客観性という二つの客観性を追求した品質評価を可能と
する品質評価用テストセットを提案してきた。ここで用いるテスト
セットは、考慮すべき文法項目を系統立てて収集し、その各項目に
例文を付加して作られた。各例文に解説や設問を付加することによ
って評価の手順を明確に記述することが可能となった。

各テストセットには、評価用例文、その人間による模範訳、シス
テムの出力(翻訳結果)を評価するための設問などが記述されてお
り、評価者はテストセット中の例文を翻訳し、その翻訳結果を参照
しながら各例文に付与された設問に回答していく。ここで各設問は
判断のポイント(すなわち、例文のどの部分が、どのような役割で、
どのような訳文となっていれば良いか)が明示された yes/no 質問文
であり、評価者によって判断が異なることがないように作られてい
る。この判断をさらに容易にするために、既存の機械翻訳システム
での翻訳結果を用いた回答例が付与されている。以上により評価過
程の客観性を実現している。また、各例文には、その文がどのよう
な言語現象を評価するためのものであるかを説明する解説が付与さ
れており、開発者はその例文に対する翻訳結果から自己のシステム
が十分には対応していない言語現象を容易に理解することが出来る。
これにより、評価結果の判断の客観性を実現できる。


\subsection{本評価法の基本的立場(どのような情報を開発者に与えるか)}

この評価用テストセットは、個々の機械翻訳システムに依存しな
い汎用の品質評価法として作成している。したがって、対象とする
システムがルールベース・知識ベース・用例ベース・直接型といっ
た機械翻訳のどの手法を採用しているかには依存しない。このテス
トセットの目的は機械翻訳システムの開発者が自己のシステムの性
能を向上するために、システムの処理できない言語現象を正確に把
握することである。その言語現象を処理可能にするための手法は、
個々のシステムあるいは個々の手法によって異なっており、その判
断は開発者に任すこととし、評価基準としては、そこには立ち入ら
ない。用例ベースの手法とルールベースの手法に共通する解決策を
評価法が示すということは現実的ではない。

また、個々のシステムによって、対象とする文書が異なっており、
各言語現象の出現頻度も異なっている。したがって、システムの欠
点のうちで、どの欠点が最も重大であるかを決定することは、当事
者にのみ可能なことである。本テストセットの目標は、その当事者
の判断を可能な限り援助することにある。ここではテストセット中
の各例文には、頻度に関する情報を記述するのではなく、その例文
が判断する言語現象を記述してある。翻訳対象となる文書が特定の
言語現象に偏っている場合には、評価者はこのテストセットのうち
で、必要な言語現象に対応する部分についてのみ翻訳し、その結果
を評価すれば良い。自分にとって重要な言語現象を取り扱えるかど
うかが、個々の開発者あるいはユーザがシステムを評価する場合に
は重要であり、評価法としての独自の頻度による一般的な得点化を
行なうのは、むしろ誤った評価の原因になると考える。

また、評価に例文を用いることについては、その例文に対して高
い評価が出るようにシステムを修正することが可能であること、ま
た、全ての言語現象を網羅できるわけではないことなどの問題点が
指摘される。しかしながら、ここで提案する評価法はシステム間の
相対的な性能評価のために用いるものではない。開発者が自己のシ
ステムの改良のために、その欠点を把握することが目的であり、こ
の本来の目的のためには本テストセットに対してチューニングをす
ることに意味はない。また、本テストセットは単なる例文集ではな
く、各例文にはその対象とする言語現象が解説されており、さらに
は必要に応じて関連文と、その模範訳が付加されている。これらの
文を翻訳し検討することにより、単に一つの例文を処理できるかど
うかを判断するだけではなく、その例文に関連する言語現象につい
ての処理能力も知ることが出来る。

さらに、個々の開発者が処置するべき問題として、テストセット
中の例文に存在する未定義語の問題がある。例文中に(そのシステ
ムにとっての)未定義語があった場合には、評価者は例文中に現れ
た未定義語を辞書登録するか、あるいは例文中の未定義語を既にシ
ステムに登録されている類似の単語に変更することが要求される。
繰り返すが、この評価法はシステム間の優劣を決めることが目的で
はなく開発者が自分のためにシステムの欠陥を見つけて、それを修
正することを主たる目的としている。したがって、評価者(すなわ
ち開発者)は単純に評価結果を受け入れるのではなく、「翻訳に成
功しているが偶然良い訳語が記述されていただけだ。」「翻訳に失
敗したが、それはその単語が未定義であったためで、類似の現象自
体は取り扱う能力がある。」等については、各自の(自己のシステ
ムについての)知識に基づいて判断する必要がある。

また、評価の結果、さまざまな欠陥が見つかった場合に、限られ
た人的資源の中で、どのような順序でそれを解決していくかという
問題もある。しかしながら、各開発者毎に資源の制約や、そのシス
テムが主として対象とする文書(あるいは、対象とする言語現象)
が異なるため、一般的な優先順位を予め定めておくことは現実的で
はない。本テストセットは、比較的近い将来に正しい処理の実現が
可能な言語現象に重点をおいて作っているが、取り扱えなかった言
語現象の内で、まずどの現象を処理可能にするかという優先順位付
けは、個々のシステムの開発者に任せられている。

なお、このように近い将来に対応できるものに重点を置いて言語
現象を収集しテストセットとした場合、機械翻訳システムの技術水
準の向上に伴って、対象とする言語現象を継続的に追加あるいは削
除していくことが望まれる。常にその時点で機械翻訳において問題
となっている言語現象を１０００文程度のテストセットで示すのが
理想であろう。ただし、最低限の解析能力を試すための基本的な構
造の文は現在も(そのような基本的な構造の解析は既にほとんどの
システムにおいて解決されている問題であるとしても)テストセッ
ト中に含まれている。このような基本文はシステムの最低水準を保
証するものとして、将来に亙ってもテストセットに含まれると想定
している。

\subsection{評価用例文の収集}

テストセットの例文は機械翻訳システムや自然言語処理システム
を実際に開発してきた経験に基づいて、著者らによって収集された。
例文の収集に当たっては、我々は以下の２点を重視した。\\


\noindent(1) 基本的な言語現象を網羅すること。\\
\noindent(2) 機械翻訳システムにとって処理することが困難な言語現象を含む例文を選択すること。\\
　　ここでは特に曖昧性の問題を重視した。\\


言い替えると、(１)は評価すべき文法現象を系統立てて収集分
類(トップダウンの手法)し、それらの現象に対応する例を集める
ことである。一方(２)は機械翻訳システムによって翻訳すること
が困難であるような例文を収集する(ボトムアップの手法)ことで
ある。特に我々は処理の困難さが近い将来に解決できるであろうよ
うな言語現象に注目した。そして機械翻訳システムの評価のための
例文を系統立てて分類した。さらに、我々はこれらの例について、
いくつかの商用システムを用いて翻訳評価実験を繰り返し、テスト
セットを以下の点に焦点を当てながら改良した。これらは全て、評
価過程において客観性を維持するために重要な要素である。\\


\begin{itemize}
\item 設問に曖昧性がないこと
\item 例文に不必要な複雑さがないこと
\item 翻訳結果に曖昧性がないこと\\
\end{itemize}


なお、テストセット中の英文は、その英語としての品質を保証す
るため、英語を母国語とし、日本語を理解する自然言語処理研究者
によって、チェックされ修正された。

なお、このテストセットを用いた品質評価法の提案の主旨と、作
成の詳しい経緯については、参考文献
(井佐原 他 1992, 日本電子工業振興協会 1993, 日本電子工業振興協会
1994, Isahara et al 1994, 日本電子工業振興協会 1995a, Isahara 1995)
を参照されたい。また、
テストセットの全容は、参考文献(日本電子工業振興協会 1995b)に示されている。


\section{英日機械翻訳システム品質評価用テストセット}

本節では、英日機械翻訳システムの品質評価用テストセットに
ついて説明する。このテストセットは、機械翻訳システムが処理す
べき様々な言語現象を含んだ英語例文770文とその模範訳、及びシス
テムの出力(翻訳結果)を評価するための設問などからなる。

\subsection{概要}

我々は、英日機械翻訳システムの評価基準として、システム開発
者が自己のシステムの不備をチェックすることを主要目的とした品
質評価用テストセットを作成した。本テストセットにおける例文の
収集に際しては、「基本的な言語現象を網羅すること」「機械翻訳
システムが取り扱うことが困難な言語現象を、主に曖昧性の解消に
注目して収集・分類すること」を試みた。また、システムの出力(翻
訳結果)を見ながら回答していくことで品質に関する客観的な判断
が可能となるように、各文に判断のポイントを明示したyes/no疑問文
の形式の設問を付与している。このように本テストセットは客観的
な品質評価の実現を目指して作成したものなので、ユーザが各機械
翻訳システムの出力品質を比較する際に利用することも可能である。

本テストセットの作成作業は、平成４年度からの３年間で行った。
平成５年度末までに第１段階として、英語の単文を中心に評価すべ
き項目を抽出して評価基準を設定し、309の基本例文を収集・評価し
て「電子協平成５年度版テストセット」としてまとめた。これに加
えて、今回さらに以下の作業を行って項目の充実を図った。\\


\begin{itemize}
\item 
平成５年度版テストセットが単文中心だったのに対して、接続詞、
関係詞、比較、話法、挿入、並列など、より複雑な構造を持つ複
文・重文に関連する項目を重点的に英文法の解説書などから抽出
して収集
\item 
複数の文法書などを参考にすることにより、単文内の項目に関し
ても、平成５年度版テストセットでカバー出来ていない項目を収
集。特に、代名詞、前置詞、記号、数量表現などに関して新規の
設問を多数作成
\item 
文法項目の洩れを防ぐため、英字新聞から英文テキスト300文を選
出して市販の英日機械翻訳システムで試訳し、翻訳が困難となる
問題点を抽出\\
\end{itemize}

上記の作業により、これまでの309項目と併せて延べで約1000の項目
を抽出した。最終的にこれを整理して、770項目からなるテストセッ
トとしてまとめた。例文と関連文を合わせると、合計で1450文ほど
の規模のテストセットとすることが出来た。

また、本テストセットの実用性の検証と設問の修正のために、ハ
ードウェアタイプの異なる８種の市販の英日機械翻訳システムを対
象とした評価を行った。

このテストセット中の各項目は、文番号、例文、その模範訳、○
×で答えることが出来る質問文、主として機械翻訳システムによる
訳出例、例文と関連する言語現象を含む文、関連する項目の番号、
解説から成り立っている。テストセットの例を図１に示す。以下で
は、このテストセットを用いた品質評価の手順、対象とする言語現
象、テストセットの書式について述べる。

\vspace*{1em}
\begin{small}
\begin{verbatim}
　２．１．１　多品詞（品詞認定）
　２．１．１．２　名詞/助動詞

　【番号】　2.1.1.2-1
　【例文】　The trash can was thrown away.
　【訳文】　ごみカンは捨てられた。
　【質問】　"can" が「カン/缶」のように名詞として訳されていますか？
　【訳出例】○ (くず缶/ごみ容器/くず入れ)は(廃棄された/[投げ]捨てられた)。
　　　　　　× ごみは捨てられ得る。
　【関連文】The last will was opened.「最後の遺言書は開けられた。」
　【参照項目】2.1.1.2-2, 2.1.1.2-3
　【解説】　"can was" の並びから、"can" が助動詞でないことがわかる。
　
　【番号】　2.1.1.2-2
　【例文】　The trash can be thrown away.
　【訳文】　ごみは捨てられ得る。
　【質問】　"can" が「〜できる/得る」のように助動詞として訳されていますか？
　【訳出例】○ (くず/ごみ/くだらない人間)は(廃棄できる/[投げ]捨てられることができる)。
　　　　　　× ごみカンは捨てられた。
　【関連文】
　【参照項目】2.1.1.2-1, 2.1.1.2-3
　【解説】　2.1.1.2-1とは逆に、ここでは "can" は名詞ではなく助動詞。
\end{verbatim}
\end{small}

{\bf　　　　　　　　図１　英日機械翻訳システム用テストセットの例}

\vspace*{1em}

\subsection{テストセットの利用法}

　本テストセットは、以下の利用法を想定している。\\

\noindent(1) 評価対象となる英日機械翻訳システムを用意する。\\
\noindent(2) そのシステムでテストセット中の【例文】を翻訳する。\\
\noindent(3) 【質問】【訳出例】を見て、その翻訳結果が○か×かを判断する。\\
\noindent(4) システム開発者は、○×の分布からシステムの能力、開発段階を評価する。\\
　　特に、×と判断した項目に関連する文法・辞書を追加することで、システムの改良を図る。\\
\noindent( (5) ユーザは、各システムの○×の分布から、出力品質面での優劣を比較する。)\\
\noindent(6)各項目についてさらに詳細に評価を行う場合は、【関連文】を利用する。\\


原則として翻訳結果と質問文を見るだけで○×を回答出来るよう
になっているが、【訳出例】(各訳出例には、質問に対する○×が
予め付与されている)を参照することによって、さらに容易に判断
が出来るようになっている。

本テストセットを用いて○×の分布を見ることで、システムの対
応が不十分な(可能性がある)項目を容易に抽出できる。ただし本
テストセットでは、各項目(例文)間の重要度、頻度などの差異は
考慮していないので、単純に○の数をカウントして正解率をシステ
ム間で比較することは、本評価法の意図するところではない。

\subsection{テストセットの構成}

本テストセットは、機械翻訳システムが処理すべき様々な言語現
象を含んだ英語例文770文からなる。内訳と項目ごとの設問数を図２
に示す。

品質評価の対象項目の収集に当たっては、網羅性を保証するトッ
プダウンのアプローチと、機械翻訳における問題点を実際の翻訳結
果から抽出して、その問題性によって例文の粗密を決定するボトム
アップなアプローチを組み合わせている。

把握部においては、英文法の解説書
(江川 1964, Hornby 1977, 小川 他 1991, 荒木 他 1992, 村田 1992)
などを参考に英語の文法現象を
収集し、そのレベルによって、品詞、文の部分構造、文構造の３段
階に分類した。特に動詞、形容詞、名詞に関してその基本的な用法
を網羅するために、ホーンビーの分類した文型(Hornby 1977)を設
問項目として採用した。ただしホーンビーのパターンの中でも、機
械翻訳システムの品質評価において特に必要でないとみなした区分
については分類を省略している。同様に助動詞等の基本的な用法の
中でも、機械翻訳において対象となることが極めて稀であると思わ
れるものについては省略した。

選択部においては、翻訳で実際に問題となる言語現象を、構文構
造の曖昧性に関するものと、コロケーション(他の語との共起によ
る訳し分け)に関するものに分類した。

\begin{figure}
\begin{small}
\begin{verbatim}


　　１　把握部　　　　　　　　　　　　　　　　　　　　　　　　　　 小計684
　　　　１．１　品詞　　　　　　　　　　　　　　　　　　　　小計355
　　　　　　１．１．１　　冠詞　　　　　　　　　　　　　　15
　　　　　　１．１．２　　名詞（固有名詞を含む）　　　　　27
　　　　　　１．１．３　　代名詞　　　　　　　　　　　　　25
　　　　　　１．１．４　　形容詞　　　　　　　　　　　　　42
　　　　　　１．１．５　　副詞　　　　　　　　　　　　　　54
　　　　　　１．１．６　　前置詞　　　　　　　　　　　　　40
　　　　　　１．１．７　　動詞類　　　　　
　　　　　　　　１．１．７．１　動詞・準動詞　　　　　　　48
　　　　　　　　１．１．７．２　助動詞　　　　　　　　　　37
　　　　　　１．１．８　　関係詞　　　　　　　　　　　　　25
　　　　　　１．１．９　　接続詞　　　　　　　　　　　　　26
　　　　　　１．１．１０　記号　　　　　　　　　　　　　　16
　　　　１．２　文の部分構造　　　　　　　　　　　　　　　　小計167
　　　　　　１．２．１　　不定詞　　　　　　　　　　　　　26
　　　　　　１．２．２　　分詞、分詞構文　　　　　　　　　19
　　　　　　１．２．３　　動名詞　　　　　　　　　　　　　23
　　　　　　１．２．４　　時制　　　　　　　　　　　　　　63
　　　　　　１．２．５　　数量表現　　　　　　　　　　　　28
　　　　　　１．２．６　　慣用表現　　　　　　　　　　　　 8
　　　　１．３　文構造　　　　　　　　　　　　　　　　　　　小計162
　　　　　　１．３．１　　文種（疑問文、命令文、感嘆文）　19
　　　　　　１．３．２　　否定　　　　　　　　　　　　　　16
　　　　　　１．３．３　　特殊構文　　　　　　　　　　　　19
　　　　　　１．３．４　　比較　　　　　　　　　　　　　　21
　　　　　　１．３．５　　仮定法（条件法）　　　　　　　　16
　　　　　　１．３．６　　態　　　　　　　　　　　　　　　10
　　　　　　１．３．７　　話法　　　　　　　　　　　　　　 4
　　　　　　１．３．８　　挿入　　　　　　　　　　　　　　16
　　　　　　１．３．９　　省略　　　　　　　　　　　　　　 9
　　　　　　１．３．１０　倒置　　　　　　　　　　　　　　 7
　　　　　　１．３．１１　並列句　　　　　　　　　　　　　25
　　２　選択部　　　　　　　　　　　　　　　　　　　　　　　　　　 小計 86
　　　　２．１　構文
　　　　　　２．１．１　　多品詞（品詞認定）　　　　　　　34
　　　　　　２．１．２　　係り先認定　　　　　　　　　　　27
　　　　２．２　コロケーション　　　　　　　　　　　　　　25
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　総計７７０

\end{verbatim}
\end{small}
{\bf　　　　　　　　図２　テストセットの全体構成、項目別設問数}

\end{figure}



\subsection{テストセットの書式}

本テストセットの各項目の書式を図３に示す。なお、テストセッ
ト中で、[ ]で囲まれた部分は挿入可能な表現を、 ( / )で囲まれた部分
はいずれかを選択する表現を示す。たとえば、"Ａ[Ｂ]Ｃ(Ｄ/Ｅ)Ｆ"と
いう記号列は、``ＡＢＣＤＦ'', ``ＡＢＣＥＦ'', ``ＡＣＤＦ'',
``ＡＣＥＦ'' 
の４種の記号列を表す。

\begin{figure}
\begin{verbatim}
【番号】　　：例文の番号
【例文】　　：例文（１文のみ）
【訳文】　　：模範訳（例文の日本語訳）
【質問】　　："Ａ" が「Ｂ」のようにＣとして訳されていますか？という形式の質問文
　　　　　　　・Ａ：英語表現。" "で囲む。例文中のどの部分を翻訳することにポイン
　　　　　　　　　　トがあるのかを表す。文全体の場合、また明らかな場合などは省略
　　　　　　　　　　する。
　　　　　　　・Ｂ：日本語表現。「 」で囲む。
　　　　　　　・Ｃ：内容や文法事項の補足説明（「習慣を表す表現」、「選択疑問文」
　　　　　　　　　　等）を記す。記述が長くなるものや、原因に言及する場合は、【解
　　　　　　　　　　説】に記述する。
　　　　　　　※必ず○か×か（yes/no）で答えられる形式にする。
　　　　　　　　本テストセットは作業者が翻訳結果（訳文）を見るだけで○×を与える
　　　　　　　　ことを前提としており、解析の詳細に直接言及することは避ける。
【訳出例】　：許容される訳出例や誤訳例を列挙。
　　　　　　　・正解例（yes）の文頭には○、誤例（no）の文頭には×を付与する。
　　　　　　　・１行１文とし、原則として文全体を記述。
　　　　　　　・必要ならば正／誤の理由（説明）も示す。
　　　　　　　※各例は実際の機械翻訳システムの訳を参考にして作成した。
【関連文】　：当該の例文と関連する言語現象を含んだ例文を挙げる。
　　　　　　　・文の一部だけの記述は認めない。必ず文全体を記述する。
　　　　　　　・例文の後に、「 」で囲んだ訳文を記述する。
　　　　　　　・補足事項（may/mightでの丁寧度の違いなど）がある場合は、訳文の後
　　　　　　　　に（ ）で囲んで記述する。
【参照項目】：本テストセット内の関連項目への参照ポインタ。原則として、相互参照と
　　　　　　　する。
　　　　　　　※文番号を明示するのみで、文そのものは記述しない。
【解説】　　：その他の補足事項。フリーフォーマット。

\end{verbatim}
{\bf　　　　　　　　図３　テストセットの書式}

\end{figure}

\section{日英機械翻訳システム品質評価用テストセット}

日英翻訳システム品質評価用テストセットも英日翻訳システム用
と同様に、開発者が自己のシステムの不備な点を発見するための評
価法であり、テストセット中の各例文に付与された設問に答えるこ
とによって、客観的に評価を下せるように作られている。しかしな
がら、英日翻訳と日英翻訳の技術レベルの違いに基づいて、英日用
のテストセットとは少し異なった視点でテストセットの開発を行な
った。実際のテストセットの例を図４に示す。

\begin{figure}
\begin{small}
\begin{verbatim}

JET140000 （１−４）複合述部
JEX140000 複合述部では、並列用言の認識を行ない、また用言部と格要素・副詞句とを
JEX140000 区別して翻訳しなければならない。
JEQ141000 複合述部の並列用言としての認定
JEX141000 複合述部の並列用言を認識するには、
JEX141000   ・助詞の種類により判断する
JEX141000   ・助詞の種類と名詞の意味属性により判断する
JEX141000   ・用言性の単語が並んでいれば、並列用言と認定する
JEX141000 等といった方法がある。
JEG141001 私達は研究開発する。
JEE141001 We do research and development.
JEE141001 We are carrying out research and development.
JEC141001 (失敗例) We study it ‖ develop it.
JEC141001 (失敗例) We develop a research.
JEC141001 「私達は研究開発する」の「研究開発」が「研究し開発する」という意味に
JEC141001 訳出されるかを確認する。
JEX141001 読点で切られている場合でも、前半はサ変名詞を動詞化する「する」が記述
JEX141001 されないことがある。
JEG141002 検査者は部品を修理、計器を点検する。
JEE141002 The tester repairs the parts and checks the meter.
JEQ142000 複合述部の要素の格要素としての認定
JEX142000 複合述部の要素を格要素として認識するには、
JEX142000   ・複合語要素間の関係を用言と格要素への意味的制約により解析する
JEX142000   ・用言性の部分とそれ以外の部分を判断してデフォルト的に格関係を推定する
JEX142000 等の方法がある。
JEG142001 牛乳は栄養豊富である。
JEE142001 Milk is very nutritious.
JEE142001 Milk is very rich in nutrition.
JEC142001 「牛乳は栄養豊富である」の「栄養」と「豊富」から
JEC142001 「牛乳の栄養が豊富である」という関係を捉える。
JEQ143000 複合述部の要素の副詞句としての認定
JEX143000 複合述部の要素を副詞句として解釈する場合がある。これを行うには、
JEX143000   ・語の種類により副詞句となりえる要素を複合語より抽出する
JEX143000   ・用言性の部分と副詞句となりえる部分との共起可能性を判断し、決定する
JEX143000 等の処理が必要となる。
JEG143001 資料は当日配布すること。
JEE143001 Distribute materials on the day.
JEC143001 「当日に配布する」というように「当日」が述部修飾になっているか確認する。
JEG143002 渋滞が自然解消する。
JEE143002 The traffic jam dissolved by itself.
JEC143002 「自然に解消する」のように、「自然」が副詞として解釈されているか確認する。
JEC143002 複合述部が同一の要素を含んでいても、述部によりその要素の
JEC143002 役割が異なってくる場合がある。
JEG143003 住民が自然保護する。
JEE143003 The inhabitants conserve nature.
JEC143003 「自然を保護する」と「自然」が目的格に捉えられているか確認する。

\end{verbatim}
\end{small}

{\bf　　　　　　　　　　図４　日英機械翻訳システム用テストセットの例}

\end{figure}

我々は、客観的評価を実現するテストセットの採用に加えて、日
本語処理システムの開発者の利便を考え、言語現象と処理モジュー
ルとの対応を取ることができる形式の評価方法の開発を行なった。
すなわち、評価用例文と、その翻訳結果を評価する手段(設問)を
提供するだけでなく、各言語現象に対応してシステムがどのような
処理を行なっているかを把握するための解説も付与している。解説
によって示される言語現象の処理方法を利用して開発者は、そのシ
ステム全体としての言語現象の処理能力を評価するとともに、処理
の各段階が充分な能力を持っているかどうかを把握できる。

具体的には言語現象を約４０種類に大別し、その各項目について
問題となっている言語現象をどのように処理しているかを調べるた
めの解説が付加されている。言語現象の項目リストを図５に示す。
ここでは必要に応じて、用いている知識や処理結果の取り扱い等も
併せて説明される。各項目内の個別の言語現象については、その言
語現象を含む日本語文、その英訳、ここで確認するべき要素の解説
が記述されている。設問数は約３３０、機能確認のための対訳例は、
約４００文の構成となっている。

\begin{figure}
\begin{footnotesize}
\begin{verbatim}

　　　　 （１）述部
　　　　　 （１−１）述部の訳し分け
　　　　　 （１−２）断定文
　　　　　 （１−３）体言述語
　　　　　 （１−４）複合述部
　　　　　 （１−５）訳が一用言となる並列用言
　　　　　 （１−６）用言の副詞（句）化
　　　　　 （１−７）補助動詞
　　　　　 （１−８）基本動詞の訳し分け
　　　　 （２）名詞
　　　　　 （２−１）名詞の訳し分け
　　　　　 （２−２）複合名詞
　　　　　 （２−３）「名詞１の名詞２」という構造を持つ名詞句の処理
　　　　　 （２−４）「名詞１の名詞２の〈名詞３〉」という構造を持つ名詞句の処理
　　　　　 （２−５）並列構造を持つ名詞句の処理
　　　　　 （２−６）疑問表現の名詞節の処理
　　　　　 （２−７）用言性名詞（サ変名詞）
　　　　　 （２−８）英語における数の扱い
　　　　　 （２−９）固有名詞表現
　　　　　 （２−１０）形式名詞
　　　　　 （２−１１）関係を示す名詞
　　　　 （３）副詞
　　　　　 （３−１）副詞のタイプ
　　　　　 （３−２）副詞句
　　　　　 （３−３）擬音語・擬態語
　　　　 （４）連体修飾語句
　　　　　 （４−１）非活用連体修飾
　　　　　 （４−２）用言性連体詞
　　　　　 （４−３）格助詞相当句
　　　　　 （４−４）埋め込み文修飾
　　　　 （５）助詞
　　　　　 （５−１）助詞の訳し分け
　　　　　 （５−２）深層格の認定
　　　　 （６）接辞
　　　　 （７）テンス、アスペクト、モーダル
　　　　　 （７−１）テンスの処理
　　　　　 （７−２）アスペクトの処理
　　　　　 （７−３）モーダルの処理
　　　　　 （７−４）ボイスの処理
　　　　 （８）特殊構造表現
　　　　　 （８−１）慣用表現の処理に関して
　　　　　 （８−２）四字熟語
　　　　　 （８−３）呼応表現
　　　　　 （８−４）天候・気象表現
　　　　　 （８−５）無生物主語構文
　　　　　 （８−６）「はが」構文
　　　　　 （８−７）比較表現
　　　　　 （８−８）比喩表現
　　　　　 （８−９）部分否定、二重否定、倒置文
　　　　　 （８−１０）敬語
　　　　　 （８−１１）引用・伝聞表現
　　　　　 （８−１２）例示・列挙表現

\end{verbatim}
\end{footnotesize}
{\bf　　　　　　　　　　　図５　テストセットの項目リスト}

\end{figure}

また、開発者がこのテストセットを使用する際の利便性を考え、
テストセットの書式を揃え、各文にインデックスをつけることによ
り、機械上での検索を容易に行なえるようにした。上記の各項目に
付けられたインデックスは基本的に図６のような構造である。図６
の??????の部分には、数字またはアルファベットが使用される。最初
の２文字がタイトルまたはサブタイトルの章番号を表す。次の３文
字が、各項目中の設問に付与された番号であり、設問は最大３階層
になっている。最後の１文字が例文及び翻訳例の文番号を示す。解
説、コメントはその対象とする項目と同じ文番号となる。

\begin{figure}
\begin{small}
\begin{verbatim}
　　   JET?????? 項目タイトル
　　   JEX?????? 全体的な解説・説明
　　   JEQ?????? 設問（着目すべき主題）
　　   JEX?????? 主題に対する解説（省略されることもある）
　　   JEG?????? 日本文
　　   JEE?????? 英文対訳例
　　   JEC?????? 訳例に対するコメント（チェックすべきポイント, 失敗例）
\end{verbatim}
\end{small}
{\bf　　　　　　　　　　　図６　インデックスの構造}\\

\end{figure}


これらのインデックスを検索のキーとして、各種のＯＳの検索コ
マンドを使用することにより、機械翻訳にかけるための原文のみの
抽出や、項目リストの抽出など、簡単に必要な部分だけを抜きだし
て使用することが出来る。使用例を図７に示す。

\begin{figure}
\begin{small}
\begin{verbatim}

【使用例】 （日英評価基準のファイル名が MT_EVAL_JE.doc であるとする）

・まず文法項目の目次を調べる。

　　　　$ grep JET  MT_EVAL_JE.doc
　　　　‾‾‾‾‾‾‾‾‾‾‾‾‾‾
　　　　JET100000 （１）述部
　　　　JET100000 （１−１）述部の訳し分け
　　　　JET120000 （１−２）断定文
　　　　JET130000 （１−３）体言述語
　　　　JET140000 （１−４）複合述部
　　　　　　　　　　　　　　：

・（１−４）の「複合述部」にどのような設問があるかを調べる。

　　　　$ grep JEQ14  MT_EVAL_JE.doc
　　　　‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
　　　　JEQ141000 複合述部の並列用言としての認定
　　　　JEQ142000 複合述部の要素の格要素としての認定
　　　　JEQ143000 複合述部の要素の副詞句としての認定

・次に「副詞句」のところにどのような例文があるか調べる。

　　　　$ grep JEG143  MT_EVAL_JE.doc
　　　　‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
　　　　JEG143001 資料は当日配布すること。
　　　　JEG143002 渋滞が自然解消する。
　　　　JEG143003 住民が自然保護する。

・例文の参考訳を調べる。

　　　　$ grep JEE143 MT_EVAL_JE.doc
　　　　‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
　　　　JEE143001 Distribute materials on the day.
　　　　JEE143002 The traffic jam dissolved by itself.
　　　　JEE143003 The inhabitants conserve nature.

・例文 JEG143001 が何を調べたいの例文なのかを調べる。

　　　　$ grep JEC143001 MT_EVAL_JE.doc
　　　　‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
　JEC143001 「当日に配布する」というように「当日」が述部修飾になっているか確認する。

・例文 JEG143001 をＭＴで訳させた結果が、コメント JEC143001 の確認事項を満たして
　いれば評価結果を ○ 、さもなければ評価結果を × とする。
　（JEE143001 は参考訳であり、必ずしもその通りの訳になっていなくとも良い）

\end{verbatim}
\end{small}
{\bf　　　　　　　　図７　テストセットの機械上での使用例}
\end{figure}


\section{おわりに}

本稿では、機械翻訳システムの翻訳品質を開発者の視点から評価
する手法を提案した。この手法は、評価用の各例文に質問と解説を
付加したテストセットを用いることにより評価過程を明確化した客
観的品質評価法である。本稿で提案したテストセットは、評価用の
例文に、その人間による訳、システムの出力を評価するための設問、
(もしあった場合には)関連する文、文法事項の解説等を付与した
ものである。例文は基本的な言語現象と、機械翻訳において現在課
題となっている言語現象を網羅することを念頭において収集された。

テストセット中の設問は評価するべき点を明確にするように作成
されている。各例文の翻訳結果が与えられると、システム開発者は
その例文に付与されている設問に答えていくだけで、自己のシステ
ムの評価を行なうことが出来る。設問は○×式であり、評価者によ
って判断が分かれないように作られている。これにより、客観的な
評価が可能となる。さらに、解説を参照することにより、システム
開発者は自己のシステムがどの言語現象を処理できないかを正確に
認識することが出来る。

ここで提案した英日及び日英翻訳システム用のテストセットは無
料で一般に公開されている。我々は、この評価法が機械翻訳システ
ムの一層の発展の一助となることを期待してやまない．\\


\clearpage

\begin{thebibliography}{99}

\bibitem{}
荒木一雄 他 (1992). 現代英文法辞典. 三省堂.
\bibitem{}
江川泰一郎 (1964). 英文法解説(改訂新版). 金子書房.
\bibitem{}
Hornby, A. S. (1977). 英語の型と語法(第２版). オックスフォード大学出版局(東京).
\bibitem{}
池原悟・小倉健太郎 (1990). ``日英機械翻訳における機能試験項目の検討.''
電子情報通信学会１９９０年秋期全国大会論文集 D-68.
\bibitem{}
池原悟 他 (1994). ``言語表現体系の違いに着目した日英機械翻訳機能試験項目の構成.''
人工知能学会誌, {\bf 9} (4).
\bibitem{}
井佐原均 他 (1992). ``ＪＥＩＤＡ機械翻訳システム評価基準(品質評価編)−英日翻訳の品質評価項目の検討と評価用コーパスの作成−.''
自然言語処理研究会 96-11, 情報処理学会.
\bibitem{}
Isahara, H. et al (1994).
``Technical Evaluation of MT Systems from the Developer's Point of View: Exploiting Test-Sets for Quality Evaluation,''
In {\em Proceedings of the AMTA-94 (First conference of the Association for Machine Translation in the Americas)}.
\bibitem{}
Isahara, H. (1995).
``JEIDA's Test-Sets for Quality Evaluation of MT Systems -- Technical Evaluation from the Developer's Point of View.''
In {\em Proceedings of the MT Summit V}.
\bibitem{}
石崎俊・井佐原均 (1988).
``日本語文の複雑さの定性的・定量的特徴抽出.''
自然言語処理研究会 67-6, 情報処理学会.
\bibitem{}
村田勇三郎 (1992). 機能英文法. 大修館書店.
\bibitem{}
成田一 (1988). ``機械翻訳における構造処理能力の評価.''
自然言語処理研究会 69-1, 情報処理学会.
\bibitem{}
日本電子工業振興協会 (1985). ``機械翻訳例文資料.''
機械翻訳システムの調査研究 60-C-513.
\bibitem{}
日本電子工業振興協会 (1988). 機械翻訳システムの調査研究.
\bibitem{}
日本電子工業振興協会 (1993). 機械翻訳システムの実用化に関する調査研究 93-計-6.
\bibitem{}
日本電子工業振興協会 (1994). 自然言語処理技術の動向に関する調査報告書 94-計-4.
\bibitem{}
日本電子工業振興協会 (1995a). 自然言語処理技術の動向に関する調査報告書 95-計-3.
\bibitem{}
日本電子工業振興協会 (1995b).
機械翻訳システム評価基準−−品質評価用テストセット−− 95-計-17.
\bibitem{}
野村浩郷・井佐原均 (1992). ``機械翻訳の評価基準について.''
自然言語処理研究会 89-9, 情報処理学会.
\bibitem{}
Nomura H. and H. Isahara (1992a). ``JEIDA's Criteria on Machine Translation Evaluation.''
In {\em Proceedings of the International Symposium on Natural Language Understanding and AI}.
\bibitem{}
Nomura H. and H. Isahara (1992b). ``JEIDA Methodology and Criteria on
Machine Translation Evaluation.'' 
In {\em Proceedings of the MT Evaluation Workshop}.
\bibitem{}
小川芳男 他 (1991). よくわかる英文法[再訂新版]. 旺文社.
\bibitem{}
Tomita M. (1992). ``Application of the TOEFL Test to the Evaluation.''
In {\em Proceedings of the MT Evaluation Workshop}.
\bibitem{}
White, J. S. et al. (1994). ``The ARPA MT Evaluation Methodologies: Evolution, Lessons, and Future Approaches.''
In {\em Proceedings of the AMTA-94 (First conference of the As- sociation for Machine Translation in the Americas)}.

\end{thebibliography}


\begin{biography}
\biotitle{略歴}
\bioauthor{井佐原 均}{
1978年京都大学工学部電気工学第二学科卒業. 
1980年同大学院修士課程修了. 工学博士. 
現在, 郵政省通信総合研究所関西支所知的機能研究室長. 
自然言語処理, 機械翻訳の研究に従事. }

\bioauthor{内野 一}{
1987年茨城大学工学部情報工学科卒業. 
1989年同大学院修士課程修了. 
現在, ＮＴＴコミュニケーション科学研究所研究主任. 
自然言語処理, 機械翻訳の研究に従事. }


\bioauthor{荻野 紫穂}{
1988年東京女子大学大学院文学研究科修士課程修了. 
現在, 日本ＩＢＭ東京基礎研究所に勤務. 
自然言語処理, 機械翻訳の研究に従事. }

\bioauthor{奥西 稔幸}{
1984年大阪大学基礎工学部情報工学科卒業. 
現在, シャープ株式会社情報システム事業本部情報商品開発研究所に勤務. 
機械翻訳システムの研究開発に従事. }

\bioauthor{木下 聡}{
1983年東京工業大学工学部情報工学科卒業. 
1985年同大学院修士課程修了. 
現在, (株)東芝研究開発センター情報・通信システム研究所に勤務. 
自然言語処理, 機械翻訳の研究に従事. }

\bioauthor{柴田 昇吾}{
1985年早稲田大学理工学部電子通信学科卒業. 
1987年同大学院修士課程修了. 
現在, キヤノン株式会社情報メディア研究所に勤務. 
自然言語処理の研究に従事. }

\bioauthor{杉尾俊之}{
1982年熊本大学工学部電子工学科卒業. 
現在, 沖電気工業(株)研究開発本部関西総合研究所に勤務. 
機械翻訳システム, 自然言語処理の研究開発に従事. }

\bioauthor{高山 泰博}{
1985年九州工業大学工学部情報工学科卒業. 
1987年九州大学大学院修士課程修了. 
現在, 三菱電機(株)情報技術総合研究所に勤務. 
自然言語処理の研究に従事. }

\bioauthor{土井 伸一}{
1985年東京大学教養学部基礎科学科第二卒業. 
1990年同大学院総合文化研究科博士課程満期退学. 
現在, 日本電気(株)情報メディア研究所音声言語研究部主任. 
自然言語処理, 機械翻訳の研究開発に従事. }

\bioauthor{永野 正}{
1987年慶応義塾大学電気工学科卒業. 
1989年同大学院修士課程修了. 
現在松下通信工業(株)カーシステム事業部に勤務. }

\bioauthor{成田 真澄}{
1987年津田塾大学大学院修士課程修了. 
(株)リコー情報通信研究所に勤務. 
機械翻訳の研究に従事. }

\bioauthor{野村 浩郷}{
1967年大阪大学工学部通信工学科卒業. 
1969年同大学院修士課程修了. 工学博士. 
日本電信電話公社基礎研究所を経て, 現在, 九州工業大学情報工学部教授. 
言語知能, 知能ネット, 計算言語学, 機械翻訳の研究に従事. }

\bioreceived{受付}
\bioaccepted{採録}

\end{biography}

\end{document}
