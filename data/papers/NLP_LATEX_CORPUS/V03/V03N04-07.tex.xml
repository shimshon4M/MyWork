<?xml version="1.0" ?>
<root>
  <title>日本語の文法および未知の認知単位の自動獲得のための一方法</title>
  <author>横田和章亀田弘之藤崎博也</author>
  <jabstract>筆者らは,コーパスに基づいて形態素を基本とした日本語文法を自動獲得する方法を既に提案している.本論文は，この方法における処理単位として，形態素の代わりにより長い単位---認知単位---を用いた新しい方法を提案するものである．認知単位は，人間を被験者とした知覚実験の結果から得られた人間の文解析の単位である．こうした，形態素より長い単位を解析に用いることにより，構文解析における経路数を抑えることができる．しかし，単純に認知単位を辞書に登録して用いるだけでは，未知認知単位の出現確率が高まり，結果として文解析の正解率が低下する．この現象を抑えるため，既知認知単位から未知認知単位を推定する新しい方法を更に取り入れた．この方法で天気概況文コーパスを処理し，得られた文法に基づき構文解析を行った結果，形態素を処理単位とした解析に比べ高い処理効率を得ることができた．</jabstract>
  <jkeywords>構文解析，コーパス，文脈自由文法，シミュレーテッド・アニーリング法，認知単位</jkeywords>
  <subsection title="">*[天気概況文における機械処理用の認知単位の定義][認知単位=.]ただし，複合語は1つの自立語として扱う．また，活用する語については活用語尾も含めて1つの自立語とする．補助的な語は，以下の形態素もしくはその組み合わせとする．「が」，「は」，「です」，「ます」のような付属語列継続，状態を示す「いる」，「おる」状態を示す「なる」quotation</subsection>
  <section title="まえがき">自然言語の機械による処理方法の一つに，人間が与えた規則を用いて解析する方法がある．この方法では，一般に知識が複雑になるほど精密な解析ができるが，この複雑化に伴い知識獲得が難しくなるため，解析の対象となる話題を限定することがほぼ必須となる．この点において，人間により与えられた規則にのみ基づく解析は，限界にきているとの見方もある．これに対して，自然言語に関する統計的情報を自然言語処理に利用する研究が盛んに行われている．人間によって与えられた規則を元に解析を行う方法においても，規則の適用される確率を統計的に調べておくことにより良い結果が得られることが多く，統計的な情報を自然言語処理に用いることは処理の効率化に効果があるとみられる．筆者らは既に，統計情報を自然言語処理に利用する方式の一つとして，コーパスに基づいて日本語文法を自動獲得する方法を提案している．この獲得法は，まず構文木情報の付加されたコーパスから多数の文の構文木を作成し，それぞれの節点にランダムに非終端記号を割り当て，その後この割当てをエントロピーにより評価し，エントロピーが最小となるようシミュレーテッド・アニーリング法により割り当てを変更するものである．この方法を新聞記事の文法の獲得に適用した所，得られた文法は終端記号と非終端記号との間の置き換え規則のエントロピーが比較的高いことがわかった．従って，この獲得法の単位として形態素より長い単位---認知単位---を利用することによりエントロピーを下げれば，パーザの動作効率を高めることができると期待される．本論文ではこのような知見に基づき，形態素より長い単位を人間による知覚実験の結果から定義し，文法の自動獲得に応用した，新しい方法を提案する．</section>
  <section title="文法の自動獲得法">今，図(a)のように例文と構文木が与えられていると仮定する．この場合，文脈自由文法における終端記号の集合はT=東,日本,では,晴れて,い,ますと書ける．非終端記号の集合をN=n_1,n_2,n_3,n_4，*-1mm初期記号をn_1として，*-1mmこの構文木を同図(b)のように変形し，各節点に非終端記号を割り当てたとする．すると，各節点の上下関係から次のshift-reduceパーザの規則を得ることができる．この規則の中にはR10，R14，R16のように左辺が等しく右辺が異なるものが存在する．このような規則は，shift-reduceパーザの探索空間を広げ，処理速度を低下させる．先の規則において左辺がn_i,n_jの時，右辺がn_kとなる条件つき確率をP_n_in_j(n_k)，右辺がshiftとなる条件つき確率をP_n_in_jとする．同様に，左辺が終端記号t_iの時，右辺がn_jとなる条件つき確率をP_t_i(n_j)で表す．更に規則n_i,n_jn_kの出現確率をP(n_i,n_j,n_k)，規則n_i,n_jshiftの出現確率をP_(n_i,n_j)とする．また規則t_in_jの出現確率をP(t_i,n_j)とする．すると，上記のshift-reduceパーザの規則はこれらの確率を用いて次のように書き直すことができる．[]R1R16において左辺が等しく右辺が異なるような規則を減らすということは，上記の条件つき確率のすべてを1または0に近づけるということに対応する．これは更に次の()式で定義されるエントロピーHを減少させることに等しい．*-2mmH&amp;=&amp;_i,jP_(n_i,n_j)P_n_in_j&amp;&amp;-_i,j,kP(n_i,n_j,n_k)P_n_in_j(n_k)&amp;&amp;-_i,jP(t_i,n_j)P_t_i(n_j)eqnarray従って，構文木の各節点に対する非終端記号の割当てを，*-1mmHが最小となるように変更すれば，shift-reduceパーザの動作に最適な規則を得ることができる．*-2mmこの最小化は組合わせ最適化問題に対応する．この場合，組合せ空間にはいくつもの極小値が存在する．よって，この方法ではシミュレーテッド・アニーリング法を用いてHの最小化を行う．こうして獲得したshift-reduceパーザの動作規則からは，容易に文脈自由文法を作り出すことができる．すなわちこの方法は，文法を獲得する方法であるとみなせる．また，Hを用いてperplexityQを次のように計算できる．*-2mmQは物理的には，一つの左辺に対して平均いくつの右辺が存在するかを示す値となる．新聞記事7500文を対象として，この方法により解析を行った結果，左辺が形態素である規則の条件つき生起確率P_t_i(n_j)は，左辺が非終端記号2個の規則の条件つき生起確率P_n_in_j(n_k)と比べて，値が小さくなることが示された．これは，一つの形態素が多数の用法を持っていることを示している．従って複数の形態素を組合わせたより長い文字列を，この解析の単位として用いることにより，shift-reduceパーザの解析効率をより高めることができると予想される．</section>
  <section title="認知単位の知覚実験">機械による文解析は，専ら形態素を単位として行われている．しかし，人間では果たしてどのような単位が用いられているのだろうか．これを確かめるため，知覚実験を行った．この実験では，コンピュータのディスプレイ上に30字程度の漢字かな混じり文を短時間表示し，被験者に口頭で読んでもらう．使用したディスプレイは，640400ピクセルの15インチディスプレイで，被験者から約1mの距離に配置してあり，1616ピクセルの白いフォントで文が提示される．被験者は成人男子大学生4名である．まず，表示時間を50msとして1文を提示し，被験者に直ちに口頭で再生してもらう．文は24用意してあり，この実験を全文につき行なう．24文の実験が終了すると，提示時間を100msとして再度24文の実験を行なう．ただし，次に現れる文が予測できないよう文を提示する順序を変える．表示時間を50ms刻みで1sまで長くしながらこの実験を繰り返し，表示時間と，被験者が読むことのできた文字数との関係を調べる．画面上には，文の開始位置が常に示されており，被験者には提示の前に視点をその位置に移動しておくように指示してある．従って，被験者は文を文頭から認識することになる．被験者にはあらかじめ文を覚えないよう伝えてあるが，実験を繰り返すうちに文頭付近を覚えることは避けられない．しかし，提示時間は徐々に長くなるため，被験者が再生できた文字列の末尾付近については認識経験が少なく，記憶による影響は小さい．実験結果を図に示す．*-2mmこの例では，*-2mm「この問題は解決ずみというつもりなのかもしれないが私はそうは思わない．」という文を表示している．結果は図のような階段状になり，人間が文字単位で文を処理しているのではないことは明らかである．また，読めた部分の最後に着目すると，それはすべて文節境界となりうる形態素で終っている．更に，「というつもり」*-1mmや*-1mm「かもしれないが」などのように，複数の文節にまたがる句が一度に検出されているケースもある．従って，人間は文節よりも長い句を一度に検出していることが分かる．「は」，「している」，「というつもり」，「かもしれないが」のように，それだけでは意味をなさず，先行する句の後について補助的な意味を表すような句は，先行する句の一部として先行する句とともに一度に検出されている．この結果から，人間の場合，まずこのような補助的な句を含めた長い句を一度に検出する処理を行い，この処理の後，検出された長い句を組合わせて文を処理していると考えられる．24文の実験結果から，人間は，次のような句を一度に検出していることが分かった．文節「〜かもしれない」などの慣用句「〜している」などの補助用言を含んだ句このような句を，本論文は認知単位と呼ぶことにする．</section>
  <section title="認知単位を用いた文法の獲得法"/>
  <subsection title="認知単位を用いた文法の獲得法の概要">2節で述べた獲得法により獲得した文法を用いるshift-reduceパーザは，認知単位の内部まで係受けを調べるため，探索空間は膨大なものとなる．しかし，前節の考察から，人間においては，認知単位の内部については，通常解析は行っていないと考えられる．よって，2節の解析方法の単位として，3節で述べた認知単位を用いれば，探索空間は大きく狭まり検索効率は向上すると考えられる．本研究では，図のように，認知単位を用いた構文木を作り文法を獲得するものとした．</subsection>
  <subsection title="天気概況文における機械処理用の認知単位">この文法獲得を行うにあたり，NHKの気象通報の始めに放送される天気概況文1000文を，構文木情報を含めて手入力し，コーパスとして用いた．使用した天気概況文の例を図に示す．人間の認知単位は知覚実験により得られるもので，人間における認知単位をすべて明らかにして辞書を作成するためには膨大な知覚実験が必要となる．従って，本研究では簡単のため，人間同様と思われる単位を新たに定義し，機械処理用の認知単位として解析に利用することとした．以下，本論文ではこの機械処理用の認知単位を，単に認知単位と呼ぶ．本論文では，天気概況文における機械処理用の認知単位を次のように定義する．</subsection>
  <subsection title="認知単位を用いた文法の獲得実験">前節に示したコーパスを用いて実際に文法の自動獲得を行なった．非終端記号数N_n=*1mm20,40,60,80における，シミュレーテッド・アニーリング法による文法獲得の様子を図に示す．C_pは温度パラメータであり，初期値を経験的に定め，項比0.98の等比数列に従い減少させた．*-2mm各C_pについて，各節点とも2N_n回の非終端記号の更新を行った．この結果得られたQの最終値を表に示す．獲得の結果は，すべてQが1.3以下になった．これは動作規則の左辺1つに対して，右辺が1.3以下となる規則が得られたことを示している．</subsection>
  <section title="未知の認知単位の自動獲得法">前節に述べた方法により，認知単位を基本とした文法を獲得することができる．従って，コーパスに出現した認知単位のすべてを辞書に納めておけば，前節で獲得した動作規則に基づいて構文解析を行うことができる．しかし，認知単位は形態素を複数組合わせたものであるため，認知単位の中には極めて出現率が低いものがいくつも存在し，これらの認知単位は限られたコーパス中においては，一度も出現しない可能性がある．従って収録文数が限られたコーパスでは，形態素を単位とした解析法よりも，認知単位を単位とした解析法の方が未知語の比率が高くなる．このようなコーパスの場合，2節の方法の単位として単に認知単位を用いただけでは，未知の認知単位を含む文が解析不能となり，結果的に解析効率が低下する．この現象を抑えるためには，未知の認知単位に関する知識を，既知の認知単位に関する知識から推定する必要がある．本研究ではこの推定を行うため，認知単位を，形態素を基本とする状態遷移図で表現できると仮定する．すると，例えば「東日本では」という認知単位が「東」，「日本」，「では」という3つの形態素からなり，shift-reduceパーザの動作規則または文脈自由文法の生成規則によって，非終端記号n_1に置き換え可能であるとすると，この認知単位を図のように，隠れ状態u_1u_4を持つ状態遷移図モデルで表現し，取り扱うことができる．同図における各状態に対して更に，*-1mmu_1を初期状態，u_2，u_3を中間状態，u_4を受理状態と呼ぶことにし，この受理状態u_4が非終端記号n_1に対応しているものと考える．コーパスに出現するすべての認知単位に対しこのモデルを適用し，各認知単位についてすべて異なる隠れ状態u_iを生成すると，おびただしい数の隠れ状態が必要となる．このため，隠れ状態の総数N_uより小さいN_sを考え，*-2mmu_1のような初期状態を初期状態記号s_1に写像し，*-1mmu_2，*-1mmu_3のような中間状態を中間状態記号s_2s_N_sのいずれかに写像する写像s_y=T_us(u_x)を考え，状態を統一化する．写像T_usを決めると，コーパスより，状態s_iから単語w_jを通ってs_kに移る確率P_s(s_i,w_j,s_k)と条件つき確率P_ss_i(w_j,s_k)を調べることができる．同様に状態s_iから単語w_jを通ってn_kに移る確率P_s(s_i,w_j,n_k)と条件つき確率P_ss_i(w_j,n_k)も調べることができる．これらの確率を用いて，状態遷移図のエントロピーは次のように表現される．H_s&amp;=&amp;-_i,j,kP_s(s_i,w_j,s_k)P_ss_i(w_j,s_k)&amp;&amp;-_i,j,kP_s(s_i,w_j,n_k)P_ss_i(w_j,n_k)eqnarrayこのエントロピーH_sを用いて，状態遷移図における平均分岐数は次のように求まる．Q_sは物理的には，一つの状態から平均いくつの枝が出ているかを示している．この方法で得られた状態遷移図を用いて，有限オートマトンで認知単位を検出するとすれば，この分岐数Q_sが小さい程オートマトンの決定性が高まり，動作が効率的になる．Q_sが最小となるようT_usを求める問題は，組合わせ最適化問題となる．この組合わせ空間にはやはり多数の極小値が存在するため，本研究ではシミュレーテッド・アニーリング法によりQ_sを最小化する．T_usによる状態の統一化により，ある認知単位に関する状態遷移図と，その認知単位に近い用法を持つ別の認知単位に関する状態遷移図は交差する．この交差により，認知単位に関する知識は統一化され，未知の認知単位も受理できるようになる．従って，こうして得た状態遷移図は未知の認知単位を含めた状態遷移図となる．T_usの最適化は，エントロピーH_sを基準としてこの交差を最適化することになる．本研究では，この最適化により未知の認知単位に関する状態遷移図も最適化されると仮定し，最適化により得た状態遷移図に基づき認知単位を受理する．このように形態素を基本とした状態遷移図を用いる方法では，最終的には辞書としては形態素の辞書を持つことになる．しかし，有限オートマトンによる解析は，shift-reduceパーザのようなより高次の解析方法に比べて動作が直線的であるため一般に高速である．従って，認知単位内の解析に状態遷移図と有限オートマトンを用いる方法は，文全体をshift-reduceパーザで処理する方法に比べ高速となる利点がある．</section>
  <section title="未知の認知単位の自動獲得実験">4節で獲得した認知単位に関する知識に基づき，5節で述べた方法により未知の認知単位も含めた状態遷移図を獲得する実験を行った．状態記号数N_uは20とした．この獲得の様子を図に示す．この結果，最終的に得られたQ_sはほぼ9程度となった．Q_sの最終値を表に示す．非終端記号数N_n=20として獲得した場合の，状態遷移図における遷移確率の高い枝の一部を表に示す．状態遷移図の獲得により，形態素は自動的にクラスタリングされるが，このクラスタリングは人間のクラスタリングに類似していることが分かる．</section>
  <section title="獲得した知識に基づく構文解析">以上の議論に基づき，(A)形態素を基本として文法を獲得する方法，(B)認知単位を基本として文法を獲得し，認知単位をそのまま辞書に登録する方法，(C)認知単位を基本として文法を獲得し，認知単位を受理する状態遷移図を獲得する方法の3つの評価を行った．評価は，獲得した文法に基づき，別に用意した100文を構文解析することによって行った．計算はSUNのSPARCStation20モデル612を用いた．この結果を表に示す．表中において正解率はこの結果，最も確からしいと判断された構文木が，コーパスに与えられている構文木と等しい確率を示す．探索はbest-firstsearch法を用いているため，既存の知識では最終的に構文木が生成できない文があると，その文の処理に極端に時間がかかる．その一方で，解に容易に到達できる場合もあり，文によって処理時間のばらつきが大きい．非終端記号20では，このように探索に時間がかかる文が多く，(A)(B)(C)ともに長い時間を要している．特に認知単位を用いた(B)および(C)では，表におけるQが，他に比べて大きく，この結果長い時間がかかっているものと思われる．従って，認知単位を用いた方法では，非終端記号20では十分に整理された文法が得られないものと考えられる．しかし，非終端記号数が40以上になると(B)(C)，特に(B)は，処理速度が著しく高速になる．これは，認知単位を用いる方が，構文木を構成する葉の候補の数が少ないため，構文解析での探索経路が少なくなることに起因する．正解率でみると，(C)が最も良く，ついで(A)(B)の順となっている．(B)が(A)に比べて劣るのは未知認知単位があるためであると考えられる．(C)において未知認知単位の自動獲得が有効に機能しているのが分かる．</section>
  <section title="むすび">以上，認知単位を用いた文法の自動獲得法を提案した．認知単位を基本とした文法を用いる解析法は，形態素を基本とした文法を用いる解析法に比べ効率が高い．一般に自然言語の文法は多重折込み要素が存在するため，文全体の解析に状態遷移図を利用するのは適当ではないが，認知単位のような狭い範囲に状態遷移図を利用するのは有効であることが明らかとなった．本方法以外の文解析方法においても，認知単位を利用することにより処理を効率化することができるものと考えられる．</section>
</root>
