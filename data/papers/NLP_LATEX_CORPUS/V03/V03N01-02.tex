\documentstyle[epsf,jnlpbbl]{jnlp_j}

\def\atari(#1,#2){}

\setcounter{page}{29}
\setcounter{巻数}{3}
\setcounter{号数}{1}
\setcounter{年}{1996}
\setcounter{月}{1}
\受付{1995}{1}{6}
\再受付{1995}{5}{24}
\再々受付{1995}{7}{18}
\採録{1995}{9}{8}

\setcounter{secnumdepth}{2}

\title{名詞間の意味的共起情報を用いた複合名詞の解析}
\author{小林 義行\affiref{TIT} \and 徳永 健伸\affiref{TIT} \and 田中 穂積\affiref{TIT}}

\headauthor{小林 義行, 徳永 健伸, 田中 穂積}
\headtitle{名詞間の意味的共起情報を用いた複合名詞の解析}

\affilabel{TIT}{東京工業大学 情報理工学研究科 計算工学専攻}
{Department of Computer Science, Tokyo Institute of Technology}

\jabstract{複合名詞は名詞を結合することによって数限りなく生成できるので，
全てを辞書に登録することは不可能である．したがって，辞書に登録されてい
る名詞の組み合わせとして複合名詞を解析する手法が必要である．そのために
は，複合名詞をそれを構成している名詞に分割し，名詞間の係り受け構造を
同定しなくてはならない．
これらの処理は統語的な手係りが少ないために難しく，
何らかの意味的な情報が必要である．
しかし，大規模な意味的情報を人手で構築し保守することはコストが
大きいため，計算機によって自動的に知識を獲得することが望ましい。
本論文では，コーパスから自動的に抽出した名詞間の意味的共起情報を用いて
複合名詞の構造を解析する方法を提案する．この方法では，共起情報を統計的
に処理して名詞間の意味的関係の強さを評価し，係り受け関係の曖昧性解消に
利用する．
まず，4文字漢字語16万語から意味クラスの共起データを抽出した．
抽出した共起データから統計的に名詞間の意味的関係の強さを
計算する．そのための尺度として相互情報量を基にした評価尺度を提案する．
この尺度と複合名詞の構造に関するヒューリスティクス，機械可読辞書から得
られる言語知識を用いて複合名詞を解析する．評価のために新聞や用語集から
抽出した漢字複合名詞を解析し，平均語長5.5文字の漢字複合名詞を約78\%の
精度で解析できた．
}

\jkeywords{統計的自然言語処理，複合名詞解析, 共起}

\etitle{Analysis of Japanese Compound Noun \\Using Collocational Information}
\eauthor{KOBAYASI Yosiyuki \affiref{TIT} \and TOKUNAGA Takenobu\affiref{TIT}  \and TANAKA Hozumi\affiref{TIT}} 

\eabstract{Analyzing compound nouns is one of the crucial issues for
  natural language processing systems. Registering all compound nouns
  in a dictionary is an impractical approach, since we can create a
  new compound noun by combining nouns.  Therefore, a mechanism to
  analyze the structure of a compound noun from the individual nouns
  is necessary. However, the analysis are difficult only when using
  syntactic knowledge. Therefore, we have to use semantic knowledge.
  It is hard to construct and maintain a large semantic knowledge\_base,
  so we need a method to acquire semantic knowledge and use such the
  knowledge for the analysis.  In this paper, we propose a method to
  analyze structures of Japanese compound nouns by using word
  collocational information and a thesaurus. The collocational
  information is acquired from a corpus of four {\it kanzi} character words. 
  For each possible structure of a compound noun, the preference is
  calculated based on this collocational information.  An experiment
  is conducted with 160,000 word collocations to analyze compound
  nouns of with an average length of 5.5 characters. The accuracy of
  this method is about 78\%.
}

\ekeywords{Statistical NLP, Compound noun analysis, Collocation}

\makeatletter
\def\figcap#1#2{}
\def\tblcap#1#2{}
\makeatother


\begin{document}
\maketitle

\section{はじめに}

  複合名詞は名詞を結合することによって数限りなく生成できるので，
全てを辞書に登録することは不可能である．したがって，辞書に登録されてい
る名詞の組み合わせとして複合名詞を解析する手法が必要である．そのために
は，複合名詞をそれを構成している名詞に分割し(複合名詞の形態素解析)，名
詞間の係り受け構造を同定しなくてはならない．

例として，「歩行者通路」という複合名詞をとりあげる．「歩行者通路」の分
割可能性として少なくとも「歩行/者/通路」，「歩/行者/通路」の2通りが考
えられる．さらに，前者の分割の結果に対して[[歩行,者],通路]と[歩行,[者,
通路]]の2通りの係り受け構造が，後者については[[歩,行者],通路]と[歩,[行
者,通路]]の2通りの係り受け構造が考えられる．このなかから正しい係り受け
構造[[歩行,者],通路]を選択しなくてはならない．

日本語のように語と語の間に区切り記号のない言語では，まず，複合名詞の分
割が困難である．また，複合名詞は名詞の並びによって構成されているので，
品詞などの統語的な手係りが少なく，係り受け構造の解析も困難である．した
がって何らかの意味的な情報を用いることが必要である．そのために方法とし
て，名詞をいくつかの意味的なクラスに分け，それらのクラスの間の係り受け
関係に関する情報を用いて複合名詞の構造を解析することが考えられる．

たとえば，宮崎らは，語が表す概念に関する知識，概念間の係り受けに関する
規則を人手で記述し，これらを用いて複合名詞の係り受け構造を解析する方法
を提案している~\cite{miyazaki:84:a,miyazaki:93:a}．
AI関係の新聞記事のリード文に現れる複合名詞で未定義語を含まない語167語
の解析に適用し精度94.6\%で解析できている\footnote{この結果はNTT通信研
  究所が独自に作成した辞書や知識ベースを用いて得た結果であるので，一般
  に手に入る辞書や知識ベースを用いて得た結果と簡単に比較できない．}
\cite{miyazaki:93:a}．この方法では，係り受けが成立する名詞意味属性の組
を表に記述し，その表を用いて係り受けを解析している．この表からは，係り
受けが可能か不可能かを知ることはできるが，複数の係り受けの可能性がある
場合にどちらが尤もらしいかといったことを知ることはできない．対象領域
を拡大したり語彙を増やした場合，このような成立/不成立のような2値の情報
で正しく係り受け解析が行なえるか検討の余地がある\footnote{現在のバー
  ジョンでは構造的曖昧性のある複合名詞に対して候補それぞれに評価値をつ
  ける方向で拡張がなされている．}．

また，高い精度を得
るためには，係り受け規則や名詞意味属性の体系を領域にあわせて調整するこ
とが不可欠である．このように人手で知識を記述する場合には以下の問題がある．
  
\begin{itemize}
\item 新しい言語現象に対応するための規則や知識の拡張や保守が容易でない．
\item 領域ごとに知識を用意するのはコストが高い．
\end{itemize}

これらの問題を解決するためには，複数の候補に何らかの優先度をつける方法
と自動的に知識を獲得する方法の2つが必要である．

そのような方法を研究しているものに，藤崎らの研究がある~
\cite{nishino:88:a,takeda:87:a}．藤崎らは，複合名詞の分割にHMMモデルを
用い，係り受け構造を解析するために統計的クラスタリングによって得た語の
クラスと確率付き文脈自由文法を用いている．平均語長4.2文字の漢字複合語
を精度73\%で解析している．以下の問題点がある．
\begin{itemize}
\item 複合名詞の分割を統計的な方法(HMM)のみで行なっているため，存在しない
  語を含む分割結果が得られることがある．
\item 統計的に得た語のクラスが，語の直観的な意味的クラスを反映しないこ
とがあるので構造解析の結果を用いて意味解析を行なう場合に障害になる．
\item 複合語は1文字語と2文字語から構成されると仮定している．
\end{itemize}

藤崎らの方法は複合名詞の統計的な性質のみを用いている点が問題である．語
の意味クラスについては，すでに言語学者が作成した意味分類辞書(たとえば，
分類語彙表~\cite{hayashi:66:a})がある．このような知識も積極的に利用すべき
である．

本論文では，既存の意味分類辞書とコーパスから自動的に抽出した名詞間の意
味的共起情報を用いて複合名詞の係り受け構造を解析する方法を提案する．
Churchらは，大量の語と語の共起データから相互情報量を計算することで意味
的なつながりの程度を評価できることを示している~\cite{church:91:a}．この
場合の問題は，正しい共起データを大量に獲得することが困難なことである．
統語的，意味的曖昧性が解消されていない共起データでは正しい統計情報は獲
得できない．自動的に大量の正しい共起データを獲得する方法を考えなくては
ならない．

本論文では，大量の共起情報をコーパスから高い精度で自動的に獲得するため
に4文字漢字語を利用する．まず，4文字漢字語16万語から意味クラスの共起デー
タを抽出した．抽出した共起データから統計的に名詞間の意味的関係の強さを
計算する．そのための尺度として相互情報量を基にした評価尺度を提案する．
この尺度と複合名詞の構造に関するヒューリスティクス，機械可読辞書から得
られる言語知識を用いて複合名詞を解析する．評価のために新聞や用語集から
抽出した漢字複合名詞を解析し，平均語長5.5文字の漢字複合名詞を約78\%の
精度で解析できた．実際の文章では，漢字複合名詞の平均語長は約4.2文字で
あることを考慮すると，我々の方法による係り受け構造の解析精度は約93\%と
推定される．

本論文の構成は以下の通りである．\ref{sec:acq} 章で共起データの獲得方法
について，\ref{sec:anl} 章で複合名詞の解析方法について述べる．
\ref{sec:rsl} 章で提案した方法を用いて複合名詞を解析した実験と結果につ
いて述べる．\ref{sec:imp} 章では\ref{sec:rsl} 章での結果に基づきヒュー
リスティクス導入による解析方法の改良について述べ，\ref{sec:rsl2} 章で改
良した方法による解析結果について述べる．

\section{名詞の意味的クラスの共起情報の獲得}
\label{sec:acq}

共起データを抽出するときの問題は，統語的，意味的な曖昧性を解消した正し
い共起データを獲得することが困難なことである．Smadjaは，ある語とその前
後5語に現れる語の共起頻度を計算し，頻度の高い共起を意味のある共起デー
タとして利用している\cite{smadja:91:a}．しかし，この方法では多くの誤っ
た共起も抽出してしまう．Hindleは統語解析を行い，主語と述語などの意味
的に尤もらしい共起のみを抽出している~\cite{hindle:90:a}．

本研究では，コーパスから4文字漢字語を抽出し，それらの語から共起データ
を抽出する．4文字漢字語を用いて正しい共起関係データを抽出できると考え
ら理由は以下の3つである．

\begin{enumerate}
\item 漢字連続をコーパスから抽出することは自動的にできる．
\item 4以上の長さの漢字列は多くの場合，複合名詞と考えられる．本論文で
用いる分類語彙表~\cite{hayashi:66:a}では，漢字のみからなる見出し語の
うち4\%が4 以上の長さの漢字語であった．一方，新聞など22万文から自動的
に抽出した漢字列では，異なり語のうち71\%が4文字以上の長さであった．つ
まり，4文字以上の長さを持つ語のほとんどは複合語であると考えられる．
\item 4文字漢字列は2つの2文字語に分割することによって正しい分割を得る
ことができる可能性が高い．新聞と用語集から抽出した4文字漢字語1000個を
分析した結果，2つの2文字語に分割できる語が約96\%であった．この場合，係
り受けのあいまい性は生じないので，両方の2文字語が辞書の見出し語である
か確認することによって語の共起関係を得ることができる．
\end{enumerate}

複合名詞の解析に用いる共起データを獲得する方法の概要は以下の通りである．
\begin{enumerate}
\item 4文字漢字語を収集する．
\item 4文字漢字語を2つの2文字語に2分割して語と語の共起関係を求める．
\item 各2文字語を意味分類辞書の意味分類で置き換え，意味分類の共起関係を
  獲得する．ここで，該当する意味分類がない語を含む共起データは利用しない．
\item 意味分類の共起頻度を求める．ただし，複数の意味分類に含まれる語を
含む共起データは利用しない．
\end{enumerate}

図\ref{fig:bunkatu} にこの方法の例を示す．

\section{共起情報を用いた複合名詞の解析}
\label{sec:anl}

獲得した意味分類の共起データを用いて複合名詞の構造解析を行なう．本研究
では複合名詞の構造について以下の2つの仮定をしている．
\begin{itemize}
\item 複合名詞の係り受け構造は，二分木で表現できる．
\item 左側の語が右側の語を修飾するので，複合名詞の意味分類は最も右の語
の意味分類に等しい．
\end{itemize}
例えば，「歩行者通路」の係り受け構造は[[歩行,者],通路]と表現できる．部
分複合名詞[歩行,者]の意味分類は「者」の意味分類と等しく，複合名詞[[歩
行,者],通路]の意味分類は「通路」と等しい．


以下に構造解析の手順を示す．
\begin{enumerate}
\item 意味分類辞書の見出し語を用いて，可能な複合名詞の分割を求める．こ
のとき，自立語数最小法によって候補を絞る．
\item 各語の意味分類辞書での意味分類を求める．
\item 可能な全ての構造を求める．
\item 全ての構造について共起頻度を基に優先度を計算する．
\item 複数の意味分類に属する語を含む場合，それぞれの意味分類について別々
に優先度を計算する．
\end{enumerate}

複合名詞の各構造$t$の優先度$p(t)$は，以下の式で計算する．
\begin{displaymath}
  p(t) = \left\{
  \begin{array}{l@{\qquad\qquad}l}
    1 & \mbox{if $t$ is leaf} \\
    p(l(t))\cdot p(r(t))\cdot cv(class(l(t)),class(r(t)))
      & \mbox{otherwise}\\
  \end{array} \right.
\end{displaymath}
関数$l(t)$, $r(t)$はそれぞれ，木$t$の左側の部分木，右側の部分木を返す．
$cv(class_1,class_2)$は，語の意味分類の共起を評価した値である．

Churchらは，語の間の意味的関係を共起頻度を基に相互情報量から獲得する方
法を提案している~\cite{church:91:a}．我々は，語の順序を考慮するように
相互情報量を修正した以下の式によって語のクラス間の意味的関係を評価する．

\begin{description}
\item[修正相互情報統計] (MMIS: 
  Modified mutual information statistics)
  $$cv(class_1,class_2) = \frac{RF(class_1;class_2)}{RF(class_1;*)\cdot RF(*;class_2)}$$

  $RF(class_1,class_2)$は，$class_1$と$class_2$がこの順序でコーパスに出
現した相対頻度である．

*はどのような意味分類でもよいことを表す．
\end{description}

\begin{center}
  \epsfile{filename=fig1,width=137mm}
  \figcap{共起データの獲得}{fig:bunkatu}
\end{center}

\subsection*{解析例}

「歩行者通路」を例にして，解析過程を説明する．
\begin{enumerate}
\item 自立語数最小となる全ての可能な分割を求める．
  \begin{enumerate}
  \item 歩行/者/通路
  \item 歩/行者/通路
  \end{enumerate}
\item 意味分類辞書を検索する．``：'' は複数の意味分類に属することを意
味する．この例では分類語彙表の分類を用いる．
  \begin{enumerate}
  \item[\hspace*{10mm}{\bf a}] 歩行[133]/者[110:120]/通路[147]
  \item[\hspace*{10mm}{\bf b}] 歩[119:133:145]/行者[124]/通路[147]
  \item[\hspace*{10mm}{~}] ...
  \end{enumerate}
\item 優先度を計算する．曖昧な意味分類が別々に計算されることに注意．
  \begin{itemize}
    \item {\bf a}の場合，曖昧な意味分類を展開すると以下の4つの構造が考
えられる．

  (イ.)[[133,110],147],(ロ.)[133,[110,147]],\\
  (ハ.)[[133,120],147],(ニ.)[133,[120,147]]\\
構造(イ.)の優先度を計算すると，

$p([[133,110],147])$\\
    $= p([133,110])\cdot p(147) \cdot cv(110,147)$\\
    $ = p(133)\cdot p(110)\cdot cv(133,110)\cdot cv(110,147)$\\
    $ = cv(133,110)\cdot cv(110,147)$\\
    $ = 1.19 \cdot 1.14$\\
    $ = 1.36$

    構造(ロ.)の優先度は，
    
    $p([133,[110,147]])$\\
    $ = cv(133,147)\cdot cv(110,147)$\\
    $ = 1.13 \cdot 1.14$\\
    $ = 1.29$

構造(ハ.)(ニ.)の場合も同様に計算する．

\item {\bf b}の場合も同様に計算する．
\end{itemize}
\end{enumerate}

図\ref{fig:kaiseki} に上記処理の関係を示す．


\section{実験}
\label{sec:rsl}
\subsection{実験データ}
\label{sec:data-analy}

評価用データは，新聞のコラムと社説，用語辞典から抽出した漢字のみからな
る複合名詞である．4文字語954語，5文字語730語，6文字語787語，7文字以上
の漢字語535語である．
\newpage
\begin{center}
  \epsfile{filename=fig2,width=92mm}
  \figcap{解析例}{fig:kaiseki}
\end{center}
これらの評価用複合名詞は，自動的に抽出したものを
人間が検査し，正しい係り受け構造を付与した．

実験対象データからは，意味分類辞書のみでは分割できない複合名詞は除いて
いる．例えば「土地取引」という語には，「土/地/取/引」「土地/取/引」
「土/地取/引」「土/地/取引」「土地/取引」「土地取/引」「土/地取引」
「土地取引」の8つの分割の候補があるが，いずれの分割も意味分類辞書に含
まれない語を含んでしまう\footnote{「土地/取引」という分割は成功しそう
であるが，「取引」が異表記形「取り引き」でしか辞書に登録されていないた
めに失敗する．}．このような辞書引きの段階で失敗する語は，今回の実験の対
象外としている．ただし「炭鉱労働者」の場合，「炭鉱」という語が辞書にな
いが，「炭/鉱/労働者」という分割結果を得ることができる．このような場合
は，「炭鉱」は「炭」と「鉱」から構成できると考え，このような複合名詞は
除外していない．

解析用の知識は以下の通りである．
\begin{description}
\item[共起情報源] 田中(康仁)によって収集された4文字漢字列16万語を含むコー
パス~\cite{tanaka:92:g}．
\item[意味分類辞書] 分類語彙表~\cite{hayashi:66:a}(意味分類として上位3 
桁を利用)．分類語彙表では，全ての表記形が記述されているわけではない． 
表記のゆれがあるばあい，代表的と考えられる表記形のみが記述されている．
そこで，複数の表記方法がある場合，「大辞林」\cite{daizirin:88}から異表 
記形を獲得し，解析用辞書に追加した\footnote{上で例にあげた「取引」は，
「大辞林」にも「取引」という表記しか記述されていないので，「取り引き」
と「取引」の関係を機械可読の言語資源から得ることはできなかった．}．
\end{description}

\subsection{結果}
\label{sec:rsl1}

実験結果を表\ref{rsl1} に示す．平均名詞数は，正解における複合名詞を構成
する名詞の数を平均したものである．精度は正解の優先順位が単独一位のもの
の割合で評価した．

\begin{center}
  \tblcap{解析結果}{rsl1}
  \begin{tabular}{|r|c|c|c|c|}
    \hline
    文字長 & 4文字 & 5文字 & 6文字 & 7文字以上\\
    &&&&平均7.9文字\\
    \hline
    データ数 & 956 & 730 & 787 & 535 \\
    \hline
    平均名詞数 & 2.0 & 2.7 & 3.1 & 6.5\\
    \hline
    精度[\%] & 96 & 69 & 61 & 32 \\
    \hline
  \end{tabular}
\end{center}

\subsection{考察}
\label{sec:resul-discuss1}

解析を失敗したものは，分割の段階で失敗したものと構造解析で失敗したもの
に分けられる．分割を失敗した主な原因は以下の2つである．

\begin{enumerate}
\item 適切な語が辞書に記述されていない場合．例えば「現代版天水桶」にお 
いて「桶」という語が辞書にないので「現代/版/天/水桶」と分割される．
この失敗は10例(4文字)，28例(5文字)，14例(6文字)，2例(7文字以上)であっ
た．
\item ヒューリスティクスとして用いた自立語数最小法によって，正しい分割
結果を排除してしまう場合．この失敗は，18例(5文字)，6例(6文字)，12例(7
文字以上)であった．この失敗は，数詞と接辞を含む語が辞書に登録されてい
る場合に起こる．例えば，「約/二千/万人」「自己/中心的」などがある．数
詞を含む複合名詞はこのヒューリスティクによってほとんど分割に失敗してい
る．
\end{enumerate}

分割に成功して，構造解析に失敗する原因には以下のものがある．

\begin{enumerate}
\setcounter{enumi}{2}  
\item 接辞の知識がないため接頭辞が語末にくる語や，接尾辞が語頭にくる語
を許している．このような例は，45例(5文字)，28例(6文字)であった．
\item 数詞を含む語の構造が一般の複合名詞と異なる．
\item 団体，機関，組織の名詞を解析する場合は，共起データから得らる意味
的近さでは係り受け構造の優先度を正しく評価できない．例えば「日本野鳥保
護協会」などである．7文字以上の漢字複合語にこのような語が多い．
\item 2項関係のみの係り受け構造では表現できない並立構造や3項構造を含む
場合，例えば「保守対革新」や「領土領空領海」などがある．
\item 該当する共起が共起データ源のコーパスに含まれていない場合がある．
\item 該当する意味分類が意味分類辞書に記述されていない場合．例えば，
「米通商代表部」の場合の「米」という語が分類語彙表に記述されていない．
\item 解析精度を向上させるためにはより詳細な意味分類(分類語彙表では4桁
目以降)を用いることが考えられるが，そのためには共起データの量が足り
ない．
\end{enumerate}

\section{ヒューリスティクスの導入による解析方法の改良}
\label{sec:imp}

前章で述べたように，数詞を含む複合名詞は分割に失敗することが多い．構造
も一般の複合名詞とは異なる．数詞が連続して数を表現している部分とそれ
以外の部分を分けて解析することが必要と考えられる．

また，接辞と名詞は統語的な振舞いが異なるが，意味分類辞書では同じ意味に
分類されている．接頭辞は複合語の語末に，接尾辞が複合語の語頭に現れない
という統語的な制約を与える必要がある．

そこで，接辞と数詞における誤りを解消するために，以下の解析用の知識を追加する．
\begin{itemize}
\item 機械可読辞書から抽出した接辞．本論文では「大辞林」から接頭辞560
語，接尾辞170語を抽出した．
\item 数詞とコーパスから抽出した助数詞．助数詞は，新聞と用語集から数詞
連続の前後に現れる語のなかで頻度の高い語を抽出し，人間が助数詞として適
切かどうかを判断することによって獲得した．本論文で用いた数詞，助数詞を以下に
示す．

接頭助数詞=\{約,第\}

接尾助数詞=\{円,人,年,時,分,個,件,日\}

数詞=\{一,二,三,四,五,六,七,八,九,十,百,千,万,億,兆,数,何\}
  
\item 接辞，数詞，助数詞の用法に関するヒューリスティクスの利用．
  \begin{itemize}
  \item 接頭辞が複合名詞の語末にくる構造を優先度計算の前に排除する．
  \item 接尾辞が複合名詞の語頭にくる構造を優先度計算の前に排除する．
  \item 数詞，助数詞を含む語をテンプレートによって解析する．テンプレート
として以下のものを用いる．

[[部分複合語* [[接頭助数詞* 数詞+] 接尾助数詞*]] 部分複合語*]

[[部分複合語* [[数詞+ 年] [数詞+ 月] [数詞+ 日]]] 部分複合語*]
  \end{itemize}

  ただし，A*はAが0語以上連続することを，A+はAが1語以上連続することを表す．
\end{itemize}

\bigskip

さらに複合名詞の構造の分布を分析した結果に基づき，ヒューリスティクスを
導入する．3節で述べた優先度の計算方法では，2つの語の距離を考慮していな
かった．構造の出現頻度と語の距離の関係を調査した結果，表\ref{bunpu} に
示すような分布を得た．ここで，語と語の距離は，2つの語の間にある語の数
+1で定義する．例えば，[A,B,C]という単語列の場合，AとB，BとCの距離はそ
れぞれ1，AとCの距離は2となる．距離の総和は構造中に含まれるすべての語の
組の距離の和である．表\ref{bunpu} より構成要素が同じ数の場合，距離総和
が大きい構造ほど，出現頻度が低いことが分かる．

\begin{center}
  \tblcap{構造の出現頻度}{bunpu}
  \begin{tabular}{|l|r|r|c|}
    \hline
    構造 & 5文字 & 6文字 & 距離総和 \\
    \hline
    $[w_1]$ & 0 & 1 & 0\\
    \hline
    $[w_1, w_2]$ & 268 & 78 & 1 \\
    \hline
    $[[w_1,w_2],w_3]$ & 283 & 406 & 2 \\
    $[w_1,[w_2,w_3]]$ & 84 & 160 & 3 \\
    \hline
    $[[[w_1,w_2],w_3],w_4]$ & 13 & 43 & 3 \\
    $[[w_1,w_2],[w_3,w_4]]$ & 16 & 48 & 4 \\
    $[[w_1,[w_2,w_3]],w_4]$ & 4 & 11 & 4\\
    $[w_1,[[w_2,w_3],w_4]]$ & 3 & 8 & 5\\
    $[w_1,[w_2,[w_3,w_4]]]$ & 2 & 3  & 6\\
    \hline
  \end{tabular}
\end{center}
\bigskip

構造中に含まれる語の距離の総和が大きい複合名詞が現われにくいという現象
は，丸山が文節間の係り受け関係において，位置的に近い文節間の係り受け関
係のほうが高い頻度で生じているという分析結果と関係があると考えられる~
\cite{maruyama:92:a}．丸山は，文節間の距離$k$と文節間の係り受け頻度の
相対頻度$q(k)$の関係を表す式を以下のように求めている．

\begin{displaymath}
  q(k) = 0.54\cdot k^{-1.896}
\end{displaymath}
複合名詞の構造においても文節間の係り受け関係と同じ関係が成り立つと仮定
して，優先度の計算に丸山の求めた以下の式を利用する．上式を用いて2つ
の意味分類の関係の評価値を以下のように再定義する．
\begin{displaymath}
  cv'(class_1, class_2, k) = cv(class_1,class_2) \cdot q(k)
\end{displaymath}


\section{実験2}
\label{sec:rsl2}

\ref{sec:rsl} 章と同じ共起データ源とテストデータを用いて実験を行なった．
実験は\ref{sec:imp} 章で述べた3種類の情報を組み合わせて追加したものについ
て行なった．以下，それぞれの実験を実験2.1〜実験2.7と呼ぶ．接辞情報は
「大辞林」から，数詞と助数詞は共起データ源のコーパスから抽出した．

\begin{itemize}
\item{2.1} 距離の導入．
\item{2.2} 数詞テンプレート．
\item{2.3} 接辞情報．
\item{2.4} 距離の導入+数詞テンプレート．
\item{2.5} 距離の導入+接辞情報．
\item{2.6} 数詞テンプレート+接辞情報．
\item{2.7} 距離の導入+数詞テンプレート+接辞情報．
\end{itemize}


\subsection{結果}

実験結果を表\ref{rsl2} に示す．平均名詞数は，正解における複合名詞を構成
する名詞の数を平均したものである．精度は正解の優先順位が単独一位のもの
の割合で評価した．

\begin{center}
  \tblcap{解析結果}{rsl2}
  \begin{tabular}{|r|c|c|c|c|}
    \hline
    文字長 & 4文字 & 5文字 & 6文字 & 7文字以上\\
    &&&&平均7.9文字\\
    \hline
    データ数 & 956 & 730 & 787 & 535 \\
    \hline
    平均名詞数 & 2.0 & 2.7 & 3.1 & 6.5\\
    \hline
    実験1[\%] & 96 & 68 & 61 & 32 \\
    \hline
    \hline
    実験2.1[\%] & 96 & 81 & 71 & 44 \\
    \hline
    実験2.2[\%] & 96 & 73 & 60 & 28 \\
    \hline
    実験2.3[\%] & 96 & 71 & 63 & 34 \\
    \hline
    実験2.4[\%] & 96 & 84 & 73 & 46 \\
    \hline
    実験2.5[\%] & 96 & 81 & 72 & 45 \\
    \hline
    実験2.6[\%] & 96 & 75 & 63 & 30 \\
    \hline
    実験2.7[\%] & 96 & 84 & 72 & 44 \\
    \hline
  \end{tabular}
\end{center}

\subsection{考察}

\begin{enumerate}
\item 語間の距離を用いることで解析精度を向上させることができた．
\item 数詞を含む複合名詞の分割処理をテンプレートで行なうことによって，
自立語数最小法による分割失敗を18例から11例(5文字)，6例から1例(6文字)，12
例から7例(7文字以上)に減少させることができた．
\end{enumerate}


\begin{enumerate}
\setcounter{enumi}{2}
\item テンプレートによって解析した数詞を含む複合名詞は，22例(5文字)，
24例(6文字)，15例(7文字以上)であるが構造解析に失敗した語は1例(6文字)，
2例(7文字以上)であった．また，テンプレートを用いたことで正しく解析でき
なくなった語はなかった．数詞を含む語に対してはテンプレートを用いること
は有効であると考えられる．
\item 接辞情報を用いることで正しい結果が得られるようになった一方で，正
しい結果が得られていたものが解析できなくなるという副作用が発生した．そ
れは，同形で名詞にも接辞にもなる語があるためで，そのために正しい解析結
果まで接辞の規則によって排除されることがある．例えば，「悪」という語は
名詞でも接頭辞でもある．「悪」を接頭辞と思って複合名詞の語末にくる場合
を排除すると，「必要悪」のような語を正しく解析できない．ある語の接頭辞
としての使われやすさを考慮する優先度を導入する必要がある．
\item 「可能性」の「性」は名詞であるが，接辞的に振る舞う名詞である．こ
のような接辞的名詞を機械可読辞書から獲得できなかった．
\item 実験に用いたコーパスにおける漢字連続語の頻度を表\ref{hindo} に示
す．漢字複合名詞は漢字4文字以上であると仮定すると，漢字複合名詞の長
さの平均は4.2語で，表\ref{rsl2} の結果より精度93\%で解析できると推定で
きる．
\end{enumerate}


\begin{center}
  \tblcap{漢字複合語の出現頻度}{hindo}
  \begin{tabular}{|r|c|c|c|c|}
    \hline
    文字長 & 4文字 & 5文字 & 6文字 & 7文字以上\\
    &&&&平均7.9文字\\
    \hline
    出現頻度[\%] & 90 & 5 & 3 & 2 \\
    \hline
  \end{tabular}
\end{center}

\section{おわりに}

本論文では，コーパスから共起知識を獲得する方法と，獲得した共起知識と意
味分類辞書を用いて複合名詞を解析する方法について述べた．4文字漢字語を
共起知識源として利用することで高い精度で正しい共起データを自動的に得る
ことが可能になった．また，複合名詞の構造について，構造中の語と語の距離
の総和が小さいものほど出現しやすいという分析結果を得た．名詞の意味的共
起情報と，語と語の距離を用いて複合名詞を解析することによって，実際のテ
キストに換算して平均語長4.2語の漢字複合語を約93\%の精度で解析できるこ
とを確認した．

統計的な情報は，詳細な規則を記述するのに比べ獲得が簡単であるが，統計的
な知識のみでは精度の向上に限界がある．例えば「日本野鳥保護協会」では
「日本」と「協会」に係り受け関係があるが，統計的情報のみでこの係り受け
関係を推定することは難しい．この2語はさまざまな意味分類の語と共起す
るので，2つの語の間に意味的関係があると推定することが困難であるから
である．コーパスから得られる統計的な情報を，機械可読辞書などから抽出可
能な言語学的な知識や人間が記述する規則とうまく組み合わせることが重要な
問題と考えられる．

今後の課題としては，以下のような項目がある．
\begin{description}

\item[意味分類の詳細化] 分類語彙表の詳細な意味分類を用いることが考えら
れる．また分類語彙表よりも大規模で，詳細な意味分類を持つ意味分類辞書に
EDRの概念体系がある．ただし，大規模な意味分類辞書を用いるためには大規
模な知識源用コーパスも同時に必要である．

\item[辞書の整備]たとえば，「許可」と「認可」から「許認可」が構成され 
ることを共起データのみから推定することはできない．このような語は解析用
辞書に登録する必要がある．また新聞などでは「税調」などの略語がよく現れ
るので辞書に登録することが必要である．また，今回の実験では固有名詞を考
慮していない．固有名詞を辞書に登録することも必要である．

\item[接辞の扱い]接辞と名詞の両方で用いられる語については，機械可読辞
書から得られる情報のみでは，どちらで用いられているのか曖昧性を解消する
には不十分である．また，「可能性」の「性」のような国語辞典には接辞と記
述されていないが，接辞的にふるまう名詞も存在する．コーパスを用いて，接
辞/名詞の品詞の曖昧性解消や接辞的名詞の獲得などを検討することが必要で
ある．
  
\item[分割誤りの改善] 本論文では，複合名詞を分割するとき分割候補を絞り
込むために自立語数最小法を用いている．そのために分割の段階で正解を排除
する可能性がある．テンプレートを用いて数詞を含む複合名詞についてはこの
点を改良することができた．接辞に関する情報を獲得することができれば，
「自己/中心的」の「中心的」のような接辞を含む語が辞書に登録されて
いる場合の分割誤りに対して何らかの処置ができるかもしれない．

\item[意味解析] 複合名詞を構成する名詞のあいだの意味的な関係を推定する
ことも必要である．例えば「閣僚資産公開」は「資産」が「公開」の目的語で
「閣僚」が「資産」の所有者であるといった意味的関係を知ることができれば，
「閣僚が持つ資産を公開」と言い換えることができる．関連する研究として，
機械可読辞書の意味知識を用いて英語の複合名詞を解析するVanderwendeの研
究がある~\cite{vanderwende:94:a}．
  
\item[他の構造解析への応用]たとえば，Hindleらは共起知識を用いて前置詞 
句接続の曖昧性を解消する手法を提案している~\cite{hindle:91:a}．本手法
を文節間の係り受け関係の曖昧性解消に適用することが考えられる．
\end{description}

\bigskip

\acknowledgment

本研究を進めるにあたって4文字漢字列コーパスを提供して下さいました兵庫
大学の田中康仁教授に感謝いたします．

\bibliographystyle{jnlpbbl}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{'91}{ACL}{1991}]{ACL-91}
ACL '91 \BBOP 1991\BBCP.
\newblock {\Bem Proceedings of the 29th Annual Meeting of the Association for
  Computational Linguistics}.

\bibitem[\protect\BCAY{Church, Hanks, \BBA\ Hindle}{Church
  et~al.}{1991}]{church:91:a}
Church, K.~W., Hanks, W. G.~P., \BBA\ Hindle, D. \BBOP 1991\BBCP.
\newblock \BBOQ Using Statistics in Lexical Analysis\BBCQ\
\newblock In {\Bem Lexcal Acquisitin}, \BCH~6. Lawrence Erlbaum Associates.

\bibitem[\protect\BCAY{松村}{松村}{1988}]{daizirin:88}
松村明\JED\ \BBOP 1988\BBCP.
\newblock \Jem{大辞林}.
\newblock 三省堂.

\bibitem[\protect\BCAY{林}{林}{1966}]{hayashi:66:a}
林大 \BBOP 1966\BBCP.
\newblock \Jem{分類語彙表}.
\newblock 秀英出版.

\bibitem[\protect\BCAY{Hindle}{Hindle}{1990}]{hindle:90:a}
Hindle, D. \BBOP 1990\BBCP.
\newblock \BBOQ Noun Classification from Predicate-Argument Structures\BBCQ\
\newblock In {\Bem Proceedings of the 28th Annual Meeting of the Association
  for Computational Linguistics}, \BPGS\ 268--275. ACL '90.

\bibitem[\protect\BCAY{Hindle \BBA\ Rooth}{Hindle \BBA\
  Rooth}{1991}]{hindle:91:a}
Hindle, D.\BBACOMMA\  \BBA\ Rooth, M. \BBOP 1991\BBCP.
\newblock \BBOQ Structural Ambiguity and Lexical Relations\BBCQ.
\newblock In {\Bem Proceedings of the 29th Annual Meeting of the Association
  for Computational Linguistics\/} \citeyear{ACL-91}, \BPGS\ 229--236.

\bibitem[\protect\BCAY{Maruyama \BBA\ Ogino}{Maruyama \BBA\
  Ogino}{1992}]{maruyama:92:a}
Maruyama, H.\BBACOMMA\  \BBA\ Ogino, S. \BBOP 1992\BBCP.
\newblock \BBOQ A Statistical Property of {Japanese} Phrase-to-Phrase
  Modifications\BBCQ\
\newblock {\Bem Mathematical Linguistics}, {\Bbf 18}  (7), 348--352.

\bibitem[\protect\BCAY{宮崎}{宮崎}{1984}]{miyazaki:84:a}
宮崎正弘 \BBOP 1984\BBCP.
\newblock \JBOQ 係り受け解析を用いた複合語の自動分割法\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 25}  (6), 1035--1043.

\bibitem[\protect\BCAY{宮崎, 池原, 横尾}{宮崎\Jetal }{1993}]{miyazaki:93:a}
宮崎正弘, 池原悟, 横尾昭男 \BBOP 1993\BBCP.
\newblock \JBOQ 複合語の構造化に基づく対訳辞書の単語結合型辞書引き\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 34}  (4), 743--753.

\bibitem[\protect\BCAY{西野, 藤崎}{西野\JBA 藤崎}{1988}]{nishino:88:a}
西野哲朗,  藤崎哲之助 \BBOP 1988\BBCP.
\newblock \JBOQ 漢字複合語の確率的構造解析\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 29}  (11), 1034--1042.

\bibitem[\protect\BCAY{Smadja}{Smadja}{1991}]{smadja:91:a}
Smadja, F.~A. \BBOP 1991\BBCP.
\newblock \BBOQ From N-Grams to Collocations: An Evaluation of Xtract\BBCQ.
\newblock In {\Bem Proceedings of the 29th Annual Meeting of the Association
  for Computational Linguistics\/} \citeyear{ACL-91}, \BPGS\ 279--284.

\bibitem[\protect\BCAY{武田, 藤崎}{武田\JBA 藤崎}{1987}]{takeda:87:a}
武田浩一,  藤崎哲之助 \BBOP 1987\BBCP.
\newblock \JBOQ 確率的手法による漢字複合語の自動分割\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 28}  (9), 952--961.

\bibitem[\protect\BCAY{田中}{田中}{1992}]{tanaka:92:g}
田中康仁 \BBOP 1992\BBCP.
\newblock \JBOQ 自然言語の知識獲得 -- 四文字漢字列\JBCQ\
\newblock \Jem{情報処理学会第45回全国大会}.

\bibitem[\protect\BCAY{Vanderwende}{Vanderwende}{1994}]{vanderwende:94:a}
Vanderwende, L. \BBOP 1994\BBCP.
\newblock \BBOQ Algorithm for Automatic Interpretation of Noun Sequences\BBCQ\
\newblock In {\Bem Proceedings of the 14th International Conference on
  Computational Linguistics}, \lowercase{\BVOL}~2, \BPGS\ 782--788. COLING '94.

\end{thebibliography}

\begin{biography}
  \biotitle{略歴} \bioauthor{小林義行}{ 1968年生．1988年明石工業高等専
    門学校電気工学科卒業．1991年東京工業大学工学部情報工学科卒業．1993
    年同大学院修士課程修了．1993年同大学院博士課程入学，現在在学中．自
    然言語処理，知識情報処理の研究に従事．情報処理学会，人工知能学会，
    各会員}

  \bioauthor{徳永健伸}{1961年生. 1983年東京工業大学工学部情報工学科卒
    業. 1985年同大学院理工学研究科修士課程修了. 同年(株)三菱総合研究所
    入社. 1986年東京工業大学大学院博士課程入学. 現在, 同大学大学院情報
    理工学研究科計算工学専攻助教授. 博士 (工学). 自然言語処理, 計算言
    語学に関する研究に従事. 情報処理学会, 認知科学会, 人工知能学会, 計
    量国語学会, Association for Computational Linguistics, 各会員.  }

  \bioauthor{田中穂積}{1941年生. 1964年東京工業大学工学部情報工学科卒
    業. 1966年同大学院理工学研究科修士課程修了. 同年電気試験所(現電子
    技術総合研究所)入所. 1980年東京工業大学助教授. 1983年東京工業大学
    教授. 現在, 同大学大学院情報理工学研究科計算工学専攻教授. 工学博士. 
    人工知能，自然言語処理に関する研究に従事. 情報処理学会, 電子情報通
    信学会，認知科学会, 人工知能学会, 計量国語学会, Association for
    Computational Linguistics, 各会員.  }

\bioreceived{受付}
\biorevised{再受付}
\biorerevised{再々受付}
\bioaccepted{採録}

\end{biography}

\end{document}
