



\documentstyle[jnlpbbl,fleqn]{jnlp_j}

\setcounter{page}{67}
\setcounter{巻数}{3}
\setcounter{号数}{4}
\setcounter{年}{1996}
\setcounter{月}{10}
\受付{1995}{11}{9}
\再受付{1995}{12}{18}
\採録{1996}{2}{20}

\setcounter{secnumdepth}{2}


\title{確率モデルによるゼロ主語の補完}
\author{江原 暉将\affiref{KUEE} \and 金 淵培\affiref{KUEE}}

\headauthor{江原 暉将・金 淵培}
\headtitle{確率モデルによるゼロ主語の補完}

\affilabel{KUEE}{ＮＨＫ放送技術研究所，先端制作技術研究部}
{NHK Science and Technical Research Laboratories,
 Program Production Technology Research Division,
 \{eharate,kimyb\}@strl.nhk.or.jp}

\jabstract{
主語のない日本語文に対し，確率モデルを用いて自動的にゼロ主語を補完する手法について述べる．これは，日英機械翻訳の前処理としての自動短文分割の後で適用されるものである．確率モデルを用いる方法として，従来 (1)多次元正規分布に基づくモデルを利用するものがあった．本稿では，新たに３種類のゼロ主語補完のためのモデルを提案する．それらは，連続分布に対して，(2)正規分布に基づくGram-Charlier展開を多次元に拡張した分布（疑似正規分布）に基づくモデル，離散分布に対しては，(3)１次対数線形分布，(4)２次対数線形分布に基づくモデルである．これら４種の確率モデルについて，補完精度を比較する実験を行った．その結果，(1)〜(4)の精度は，順に，７３％，７８％，７８％，８１％であり，２次対数線形分布を用いる方法が最も精度が高かった．また，補完を誤った事例について考察を加えた結果，主語と述語の意味的整合性をより正確に計算する必要があることなどがわかった．
}

\jkeywords{照応解析，ゼロ代名詞，確率モデル，機械翻訳}

\etitle{Zero-subject Resolution by Probabilistic Model}
\eauthor{Terumasa Ehara \affiref{KUEE} \and Yeun-Bae Kim\affiref{KUEE}} 

\eabstract{
Probabilistic resolution method for Japanese zero-subjects is described.
 It is designed to be used for the back-end processor of an automatic shortening system of long Japanese sentences in a Japanese to English machine translation system.
 Ordinary probabilistic resolution method uses (1) normal distribution model in the continuous probability space. 
 In this article, we propose 3 new models.
 They are (2) quasi-normal distribution model in the continuous space, (3) 1st order log-linear distribution model in the discrete space and (4) 2nd order log-linear distribution model in the discrete space.
 For these four models, we make an experiment to measure the resolution accuracy.
 The test sample is from television broadcasting news.
 The measured accuracy by the cross validation test are 73\%, 78\%, 78\% and 81\% for (1), (2), (3) and (4) models, respectively.
 The unresolved examples show that semantic agreement between subject and predicate should be observed more accurately.
}

\ekeywords{Anaphoric binding, Zero-pronoun, Probabilistic model,
 Machine translation, Japanese language}

\begin{document}
\maketitle



\section{はじめに} \label{sec:はじめに}

照応や省略の問題は，言語学および言語工学の問題として広く研究されている．特に，日本語では，主語が省略される場合が多く，一方，英語では主語が必須であるため，日英機械翻訳において，省略された主語（ゼロ主語）の照応先を同定し，補完することが問題となる．主語を補完せず，受動文に翻訳することも考えられるが，受動文よりは能動文のままの方が望ましい．また，日英機械翻訳の別の問題として，文が長すぎるという問題がある．長い文は，翻訳に失敗することが多く，人手による前処理でも，長文の分割は大きな部分を占めている．この問題に対処する手段として，長文を複数の短文に自動的に分割する自動短文分割がある．しかし，分割された短文には，主語が含まれないことが多く，ここでもゼロ主語の補完の問題が発生する．
このような背景の下で，筆者らは，自動短文分割を利用した放送ニュース文の日英機械翻訳システムの中で，ゼロ主語の補完の問題を研究している．その基本的な考え方は確率モデルを用いるものである．ここで述べるゼロ主語の補完の問題は，従来から行われてきた，ゼロ主語の補完の問題とは，完全には一致していない．つまり，従来手法は，初めから異なる文の間で発生するゼロ主語を取り扱っており，ここでの問題は，短文分割によって人工的に生ずるゼロ主語を扱うものである
\footnote{例えば，従来手法は，「太郎は食べようとした」「しかし食べられな
  かった」のように２文からなる表現に対して，後方の文のゼロ主語を考察する
  ものが多い．しかし，ここでは，「太郎は食べようとしたが，食べられなかっ
  た」のように元は１文から成る文を２文に自動的に分割した後の表現を扱うの
  で，従来手法の考察範囲とはずれがある．そこで，本稿の手法が従来の問題に
  そのまま適用できることはない．}．
しかし，共通する部分も多いので，まず従来手法に検討を加える．

ゼロ主語の補完に対する従来のアプローチは大きく３種類に分類できる．第１
の方法は，「焦点」，「Centering」など，言語学における談話理論から得られ
る知見を利用するものである
\cite{Yoshimoto88,Nakagawa92,Nomoto93,Walker94,Takada95,清水95}．
この方法は，理論的な基礎づけがあるものの，比較的単純な文が対
象であり，放送ニュース文のような複雑な文に適用した例は見あたらない．ニ
ュース文に対するゼロ主語の補完には，従来の談話理論から得られる情報だけ
でなく，意味的なものなどさまざまな情報を広く考慮する必要がある．
第２の方法は，待遇表現など主として文末に現われる情報を利用するものである
\cite{Yoshimoto88,堂坂89,鈴木92}．しかし，本方法は対話文には
有効であるものの，ニュース文には不適当である．第３の方法は，ゼロ主語のま
わりの文脈から得られた各種情報をヒューリスティック規則にまとめるものであ
る\cite{Carbonell88,村田95}．この方法は，確率モデルによる方法と同
様，様々な情報が利用できる利点があるが，ヒューリスティック規則の作成や規
則適用の優先度の付与を人手で行っており，恣意性がある．

これらの従来手法に対して，確率モデルによる方法は，以下のような特徴を持つ．
\begin{itemize}
\item ゼロ主語の補完に有効な様々な情報を統一的に取り扱うことができる．
\item いったん学習データを作成した後は，自動的にモデルが構築できるので客観的であり，恣意性がない．
\item 確率モデルは言語工学のみでなく，多くの分野で利用されており，そこで得られた理論的知見や適用事例が利用できる．
\end{itemize}

確率モデルを用いたゼロ主語補完の方法としては，従来，多次元正規分布が用い
られていた\cite{金94}．本稿では，これをいくつかの分布に拡張する．そし
て，それらの分布を用いたモデルについて，主語補完の精度を評価するととも
に，誤った事例について考察を加え今後の課題を明らかにする．以下，
\ref{sec:主語補完の方法} 章では，主語補完の基本的な手順の説明を行う．
\ref{sec:確率モデル} 章では，本稿で考察する４種の確率モデルについて述べ
る．\ref{sec:補完実験} 章では，ゼロ主語の補完実験の方法と結果について述
べ，誤事例について考察する．

\section{主語補完の方法} \label{sec:主語補完の方法}

\subsection{基本的考え方} \label{subsec:基本的考え方}
言語を用いた人と人とのコミュニケーションにおいては，「言わなくとも分かること」は言わないのが普通であり，ゼロ主語の場合もこれに相当する．このような言われなかったことが実際に何を表すかは，広い意味での文脈から推定される．人間の場合は，生まれて以来修得した，あるいは生まれる前から持っている各種の知識が文脈として利用できるが，現在の計算機では，このようなことは不可能である．そこで，計算機で取り扱えるより狭い文脈を利用せざるをえない．つまりゼロ主語のまわりのテキスト自体を文脈として利用することになる
\footnote{「テキストが実世界とどのような関係にあるのか」という意味での文脈を context，「テキストのある部分が，そのテキスト全体とどのような関係にあるのか」という意味での文脈を discourse として区別することもあるが，ここでは両者ともに文脈と呼ぶ．}．
以下その方法を説明する．具体例については\ref{sec:補完実験} 章で述べる．ま
ず，主語補完が必要となる述語のまわりの文脈から，主語となりうる名詞句を候
補として取り出す．そして，これらの主語候補名詞句に関する様々な情報を特徴
パラメータとして，やはり文脈から抽出する．その結果，主語候補名詞句は特徴
パラメータの数の次元を持つ空間内の点として表現される．この空間を特徴パラ
メータ空間と呼ぶ．


実際の主語補完は，学習フェーズと補完フェーズの２つのフェーズに分けられる．前者は，学習データ（標本）を用いて，確率分布を推定するフェーズであり，補完フェーズに先だって行われる．後者は，実際の主語補完を行うフェーズである．

学習フェーズでは，学習データを使って，特徴パラメータ空間上で主語になる名詞句の分布と主語にならない名詞句（非主語）の分布を求める．具体的には，主語補完が必要な述語に対して，主語候補名詞句を抽出し，それらの名詞句の中でどれが真の主語であるかを人手で判断したデータを学習データとして用意する．そして，これらの学習データを用いて，特徴パラメータ空間上の確率分布を推定する．確率分布は，離散型の場合，確率関数で与えられ，連続型の場合は，確率密度関数で与えられる．このようにして学習（推定）された，主語の確率（密度）関数を$p$，非主語の確率（密度）関数を$q$ と書く．

補完フェーズでは，主語補完が必要な述語に対して，主語候補の名詞句$\{n_{1},n_{2},\cdots ,n_{k}\}$とそれらの特徴パラメータの値を文脈から抽出する．そして，これらの名詞句の中から，$p$と$q$ の比が最大となるもの
\begin{equation}
 n = \arg\max_{i=1, \cdots ,k} \frac{p(n_{i})}{q(n_{i})}
                                             \label{eq:尤度比}
\end{equation}
を主語として補完する．

\subsection{主語候補の範囲} \label{subsec:主語候補の範囲}
まず，文脈として考慮しているゼロ主語の付近，つまり，主語のない補完対象述語の付近のテキストの中から，補完されるべき主語候補を抽出する範囲を決めなければならない．本稿では，自動短文分割の後処理としての主語補完を考えているので，以下の範囲の名詞句に主語候補を制限した．
\begin{enumerate}
\item 主語候補は補完対象述語の左側にある．つまり，前方照応のみを考えている．
\item 主語候補は分割対象文内にある．分割前の複数文内の照応は考慮していない．
\item 主語候補は「は，が，では，を，で，も，に，の，としては，には」のいずれかの助詞（助詞相当表現を含む）を持つ名詞句である．ただし，「の」は動詞に連接する場合のみ（「太郎の書いた本」など）を対象とする
\footnote{ここで対象としてる格助詞は，原文での格を表わす助詞であり，補完
  された主語の格を表わすものではない．格助詞「を」を持つ名詞句が，正解候
  補である例は，\ref{subsec:誤りデータの分析}節の第１の例にある．}．
\end{enumerate}
これらの条件を満足する名詞句を主語候補として抽出する．

\subsection{特徴パラメータの設定} \label{subsec:特徴パラメータの設定}
次にこれらの主語候補や文脈が持っている種々の性質から主語補完に有効である性質を特徴パラメータとして取り出す．このような性質として，ここでは８種のものを選定した．この選定は，データの事前分析による経験的なものである．これらの特徴パラメータは以下に示すように，文法的性質，意味的性質および当該名詞句と補完対象述語の間の各種の距離に関する性質に分けられる．以下各特徴パラメータについて説明する．

\paragraph{（１）助詞の種類}
候補名詞句に付属する助詞の種類は主語補完に利用できる．この情報は従来の「談話分析」に基づく主語補完でも利用されている．考察する助詞の種類は，候補名詞句の範囲に含まれるものである．予備実験の結果，最も主語となる可能性が高い助詞から順に並べて，その順番に数値を小さい方から割り当てた．その結果，「は，では，が，の，としては，に，で，を，も，には」が０から９に対応した．間隔は１である．

\paragraph{（２）文字数}
主語が補完対象述語からどの程度離れているのかは，主語認定のもう一つの手掛かりになる．一般的に遠く離れているほど主語になれる可能性は低くなる．ここではその離れている度合，即ち距離を計る基準として，候補名詞句と補完対象述語との間の文字数を用いた．ただし，離散分布のときはスパースになりすぎるので文字数を１０で割って，少数点以下を切り捨てた値を特徴パラメータとした．距離に関するその他の基準としては，（５）から（８）までがある．

\paragraph{（３）意味的整合性}
主語候補と補完対象述語間の意味的結合の整合度は，格助詞「が」を中心とした語と語の係り受けデータ\cite{田中89}と分類語彙表\cite{国語研64}を利用して計算する．まず，あらかじめ係り受けデータを分類語彙表を用いて，係り元の分類番号（３桁）と係り先の語形の間の係り受けデータに変換しておく．次に，実行時には，主語候補の分類番号を求め，その番号と補完対象述語の語形との間に係り受け関係があるかどうかを係り受けデータの中で検索する．そして，検索に成功したものを整合するとして，以下の数値を用いる．
\begin{itemize}
 \item 整合する場合：2.0　
 \item 整合しない場合：0.0
 \item 主語候補の分類番号が得られなかった場合：1.0
\end{itemize}

\paragraph{（４）連体節との関係}
連体節に含まれる名詞句の係り受け範囲はその連体節に制限される場合が多いので，主語候補が連体節に含まれているかいないかは主語認定の手掛かりになる．連体節に含まれている場合は「１」，いない場合は「０」に数量化した．

\paragraph{（５）「は」の数}
一般的に係助詞「は」はある主題を表すので，同一文内で他の「は」によって主題の切り替えを行なった際，前者が後者を越えて係る場合はあまり見られない．即ち，同一文内の「は」助詞は相互に影響を受ける．本パラメータは，候補名詞句と補完対象述語との間の係助詞「は」の数である．

\paragraph{（６）「が」の数}
同じく，格助詞「が」の数である．「が」も「は」のように相互に影響を受けるため，他の「が」の存在は主語補完に有効な情報である．

\paragraph{（７）「は」「が」以外の格文節の数}
同じく，「は」と「が」以外の格文節の数である．通常，主語候補の内，述語により近いものが主語として認定される可能性が高いのでこの格文節の数が少ないほど主語として認定されやすい．ただし，ここでは補完対象述語自身は数えない．

\paragraph{（８）動詞の数}
主語候補と述語の間に存在する動詞の数を示す．一般的に，文末に係る主語を除
いて，この数値が大きいほど主語になれる可能性は低い．ただし，連体形の動詞
は数えない．

\bigskip\bigskip
以上の特徴パラメータの値は，形態素解析，文節認定およびグルーピングと呼ば
れる部分的な構文解析によって得られる\cite{金94}．また，
\ref{subsec:主語候補の範囲} 節で述べた主語候補の抽出もこれらのプログラム
によって行うことができる．

\subsection{確率モデルの範囲と主語補完の方法} \label{subsec:確率モデルの範囲と主語補完の方法}

\ref{subsec:特徴パラメータの設定} 節で述べた特徴パラメータの個数は$8$であ
るので，特徴パラメータ空間の次元は$8$となる．従来法では，この特徴パラメ
ータの空間を，実ベクトル空間として，多次元正規分布モデルによる主語補完を
行っていた\cite{金94}．しかし，特徴パラメータは，本来，離散的なものであ
る．そこで，本稿では，連続モデルと離散モデルの双方について考察する．本稿
で対象としている確率モデルは

\begin{quote} \vspace*{2mm}
\begin{tabular}{ll}
連続分布 & 正規分布 \\
         & 疑似正規分布 \\
離散分布 & １次対数線形分布 \\
         & ２次対数線形分布 \\
\end{tabular}
\vspace*{2mm} \end{quote}
である．このモデルの詳細は章を改めて述べる．学習フェーズでは，これらのモ
デルに対して，その母数\footnote{確率分布のパラメータのことであるが，特徴
  パラメータと混同しないために母数という用語を用いる．}を学習データから推
定する．補完フェーズでは，主語と非主語の確率（密度）関数の値，$p$と$q$ 
を求め，式(\ref{eq:尤度比})に従って主語を補完する．

\section{確率モデル} \label{sec:確率モデル}

\subsection{連続分布} \label{subsec:連続分布}
連続分布としては，多次元正規分布と正規分布に基づくGram-Charlier展開\cite[pp.228-229]{Stuart94}を多次元に拡張した分布（疑似正規分布と呼ぶ）について考察した．連続分布の場合は，$p,q$ として，確率密度関数を用いる．それらを，正規分布の場合は，$p_{G},q_{G}$と書き，疑似正規分布の場合は，$p_{H},q_{H}$と書く．

\paragraph{正規分布}
正規分布は連続分布として広く用いられる分布であり，まず正規分布から出発するのは自然である．正規分布の密度関数は，特徴パラメータ空間の次元を$k$（今の場合$k=8$）とするとき，以下のようになる．主語の分布に対して，平均値ベクトルを$\mu_{p}$，共分散行列を$\Sigma_{p}$とし，特徴パラメータ空間における主語候補の点の位置を${\bf x}$とするとき，
\begin{equation}
 p_{G}({\bf x})=(\frac{1}{\sqrt{2\pi}})^{k}
       \frac{1}{\sqrt{\det{\Sigma_{p}}}}
       \exp{-\frac{1}{2}({\bf x}-\mu_{p})^{t}\Sigma_{p}^{-1}
        ({\bf x}-\mu_{p})}
\end{equation}
と書ける．非主語の分布に対する$q_{G}$についても同様である．分布の母数の数は平均値ベクトルで$k$個，共分散行列で$k(k+1)/2$個である．

\paragraph{疑似正規分布}
正規分布は対称であるが，後述する実験から，$p,q$は非対称であることが観察される．そこで，非対称性を扱える分布として，疑似正規分布を考える．この場合は，密度関数が
\begin{equation}
 p_{H}({\bf x})=[\sum_{(i_{1},i_{2},\cdots,i_{k})\in I}
       a_{i_{1}i_{2} \cdots i_{k}}
       H^{1}_{i_{1}}({\bf x}) H^{2}_{i_{2}}({\bf x}) \cdots
       H^{k}_{i_{k}}({\bf x})] p_{G}({\bf x})
       \label{eq:hermite}
\end{equation}
と表される．ここで，$I$ はインデックスの集合であり，$p_{G}({\bf x})$は正規分布の密度関数である．$H^{j}_{i_{j}}$は$i_{j}$次のHermite多項式から計算される．式 (\ref{eq:hermite})の導出は付録\ref{app:疑似正規分布}で詳述する．非主語に対する$q_{H}$の場合も同様である．疑似正規分布の母数は，平均値ベクトル，共分散行列に加えて，係数$a_{i_{1}i_{2}\cdots i_{k}} ((i_{1},i_{2},\cdots ,i_{k})\in I)$がある．係数$a_{i_{1}i_{2}\cdots i_{k}}$の次数を$m=i_{1}+i_{2}+\cdots +i_{k}$とすると，$m$次の係数の総数は$(k+m-1)!/m!(k-1)!$となる．$0$次の係数は$1$であり，$1$次と$2$次の係数はすべて$0$である．今回の考察では，$3$次以下の係数のみを用いている．そこで，$a_{i_{1}i_{2}\cdots i_{k}} ((i_{1},i_{2},\cdots ,i_{k})\in I)$の総数は$k(k+1)(k+2)/6$個である（$0$次を除く）．なお，疑似正規分布では，分布の裾の方で値が$0$以下になってしまう場合が起こり得る．このような場合には，$p_{H}$や$q_{H}$の代わりに$p_{G}$や$q_{G}$を用いた．

\subsection{離散分布} \label{subsec:離散分布} 
前節で述べたように，特徴パラメータは離散的であり，離散分布を適用するのが本来である．離散分布は特徴パラメータに対する同時分布の確率関数$p(i_{1},i_{2}, \cdots ,i_{k})$で表現される．この意味は，$j$番目$(j=1,\cdots,k)$の特徴パラメータが$i_{j}$という値を取る事象の確率である．$j$番目のパラメータが取る値の範囲を$i_{j}=1,2,\cdots,I_{j}$とすると，単純に離散モデルを適用した場合，母数の数は$I_{1} \times I_{2} \times \cdots \times I_{k}$となってしまう．このように多くの母数に対して，その値を精度良く推定するためには，極めて大きい標本が必要となり，現実的でない．そこで，母数の数を少なくするために対数線形分布を用いる．この分布は，確率関数$p$の対数が
\begin{eqnarray}
 \lefteqn{
  \log{p(i_{1},i_{2}, \cdots ,i_{k})}
 } \nonumber \\
 &=& \log{h^{(0)}}+ \sum_{j=1}^{k} \log{h^{(1)}_{j}(i_{j})}
   +\sum_{j=1}^{k-1} \sum_{l=j+1}^{k} \log{h^{(2)}_{j,l}(i_{j},i_{l})}
   \nonumber \\
 & & +\sum_{j=1}^{k-2} \sum_{l=j+1}^{k-1} \sum_{m=l+1}^{k} 
   \log{h^{(3)}_{j,l,m}(i_{j},i_{l},i_{m})}+ \cdots
\end{eqnarray}
のように書ける分布である．ここで，関数$h^{(i)}_{j_{1},j_{2}, \cdots ,j_{i}}$の値は$j_{1},j_{2}, \cdots ,j_{i}$番目の特徴パラメータの値のみの関数であり，それらの特徴パラメータに対する周辺分布から計算される．本稿では，$h^{(1)}_{j}$のみを用いる１次対数線形分布および$h^{(2)}_{j,l}$のみを用いる２次対数線形分布を考える．前者に対する確率関数$p$，$q$を$p_{1}$，$q_{1}$と書き，後者に対しては，$p_{2}$，$q_{2}$と書く．ただし，両分布とも，$p$の値が$0$となる場合には，主語に対する学習データの総数$N_{p}$を用いて，$ p=\frac{1}{N_{p}} $とフロアリングした．$q$の値が$0$となる場合には，非主語に対する学習データの総数$N_{q}$を用いて，$ q=\frac{1}{N_{q}} $とした．

\newpage
\paragraph{１次対数線形分布} 
１次対数線形分布は
\begin{equation}
 p_{1}(i_{1},i_{2}, \cdots ,i_{k})=
  \prod_{j=1}^{k} h^{(1)}_{j}(i_{j})
\end{equation}
と表される．$h^{(1)}_{j}(i_{j}) (j=1,\cdots,k)$は$j$番目の特徴パラメータの値$i_{j}$のみの関数であり，$p^{(1)}_{j}$をパラメータ$j$ に対する１次の周辺分布とするとき，
\begin{equation}
 p^{(1)}_{j}(i_{j})=
  \sum_{i_{1}=1}^{I_{1}} \cdots \sum_{i_{j-1}=1}^{I_{j-1}}
  \sum_{i_{j+1}=1}^{I_{j+1}} \cdots \sum_{i_{k}=1}^{I_{k}}
  \prod_{j^{'}=1}^{k} h^{(1)}_{j^{'}}(i_{j^{'}})
\end{equation}
を満足するように定められる．このような$h^{(1)}_{j}$は実は$p^{(1)}_{j}$そのものである．つまり，
\begin{equation}
  p_{1}(i_{1},i_{2}, \cdots ,i_{k})=
    \prod_{j=1}^{k} p^{(1)}_{j}(i_{j})
\end{equation}
となる．これは特徴パラメータが互いに独立であると仮定した分布に他ならない．この場合の母数は$p^{(1)}_{j}(i_{j}) (j=1, \cdots ,k; i_{j}=1, \cdots ,I_{j})$であり，その総数は$I_{1}+I_{2}+ \cdots +I_{k}$となる．非主語に対する１次対数線形分布$q_{1}$についても同様に定義される．

\paragraph{２次対数線形分布} 
２次対数線形分布は
\begin{equation}
  p_{2}(i_{1},i_{2}, \cdots ,i_{k})= 
   \prod_{j=1}^{k-1} \prod_{l=j+1}^{k}
   h^{(2)}_{j,l}(i_{j},i_{l})
\end{equation}
と表される．$h^{(2)}_{j,l}(i_{j},i_{l}) (j=1,\cdots,k-1, l=j+1,\cdots,k)$は$j$番目の特徴パラメータの値$i_{j}$および$l$番目の特徴パラメータの値$i_{l}$のみの関数であり，$p^{(2)}_{j,l}(i_{j},i_{l})$をパラメータ$j,l$に対する２次の周辺分布とするとき，
\begin{eqnarray}
 \lefteqn{
  p^{(2)}_{j,l}(i_{j},i_{l})
 }  \nonumber \\
 &=& \sum_{i_{1}=1}^{I_{1}} \cdots \sum_{i_{j-1}=1}^{I_{j-1}}
  \sum_{i_{j+1}=1}^{I_{j+1}} \cdots \sum_{i_{l-1}=1}^{I_{l-1}}
  \sum_{i_{l+1}=1}^{I_{l+1}} \cdots \sum_{i_{k}=1}^{I_{k}}
  \prod_{j^{'}=1}^{k-1} \prod_{l^{'}=j^{'}+1}^{k}
    h^{(2)}_{j^{'},l^{'}}(i_{j^{'}},i_{l^{'}})
    \label{eq:制約式２}
\end{eqnarray}
を満足するように定められる．このような$h^{(2)}_{j,l}(i_{j},i_{l})$は２次の周辺分布から，比例反復法\cite[pp.235-238]{廣津82}に基づいて求めることができる．その方法を付録\ref{app:比例反復法}に示す．この場合の母数は$h^{(2)}_{j,l}(i_{j},i_{l}) (j=1,2, \cdots ,k-1; i_{j}=1,2, \cdots ,I_{j}; l=j,j+1, \cdots ,k; i_{l}=1,2, \cdots ,I_{l})$であり，その総数は，
\begin{equation}
  \sum_{j=1}^{k-1} \sum_{l=j+1}^{k} I_{j} \cdot I_{l}
\end{equation}
となる．非主語に対する２次対数線形分布$q_{2}$についても同様に定義される．

\section{補完実験} \label{sec:補完実験}
３８１文の放送ニュース文を用いて，ゼロ主語の補完実験を行った．これらの文
は，１９９１年１月１日から２月１０日までの間のＮＨＫのニュース原稿からラ
ンダムに選択された．これらの文にあらかじめ形態素解析と自動短文分割を施し
た結果，主語補完が必要な文が１０８文得られた．これら１０８文に含まれる補
完対象述語に対して主語候補名詞句を文脈中より抽出した．各補完対象述語に対
する主語候補の個数の分布を図\ref{fig:候補名詞数の分布} に示す．

\begin{figure}
 \center{
  \atari(70.0,50.0)
  
  \caption{候補名詞数の分布} \label{fig:候補名詞数の分布}
 }
\end{figure}
図\ref{fig:候補名詞数の分布} から，１０８個の述語に対して，ランダムに主語
補完を行った時の補完精度は$35.8$\%であることが分かる．いかなる補完手法で
あっても，補完精度がこの値より良くなくては意味がない．そこで，この値を基
準精度とすることができる．次にこれらの述語に対して正しい主語を人手により
選択するとともに，主語候補の名詞句の特徴パラメータの値を求め，実験データ
を作成した．そして，実験データを元に交差確認法（cross validation）によっ
て，手法の精度を評価した．

\subsection{母数の推定値の考察}
精度評価実験を行う前に，\ref{sec:確率モデル} 章で述べた各分布に対して，母
数を推定した結果を考察する．なお，ここでの推定は，実験データを全て用いて
行った．

\paragraph{連続分布}
まず，正規分布と疑似正規分布の母数の推定値について考察する．平均値ベクトル$\mu_{p},\mu_{q}$は以下のようになった．
\begin{equation}
  \mu_{p} = ( 1.03, 2.48, 1.54, 0.01, 0.12, 0.35, 2.81, 1.58)^{t}
\end{equation}
\begin{equation}
  \mu_{q} = ( 4.83, 2.44, 0.74, 0.23, 0.28, 0.52, 2.60, 1.58)^{t}
\end{equation}
また，共分散行列$\Sigma_{p}, \Sigma_{q}$の下三角成分は以下のようになった．
\begin{equation}
\def\arraystretch{}
\begin{array}{rrrrrrrr}
\Sigma_{p} = \hspace*{12mm} \\[-1mm]
   1.93 \\
  -0.55 &  2.08 \\
   0.14 &  0.19 &  0.58 \\
   0.02 & -0.01 &  0.00 &  0.01 \\
   0.00 &  0.14 &  0.02 & -0.00 &  0.16 \\
  -0.05 &  0.42 &  0.02 &  0.01 &  0.06 &  0.28 \\
  -0.92 &  1.93 &  0.09 & -0.02 &  0.13 &  0.27 &  2.93 \\
  -0.23 &  0.95 &  0.18 & -0.01 &  0.11 &  0.24 &  0.91 &  0.82
\end{array}
\end{equation}
\begin{equation}
\def\arraystretch{}
\begin{array}{rrrrrrrr}
\Sigma_{q} = \hspace*{12mm} \\[-1mm]
     7.59 \\
  -1.08 &  1.77 \\
  -0.25 &  0.03 &  0.75 \\
   0.07 &  0.06 &  0.01 &  0.18 \\
  -0.26 &  0.27 &  0.01 &  0.01 &  0.31 \\
  -0.26 &  0.54 &  0.03 &  0.02 &  0.09 &  0.42 \\
  -0.58 &  1.39 &  0.07 &  0.03 &  0.16 &  0.29 &  2.14 \\
  -0.52 &  0.84 &  0.16 & -0.02 &  0.19 &  0.26 &  0.72 &  0.93
\end{array}
\end{equation}
$\mu_{p}$と$\mu_{q}$を比較することで，以下のことが平均的には言える．
\begin{enumerate}
\item 主語は数値の小さい助詞を持つ名詞句がなりやすい．
\item 意味的整合性が高い方が主語になりやすい．
\item 連体節に含まれる名詞句は主語になりにくい．
\item 補完対象述語と候補名詞句の間の「は」や「が」の数が少ないほど主語になりやすい．
\end{enumerate}
これらの結果は，\ref{subsec:特徴パラメータの設定} 節で述べたことがらとほ
ぼ一致しており，特徴パラメータの性質が実験的にも確かめられた．共分散行列
は，対角に近いものであり，各特徴パラメータの間の相関はあまり強くないこと
が分かる．共分散行列を用いた詳しい考察は\cite{金93}を参照されたい．

\noindent
共分散行列の行列式の値は
\begin{eqnarray}
　\det{ \Sigma_{p} }= 0.0002 \\
　\det{ \Sigma_{q} }= 0.0488
\end{eqnarray}
であった．この値から主語の分布より非主語の分布の方が広がりが大きいことがわかる．
共分散行列から計算された Cholesky 分解（後述）の逆行列の下三角成分は以下のようになった．
\begin{equation}
\def\arraystretch{}
\begin{array}{rrrrrrrr}
C_{p}^{-1} = \hspace*{12mm} \\[-1mm]
　 1.39 \\
　-0.40 &  1.39 \\
　 0.10 &  0.17 &  0.74 \\
　 0.01 &  0.00 &  0.00 &  0.09 \\
　 0.00 &  0.11 &  0.00 & -0.01 &  0.39 \\
　-0.03 &  0.29 & -0.03 &  0.07 &  0.08 &  0.43 \\
　-0.66 &  1.20 & -0.07 & -0.07 & -0.01 & -0.23 &  0.99 \\
　-0.17 &  0.63 &  0.12 & -0.03 &  0.10 &  0.11 &  0.07 &  0.59
\end{array}
\end{equation}
\begin{equation}
\def\arraystretch{}
\begin{array}{rrrrrrrr}
C_{q}^{-1} = \hspace*{12mm} \\[-1mm]
　 2.76 \\
　-0.39 &  1.27 \\
　-0.09 &  0.00 &  0.86 \\
　 0.02 &  0.05 &  0.01 &  0.42 \\
　-0.09 &  0.18 &  0.00 &  0.01 &  0.52 \\
　-0.09 &  0.39 &  0.03 &  0.01 &  0.02 &  0.51 \\
　-0.21 &  1.03 &  0.06 & -0.04 & -0.09 & -0.28 &  0.97 \\
　-0.19 &  0.60 &  0.17 & -0.12 &  0.12 &  0.00 &  0.05 &  0.69
\end{array}
\end{equation}
次に，疑似正規分布のパラメータを吟味する．１２０個の３次の係数の推定値の
分布は図\ref{fig:疑似正規分布の係数の値} のようである．
\begin{figure}
 \center{
  \atari(140.0,55.0)
  
  \caption{疑似正規分布の係数の値} \label{fig:疑似正規分布の係数の値}
 }
\end{figure}
このことから，多くの係数は$0$に近いことがわかる．特に，非主語の係数について，そうである．絶対値が$0.2$より大きい係数は，以下のとおりである．
\begin{equation}
\def\arraystretch{}
\begin{array}{rrcrr}
  \multicolumn{2}{c}{主語の分布}  & & \multicolumn{2}{c}{非主語の分布} \\
  i_{1},\cdots,i_{k} & a_{i_{1}\cdots i_{k}} & 　　　 &
  i_{1},\cdots,i_{k} & a_{i_{1}\cdots i_{k}}  \\
　0  0  0  3  0  0  0  0 &  1.65 & &  0  1  0  0  2  0  0  0 &  0.36  \\
　1  0  0  2  0  0  0  0 &  0.72 & &  0  1  0  0  0  2  0  0 &  0.35  \\
　0  0  0  0  3  0  0  0 &  0.65 & &  0  0  0  0  3  0  0  0 &  0.29  \\
　0  1  0  0  2  0  0  0 &  0.58 & &  0  0  0  3  0  0  0  0 &  0.20 \\
　0  1  0  0  0  2  0  0 &  0.31  \\
　3  0  0  0  0  0  0  0 &  0.30  \\
　0  1  1  0  0  0  0  1 &  0.23  \\
　0  3  0  0  0  0  0  0 &  0.22  \\
　0  0  1  2  0  0  0  0 &  0.22  \\
　0  1  0  0  0  0  0  2 &  0.21  \\
　0  1  1  0  0  1  0  0 & -0.21 \\
\end{array}
\end{equation}
$i_{4}$の部分は，特徴パラメータの$(4)$「連体節との関係」にほぼ対応している．このパラメータの値は，主語の分布に対する学習データのうちで１となるものが１データしかなく，分布の偏りが特に大きい．このため，主語の分布の第１，２行目の係数値が大きくなっている．

\paragraph{離散分布}
１次対数線形分布の母数の推定値は，１次の周辺分布である．それを図
\ref{fig:１次の周辺分布} に示す．図\ref{fig:１次の周辺分布} から，
\ref{subsec:特徴パラメータの設定} 節で述べたことが確認できる．また，
分布の非対称性が大きいことが分かる．

\begin{figure}
 \center{
  \atari(130.0,190.0)
  
  \caption{１次の周辺分布} \label{fig:１次の周辺分布}
 }
\end{figure}

２次対数線形分布の母数の推定値$h^{(2)}_{j,l}(i_{j},i_{l})$と２次の周辺分
布$p^{(2)}_{j,l}(i_{j},i_{l})$の関係を主語の場合について，
図\ref{fig:２次対数線形分布の母数} に示す．
$h^{(2)}_{j,l}(i_{j},i_{l})$の値はかなり
ばらついていることが分かる．この値は$4$回の繰り返し後の結果である．この
$h^{(2)}$を式(\ref{eq:制約式２})に代入して得た$p^{(2)}$の値と実験データ
から直接推定した$p^{(2)}$の値の差は最大$0.005$であり，比例反復法は十分に
収束している．

\begin{figure}
 \center{
  \atari(70.0,47.0)
  
  \caption{２次対数線形分布の母数} \label{fig:２次対数線形分布の母数}
 }
\end{figure}

\subsection{ゼロ主語補完精度の評価}
\ref{sec:確率モデル} 章で提案した$4$種の確率モデルについて，
式(\ref{eq:尤度比})に基づくゼロ主語補完の実験を行い，精度を評価した．
実験は closed test と open test に分けて行った．closed test は実験データ
全体を学習データと試験データの双方に用いるものである．一方，open test は
以下のような交差確認法（cross validation test）によった．
実験データから４個のデータを除いて，残りを学習データとし，除いたデータを
試験データとして，補完実験を行う．このような実験を試験データの範囲をずら
せながら，合計$27$回$(108/4)$行った．実験結果を表\ref{tab:実験結果} に示
す．ここで，１位とは，正解の主語に対する式(\ref{eq:尤度比})の値が１位で
あることを意味する．

   \begin{table}
   \begin{center}
    \caption{ゼロ主語補完実験結果}
    \label{tab:実験結果}
     closed test
    \vspace{.5\baselineskip}\\
    \begin{tabular}{|c|c|c|c|c|} \hline
             &    Ｇ      &     Ｈ     &     １      &   ２       \\ \hline
    １位     &  84(77.8)  &  93(86.1)  &  91(84.3)   & 107(99.1)  \\
    １〜２位 & 101(93,5)  & 104(96.3)  &  106(98.1)  & 108(100.0) \\
    ３位以下 &   7        &   4        &   2         &   0        \\ \hline
    \end{tabular}
    \vspace{\baselineskip}\\
     open test
    \vspace{.5\baselineskip}\\
    \begin{tabular}{|c|c|c|c|c|} \hline
             &    Ｇ      &     Ｈ     &     １      &   ２       \\ \hline
    １位     &  79(73.1)  &  84(77.8)  &  84(77.8)   &  87(80.6)  \\
    １〜２位 & 100(92.6)  & 101(93.5)  &  103(95.4)  & 102(94.4)  \\
    ３位以下 &   8        &   7        &   5         &   6        \\ \hline
    \end{tabular}
    \vspace{.5\baselineskip}\\
    \begin{tabular}{l}
      Ｇ：正規分布　Ｈ：疑似正規分布 \\
      １：１次対数線形分布　２：２次対数線型分布 \\
      かっこ内は補完精度（％） \\
    \end{tabular}
   \end{center}
   \end{table}
   
この結果から以下のことがいえる．
\begin{itemize}
\item 母数の数が多い分布を用いた方が，少ない分布を用いるより closed test，open test 共に精度が高い．つまり，過学習による精度の低下は見られない．
\item 連続分布モデルより離散分布モデルの方が精度が高い．
\item ２次対数線形分布モデルは closed test，open test 共に最も精度が高い．
\end{itemize}

\subsection{補完例}
試験データに対して，ゼロ主語補完を行った例を示す．(\ref{eq:補完例})で，$L_{p_{G}/q_{G}}$などとあるのは，$p_{G}/q_{G}$の$10$を底とする対数の意味である．
\begin{itemize}
\item 原文：橋本大蔵大臣はきょうの閣議のあとの記者会見で，湾岸戦争終結後，円安・ドル高が進んでいる為替水準について，現在のドル高はアメリカ経済のファンダメンタルズ＝基礎的な力を反映したものではなく好ましくないという考えを強調しました．
\item 分割文２：考えを強調しました．
\item 補完対象述語：強調する
\item 主語候補パラメータ値と評価値：
\begin{equation}
\begin{array}{lrrrrr} \nonumber
 主語候補 & パラメータ値 & L_{p_{G}/q_{G}} & L_{p_{H}/q_{H}} 
                         & L_{p_{1}/q_{1}} & L_{p_{2}/q_{2}} \\
 大臣　　 & 0\ 52\ 2\ 0\ 1\ 1\ 4\ 4 &   1.92 &   4.16 &  0.82 &   1.82 \\
 会見　　 & 6\ 44\ 0\ 0\ 1\ 1\ 4\ 3 & -11.36 &  -8.52 & -4.03 & -20.50 \\
 ドル高　 & 2\ 32\ 1\ 1\ 1\ 0\ 3\ 3 & -57.19 & -49.85 & -3.91 & -36.12 \\
 ドル高　 & 0\ 22\ 1\ 0\ 0\ 0\ 2\ 2 &   3.63 &   4.23 &  1.71 &   1.33 \\
 力　　　 & 7\ 13\ 2\ 1\ 0\ 0\ 1\ 2 & -53.73 & -46.82 & -5.62 & -13.26 \\ \\
\end{array}
\label{eq:補完例}
\end{equation}
\end{itemize}
正しい主語は「大臣」である．この場合，正規分布，疑似正規分布，１次対数線形分布はいずれも２番目の「ドル高」を補完しており，不正解である．これは，「ドル高」に付加している助詞が「は」であり，しかも述語に近いためである．これに対して，２次対数線形分布は正しく「大臣」を補完している．特徴パラメータ間の相互関係を考慮することが有効に働いて正しい補完が行われた．

\subsection{誤りデータの分析} \label{subsec:誤りデータの分析}
本節では，実験の結果，最も精度が高かった２次対数線形分布モデルについて，
主語補完を誤った事例を分析する．このような誤事例に対して，正解候補と補完
候補の意味的整合性に関する分布を
表\ref{tab:誤事例の意味的整合性に関する分布} に示す
（パラメータ値の意味は\ref{subsec:特徴パラメータの設定} 節参照）．
誤事例の総数は$21$である．この表から，以下のようなことが明らかになる．


   \begin{table}
   \begin{center}
    \caption{誤事例の意味的整合性に関する分布}
    \label{tab:誤事例の意味的整合性に関する分布}
    \begin{tabular}{|c|c||c|c|c|} \hline
    \multicolumn{2}{|c||}{} & \multicolumn{3}{c|}{補完候補の} \\
    \multicolumn{2}{|c||}{} & \multicolumn{3}{c|}{パラメータ値} \\
        \cline{3-5}
    \multicolumn{2}{|c||}{}
         & \multicolumn{1}{p{1.2em}|}{\centering 2}
         & \multicolumn{1}{p{1.2em}|}{\centering 1}
         & \multicolumn{1}{p{1.2em}|}{\centering 0} \\ \hline \hline
     \raisebox{-5pt}[0pt][0pt]{正解候補の}
         & 2 & 6 & 0 & 8\\
         & 1 & 1 & 1 & 1\\
     \raisebox{5pt}[0pt]{パラメータ値}
         & 0 & 1 & 0 & 3\\ \hline
    \end{tabular}
   \end{center}
   \end{table}

正解候補が非整合$(0)$で，補完候補が整合$(2)$している事例は１例である．このことから，意味的整合性を特徴パラメータに加えたことによって，精度が低下することは少ないことがわかる．言い替えると，意味的整合性が副作用を起こす場合は少ないとも言える．

正解候補が整合で，補完候補が非整合の事例は８例ある．これらは，意味的に整
合しているにもかかわらず，正解として選択されていない例である．８例の正解
候補に対する助詞の種類を調べると，「は」が２例で，「では，が，の，として
は，に，を」が各１例である．このように，主語になりにくい助詞が付加してい
る場合が半数である．このことから，意味的整合性の把握が，まだ不十分である
ことがわかる．つまり，助詞の種類の情報を上回るだけの意味的整合性の情報が
得られていない．このことは，図\ref{fig:１次の周辺分布} （ｃ）で，主語かつ
非整合，非主語かつ整合の確率がそれほど小さくないことからも分かる．意味的
整合性をより正確に捉える特徴パラメータを見いだすことは今後の課題である．
この場合の誤事例を以下に示す．

\begin{itemize}
\item 原文：政府は湾岸危機に対する中東貢献策のひとつとして国連平和協力法案を去年の秋の臨時国会に提出しましたが，野党側が強く反発し，結局，廃案となりました．
\item 主語補完対象述語：廃案となる
\item 正解候補：法案　整合
\item 補完候補：野党側　非整合
\vspace*{3mm}
\end{itemize}

正解候補も補完候補も非整合である３例を正解とするためには，前項と同様に，より正確な意味的整合性の把握が必要である．これら３例は，いずれも人間が判断すれば，正解候補が整合となるものである．この場合の誤事例を以下に示す．
\begin{itemize}
\item 原文：一戸建住宅の福袋は１個だけ，福袋のコーナーでは家族連れなどが住宅の写真や間取りを見ながら次々と申込みを済ませていました．
\item 主語補完対象述語：済ませる
\item 正解候補：家族連れ　非整合
\item 補完候補：コーナー　非整合
\vspace*{3mm}
\end{itemize}

正解候補も補完候補も整合の６事例は，ここで用いているような単純な意味的整合性ではどちらも整合となる場合であり，この誤りをなくすには，より深い解析が必要であろう．しかし，現状では，このような深い解析を広範な文書に対して行うのは困難であり，この種の誤事例が最後まで残るものと思われる．この場合の例を示す．
\begin{itemize}
\item 原文：政府としては，こうした流れを踏まえて，サミット後の７月下旬にも中山外務大臣がソビエトを訪問し，このあと，海部総理大臣の早期のソビエト訪問を実現し，より突っ込んだ交渉を行うことを目指しています．
\item 主語補完対象述語：実現する
\item 正解候補：政府　整合
\item 補完候補：（中山外務）大臣　整合
\vspace*{3mm}
\end{itemize}

最後に，正解候補または補完候補の分類番号が得られなかった誤事例は，３例であり，比較的少数である．これらは，分類語彙表に出現しない未登録語であり，その解決には，分類語彙表の増補を待たなければならない．他の類語辞典を利用することも考えられるが，いずれにしても，未登録語が出現する．

\section{おわりに}
確率モデルを用いたゼロ主語補完の方法について，４種類のモデルを比較した．
その結果，２次対数線形分布モデルが最も精度が高かった．さらに，３次以上の
対数線形分布モデルや，複数の次数が混在しているモデルも考えられるが，２次
のモデルが，学習データに対して，極めて高い精度をもっていることから，単な
る次数の増加による精度の向上は期待できない．それよりも，
\ref{subsec:誤りデータの分析} 節で述べたような誤事例をふまえて，より適切
な特徴パラメータを利用することが望まれる．この点は今後の課題である．
本方法は，計算機によって観測可能でありさえすれば，いかなる情報であっても
特徴パラメータとして利用できるので，（計算）言語理論の進展に伴って，
精度の向上が期待できる．

ここで述べた確率モデルはいずれも特徴パラメータ空間を基礎にしており，一般化すれば，特徴パラメータ値のリストとカテゴリー（本稿の場合は，主語か非主語）の組からなる表状のデータに対する解析と見ることができる．このようなデータ形式は，種々の情報を組み合わせて利用するような問題で，しばしば現われる．本稿で述べた確率モデルはそのような問題にも適用することができる．例えば，
\begin{itemize}
\item 主語以外の必須格に対するゼロ要素の補完
\item 代名詞の照応
\item 名詞の定，不定の判別
\end{itemize}
などがあるが，さらに，言語工学の基本問題である
\begin{itemize}
\item 語彙的曖昧性の解消問題
\item 構造的曖昧性の解消問題
\end{itemize}
にも適用可能であろう．

\acknowledgment

本研究と発表の機会を与えていただいたＮＨＫ放送技術研究所 西澤台次所長，先端制作技術研究部 榎並和雅部長に感謝する．また，本研究に対して有意義なコメントをいただいた当部自動翻訳研究グループの各氏に感謝する．


\appendix
\section{疑似正規分布の導出と母数の推定} \label{app:疑似正規分布}

$k$次元の実数空間に値をとる確率変数${\bf X}=(X_{1},X_{2},\cdots,X_{k})^{t}$の$(i_{1},i_{2},\cdots,i_{k})$次のモーメント$\mu_{i_{1}i_{2}\cdots i_{k}}$は$E$を期待値をとる作用素として，
\begin{equation}
 \mu_{i_{1}i_{2}\cdots i_{k}}=
   E[X_{1}^{i_{1}}X_{2}^{i_{2}} \cdots X_{k}^{i_{k}}]
\end{equation}
である．これらを用いて，まず，平均値ベクトル$\mu$と共分散行列$\Sigma$が以下のように求められる．$\mu$の要素を$\mu_{1},\mu_{2},\cdots,\mu_{k}$とすると，
\begin{equation}
 \begin{array}{ll}
 \mu_{1} = \mu_{100 \cdots 0}, \\
 \mu_{2} = \mu_{010 \cdots 0}, \\
 　　　\cdots  \\
 \mu_{k} = \mu_{00 \cdots 01}
 \end{array}
\end{equation}
である．また，$\Sigma$の$(i,j)$要素$(i,j=1, \cdots ,k)$を$\Sigma_{ij}$とすると
\begin{equation}
 \begin{array}{ll}
 \Sigma_{11} = \mu_{20 \cdots 0} - \mu_{1} \mu_{1},  \\
 \Sigma_{12} = \mu_{110 \cdots 0} - \mu_{1} \mu_{2},  \\
 　　　\cdots  \\
 \Sigma_{ij} = \mu_{0 \cdots 0 \breve{1} 0 \cdots 0 \breve{1} 0 
   \cdots 0}^{\; \; \; \; \; \; \; i \; \; \; \; \; \; \; j } 
    - \mu_{i} \mu_{j}
 \end{array}
\end{equation}
などと求められる．

$\Sigma$の Cholesky 分解$(\Sigma=CC^{t})$が正則であるとして，
\begin{equation}
 {\bf Y} = C^{-1}( {\bf X} - \mu)
\end{equation}
と変数変換を行い，$\mu$のまわりの $(i_{1},i_{2}, \cdots ,i_{k})$次の正規化モーメント$\alpha_{i_{1}i_{2} \cdots i_{k}}$が
\begin{equation}
 \alpha_{i_{1}i_{2} \cdots i_{k}}=
   E[Y_{1}^{i_{1}}Y_{2}^{i_{2}} \cdots Y_{k}^{i_{k}}]
\end{equation}
と求められる．

さらに，式(\ref{eq:hermite})の係数を求める．式(\ref{eq:hermite})の$H^{j}_{i_{j}}({\bf X})$は$i_{j}$次のHermite多項式$\tilde{H}_{i_{j}}$を用いて
\begin{equation}
 H^{j}_{i_{j}}({\bf X})=\tilde{H}_{i_{j}}(Y_{j})
\end{equation}
である．係数$a_{i_{1}i_{2} \cdots i_{k}}$はHermite多項式の直交性を利用して，以下のように求められる．
\begin{eqnarray}
 \lefteqn{
  \int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty}
  H^{1}_{i_{1}}({\bf X}) \cdots H^{k}_{i_{k}}({\bf X})
  p_{H}({\bf X})d{\bf X}
 } \nonumber \\
 &=&\!\!\int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty}
  H^{1}_{i_{1}}({\bf X}) \cdots H^{k}_{i_{k}}({\bf X})
  [\sum_{(j_{1},j_{2},\cdots,j_{k})\in I}a_{j_{1}j_{2} \cdots j_{k}}
   H^{1}_{j_{1}}({\bf X}) \cdots H^{k}_{j_{k}}({\bf X})]
   p_{G}({\bf X})d{\bf X} \nonumber \\
 &=&\!\!\int_{-\infty}^{\infty} \cdots \int_{-\infty}^{\infty}
  \tilde{H}_{i_{1}}(Y_{1}) \cdots \tilde{H}_{i_{k}}(Y_{k}) \nonumber
  [\sum_{(j_{1},j_{2},\cdots,j_{k})\in I} a_{j_{1}j_{2} \cdots j_{k}}
  \tilde{H}_{j_{1}}(Y_{1}) \cdots \tilde{H}_{j_{k}}(Y_{k})] \nonumber \\
 & &\!\!\frac{1}{\sqrt{2\pi}}\exp{-\frac{Y_{1}^{2}}{2}} \cdots
  \frac{1}{\sqrt{2\pi}}\exp{-\frac{Y_{k}^{2}}{2}}
  dY_{1} \cdots dY_{k} \nonumber \\
 &=&\!\!a_{i_{1}\cdots i_{k}}i_{1}! \cdots i_{k}!
\end{eqnarray}
そこで
\begin{equation}
 c_{ir}=(-1)^{r}(2r-1)!! \frac{i!}{2r!(i-2r)!}
\end{equation}
とおくと，
\begin{equation}
 a_{i_{1}i_{2} \cdots i_{k}}
 =\frac{1}{i_{1}!i_{2}! \cdots i_{k}!}
  \sum_{r_{1}=0}^{[\frac{i_{1}}{2}]}
  \sum_{r_{2}=0}^{[\frac{i_{2}}{2}]} \cdots
  \sum_{r_{k}=0}^{[\frac{i_{k}}{2}]}
  c_{i_{1}r_{1}}c_{i_{2}r_{2}} \cdots c_{i_{k}r_{k}}
  \alpha_{(i_{1}-2r_{1})(i_{2}-2r_{2}) \cdots (i_{k}-2r_{k})}
\end{equation}
となる．ここで，$[n]$は$n$を越えない最大の整数である．

以上の式を用いて，学習データ（標本）からモーメントおよび正規化モーメントの推定値を計算すれば，全ての母数，$\mu$，$\Sigma$および$a_{i_{1}i_{2}\cdots i_{k}}$の推定値が得られる．

\section{比例反復法による２次対数線形分布の母数の推定} \label{app:比例反復法}

２次対数線形分布の母数である$h^{(2)}_{j,l}(i_{j},i_{l}) (j=1,2, \cdots ,k-1;　i_{j}=1,2, \cdots ,I_{j};　l=j,j+1, \cdots ,k;　i_{l}=1,2, \cdots ,I_{l})$は以下の比例反復法によって求めることができる．２次対数線形分布の制約式である
\begin{equation}
p^{(2)}_{j,l}(i_{j},i_{l})=
  \sum_{i_{1}=1}^{I_{1}} \cdots \sum_{i_{j-1}=1}^{I_{j-1}}
  \sum_{i_{j+1}=1}^{I_{j+1}} \cdots \sum_{i_{l-1}=1}^{I_{l-1}}
  \sum_{i_{l+1}=1}^{I_{l+1}} \cdots \sum_{i_{k}=1}^{I_{k}}
  \prod_{j^{'}=1}^{k-1} \prod_{l^{'}=j^{'}+1}^{k}
  h^{(2)}_{j^{'},l^{'}}(i_{j^{'}},i_{l^{'}})
 \label{eq:２次周辺分布}
\end{equation}
を変形すると，
\begin{eqnarray}
 \lefteqn{
    p^{(2)}_{j,l}(i_{j},i_{l})
 }  \nonumber \\
  &=& h^{(2)}_{j,l}(i_{j},i_{l}) \nonumber \\
  & & \times 
  \sum_{i_{1}=1}^{I_{1}} \cdots \sum_{i_{j-1}=1}^{I_{j-1}}
  \sum_{i_{j+1}=1}^{I_{j+1}} \cdots \sum_{i_{l-1}=1}^{I_{l-1}}
  \sum_{i_{l+1}=1}^{I_{l+1}} \cdots \sum_{i_{k}=1}^{I_{k}}
  \prod_{j^{'}=1}^{k-1} 
  \prod_{l^{'}=j^{'}+1,(j^{'},l^{'})\neq (j,l)}^{k} 
   h^{(2)}_{j^{'},l^{'}}(i_{j^{'}},i_{l^{'}}) \nonumber \\
\end{eqnarray}
と書くことができる．そこで，$h^{(2)}_{j,l}(i_{j},i_{l})$の$r$回目の推定値を$h^{(2),(r)}_{j,l}(i_{j},i_{l})$とし，式(\ref{eq:２次周辺分布})の右辺に$h^{(2),(r)}_{j,l}(i_{j},i_{l})$を代入して求めた２次周辺分布を$p^{(2),(r)}_{j,l}(i_{j},i_{l})$とするとき，$r+1$回目の推定値を
\begin{equation}
    h^{(2),(r+1)}_{j,l}(i_{j},i_{l})
  = \frac{p^{(2)}_{j,l}(i_{j},i_{l})}
  {p^{(2),(r)}_{j,l}(i_{j},i_{l})}
  h^{(2),(r)}_{j,l}(i_{j},i_{l})
\end{equation}
のようにして求める．この反復を，推定値が収束するまで繰り返し行う．なお，初期値は以下のように設定した．
\begin{eqnarray}
 h^{(2),(0)}_{j,l}(i_{j},i_{l})=
  \left\{
  \begin{array}{ll}
   1, & \mbox{$p^{(2)}_{j,l}(i_{j},i_{l})\neq 0$} \\
   0, & \mbox{else}
  \end{array}
  \right.
\end{eqnarray}




\bibliographystyle{jnlpbbl}
\bibliography{nlp}


\begin{biography}
\biotitle{略歴}
\bioauthor{江原 暉将}{
1967年早稲田大学理工学部電気通信学科卒業．
同年，日本放送協会に入局．1970年より放送技術研究所に勤務．現在，先端制作技術研究部主任研究員．
かな漢字変換，機械翻訳などの研究に従事．
電子情報通信学会，情報処理学会，ＡＣＬ，機械翻訳協会 各会員．
}
\bioauthor{金 淵培}{1958年生．1983年 University of S$\tilde{a}$o Paulo 大学工学部化学工学科卒業．1984年（株）ブラビス・インターナショナル入社．1991年ＮＨＫ入局．現在，放送技術研究所・先端制作技術研究部においてニュース用日英機械翻訳，自然言語処理等の研究に従事．情報処理学会，ＡＡＡＩ 各会員．
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}
