<?xml version="1.0" ?>
<root>
  <title>認知単位bigramを用いた日本語文解析の一方法</title>
  <author>横田和章藤崎博也</author>
  <jabstract>現在，自然言語処理システムの多くは，処理単位として形態素を用いているが，人間はもっと大きな単位で文を処理していることが既に分かっている．この単位を認知単位と呼ぶ．この知見から，人間の文解析処理は，認知単位の検出処理と，検出した認知単位の取捨選択の2段階に分離できるものと考えられている．本論文では，この考えに基づき，第一段階として状態遷移図を用いて認知単位を検出し，第二段階としてbigramを用いて認知単位を選択する，計二段階からなる文解析法を提案するものである．この方法を用いて誤りを含んだテキストに対し誤り訂正を行う実験を行った結果，形態素を単位としたbigramを用いるよりも良い結果を得ることができた．</jabstract>
  <jkeywords>文解析，bigram，状態遷移図，有限オートマトン，認知単位</jkeywords>
  <subsection title="">*[誤りのモデル]情報源の1文字あたり，確率P_nで誤りが発生する．誤りが発生した場合，次のいずれかがそれぞれ条件つき確率1/3で起こる．quotation以降の実験では，このモデルに従い誤りを含んだ文字列を発生させており，挿入または置換の際必要となる文字としては，簡単のため平仮名46文字のいずれかをランダムに選んで使用している．今，aとbをそれぞれ文字列とし，aの長さはl文字，aとbの距離はdであるとする．上記の誤りによってaがbに変化する確率P_e(a,b)は，l-d文字に誤りが発生せず，d文字に誤りが発生したと考えることにより，次の式で近似できる．実際にはd+1文字以上の誤りによって，aがbに変化する場合も考えられるが，本研究ではP_eが十分小さいと考え，上式においてはこれらの場合は無視している．手順(2)においては図(b)のように，手順(1)により得た形態素ラティスに基づいて形態素を組み合わせることにより，認知単位を検出して認知単位ラティスを作り，上式を用いて変化確率を計算するものとした．*-1mm</subsection>
  <section title="まえがき">現在，機械による文解析の処理単位としては，形態素が利用されることが多いが，これは，形態素を用いることにより辞書の語数を制限でき，計算機の記憶を経済的に利用できるという利点があるからである．bigramによる解析方式は，文解析や音声認識など様々な分野において高い評価を得ているものの，文字や形態素を単位としたbigramによる解析は，単位が小さすぎて，文の局所的な性質を解析しているのに過ぎないと考えられる．しかし，trigramや4-gram以上になると，しばしば計算機の記憶容量の限界を超えてしまい，実用的ではない．筆者らは，知覚実験により，人間による文解析には，形態素より長い単位が用いられていることを既に明らかにしている．従って，人間の場合と同様の長い単位を解析に用いれば，機械においても高い処理効率が得られると期待される．本論文は，このような観点から，bigramの単位として認知単位を用いる方法を提案するものである．形態素より長い単位を解析に用いる方法は，他にもいくつか報告されている．例えば，音声認識の分野において，伊藤らは休止を単位とした解析を行う方法を提案している．また，テキスト処理において，文法的な解析が難しい発話を処理するために，発話を部分的に構文解析する方法なども提案されている．しかし，これらの解析に用いられている長い単位は，解析の効率化のために便宜上導入されたもので，比較的専用の用途にのみ使用できるものである．人間における文解析処理が複数段階の処理からなると仮定すれば，認知単位はその複数段階の処理において主に単位として利用されていると考えられる．従って，機械における処理を同様に多段に分けて考えるとすれば，認知単位はこの多くの段階において単位として汎用的に利用できることが期待される．機械の処理が，形態素解析，構文解析，意味解析，談話解析からなるとすれば，認知単位を利用することにより構文解析の処理を効率化できることが既に筆者らにより実証されている．本論文では，認知単位を利用することにより形態素解析に相当する処理の効率化を行なう方法を提案し，認知単位の有効性を実証する．</section>
  <section title="認知単位の知覚実験">筆者らは知覚実験の結果から，人間による文解析には形態素より長い単位が用いられていることを既に明らかにしている．図は文献において，このことを確かめるために行った実験の結果である．この実験では，コンピュータのディスプレイ上に30字程度の漢字かな混じり文を短時間表示し，被験者に口頭で読んでもらう．文は24文用意してあり，被験者が文を覚えないようランダムな順番で表示される．提示時間は50msから1sまで50ms刻みで長くしてゆく．こうして，提示時間と，被験者が読むことのできた文字数との関係を調べる．図の実験では，「この問題は解決ずみというつもりなのかもしれないが私はそうは思わない．」という文を提示している．結果は図の様な階段状になり，人間が文字単位で文を処理しているのではないことは明らかである．また，読めた部分の最後に着目すると，それはすべて文節境界となりうる形態素で終っている．更に，「というつもり」や「かもしれないが」などのように，複数の文節にまたがる句が一度に検出されていると思われるケースもある．従って，人間は文節よりも長い句を検出していると推察される．特に，「は」，「している」，「というつもり」，「かもしれないが」のように，それだけでは意味をなさず，先行する句の後について補助的な意味を表すような句は，先行する句とともに一度に検出されている．この結果から，人間の場合，まず長い句を一度に検出する処理を行い，この処理の後，検出された長い句を単位として，更に高次の解析を行っているものと考えることができる．この実験の結果から，人間においては次のような句が一度に検出されることが見出された．文節「かもしれない」などの慣用句「している」などの補助用言を含んだ句この単位を本論文では認知単位と呼ぶ．この実験では口頭により被験者に文を読んでもらっているため，発話された文は，脳内の処理を経て出力されたものである．従って，認知単位は，意味処理を含む脳内の多段の処理において主に単位として利用されているものと考えられる．</section>
  <section title="認知単位の検出方法">前節における実験の結果から，人間における文解析過程は，認知単位を検出する処理と，認知単位を組み合わせて文を認識する処理の2段階に分離できるものとみなせる．このモデルに従い，機械においても文解析の処理を，認知単位を検出する処理と，検出した認知単位の取捨選択の処理の2段階に分ければ，解析の効率を高めることができると期待される．前者の処理において，通常の形態素の辞書を用いて文から認知単位を検出するには，どのような形態素の並びが認知単位になるかという局所的な文法が必要である．認知単位の内部における形態素の並びには，多重埋め込み的なものは少ない．従って，この局所的な文法は状態遷移図で記述するのがふさわしい．よって本研究では，認知単位を有限オートマトンで検出することにした．*-4mm</section>
  <subsection title="状態遷移図による認知単位の表現">本研究では，処理の対象として，NHKラジオの気象通報の始めに放送される天気概況文を用いた．この例を図に示す．これらの文に現れる認知単位を表層的な形式から128に分類し，人手で128の受理状態を持つ状態遷移図を作成した．得られた状態遷移図の一部を図に示す．図中Z_iは受理状態，S_iは中間状態である．名詞句はあらかじめ地名，海，方角，数字，高気圧・低気圧，台風，波，霧，天気などに分類してあり，この状態遷移図においては，品詞の並びが同じでも名詞句の分類が異なる名詞節は，異なる受理状態に遷移する．従って，「日本海では」，「日本海は」，「気温は」は，すべて別の受理状態に遷移する．これは述語句や，その他の修飾句に関しても同様で，品詞の並びだけではなく，意味的に気圧配置，気温，気圧，波，霧のどの状態を示すのに使われるかによっても分類される．従って，「悪くなっており」，「悪くなっています」，「高くなっています」はすべて別の受理状態に遷移する．天気概況文は気圧配置，天気，海上，霧，気温に関する文に大別できるが，それぞれ表現の形式が限定されているため，比較的厳格な文法によりその文法を記述できると考えられる．また，出現する形態素の数が限られており，同じ形態素が何度も反復して現れる．従って，小規模なコーパスから得られたデータでも，精度の高い解析が行える．</subsection>
  <subsection title="誤りを含んだ文からの認知単位の検出">前節で構成した有限オートマトンにより，文から認知単位を検出する手順は以下の通りになる．tejun文全体を走査し，形態素を検出して形態素ラティスを得る．得られた形態素ラティスに対し，有限オートマトンによる走査を行い，認知単位を検出する．誤りを含んだ文に対し，文解析によって誤り訂正を行うタスクは，通信やOCRなど様々な分野にしばしば求められるタスクである．認知単位は，意味処理を含む脳内の多段の処理において主に単位として利用されているものと考えられるため，このような誤りを含むテキストから誤りを取り除く場合にも人間はいずれかの段階で認知単位を用いているものと思われる．従って，機械により誤り訂正を行う場合にも認知単位は有効であると期待される．誤りを含む文においては，形態素が近い綴りをもつ別の文字列に置き換わることがある．従って，誤りを含む文に対して誤り訂正を行なうためには，手順(1)において形態素を検出する際に，厳密に文の一部に一致する形態素だけでなく，ごく近い形態素についても，誤りによって文の一部に変化する可能性を推定しながら検出する必要がある．本研究では，このタスクに対応するため，手順(1)において図(a)のように距離1の形態素も検出することにした．尚，この検出にはDP照合法を用いた．誤りには，挿入，欠落，置換の3種類がある．ここでは，誤りが図に示すように，次のモデルに従って発生するものと考える．</subsection>
  <section title="bigram による認知単位の取捨選択">*-1mm前節に示した手順により，文から認知単位を検出できる．検出した認知単位は，状態遷移図における受理状態により128に分類される，この認知単位に対して取捨選択を行い，文を組み立てるには，様々な方法が考えられる．筆者らは既に，自動的に獲得した文法に基づき，認知単位を利用して構文解析を行う方法を提案している．本論文では，誤りを含んだテキストから誤りを取り除く実験を行うが，この実験において上記の構文解析を行うと，探索経路が莫大となって計算に時間がかかる．従ってこの実験には，より簡単な処理で効果的に誤り訂正を行える方法が適している．このような観点から，本論文ではbigramを用いて解析を行うことにした．bigramによる方法は，自然言語のようなマルコフ性を有する系列に対し効果的に取捨選択を行うことができ，特に音声認識などの分野では高い評価を得ている．本研究では簡単のため意味解析は行わないが，このように誤りを含むテキストを処理する場合，構文解析や意味解析など，より高度な解析が必要な場合にも，あらかじめ認知単位のbigramにより不的確な候補を効率的に削除しておくことにより処理が効率化するものと思われる．bigramの出現頻度表により記述できる性質は，系列の単純マルコフ的な性質に限られるが，状態遷移図は多重マルコフ的な性質をも表すことができる利点を持つ．しかし，認知単位の境界は分岐数が多いため，認知単位の多重マルコフ的な性質を調べるのは極めて難しい作業となる．従って，本研究では状態遷移図による解析は認知単位内にとどめる．今，認知単位の系列A=a_1,a_2,a_3,a_nの出現確率をP(A)とすれば，*-1mmbigramモデルでは，系列Aの出現確率は次のように表すことができる．*-1mmP(A)&amp;=&amp;P(a_1|)P(a_2|a_1)P(a_3|a_2)&amp;&amp;P(a_n|a_n-1)eqnarrayここで，*1mmP(a_i|a_i-1)*1mmは認知単位*1mma_i-1*1mmの次に*1mma_i*1mmが生起する条件つき確率である．*1mmまた，P(a_1|)は文頭にa_1が生起する条件つき確率である．従って，A=a_1,a_2,a_nが誤りにより変化してB=b_1,b_2,b_nとして生起される確率は次のようになる．P_p(A,B)&amp;=&amp;P(a_1|)P_e(a_1,b_1)&amp;&amp;P(a_2|a_1)P_e(a_2,b_2)&amp;&amp;P(a_3|a_2)P_e(a_3,b_3)&amp;&amp;P(a_n|a_n-1)P_e(a_n,b_n)eqnarrayここでは，a_iとして認知単位の状態遷移図における受理状態の記号z_j(0j127)を用いる．従って，P(a_i|a_j)，P(a_i|)をあらかじめコーパスにより図の形のbigramにして求めておき，()式のP_p(A,B)を最大とする系列Aを幅優先探索法によって探索する．形態素を単位としたbigramを用いる方法では，文を局所的に解析することしかできず，また，より大域的な解析を行うためにtrigramや4-gramを用いることにすれば，必要とされる記憶容量が指数関数的に増大する他，巨大なコーパスを必要とするなど様々な問題が生じる．この代わりに，このように認知単位を単位としたbigramを用いることにより，記憶容量を抑えながら，大域的な解析を行うことができる．</section>
  <section title="評価">以上の方式を用いて，誤りを含むテキストに対して誤り訂正を施す実験を行った．まず，解析の元となるbigramを作成するため，認知単位に分割されたコーパスが必要である．このコーパスは手入力した天気概況文1569文から作成した．今回用いた天気概況文の場合，出現する形態素が限られているため，図の状態遷移図で文を走査し，単純な最長一致法で区切ることにより各文を認知単位に分割することができた．その際，各文を処理する途上で通った状態遷移図の経路から，形態素の区切りも検出し，コーパスに形態素情報として付加した．得られたコーパスの異なり形態素数は196，のべ形態素数は26834，1形態素あたりの平均文字数は3.90，perplexityは3.2となった．こうして作成したコーパスから，更に認知単位のbigramを作成し，図のモデルにより誤りを混ぜた文300文に対し，誤り訂正を施して認知単位に区切る実験を行った．比較のため同じコーパスから，形態素情報を用いて形態素のbigramを作成し，同じ文に誤り訂正を施し形態素に区切る実験も行った．この計算にはSUNのSPARCStation20モデル612を使用した．実験の結果，正しく誤り訂正ができた割合(正解率)と300文の処理にかかった時間とを表に示す．このような探索方法では，長い文においてあらゆる誤りの組合せをすべて調べるには，巨大なメモリと極めて長い計算時間とを要する．これらを制限するため，探索の各時点で，()式により探索経路を評価し，最も評価値の高い300経路だけを残す方式を採った．このような経路限定を行うと，誤りが無い場合に比べ，誤りがある場合では経路の数が増えて，解が300経路に残らない確率が高くなり，結果として処理は高速になる．誤りが全くない場合は形態素，認知単位のいずれのbigramを利用した方法でも，100%正しく文を区切ることができた．また，その他の場合は正解率は後者が前者に比べて3%〜10%程高くなった．このことから前者では，解の経路の評価値が300位以下に落ちて，途中で失われる確率が，後者に比べて高いと考えられる．処理中に消費するメモリの量については，探索経路数が等しいため両方法ともほぼ同等である．しかし，認知単位を用いた解析の場合，解の経路を残す確率が高い分，計算の時間が長くなっている．この計算時間を評価するため，形態素のbigramを用い，探索経路数を1200として誤り訂正を行った．その結果を表に示す．この表の場合，認知単位のbigramを用いて探索経路を300とした場合とほぼ同等の正解率が得られているが，計算時間は誤り率0の場合を除いてほぼ7倍となっている．また，メモリ消費量は探索経路数に比例するため4倍である．これらの結果は，認知単位をあらかじめ検出しておいて解析に用いることにより，処理を効率化できることを示している．</section>
  <section title="むすび">人間の文解析を認知単位の検出と取捨選択の2段階からなるとみなし，このモデルに基づいて，局所的な解析に有限オートマトンを用い，大域的な解析をbigramに基づいて行う方法を提案した．有限オートマトンの処理は，他の解析方法と比べて直線的であり高速である．認知単位内の形態素の並びのように，局所的な解析は直線的なモデルが適合する．bigramより更に高度な文解析法では，一層再帰的な処理を行うため，より長い計算時間を要することが多い．このような解析方法においても，認知単位のような局所的な範囲については直線的な解析法を用いることにより効率化できると考える．</section>
</root>
