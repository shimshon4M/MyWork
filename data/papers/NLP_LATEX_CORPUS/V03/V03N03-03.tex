\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\def\myinm{}
\def\myjv{}
\def\ev{}

\setcounter{page}{53}
\setcounter{巻数}{3}
\setcounter{号数}{3}
\setcounter{年}{1996}
\setcounter{月}{7}
\受付{95}{7}{10}
\再受付{95}{8}{22}
\採録{96}{2}{20}

\setcounter{secnumdepth}{10}

\title{人手作成ルールと事例に基づく英語動詞選択ルールの学習}
\author{秋葉 泰弘\affiref{NTT} \and 石井 恵\affiref{NTT}
\and Hussein ALMUALLIM\affiref{KFUPM} \and 金田 重郎\affiref{NTT}}

\headauthor{秋葉 泰弘・石井 恵・Hussein ALMUALLIM・金田 重郎}
\headtitle{人手作成ルールと事例に基づく英語動詞選択ルールの学習}

\affilabel{NTT}{NTTコミュニケーション科学研究所}
{NTT Communication Science Laboratories}
\affilabel{KFUPM}{サウジアラビア国立石油鉱物大学}
{King Fahd Univ. of Petroleum \& Minerals}

\jabstract{機械学習により日英翻訳のための英語動詞選択ルールを獲得する
手法を提案する．英語動詞選択ルールの学習手法としては，既に，翻訳事例の
みから獲得する手法が知られている．この従来の翻訳事例のみから獲得する手
法では，ルールの正解率を向上させるために，多数の事例を必要とする．しか
し，現実には，動詞出現頻度の偏りにより，全動詞に十分な翻訳事例を収集す
る事は極めて困難である．そこで，本論文では，人手作成のルールと収集され
た少数の翻訳事例から，英語動詞選択ルールを獲得する修正型の学習手法を提
案する．具体的には，本手法は，(1)人手作成のルールから仮の事例(仮事例)
を生成し，(2)その仮事例と現実の事例を訓練事例として，既存の学習アルゴ
リズム(内部学習アルゴリズム)に入力する，の２ステップから構成される．内
部学習アルゴリズムの出力が，最終的に獲得されたルールである．評価を目的
として，NTT が開発中の日英機械翻訳システム ALT-J/Eの英語動詞選択ルール
を本手法により実験的に学習した．その結果，学習されたルールは，実事例の
みから学習されたルールや人手作成のルールより高い正解率を示し，本提案
手法の有効性を確認できた．}

\jkeywords{機械翻訳，学習，動詞選択，事例，知識}

\etitle{~~~~~~~~~~~~~A Revision Learner\\ to Acquire English Verb Selection Rules}
\eauthor{Yasuhiro AKIBA\affiref{NTT} \and Megumi ISHII\affiref{NTT}
\and Hussein ALMUALLIM\affiref{KFUPM} \and Shigeo KANEDA\affiref{NTT}}

\eabstract{This paper proposes a learning method that automatically
acquires English verb selection rules for machine translation using a
machine learning technique. If the rules are learned from only real
translation examples, many examples are necessary for good translation
quality. It is, however, difficult to gather a sufficiently large
number of real translation examples. The main causes are verbs of low
frequency and the frequent usage of the same sentences. To resolve
this problem, the proposed method learns English verb selection rules
from hand-made translation rules and a small number of real
translation examples. The proposed method has two steps: generating
artificial examples from the hand-made rules, and then putting the
resultant artificial examples and real examples into an internal
learner as the training set. The internal learner outputs the final
rules with improved verb selection accuracy. The most notable feature
of the proposed learner is that any attribute-type learning algorithm
can be adopted as the internal learner. To evaluate the validity of
the proposed learner, English verb selection rules of NTT's
Japanese-English Machine Translation System ALT-J/E are experimentally
learned from hand-made rules and real examples. The resultant rules
have better accuracy than either those constructed from the real
examples or those that are hand-made.}

\ekeywords{Machine Translation, Learning, Verb Selection, Examples, Knowledge}

\begin{document}
\maketitle

\vspace*{-1mm}
\section{はじめに}
\vspace*{-1mm}

機械翻訳システムは，巨大なルールベースシステムであり，
NTTにおいて開発を進めている機械翻訳システム
ALT-J/E~\cite{Ikehara89,Ikehara90}でも，1万ルール以上のパタン対ルール
(翻訳ルール)を利用している．他のルールベースシステムと同様，機械翻訳シ
ステムにおいても，ルールベースの作成・改良工数は大きな問題であり，特に
そのルール数が巨大なだけに，その工数削減が強く望まれている．

ルールベースの構築・保守を支援する手法として，近年，事例からの学習を利
用する研究が活発となっている．機械翻訳システムにおいても，ルールベース
構築への学習技術適用が試みられており，田中は，英日翻訳事例(コーパス)
から語彙選択ルールを学習する手法を提案している\cite{Tanaka94}．また，
Almuallim も，日英翻訳事例から，英語動詞選択ルール\footnote{パタン対ルー
ルの主要部分である．}を学習している\cite{Almuallim94c}．更に，宇津呂は，
日英翻訳事例から格フレームを獲得している\cite{Utsuro93}．

これら既存のアプローチでは，ルールが全く存在しない状態からスタートして，
事例のみに基づいてルールを作り出している．従って，未知事例に対して高い
正解率を持つルールを学習するには，多くの翻訳事例(これを以下，{\bf 実事
例}と呼ぶ．)を必要とする．しかし，現実には，既存文書における動詞分布の
偏り等の理由により，学習に必要な個数の実事例を，全動詞に対して収集する
事は，極めて困難である．

事例からの学習がルールベース構築に利用されるようになったのは，矛盾の無
い完全なルールを生成する事が，人間には困難だからである．しかし，人間は，
完全なルールを構成できなくとも，概略的あるいは部分的なルールは生成でき
る．そこで，人手作成の粗いルールと実事例とを融合してルールを学習できれ
ば，人手作成ルール及び実事例のいずれよりも高い正解率を持つルールが作成
でき，実事例のスパース性の問題を回避できる可能性がある．

そこで，本論文では，人手作成のルールと実事例を統合して，より精度の高い
ルールを生成する，修正型の学習方法を提案する．具体的には，まず，人手作
成のルールから逆に事例を生成(以下，この生成された事例を{\bf 仮事例}と
呼ぶ．)する．次に，仮事例と実事例を既存の学習アルゴリズム(これを，以下，
{\bf 内部学習アルゴリズム}と呼ぶ．)に入力する．内部学習アルゴリズムの
出力が，最終的に獲得されたルールである．内部学習アルゴリズムは，属性ベ
クトル型の事例表現を持つ学習アルゴリズムなら任意の学習アルゴリズムを選
択できる．尚，人手作成ルールの表現形式は，その表現能力の高さから
HausslerによるIDE形式\cite{Haussler88}とした．

提案手法では，仮事例と実事例の重要度を表現するために，重みを各事例に対
して与える必要がある．即ち，人手作成のルールが非常に正確であれば，ルー
ルから生成された仮事例に大きな重みを置くべきである．逆に，人手作成のルー
ルが不正確であれば，小さい重みを置くべきである．提案手法では，この最適
な重みの決定に，クロスバリデーションによるパラメータチューニングを利用
する．

本手法の有効性を評価するため，既存のドキュメントから抽出した実事例を用
いて，ALT-J/Eの英語動詞選択ルールの獲得実験を行なった．内部学習アルゴ
リズムとしては，意味カテゴリーシソーラスのエンコーディング手法に特徴を
持つAlmuallimによる学習手法\cite{Almuallim94c}を利用した．その結果，本
手法により獲得された英語動詞選択ルールは，実事例のみから獲得されたルー
ルや初期投入した人手作成のルールに比べて，高い正解率を示した．

以下，第2章では，英語動詞選択ルールを説明する．第3章では，従来のアルゴ
リズムとその問題を概観する．新しい学習手法を第4章で提案する．第5章では，
評価結果を示す．第6章では，他の修正型学習手法との差異について論ずる．
第7章は本論文のまとめである．

\section{英語動詞選択ルールとその獲得}
本章では，英語動詞選択ルールを説明し，その獲得における問題点について述
べる．

\subsection{英語動詞選択ルール}
NTTの開発しているALT-J/Eでは，日英翻訳のために，1万個を超えるパタン対
ルールを利用している．パタン対ルールは，日本文のパターン(単文)に英文の
パターンを対応させるマッピングルールである．即ち，左辺に日本文のパター
ンを，右辺に英文のパターンをもつ．以下に，日本語動詞「焼く」に対するパ
タン対ルールの例を示す．

{\scriptsize
\begin{center}
\begin{tabular}[t]{llllll}
IF&           &                         & THEN &        &\\
  &J-Verb     &  = ``焼く''               &      & Subj   & = $N_1$\\
  &$N_1$ (Subj)  & \myinm  ``人''               &      & E-Verb & = ``bake''\\
  &$N_2$ (Obj)   & \myinm  ``パン'' or ``菓子'' &      & Obj    & = $N_2$\\
\end{tabular}\\
\end{center}
}
\noindent{だだし，これより以下，`` \myinm'' は，``an instance of''を意
味するものとする．}

本論文における英語動詞選択ルールとは，図~\ref{YakuSelectionRule} のよう
なルールで，左辺に日本文パターン，右辺に英語動詞を持ち，日本文パターン
を英語動詞に対応させる．即ち，英語動詞選択ルールは，パタン対ルールにお
いて，英語側パタンを英語動詞のみに限定したものである\footnote{英語パタ
ン自体を学習できる事が望ましいが，本論文では，その第１ステップとして，
その主要部である動詞のみを対象とする．}．

\begin{figure}[ht]
{\scriptsize
\begin{center}
\begin{tabular}[t]{llllll}
IF&           &                         & THEN &        &\\
  &J-Verb     &  = ``焼く''               &      &    & \\
  &$N_1$ (主格)  & \myinm  ``人''               &      & E-Verb & = ``bake''\\
  &$N_2$ (目的格)   & \myinm  ``パン'' or ``菓子'' &      &     &\\
IF&           &                         & THEN &        &\\
  &J-Verb     &  = ``焼く''               &      & &\\
  &$N_1$ (主格)  & \myinm  ``人''              &      & E-Verb & = ``roast''\\
  &$N_2$ (目的格)   & \myinm  ``肉'' &      &  &\\
IF&           &                         & THEN &        &\\
  &J-Verb     &  = ``焼く''               &      & &\\
  &$N_1$ (主格)  & \myinm  ``人''                &      & E-Verb & = ``broil''\\
  &$N_2$ (目的格)   & \myinm  ``魚'' or ``魚介類'' &      & & \\
IF&           &                         & THEN &        &\\
  &J-Verb     &  = ``焼く''               &      &  & \\
  &$N_1$ (主格)  & \myinm  ``主体''                &      & E-Verb & =
``cremate''\\
  &$N_2$ (目的格)   & \myinm  ``人'' or ``動物'' &      &  & \\
IF&           &                         & THEN &        &\\
  &J-Verb     &  = ``焼く''               &      &  & \\
  &$N_1$ (主格)  & \myinm  ``主体'' or ``機械''   &      & E-Verb & = ``burn''\\
  &$N_2$ (目的格)   & \myinm  ``場所'' or ``具対物'' or &   &  & \\
  &           & ~~~ ``場''           &   &        &\\
\end{tabular}
\\\vspace{1em}
\vspace{-1mm}
\caption{日本語動詞``焼く''に対する英語動詞選択ルール}
\label{YakuSelectionRule}
\end{center}
}

\begin{center}
\epsfile{file=zu3.eps}
\vspace*{-1mm}
\caption{ALT-J/Eにおける意味カテゴリーシソーラスの一部}
\label{SemanticHierarchy}
\end{center}
\vspace*{-2mm}
\end{figure}


図~\ref{YakuSelectionRule} から分かるように，左側の日本文パターンは，一
つの日本語動詞と$N_1，N_2$ 等のパラメータから成る．$N_1，N_2$ 等は，主
格，目的格等の日本文を構成する格である．ALT-J/Eでは，13種類の格を持つ．
また，``魚''，``魚介類''等は，意味カテゴリーである．ALT-J/E の場合，約
３千個の意味カテゴリーを持ち，各意味カテゴリーは，12段を持つ意味カテゴ
リーシソーラス上のノードである．上位ノードと下位ノードは，is-a 関係で
結ばれている．図\ref{SemanticHierarchy} に，意味カテゴリーシソーラ
スの一部を示す．

ALT-J/Eは，約40万語の名詞意味辞書を持ち，この名詞意味辞書は，日本語名
詞を意味カテゴリーに対応させる機能を持つ．例えば，名詞``鶏''は，肉と鳥
のインスタンスを持つ．この例からも分かる様に，1個の名詞は，通常，複数
の意味カテゴリーを持っている．

図~\ref{YakuSelectionRule} において，例えば，英語動詞がbakeとなるのは，
(1)~入力された日本文の主格の名詞が，``人'' またはその下位の意味カテゴ
リーを持ち，かつ，(2)~目的格の名詞が，``パン'' ，``菓子'' ，またはそれ
らの下位の意味カテゴリーを持ち，かつ日本語動詞が，``焼く'' である時で
ある．

\subsection{英語動詞選択ルールを獲得する難しさ}
英語動詞選択ルールを獲得する際に，最も困難な作業は，ルール中の各格に対
する適切な意味カテゴリーの組合せの選択である．これは，ALT-J/Eにおける
約３千の意味カテゴリーの組合せが巨大である点に起因する．従って，ルール
中の各格に対して適切な意味カテゴリーの組合せを見い出す事が，学習アルゴ
リズムに課せられた課題となる．

\section{従来手法とその問題点\label{TheFormerWork}}
本章では，従来手法のひとつとしてAlmuallimの手法\cite{Almuallim94c}を例
にとり，学習事例収集の困難さについて論ずる．尚，ここで示す問題は他の事
例からの翻訳ルール学習手法にも共通していると思われる．

Almuallimは，日英翻訳事例から英語動詞選択ルールを学習する2つのアルゴリ
ズム\cite{Almuallim94c}を提案した．
このAlmuallimのアプローチでは，学習用の事例(以下これを，``訓練事例''
と呼ぶ．)が，以下のようにして作成される．
\begin{description}
\item[(1)] 次のような日本語の単文と適切な英語動詞の対を準備，\\
(``コックがアップルパイを焼く'' ``bake'' )
\item[(2)] 日本語の単文を構文解析，
\item[(3)] 単文中の主名詞を抽出，
\item[(4)] ステップ(3)で抽出した名詞を元に以下のように訓練事例を生成．\\
$\langle$ N1 \myinm ``道具'', ``人'', or ``職業'', N2 \myinm ``菓子'',
``bake'' $\rangle$\\
\end{description}

Almuallimのアプローチで，未知事例に対して高い正解率を示す英語動詞選択
ルールを獲得するには，訓練事例を多数必要とする．英語動詞選択ルールを獲
得するために，十分な訓練事例が現実に準備できるか否かを検証するため，5
万事例規模の対訳コーパスを既存のドキュメントから抽出した
\cite{bunka90,Keene91}．この5万文の対訳コーパスには，約５千種類
の日本語動詞が含まれていた．

Almuallimらの実験によれば，英語動詞選択ルール1個あたり，最低でも20から
30 の翻訳事例が必要である．仮に日本語動詞に対応する英語動詞が，日本語
動詞1個あたり平均4英語動詞だとすると，１日本語動詞につき100事例を，準
備する必要がある．5万文の中で，100文以上の日本文で使われている動詞(つ
まり，訓練事例が100個以上収集できる動詞)は，全体の僅か約1\%にすぎなかっ
た．しかも，現実には，翻訳事例の中には繰り返し出てくるものもあるため，
実効的な個数は更に減少する．

逆に，上記の5万事例中では，事例数を2まで許容すれば95\%の動詞を包含でき
た．従って，95\%の動詞を学習するには，５万事例の50倍，250万の単文の対
訳が必要になる．この規模の翻訳事例は，収集が極めて困難である．即ち，既
存のドキュメントだけから抽出した翻訳事例から学習アルゴリズムにより英語
動詞選択ルールを獲得できると結論付けるのは楽観的すぎる．

ところで，人間が動詞選択ルールを作成する過程を考えると，(1)頭の中に仮
想的な事例を思い浮かべながらざっとしたルールを作成し，(2)この粗いルー
ルを現実の事例と照合させながら修正し，最終的なルールを作成してゆくと考
えられる．もし，実事例に加え，頭に思い浮かべた仮想事例をも学習に利用で
きれば，学習アルゴリズムに入力される訓練事例を増加させることができる．
しかし，仮想事例そのものにアクセスすることは一般に出来ない．一方，仮
想事例を説明している人手作成の英語動詞選択ルールには，アクセスできる．

従って，上記の事例のスパース性を回避する現実的な方法として，最初に人間
にルールを作成させ，この人手作成の英語動詞選択ルールと現実の翻訳事例を
融合して最終的なルールを形成する方法が考えられる．即ち，少ない実事例と，
正解率が十分でない人手作成動詞選択ルールを入力として，十分な正解率を示
す英語動詞選択ルールを学習する学習アルゴリズムが望まれる．次章では，上
記のアプローチを実現する学習方法を提案する．

\section{修正型学習手法}
本章では，英語動詞選択ルールを人手作成ルールと現実の翻訳事例から獲得す
る修正型学習手法を提案する．まず最初に，学習タスクを明確にする．

\subsection{学習タスク\label{LearningTask}}
与えられた日本語動詞 \myjv{} と可能なその英語訳 $\ev_i$ に対して，アル
ゴリズムに与えられた課題は，\myjv{} に $\ev_i$ を対応させるために，文
脈上，取るべき適切な条件を探す事である．

ある日本語動詞(例えば日本語動詞``焼く'')に対する，英語動詞選択ルールを
学習するためには，その学習タスクは以下のように記述される．\\

【学習タスク】
\begin{description}
\item[Step-I] 図\ref{YakuSelectionRule} に示すような英語動詞選択
ルールを人手作成．
\item[Step-II] 実事例を収集
\footnote{収集される実事例は，それらだけから英語動詞選択ルールを獲得す
るには，少ないものとする．}．
\item[Step-III] 上記実事例と上記人手作成ルールから最終的なルールを生成．
\end{description}

\subsection{修正型学習手法の概要\label{Outline}}
修正型学習手法は，人手作成の英語動詞選択ルールと実事例から情報を得る．
もし，人手作成のルールが，非常に正確であるなら，修正型学習手法は人手作
成のルールに重きを置く必要がある．一方，人手作成のルールが余り正確でな
ければ，それらのルールに対して，小さな重みだけが付加される必要がある．

人手作成のルールへの重さの程度と実事例への重さの程度を表現するために，
修正型学習手法は，数値を利用する．この数値を以後，``{\bf 重み値}''と呼
ぶ．修正型学習手法では，この重み値を定めるための情報を，人手作成ルール
と実事例以外には持たない．
重み値の候補数を N とすれば，修正型学習手法の骨子は以下の通りである．
\\

【修正型学習手法】
\begin{description}
\item[Step-i] 人手作成の英語動詞選択ルールから仮事例を生成．
ここで，生成方法の詳細は，\ref{GenerationMethod} 節で述べる．
\item[Step-ii] 事例集合の族 $\{Data_j ; j=1 \cdots N\}$ を作成．
ここで，$Data_j$ は，Step-iで生成された仮事例と予め準備した実事例全体
からなる集合で，第 j 番目の重み値候補に従って，仮事例と実事例に重み値
が付加されている．尚，重み値候補の集合は，実事例の重み値と仮事例の重み
値の対をその要素としている．
\item[Step-iii] 各 $Data_j$ に対して，$Data_j$ から学習されたルールの
未知事例に対する平均正解率 $A_j$ をクロスバリデーション法により算出．
ここで，クロスバリデーション法\footnote{クロスバリデーション法を実行す
る際には，テスト事例の重み値は，1.0 とすべきである．}の詳細は，
\ref{CrossValidation} 節で述べる．
\item[Step-iv] 最後に，$A_i~~(i=1 \cdots N)$の中で，最高値をもつルール
を出力．
\end{description}

\bigskip
修正型学習手法 Step-i で生成される仮事例は，3章で述べた仮想事例に当る
ものである．仮想事例は人手作成のルールで説明されているので，仮事例の中
には仮想事例が含まれている．仮事例の，実事例への混合は，仮想事例をも学
習に利用するという狙いの実現である．

ただし，仮事例の中には言語的に間違った事例が存在する可能性がある．これ
を防止するためには，ルール作成者が既存ルールを作成する際に，思い浮かべ
た具体例を汎化し過ぎないように注意する必要がある．そうすれば，言語的に
間違った事例，即ちノイズ事例を最小限に押えられる．ノイズが少なければ，
内部学習アルゴリズムとして，C4.5の様にノイズに強い学習アルゴリズムを選
択すれば，提案手法で生成される英語動詞選択ルールは，ノイズの影響を殆ん
ど受けない．

\subsection{仮事例生成法\label{GenerationMethod}}
本節では，\ref{Outline} 節の Step-i における，仮事例の生成法について説
明する．仮事例生成法は以下の通りである．

\bigskip
\begin{description}
\item[Step-A] 人手作成の英語動詞選択ルールを単位ルールに分解．
ここで，単位ルールとは，以下に示すようなルール\footnote{ルール条件部の
否定は，次の形式で表現される．: \\$N_1$ $\equiv$ not $V_1$.}である．
\begin{flushleft}
IF  ($N_1 \equiv V_1$) \& ($N_2 \equiv V_2$) \& $\cdots$   \\
THEN Class = CV,\\
\end{flushleft}
ただし，
$N_1, N_2$ 等は格要素，
$V_1, V_2$ 等は意味カテゴリー，CV はある英語動詞である．

\item[Step-B]上記単位ルールから，以下に示す形式の仮事例を生成．
\begin{flushleft}
        $\langle N_1 \equiv v_1, N_2 \equiv v_2, \cdots ,CV \rangle$，\\
\end{flushleft}
ここで， $N_1, N_2$ 等は格要
素，$v_i$ は単位ルール中の意味カテゴリー $V_i$ の下位ノード(意味カテゴリーシ
ソーラス上の)からランダムに選択する．

\item[Step-C] 望まれる個数の仮事例が生成されるまで，Step-B を反復．
\end{description}

\bigskip
仮事例生成法 Step-Bにおけるランダムな事例生成は一様分布に基づいており，
日本語の分布とは異なるが，今の所一様分布に従うのが最善の策と考える．本
来は，実際に使われる日本語の分布の真の分布に従ってランダム生成するのが
いいように思われるが，真の分布は知られておらず，大量の解析済みの日本語
コーパスが現在ない以上，真の分布のよい近似を得るのも難しい．この現実を
鑑みると，現在我々が拠り所とすべき分布は，統計学的に見て一様分布をおい
て他にない．もちろん，将来的に，真の分布を推定するのに，十分な量の解析
済み日本語コーパスが準備出来れば，それらを利用して推定した分布に基づき
ランダムな事例生成を行なうべきであろう．

\subsection{クロスバリデーション法\label{CrossValidation}}
仮事例/実事例の重み値を決定するためには，与えられた重み値で学習を行なっ
た時の，結果として得られるルールの未知事例に対する性能を推定する必要が
ある．本論文では，このためにクロスバリデーション法を用いる．以下，
\ref{Outline} 節のStep-iii クロスバリデーション法について説明する．クロ
スバリデーションは，機械学習の分野では良く知られている．クロスバリデー
ションは，通常はルールの正解率を推定するためにだけに使われる．しかし，
本論文では，これを学習段階の重み値調整に利用する．

与えられた正整数 $m$ と データ集合 $D$ に対して，クロスバリデーションは
以下のようになる\footnote{正確には，m フォールド クロスバリデーション
である．}．

\begin{description}
\item[Step-a] 与えられた集合 $D$ を $m$ 個の部分集合 $S_k ~~(k = 1
\cdots m)$ に分割．但し，各 $S_k$ は，共通な事例を持たない．

\item[Step-b] 各差集合 $D \setminus S_k ~~(k = 1 \cdots m) $ 毎に内部学習ア
ルゴリズムを利用して，ルール $rule_k$ を学習．

\item[Step-c] 各ルール$rule_k ~~(k = 1 \cdots m)$ 毎に，残りの集合 $S_k$ 
をテスト事例として利用し，正解率 $accuracy_k$ を計算．

\item[Step-d] 正解率 $accuracy_k ~~(k = 1 \cdots m)$ の平均値を計算．
\end{description}

\bigskip
尚，通常は，ルールの正解率を計算するために，m の値を 10 または 「学習
事例の個数」とする．

\section{実験結果}
提案手法を実験的に評価した．適用する内部学習アルゴリズムは，学習アルゴ
リズム ID3(C4.5)\cite{Quinlan86,Quinlan92}に基づくAlmuallim の学習手法
\cite{Almuallim94c}である．

\subsection{実験}
以下に示す実験を行なった．
\begin{description}
\item[\underline{評価データ}]
評価に利用した人手作成のルールは，ALT-J/Eの中の英語動詞選択ルール から
選択した．実事例は，既存のドキュメント\cite{Horiguchi89}を参考にして作っ
たものであり，必須格のみで表現されている．対象とした日本語動詞は，``入
る'', ``見える'' ,``見る'',及び``取る''である．実事例の個数は，それぞ
れ，95，33，385そして130事例である．また，仮事例の個数は，それぞれ，92，
33，384そして128事例で，実事例とほぼ同数
\footnote{各単位ルールからは，同数の仮事例を生成した．各単位ルールから
生成した仮事例の数は，生成される仮事例の総数が実事例の個数を越えない最
大の整数にした．そのため，実事例の個数と仮事例の個数に，若干差がある．}
になるように生成した．ほぼ同数になるようにしたのは，実事例と仮事例に与
える重み値が同じ時に，実事例と仮事例が学習アルゴリズムに与える影響を互
角にするためである．意味カテゴリーシソーラスは，ALT-J/E の意味カテゴリー
シソーラスを利用し，クロスバリデーションは，10フォールド・クロスバリデー
ションである．

\item[\underline{仮事例中の格要素の値}]
普通，ルールは，意味カテゴリーシソーラス上の上層部に位置する意味カテゴ
リーで記述されている．それに対して，実事例は，意味カテゴリーシソーラス
上の下層部に位置する意味カテゴリーで記述されている．従って，ルールから
仮事例を生成する際に(\ref{GenerationMethod}節を参照)，仮事例を表現する
意味カテゴリーとして，次のいずれかを選択し得る．
\begin{itemize}
\item[(1)] ルール中の意味カテゴリーを先祖に持つ葉（以下の評価結果では，
``leaf''と図示する．），

\item[(2)] ルール中の意味カテゴリーの任意の下位ノード（以下の評価結果
では，``descendant''と図示する．）．

\end{itemize}
これら2つのカテゴリー選択法を用いて評価する．

\item[\underline{学習されるルール中の格要素の値}]
良く知られているように，ID3は属性選択に``information gain''を利用している．
本論文の場合，属性は格要素である．この場合，``information gain''値が等
しい格要素が複数ある事がしばしば生じる．従って，我々は，``information
gain''値が等しい場合について，次の2種類の学習戦略を比較評価する事とす
る．

\begin{itemize}
\item[(1)] 意味カテゴリーシソーラス上で上位ノードを優先して選択
（以下の評価結果では，``upper''と図示する．)，
\item[(2)] 意味カテゴリーシソーラス上で下位ノードを優先して選択
（以下の評価結果では，``lower''と図示する．)．
\end{itemize}

\item[\underline{正解率}]
本論文では，正解率として，訓練事例に対する正解率ではなく，未知の事例に
対する正解率を利用している．この要件は，4.4節のクロスバリデーションで
実現される．但し，4.4節から分かるように，テスト事例は仮事例からも実事
例からも採られている．従って，生成されるルールは，いままで正しく翻訳さ
れていた例文に対する性能を極力下げることなく，一方，新しい翻訳文(実事
例)に対する翻訳も正しく行なわれる様にチューンされる．

\end{description}

\subsection{評価結果}
\begin{table}
\caption{正解率が最大となる重み組み合わせ}
\label{最大重み}
\begin{center}

\begin{tabular}[b]{|c|c|c|c|c|}
\hline
        & \begin{minipage}[c]{3em}
                \begin{center}
                \vspace{0.5em}
                upper\\ \vspace{-0.2em}
                +leaf 
                \vspace{0.5em}
                \end{center}
          \end{minipage}
        & \begin{minipage}[c]{3em}
                \begin{center}
                \vspace{0.5em}
                lower\\ \vspace{-0.2em}
                +leaf 
                \vspace{0.5em}  
                \end{center}
          \end{minipage}
        & \begin{minipage}[c]{6em}
                \begin{center}
                \vspace{0.5em}
                upper\\ \vspace{-0.2em}
                +descendant 
                \vspace{0.5em}
                \end{center}
          \end{minipage}
        & \begin{minipage}[c]{6em}
                \begin{center}
                \vspace{0.5em}
                lower\\ \vspace{-0.2em}
                +descendant
                \vspace{0.5em}
                \end{center}
          \end{minipage}\\ 
\hline
入る    & (5,5) & (4,6),(5,5) & (7,3) & (4,6)\\
\hline
見える  & (4,6) & \begin{minipage}[c]{5em}
                        \vspace{0.5em}
                        (4,6),(5,5),\\
                        (6,4),(7,3),\\ 
                        (8,2) 
                        \vspace{0.5em}
                  \end{minipage}
        & (9,1) & (5,5),(6,4)\\
\hline
見る    & (5,5) & (7,3),(8,2) & (9,1) & (5,5) \\
\hline
取る    & (9,1) & (7,3) & (1,9) & (2,8),(3,7)\\
\hline
\end{tabular}

\end{center}
\end{table}

\begin{figure}
\begin{center}
\epsfile{file=zu6.eps}
\caption{未知事例に関する正解率(``入る'')}
\label{test1}
\epsfile{file=zu7.eps} 
\caption{未知事例に関する正解率(``見える'')}
\label{test2}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\epsfile{file=zu8.eps} 
\caption{未知事例に関する正解率(``見る'')}
\label{test3}
\epsfile{file=zu9.eps}
\caption{未知事例に関する正解率(``取る'')}
\label{test4}
\end{center}
\end{figure}

実験結果を図3 -- 図6に示す．これらの図中で，real examplesは，実事例だ
けから学習したルールの正解率を意味し，artificial examplesは，仮事例だ
けから学習されたルールの正解率を意味する．また，mixed examplesは，実事
例と仮事例の双方から学習したルールの正解率である．mixed examplesの場合，
\ref{Outline} 節 Step-ii 中の重み値の候補は，以下に示す候補集合から選ん
だ．実事例と仮事例それぞれに対する重み値は，その和を10としている．

(実事例の重み値，仮事例の重み値) =
(0.01,9.99), (0.1,9.9), (1,9), (2,8), (3,7), (4,8),
(5,5), (6,4), (7,3), (8,2), (9,1), (9.9,0.1), (9.99,0.01).

図3 -- 図6 中に示されたmixed examplesの正解率は，これら重み値候補中で
正解率の一番高かったものであり，その時の重み組み合わせは表\ref{最大重
み} に示す通りである．これらの図の中で，例えば，{\em Upper   +
Descendant} は(1)学習されるルール中の格要素の値は，意味カテゴリーシソー
ラス上で上位の意味カテゴリーを優先して選択し，(2)仮事例生成において，
ルール条件に指定された意味カテゴリーの下位にあるノードから，ランダムに
ノードが選ばれて仮事例生成に利用される，事を意味する．

図3 -- 図6に示すように，仮事例生成時の下位ノードの選択方法や，学習時の
上位/下位のノード選択方法にかかわらず，提案手法により学習されたルール
は，最も高い正解率を持つ．従って，実事例と人手作成のルールを同時に利用
する我々のアプローチは，実事例不足を補っていると言えよう．

本手法において，一番高い正解率を示す条件は，日本語３動詞 ``入る'', ``見え
る'', 及び``取る''の場合は，``lower + leaf''である．また，日本語動詞``
見る''の場合は，``upper + leaf'' である．ここに示した動詞のみではなく，
一般に事例が多い場合には，``upper''が良く，事例が少ない場合には，
``leaf''が良い傾向がある．このような違いを生じる理由は明確ではないが ，
(1)数多くの実事例を集められるなら，どこまでをカバーして良いかが明確
にわかるので，できるだけ，汎化してルールを作成した方が良く，
(2)事例が少ない場合には，不用意に，上位のノードとして汎化すると，
カバーしてはならない部分までカバーする，ためではないかと推定される．

また，動詞``見る''では，正解率が，他の日本語動詞に対する正解率より，大
幅に良くなっている．この現象は，人手作成ルールの条件と，実事例が表す条
件が良くマッチしていたためと思われる．

また，本評価では，実事例の重み値と仮事例の重み値の合計を10とした．直観
的に考えれば，実事例の重みを1として，仮事例の重みを変化させれば充分で
ある．しかし，C4.5では，事例の重みが変化すると，プルーニング機能に影響
し，未知事例に対する性能が変化する．一般には，事例の重みを増加させた方
が，性能が向上する．本論文で，仮/実事例の重み合計を一定としたのは，こ
のC4.5固有の性質を極力排除するためである．他の学習アルゴリズムでは，こ
のような配慮が不要となる場合もあるものと思われる．

\section{関連学習手法との比較}
本論文の修正型学習手法の様に，既存のルールと実事例から新たにルールを生
成する学習手法としてはTheory Revisionがあり，既に多くの研究がある
\cite{Tangkitvanich93,Raedt92}．しかし，Theory Revisionでは，新
たな事例を許容する様に既存のルールを修正する事に主眼がおかれ，本論文の
様に，既存のルールを満たしていた事例の一部が例外として除去されるような
ケースは想定していない\cite{Murphy94}．このため，Theory Revisionは本論
文の応用には適用困難である．

また，一階述語論理形式の事例表現を用いるTheory Revision以外にも，本論
文で扱った属性型の事例表現を用いるものとして，
AQ\cite{AI-jiten2}\footnote{学習アルゴリズムAQは，事例とルールの間で表
現形式が同一であり，一種の修正型学習アルゴリズムである．}，
ID3\cite{Quinlan86}において知識と事例の融合を可能にした手法
\cite{Tsujino94}等がある．しかし，Theory Revisionを含めて，これら従来
の手法では，いずれも，既存の学習アルゴリズムを，個別に修正型へ改造して
いる．

これに対して，現実の応用においては，対象タスクによって最適な学習アルゴ
リズムは変化する．即ち，最初に様々の修正型学習アルゴリズムを適用して，
その結果，最も正答率のよい学習アルゴリズムを最終的に採用できる事が望ま
しい．本論文で提案した修正型学習アルゴリズムは，内部学習アルゴリムを自
由に選択できる点に大きな特長があり，上記要求を満たすロバストな学習アル
ゴリズムである．本論文で，複雑な背景知識(意味カテゴリーシソーラス)を前
提とした修正型学習が実現できたのもこのロバスト性のひとつの成果である．

尚，評価結果にも示した様に，どの様な人手作成ルールを与えても最終的な学
習結果が向上するわけではなく，事例のもつ情報と合致/相補する人手作成ルー
ルを与えない限り，最終的な結果の性能向上は望めない．従って，事例の統計
的性質に合致したルールをどのようにして人間に生成させるかが，今後の一つ
の課題となると思われる．

\section{むすび}

本論文では，人手作成の英語動詞選択ルールと少ない実事例から高い正解率を
示す英語動詞選択ルールを自動獲得する手法を提案した．まず，仮事例を人手
作成の英語動詞選択ルールから生成する．次に，上記仮事例と実事例を内部学
習アルゴリズムに対する訓練事例として利用する．最後に，内部学習アルゴリ
ズムは，人手作成ルールより高い正解率を示す英語動詞選択ルールを出力する．
ここでの課題は，仮事例と実事例の双方に与える重み値の決定である．本論文
では，最適重み値をクロスバリデーションにより決定した．

提案手法の性能を評価するために，人手作成の英語動詞選択ルールとドキュメ
ントから抽出した現実の事例に適用した．なお，内部学習アルゴリズムには，
Almuallim の学習アルゴリズムを利用した．和語動詞4種類に本提案の手法を
適用した結果，クロスバリデーションによる重み値決定は正常に動作し，実事
例のみから生成されたルールや人手作成ルールと比べて，平均10\%以上の高い
正解率をもつルールを獲得できた．

尚，本提案の手法の最大の特長は，内部学習アルゴリズムを選ばないロバスト
性にある．従って，Almuallim の学習アルゴリズムのみではなく，統計解析的
手法を含めた幅広い学習アルゴリズムに本手法を適用できる．

\acknowledgment

本研究を進めるにあたり，種々の協力・議論を頂いた，NTTコミュニケーショ
ン科学研究所・池原悟主幹研究員(現在，鳥取大学工学部教授)を初めとする，
池原研究グループ各位に深謝いたします．また，事例データを提供頂いた，
NTTコミュニケーション科学研究所・山崎毅文主任研究員に深謝いたします．

\bibliographystyle{jnlpbbl}
\bibliography{final}

\begin{biography}
\biotitle{略歴}
\bioauthor{秋葉 泰弘}{
昭和63年早稲田大学教育学部理学科数学専修卒業．
平成2年同大大学院理工学研究科数学専攻修士課程修了．
同年，日本電信電話株式会社入社．
以来，機械学習，知識獲得等の研究に従事．
平成7年人工知能学会全国大会優秀論文賞受賞．
現在，ＮＴＴコミュニケーション科学研究所，研究主任．情報処理学会会員．}

\bioauthor{石井 恵}{
平成1年慶応義塾大学理工学部数理科学科卒業．
同年，日本電信電話株式会社入社．
以来，エキスパートシステム，機械学習の研究に従事．
平成4，7年人工知能学会全国大会優秀論文賞受賞．
平成5年情報処理学会・秋期・全国大会奨励賞受賞．
現在，ＮＴＴコミュニケーション科学研究所，研究主任．情報処理学会，人工
知能学会各会員．}

\bioauthor{Hussein ALMUALLIM}{
昭和59年東京工業大学工学部電子物理工学科卒業．
昭和61年同大学大学院工学研究科情報工学専攻修士課程修了．
平成4年 Oregon State University 計算機学科博士課程修了．
同年，ＮＴＴ情報通信網研究所にて，ポスドク研究員．
現在，サウジアラビア国立石油鉱物大学計算機学科助教授．
平成6年ＮＴＴコミュニケーション科学研究所招聘教授.
Ph.D. in Computer Science.
機械学習，文字認識などの研究に従事．
平成3年 AAAI Honorable Mention Award 受賞．
平成7年人工知能学会全国大会優秀論文賞受賞．
AAAI，人工知能学会各会員．}

\bioauthor{金田 重郎}{
昭和49年京都大学工学部電気第二学科卒業．
昭和51年同大学大学院電子工学専攻修士課程修了．
同年，日本電信電話公社・武蔵野電気通信研究所入所．
以来，誤り訂正符号，フォールトトレラント技術，知識獲得，エキスパートシ
ステム，等の研究に従事．
現在，ＮＴＴコミュニケーション科学研究所，主幹研究員．
工学博士．技術士(情報処理部門)．
平成4，7年人工知能学会全国大会優秀論文賞受賞．
IEEE，電子情報通信学会，情報処理学会，人工知能学会各会員．}
\bioreceived{受付}
\biorevised{再受付}
\再受付{96}{1}{25}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}
