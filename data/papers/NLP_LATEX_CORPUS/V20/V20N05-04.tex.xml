<?xml version="1.0" ?>
<root>
  <jtitle>k近傍法とトピックモデルを利用した語義曖昧性解消の領域適応</jtitle>
  <jauthor>新納浩幸佐々木稔</jauthor>
  <jabstract>本論文では語義曖昧性解消(WordSenseDisambiguation,WSD)の領域適応に対する手法を提案する．WSDの領域適応の問題は，2つの問題に要約できる．1つは領域間で語義の分布が異なる問題，もう1つは領域の変化によりデータスパースネスが生じる問題である．本論文では上記の点を論じ，前者の問題の対策として学習手法にk~近傍法を補助的に用いること，後者の問題の対策としてトピックモデルを用いることを提案する．具体的にはターゲット領域から構築できるトピックモデルによって，ソース領域の訓練データとターゲット領域のテストデータにトピック素性を追加する．拡張された素性ベクトルからSVMを用いて語義識別を行うが，識別の信頼性が低いものにはk~近傍法の識別結果を用いる．BCCWJコーパスの2つの領域PB（書籍）とOC（Yahoo!知恵袋）から共に頻度が50以上の多義語17単語を対象にして，WSDの領域適応の実験を行い，提案手法の有効性を示す．別種の領域間における本手法の有効性の確認，領域の一般性を考慮したトピックモデルをWSDに利用する方法，およびWSDの領域適応に有効なアンサンブル手法を考案することを今後の課題とする．</jabstract>
  <jkeywords>語義曖昧性解消，領域適応，トピックモデル，k~近傍法，教師なし学習</jkeywords>
  <section title="はじめに">自然言語処理のタスクにおいて帰納学習手法を用いる際，訓練データとテストデータは同じ領域のコーパスから得ていることが通常である．ただし実際には異なる領域である場合も存在する．そこである領域（ソース領域）の訓練データから学習された分類器を，別の領域（ターゲット領域）のテストデータに合うようにチューニングすることを領域適応という．本論文では語義曖昧性解消(WordSenseDisambiguation,WSD)のタスクでの領域適応に対する手法を提案する．まず本論文における「領域」の定義について述べる．「領域」の正確な定義は困難であるが，本論文では現代日本語書き言葉均衡コーパス(BCCWJコーパス)におけるコーパスの「ジャンル」を「領域」としている．コーパスの「ジャンル」とは，概略，そのコーパスの基になった文書が属していた形態の分類であり，書籍，雑誌，新聞，白書，ブログ，ネット掲示板，教科書などがある．つまり本論文における「領域」とは，書籍，新聞，ブログ等のコーパスの種類を意味する．領域適応の手法はターゲット領域のラベル付きデータを利用するかしないかという観点で分類できる．利用する場合を教師付き手法，利用しない場合を教師なし手法と呼ぶ．教師付き手法については多くの研究があるの研究(Daum'e2007)daume0はその簡易性と有効性から広く知られている．．また能動学習や半教師あり学習は，領域適応の問題に直接利用できるために，それらのアプローチをとる研究も多い．これらに対して教師なし手法の従来研究は少ない．教師なし手法は教師付き手法に比べパフォーマンスが悪いが，ラベル付けが必要ないという大きな長所がある．また領域適応は転移学習と呼ばれることからも明らかなように，ソース領域の知識（例えば，ラベル付きデータからの知識）をどのように利用するか（ターゲット領域に転移させるか）が解決の鍵であり，領域適応の手法はターゲット領域のラベル付きデータを利用しないことで，その効果が明確になる．このため教師なし手法を研究することで，領域適応の問題が明確になると考えている．この点から本論文では教師なし手法を試みる．本論文の特徴はWSDの領域適応の問題を以下の2点に分割したことである．領域間で語義の分布が異なる領域の変化によりデータスパースネスが生じる領域適応の手法は上記2つの問題を同時に解決しているものが多いために，このような捉え方をしていないが，WSDの領域適応の場合，上記2つの問題を分けて考えた方が，何を解決しようとしているのかが明確になる．本論文では上記2点の問題に対して，ターゲット領域のラベル付きデータを必要としない各々の対策案を提示する．具体的に，(1)に対してはk~近傍法を補助的に利用し，(2)に対しては領域毎のトピックモデルを利用する．実際の処理は，ターゲット領域から構築できるトピックモデルによって，ソース領域の訓練データとターゲット領域のテストデータにトピック素性を追加する．拡張された素性ベクトルからSVMを用いて語義識別を行うが，識別の信頼性が低いものにはk~近傍法の識別結果を用いる．上記の処理を本論文の提案手法とする．提案手法の大きな特徴は，トピックモデルをWSDに利用していることである．トピックモデルの構築には語義のラベル情報を必要としないために，領域適応の教師なし手法が実現される．トピックモデルをWSDに利用した従来の研究はいくつかあるため，それらとの差異を述べておく．まずトピックモデルをWSDに利用するにしても，その利用法は様々であり確立された有効な手法が存在するわけではなく，ここで利用した手法も1つの提案と見なせる．また従来のトピックモデルを利用したWSDの研究では，語義識別の精度改善が目的であり，領域適応の教師なし手法に利用することを意図していない．そのためトピックモデルを構築する際に，もとになるコーパスに何を使えば有効かは深くは議論されていない．しかし領域適応ではソース領域のコーパスを単純に利用すると，精度低下を起こす可能性もあるため，本論文ではソース領域のコーパスを利用せず，ターゲット領域のコーパスのみを用いてトピックモデルを構築するアプローチをとることを明確にしている．この点が大きな差異である．実験ではBCCWJコーパスの2つ領域PB（書籍）とOC（Yahoo!知恵袋）から共に頻度が50以上の多義語17単語を対象にして，WSDの領域適応の実験を行った．単純にSVMを利用した手法と提案手法とをマクロ平均により比較した場合，OCをソースデータにして，PBをターゲットデータにした場合には有意水準0.05で，ソースデータとターゲットデータを逆にした場合には有意水準0.10で提案手法の有効性があることが分かった．</section>
  <section title="WSD の領域適応の問題">WSDの対象単語(w)の語義の集合を(C=c_1,c_2,,c_k)，(w)を含む文（入力データ）を(x)とする．WSDの問題は最大事後確率推定を利用すると，以下の式の値を求める問題として表現できる．[_cCP(c)P(x|c)]つまり訓練データを利用して語義の分布(P(c))と各語義上での入力データの分布(P(x|c))を推定することでWSDの問題は解決できる．今，ソース領域を(S)，ターゲット領域を(T)とした場合，WSDの領域適応の問題は(P_S(c)P_T(c))と(P_S(x|c)P_T(x|c))から生じている．(P_S(c)P_T(c))が成立していることは明らかだが，(P_S(x|c)P_T(x|c))に対しては一考を要する．一般の領域適応の問題では(P_S(x|c)P_T(x|c))であるが，WSDに限れば(P_S(x|c)=P_T(x|c))と考えることもできる．実際Chanらは(P_S(x|c))と(P_T(x|c))の違いの影響は非常に小さいと考え，(P_S(x|c)=P_T(x|c))を仮定し，(P_T(c))をEMアルゴリズムで推定することでWSDの領域適応を行っている．古宮らは2つのソース領域の訓練データを用意し，そこからランダムに訓練データを取り出してWSDの分類器を学習している．論文中では指摘していないが，これも(P_S(c))を(P_T(c))に近づける工夫である．ソース領域が1つだとランダムに訓練データを取り出しても(P_S(c))は変化しないが，ソース領域を複数用意することで(P_S(c))が変化する．ただし(P_S(x|c)=P_T(x|c))が成立していたとしても，WSDの領域適応の問題が(P_T(c))の推定に帰着できるわけでない．仮に(P_S(x|c)=P_T(x|c))であったとしても，領域(S)の訓練データだけから(P_T(x|c))を推定することは困難だからである．これは共変量シフトの問題と関連が深い．共変量シフトの問題とは入力(x)と出力(y)に対して，推定する分布(P(y|x))が領域(S)と(T)で共通しているが，(S)における入力の分布(P_S(x))と(T)における入力の分布(P_T(x))が異なる問題である．(P_S(x|c)=P_T(x|c))の仮定の下では，入力(x)と出力(c)が逆になっているので，共変量シフトの問題とは異なる．ただしWSDの場合，全く同じ文(x)が別領域に出現したとしても，(x)内の多義語(w)の語義が異なるケースは非常に稀であるため(P_S(c|x)=P_T(c|x))が仮定できる．(P_T(c|x))は語義識別そのものなので，WSDの領域適応の問題は共変量シフトの問題として扱えることができる．共変量シフト下では訓練事例(x_i)に対して密度比(P_T(x_i)/P_S(x_i))を推定し，密度比を重みとして尤度を最大にするようにモデルのパラメータを学習する．Jiangらは密度比を手動で調整し，モデルにはロジステック回帰を用いている．齋木らは(P(x))をunigramでモデル化することで密度比を推定し，モデルには最大エントロピーモデルを用いている．ただしどちらの研究もタスクはWSDではない．WSDでは(P(x))が単純な言語モデルではなく，「(x)は対象単語(w)を含む」という条件が付いているので，密度比(P_T(x)/P_S(x))の推定が困難となっている．また教師なしの枠組みで共変量シフトの問題が扱えるのかは不明である．本論文では(P_S(c|x)=P_T(c|x))を仮定したアプローチは取らず，(P_S(x|c)=P_T(x|c))を仮定する．この仮定があったとしても，領域(S)の訓練データだけから(P_T(x|c))を推定するのは困難である．ここではこれをスパース性の問題と考える．つまり領域(S)の訓練データ(D)は領域(T)においてスパースになっていると考える．スパース性の問題だと考えれば，半教師あり学習や能動学習を領域適応に応用するのは自然である(Rai,Saha,Daum'e,andVenkatasubramanian2010)rai2010domain．また半教師あり学習や能動学習のアプローチを取った場合，(T)の訓練データが増えるので語義の分布の違い自体も同時に解消されていく．ここで指摘したいのは(P_S(x|c)=P_T(x|c))が成立しており(P_T(x|c))の推定を困難にしているのがスパース性の問題だとすれば，領域(S)の訓練データ(D)は多いほどよい推定が行えるはずで，(D)が大きくなったとしても推定が悪化するはずがない点である．しかし現実には(D)を大きくするとWSD自体の精度が悪くなる場合もあることが報告されている（例えば）．これは一般に負の転移現象と呼ばれている．WSDの場合(P_T(x|c))を推定しようとして，逆に語義の分布(P_T(c))の推定が悪化することから生じる．つまり領域(T)におけるWSDの解決には(T)におけるデータスパースネスの問題に対処しながら，同時に(P_T(c))の推定が悪化することを避けることが必要となる．また領域適応ではアンサンブル学習も有効な手法である．アンサンブル学習自体はかなり広い概念であり，実際，バギング，ブースティングまた混合分布もアンサンブル学習の一種である．Daum'eらは領域適応のための混合モデルを提案している(Daum'eandMarcu2006)daume2006domain．そこでは，ソース領域のモデル，ターゲット領域のモデル，そしてソース領域とターゲット領域を共有したモデルの3つを混合モデルの構成要素としている．Daiらは代表的なブースティングアルゴリズムのAdaBoostを領域適応の問題に拡張したTrAdaBoostを提案している．またKamishimaらはバギングを領域適応の学習用に拡張したTrBaggを提案している．WSDの領域適応については古宮の一連の研究があるが，そこではターゲット領域のラベルデータの使い方に応じて学習させた複数の分類器を用意しておき，単語や事例毎に最適な分類器を使い分けることで，WSDの領域適応を行っている．これらの研究もアンサンブル学習の一種と見なせる．</section>
  <section title="提案手法"/>
  <subsection title="k~近傍法の利用">領域(T)におけるデータスパースネスの問題に対処する際に，(P_T(c))の推定が悪化することを避けるために，本論文では識別の際に(P_T(c))の情報をできるだけ利用しないという方針をとる．そのためにk~近傍法を利用する．どのような学習手法を取ったとしても，何らかの汎化を行う以上，(P_T(c))の影響を受けるが，k~近傍法はその影響が少ない．k~近傍法はデータ(x)のクラスを識別するのに，訓練データの中から(x)と近いデータ(k)個を取ってきて，それら(k)個のデータのクラスの多数決により(x)のクラスを識別する．が(P_T(c))の影響が少ないのは(k=1)の場合（最近傍法）を考えればわかりやすい．例えば，クラスが(c_1,c_2)であり，(P(c_1)=0.99)，(P(c_2)=0.01)であった場合，通常の学習手法であれば，ほぼ全てのデータを(c_1)と識別するが，最近傍法では，入力データ(x)と最も近いデータ1つだけがクラス(c_2)であれば，(x)のクラスを(c_2)と判断する（参照）．つまりk~近傍法ではデータ全体の分布を考慮せずに(k)個の局所的な近傍データのみでクラスを識別するために，その識別には(P_T(c))の影響が少ない．ただしk~近傍法は近年の学習器と比べるとその精度が低い．そのためここではk~近傍法を補助的に利用する．具体的には通常の識別はSVMで行い，SVMでの識別の信頼度が閾値()以下の場合のみ，k~近傍法の識別結果を利用することにする．ここで()の値が問題だが，語義の数が(K)個である場合，識別の信頼度（その語義である確率）は少なくとも(1/K)以上の値となる．そのためここではこの値の1割をプラスし(=1.1/K)とした．なおこの値は予備実験等から得た最適な値ではないことを注記しておく．</subsection>
  <subsection title="トピックモデルの利用">領域(T)におけるデータスパースネスの問題に対処するために，ここではトピックモデルを利用する．WSDの素性としてシソーラスの情報を利用するのもデータスパースネスへの1つの対策である．シソーラスとしては，分類語彙表などの手作業で構築されたものとコーパスから自動構築されたものがある．前者は質が高いが分野依存の問題がある．後者は質はそれほど高くないが，分野毎に構築できるという利点がある．ここでは領域適応の問題を扱うので，後者を利用する．つまり領域(T)からシソーラスを自動構築し，そのシソーラス情報を領域(S)の訓練事例と領域(T)のテスト事例に含めることで，WSDの識別精度の向上を目指す．注意として，WSDでは単語間の類似度を求めるためにシソーラスを利用する．そのため実際にはシソーラスを構築するのではなく，単語間の類似度が測れる仕組みを作っておけば良い．この仕組みが単語のクラスタリング結果に対応する．つまりWSDでの利用という観点では，シソーラスと単語クラスタリングの結果は同等である．そのため本論文においてシソーラスと述べている部分は，単語のクラスタリング結果を指している．この単語のクラスタリング結果を得るためにトピックモデルを利用する．トピックモデルとは文書(d)の生起に(K)個の潜在的なトピック(z_i)を導入した確率モデルである．[p(d)=_i=1^Kp(z_i)p(d|z_i)]トピックモデルの1つであるLatentDirichletAllocation(LDA)を用いた場合，単語(w)に対して(p(w|z_i))が得られる．つまりトピック(z_i)をひとつのクラスタと見なすことで，LDAを利用して単語のソフトクラスタリングが可能となる．領域(T)のコーパスとLDAを利用して，(T)に適した(p(w|z_i))が得られる．(p(w|z_i))の情報をWSDに利用するいくつかの研究があるが，ここではハードタグを利用する．ハードタグとは(w)に対して最も関連度の高いトピック(z_i)を付与する方法である．[i=_ip(w|z_i)]まずトピック数を(K)としたとき，(K)次元のベクトル(t)を用意し，入力事例(x)中に(n)種類の単語(w_1,w_2,,w_n)が存在したとき，各(w_j)((j=1n))に対して最も関連度の高いトピック(z_i)を求め，(t)の(i)次元の値を1にする．これを(w_1)から(w_n)まで行い(t)を完成させる．作成できた(t)をここではトピック素性と呼ぶ．トピック素性を通常の素性ベクトル（ここでは基本素性と呼ぶ）に結合することで，新たな素性ベクトルを作成し，その素性ベクトルを対象に学習と識別を行う．なお，本論文で利用した基本素性は，対象単語の前後の単語と品詞及び対象単語の前後3単語までの自立語である．</subsection>
  <section title="実験"/>
  <subsection title="実験設定と実験結果">現代日本語書き言葉均衡コーパス（BCCWJコーパス）のPB（書籍）とOC（Yahoo!知恵袋）を異なった領域として実験を行う．SemEval-2の日本語WSDタスクではPBとOCを含む4ジャンルの語義タグ付きコーパスが公開されているので，語義のラベルはこのデータを利用する．PBとOCから共に頻度が50以上の多義語17単語をWSDの対象単語とする．これらの単語と辞書上での語義数及び各コーパスでの頻度と語彙数をに示す．領域適応としてはPBをソース領域，OCをターゲット領域としたものと，OCをソース領域，PBをターゲット領域としたものの2種類を行う．注意としてSemEval-2の日本語WSDタスクのデータを用いれば，更に異なった領域間の実験は可能であるが，領域間に共通してある程度の頻度で出現する多義語が少ないことなどから本論文ではPBとOC間の領域適応に限定している．PBからOCへの領域適応の実験結果をと図~に示す．またOCからPBへの領域適応の実験結果をと図~に示す．との数値は正解率を示している．「k-NN」の列はk~近傍法の識別結果を示す．ここでは(k=1)としている．「SVM」の列は基本素性だけを用いて学習したSVMの識別結果を示し，「SVM+TM」の列は基本素性にターゲット領域から得たトピック素性を加えた素性を用いて学習したSVMの識別結果を示し，「提案手法」の列は「SVM+TM」の識別で信頼度の低い結果をk~近傍法の結果に置き換えた場合の識別結果を示す．また「self」はターゲット領域の訓練データに対して5分割交差検定を行った場合の平均正解率であり，理想値と考えて良い．ただし一部の単語で「self」の値が「提案手法」などよりも低い．これはそれらの単語のソース領域のラベル付きデータの情報が，ターゲット領域で有効であったことを意味している．つまり「負の転移」が生じていないため，これらの単語については領域適応の問題が生じていないとも考えられる．本実験のSVMの実行には，SVMライブラリのlibsvmcjlin/libsvm/を利用した．そこで用いたカーネルは線形カーネルである．また識別の信頼度の算出にはlibsvmで提供されている|-b|オプションを利用した．このオプションは，基本的には，onevs.rest法を利用して各カテゴリ（本実験の場合，語義）までの距離（識別関数値）の比較から，信頼度を算出している．識別結果は最も信頼度の高いカテゴリ（語義）となる．またBCCWJコーパスは形態素解析済みの形で提供されているため，基本素性の単語や品詞は，形態素解析システムを利用せずに直接得ることができる．またトピックモデルの作成にはLDAツールdaiti-m/dist/lda/を用い，トピック数は全て100として実験を行った．17単語の正解率のマクロ平均をみると，PBからOCへの領域適応とOCからPBへの領域適応のどちらにおいても，以下の関係が成立しており，提案手法が有効であることがわかる．k-NN&lt;SVM&lt;SVM+TM&lt;提案手法verbatimなお本実験の評価はマクロ平均で行った．マイクロ平均による評価も可能ではあるが，本実験の場合，テストデータの用例数に幅がありすぎ，結果的にテストデータの用例数の多い単語の識別結果がマイクロ平均の値に大きく影響する．このためここではマクロ平均のみによる評価を行っている．マイクロ平均で評価した場合は，わずかではあるがSVMが最も高い評価値を出していた．</subsection>
  <subsection title="有意差の検定">t検定を用いて各手法間の正解率のマクロ平均値の有意差を検定する．対象単語(w)のソース領域でのラベル付きデータからランダムにその9割を取り出し，その9割のデータから前述したWSDの実験（「SVM」，「SVM+TM」，「提案手法」）を行う．この際，「提案手法」ではk-NNの結果を用いるが，そこでも9割のデータしかないことに注意する．これを1セットの実験とし，50セットの実験を行い，その正解率のマクロ平均を求めた．PBからOCへの領域適応の結果をに示す．またOCからPBへの領域適応の結果をに示す．t検定を行う場合，まず分散比の検定から2つのデータが等分散と見なせることを示す必要がある．自由度(49,49)のF値を調べることで，有意水準0.10で等分散を棄却するためには，分散比が0.6222以下か1.6073以上の値でなければならない．とから，各領域適応でどの手法間の組み合わせを行っても，正解率の分散が等しいことを棄却できないことは明らかであり，ここではt検定を行えると判断できる．t検定の片側検定を用いた場合，ここでの自由度は48なので有意水準0.05で有意差を出すt値は1.6772以上，有意水準0.10で有意差を出すt値は1.2994以上の値となる．このため有意差の検定結果はとのようにまとめられる．結論的には提案手法とSVMとの正解率のマクロ平均の差はOCからPBの領域適応では有意だが，PBからOCの領域適応では有意ではない．ただし有意水準を0.10に緩和した場合には，PBからOCの領域適応でも有意であると言える．細かく手法を分けて調べた場合，トピックモデルを利用すること（SVM+TMとSVMの差）とk-NNを併用すること（提案手法とSVM+TMの差）についての有意性はまちまちであった．ただし有意水準を0.10に緩和した場合，トピックモデルを利用する手法についてPBからOCの領域適応以外の組み合わせについては全て有意性が認められた．</subsection>
  <section title="考察"/>
  <subsection title="語義分布の違い">本論文では，WSDの領域適応は語義分布の違いの問題を解決するだけは不十分であることを述べた．NaiveBayesを利用して，この点を調べた．NaiveBayesの場合，以下の式で語義を識別する．[P_S(c)P_S(x|c)]ここで事前分布(P_S(c))の代わりに領域(T)の訓練データから推定した(P_T(c))を用いる．これは語義分布を正確に推定できたという仮定での仮想的な実験である．結果をに示す．全体として理想的な語義分布を利用すれば，正解率は改善されるが，効果はわずかしかない．またPBからOCの「前」やOCからPBの「見る」「持つ」は逆に精度が悪化している．更に理想的な語義分布を利用できたとしても，通常のSVMよりも正解率が劣っている．これらのことから，語義分布の正確な推定のみではWSDの領域適応の解決は困難であることがわかる．</subsection>
  <subsection title="トピックモデルの領域依存性の度合い">WSDにおいてデータスパースネスの問題の対処として，シソーラスを利用することは一般に行われてきている．LDAから得られるトピック(z_i)のもとで単語(w)が生起する確率(p(w|z_i))は，単語のソフトクラスタリング結果に対応しており，これはLDAの処理対象となったコーパスに合ったシソーラスと見なせる．このためトピックモデルがWSDに利用できることは明らかである．ただしその具体的な利用方法は確立されていない．問題は2つある．1つはトピック素性の表現方法である．ここではハードタグを利用したが，ソフトタグの方が優れているという報告もある．國井はハードタグとソフトタグの中間にあたるミドルソフトタグを提案している．いずれにしても，トピック素性の有効な表現方法はトピック数やコーパスの規模にも依存した問題であり，どういった表現方法で利用すれば良いかは未解決である．もう1つの問題はトピックモデルから得られるシソーラスの領域依存性の度合いである．本論文でもLDAから領域依存のトピックモデルが作成できることに着目してトピックモデルを領域適応の問題に利用した．ただし領域(A)のコーパスと領域(B)のコーパスがあった場合，各々のコーパスから各々の知識を獲得するよりも，両者のコーパスを合わせて両領域の知識を獲得した方が，一方のコーパスから得られる知識よりも優れていることがある．例えば森は単語分割のタスクにおいて，各々の領域のタグ付きデータを使うことで精度を上げることができたが，全ての領域のタグ付きデータを使えば更に精度を上げることができたことを報告している．領域の知識を合わせることは，その知識をより一般的にしていることであり，領域依存の知識はあまり領域に依存しすぎるよりも，ある程度，一般性があった方がよいという問題と捉えられる．本実験で言えばPBのコーパスとOCのコーパスと両者を合わせて学習したトピックモデルは，各々のコーパスから学習したトピックモデルよりも優れている可能性がある．以下その実験の結果をに示す．ターゲット領域がPBの場合，ソース領域のOCのコーパスを追加することで正解率は低下するが，ターゲット領域がOCの場合，ソース領域のPBのコーパスを追加することで正解率が向上する．これはOC（Yahoo!知恵袋）のコーパスの領域依存が強いが，その一方で，PB（書籍）のコーパスの領域依存が弱く，より一般的であることから生じていると考える．一般性の高い領域に領域依存の強い知識を入れると性能が下がるが，より特殊な領域には，その領域固有の知識に一般的知識を組み入れることで性能が更に向上すると考えられる．これらの詳細な分析と対策は今後の課題である．</subsection>
  <subsection title="k~近傍法の効果とアンサンブル手法">本論文ではSVMでの識別の信頼度の低い部分をk~近傍法の識別結果に置き換えるという処理を行った．置き換えが起こったものだけを対象にして，k~近傍法とSVMでの正解数を比較した．結果をとに示す．PBからOCへの領域適応では「子供」，OCからPBへの領域適応では「入れる」についてはSVMの方がk~近傍法の方よりもよい正解率だが，それ以外はk~近傍法の正解率はSVMの正解率と等しいかそれ以上であった．つまりSVMで識別精度が低い部分に関しては，k~近傍法で識別する効果が確認できる．またk~近傍法の(k)をここでは(k=1)とした．この(k)の値を3や5に変更した実験結果をとに示す．複数の分類器を組み合わせて利用する学習手法をアンサンブル学習というが，本論文の手法もアンサンブル学習の一種と見なせる．k~近傍法自体は(k=1)よりも(k=3)や(k=5)の方が正解率が高いが，本手法のようにSVMの識別の信頼度の低い部分のみに限定すれば，(k=1)のを利用した方がよい．これはアンサンブル学習では高い識別能力の学習器を組み合わせるのではなく，互いの弱い部分を補強し合うような形式が望ましいことを示している．</subsection>
  <section title="おわりに">本論文ではWSDの領域適応に対する手法を提案した．まずWSDの領域適応の問題を，以下の2つの問題に要約できることを示し，関連研究との位置づけを示した．領域間で語義の分布が異なる領域の変化によりデータスパースネスが生じる次に上記の2つの問題それぞれに対処する手法を提案した．1点目の問題に対してはk~近傍法を補助的に用いること，2点目の問題に対してはトピックモデルを利用することである．BCCWJコーパスの2つ領域PB（書籍）とOC（Yahoo!知恵袋）から共に頻度が50以上の多義語17単語を対象にして，WSDの領域適応の実験を行い，提案手法の有効性を示した．ただし領域はOCとPBに限定しており，提案手法が他の領域間で有効であるかは確認できていない．この点は今後の課題である．また領域の一般性を考慮したトピックモデルをWSDに利用する方法，およびWSDの領域適応に有効なアンサンブル手法を考案することも今後の課題である．document</section>
</root>
