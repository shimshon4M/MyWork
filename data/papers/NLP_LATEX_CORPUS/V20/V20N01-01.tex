\documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{multirow}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}

\def\sec#1{}
\def\eq#1{}
\def\fig#1{}
\def\tab#1{}

\def\algo#1{}





\Volume{20}
\Number{1}
\Month{March}
\Year{2013}

\received{2012}{8}{3}
\revised{2012}{10}{26}
\accepted{2012}{11}{28}

\setcounter{page}{3}

\jtitle{意見集約における相対的特徴を考慮した評価視点の構造化}
\jauthor{
乾　　孝司\affiref{Author} \and 板谷　悠人\affiref{Author} \and 山本　幹雄\affiref{Author} \and 新里　圭司\affiref{Author_2} \and \\
	平手　勇宇\affiref{Author_2} \and 山田　　薫\affiref{Author_2}}
\jabstract{
本論文では，レビュー集合から多数の評価視点が得られる状
況において，評価対象間の相対的特徴を考慮した重要度（ス
コア）に従って評価視点をランキングする課題について述
べる．また，レビューはその数だけ書き手が存在することか
ら評価視点の異表記が生じやすく，これがランキングに悪影
響を与える．本論文では，評価視点に対してクラスタリング
を適用することで異表記問題へ対応する手法を提案する．
評価実験を通して，提案したスコア関数がランキング性能の
向上に有効であること，およびクラスタリングに基づくラン
キング補正手法によって，平均適合率（MAP指標）が向上する
ことを確認した．
}
\jkeywords{評判分析，評価視点，属性，対数尤度比，異表記}

\etitle{Structuring Opinions by Relative Characteristics \\ for User-Opinion Aggregation}
\eauthor{
Takashi Inui\affiref{Author} \and Yuto Itaya\affiref{Author} \and Mikio Yamamoto\affiref{Author}
	\and Keiji Shinzato\affiref{Author_2} \and \\
	Yu Hirate\affiref{Author_2} \and Kaoru Yamada\affiref{Author_2}} 
\eabstract{
We propose a scoring function for aspect ranking that
facilitates user-opinion aggregation.  The function
uses the log-likelihood ratio to capture relative
characteristics between opinions.  Review documents
contain many variant expressions because they are
written by different web users.  We also propose a
re-ranking method that identifies variant expressions
having the same meaning by using several clustering
techniques.  The experimental results indicate that
the proposed scoring function and the re-ranking
method are more effective than baseline methods.
}
\ekeywords{sentiment analysis, aspect, log-likelyhood ratio, variant expression}

\headauthor{乾，板谷，山本，新里，平手，山田}
\headtitle{意見集約における相対的特徴を考慮した評価視点の構造化}

\affilabel{Author}{筑波大学システム情報工学研究科コンピュータサイエンス専攻}{Department of Computer Science, Graduate school of SIE, University of Tsukuba}
\affilabel{Author_2}{楽天株式会社}{Rakuten, Inc.}



\begin{document}
\maketitle


\section{はじめに}
\label{sec:intro}

近年のWeb の発展は目覚ましいものがあり，Blog や掲示板の
ように，個人が気軽に自分の意見や感想を書き込める場が増
えている．
特に，商品購入サイトやオークションサイトなどでは，実際
に商品を購入したり，サービス提供を受けたユーザが感想を
書き込めるユーザレビュー用ページを提供している場合も多
く，レビューは，商品やサービスの潜在的購入者にとって，
貴重な情報源のひとつになっている．

レビューの件数が増加すれば，それだけ多くの感想を読む機
会を得ることになるが，商品やサービスによっては何百件か
ら何千件もレビューが存在することもある．この場合，レ
ビューの内容をすべて把握することは困難であるが，このよ
うな問題に対して従来からレビューを自動的に分類したり，
意見を集約する研究が盛んに行われている\cite{sa2}．

意見の集約に関する研究の例として，例えば，Huら
\cite{hu}は，評価視点 (opinion features) という概念に基
づいてレビュー集合内の意見を集約する手法を提案している．
ここで，評価視点とは，評価対象（すなわち商品やサービス）
の部分や属性のことであり，例えば，評価対象としてデジタ
ルカメラの特定の商品（「デジタルカメラ$X$」）があったと
すると，「画質」や「解像度」などがその評価視点となる．
Huらは，レビュー集合からユーザ評価が肯定または否定とな
る評価視点を自動抽出し，
\begin{itemize}
 \item デジタルカメラ$X$
 \begin{itemize}
  \item 画　質　肯定：253／否定：6
  \item 解像度　肯定：134／否定：10
  \item ...
 \end{itemize}
\end{itemize}
のような集約結果を生成する手法を提案した．ここで，集約
結果内の数値は頻度を表しており，デジタルカメラ$X$の画質
に対しては253件の肯定評価を示すレビューがあったことを意
味する．

このような評価視点の（半）自動抽出に基づく研究は他にも，
小林ら\cite{kobayashi}や，Liuら\cite{liu}，Jakobら
  \cite{jakob}等がある．
しかしながら，これらの先行研究では，基本的に評価視点を
漏れなく列挙することが目的となっているため，結果として，
数多くの評価視点が出力され，どの評価視点が評価対象にとっ
て重要であるかがわからないという問題がある．また，実際
に集約結果としてユーザに評価視点を提示することを考えた
場合にも，重要度に応じて提示する評価視点に順序を与えた
り，取捨選択できることが望ましい．

本論文では，このような背景に基いて，上記の先行研究など，
何らかの方法によって得られた多数ある評価視点に対し，そ
れらをある重要度に従ってランキングする課題を新たに考え，
ランキングに適した手法について検討する
（\sec{uniq_aspect_ranking}）．
重要度の考え方にはいろいろ考えられるが，本論文では，ユー
ザは商品購入の際に複数の競合商品を横並びで比較すること
が多い事を踏まえ，次のように考える．
すなわち，競合する複数の評価対象に対して，これらの中で，
他の評価対象からある特定の評価対象を差別化できるような
評価視点ほど重要であると考え，そのような評価視点に高い
重要度を割り当てることを考える．以降，本論文では，この
ような評価視点のことを特徴的評価視点と呼ぶ．
例えば，あるユーザが出張の際に利用する宿泊施設を探して
おり，幾つか探し当てたとする（宿泊施設$X$，$Y$，$Z$）．
しかし，どの施設も値段や立地条件が似たり寄ったりであり，
どれを選ぶか悩んでいる．このような状況において，提案手
法を用いて各施設のレビューから特徴的評価視点を見つけ出
し，施設$X$は特に宿泊利用者の間で「朝食バイキング」が人
気であり，施設$Z$だけが「まくら」にこだわっていることを
自動抽出することができれば，こういった情報を優先的にユー
ザに提示する手段を提供することができると考えている．
なお，\sec{experiment}の評価実験では，実験データとして
宿泊施設予約サイトから得られた宿泊施設についてのレビュー
データを用いている．そのため，以降においても提案手法の
説明に例を用いる場合は宿泊施設を評価対象とする例を用い
る．

また，レビューはその数だけ書き手が存在することから評価
視点の異表記が生じやすい．そこで，本研究では，評価視点
のランキングに際して，クラスタリングによって異表記の影
響を考慮したランキングの補正手法を提案し，ランキングと
クラスタリングを併用することで評価視点の構造化をおこな
う（\sec{cl}）．


本論文の貢献をまとめると，以下のようになる．

\begin{itemize}
\item[（1）]

従来手法によって多数抽出される評価視点を構造化して提示
する際，その構造化として，特定の評価対象を他から差別化
できるような評価視点が重要であると考え，その重要度に従っ
てランキングすることを提案している点．

\item[（2）]

上記ランキング課題に利用できる具体的な尺度として，
\sec{uniq_aspect_ranking}で説明する対数尤度比に従った尺
度を適用し，その有効性を実験的に検証している点．

\item[（3）]

また，上記ランキング課題では異表記問題が発生するため，
その解決策として評価視点をクラスタリングすることの提案，
および具体的なクラスタリング手法を用いて，その有効性を
実験的に検証している点．
\end{itemize}

本論文の構成は以下の通りである．まず，\sec{relation}で
関連研究について述べ，続く，\sec{uniq_aspect_ranking}と
\sec{cl}で評価視点をランキングするための提案手法につい
て述べる．\sec{experiment}で評価実験について述べた後，
\sec{owarini}で本論文をまとめる．



\section{関連研究}
\label{sec:relation}

本論文と関連する，レビューを処理対象とする研究課題を時
系列順に追って概観する．関連研究としてまず取り組まれた
課題は，レビューをその内容に従って肯定か否定かに分類す
る課題である\cite{turney,pang,mullen}．しかし，文書単位
（レビュー単位）で分類するだけでは「何がどう良いか？」
がわからない点が問題とされた．
そこで，この問題を解決するために，文書内で具体的に評価
されている事柄（すなわち，評価視点）を特定する研究が行
われるようになった\cite{hu,liu,kobayashi2,jakob}．しか
し，前節でも述べたように，これら手法では評価視点が多量
に出力されることから，出力される評価視点群を何らかの方
法で構造化することに関心が集まるようになった．


具体的な構造化の手法として，これまで，評価視点群をグルー
ピングする手法やランキングする手法が提案されている
\cite{zhai,yu}．
グルーピングする手法では，「buttery power」と「buttery
  life」といった同一あるいは類似の評価視点を同じグルー
プに所属させて合わせてユーザに提示することで，ユーザの
可読性を向上させることを狙う．このような手法として，例
えば，Zhaiら\cite{zhai}は，事前に人手で定義した評価視点
クラスに各評価視点を自動分類する手法を提案している．よ
り具体的には，Nigamら\cite{nigam2000a}によって提案され
た半教師あり学習手法に，「同じ語を含む評価視点は同じ評
  価視点クラスになりやすい」といった情報を制約として取
り込む手法を提案している．
この手法のように評価視点を分類して構造化する場合，あら
かじめ定義した通りの構造化ができる利点がある一方で，想
定していない評価視点のクラスが必要になった場合の対応に
かかる負荷が高いという欠点がある．


次に，評価視点をランキングする手法では，事前に定めたあ
る観点に従って各評価視点にスコアを付け，スコアの大きさ
に基いて評価視点を順番に並べてユーザに提示することを考
える．これによって，ユーザは観点に合致する評価視点のみ
を選択的にすばやく確認することが可能になる．
このような研究として，Yuら\cite{yu}の研究がある．Yuらは，
まず，レビューには評価対象に対する総合的な評価点
(rating) が書き手によって与えられていることを前提とす
る．そして，このようなレビューの中で，ユーザから多く言
及されており，かつ総合的な評価点の決定にもっとも影響を
与える評価視点が重要な評価視点であると仮定し，そのよう
な評価視点をランキングする手法を提案している．論文中で
は重要な評価視点の例として評価対象が「iPhone 3GS」であ
る場合，「moisture sensor」という評価視点よりも
「battery」や「speed」などの評価視点がより重要であると
述べている．

評価視点をランキングするという点で見た場合，本研究は上
述のYuらの研究と似ている．
しかし，Yuらの手法では，レビューに付与された総合的な評
価点を説明付ける評価視点に関心がある．そのため，評価対
象ごとに独立に評価視点のランキングをおこない，評価対象
間を比較することは念頭にない．
一方，本研究では，複数の評価対象に対して，評価対象間の
違いを明確に表すことができる評価視点に関心があり，Yuら
とは目的が異なっている．



\section{提案手法}
\label{sec:uniq_aspect_ranking}


\subsection{評価視点}

提案手法の説明の前に，ここで，評価視点という用語につい
て整理しておく．
本論文における評価視点は，基本的には，Hu ら\cite{hu}や
小林ら\cite{kobayashi,siten}の定義に従っている．後述す
る評価実験では，評価対象が宿泊施設であるので，そのこと
を踏まえると，本論文における評価視点は，
\begin{itemize}
\item 
宿泊施設に対する意見の焦点となる宿泊施設の構成物や属性，
あるいは，宿泊施設への宿泊という経験から生じる宿泊施設
に対する意見の焦点となるもの
\end{itemize}
であると言い表せる．例えば，宿泊施設の立地情報（「駅
    前」，「海沿い」）や施設が提供する設備に関する情報
（「風呂」，「加湿器」），施設のサービス（「バイキン
    グ」，「接客態度」）等が具体的な評価視点となる．


また，評価視点の表現形式は，単一単語（「バイキング」）
だけでなく，複合語（「朝食バイキング」）や句（「朝食の
    バイキング」）などの場合もある．本研究では以上の形
式は評価視点として認めているが，処理の都合上，以下に示
すように，連体修飾節を伴う場合は修飾部を除外して扱った．
下記例の場合，下線部は評価視点として認めたが，どちらの
例でも「メニューが新しくなった」は評価視点には含めてい
ない．
なお，表現形式の特定は以下のようにおこなった．単語の特
定には形態素解析器
MeCab\footnote{\url{http://mecab.sourceforge.net/}}を使
用した．複合語については，MeCabで解析後，名詞が連続して
いる箇所を複合語として特定している．句については，現在
は「名詞の名詞」というパターンで特定しており，他の形は
想定していない．ただし，上記パターンの名詞は名詞連続に
置換可能とした．
\begin{itemize}
 \item メニューが新しくなった\underline{朝食バイキング}が良かった．
 \item メニューが新しくなった\underline{朝食のバイキング}が良かった．
\end{itemize}



\subsection{評価視点ランキング}
\label{sec:llr}

提案手法について述べる．まず，使用する記号，および，評
価視点のランキング課題を以下のように定義する．
評価対象の集合を$\mathcal{O} =\{o_1, o_2,...,o_{|\mathcal{O}|}\}$とする．
全ての評価対象に対する全てのレビューの集合を
$\mathcal{R}$とし，
$\mathcal{R}$の要素であるレビューの中に書かれた評価視点(token) 
の系列を$\mathcal{V}=\langle v_1,v_2,...,v_n\rangle$，
$\mathcal{V}$の異なり要素 (type) の集合を
$\mathcal{U}=\{u_1,u_2,...,u_m\}$ ($m \le n$) とする．
例えば，以下のような，それぞれ 1 文と 2 文からなる短
い 2 つのレビューを要素とする集合$\mathcal{R}$があり，各
文の下線部が評価視点であったとすると，系列
$\mathcal{V}$と集合$\mathcal{U}$は次のようになる．
\begin{itemize}
 \item $\mathcal{R} = \big\{\text{``このホテルは\underline{\mbox{朝食$_{1}$}}と\underline{風呂}が良い．'', ``\underline{\mbox{朝食$_{2}$}}が美味しい．また来たいです．''}\big\}$
 \item $\mathcal{V}= \bigl\langle \text{朝食$_{1}$, 風呂, 朝食$_{2}$}\bigr\rangle $
 \item $\mathcal{U}= \big\{\text{朝食, 風呂}\big\}$
\end{itemize}
この時，ある評価対象$o_k$に関して評価視点をランキングす
るアルゴリズムを次の\algo{alg1}とする．このアルゴリズム
が示している通り，$\mathcal{U}$の要素$u_j$がランキング
の対象である．本論文では曖昧性を排除するために，以降，
$u_j$のことを単に評価視点と呼び，評価視点$u_j$ が
$\mathcal{R}$内で出現したものを評価視点トークンと呼ぶ．

\begin{algorithm}[h]
\caption{評価視点ランキング}         
\label{algo:alg1}
\begin{algorithmic}
\STATE{INPUT ~~~$o_k \in \mathcal{O}$：評価対象\\
~~~~~~~~~~~~~~~$\mathcal{U}$：評価視点集合}
\end{algorithmic}
\begin{algorithmic}[1]
\FOR{$u_j \in \cal{U}$}
\STATE $s[u_j] = score(o_k, u_j)$
\ENDFOR
\RETURN $\mathcal{U}の各要素u_jをs[u_j]の降順に整列$
\end{algorithmic}
\end{algorithm}

上記の\algo{alg1}で自明でない部分は，評価対象$o_k$ にお
ける評価視点$u_j$の重要度を決定するスコア関数
$\mathit{score}(o_k, u_j)$のみである．本研究では，このスコア関数
として，以下のような対数尤度比 (\textit{Log-Likelihood Ratio，LLR}) に基づく尺度を提案する．
これは内山ら\cite{uchiyama}が特定分野における単語の特徴
度を測る尺度として提案したものを評価視点ランキング課題
に適用したものである．以下，内山ら\cite{uchiyama}を参考
にしながら，上記尺度の詳細について述べる．

まず始めに，ある評価対象$o_k$と評価視点$u_j$が与えられ
た際，レビュー中で観測された評価視点トークン$v$に関する
確率変数$W_j$と$T_k$を以下のように定義する：
\begin{align}
W_j & =\begin{cases}
1 & vは評価視点u_jのレビュー内での出現である\\
0 & otherwise
\end{cases}
\label{eq:w}\\
T_k & =\begin{cases}
1 & vが観測されたのは評価対象o_kのレビュー内である\\
0 & otherwise
\end{cases}
\end{align}
ここで，評価視点トークン$v_i$ ($1 \le i \le n$) に対応
する確率変数$W_j$，$T_k$の値をそれぞれ$w^i_j$，$t^i_k$とすると，
$\mathcal{V}$ から次のような確率変数の
値の組みで表された系列$\mathcal{V}_{jk} = \bigl\langle
\langle w^1_j, t^1_k \rangle ,\langle w^2_j, t^2_k
\rangle , ... , \langle w^n_j, t^n_k \rangle
\bigr\rangle$が新たに得られる．
この時，それぞれの評価視点トークンが確率的に独立である
と仮定すると，$\mathcal{V}_{jk}$の生起確率は次式で表される：
\begin{equation}
Pr(\mathcal{V}_{jk})= \prod_{i=1}^{n}Pr(W_j=w^i_j, T_k=t^i_k)
\end{equation}

\begin{table}[b]
\vspace{-1\Cvs}
\caption{トークン集合の集計表}
\input{01table01.txt}
\end{table}

また，各トークンを変数$W_j$，$T_k$の値ごとに出現頻度を集計
\pagebreak
することを考え，各頻度を\tab{kankei}のように，それぞれ
$a$，$b$，$c$，$d$で表すことにする．ここで，$a + b + c
+ d = n$ である．

以上の準備のもと，次の対数尤度比を考える：
{\allowdisplaybreaks
\begin{align}
LLR_0(o_k,u_j) & = \log\frac{Pr(\mathcal{V}_{jk}; H_{dep})}{Pr(\mathcal{V}_{jk}; H_{indep})}
	\nonumber \\
 & = \sum_{i=1}^{n}\log\frac{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{\mathit{dep}})}{Pr(W_j=w^{i}_j,T_k=t^{i}_k;H_{\mathit{indep}})}
	\label{eq:llr0}
\end{align}
}
ここで，$H_\mathit{dep}$および$H_\mathit{indep}$は，以下のような，確
率変数に関する仮説である．
\begin{itemize}
 \item $H_\mathit{dep}$: 確率変数$W_j$と$T_k$とは互いに依存している．
 \item $H_\mathit{indep}$: 確率変数$W_j$と$T_k$とは互いに独立である．
\end{itemize}
\eq{llr0}において，$H_\mathit{indep}$の下では，
\[
Pr(W_j=w^i_j, T_k=t^i_k; H_\mathit{indep}) = Pr(W_j=w^i_j)Pr(T_k=t^i_k)
\]
が成り立つ．また，各種の確率は，
\begin{align*}
Pr(W_j=1, T_k=1; H_\mathit{dep}) & = \frac{a}{n} ,\quad 
	Pr(W_j=1, T_k=0; H_\mathit{dep}) =  \frac{b}{n} \\
Pr(W_j=0, T_k=1; H_\mathit{dep}) & = \frac{c}{n} ,\quad 
	Pr(W_j=0, T_k=0; H_{dep}) =  \frac{d}{n} \\
Pr(W_j=1) & = \frac{a+b}{n} , \quad
	Pr(W_j=0) =  \frac{c+d}{n} \\
Pr(T_k=1) & = \frac{a+c}{n} ,\quad 
	Pr(T_k=0) =  \frac{b+d}{n}
\end{align*}
で推定する．

この尺度は，2 つの確率変数$W_j$と$T_k$とが依存している
という条件，および，独立であるという条件の下で，データ
が観測される確率の比の対数を表しており，$W_j$と$T_k$の
依存性が高い程，大きな値をとる．
もし，ある評価視点がどの評価対象にも共通するような一般
的な視点であれば，評価視点トークンは，どの評価対象のレ
ビュー中にも同じように出現すると考えられる．すなわち，
$W_j$と$T_k$とは互いに独立であると考えられ，上記尺度は
小さな値をとる．一方で，ある評価視点が特定の評価対象に
のみ特徴的な出現を示すようであれば，$W_j$と$T_k$とは依
存しており，上記尺度は大きな値をとる．つまり，この尺度
をスコア関数とすることで，特定の評価対象に特徴的な評価
視点に対して大きなスコアを割り振ることができる．

ただし，上記尺度は，ある評価視点が特定の評価対象に対し
て特徴的に言及される場合と特徴的に言及されない場合を区
別できない．そのため，どちらの状況であっても大きな値を
とってしまう．そこで，言及される場合とされない場合を区
別できるよう，実際には以下のように補正して利用する．
\pagebreak
\begin{equation}
LLR(o_k,u_j) = sign(ad - bc)LLR_{0}(o_k,u_j)
\label{eq:finalrank}
\end{equation}
ただし，
\begin{equation}
sign(z) = \begin{cases}
  +1 & z > 0 \\
  -1 & \mathit{otherwise}\\
  \end{cases}
\end{equation}
である．



\section{異表記問題への対応}
\label{sec:cl}


\subsection{異表記問題}
\label{sec:clustering_summary}

レビューではユーザの数だけ書き手が存在しており，同じ概
念が述べられていたとしても，ユーザによって異なる単語が
使われることがしばしばある．
例えば，価格について何かを述べたいときに，あるユーザは
「価格」と表記したが，別ユーザは「料金」や「値段」等，
別の単語を使うことがある．
また，レビューは，評価対象という自明な文脈をもつ文書で
あるため，同じ評価対象のもとでユーザが共有しているであ
ろう情報がしばしば省略表記される傾向があり，
例えば，最寄り駅の「東京駅」を単に「駅」と表記するユー
ザ等，その表記はユーザによってさまざまに変化する．

一般的に，このような異表記の問題や表記揺れの問題（以下，
  単に異表記の問題と呼ぶ）はよく知られているが，評価視
点のランキング課題に対しても悪影響を与えていると考えら
れる．前節で述べた提案尺度では評価視点の出現頻度の情報
を用いているが，異表記が考えられる評価視点については，
異表記の数だけ頻度が分散してカウントされてしまい，その
結果，それらの評価を誤ってしまう．

以下では，この異表記問題の影響を回避する手法について述べ
る．本手法は，評価視点をクラスタリングすることによって，
同じ意味あるいは類似した意味の評価視点をクラスタにまと
め上げ，クラスタ情報に基いてランキングを補正する．手法
は，クラスタ情報をランキングに反映させる方法によって，
事前処理法と事後処理法の 2 つに分かれる
（\fig{clustering}）．
以下ではまず，2 つの手法について述べ，その後，各手法の
中で用いるクラスタリング手法について述べる．



\subsection{事前処理法と事後処理法}

事前処理法（\fig{clustering}の(b)）では，ランキングの前
に評価視点のクラスタリングを実施し，同一の意味あるいは
類似した意味の評価視点をクラスタにまとめ上げる．
そして，同じクラスタとなる視点群をひとつの評価視点であ
るように扱い出現頻度を数えることで対数尤度比を計算し，
ランキングをおこなう．

\begin{figure}[t]
 \begin{center}
 \includegraphics{20-1ia960f1.eps}
 \end{center}
 \caption{ランキングの補正手法の概略}
 \label{fig:clustering}
\end{figure}

具体的には，\sec{llr}で導入した\eq{w}の評価視点トークン
に関する確率変数$W_j$を次の\eq{w2}のように再定義してス
コア関数を計算することで，クラスタ情報をランキングに反
映させる．ただし，下記の式中の$v$と$u_j$は\eq{w}と同様，
評価視点トークンと評価視点をそれぞれ意味する．
\begin{equation}
W_j=\begin{cases}
1 & \text{$v$ は評価視点 $u_j$ のレビュー内での出現である}\\
1 & \text{$v$ は $u_j$ と同じクラスタに属する評価視点のレビュー内での出現である}\\
0 & \mathit{otherwise}
\end{cases}
\label{eq:w2}
\end{equation}


事後処理法（\fig{clustering}の(c)）では，ランキングを先
に行い，その後，クラスタリングによって得られたクラスタ
情報に従ってランキング結果を補正する．
具体的には，ある評価視点$u_j$がクラスタ$C(u_j)$に所属す
る場合を考えると，ランキングに使用するスコア関数
\eq{finalrank}で得られた値に対して，次の
\eq{finalrank2}を計算する．
\begin{equation}
\mathit{LLR}\_\mathit{cluster}(o_k, u_j) = \frac{1}{|C(u_j)|} \sum_{ u_l \in C(u_j)} \mathit{LLR}(o_k,u_l)
\label{eq:finalrank2}
\end{equation}
\eq{finalrank2}が示すように，事後処理法では，元の重要度
をクラスタ内で平均化した値を重要度として採用する．


\subsection{評価視点クラスタリング}
\label{sec:clustering_mothod}

次に，上記の補正手法で用いるクラスタリングについて述べ
る．クラスタリングのアルゴリズムは，以下に示す標準的な
アルゴリズム\cite{clustering}を採用する．ただし，アルゴ
リズム内で利用される評価視点間の類似度尺度については，
以下で述べるシソーラスに基づく類似度において，ユーザレ
ビューの特性を踏まえて拡張を施した尺度を新たに採用する．
なお，クラスタリングの議論をおこなう場合，一般には距離
や非類似度を定義することが多いが，説明の便宜上，ここで
は類似度を定義している点に注意されたい．

以下，クラスタリング・アルゴリズムについて概要を述べた
後，評価視点間の類似度尺度について述べる．

クラスタリングには，以下に示す 3 つのアルゴリズムを採用
した．いずれも，凝集型の手法であり，もっともクラスタ間
類似度の高い 2 つのクラスタをボトムアップに再帰的に併合
しながらクラスタリングを進める点が共通しているが，クラ
スタ間類似度の定義が異なる．

単連結法(\textit{single linkage method})は，クラスタ$C_i$
と$C_j$の要素間の類似度$\mathit{wsim}(k, s)$の中で，最大の類似度
をクラスタ間の類似度$\mathit{csim}(C_i,C_j)$とする：
\begin{equation}
\label{eq:single}
\mathit{csim}(C_i,C_j) = \max_{k \in C_i, s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

完全連結法(\textit{complete linkage method})は，クラ
スタ$C_i$と$C_j$の要素間の類似度の中で，最小の類似度
をクラスタ間の類似度とする：
\begin{equation}
\label{eq:complete}
\mathit{csim}(C_i,C_j) = \min_{k \in C_i, s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

また，群平均法(\textit{group average method})は，クラスタ
$C_i$と$C_j$の各要素間の平均類似度をクラスタ間の類似度
とする：
\begin{equation}
\label{eq:group}
\mathit{csim}(C_i,C_j) = \frac{1}{|C_i||C_j|}\sum_{k \in C_i}\sum_{s \in C_j}\mathit{wsim}(k, s)
\end{equation} 

次に，評価視点間の類似度$\mathit{wsim}(k, s)$ について説明する．
評価視点間の類似度には，以下で述べる 3 種類の類似度尺度
を併用した．なお，どの類似度も0以上1以下の値をとり，同
じ評価視点が入力となった場合に対して最大値$1$を返す
 ($\mathit{wsim}(k, k) = 1$)．



\subsubsection{シソーラスに基づく類似度}

2 つの単語$k$と$s$の類似度を求める手法として，シソーラ
スに基づく類似度がある．これは次式のように定義される
\cite{nagao}：
\begin{equation}
\label{eq:thesaurus}
\mathit{wsim}'_\mathit{the}(k, s)=
 \begin{cases}
  \frac{2 × d_\mathit{share}(k, s)}{d(k)+d(s)} & (k,s \in T) \\
  0  & (\mathit{otherwise}) \\
\end{cases}
\end{equation}
ここで，$d(k)$と$d(s)$は階層構造をなすシソーラス中での
当該単語の位置する深さをあらわし，$d_\mathit{share}(k,s)$は階
層構造における単語$k$と単語$s$の共通祖先ノードが位置す
る深さの最大値をあらわす．また，$T$はシソーラスに含まれ
る見出し語の集合である．

一般に，シソーラスは人手により構築されていることから，
シソーラスの見出し語に含まれる単語間の類似度を測るには
この尺度は有用と言える．
しかし，今回対象としている評価視点には「施設管理」といっ
たシソーラスには登録されにくい複合語なども含まれている
ため，上記尺度そのままでは多数の評価視点間の類似度が
$0$となってしまう問題がある．
そこで，本論文では類似度が求められる評価視点ペアの被覆
率を上げるために，以下のように拡張した類似度を採用する：
\begin{equation}
\label{eq:thesaurus_k}
wsim_{the}(k, s)=
 \begin{cases}
  \mathit{wsim}'_\mathit{the}(k, s) & (k, s \in T) \\
  \frac{1}{|k|} \sum_{i=1}^{|k|} \mathit{wsim}'_\mathit{the}(k_i, s) & (k \notin T, s \in T) \\
  \frac{1}{|s|} \sum_{j=1}^{|s|} \mathit{wsim}'_\mathit{the}(k, s_j) & (k \in T, s \notin T) \\
  \frac{1}{|k||s|} \sum_{i=1}^{|k|}\sum_{j=1}^{|s|} \mathit{wsim}'_\mathit{the}(k_i, s_j) & (k \notin T, s \notin T)
 \end{cases}
\end{equation}
ここで， 形態素解析によって各評価視点を形態素に分割した
ものをそれぞれ$k_1,\ldots,k_{|k|}$，$s_1,\ldots,s_{|s|}$で表
しており，
拡張版では，従来の式で類似度が求められない場合は対象を
分割して類似度を求めていることがわかる．
例えば，引数$k$が「施設管理」である例を考える．ここで，
「施設管理」はシソーラスに含まれておらず，またもう一方
の引数$s$はシソーラスに含まれる何らかの単語であるとする．
この場合の類似度計算は\eq{thesaurus_k}の 2 行目によって
おこなわれ，「施設管理」を「施設」と「管理」に分割させ
た後，それぞれの形態素に対して\eq{thesaurus}の
$\mathit{wsim}'_\mathit{the}()$へ問合せを実行し，個別に$s$との類似度を
求める．そして，問合せ結果の平均を「施設管理」と$s$との
間の類似度であるとする．
\eq{thesaurus_k}では，分割操作によって，シソーラスのエ
ントリとの照合率が改善され，類似度が求められない事例数
を削減させる効果が期待できる．


\subsubsection{表層文字列に基づく類似度}

次に，上記のシソーラスに基づく類似度尺度を補完するため
に，評価視点の表層文字列に基づく類似度を考える．
本研究では，最長共通部分文字列 \textit{LCS} (\textit{longest common subsequence}) 
\cite{hirschberg}に基づく以下の類似度尺
度を採用する：
\begin{equation}
\mathit{wsim}_\mathit{lcs}(k, s) = \frac{2 \times \mathit{LCS}(k, s)}{|k|+|s|}
\label{eq:lcs}
\end{equation}
ここで，$\mathit{LCS}(k,s)$は$k$と$s$の最長共通部分文字列の長さ
であり，上式は，その値を$k$，$s$それぞれの文字列の長さ
を基に正規化している．
表層文字列に基づく類似度は，「焼きたてパン」と「焼き立
  てパン」のような部分的な漢字表記とひらがな表記の違い
や，「バイキング」と「朝食バイキング」のような文字数の
比較的多いカタカナ列からなる評価視点の類似性を測る際に
特に効果的であると期待できる．
例えば，6 文字で構成される「焼きたてパン」と「焼き立て
  パン」がそれぞれ$k$と$s$である例を考える．両者の違い
は，ひらがな「た」と漢字「立」の 1 文字だけであり，その
他は各文字の順序等すべて同じである．この場合，
$\mathit{LCS}(k,s)=5$で，$\mathit{wsim}_\mathit{lcs}(k,s)=10/12$となり，高い類似
度が得られる．

LCS の代わりに，不連続になる部分文字列の影響を考慮した文
字列カーネル\cite{lodhi}を用いた予備実験も行ったが，
LCSとほぼ同様の実験結果を得た．そのため，
\sec{experiment}の実験ではLCSを用いた結果のみ報告する．


\subsubsection{文脈情報に基づく類似度}

類似度を補完するもう一つの方法として，評価視点が現れる
文脈の情報に基づく類似度を考える．これは一般に，似た意
味をもつ単語は似た文脈に現れやすいと言われており，この
性質に従って，単語が現れる周辺文脈を基に類似度を求める
手法である．
本研究では，代表的な手法の一つである，次式のコサイン類
似度を採用する\cite{lin}：
\begin{equation}
\label{eq:context}
\mathit{wsim}_\mathit{cos}(k, s) = \frac{\boldsymbol{v}_{k} \cdot \boldsymbol{v}_{s}}{||\boldsymbol{v}_{k}|| ||\boldsymbol{v}_{s}||}
\end{equation}
ここで，$\boldsymbol{v}_k$と$\boldsymbol{v}_s$は，それぞれ$k$と$s$の文脈に現れる
単語から構成される単語頻度ベクトルである．
また，ここでは，当該の評価視点に対応するすべての評価視
点トークンから文脈情報を獲得し，それらの情報からひとつ
のベクトルを作成する．
文脈情報に基づく類似度は，「東京駅」と「駅」や「最寄り
  駅」のような，文脈に依存した評価視点の類似性を測る際
に特に効果的であると期待できる．


\subsubsection{各種類似度の統合}

ここまで述べたように各類似度尺度は，それぞれ異なる情報
に基いており，互いに相補関係にあると言える．そこで，ク
ラスタリングの際は，各類似度尺度を単独で用いるのではな
く，次式のように統合して用いる事とする：
\begin{equation}
\mathit{wsim}(k, s) = \max \{\mathit{wsim}_\mathit{the}(k, s),\ \mathit{wsim}_\mathit{lcs}(k, s),\ \mathit{wsim}_\mathit{cos}(k, s)\}
\label{eq:sim_mix}
\end{equation}


\section{評価実験}
\label{sec:experiment}

\subsection{実験条件}

実験には，代表的な宿泊施設予約サイトのひとつである楽天
トラベル\footnote{\url{http://travel.rakuten.co.jp/}}
に書き込まれた
\pagebreak
レビューを用いた．楽天トラベルに登録され
ている宿泊施設のうち，都内近辺に立地している11施設を対
象とし，各施設ごとに100レビューを実験に使用した．
また，上記レビュー群から人手で評価視点を抽出して実験の
入力データとして用いることにし，さらにそこから特徴的評
価視点を人手で選び出し，評価用データとして用いた．この
作業によって得られた評価視点は施設あたり平均101個であり，
得られた特徴的評価視点は施設あたり平均12.1個である．
データの信頼性を検証するために 2 名の作業者（$A$と$B$）
によってデータ作成をおこない，特徴的評価視点と判定する
際の一致度を以下の計算式で求めた．
\begin{equation}
 \mathit{agreement}(X,Y) = 
   \frac{\text{$X$ と $Y$ が共に特徴的であると判定した評価視点の数}}{\text{$X$ が特徴的であると判定した評価視点の数}}
\end{equation}
判定の一致度は，$\mathit{agreement}(A,B)=0.72$と
$\mathit{agreement}(B,A)=0.77$となり，この結果から，作業者間の判
定はある程度一致していることが確認できる．
また，事例分析から，以下のような事例において判定が一致
しない傾向があることが確認できた．
\begin{itemize}
\item 
評価視点に異表記がある場合：作業者が共に特徴的であると
判定した評価視点に異表記がある場合，作業者による異表記
の認定不足から，一部の評価視点が特徴的であると判定され
ない．
\item 
連続量を伴う評価視点の場合：例えば「駅前で良かった」や
「駅に近く良かった」のような最寄り駅からの近さについて
の言及があった場合，どの程度の距離であれば特徴的な評価
視点であると判定するかについては作業者の主観に拠る部分
が多い．
\end{itemize}
なお，一致度の測定に$\kappa$値を用いることも考えられる．
しかし，次の理由から今回は実態を把握するのに適していな
いと考え，$\kappa$値の採用を見送った．
すなわち，本実験で用いたデータは，特徴的でない評価視点
が全体の 9 割程度を占めているが，$\kappa$値ではこれらに
対して作業者が共に特徴的でないと判定した場合も一致度に
反映されるためである．

シソーラスに基づく類似度を計算するためのシソーラスには，
分類語彙表\cite{bunrui}を用いた．
また，文脈情報に基づく類似度では，予備実験の結果から経
験的に窓枠を 5 と定め，対象の前後 5 単語を文脈情報として
利用した．ただし，単語情報はMeCabによって文脈を形態素解
析することで獲得し，その際，品詞が「助詞」，「助動詞」，
「記号」である場合は窓枠のカウント対象から除外した．

実験において，スコア関数として対数尤度比を実際に計算す
る際は，ラプラススムージング\cite{map}を適用した．


スコア関数のベースラインとして，\textit{TF} および \textit{TF-IDF}\cite{map}に基づく関数を用いた．
一般に，\textit{TF}, \textit{TF-IDF}は，文書ごとに単語へ重み付
けする際に利用される．しかし，ここでは文書ごとの差異で
はなく施設ごとの差異に注目したいため，次式のように，あ
る施設に対する全レビューをひとつの文書として扱う．


\subsubsection{TF法}

\vspace{-1\abovedisplayskip}
\begin{equation}
\mathit{TF}(o_k, u_j) = \text{施設 $o_k$ の全レビューにおける評価視点}
u_j の出現頻度
\label{eq:tf}
\end{equation}
これは，言い換えると，\tab{kankei} の$a$のみをスコア関
数として考慮することに等しい．


\subsubsection{TF-IDF法}

\vspace{-1\abovedisplayskip}
\begin{equation}
\mathit{TF-IDF}(o_k, u_j) = \mathit{TF}(o_k,u_j) × \log ( \frac{|D|}{DF(u_j)} + 1 ) 
\label{eq:tfidf}
\end{equation}
$|D|$は一般的な定義では文書数であるが，上記で述べたよう
に今回は施設数に等しい．$DF(u_j)$はレビューに評価視点
$u_j$が現れた施設数である．

評価尺度には，情報検索のランキング課題の評価によく利用
される \textit{Mean Average Precision} (\textit{MAP}) を用いた．
\textit{MAP} は次式で定義される\cite{map}．
\begin{equation}
 \mathit{MAP} = \frac{1}{|\mathcal{O}|}\sum_{o_k \in \mathcal{O}}\frac{1}{|\mathcal{A}_k|}\sum_{\hat{u}_j \in \mathcal{A}_k}
	\mathit{Precision}(\mathit{rank}(o_k, \hat{u}_j))
\label{eq:map}
\end{equation}
ここで，$\mathcal{O}$は評価対象の集合であり，
$\mathcal{A}_k$は評価対象$o_k$のレビューから人手によっ
て得られた特徴的評価視点の集合である．$\mathit{rank}(o_k, \hat{u}_j)$
は$o_k$中のある特徴的評価視点$\hat{u}_j$が，何らかのランキン
グ手法によって与えられた順位を示しており，
$\mathit{Precision}(\mathit{rank}(o_k, \hat{u}_j))$は，その順位までの出力結果に
おける適合率である．
つまり，ここでは，ひとつの評価対象が情報検索におけるひ
とつの検索課題に相当するものと見なされて評価される．



\subsection{実験結果}
\label{sec:experiment1}

\begin{table}[b]
 \caption{実験結果（異表記を考慮しない場合）}
 \label{tab:ranking_result}
\input{01table02.txt}
\end{table}

まず，異表記問題への対応を考慮しない場合の結果について
述べる．この結果を\tab{ranking_result}に示す．
\tab{ranking_result}から提案手法 \textit{LLR} がベースライン手法
    （\textit{TF}および\textit{TF-IDF}）よりも性能が向上するこ
    とが確認できた．
\textit{TF} では，\eq{tf}からもわかるように，比較すべき他施設の
評価視点に関する情報を全く考慮していない．そのため，もっとも
低い性能になったと考えられる．
次に，\textit{TF-IDF}では，$\mathit{DF}(u_j)$によって他施設の情
報をある程度考慮することができるが，その情報は出現の有
無のみである．
一方の \textit{LLR} では，評価視点の他施設での出現頻度に関する情
報も反映できており，この差が\tab{ranking_result}の結果
に繋がったと考えられる．

\tab{ranking_result}の結果に対して，「手法間の
\textit{Average Precision} に差がない」という帰無仮説を立て，
対応のある両側$t$検定を実施した．その結果，\textit{LLR} 法と
\textit{TF} 法，および \textit{LLR} 法と \textit{TF-IDF} 法のどちらとの間
でも，有意水準$1\%$で統計的有意差が確認できた．

\begin{table}[b]
 \caption{評価視点ランキングの結果例（異表記を考慮しない場合）}
 \label{tab:ranking_top}
\input{01table03.txt}
\end{table}

\tab{ranking_top}に，実験データ中の 3 つの宿泊施設におけ
るランキング結果の例を示す．下線にボールド体の評価視点
が正しい特徴的評価視点をあらわす．また，括弧内は出現頻
度（\textit{TF}値）である．
評価視点の右に``＊''印があるものについては，その評価視
点が含まれていた文脈（の一部）を例として
\tab{ranking_top_example}に示す．
\tab{ranking_top}の事例の観察から，
\textit{TF} では「部屋」や「立地」，「対応」など一般的で出現頻
度が高くなりやすい語が上位を占めており，それらの一部が
誤りとなっていた．その一方で，\textit{LLR} では「武道館」などの
出現頻度は決して高くないが対象施設に固有な評価視点の順
位がベースラインよりも上がっており，提案手法では他施設
との比較がうまく機能していたことがわかる．
しかし，\tab{ranking_top}の観察によると，「パン」と「朝
  食のパン」のように，宿泊者から見れば同一の事物と考え
られるものが異なる順位として現れており，また，
\tab{ranking_top}から外れた下位の評価視点に目を向けると，
12位に「クロワッサン」，50位には「焼き立てパン」などが
含まれており，異表記が生じていることも同時に確認できた．

\begin{table}[t]
 \caption{評価視点を含む文脈の例}
 \label{tab:ranking_top_example}
\input{01table04.txt}
\end{table}

そこで次に，\sec{cl}で述べた補正手法によって異表記問題
に対応した場合の結果について述べる．
3 つのランキング手法（\textit{TF}，\textit{TF-IDF}，および，
\textit{LLR}）に対して補正手法を適用した実験をおこなったが，
\textit{TF}，\textit{TF-IDF} が \textit{LLR} を上回ることがなかったため，
以下では，\textit{LLR} に対して補正手法を適用する場合の結果を中
心に述べる．

補正手法を適用した結果を\fig{ranking_result_be}と
\fig{ranking_result_af}に示す．\fig{ranking_result_be}
が事前処理法の結果であり，\fig{ranking_result_af}が事後
処理法の結果である．
各図において，縦軸は \textit{MAP} を示し，横軸は以下で述べる類似
度への閾値を示している．凝集型クラスタリングでは，デン
ドログラムと呼ばれるクラスタをノードとする木を生成する
が，各クラスタにはその子ノードの情報から計算される類似
度が付随している．本実験では，この類似度に閾値を設け，
類似度が閾値以下になったときに併合を停止させてクラスタ
リング結果を得ることにし，閾値を変化させながら，それぞ
れの \textit{MAP} を計測した．
今回の場合，類似度の値が$1.0$ となる事例が存在していな
かったため，横軸左端の結果は，クラスタリングを行わない
場合の結果（\tab{ranking_result}の$0.574$）と同一となっ
ている．

\begin{figure}[t]
 \begin{center}
 \includegraphics{20-1ia960f2.eps}
 \end{center}
 \caption{実験結果（異表記を考慮する場合：事前処理法）}
 \label{fig:ranking_result_be}
\end{figure}
\begin{figure}[t]
 \begin{center}
 \includegraphics{20-1ia960f3.eps}
 \end{center}
 \caption{実験結果（異表記を考慮する場合：事後処理法）}
 \label{fig:ranking_result_af}
\end{figure}

\fig{ranking_result_be}，\fig{ranking_result_af}共に，
全体的な傾向として，類似度の閾値を$1.0$から下げるに従い
\textit{MAP}が上昇していくことから，クラスタリングを施すことに
一定の効果があることが確認できるが，ある類似度を契機に
下降に転ずることがわかる．
このような結果は次の理由によると考えられる．すなわち，
もともと全ての評価視点において異表記が存在するわけでは
ないため，クラスタリングすべき評価視点も部分的となる．
今回のようにボトムアップにクラスタリングを進めた時，あ
る点でクラスタリングすべき評価視点のまとめ上げが終了し，
この時点が最適なクラスタ数となり最良の \textit{MAP} 値を得る．し
かし，それ以降は本来クラスタリングすべき評価視点に対す
るまとめ上げではなくなるため本来の目的とは逆に過併合が
生じることになり，性能が悪化すると考えられる．

\textit{MAP} 値が下降するタイミングがクラスタリング手法によって
大幅に異なるが，この違いはクラスタリング手法に起因して
必然的に生じる結果であると考えられる．すなわち，単連結
法（\eq{single}）は類似度の最大値に基いて併合を進めるた
め，ノードに付随する類似度が 3 手法の中で最も速く大きく
なり，\textit{MAP}値も最も速く下降していく．完全連結法
（\eq{complete}）は，逆に，類似度の最小値に基いているた
め，\textit{MAP} 値の下降が最も遅い．また，類似度の平均値に基づ
く群平均法（\eq{group}）は，上記両者の中間に位置してい
ると言える．


\begin{table}[b]
\caption{評価視点ランキングの結果例（異表記を考慮した場合）}
\label{tab:ranking_top2}
\input{01table05.txt}
\end{table}

クラスタリングを施した場合のランキング結果の例を
\tab{ranking_top2}に示す．例示している宿泊施設は
\tab{ranking_top}と同じであり，\tab{ranking_top2}におい
て，下線にボールド体の評価視点が正しい特徴的評価視点を
あらわす．また，各表の右列がクラスタ情報である．
表の観察から，クラスタリングによって異表記がまとめ上げ
られていることが確認できる．また，
宿泊施設Aのように，クラスタリング前は「パン」，「朝食の
  パン」という情報しかわからなかった状態において，「ク
  ロワッサン」のように，詳細な情報を補う効果も事例によっ
て期待できることがわかった．
同様の観点で\tab{ranking_top2}以外の事例を観察してみる
と，クラスタリング前は「野菜」という評価視点のみが上位
にランクされていたが，クラスタリングによって野菜が「春
  野菜」であることが補えたり，クラスタリング前は「壁」
のみであったものが，クラスタリングによって「防音」の壁
であることが補える例が存在していた．


\begin{figure}[b]
 \begin{center}
 \includegraphics{20-1ia960f4.eps}
 \end{center}
 \caption{類似度尺度ごとの性能}
 \label{fig:ranking_sim}
\end{figure}
\begin{table}[b]
 \caption{クラスタリングによって構成された評価視点の異表記クラスタの例}
 \label{tab:cluster}
\input{01table06.txt}
\end{table}

最後に，3 種類の類似度を統合した効果を確認する．
\fig{ranking_sim}に 3 種類の類似度尺度を単独で用いた場合
の結果および類似度を統合した場合の結果を示す．類似度尺
度以外の実験設定は先程の結果で最良の$MAP$値となった設定，
すなわち，群平均法でクラスタリングし，事後処理法でラン
キングを補正する手法を適用した．
また，
クラスタリングによって構成されたクラスタの例を
\tab{cluster}に示す．表の各行において，そのクラスタを構
成した類似度尺度に「◯」印を付けている．また，2 つ以上
の類似度尺度で同じクラスタが構成されていた場合は類似度
の値が最も高い類似度尺度に「◯」印を付けている．
\fig{ranking_sim}から，どの類似度尺度も統合結果の最良値
を上回ることはなく，このことから，類似度を統合すること
の効果が確認できた．ただし，
今回使用したデータに対して人手でクラスタリングを施した
結果を用いてランキングを補正したところ，\textit{MAP} 値は
$0.713$まで向上した．つまり，クラスタリング手法および統
合手法に対する改善の余地が残されていることが示唆される．



\section{おわりに}
\label{sec:owarini}

本論文では，レビュー集合から得られる多数の評価視点を重
要度に従ってランキングする課題を考え，対数尤度比の考え
方に基づく，意見集約のための重要度を提案した．
また，クラスタリングをおこなう事で，評価視点の異表記の
問題に対処する手法を提案し，それらの有効性を評価実験を
通して検証した．その結果，単純な出現頻度に基づく \textit{TF} 法
や，\textit{TF} 法に出現文書数の情報を加えた\textit{TF-IDF}法よ
りも，対数尤度比に基づく提案手法を用いた方がランキング
性能が向上すること，また，クラスタリングによって評価視
点の異表記の問題を改善することができることを確認した．


今後の課題として，以下の項目が挙げられる．
まず，本論文では意見集約のための重要度として，対数尤度
比の考え方に従った尺度についてその有効性を検証した．し
かし，単語の重み付け尺度は本論文で議論した 3 つの尺度以
外にも従来から提案されているため，それらの尺度についても，
今後，意見集約に適した尺度であるかどうか検討していきた
い．

本論文の冒頭で紹介したHuらの研究\cite{hu}のように，一般
に，レビューから抽出された評価視点には，その視点に対す
るユーザの評価（肯定評価か否定評価）が付随しているが，
現在の提案手法では評価情報は無視している．そこで，評価
視点への評価情報を重要度に反映させる手法を検討すること
が考えられる．
例えば，評価対象間における肯定評価と否定評価の分布の異
なり方に応じて重要度を修正することなどが考えられる．

\sec{experiment}の評価実験では，提案した補正手法によっ
て評価視点の異表記の問題に対処することでランキングの性
能が改善できることを確認した．しかし，評価視点の異表記
を発見する手法に関しては，今後，他手法も含めたさらに詳
細な検討が必要である．
他手法としては，例えば，分類語彙表のかわりに日本語
WordNet\cite{isahara2008a}を用いた手法や，また，シソー
ラス等の既存の言語知識に頼らない教師あり学習に基づく類
義語検出法\cite{mauge2012a}の検討などが考えられる．
また，異表記とは逆に，多義の評価視点に対する対応も今後
必要であると考えられる．
例えば，評価実験の際に使用した宿泊施設のレビューの中に
は，宿泊施設への送迎に利用される乗り物としての「バス (bus)」と，
部屋にある入浴設備としての「バス (bath)」
があるが，現在これらは「送迎バス」というように明示的な
修飾を伴わない限り，区別して扱われていない．今後は異表
記と同様に多義語への対応についても検討したい．



\acknowledgment

本研究の一部は科学研究費補助金（課題番号 23300053）の
もとで実施された．
また，実験にあたり，楽天トラベル株式会社から施設レビュー
データを提供して頂いた．ここに記して感謝の意を表しま
す．



\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Hastie, Tibshirani, \BBA\ Friedman}{Hastie
  et~al.}{2001}]{clustering}
Hastie, T., Tibshirani, R., \BBA\ Friedman, J. \BBOP 2001\BBCP.
\newblock {\Bem The Elements of Statistical Learning}.
\newblock Springer.

\bibitem[\protect\BCAY{Hirschberg}{Hirschberg}{1977}]{hirschberg}
Hirschberg, D.~S. \BBOP 1977\BBCP.
\newblock \BBOQ Algorithms for the longest common subsequence problem.\BBCQ\
\newblock {\Bem Journal of the Assoclauon for Computing Machinery}, {\Bbf 24}
  (4), \mbox{\BPGS\ 664--675}.

\bibitem[\protect\BCAY{Hu \BBA\ Liu}{Hu \BBA\ Liu}{2004}]{hu}
Hu, M.\BBACOMMA\ \BBA\ Liu, B. \BBOP 2004\BBCP.
\newblock \BBOQ Mining Opinion Features in Customer Reviews.\BBCQ\
\newblock In {\Bem Proceedings of the 19th National Conference on Articial
  Intelligence}, \mbox{\BPGS\ 755--760}.

\bibitem[\protect\BCAY{Isahara, Bond, Uchimoto, Utiyama, \BBA\ Kanzaki}{Isahara
  et~al.}{2008}]{isahara2008a}
Isahara, H., Bond, F., Uchimoto, K., Utiyama, M., \BBA\ Kanzaki, K. \BBOP
  2008\BBCP.
\newblock \BBOQ Development of Japanese WordNet.\BBCQ\
\newblock In {\Bem Proceedings of 6th International Conference on Language
  Resources and Evaluation}, \mbox{\BPGS\ 2420--2423}.

\bibitem[\protect\BCAY{Jakob \BBA\ Gurevych}{Jakob \BBA\
  Gurevych}{2010}]{jakob}
Jakob, N.\BBACOMMA\ \BBA\ Gurevych, I. \BBOP 2010\BBCP.
\newblock \BBOQ Extracting opinion targets in a single- and cross-domain
  setting with conditional random fields.\BBCQ\
\newblock In {\Bem Proceedings of the 2010 Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 1035--1045}.

\bibitem[\protect\BCAY{小林}{小林}{2007}]{kobayashi2}
小林のぞみ \BBOP 2007\BBCP.
\newblock {\Bem Opinion mining from Web Documents:Extraction and
  Structurization}.
\newblock Ph.D.\ thesis, 奈良先端科学技術大学院大学情報科学研究科.

\bibitem[\protect\BCAY{小林\JBA 乾\JBA 松本}{小林 \Jetal }{2006}]{siten}
小林のぞみ\JBA 乾健太郎\JBA 松本裕治 \BBOP 2006\BBCP.
\newblock 意見情報の抽出/構造化のタスク仕様に関する考察.\
\newblock \Jem{情報処理学会研究報告（NL171-18）}, \mbox{\BPGS\ 111--118}.

\bibitem[\protect\BCAY{小林\JBA 乾\JBA 松本\JBA 立石\JBA 福島}{小林 \Jetal
  }{2005}]{kobayashi}
小林のぞみ\JBA 乾健太郎\JBA 松本裕治\JBA 立石健二\JBA 福島俊一 \BBOP 2005\BBCP.
\newblock 意見抽出のための評価表現の収集.\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (2), \mbox{\BPGS\ 203--222}.

\bibitem[\protect\BCAY{国立国語研究所}{国立国語研究所}{2004}]{bunrui}
国立国語研究所 \BBOP 2004\BBCP.
\newblock \Jem{分類語彙表—増補改訂版—}.
\newblock 大日本図書.

\bibitem[\protect\BCAY{Lin}{Lin}{1998}]{lin}
Lin, D. \BBOP 1998\BBCP.
\newblock \BBOQ Automatic retrieval and clustering of similar words.\BBCQ\
\newblock In {\Bem Proceeding of the {COLING}-{ACL}}, \mbox{\BPGS\ 768--774}.

\bibitem[\protect\BCAY{Liu, Hu, \BBA\ Cheng}{Liu et~al.}{2005}]{liu}
Liu, B., Hu, M., \BBA\ Cheng, J. \BBOP 2005\BBCP.
\newblock \BBOQ Opinion Observer: Analyzing and Comparing Opinions on the
  Web.\BBCQ\
\newblock In {\Bem Proceedings of the 14th International World Wide Web
  Conference}, \mbox{\BPGS\ 342--351}.

\bibitem[\protect\BCAY{Lodhi, Saunders, Shawe-Taylor, Cristianini, \BBA\
  Watkins}{Lodhi et~al.}{2002}]{lodhi}
Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N., \BBA\ Watkins, C.
  \BBOP 2002\BBCP.
\newblock \BBOQ Text Classification using String Kernels.\BBCQ\
\newblock {\Bem The Journal of Machine Learning Research}, {\Bbf 2},
  \mbox{\BPGS\ 419--444}.

\bibitem[\protect\BCAY{Manning, Raghavan, \BBA\ Schutze}{Manning
  et~al.}{2008}]{map}
Manning, C.~D., Raghavan, P., \BBA\ Schutze, H. \BBOP 2008\BBCP.
\newblock {\Bem Introduction to Information Retrieval}.
\newblock Cambridge University Press.

\bibitem[\protect\BCAY{Mauge, Rohanimanesh, \BBA\ Ruvini}{Mauge
  et~al.}{2012}]{mauge2012a}
Mauge, K., Rohanimanesh, K., \BBA\ Ruvini, J.-D. \BBOP 2012\BBCP.
\newblock \BBOQ Structuring E-Commerce Inventory.\BBCQ\
\newblock In {\Bem Proceedings of the 50th Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 805--814}.

\bibitem[\protect\BCAY{Mullen \BBA\ Collier}{Mullen \BBA\
  Collier}{2004}]{mullen}
Mullen, T.\BBACOMMA\ \BBA\ Collier, N. \BBOP 2004\BBCP.
\newblock \BBOQ Sentiment Analysis using Support Vector Machines with Diverse
  Information Sources.\BBCQ\
\newblock In {\Bem Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}.

\bibitem[\protect\BCAY{長尾}{長尾}{1996}]{nagao}
長尾真（編） \BBOP 1996\BBCP.
\newblock \Jem{自然言語処理}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{Nigam, McCallum, Thrun, \BBA\ Mitchell}{Nigam
  et~al.}{2000}]{nigam2000a}
Nigam, K., McCallum, A.~K., Thrun, S., \BBA\ Mitchell, T.~M. \BBOP 2000\BBCP.
\newblock \BBOQ Text Classification from Labeled and Unlabeled Documents using
  {EM}.\BBCQ\
\newblock {\Bem Machine Learning}, {\Bbf 39}  (2/3), \mbox{\BPGS\ 103--134}.

\bibitem[\protect\BCAY{Pang \BBA\ Lee}{Pang \BBA\ Lee}{2002}]{pang}
Pang, B.\BBACOMMA\ \BBA\ Lee, L. \BBOP 2002\BBCP.
\newblock \BBOQ Thumbs up? Sentiment Classification using Machine Learning
  Techniques.\BBCQ\
\newblock In {\Bem Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 76--86}.

\bibitem[\protect\BCAY{Pang \BBA\ Lee}{Pang \BBA\ Lee}{2008}]{sa2}
Pang, B.\BBACOMMA\ \BBA\ Lee, L. \BBOP 2008\BBCP.
\newblock {\Bem Opinion Mining and Sentiment Analysis - Foundations and Trends
  in Information Retrieval Vol.2, Issue 1-2}.
\newblock Now Publishers Inc.

\bibitem[\protect\BCAY{Turney \BBA\ Littman}{Turney \BBA\
  Littman}{2002}]{turney}
Turney, P.~D.\BBACOMMA\ \BBA\ Littman, M.~L. \BBOP 2002\BBCP.
\newblock \BBOQ Unsupervised Learning of Semantic Orientation froma
  Hundred-Billion-Word Corpus.\BBCQ\
\newblock \BTR, Technical Report ERB-1094, National Research Council Canada.

\bibitem[\protect\BCAY{内山\JBA 中條\JBA 山本\JBA 井佐原}{内山 \Jetal
  }{2004}]{uchiyama}
内山将夫\JBA 中條清美\JBA 山本英子\JBA 井佐原均 \BBOP 2004\BBCP.
\newblock 英語教育のための分野特徴単語の選定尺度の比較.\
\newblock \Jem{自然言語処理}, {\Bbf 11}  (3), \mbox{\BPGS\ 165--197}.

\bibitem[\protect\BCAY{Yu, Zha, Wang, \BBA\ Chua}{Yu et~al.}{2011}]{yu}
Yu, J., Zha, Z.-J., Wang, M., \BBA\ Chua, T.-S. \BBOP 2011\BBCP.
\newblock \BBOQ Aspect Ranking: Identifying Important Product Aspects from
  Online Consumer Reviews.\BBCQ\
\newblock In {\Bem Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 1496--1505}.

\bibitem[\protect\BCAY{Zhai, Liu, Xu, \BBA\ Jia}{Zhai et~al.}{2010}]{zhai}
Zhai, Z., Liu, B., Xu, H., \BBA\ Jia, P. \BBOP 2010\BBCP.
\newblock \BBOQ Grouping Product Features Using Semi-Supervised Learning with
  Soft-Constraints.\BBCQ\
\newblock In {\Bem Proceedings of the 23rd International Conference on
  Computational Linguistics}, \mbox{\BPGS\ 1272--1280}.

\end{thebibliography}


\begin{biography}
\bioauthor{乾　　孝司}{
2004年奈良先端科学技術大学院大学情報科学研究科博士課程
修了．日本学術振興会特別研究員，東京工業大学統合研究院
特任助教等を経て，2009年筑波大学システム情報工学研究科
助教．現在に至る．博士（工学）．
近年はCGMテキストに対する評判分析に興味をもつ．
}
\bioauthor{板谷　悠人}{
2010年筑波大学第三学群情報学類卒業．
2012年筑波大学大学院システム情報工学研究科コンピュータサイエンス専攻修了．
同年4月から株式会社ミクシィ．在学中は自然言語処理の研究に従事．
}
\bioauthor{山本　幹雄}{
1986年豊橋技術科学大学大学院修士課程了.
同年株式会社沖テクノシステムズラボラトリ研究開発員.
1988年豊橋技術科学大学情報工学系教務職員. 1991年同助手. 
1995年筑波大学電子・情報工学系講師. 1998年同助教授.
2008年筑波大学システム情報工学研究科教授.
博士（工学）. 自然言語処理の研究に従事.
}
\bioauthor{新里　圭司}{
2006年北陸先端科学技術大学院大学情報科学研究科博士後期課程修
了．京都大学大学院情報学研究科特任助教，特定研究員を経て，2011年から楽
天技術研究所．博士（情報科学）．言語知識獲得，情報抽出，情報検索，テキス
トマイニングに興味をもつ．
}
\bioauthor{平手　勇宇}{
2008年早稲田大学大学院理工学研究科博士課程修了．
早稲田大学メディアネットワークセンター助手を経て，
2009年から楽天株式会社楽天技術研究所．博士（工学）．
近年は大規模データに対するデータマイニングに興味を持つ．
}
\bioauthor{山田　　薫}{
2002年名古屋大学大学院国際言語文化研究科博士前期課程修了．
ヤフー株式会社検索事業部等を経て，2010年から楽天株式会社楽天技術研究所．
現在は同社ビッグデータ部にて商品検索システムの開発・運用に従事．
}
\end{biography}


\biodate



\end{document}
