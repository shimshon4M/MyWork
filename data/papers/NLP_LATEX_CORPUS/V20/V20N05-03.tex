    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{url}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{ascmac}

\def\sec#1{}
\def\eq#1{}
\def\fig#1{}
\def\tab#1{}
\def\algo#1{}
    \newcommand{\argmax}{}

\Volume{20}
\Number{5}
\Month{December}
\Year{2013}

\received{2013}{5}{9}
\revised{2013}{8}{2}
\accepted{2013}{9}{17}

\setcounter{page}{683}

\jtitle{評価表現と文脈一貫性を利用した\\
	教師データ自動生成によるクレーム検出}
\jauthor{乾　　孝司\affiref{Author} \and 梅澤　佑介\affiref{Author} \and 山本　幹雄\affiref{Author}}
\jabstract{
本論文では，レビュー文書からクレームが記述された文を自
動検出する課題に対して，従来から問題となっていた人手負
荷を極力軽減することを指向した次の手続きおよび拡張手法
を提案する：
(1) 評価表現と文脈一貫性に基づく教師データ自動生成の手続き．
(2) 自動生成された教師データの特性を踏まえたナイーブベイズ・モデルの拡張手法．
提案手法では，大量のレビュー生文書の集合と評価表現辞書
が準備できれば，クレーム検出規則の作成・維持・管理，あ
るいは，検出規則を自動学習するために必要となる教師デー
タの作成にかかる人手負荷は全くかからない利点をもつ．
評価実験を通して，提案手法によって検出対象文の文
脈情報を適切に捉えることで，クレーム文の検出精度を向上
させることができること，および，
人手によって十分な教師データが作成できない状況において
は，提案手法によって大量の教師データを自動生成すること
で，人手を介在させる場合と同等あるいはそれ以上のクレー
ム検出精度が達成できることを示した．
}
\jkeywords{クレーム，評価表現，文脈一貫性，教師データ}

\etitle{Complaint Sentence Detection via Automatic Training \\
	Data Generation using Sentiment Lexicons \\
	and Context Coherence}
\eauthor{Takashi Inui\affiref{Author} \and Yusuke Umesawa\affiref{Author} \and Mikio Yamamoto\affiref{Author}} 
\eabstract{
We propose an automatic method for detecting complaint
sentences from review documents. The proposed method
consists of two procedures. One is a data generation
procedure using sentiment lexicons and context
coherence and the other is the expansion of a naive
Bayes classifier based on the characteristics of the
training data.  This method has an advantage of not
requiring human effort for the creation of large-scale
training data and management of rules for complaint
detection. The experimental results indicate that this
method is more effective than the baseline methods.
}
\ekeywords{complaint, sentiment expression, context coherence, labeled data}

\headauthor{乾，梅澤，山本}
\headtitle{評価表現と文脈一貫性を利用した教師データ自動生成によるクレーム検出}

\affilabel{Author}{筑波大学大学院システム情報工学研究科コンピュータサイエンス専攻}{Department of Computer Science, Graduate school of SIE, University of Tsukuba}



\begin{document}
\maketitle


\section{はじめに}
\label{sec:hajimeni}

インターネットの普及により，個人がWeb上で様々な商品を購
入したり，サービスの提供を受けることが可能になった．ま
た，これに伴い，商品やサービスに対する意見や感想が，大
量にWeb上に蓄積されるようになった．
これらの意見や感想は，ユーザが商品やサービスを購入する
際の参考にするだけでなく，企業にとっても商品やサービス
の改善を検討したり，マーケティング活動に活用するなど，
利用価値の高い情報源として広く認識されている．

近年ではさらに，ユーザ参加型の商品開発が注目されるなど，
ユーザと企業とがマイクロブログやレビューサイト等のソー
シャルメディアを通して，手軽に相互にコミュニケーション
を持つことも可能となっている．
そして，このようなコミュニケーションの場においては，い
わゆる「クレーム」と呼ばれる類のユーザの意見に対して企
業側は特に敏感になる必要があり，ユーザが発言したクレー
ムに対しては，適切に対応することが望まれている．しかし
ながら，このようなコミュニケーションの場では，次のよう
な理由からユーザのクレームを見落としてしまう懸念がある．

\begin{figure}[b]
\input{03fig01.txt}
\caption{クレームが含まれたレビューの例 1}
\label{fig:review}
\end{figure}
\begin{figure}[b]
\input{03fig02.txt}
 \caption{クレームが含まれたレビューの例 2}
 \label{fig:review2}
\end{figure}

\begin{itemize}
 \item 
見落とし例 1：特に，マイクロブログ型サービスを通したコ
ミュニケーションでは，多対一型のコミュニケーション，つ
まり，大勢のユーザに対して少数の企業内担当者が同時並行
的にコミュニケーションを持つことが多く，そのため，一部
のユーザが発言したクレームを見落としてしまう可能性がある．

\item 
見落とし例 2：特に，レビューサイトを通したコミュニケー
ションでは，ユーザは様々な意見をひとつのレビュー文書中
に書き込むことが多く，その中に部分的にクレームが埋め込
まれることがある（\fig{review}および\fig{review2}に例を
  示す．下線部がクレームを示す）．この場合，レビューの
中からクレームを見つける必要があるが，これらの一部を見
落としてしまう可能性がある．

\end{itemize}

本論文では，上記のうち，2 つ目の見落とし問題に対処すべ
く，レビューからクレームを自動検出する手法について述べ
る．より具体的には，まず，文単位の処理を考え，
\tab{data_detail}のような内容を含む文を「クレーム文」と
定義する．そして，レビューが入力された際に，そのレビュー
中の各文のそれぞれに対して，それらがクレーム文かそうで
ないかを自動判定する手法について検討する．

\begin{table}[b]
 \caption{クレーム文の定義}
 \label{tab:data_detail}
\input{03table01.txt}
\end{table}

これまで，テキストからクレームを検出することを目的とし
た先行研究としては，永井らの研究\cite{nagai1,nagai2}が
ある．
永井らは，単語の出現パタンを考慮した検出規則に基づいた
クレーム検出手法を提案している．しかしながら，彼らの手
法のように人手で網羅的に検出規則を作成するには，作成者
がクレームの記述のされ方に関する幅広い言語的知識を有し
ている必要がある．
また，現実的に検出規則によって運用するには，膨大な量の
規則を人手で作成・維持・管理する必要があり，人的負荷が
高いという問題がある．
この問題に対する解決策のひとつとして，教師あり学習によっ
て規則を自動学習することが考えられるが，その場合でも，
事前に教師データを準備する必要があり，単純には，教師デー
タの作成に労力を要するという別な問題が発生してしまう．

本論文では，上記のような背景を踏まえて，人的な負荷をな
るべく抑えたクレーム検出手法を提案する．
より具体的には，レビュー文書からクレーム文を自動検出す
る際の基本的な設定として，テキスト分類において標準的に
利用されるナイーブベイズ・モデルを適用することを考え，
この設定に対して，極力人手の負荷を軽減させるために，次
の手続きおよび拡張手法を提案する．



\begin{itemize}
\item 
評価表現および文脈一貫性に基づく教師データ自動生成手法
を提案する．従来，学習用の教師データを作成するには負荷
の高い人手作業に頼らざるを得なかったが，本研究では既存
の言語資源と既存の知見に基づくことで，人手作業に頼らず
に教師データを自動生成する手法を提案する．

\item 
次に，上記で生成された教師データに適したモデルとなるよ
うに拡張されたナイーブベイズ・モデルを提案する．上記の
提案手法によって生成された教師データは自動化の代償とし
て人手作成されたデータと比べて質が劣化せざるを得ず，標
準的な分類モデルをそのまま適用するだけでは期待した精度
は得られない．本研究では上記のデータ生成手法で生成され
るデータが持つ特性を踏まえて，ナイーブベイズ・モデルを
拡張する．

\end{itemize}

提案手法では，従来手法で問題となっていた検出規則の作成・
維持・管理，あるいは，規則を自動学習するために必要とな
る教師データの作成にかかる人手負荷は全くかからない利点
をもつ．
本論文では，上記の手続きおよび拡張手法について，実デー
タを用いた評価実験を通して，その有効性を検証する．
本論文の構成は以下の通りである．まず\sec{gen}で教師デー
タの自動生成手法について説明する．その後，\sec{model}で
ナイーブベイズ・モデルの拡張について説明し，\sec{exp}で
評価実験について述べる．\sec{related}で関連研究を整理し
た後，\sec{owarini}で本論文をまとめる．


\section{教師データ自動生成}
\label{sec:gen}

\subsection{教師データ}

まず，生成したい教師データについて整理する．
本研究では，クレーム文を検知するためにナイーブベイズ
分類器\cite{nv}を構築し，文がクレームを表しているか，あ
るいはクレームを表していないかのどちらかに分類したい．
このような分類器の構築に必要となる教師データは，言うま
でもなく，クレームを表している文（以下，クレーム文と呼
  ぶ）の集合と，クレームを表していない文（以下，非クレー
  ム文）の集合となる．
以下では，説明の便宜上，このデータ集合を得る手続きをラ
ベル付けと呼び，【クレーム】および【非クレーム】という
ラベルによって，どちらの集合の要素となるかを区別するこ
ととする．例えば，\fig{review}の各文に対してラベル付け
が実施されたとすると，次のようなラベル付きの教師データ
が得られる．

\begin{itemize}
 \item 【非クレーム】従業員の方は親切でした．
 \item 【非クレーム】最寄りの病院など教えて頂き，とても助かりました．
 \item 【非クレーム】ありがとうございました．
 \item 【クレーム】ただ残念だったのが，シャワーの使い方がよくわからなかったことです．
 \item 【クレーム】使い方の説明をおいて頂きたいです．
\end{itemize}


本論文で提案する教師データ自動生成手法は，評価表現の情
報に基づくラベル付けステップと，ある文の文脈に対する文
脈一貫性の情報に基づくラベル付けステップの 2 ステップで
構成される．
各ステップをそれぞれ核文ラベル付けおよび近接文ラベル付
けと呼ぶことにし，以下で順に説明する．


\subsection{核文ラベル付け}
\label{sec:data_core}

核文ラベル付けは，評価表現の情報に基いて行う．
評価表現とは，「おいしい」や「まずい」等，評価対象に対
する評価を明示的にあらわす言語表現のことである．
一般的には，これら表現に「おいしい／肯定」や「まずい／
  否定」のような肯定・否定の評価極性値を付随させたもの
を集めて評価表現辞書と呼ばれている\cite{inui}．

核文ラベル付けステップでは，評価表現辞書に否定極性とし
て登録されている評価表現に着目し，このような評価表現を
含む文はクレームを表しやすいと仮定する．そして，否定極
性の評価表現を含む文をクレーム文としてラベル付けする．
以降，この手続きで得られる文を次ステップで得られる文と
区別するため核文と呼び，特に，核文がクレーム文である場
合はクレーム核文と呼ぶ．
例えば，「まずい／否定」という単語が評価表現辞書に登録
されている場合，次の例文はクレーム核文としてラベル付け
される．

\begin{itemize}
  \item 【クレーム（核）】 朝食のカレーが\underline{まずい}．
\end{itemize}

もし，ある文が肯定極性をもつ評価表現を含み，かつ「ない」
や「にくい」などの否定辞が評価表現の 3 単語以内に後続し
ていた場合もクレーム核文としてラベル付けする．例えば，
次の例文は「おいしい／肯定」の直後に否定辞「ない」が後
続しているため，クレーム核文としてラベル付けされる．

\begin{itemize}
  \item 【クレーム（核）】朝食のカレーが\underline{おいしく} \unc{ない}．
\end{itemize}

また，評価表現の否定極性と肯定極性を読み替えて上記と同
様の手続きを行った場合に得られる文を非クレーム核文
と呼び，クレーム核文と同じようにラベル付けしておく．

\begin{itemize}
  \item 【非クレーム（核）】朝食のカレーが\underline{おいしい}．
  \item 【非クレーム（核）】ハヤシライスは別に\underline{まずく}は\unc{ない}．
\end{itemize}

さらに，「ほしい」等の要求表現を集めた要求表現辞書が利
用できる場合は，次の例のように要求表現を含む文をクレー
ム核文としてラベル付けする
\footnote{
\setulsep{0pt}
この操作によって，例えば，「このサービスは是非今後も継
  続して\underline{ほしい}」というような肯定的な要求に
ついては誤ってクレーム文として扱ってしまう．しかし，後
述する本研究で使用したデータセットでは，上記のような事
例はごく稀であり，本研究ではこのような肯定的な要求に対
する特別な処理は施していない．}
．ただし，要求表現に注目したラベル付けの場合は，評価表
現の時とは違って，否定辞の有無に関係なくクレーム核文と
してラベル付けする．

\begin{itemize}
  \item 【クレーム（核）】朝食に和食メニューをもっと増やして\underline{ほしい}．
  \item 【クレーム（核）】朝食を洋風なものばかりにして\underline{ほしく} \unc{ない}．
\end{itemize}


以降，クレーム核文と非クレーム核文をあわせた文の集合を
$\mathcal{S}_\mathrm{core}$であらわす．



\subsection{近接文ラベル付け}
\label{sec:data_context}

那須川ら\cite{nasukawa}は，彼らの論文の中で，評価表現の
（文をまたいだ）周辺文脈には以下のような傾向があると述
べており，これを評価表現の文脈一貫性と呼んだ．

{\setlength{\leftskip}{3zw}\noindent
文書中に評価表現が存在すると，その周囲に評価表現の連続
する文脈（以降，評価文脈\footnote{
元論文では「評価部脈」と書かれているが，これは「評価文脈」の書き誤りであると考えられる．}）
が形成されることが多く，その中では，明示されない限り，
好不評の極性が一致する傾向がある．
\par}


本研究では，この評価表現の文脈一貫性の考え方に基いて近
接文ラベル付けを行う．
先の核文ラベル付けの際に考慮した評価表現（あるいは要求
  表現）を含む文の周辺文脈について，「評価表現（要求表
    現）の存在に基づいて（非）クレーム文として選ばれた
  文の前後文脈に位置する文は，やはり（非）クレーム文で
  ある」という仮定をおき，この仮定に従って，核文の周辺
文脈に対してラベル付けを行う．この手続きで得られる
文を近接文（より詳細にはクレーム近接文あるいは非クレー
  ム近接文）と呼ぶ．

\begin{algorithm}[b]
 \caption{近接文ラベル付け}
 \label{algo:alg1}
\input{03algo01.txt}
\end{algorithm}

近接文ラベル付けの手続きを\algo{alg1}に示す．この手続き
への入力は，核文ラベル付けを終えたレビュー$d$と，核文に
対する周辺文脈の長さを決定する窓枠長$N$ ($ \ge 0$) であ
り，レビュー$d$ に含まれる核文に対して，レビューの先頭
側に現れる核文から末尾側に現れる核文に向かって順に処理
が進む．
なお，\algo{alg1}において，$s_i$はレビュー$d$内の先頭か
ら$i$番目の文をあらわし，$|d|$は$d$内の文数をあらわす．
処理の大きな流れとしては，line.2--9でラベル付けされる文
が選択され，line.10--16でラベル付けが実施される．
line.17--34の各関数では，付与するラベルの種類（``クレー
  ム''か``非クレーム''）を確定する際に必要な仮のラベル
情報が決められ，その情報が格納される．

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-5ia3f3.eps}
  \end{center}
  \caption{近接文ラベル付けの例（窓枠長$N=2$の場合）}
  \label{fig:context}
\end{figure}


\fig{context}を使って近接文ラベル付けの具体的な実行例を
示す．図の例では，対象となるレビューは 8 つの文から構成
されており，核文ラベル付けによって文$s_1$が非クレーム核
文，文$s_5$ がクレーム核文とラベル付けされた状態であり，
この状態から近接文ラベル付けが開始される．窓枠長は
$N=2$とする．この場合，
まず，核文$s_1$の周辺文脈に対する処理がなされる
（\algo{alg1}のline.3）．$s_1$は文書の先頭文であり前方
文脈 (Backward context) は存在しない．そのため，後方文
脈 (Forward context) の$s_2$と$s_3$に対してのみ処理がな
され (line.6--7)，それぞれ``非クレーム'' ラベルが配列に
格納される (line.29)．
次に核文$s_5$の周辺文脈に対する処理がなされる．$s_5$は
クレーム文であるため，前方文脈では$s_3$に対して 2 つ目の
ラベル``クレーム''が格納され (line.19)，また新たに
$s_4$ に対して``クレーム''ラベルが格納される (line.19)．
後方文脈では，まず$s_6$に対して``クレーム''ラベルが配列
に格納される (line.28)．その一方で，$s_7$ は逆接関係の
接続詞「しかし」の影響があるため，``クレーム''ではなく
``非クレーム''ラベルが格納される (line.31)．
最後に，各文に対して格納されたラベル情報をチェックし，
格納されたラベルに不整合がない場合は，そのラベル情報に
従ってラベル付けを行う (line.10--16)．不整合が生じ
ている場合はその文に対してどのラベルも付与しない．
以上の操作によって，この例では 2 つの核文から新たに 4 つ
の近接文（$s_2$，$s_4$，$s_6$および$s_7$）が得られる．

以降，クレーム近接文と非クレーム近接文をあわせた文の集合
を$\mathcal{S}_{sat}$\footnote{添字$sat$は
  \underline{sat}ellite の略である．}であらわす，また，
必要に応じて，核文の前方文脈から得られた近接文
$\mathcal{S}_{sat}^{B}$と，後方文脈から得られた近接文
$\mathcal{S}_{sat}^{F}$を区別する ($\mathcal{S}_{sat}
  = \mathcal{S}_{sat}^{B} \cup \mathcal{S}_{sat}^{F}$)．







\section{ナイーブベイズ・モデルの拡張}
\label{sec:model}

\subsection{ナイーブベイズ・モデル (Na\"{i}ve Bayes model; NB)}
\label{sec:base_model}

前節で述べた手法によって自動生成された教師データは，人
手によって作成された教師データと比べて質が劣化せざるを
得ず，標準的な分類モデルをそのまま適用するだけでは期待
した精度は得られない．
そこで，前節で述べた手法で得られる劣化を含むデータを使
用するという前提をおき，この劣化データがもつ特性を踏ま
えてナイーブベイズ・モデルを拡張することを考える．
以下では，まず，通常のナイーブベイズ・モデル（多項モデ
  ル）について述べ，その後，モデルの拡張について述べる．

ナイーブベイズ分類器では，ある文$s$の分類クラスを判定す
る際に，条件付き確率$P(c|s)$を考え，この確率値が最大と
なるクラス$\hat{c}$を分類結果として出力する．つまり，
\begin{equation}
\hat{c} = \argmax _{c}P(c|s)
\label{eq:eq0}
\end{equation}
である．通常のナイーブベイズ・モデルでは上式
を次のように展開する．
\begin{align}
 \argmax _{c}P(c|s)
	&= \argmax _{c}P(c)P(s|c)\nonumber \\ 
	& = \argmax_{c} \big\{ \log p_{c}+\sum_{w\in{\mathcal{V}}}^{}n_{w}(s)\log q_{w,c} \big\}
\label{eq:eq1}
\end{align}
ここで，$\mathcal{V}$は語彙集合，$n_{w}(s)$は文$s$にお
ける単語$w$の出現回数をあらわす．
また，$q_{w,c}$ ，$p_{c}$は教師データを使ってそれぞれ以
下の式で計算される．本研究ではパラメータを推定する際に
ラプラススムージング\cite{nv}を用いる．
\begin{align}
q_{w,c}&= \frac{\displaystyle n_{w,c}(\mathcal{D})+1}{\displaystyle \sum_{w}^{}n_{w,c}(\mathcal{D})+|\mathcal{V}|}\label{eq:eq2}\\
p_{c}  &= \frac{\displaystyle n_{c}(\mathcal{D})+1}{\displaystyle \sum_{c}^{}n_{c}(\mathcal{D})+|\mathcal{C}|} \label{eq:eq3}
\end{align}
ここで，$\mathcal{D}$は教師データとなる文の集合，
$n_{w,c}(\mathcal{D})$はデータ$\mathcal{D}$においてクラ
ス$c$に属する文に現れる$w$の出現回数，
$n_{c}(\mathcal{D})$はデータ$\mathcal{D}$においてクラス
$c$に属する文の数，
$|\mathcal{V}|$は語彙の種類数，
$|\mathcal{C}|$は分類クラスの種類数である．


以上からもわかるように，通常のモデルでは，分類対象とな
る文内の情報のみを考慮し，分類対象文の周辺文脈の様子は
全く考慮されない．たとえ同一文書内であっても個々の文は
独立に評価・分類する．
また，教師データの利用にあたっても，当然のことながら，
核文であるか近接文であるかといった区別はなく，両タイプ
の文が同等にモデルの構築に利用される．



\subsection{モデル拡張}
\label{sec:pro_model}

前節で述べた教師データ生成過程から得られるデータには，
核文および近接文という 2 種類の文が存在する．
この 2 種類の文のうち，核文は近接文とは独立にラベル付け
される一方で，近接文は核文の情報に基いて間接的にラベル
付けされる．そのため，核文ラベル付けが結果として誤りで
あった事例に関しては近接文もその誤りの影響を直接受ける
ことになる．また，当然ながら，文脈一貫性の仮定が成立し
ない事例もあり得る．このような理由から，近接文は核文に
比べて相対的に信頼性の低いデータとなる可能性が高い．

そこで，このことを考慮し，核文と近接文の情報をモデル内
で区別して扱い，近接文の情報がモデル内で与える影響を下
げるよう，\eq{eq1}の代わりに次のような\eq{eqex}を用いる．
\begin{align}
\argmax _{c}P(c|s)
	&= \argmax _{c}P(c)P(s|c) \nonumber \\
	&= \argmax_{c} \big\{ \log p_{c}+\sum_{w}n_{w}(s)\log q^{tgt}_{w,c} \nonumber \\ 
	& \phantom{= \argmax_{c} \big\{ \log p_{c}}~+ \frac{1}{|ctx(s,N)|}\sum_{w}n_{w}(ctx(s,N))\log q^{ctx}_{w,c} \big\}
\label{eq:eqex}
\end{align}

右辺第 3 項に現れる$ctx(s,N)$は$s$の周辺文脈に位置する前方
および後方のそれぞれ$N$文から構成される文の集合を表して
おり，この項が分類対象の周辺文脈をモデル化している．
この項の係数$1/|ctx(s,N)|$で，周辺文脈の文数に応じてその
影響を調整している．
なお，$n_{w}(ctx(s,N))$は，集合$ctx(s,N)$の要素となる全ての
文における単語$w$の総出現回数をあらわす．
また，右辺第 2 項は通常のモデルと同様に分類対象となる文
をモデル化したものであるが，第 3 項の周辺文脈との区別を
明瞭にするため，$q^{tgt}_{w,c}$という記号を新たに導入し
た
\footnote{\setulminsep{1.2ex}{0.45ex}
上付きの添字$tgt$と$ctx$は，それぞれ
  \underline{t}ar\underline{g}e\underline{t}，
\underline{c}on\underline{t}e\underline{x}t をあらわしている．
} ．


\eq{eqex}の$q^{tgt}_{w,c}$と$q^{ctx}_{w,c}$，および
$p_{c}$はそれぞれ次式で求める．式中の各記号の意味は
\eq{eq2}，\eq{eq3}と同様である．
ここで，$\mathcal{D}_{tgt}$は分類対象文をモデル化するため
の教師データ集合，$\mathcal{D}_{ctx}$は分類対象の周辺文
脈をモデル化するための教師データ集合である．
基本的には，前節で得られる教師データのうち，核文
データを$\mathcal{D}_{tgt}$に割り当て，近接文データを
$\mathcal{D}_{ctx}$に割り当てるが，正確な記述は後述の
\sec{wariate}で与える．
\begin{align}
q^{tgt}_{w,c} & = \frac{\displaystyle n_{w,c}(\mathcal{D}_{tgt})+1}{\displaystyle \sum_{w}n_{w,c}(\mathcal{D}_{tgt})+|\mathcal{V}_{tgt}|}
\label{eq:qtbt}\\
q^{ctx}_{w,c} & = \frac{\displaystyle n_{w,c}(\mathcal{D}_{ctx})+1}{\displaystyle \sum_{w}n_{w,c}(\mathcal{D}_{ctx})+|\mathcal{V}_{ctx}|}
\label{eq:qctx}\\
p_{c}  & = \frac{\displaystyle n_{c}(\mathcal{D}_{tgt})+1}{\displaystyle \sum_{c}n_{c}(\mathcal{D}_{tgt})+|\mathcal{C}|}
\end{align}
以降，便宜的にこの拡張されたモデルを\textbf{NB+ctx}と呼ぶ．

さらに，\eq{eqex}の第 3 項について，周辺文脈を分類対象文
からの相対位置で詳細化した
\begin{equation}
  \frac{1}{|ctx(s,N)|} \big\{ \sum_{w}n_{w}(Bctx(s,N))\log q^{Bctx}_{w,c} 
	+ \sum_{w}n_{w}(Fctx(s,N))\log q^{Fctx}_{w,c} \big\}
\label{eq:eqex2}
\end{equation}
を代わりに利用するモデルも考えられる．
ここで，$Bctx(s,N)$は，$s$の前方文脈に位置する$N$文から構
成される文の集合であり，$Fctx(s,N)$は同様に後方文脈で構成
される文集合である．
また，式中の$q^{Bctx}_{w,c}$および$q^{Fctx}_{w,c}$は次
式で求める．ただし，$\mathcal{D}_{ctx} =
\mathcal{D}^{B}_{ctx} \cup \mathcal{D}^{F}_{ctx}$である．
\begin{align}
q^{Bctx}_{w,c} & = \frac{\displaystyle n_{w,c}(\mathcal{D}^{B}_{ctx})+1}{\displaystyle \sum_{w}n_{w,c}(\mathcal{D}^{B}_{ctx})+|\mathcal{V}_{Bctx}|}\\
q^{Fctx}_{w,c} & = \frac{\displaystyle n_{w,c}(\mathcal{D}^{F}_{ctx})+1}{\displaystyle \sum_{w}n_{w,c}(\mathcal{D}^{F}_{ctx})+|\mathcal{V}_{Fctx}|}
\end{align}
以降，便宜的にこのモデルを\textbf{NB+ctxBF}と呼ぶ．



\subsection{データ割当規則}
\label{sec:wariate}

ここでは，さきほどの説明で保留していた，パラメータ推定
の際に必要となる教師データの与え方について述べる．
ここで，前節で述べた手法によって得られるデータ集合を確
認すると，

\begin{itemize}
 \item $\mathcal{S}_{core}$：クレーム核文と非クレーム核文をあわせた文の集合
 \item $\mathcal{S}_{sat~}$：クレーム近接文と非クレーム近接文をあわせた文の集合
 \item $\mathcal{S}^{B}_{sat~}$：$\mathcal{S}_{sat}$の要素のうち，核文の前方文脈から得られた文で構成される集合
 \item $\mathcal{S}^{F}_{sat~}$：$\mathcal{S}_{sat}$の要素のうち，核文の後方文脈から得られた文で構成される集合
\end{itemize}

であり，$\mathcal{S}_{sat} = \mathcal{S}_{sat}^{B} \cup \mathcal{S}_{sat}^{F}$であった．

これらデータ集合に対して，まず，核文と近接文を区別しな
い単純な割当として，得られた全データをまとめて利用する
ことが考えられる．この場合，拡張モデルNB+ctx においての
割当は，

\begin{itemize}
 \item $\mathcal{D}_{tgt} = \mathcal{S}_{core} \cup \mathcal{S}_{sat} $
 \item $\mathcal{D}_{ctx} = \mathcal{S}_{core} \cup \mathcal{S}_{sat} $
\end{itemize}

となる．これを以降\textbf{NB+ctx(all)}と呼ぶ．また同様に，
拡張モデルNB+ctxBF においての単純な割当は，

\begin{itemize}
 \item $\mathcal{D}_{tgt} = \mathcal{S}_{core} \cup \mathcal{S}_{sat} $
 \item $\mathcal{D}^{B}_{ctx} = \mathcal{S}_{core} \cup \mathcal{S}_{sat} $
 \item $\mathcal{D}^{F}_{ctx} = \mathcal{S}_{core} \cup \mathcal{S}_{sat} $
\end{itemize}

となるが，これは先のNB+ctx(all)と事実上同等となるため
以降の議論では割愛する．

次に，核文と近接文の区別を考慮したデータ割当を考える．
拡張モデルNB+ctx においての割当としては，

\begin{itemize}
 \item $\mathcal{D}_{tgt} = \mathcal{S}_{core}$
 \item $\mathcal{D}_{ctx} = \mathcal{S}_{sat} $
\end{itemize}

が考えられる．これを以降\textbf{NB+ctx(divide)}と呼ぶ．
また同様に，拡張モデルNB+ctxBF においてのデータ割当とし
て，

\begin{itemize}
 \item $\mathcal{D}_{tgt}     = \mathcal{S}_{core}$
 \item $\mathcal{D}^{B}_{ctx} = \mathcal{S}^{B}_{sat} $
 \item $\mathcal{D}^{F}_{ctx} = \mathcal{S}^{F}_{sat} $
\end{itemize}

が考えられる．これを以降\textbf{NB+BFctx(divide)}と呼ぶ．


最後に，通常のナイーブベイズについて考えると，この場合
は，もともとのモデルにデータを区別する枠組みが存在しな
いため，

\begin{itemize}
 \item $\mathcal{D} = \mathcal{S}_{core} \cup \mathcal{S}_{sat}$
\end{itemize}

という割当のみを考えることになる．
なお，$\mathcal{D} = \mathcal{S}_{core}$ という核文のみ
を考慮し，近接文を利用しない割当も考えられるが，これは
$\mathcal{D} = \mathcal{S}_{core} \cup
\mathcal{S}_{sat}$において近接文の窓枠長を$0$とする場合
に等しいため，割当規則として明示的には議論しないが，第
\sec{exp}の評価実験では，近接文の窓枠長が$0$の場合も含
めて議論する．以降，これを\textbf{NB}と呼ぶ．

ここまでの議論を整理すると，前節の手法で自動生成された
教師データを利用するという前提のもとで，通常のナイーブ
ベイズ・モデルも含めて， 4 つのクレーム文検出モデルが与
えられたことになる．次節では，評価実験を通じて，これら
の有効性を検証していく．




\section{評価実験}
\label{sec:exp}


\subsection{検証項目}

評価実験を通して，提案手法の有効性を検証する．具体的に
は以下の 3 項目を検証する．
\begin{enumerate}
 \item 
提案手法の比較：前節までで述べた 4 つのクレーム文検出モ
デルの中で，どのモデルが最良であるかを検証する．

 \item 
他手法との比較：提案手法と他手法との比較実験を行い，
その結果から提案手法の有効性を検証する．

 \item 
学習データ量とクレーム文検出精度の関係について：提案した
データ生成手法は学習データを自動生成できるため，人手に
よる生成に比べて遥かに多くの教師データを準備できる．こ
の利点を実験を通して検証する．

\end{enumerate}



\subsection{実験の設定}
\label{sec:setting}

実験には，楽天データ公開
\footnote{http://rit.rakuten.co.jp/rdr/index.html}
において公開された楽天トラベルの施設データを利用した．
このデータは約35万件（平均4.5文／件）の宿泊施設に関するレ
ビューから構成されており，ここから，無作為に選んだ
1,000レビューに含まれる文を評価用データとして用い，残り
を教師データ生成用に利用した．
評価用データには4,308文が含まれており，その内の24\%にあ
たる1,030文がクレーム文
であった．
つまり，4,308文からクレームを述べている1,030文を過不足
なく検出することがここでの実験課題である．
評価用データの作成では，まず，レビュー文書中の各文が 1
行 1 文となるようにデータを整形し，それを作業者に提示し
た．そして作業者は，与えられたデータの 1 文（1 行）ごと
にクレーム文か否かを判定していった．なお，ある文の判定
時には，同一レビュー内の他の全ての文が参照できる状態に
なっている．2 名の作業者によって上記の作業を独立に並行
に行ったが，このうち 1 名の作業結果を評価用データと
して採用した．2 名の作業者間の一致度を$\kappa$係数の値
によって評価したところ，$\kappa =0.93$であった．この結
果は，作業者間の判断が十分に一致していたことを示してい
る．作業者間で判断が一致しなかった事例としては，文が長
く，ひとつの文で複数の事柄が述べられている場合や，「長
  身で据え置きのものでは短くて…」のように，クレームの
原因が宿泊施設側にあるとは必ずしも言えない場合が多かっ
た．

教師データ生成時に必要となる評価表現辞書には，高村ら
\cite{takamura}の辞書作成手法に基いて作成された辞書を使
用した．ただし，高村らのオリジナルの辞書は自動構築され
たもので，そのままでは誤りが含まれているため，以下の手
続きによって誤り修正を施し，本実験で使用する辞書として
採用した．オリジナルの辞書には各登録語に対して肯定／否定
の強さを示すと解釈できる$[-1,1]$の範囲のスコアが付与さ
れている．このスコアは，値が大きいほど肯定，また，小さ
いほど否定をあらわし，0付近はどちらでもないことを示して
いると解釈できる．そこでまず，このスコアの絶対値の大き
いものから0.9付近までの単語を自動的に選択した．そして，
選択された各単語に対して人手による誤り修正を施し，結果
として肯定表現760件，否定表現862件からなる辞書を作成し，
本実験に用いた．

また，要求表現辞書として，「欲しい」，「ほしい」，
  「べし」からなる辞書を作成して実験に使用した
\footnote{
評価表現辞書と比べて要求表現辞書への登録単語数が少ない
印象を受けるかもしれない．しかし，要求表現は評価表現と
は違い，「〜して\underline{ほしい}」のように自立語に
付随する形態を取りやすく，そのため辞書に登録できる単語もそれほ
ど多くない．}．
周辺文脈の窓枠長$N$の指定は，データ作成時，モデル学習時，
評価用データの分類時のすべての過程で同期させている．ま
た，各データの単語分割は
MeCab\footnote{http://mecab.sourceforge.net/}によって行った．
また，計算の都合上，$N=0$の場合は$1/|ctx(s,N)|=0$とした．

今回のように，分類すべきクラスがクレーム／非クレームと
いう 2 クラスの分類問題の場合，\eq{eq0}による意思決定は，
以下の\eq{deci}の符号が正の場合にクレームと判定すること
になる．
\begin{equation}
P(\text{``クレーム''}|s) - P(\text{``非クレーム''}|s)
\label{eq:deci}
\end{equation}
しかし，本研究では，\eq{deci}に意思決定の閾値$\theta$を
加えた次の条件式を新たに導入し，この条件式が成立する場
合にクレームと判定し，成立しない場合は非クレームと判定
することとした．
\begin{equation}
P(\text{``クレーム''}|s) - P(\text{``非クレーム''}|s) > \theta
\label{eq:deci2}
\end{equation}
\eq{deci2}の左辺は，クレームと判定する際の確信度を示し
ていると考えることができ，閾値$\theta$はこの確信度に応
じて出力を制御する役割りを持つ．閾値を$\theta = 0$ と設
定すると，これは\eq{deci}を用いた通常の意思決定と同じ動
作となる．閾値を$0$から大きくすると，より確信度が高い場
合のみクレームと判定することになる．
実験では，閾値$\theta$を増減させ，以下の式で計算される
適合率および再現率，あるいはその要約である11点平均適合
率\cite{iir}を求め，検出精度を評価した．
11点平均適合率とは再現率が $\{0.0,\ 0.1,\ \ldots ,\ 1.0\}$ となる
11点における適合率の平均値である．
\begin{align}
\mbox{適合率} &=\frac{\mbox{正しくクレーム文として検出できた数}}{\mbox{クレーム文として出力された数}} \\[1ex] 
\mbox{再現率} &=\frac{\mbox{正しくクレーム文として検出できた数}}{\mbox{クレーム文の数}}
\end{align}
データにおけるクレーム文と非クレーム文の割合等に応じて，
検出性能に対して最適な$\theta$ を自動推定することも考え
られるが，これについては今後の課題である．


\subsection{提案手法の比較}
\label{sec:exp_model}

実験結果を\fig{model_length}に示す．
このグラフは，4 つの各検出モデルについて，考慮する周辺
文脈の窓枠長を変化させながら性能変化をプロットしたもの
である．
文脈長$N=0$の場合は，どのモデルも同じになるため，グラフ
上では 1 点に集まっている．

\begin{figure}[b]
 \begin{center}
 \includegraphics{20-5ia3f4.eps}
 \end{center}
 \caption{実験結果（提案手法の性能比較）}
 \label{fig:model_length}
\end{figure}

NBモデルの結果（``◇''）を基準に考えると，
核文と近接文を区別しないNB+ctx(all)では文脈長を$N=0$か
ら$N \ge 1$のどの文脈の長さに変更しても性能が向上しない
一方で，核文と近接文の区別を考慮するNB+ctx(divide)と
NB+BFctx(divide)は文脈長を$N \ge 1$にすることで，一貫し
て性能が向上することがわかる．
このことから，文脈情報を適切にモデルに反映させるために
は，単にモデルを拡張するだけでは効果がなく，データとモ
デルを上手く組合せて，核文と近接文を区別することが重要
であることが確認できる．
性能の向上が見られたNB+ctx(divide)とNB+BFctx(divide)を
比較すると，どちらも $N \ge 1$ の場合は文脈長の変化に対
しては鈍感な傾向を示しているが，近接文の相対位置を考慮
するNB+BFctx(divide)の方が総じて良い結果を示しており，
本論文で述べた 4 つのクレーム文検出モデルの中では，
NB+BFctx(divide) モデルが最良であることがわかる．

次に，教師データとして自動生成されたクレーム近接文に含
まれる単語を確認したところ，\tab{context_word}のような
単語がクレーム核文には現れず，クレーム近接文にのみ現れ
ていた．
このような単語の情報は，周辺文脈の情報を取り込むことで
初めて考慮できるようになった情報であり，定性的にもクレー
ム検出における周辺文脈情報の利用の有効性が確認できる．

\begin{table}[t]
 \caption{クレーム近接文にのみ現れていた単語}
 \label{tab:context_word}
\input{03table02.txt}
\end{table}

また文脈情報を取り込むことで正しく分類ができるようになっ
た事例を以下に示す．下線の引かれた文が分類対象であり，
左端の数字は分類対象文からの相対位置を示す．

\begin{itemize}
\item 【正しくクレーム文であると判定できた例】\\
\begin{tabular}{rl}
$-2$：& 疲れていたので苦情をいうのも面倒で，さっさとチェックアウトしました．\\
$-1$：& 普段だったらクレームを入れるレベルです．\\
$0$：&\underline{もう宿泊はないと思います．}\\
$+1$：&残念です．
\\
\end{tabular}


\item 【正しく非クレーム文であると判定できた例】\\
\begin{tabular}{rp{352pt}}
$-1$：& 昨年寒い1月に宿泊した際，犬を入室させてもらえ助かりました．\\
$0$：& \underline{今回は寒くはないが飼い犬のミニチュアダックスが\mbox{老齢18歳で}泊めて頂け大変助かりました．}\\
$+1$：& また泊めて頂きます．\\
$+2$：& 感謝．
\\
\end{tabular}
\end{itemize}



次に，誤りの傾向を分析したところ，以下のような事例につ
いて，判定誤りが多く見られた．

\begin{itemize}
 \item 【誤ってクレーム文と判定する例】
 \begin{itemize}
  \item[A.] 不満の表明ではあるが，その対象・原因が宿泊者にある場合
  \begin{itemize}
   \item 【例】仕事で到着が遅くなり，ゆっくりできなかったのが残念でした．
  \end{itemize}
  \item[B.] クレームの対象となりやすい事物が文中に多く記述されている場合
  \begin{itemize}
   \item 【例】部屋は\underline{デスク}，\underline{姿見}，\underline{椅子}，\underline{コンセント}があり，…従業員の対応もまずまずでした．
  \end{itemize}
 \end{itemize}

 \item 【誤って非クレーム文と判定する例】
 \begin{itemize}
  \item[C.] 記述の省略を伴う場合
  \begin{itemize}
   \item 【例】バイキングにステーキがあればなぁ．
  \end{itemize}
  \item[D.] 外部的な知識を要する場合
  \begin{itemize}
   \item 【例】全体的な評価としてはE ランクでした．
  \end{itemize}
 \end{itemize}
\end{itemize}

誤ってクレーム文と判定する事例のうち，A. のような事例に
対応するには，意見の対象や原因を特定する等の詳細な自動
解析の実現が望まれる．
手元のデータによると，B. に該当する上述の例のうち，下線
部がクレーム対象となりやすい事物であった．このような事
例については，文中では名詞が多く現れることから，単語の
品詞情報を考慮する等，単語や単語クラス毎にモデル内での
扱いを変更することが考えられる．
また，誤って非クレーム文と判定する事例については，「Eラ
  ンク」を否定極性の単語として扱うなど，ヒューリスティッ
ク規則によるチューニングは可能であるが，総体的には現在
の技術では改善が困難な事例が多い印象である．



\subsection{他手法との比較}
\label{sec:exp_base}

次に，提案手法と他手法との比較実験を行い，その結果
から提案手法の有効性を検証する．他手法としては，以下に
示す 3 手法を検討した．始めの 2 つは，従来から考えられる
ラベル付け方法に基づく手法であり，残りの 1 つは，教師あ
り学習を適用しない，辞書の情報に基づいたルールベースの
手法である．


\begin{itemize}
  \item 人手によって教師データを作成する手法（以下，人手ラベル）

教師データ用のレビュー集合から2,000件のレビューを無作為
に抽出し，そこに含まれる全ての文に対して人手でクレーム／
非クレームのラベル付けを行ったものを教師データとしてモ
デル学習に用いる．この手法で得られるデータでは核文と近
接文の区別がないため，学習には通常のナイーブベイズ・モ
デルを用いる．提案手法と比べると，この手法では量は少量
だが質の高い学習データが利用できる．
このデータ作成作業は，評価実験の正解データ作成と同一の
作業となる．ただし，このデータ作成には正解データの作成
に従事した作業者のうちの 1 名によって執り行なった．作業
時間は約30時間であった．

\item 文書ラベルを教師データ作成に用いる手法（以下，文書ラベル）

本実験で使用しているレビューデータには，本研究でいうク
レームとほぼ同等の概念を示している「苦情」というラベル
がレビュー単位に付与されている．
そこで，ここでは，文よりも粗い文書に対する教師情報を利
用して，文単位の教師データを自動生成することを考える
\cite{nigam2004a}．
具体的には，「苦情」ラベルが付与されたレビューに含まれ
ている全ての文をクレーム文とみなし，逆に，「苦情」ラベ
ルが付与されていないレビューに含まれている全ての文を非
クレーム文とみなすことで教師データを自動生成し，モデル
学習に用いる．
モデルは先と同様の理由で通常のナイーブベイズ・モデルを
用いる．
提案手法と比べると，この手法では相対的に質は低いが，大
量の学習データが利用できる．

\item 辞書による手法

この手法は教師あり学習は行わず，辞書のエントリをルー
ルとみなしたルールベース手法である．評価用データに対し
て\sec{data_core}で述べた核文ラベル付け，および
\sec{data_context}で述べた近接文ラベル付けの手続きを直
接適用してクレーム文を検出する．ただし，ここでの焦点は
データ生成時とは違って，クレーム文を検出できるか否かで
あるため，ラベル付けの結果，クレームとラベル付けされた
文以外は全て非クレームであるとみなして評価した．
なお，辞書は\sec{setting}で述べた辞書を用いる．

\end{itemize}

実験結果を\fig{baseline}に示す．また，\tab{data}に提案
手法のラベル付けと人手ラベル，文書ラベルの各手法による
ラベル付けの特徴をまとめる．

\begin{figure}[b]
 \begin{center}
 \includegraphics{20-5ia3f5.eps}
 \end{center}
 \caption{実験結果（他手法との比較）}
 \label{fig:baseline}
\end{figure}
\begin{table}[b]
 \caption{各ラベル付け手法で生成される教師データの特徴}
 \label{tab:data}
\input{03table03.txt}
\end{table}

\fig{baseline}において，辞書による手法は，ナイーブベイ
ズモデルを用いた分類時に導入した閾値のパラメータが存在
しないため，11 点平均適合率を計算できない．そのため，こ
こでは再現率と適合率によって分類性能を評価している．
なお，図中の``提案ラベル''が提案手法の結果であり，さき
ほどの評価実験で最良であった拡張モデルNB+ctxBF(divide)
で文脈長$N=2$の実験結果を掲載している．
また，``辞書（核）''は，辞書による手法のうち，核文ラベ
ル付けのみを考慮した場合の結果であり，``辞書（核+近
  接）''が，核文ラベル付けと近接文ラベル付けの両方を考
慮した場合の結果である．

\fig{baseline}から，比較したどの手法よりも提案手法が良
い性能を示していることがわかる．
辞書による方法は，辞書に登録されている単語が含まれてい
ない文に対しては適用できないため，再現率が低い．近接文
を考慮することである程度の再現率を確保することは可能で
あるが，当然ながらその代償として適合率が下がる結果となっ
ている．
ここで，固有表現抽出課題がそうであるように，一般に，辞
書に基づいた手法では再現率が低くなるがその一方で適合率
が高くなる傾向がある．近接文の情報を用いない``辞書
（核）'' の結果は特にその傾向を示している．ただし，今回
の実験結果では，再現率を固定させて適合率を見ると，ナイー
ブベイズ・モデルを用いた手法の方が適合率がより高い結果
となっていた．これは，本研究課題では，辞書に登録されて
いる一部の単語の情報だけでは文全体のクラス（クレーム／
  非クレーム）が正しく決定できない場合があり，このよう
な場合には，辞書による方法よりも文内の単語情報を総合的
に考慮できるナイーブベイズ・モデルが適していたためと考
えられる．

次に，文書ラベルを利用する方法は，文書内のすべての文を
教師データとして利用できる．そのため，提案手法と同程度
かそれ以上の教師データが利用できるという特徴がある．し
かし，文書内には一般的にクレームと非クレームが混在する
ことから，文書ラベルと整合していない信頼性の低いデータ
を多く含む結果となり，そのことが性能の低下に繋がってい
ると考えられる．
最後に，人手作成による方法は，もっとも質の高い教師デー
タを準備することができるが，作成負荷の高さから，量を確
保することが難しい．今回は人手で2,000件（8,639 文）のレ
ビューから教師データを作成したが，提案手法を上回ること
はなかった．


\subsection{学習データとクレーム文検出精度の関係について}
\label{sec:exp_size}

先でも述べたように，一般に，人手作成された教師データは
質が高い反面，多くの量を準備することが困難である．一方，
提案手法のように自動生成された教師データは人手作成され
たデータよりも質が落ちるが，ラベルのない生データを準備
するだけで手軽に増量できる．
ここでは，人手によって教師データを作成する場合と第
\sec{gen}の提案手法によって教師データを自動生成する場合
のそれぞれについて，教師データの量と分類性能の関係を調
査する．
なお，両者で教師データ以外の実験条件を合わせるために，
この実験では，モデルには通常のナイーブベイズ・モデルを
用いた．


実験結果を\fig{datasize}に示す．横軸が学習データ量（対
  数スケール）であり，縦軸が11点平均適合率である．
どちらの実験結果についても，まず今回の実験において最大
で利用可能なデータ量（人手ラベルの場合：レビュー2,000件，
  提案ラベルの場合：レビュー約347,000件）から性能測定を
開始し，そこから一部の学習データを無作為に削除すること
で使用できる学習データ量がより少ない環境を設定して，こ
れを繰り返しながらグラフをプロットした．

\begin{figure}[t]
 \begin{center}
 \includegraphics{20-5ia3f6.eps}
 \end{center}
 \caption{教師データ量の影響}
 \label{fig:datasize}
\end{figure}

\fig{datasize}から，まず，どちらの手法においてもデータ
量を増やすことで性能が向上することが確認できる．データ
量が同じ場合は，当然のことながら，人手による方法の方が
良い性能となる．しかし，提案手法によってデータ量を増加
させることで，今回の場合は10,000件までデータ量を増やし
た時点で両者の性能が同等となり，さらにデータ量を増やす
ことで提案手法が人手による手法を上回ることができた．

この実験結果は，あくまでひとつのケース・スタディであり，
具体的な数値自体に意味を求めることは困難であると考えられる．
しかし，この結果は，人手によって十分な教師データが作成
できない状況においては，自動生成手法を適用することで得
られる教師データの量的利点という恩恵を受けられることを
示唆していると言える．


\section{関連研究}
\label{sec:related}

従来から，評判分析に関する研究を中心にして，意見を好評／
不評に分類する研究が多くなされている\cite{sa2} ．しかし，
本論文では，応用面を重視した際，主に製品やサービスを提
供する企業にとっては意見の好不評という側面だけでは十分
でないことから，クレームという好不評とは異なる観点を導
入し，意見を含むテキストからクレームという特定の意見を
検出する手法について述べた．
我々と同様に好評／不評以外の意見に着目した研究には，第
\sec{hajimeni}で述べた永井らの研究\cite{nagai1,nagai2}
の他にも幾つか存在する．
例えば，金山ら\cite{kanayama2005a}は，テキストから好評／
不評の評判に加えて要望を抽出する手法を提案している．彼
らの手法は，文に含まれる評判や要望を意図フレームと呼ば
れる独自の形式に自動的に変換しつつ抽出するようになって
おり，この変換・抽出処理において，既存の機械翻訳機構を
再利用している．
彼らの抽出対象である評判，要望の中に本研究におけるクレー
ムも含まれていると考えられるが，彼らの手法は，機械翻訳
機構が内部的に備える各種の言語知識のもとに成立しており，
運用には人手による多大な管理負荷を要すると考えられる．
一方で，本研究では極力人手の負荷を軽減することを指向し
ており，金山らの手法とはアプローチの方向性が異なる．
また，他の関連研究として，自由記述アンケートから要求や
要望を判定することに特化した大塚ら\cite{otsuka2004a} や
山本ら\cite{yamamoto2006a}の研究がある．彼らの論文中に
定義がないため厳密にはよくわからないが，彼らの扱ってい
る要求や要望といった意見の分類クラスは，我々のクレーム
の一部分に該当すると考えられる．
Goldbergら\cite{goldberg2009a}は，新年の願い事が集めら
れたテキストコーパスからWish（願望）を機械学習を用いて
自動抽出する研究を行っている．

本研究では，レビュー中の各文をクレーム／非クレームに分
類する課題に対して，ナイーブベイズ・モデルを採用し，デー
タ特性に合わせて，その拡張を行った．拡張モデルでは，
文間の周辺文脈をモデルに適切に反映させることができる．
ここで，文書中の各文を対象とした分類問題を，文書中の文
系列に対するラベリング問題とみなすことで，条件付確率場
(Conditional Random Fileds; CRF) \cite{lafferty2001a}
のような，より高度なモデルを適用することについて検討す
る．
まず，\sec{gen}で述べたデータ生成過程では，文書内のすべ
ての文に対してラベルを付与するわけではなく，ある特定の
文のみにラベルを付与することで教師データを作成する．そ
のため，CRFのような系列の構成要素についての全てのラベル
を必要とするようなモデルは本研究の設定では直接は適用で
きない．
坪井ら\cite{tsuboi2009a} によって，部分的なアノテーショ
ン情報からCRFの学習を行う手法が提案されており，この手法
を適用することは不可能ではないが，彼らの手法を適切に適
用するにあたり，アノテーションされている部分は人手によ
る信頼性の高い情報であるという暗黙的な仮定が必要である
と考えられ，データの自動生成を前提とする本研究の設定と
は相性が良くないと考えられる．


\section{おわりに}
\label{sec:owarini}

本論文では，レビュー文書からクレームが記述された文を自
動検出する手法として，極力人手の負荷を軽減することを指
向した次の 2 つの手法を提案した．
(1) 評価表現と文脈一貫性に基づく教師データ自動生成手法．
(2) 自動生成された教師データの特性を踏まえたナイーブベイズ・モデルの拡張手法．
そして，評価実験を通して，これらの提案を組合せ，検出対象となる
文の周辺文脈の情報を適切に捉えることで，クレーム文の検
出精度を向上させることができることを示した．
また，人手によって十分な教師データが作成できない状況に
おいては，提案したデータ自動生成手法を適用することで得
られる教師データの量的恩恵を受けられることを示した．

本論文で議論ができなかった今後の課題としては，以下のよ
うな項目があげられる．

\begin{itemize}
\item 分類クラスの事前分布について：
ナイーブベイズ・モデルでは，\eq{eq1}にあるように，分類
クラスの事前分布$P(c)$の情報を考慮する．しかし，本研究
のように教師データを自動生成する際は事前分布$P(c)$はデー
タ自動生成手法に依存しており，本研究の場合では，利用す
る評価表現辞書の特徴に依存することになる．
今後，評価表現辞書および事前分布$P(c)$と検出性能との関
係について考察することが必要である．

\item 各種のパラメータ調整について：
本研究において，幾つかのパラメータは恣意的に指定してい
る．例えば，考慮する周辺文脈の長さについて評価実験では
可変させていたが，それらは，データ生成，モデル学習，分
類の各過程で同期させている．しかし，原理的にはデータ生
成時のみ文脈長を延長するといった設定も可能であり，これ
らの最適な調整は今後の課題である．

\item 学習アルゴリズムについて：
本研究では基本モデルとしてナイーブベイズ・モデルを採用
して議論を進めたが，同様の議論を Support Vector
Machine (SVM) \cite{vapnik1995a} のような別の学習アルゴ
リズムを用いて行うことも興味深い．ただし，SVMにはモデル
の学習速度が遅いという欠点がある．そのため，提案手法の
利点である大規模な教師データを自動生成できるという点を
活かすためにはSVMの高速学習を含めた総合的な検討が必要で
ある．

\item クレームの内容分類について：
本研究はクレーム検出をクレームであるか否かという 2 値分
類問題として扱った．しかし，実利用環境で検出されたクレー
ムを企業内で活かしていくには，クレーム内容も合わせて自
動分類できることが望ましい．例えば，対象が宿泊施設の場
合では，「部屋」や「食事」といったクレームの対象に関す
る分類クラスを別途設定し，これらも同時に考慮した検出モ
デルを検討することも興味深い．

\item 見逃し状況について：
クレームを見逃す状況として，本論文では，レビュー文書内
に部分的に現れるクレームの見逃しについて扱った．しかし，
第\sec{hajimeni}でも述べたように，多対一型のコミュニケー
ションに起因する見逃しへの対処も重要である．今後，多対
一型のコミュニケーションに起因する見逃しに対する提案手
法の適用可能性についても検討したい．

\end{itemize}



\acknowledgment

本研究を遂行するにあたり，楽天株式会社楽天技術研究所の
新里圭司氏，平手勇宇氏，山田薫氏から示唆に富む多くの助
言を頂きました．諸氏に深く感謝いたします．また，実験に
あたり，楽天トラベル株式会社から施設レビューデータを提
供して頂きました．ここに記して感謝の意を表します．

\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Goldberg, Fillmore, Andrzejewski, Xu, Gibson, \BBA\
  Zhu}{Goldberg et~al.}{2009}]{goldberg2009a}
Goldberg, A.~B., Fillmore, N., Andrzejewski, D., Xu, Z., Gibson, B., \BBA\ Zhu,
  X. \BBOP 2009\BBCP.
\newblock \BBOQ May All Your Wishes Come True: A Study of Wishes and How to
  Recognize Them.\BBCQ\
\newblock In {\Bem Proceedings of the Human Language Technology Conference and
  the North American Chapter of the Association for Computational Linguistics},
  \mbox{\BPGS\ 263--271}.

\bibitem[\protect\BCAY{乾\JBA 奥村}{乾\JBA 奥村}{2006}]{inui}
乾孝司\JBA 奥村学 \BBOP 2006\BBCP.
\newblock テキストを対象とした評価情報の分析に関する研究動向.\
\newblock \Jem{自然言語処理}, {\Bbf 13}  (3), \mbox{\BPGS\ 201--241}.

\bibitem[\protect\BCAY{金山\JBA 那須川}{金山\JBA 那須川}{2005}]{kanayama2005a}
金山博\JBA 那須川哲哉 \BBOP 2005\BBCP.
\newblock 要望表現の抽出と整理.\
\newblock \Jem{言語処理学会第 11 回年次大会発表論文集}, \mbox{\BPGS\ 660--663}.

\bibitem[\protect\BCAY{Lafferty, McCallum, \BBA\ Pereira}{Lafferty
  et~al.}{2001}]{lafferty2001a}
Lafferty, J., McCallum, A., \BBA\ Pereira, F. \BBOP 2001\BBCP.
\newblock \BBOQ Conditional random fields: Probabilistic models for segmenting
  and labeling sequence data.\BBCQ\
\newblock In {\Bem Proceedings of the 29th Internatinal Conference on Machine
  Learning}, \mbox{\BPGS\ 282--289}.

\bibitem[\protect\BCAY{Manning \BBA\ Schutze}{Manning \BBA\ Schutze}{1999}]{nv}
Manning, C.~D.\BBACOMMA\ \BBA\ Schutze, H. \BBOP 1999\BBCP.
\newblock {\Bem Foundations of Statistical Natural Language Processing}.
\newblock The MIT Press.

\bibitem[\protect\BCAY{Manning, Raghavan, \BBA\ Schutze}{Manning
  et~al.}{2008}]{iir}
Manning, C.~D., Raghavan, P., \BBA\ Schutze, H. \BBOP 2008\BBCP.
\newblock {\Bem Introduction to Information Retrieval}.
\newblock Cambridge University Press.

\bibitem[\protect\BCAY{永井\JBA 高山\JBA 鈴木}{永井 \Jetal }{2002}]{nagai1}
永井明人\JBA 高山泰博\JBA 鈴木克志 \BBOP 2002\BBCP.
\newblock 単語共起照合に基づくクレーム抽出方式の改良.\
\newblock \Jem{情報科学技術フォーラム}, \mbox{\BPGS\ 113--114}.

\bibitem[\protect\BCAY{永井\JBA 増塩\JBA 高山\JBA 鈴木}{永井 \Jetal
  }{2003}]{nagai2}
永井明人\JBA 増塩智宏\JBA 高山泰博\JBA 鈴木克志 \BBOP 2003\BBCP.
\newblock インターネット情報監視システムの試作.\
\newblock \Jem{情報処理学会研究報告. 自然言語処理研究会報告}, {\Bbf 2003}
  (23), \mbox{\BPGS\ 125--130}.

\bibitem[\protect\BCAY{那須川\JBA 金山}{那須川\JBA 金山}{2004}]{nasukawa}
那須川哲哉\JBA 金山博 \BBOP 2004\BBCP.
\newblock 文脈一貫性を利用した極性付評価表現の語彙獲得.\
\newblock \Jem{情報処理学会研究報告. 自然言語処理研究会報告}, {\Bbf 2004}
  (73), \mbox{\BPGS\ 109--116}.

\bibitem[\protect\BCAY{Nigam \BBA\ Hurst}{Nigam \BBA\ Hurst}{2004}]{nigam2004a}
Nigam, K.\BBACOMMA\ \BBA\ Hurst, M. \BBOP 2004\BBCP.
\newblock \BBOQ Towards a Robust Metric of Opinion.\BBCQ\
\newblock In {\Bem AAAI Spring Symposium on Exploring Attitude and Affect in
  Text: Theories and Applications}, \mbox{\BPGS\ 98--105}.

\bibitem[\protect\BCAY{大塚\JBA 内山\JBA 井佐原}{大塚 \Jetal
  }{2004}]{otsuka2004a}
大塚裕子\JBA 内山将夫\JBA 井佐原均 \BBOP 2004\BBCP.
\newblock 自由回答アンケートにおける要求意図判定基準.\
\newblock \Jem{自然言語処理}, {\Bbf 11}  (2), \mbox{\BPGS\ 21--66}.

\bibitem[\protect\BCAY{Pang \BBA\ Lee}{Pang \BBA\ Lee}{2008}]{sa2}
Pang, B.\BBACOMMA\ \BBA\ Lee, L. \BBOP 2008\BBCP.
\newblock {\Bem Opinion Mining and Sentiment Analysis - Foundations and Trends
  in Information Retrieval Vol.2, Issue 1-2}.
\newblock Now Publishers Inc.

\bibitem[\protect\BCAY{高村\JBA 乾\JBA 奥村}{高村 \Jetal }{2006}]{takamura}
高村大也\JBA 乾孝司\JBA 奥村学 \BBOP 2006\BBCP.
\newblock スピンモデルによる単語の感情極性抽出.\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 47}  (2), \mbox{\BPGS\ 627--637}.

\bibitem[\protect\BCAY{坪井\JBA 森\JBA 鹿島\JBA 小田\JBA 松本}{坪井 \Jetal
  }{2009}]{tsuboi2009a}
坪井祐太\JBA 森信介\JBA 鹿島久嗣\JBA 小田裕樹\JBA 松本裕治 \BBOP 2009\BBCP.
\newblock
  日本語単語分割の分野適応のための部分的アノテーションを用いた条件付確率場の学習.\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 50}  (6), \mbox{\BPGS\ 1622--1635}.

\bibitem[\protect\BCAY{Vapnik}{Vapnik}{1995}]{vapnik1995a}
Vapnik, V.~N. \BBOP 1995\BBCP.
\newblock {\Bem The Nature of Statistical Learning Theory}.
\newblock Springer.

\bibitem[\protect\BCAY{山本\JBA 乾\JBA 高村\JBA 丸元\JBA 大塚\JBA 奥村}{山本
  \Jetal }{2006}]{yamamoto2006a}
山本瑞樹\JBA 乾孝司\JBA 高村大也\JBA 丸元聡子\JBA 大塚裕子\JBA 奥村学 \BBOP
  2006\BBCP.
\newblock 文章構造を考慮した自由回答意見からの要望抽出.\
\newblock \Jem{言語処理学会第 12
  回年次大会併設ワークショップ「感情・評価・態度と言語」}.

\end{thebibliography}


\begin{biography}
\bioauthor{乾　　孝司}{
2004年奈良先端科学技術大学院大学情報科学研究科博士課程
修了．日本学術振興会特別研究員，東京工業大学統合研究院
特任助教等を経て，2009年筑波大学大学院システム情報工学研究科
助教．現在に至る．博士（工学）．近年はCGMテキストに対する評判分析に興味をもつ．
}
\bioauthor{梅澤　佑介}{
2011 年筑波大学情報学群情報メディア創成学類卒業．2013
年筑波大学大学院システム情報工学研究科コンピュータサイ
エンス専攻修了．同年4 月から株式会社ヤフー．在学中は
自然言語処理の研究に従事．
}
\bioauthor{山本　幹雄}{
1986年豊橋技術科学大学大学院修士課程修了．
同年株式会社沖テクノシステムズラボラトリ研究開発員．
1988年豊橋技術科学大学情報工学系教務職員．1991年同助手．
1995年筑波大学電子・情報工学系講師．1998年同助教授．
2008年筑波大学大学院システム情報工学研究科教授．
博士（工学）．自然言語処理の研究に従事．
言語処理学会，人工知能学会，ACL各会員．
}
\end{biography}

\biodate



\end{document}
