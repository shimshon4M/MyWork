    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline


\Volume{20}
\Number{2}
\Month{June}
\Year{2013}

\received{2012}{6}{8}
\revised{2012}{9}{20}
\rerevised{2012}{11}{30}
\accepted{2013}{1}{11}

\setcounter{page}{105}

\jtitle{新聞記事中の難解語を平易な表現へ変換する手法の提案}
\jauthor{芋野美紗子\affiref{Author_1} \and 吉村枝里子\affiref{Author_2} \and 土屋　誠司\affiref{Author_2} \and 渡部　広一\affiref{Author_2}}
\jabstract{
ロボットと人間の双方でより円滑なコミュニケーションを行うためには，ロボットにも人間のような会話能力が求められると考える．人間の会話はあいさつや質問応答，提案，雑談など多岐に渡るが，ロボットがこういった会話，例えば何かしらの情報を持った雑談のように能動的な会話を行うには，新聞記事のようなリソース中の表現を会話テンプレートに埋め込むという方法が考えられる．しかし新聞記事中の語と会話に用いられる語の馴染み深さには違いがある．例えば新聞記事中の「貸与する」という語は，会話に用いる場合には「貸す」という表現の方が自然である．つまり，人間にとって違和感のない会話のためのリソースとして新聞記事を用いるには，難解語を平易な表現へ変換する必要があると考える．そこで本稿ではロボットと人間との自然な会話生成を担う技術の一端として，新聞記事中の難解な語を会話表現に見あった平易な表現へと変換する手法を提案する．提案手法では人間が語の変換を行う際の処理になぞらえ，1つの語を別の1語で変換する1語変換および文章で変換する$N$語変換を組み合わせることでより人間にとって自然に感じる変換を行い，その有効性を示した．結果として変換すべき難解語を75.7\%の精度で平易な表現に，81.1\%の精度で正しい意味を保持した表現に変換することが出来た．
}
\jkeywords{変換，語概念連想，概念ベース，関連度計算方式，記事関連度計算方式}

\etitle{Proposal of a Method to Convert Difficult Words in Newspaper Articles to Plain Expressions}
\eauthor{Misako Imono\affiref{Author_1} \and Eriko Yoshimura\affiref{Author_2} \and Seiji Tsuchiya\affiref{Author_2} \and \\Hirokazu Watabe\affiref{Author_2}} 
\eabstract{
To smoothen the communication between robots and humans, robots must have human-like conversational abilities. Humans converse in various ways: greetings, question-answers, suggestions, and chatting, among others. Thus, methods that extract expressions from resources such as newspaper articles and embed them into the conversation template are viewed as a way to let individuals participate in active conversations, such as chat with some information by robot. However, there is a difference in the degree of difficulty of the words used in newspaper articles and the ones used in a conversation. Words in newspaper articles are generally more difficult than those used in a conversation. Hence, it is important to convert difficult words in newspaper articles to plain expressions when using newspaper articles as a resource for a robot's conversation, in order to avoid human discomfort. This paper suggests a method of converting difficult words to plain expressions, considering the differences in the degree of difficulty of words used in newspapers and in a conversation. The proposed method aims to convert feels natural for human by combining two approaches: a method that converts one word to another and a method that converts one word to a sentence. The results show that the proposed method converts words in newspaper articles from difficult to plain expressions with an accuracy of 75.7\% and converts words while retaining their meaning with an accuracy of 81.1\%. Therefore, the proposed word conversion method is found to be effective.
}
\ekeywords{Word Transfer Technique, Word Concept Association, Concept Base, Degree of Association}

\headauthor{芋野，吉村，土屋，渡部}
\headtitle{新聞記事中の難解語を平易な表現へ変換する手法の提案}

\affilabel{Author_1}{同志社大学大学院工学研究科}{Graduate School of Engineering, Doshisha University}
\affilabel{Author_2}{同志社大学理工学部}{Faculty of Science and Engineering, Doshisha University}



\begin{document}
\maketitle


\section{はじめに}
\label{First}

ロボットと人間との関係は，今後大きく変化していくと考える．今までのような単純な機械作業だけがロボットに求められるのではなく，例えば施設案内や介護現場のサポート，愛玩目的，ひいては人間と同じようにコミュニケーションを行うパートナーとしての存在も要求されると考える．このとき，人間との円滑なコミュニケーションのために必要不可欠となるのが会話能力である．あいさつや質問応答，提案，雑談といった様々な会話を人間のように行えてこそ，自然なコミュニケーションが実現すると考える．ロボットがこういった会話，とくに提案や雑談といった能動的なものを行うためにはそのためのリソースが必要である．例えば日々の時事情報が詰まった新聞などは，情報量の多さや入手の手軽さ，話題の更新速度などから言っても適当なリソースといえる．この新聞記事によって与えられる時事情報を会話の話題として利用することは，ロボットに人間らしい会話を行わせるためには有効なのではないかと考えた．

新聞記事を利用した会話をロボットに行わせる最も簡単な方法は，新聞記事表現を会話テンプレートに埋め込むといったものと考える．このとき問題になるのが新聞記事表現の難解さである．新聞のように公に対して公開される文章は短い文で端的に内容を表すため，馴染みの薄い難解な言葉，俗にいう「堅い」言葉を多く使う．これらの言葉は文章として読むには違和感はないが，会話に用いるには自然ではないことが多い．例えば「貸与する」という言葉は会話では「貸す」という言い方をするほうが自然である．また，一般的にはそう難解ではない言葉，例えば「落下した」という言葉も会話ということを考えると「落ちた」のような更に易しい表現の方が馴染みやすいと感じる．つまり会話に用いられる言葉と新聞といった公的な文中に用いられる言葉の間には，同じ意味を表すにしても難易度や馴染みの深さに違いがある．ロボットの発話リソースとして新聞を用いることを考えると，このような語の馴染みの違いに考慮しなければならない．そこで本稿ではロボットと人間との自然な会話生成を担う技術の一端として，新聞記事中の難解な語を会話表現に見あった平易な表現へと変換する手法を提案する．

本稿では変換後の記事をより人間にとって違和感の無いものとするために，人間が自然に行う語の変換に則った処理を提案する．つまり，語をそれと同じもしくは近い意味の別の平易な1語に変換する1：1の変換処理（1語変換）および語を平易な文章表現に変換する1：$N$の変換処理（$N$語変換）の双方を併用することで人間が自然だと感じる語の変換を目指す．語の難解さ，平易さの判断には\cite{Book_01}で報告されている単語親密度を用いる．これは語の「馴染み深さ」を定量化した数値であり，新聞記事に用いられる語と一般的な会話に用いられる語の間にある単語親密度の差を調査することで新聞記事中の難解語を自動的に判断，平易な表現への変換を可能とする．また，変換処理を行う上で重要な意味の保持に関しては，人間の連想能力を模倣した語概念連想を用いることでそれを実現する．語と語，文と文の間の意味関係を柔軟に表現することを目指した語概念連想の機構を利用することで，変換前の記事が持つ意味を考慮した変換を行う．


\section{関連研究と本研究の特徴}
\label{Second}

文中の語を他の表現に変換に関する研究は数多くなされており，平易な表現への変換技術そのものとしての研究\cite{Article_02}やWeb検索への利用を目的とした複数パターンの変換の生成\cite{Article_13}，利用者の言語能力に配慮した平易化\cite{Article_01,Article_12,Article_16}，会話への利用\cite{Article_15}といった形で報告が成されている．これらの研究においても，語の表現を変換するためのアプローチとして\ref{First}章で述べたような1：1の変換処理および語を文によって表現する1：{$N$}の変換処理が挙げられている．

1：1の変換については，例えば\cite{Article_01}では児童向け新聞の記事と一般の新聞記事との間でベクトル空間モデルによるマッチングを取り，同一内容の記事の対から1語対1語の変換対を作成している．また\cite{Article_13}ではWebを用いて入力された文字列中の語の変換候補を生成している．変換対象となる語（名詞，形容詞，動詞，カタカナ語）を入力から取り除いた文字列を用いてWeb検索を行うことで，変換対象の語があった場所に入る他の語を取得することが出来る．対して\cite{Article_02}の報告では，国語辞典の定義文を変換に用いる1：$N$の変換処理が報告されている．定義文を変換に適した形の文に整形するルールを策定し，日本語として違和感の無い変換を行うことを目指している．

これらの変換処理はそれぞれ，1：1の変換処理および1：$N$の変換処理を単独で行っているが，本稿で提案する手法はこの双方を組み合わせることでより人間の思考に沿った変換処理を提案できると考える．人間がある語の変換を行う際には，まず別の1語に言い換えることができないかを考える．これは変換の対象となる語の同義語や類義語によって行うことが可能である．しかし同義語や類義語を持たない語も数多く存在することを考えると，この1：1の変換では不十分である．また私たちの行う会話では，1つの語の変換に文を用いる場合も多々考えられる．これは分かりにくい語が出現した場合にその語の「意味を説明する」ことで語の変換を行っている．例えば「明言」という語ならば，同じ意味を持つ一語を探すよりも「はっきりと言い切る」という文による変換が自然である．1つの語に対して文，つまり$N$個の語による変換という機能が無ければ，人間の会話に近い自然な変換はできない．

\cite{Article_12}や\cite{Article_16}では，本稿と同じく1：1の変換と1：$N$の変換の組み合わせについて述べられている．例えば\cite{Article_12}では対象となる文章を自治体のWebページに固定し，人手による変換対の作成によって語の変換を実現している．変換対はシソーラスや国語辞典の定義文を人の目で参照して作成しており，よってある語を変換するための対は1語である場合もあれば短い文の場合もある． \cite{Article_16}では文化遺産に関する説明文を平易化することを目的として，そのための変換パターンの解析を行っている．この中では専門用語に対して文章による変換で補足を行うパターンや，外来語を同じ意味の日本語へ変換するといった手法により説明文を平易化できると報告している．これらの手法では変換対や変換のためのパターンが人手により作成されるため高精度を期待できるが，それに伴う労力も非常に大きい．また，変換対象を固定しているため作成した変換対やパターンの汎用性に欠けると考えられる．本稿の提案手法では変換のための語や文を既存の辞書資源から自動的に選択するため，労力や汎用性の点で優位性があると考える．

国外でも語の変換に着目した評価型ワークショップ\cite{Article_22,Article_23}が開催され，\cite{Article_24,Article_25,Article_26}といった研究が報告されている．\cite{Article_22}では文章中の英単語1語を別の語で変換するというタスクが設定されており，例えば\cite{Article_24}では変換のための語を得るために$N-gram$，語の出現頻度，Webヒット件数，さらには変換前の文章を他言語に翻訳した後，再度英語に翻訳するなどの様々な手法を組み合わせることで語にポイント付けを行い，変換を実現している．\cite{Article_23}では\cite{Article_22}で示された1語の変換に際してより平易な語を選択するというタスクになっている．例えば\cite{Article_25}では\cite{Article_24}のポイント付けを基礎とし，さらに\cite{Article_27,Article_28}で定義された心理言語学的モデル，例えば語の具体性やイメージアビリティといった側面でスコア付けを行ったデータを用いて平易性の判断を行っている．\cite{Article_26}では語の平易性の判断材料として様々なコーパス内における出現頻度や語の長さを用いている．
これらのタスクにおいても変換の処理は1：1のものが大半であり，英文による変換は行われていない．また，\cite{Article_23}のタスクでは人手で用意された変換の候補となる語に対して平易性のランク付けをすることで変換を行っており，変換の候補となる語の選出は行っていない．候補の選出処理は\cite{Article_24}によって報告されているが，この手法は\cite{Article_22}における総括でも述べられている通り，変換に必要なリソースや処理過程が非常に複雑なものとなっている．前述したとおり，本稿の提案手法では1：1および1：$N$の変換手法を組み合わせることで人間の自然な変換を実現する点，語概念連想を用いることで変換のための語や文を既存の辞書資源から自動的に選択できる点でこれらの研究と比べて優位性があると考える．


\section{難解語の変換手法の概要}

本稿で提案する難解語の変換手法は人間が自然に行う語の変換に沿い，1：1および1：$N$の変換処理を組み合わせることで行う．同義語，類義語を用いた1：1の変換処理（1語変換）と，1つの語を文で変換する1：$N$の変換処理（$N$語変換）によりこれを実現する．また，各変換処理において人間の連想能力を模倣した語概念連想を用いることで，語の表記に依存しない柔軟な語の変換を行う．語と語，文と文の意味的な近さを考慮した変換を行うことで，人間の常識に沿った語の選択や多義性の解消を図ることが出来る．語概念連想の詳しい構造については\ref{Gogainen}章に示す．

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f1.eps}
 \end{center}
 \caption{語変換処理の概要図}
 \label{fig:gaiyouzu}
\end{figure}

図\ref{fig:gaiyouzu}に提案する語変換処理の概要図を示す．入力は新聞記事とし，語の変換処理は句点を区切りとする記事中の1文ずつで行う．入力された記事中から会話に適さない馴染みの薄い語（難解語）を判別し，別の平易な語もしくは文に変換する．

難解語の判別には単語親密度\cite{Book_01}を用いる．単語親密度とは単語に対する馴染みの度合いを主観的に評価した値であり，数値が高いほどより馴染みのある単語であることを示す．これは18歳以上の被験者40名に対して単語を提示し，1から7までの数字で馴染みがあるか否かを評価した結果を平均化することで算出される．表\ref{tab:tansin_rei}に単語親密度の一部を示す．

\begin{table}[b]
\vspace{-1\Cvs}
\caption{単語親密度の例}
\label{tab:tansin_rei}
\input{02table01.txt}
\end{table}

表\ref{tab:tansin_rei}に示した通り，例えば「あいさつ」のようにごく一般的な語は単語親密度が高く，万人にとって馴染みの深い語であることがわかる．一方「サイドマイド」（睡眠薬の一種）は専門的な用語であり，一般的には馴染みが薄く単語親密度も低い値となる．日常的に使用する語とは，万人にとって馴染みのある語であると考える．新聞記事中に現れる「危ぶむ」という表現は，一般的な会話ならば「心配する」程度の表現の方が違和感なく馴染みやすい．つまり馴染みの度合いが高い語ほど会話への利用に適していると考えられる．また単語親密度が高ければ高い語ほど，その語を文字として提示された場合と音声として提示された場合の双方で語彙判断の反応時間が短く認知の誤りも少ないという結果が報告されており\cite{Article_20,Article_21,Book_05}，この事からも単語親密度が高い語ほど会話への利用に適した平易な語であるといえる．そこで本稿では単語親密度が低い語を変換すべき難解語とみなし，平易な表現への変換処理を行う．

難解語と置き換える平易な表現は語の同義・類義関係を示した関係語辞書\cite{Article_10,Article_11}および国語辞書から得る．1語変換においては国語辞典から自動構築された関係語辞書を用いて難解語の同義語・類義語を取得し，これらを変換に用いる語の候補（変換候補語）とする．辞書における同義語はある語と同じ意味を持つ別表記の語，類義語は類似の意味を持ち言い換えることの出来る語と定義されているため，これらの語を用いることで1語変換を行うことができる．$N$語変換では国語辞書を用いて難解語の意味を説明する定義文を取得し，これらを変換に用いる文の候補（変換候補文）とする．

$N$語変換に用いる変換候補文は辞書に記載されているそのままの形で語の変換を行うと，出力される文が日本語として不自然な場合がある．例えば辞書の定義文に出現する「転じて」や「〜の別名」といった言い回しは，そのままの形で変換に用いた場合に不自然さを発生させる要因となる．このような変換に必要の無い語を不要語と定義し，不要語リストを用いてこれらの削除を行う．また，元の記事中の語を定義文で変換した際にWhatやWhoといった文中の情報が重複することによって不自然さが発生する場合がある．そこで意味理解システム\cite{Article_03}を用いて不自然さを排除した上で難解語を文に変換し，会話に適した語句で構成された文を
出力する．


\section{語概念連想}
\label{Gogainen}

一般的に語や文の類似性を計る際には，ベクトル空間モデル\cite{Article_08}のように単語の出現頻度や共起，表記の一致などを利用した手法が往々にとられる．しかし人間はそのような情報に依存することなく，語と語や文と文の間に意味的な関連性を自然と連想し，処理している．そのような人間の連想能力を模倣し，人間らしい柔軟な言葉の意味理解を行う機構として語概念連想が提案されている．

語概念連想は語の意味定義を行う概念ベース\cite{Article_04}と，語と語の間の関連性を定量的に表現する手法である関連度計算方式\cite{Article_05}，そしてヒッチコック型輸送問題\cite{Book_06}で計算される距離尺度であるEarth Mover's Distance (EMD)を用いた記事関連度計算方式\cite{Article_06}を有する，人間の連想能力を表現した機構である．語概念連想に関する研究報告ではベクトル空間モデルといった従来手法と比べてその有効性が示されている\cite{Article_05}．

本稿では語の変換を行う際に，元の語と変換の候補となる語（変換候補語）との間の意味的な近さを考慮するために語概念連想を用いる．具体的には，まず1語変換においては複数得られる可能性のある同義語・類義語の中から最も元の語に近い意味を持つ変換候補語を選別するために関連度計算方式を用いる．次に$N$語変換においては多義性の解消のためにEMDを用いた記事関連度計算方式を用いる．これは難解語が多義語であった場合に辞書の定義文が複数取得されるため，文書間の関連性を定量化することで元の記事と最も関連の強い定義文を判別し，意味の特定を図るものである．

以下に概念ベース，関連度計算方式，EMDを用いた記事関連度計算方式について述べる．



\subsection{概念ベース}

概念ベースは複数の電子化国語辞書などの見出し語を概念と定義し，見出し語の定義文に使われる自立語群を概念の特徴を表す属性として構築された知識ベースである．本稿で使用した概念ベースは自動的に概念および属性を構築した後に人間の常識に沿った属性の追加や削除を行ったものであり，概念は87,242語となっている．

概念ベースのある概念$A$は，$m$個の属性$a_i$と，その属性の重要性を表す重み$w_i$の対によって次のように表現される．
\[
 \text{概念} A=\{(a_1, w_1), (a_2, w_2), \cdots , (a_m, w_m)\}
\]

概念$A$の意味定義を行う属性$a_i$を，概念$A$の一次属性と呼ぶ．概念ベースの特徴として，属性を成す単語群も概念ベースの中で概念として定義されている点がある．つまり属性$a_i$を概念とみなして更に属性を導くことができる．概念$a_i$から導かれた属性$a_i{}_j$を，元の概念$A$の二次属性と呼ぶ．概念ベースの具体例を表\ref{tab:gainenrei}に示す．

\begin{table}[t]
\caption{概念ベースの例}
\label{tab:gainenrei}
\input{02table02.txt}
\end{table}

例えば「医者」という概念が持つ属性「患者」は，概念「患者」としても定義されている．この概念「患者」の持つ「病人，看病，治療，…」といった属性群が，元の概念「医者」の二次属性ということになる．



\subsection{関連度計算方式}
\label{DOA}

関連度計算方式は概念ベースの特徴である属性の連鎖的構造を活用して，高い精度で概念間の関連性を定量化することが可能である．概念をベクトルで表現し，概念間の関連性をベクトル内積により算出した場合と比較しても，関連度計算方式は高い精度となっており，概念間の関連性の定量化における関連度の有効性が示されている\cite{Article_05}．以下に関連度計算方式の具体的な処理を述べる．

関連度計算方式では2つの概念間の関連性を関連度という値で定量的に表現する．関連性を算出する概念の二次属性を用いて，それぞれの一次属性を最も関連が強いもの同士で対応付けを行った上で算出する．以下に，概念$A$と概念$B$の関連度$DoA(A,B)$の算出方法について示す．
概念$A$および概念$B$の一次属性をそれぞれ$a_i$, $b_i$とし，対応する重みを$u_i$, $v_i$とする．それぞれが持つ属性数が$L$個と$M$個($L\leq M$)とすると，概念$A$, $B$はそれぞれ以下のようになる．
\begin{gather*}
 \text{概念} A=\{(a_1, u_1), (a_2, u_2), \cdots , (a_L, u_L)\} \\
 \text{概念} B=\{(b_1, v_1), (b_2, v_2), \cdots , (b_M, v_M)\}
\end{gather*}

なお，このとき各概念の属性の重みを，その総和が1.0となるよう正規化している．

ここで一次属性の数が少ない概念$A$の属性の並びを固定する．その上で概念$B$の各一次属性を対応する概念$A$の各一次属性との一致度$DoM(A,B)$の合計が最大になるように並べ替える．ただし，概念$A$の属性と対応付けされなかった属性については無視する．
\[
 \text{概念} B=\{(b_{x1}, v_{x1}), (b_{x2}, v_{x2}), \cdots ,(b_{xL}, v_{xL})\}
\]

このとき，概念$A$と概念$B$の関連度$DoA(A,B)$は，
\begin{equation}
 \mathit{DoA}(A,B)=\displaystyle{\sum_{i=1}^{L}\mathit{DoM}(a_i,b_{xi})\times\frac{(u_i+v_{xi})}{2}\times\frac{\mathit{min}(u_i,v_{xi})}{\mathit{max}(u_i,v_{xi})}}
\end{equation}
と定義する．ここで$\mathit{min}(u_i,v_{xi})$は$u_i$と$v_{xi}$を比較して小さい値を，$\mathit{max}(u_i,v_{xi})$は大きい値を指す．

なお，一致度$\mathit{DoM}(A,B)$は以下のように定義する．
\begin{equation}
\mathit{DoM}(A,B)=\displaystyle{\sum_{a_i=b_j}^{}\mathit{min}(u_i,v_j)}
\end{equation}

$a_i=b_j$は属性が表記的に一致した場合を示している．つまり一致度とは概念$A$と概念$B$双方が共通して持つ属性の内，小さいほうの重みを足し合わせたものとなる．共通した属性は概念$A$と概念$B$でそれぞれ重みが付与されており，このうち小さいほうの重み分は概念$A$と概念$B$両方の属性に有効であると考えるためである．



\subsection{EMDを用いた記事関連度計算方式}
\label{EMD}

EMDを用いた記事関連度計算方式は，ヒッチコック型輸送問題\cite{Book_06}（需要地の需要を満たすように供給地から輸送を行う際の最小輸送コストを解く問題）で計算される距離尺度であるEMDを文書検索へ適用したもので，2つの記事間の関連性を定量的に表現することが可能であり\cite{Article_06}によりその有用性が報告されている．

EMDとは2つの離散分布があるときに一方からもう一方の分布への変換を行う際の最小コストを指す．離散分布はそれを構成する要素と重みの対の集合で表現され，コスト算出の際には変換前の離散分布の要素が持つ重みを供給量，変換先の離散分布の要素が持つ重みを需要量と考え，要素間の距離を供給量，需要量にしたがって重みを運送すると考える．できるだけ短い距離で，かつ需要量に対して効率的に重みを運送する経路がEMDとなる．これを文書検索に適応させる際には，文章中の自立語（名詞，動詞，形容詞）を要素として捉え，自立語の集合を離散分布と考える．ある文章の離散分布を違う文章の離散分布へ変換すると考えると，その際のコストが最小となる文章が元の文章に最も近い文章となり文書検索へ適用することが可能となる．
EMDを用いた記事関連度計算方式について，以下の図\ref{fig:EMD}に示すような簡略図を用いて説明する．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f2.eps}
 \end{center}
 \caption{EMDによる記事関連度計算方式}
 \label{fig:EMD}
\end{figure}

ある文書$A$と$B$があったとき，文書$A$を文書$B$に変換する際のコストを考える．それぞれの文書を文中の自立語$\mathit{Word}_{Ai}，\mathit{Word}_{Bj}$の離散分布と考える．まず自立語それぞれには重みの付与を行うが，本稿では$tf・idf$の考え方を用いた．

語の網羅性である$tf$は，文書$A$中に出現する語$\mathit{Word}_{Ai}$の頻度$\mathit{tfreq}(\mathit{Word}_{Ai}, A)$を文書$A$中のすべての語数$\mathit{tnum}(A)$で割ったものを利用する．算出式は以下のようになる．
\begin{equation}
\mathit{tf}(\mathit{Word}_{Ai}, A)=\frac{\mathit{tfreq}(\mathit{Word}_{Ai}, A)}{\mathit{tnum}(A)}
\end{equation}

次に語の特定性である$idf$については，概念ベース$idf$\cite{Article_09}を用いた．概念ベースは一次属性，二次属性，というように$N$次までの属性の連鎖集合を持つ．この$N$次まで属性を展開した空間内で，ある概念$X$を属性として持つ概念数から算出されるのが概念ベース$idf$である．概念ベース$idf$の算出式は以下のように定義される．
\begin{equation}
 CV_N(\mathit{Word}_{Ai})=\log\frac{V_{\mathit{all}}}{\mathit{df}_N(\mathit{Word}_{Ai})}
\end{equation}
$CV_N(\mathit{Word}_{Ai})$は$N$次属性空間内における概念 $\mathit{Word}_{Ai} $の概念ベース$idf$である．$V_{\mathit{all}}$は概念ベースに定義されている全概念数，$\mathit{df}_N(\mathit{Word}_{Ai})$は$N$次属性集合内において概念 $\mathit{Word}_{Ai} $を属性として持つ概念の数である．本稿では\cite{Article_09}の報告より最も精度が良いとされる三次属性空間内における概念ベース$\mathit{idf}$を用いた．

以上で示した式により，自立語$\mathit{Word}_{Ai}$へ付与する重み$w$は次のような式で定義される．
\begin{equation}
w= \mathit{tf}(\mathit{Word}_{Ai}, A){\times} CV_3(\mathit{Word}_{Ai})
\end{equation}

つまりある自立語の重みは，自立語の網羅性$\mathit{tf}$と自立語の概念ベース$\mathit{idf}$を掛け合わせることで与えられる．

このようにして文書$A，B$共に自立語への重みを付与する．ここでは例として図\ref{fig:EMD}のように重みが付与されたとする．
EMDでは変換コストの算出を行う際に離散分布を構成する要素同士の距離を用いる．EMDを用いた記事分類方式ではこの距離を自立語同士の関連性であると考え，一致度によってこれを求める．$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$の距離$\mathit{dis}_{A1B1}$は次の式で表される．
\begin{equation}
 \mathit{dis}_{A1B1}=1-\mathit{DoM}(\mathit{Word}_{A1}, \mathit{Word}_{B1})
\end{equation}
一致度は関連性が高いと値が大きくなるため，1から引いた値を距離としている．ここで$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$の間の変換コスト$\mathit{cost}_{A1B1}$は次の式で算出される．
\begin{equation}
 \mathit{cost}_{A1B1}=\mathit{dis}_{A1B1}{\times}1.5
\end{equation}
これは$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$の距離に重みを掛けたものである．$\mathit{Word}_{A1}$と$\mathit{Word}_{B1}$が持つ重みは同じく1.5であるため供給量と需要量が合致し，$\mathit{Word}_{A1}$からの重みの運送はこの時点で終了する．
同様にコストの計算を行っていき，最終的にすべての運送経路のコストを足し合わせたものがEMDとなる．図\ref{fig:EMD}の例ではEMDは次のように表される．
\begin{gather}
 \mathit{EMD}= \mathit{cost}_{A1B1}+ \mathit{cost}_{A2B2}+ \mathit{cost}_{A2B3} \\
 \mathit{cost}_{A1B1}=\mathit{dis}_{A1B1}{\times}1.5 \\
 \mathit{cost}_{A2B2}=\mathit{dis}_{A2B2}{\times}2.0 \\
 \mathit{cost}_{A2B3}=\mathit{dis}_{A2B3}{\times}1.0
\end{gather}

以上のような式で算出されたEMDの値の最小値を最適化計算で求めて文書間の類似性を算出している．


\section{語の変換処理の流れ}
\label{nagarezu}

語の変換処理では入力された文から難解語を自動的に判別し，関係語辞書\cite{Article_10,Article_11}による馴染みのある語への変換，もしくは国語辞書による文への変換を行う．具体的な処理の流れを図\ref{fig:nagare}に示す．

まず入力文を構成する単語の内，馴染みのない語を単語親密度の閾値により判別し，難解語とする．この難解語をシソーラス\cite{Book_02}上で検索し，難解語を意味的に包含するノードの中にノード名「具体物」が存在する場合には$N$語変換を，それ以外の場合には1語変換を先に行う．これは具体的な物を示す単語は別の1語に変換することが困難であるため，シソーラスにより具体物と判断できる語に関しては$N$語変換のみによって変換を行うためである．例えば「サリドマイド」のように具体的な薬品名を別の1語に変換することを考えると，物質を示す化学式や化合物名などが挙がる．それらは平易な表現とは言いがたく，そもそも難解な具体物の別称が平易であることは少ないと考えられる．この場合ならば「睡眠薬の一種」という文による変換を行えば自然でかつ平易な表現となる．

ノード「具体物」を上位に持たない語は，まず1語変換の処理を行う．ここでは語の同義，類義関係を示した関係語辞書から難解語の同義語および類義語を取得することで変換候補語を得る．これら変換候補語と難解語との関連度を算出し，最も高い関連度の候補語を用いて変換を行う．ただし，この際の関連度には下限値を設定し，最大関連度が閾値以下の場合には1語変換によって得られた候補語の信憑性が薄いと判断して$N$語変換へ処理を移す．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f3.eps}
 \end{center}
 \caption{語の変換処理の流れ}
 \label{fig:nagare}
\end{figure}

$N$語変換では国語辞書から変換候補文を取得して変換を行う．難解語が多義性を持つ場合には複数の変換候補文を取得することになるため，元の記事中で使われている意味をもつ変換候補文を記事関連度計算方式により判別する．また，難解語をそのまま変換候補文に変換した場合，辞書特有の言い回しや記事全体での情報の重複などにより元の文が不自然になる場合がある．そこで元の文と変換候補文との比較を行い，不要語句の削除を行うことで変換による不自然さを排除する．これらの処理を行った上で得られる文を用いて新聞記事中の1文を変換する．


\section{難解語の判別}
\label{ikiti}
まず入力された新聞記事から，変換すべき馴染みの薄い語を判別する処理を行う．入力された新聞記事を句点（“。”もしくは“．”）を区切りとして1文ごとの記事文に分割して処理を行う．1文に対して形態素解析を行い，各単語の単語親密度に閾値を定めることによって馴染みの有無を判断し，馴染みの無い単語を難解語とする．本稿では会話のための資源として新聞記事を用いることを背景としているため，単語の馴染み深さの基準は「一般的な会話で使われる単語であるか否か」とする．この基準の作成には日本語話し言葉コーパス\cite{Book_03}を用いた．


\subsection{閾値の決定}
\label{ikiti_hyouka}

日本語話し言葉コーパスとは日本語による発話音声を大量に収集したデータベースである．収録されている発話音声中の語数は約750万語，時間は約66時間分となっている．発話音声には一般的な対話や学会講演といった様々なデータが収録されているが，このうち対話の音声を用いて「一般的な会話で使われる単語」の調査を行った．表\ref{tab:nihongo}にデータの一部を示す．
\begin{table}[b]
\vspace{-0.5\Cvs}
\caption{日本語話し言葉コーパスの例}
\label{tab:nihongo}
\input{02table03.txt}
\end{table}

単語親密度の閾値を決定するために，表\ref{tab:nihongo}に示したような日本語話し言葉コーパスの対話データを構成する単語2,000語と，新聞記事中の単語2,000語とを無作為に抽出し，それぞれの単語親密度の平均と分布を調査した．その結果，新聞記事における単語親密度の平均が5.74，標準偏差は0.70，対話データにおける単語親密度は平均が6.05，標準偏差が0.66となった．対話において用いられる語の単語親密度の平均の方が，新聞記事より高い値になっている．この事から会話に利用するには新聞記事中の単語は馴染みが薄いことがわかる．

新聞記事における単語親密度のデータ群（$A$とおく）と対話データにおける単語親密度のデータ群（$B$とおく）が，お互いにできるだけ他方の分布に属さないような値を閾値とすれば，「一般的な会話で使われる単語」を判別する閾値になると考えられる．そこで確率密度関数を用いて最適な閾値の調査を行った．確率密度関数は以下の式によって求める．
\begin{equation}
f_{(x)}=\frac{1}{\sqrt[ ]{\mathstrut (2\pi\sigma^{2})}}\mathrm{e}^{\frac{(x-\mu)^{2}}{\sigma^{2}}}
\end{equation}
ここで$\mu$は単語親密度の平均，$\sigma$は標準偏差である．ある閾値があった時に，$A$に属するデータが閾値を越える確率および$B$に属するデータが閾値を越える確率を算出し，双方の和が最も小さい時の閾値を$A$と$B$を区切る最適な値とした．その結果，新聞記事に用いられる単語と一般的な会話で使われる単語の単語親密度による閾値は5.82となった．よって，入力された新聞記事中の単語の内，単語親密度が5.82以下の単語を難解語と判別し，語の変換処理を行うこととした．


\subsection{閾値の評価}

前節で決定した閾値が，人間と同じレベルで馴染み深い語と難解語を判別できるかの評価を行った．単語親密度が5.82よりも大きい，つまり馴染み深いと判断された200語と，単語親密度が5.82以下，難解語と判断された200語を新聞記事からランダムに取得し，それらを人間の目視で評価した．評価は著者，共著者を含まない被験者3名（男性2名，女性1名）で行い，それぞれの語が会話に出現する語としたときに難解と感じるか，平易と感じるかの判断を行った．なおこのとき，被験者には評価を行う合計400語が単語親密度の閾値以上であるか否かは知らせていない．多数決により2名以上が難解と感じた語は「人が難解と感じる語」，2名以上が平易と判断した語を「人が平易と感じる語」とした．単語親密度の閾値によって馴染み深いと判断された200語については「人が難解と感じる語」であった場合に×，「人が平易と感じる語」であった場合に○と評価する．単語親密度の閾値によって難解語と判断された200語については，「人が難解と感じる語」であった場合に○，「人が平易と感じる語」であった場合に×と評価する．表\ref{tab:ikitiHyouka}に閾値の評価結果を示す．

\begin{table}[t]
\caption{閾値の評価結果}
\label{tab:ikitiHyouka}
\input{02table04.txt}
\end{table}

各評価者2名ずつのkappa係数はそれぞれ0.729，0.668，0.790であった．結果として，「人が難解と感じる語」を83.0\%の精度で難解語であると判断できた．また，「人が平易と感じる語」に関しては99.5\%の精度で馴染み深い語，つまり変換の必要がない語であると判断することができた．



\section{1語変換}

1語変換では1つの単語をより平易な別の1つの単語に変換する．難解語の同義語・類義語を取得してこれらを変換候補語とし，その中から変換に最も適した語を選択する．本稿における変換に適した語とは，変換前の語と比べて平易であり，かつ意味が同じ語である．平易であるかどうかの判断は単語親密度により行う．また，変換前と意味が同じ語を適切に選択するために関連度計算方式を用いた手法を提案する．


\subsection{変換候補語の取得}

変換候補語には難解語の同義語・類義語を用いる．これにより難解語と同じもしくは近い意味を持つ別の単語群を得ることができる．同義語・類義語の取得には関係語辞書を用いた．
関係語辞書とは国語辞書に記載されている定義文から，見出し語の同義語，類義語といった関係語を自動的に抽出した辞書である．関係語の抽出手法に関しては\cite{Article_10}および\cite{Article_11}において示されている．定義される関係語の例を表\ref{tab:gokankei}に示す．

\begin{table}[b]
\vspace{-0.5\Cvs}
\caption{関係語辞書の例}
\label{tab:gokankei}
\input{02table05.txt}
\end{table}

この辞書から得られる同義語，類義語を1語変換における変換候補語とする．表に示したように，1つの単語に対して複数の同義語・類義語が定義されている場合があるため，変換候補語は複数の単語群となる．


\subsection{単語親密度と関連度による変換語の選出}

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f4.eps}
 \end{center}
 \caption{変換語の選出}
 \label{fig:syorirei}
\end{figure}

変換候補語の語群から1語変換に適切な変換語を選出する．選出には変換候補語の単語親密度および，難解語と変換候補語との関連度を用いる．まず同義語・類義語として得られた語のうち，\ref{ikiti}章で述べた閾値5.82以上の単語親密度を持つ語を選出する．これは単語親密度が高く馴染みが深いと判断される語であるほど，平易な変換に適すると考えられるためである．しかし単語親密度は馴染みの深さのみを表現する数値であり，語と語の意味の近さに関しては考慮されていない．変換を行う以上，難解語と最も意味の近い語が選出されるべきである．そこで語の意味を定量化する手法として，\ref{DOA}節で述べた関連度計算方式を用いる．単語親密度が閾値以上である変換候補語の中から，元の難解語との関連度が最も高い語を選出することで「平易性がある語のうち，最も意味が近い語」を変換語とすることが出来る．具体的な変換候補語の選出方法について，「わが国は支配者の法を否定した．」というトルコの憲法改正についての記事の一部を用いて説明する（図\ref{fig:syorirei}）．

この文の中で「法」という語の単語親密度は5.75であり，これは\ref{ikiti}章で述べた閾値5.82を下回るため難解語となる．「法」の同義語・類義語から「法律」「規則」「方法」「道理」という4つの変換候補語が得られる．これら変換候補語から，最も適切な変換語を選択する．

まずそれぞれの単語親密度を見ると，「道理」は単語親密度が5.44となり閾値5.82に達していないため変換語から外れる．ここで各変換候補語と元の難解語「法」との関連度を算出し，最も関連度が高い語を変換語として選出する．この例では単語親密度が最も高い「方法」ではなく，関連度の最も高い「法律」が変換語として選ばれることになる．



\subsection{1語変換から$N$語変換へ移行する条件}
\label{1Nzyouken}

難解語と変換候補語との関連度に閾値を定め，閾値を越える変換候補語が存在しない場合には$N$語変換を行う．これは関連度が低いということは難解語と変換候補語との関連性が薄く，変換には不適切であると判断できるためである．

関連度の閾値設定は概念ベースの評価方法である$X$-$ABC$評価\cite{Article_04}を参考にして行う．この評価は関連度の値を比較することで概念ベースを評価する方法であり，表\ref{tab:xabc}に示すような評価セットを用いる．

\begin{table}[b]
\caption{$X$-$\mathit{ABC}$評価セットの例}
\label{tab:xabc}
\input{02table06.txt}
\end{table}

評価セットはある基準概念$X$と，この概念$X$と非常に関連が強い概念$A$，概念$A$ほどではないが関連があると思われる概念$B$，まったく関連のない概念$C$によって構成される．実際に用いた評価セットは\cite{Article_05}に示された方法で人手により作成された500組のセットとなっている\cite{Article_04}．

ここで，$X$-$A$の関係は基準概念$X$と非常に関連が強い概念$A$というもので，実際の評価セット作成時には\cite{Article_05}に示された方法を基に$X$の同義ないしは類義語となりうる語を収集している．このテストセットは被験者実験によって作成されており，つまり人間の感覚に合致した評価セットになっている．人間の自然な感覚を反映しているこの評価セットにおいて同義，類義関係と判断された$X$-$A$間の関連度は，本提案手法における難解語と変換候補語との関連性の有無を判断する閾値に値すると考えた．

評価セットは500組存在するため，$X$-$A$間の関連度も500個の値が算出される．そこから人間が同義，類義と感じる語同士の関連度を意味する値として平均値を算出した．これは\cite{Article_04}において用いられている評価式の中で，まったく関連のない$X$-$C$間の関連度の平均値を「関連がない語の間で算出される関連度」として用いる考え方に倣い，同義，類義関係にある$X$-$A$間の関連度の平均値を「同義，類義関係の語の間で算出される関連度」とした．$X$-$A$間の平均値は0.34，分散は0.04，$X$-$C$間の平均値は0.002，分散は$9.43×10^{-6}$であった．よって提案手法では，難解語と変換候補語との関連度が$X$-$A$間の平均値である0.34より低かった場合には$N$語変換へ処理を移行する．



\section{$N$語変換}

1語変換では変換ができない場合，つまり1つの語では説明できない語を相手に伝える際に人間はその語の意味を文で伝える．そこで$N$語変換では1つの単語を$N$語の単語群，つまり文で変換することで1語変換ができない難解語の変換を行う．

\ref{nagarezu}章に示した通り，まずシソーラスにおいて難解語の包含関係にあるノードに「具体物」が存在する場合には1語変換が不可能であると判断し，$N$語変換を行う．例えば「サリドマイド」という具体物は一般的に馴染みの薄い語であるが，「催眠薬の一種」という文章で変換されることでその内容を理解することが出来る．このように具体的な物を示す語は，同じ意味を持つ別の1語に変換するよりも具体物の説明を文章で行う方が馴染みのある表現になる．また\ref{1Nzyouken}節に示したように1語変換における変換候補語の関連度が閾値以下の場合にも，1語変換では適切な変換を行えなかったと判断して$N$語変換を行う．


\subsection{変換候補文の取得}

$N$語変換では国語辞書\cite{Book_04}に記載された語の定義文を，変換を行うための文（変換候補文）として利用する．国語辞書の定義文は語の意味を説明する文であるため，これを利用することで難解語の意味を損ねることなく$N$語による変換が可能になる．また，定義文が端的かつ正しい日本語表現で記されているため，変換後の記事表現が煩雑にならないと考えられる点で，$N$語変換の資源として国語辞書は適当である．

本稿で使用した国語辞書には238,000語の見出し語とその定義文が格納されている．このうち，固有名詞および単一で意味を成さない代名詞，助詞の見出し語を省いた94,544語の見出し語と定義文を$N$語変換に用いた．


\subsection{多義語の意味特定}

難解語が多義語であった場合，それぞれの意味から辞書の説明文が得られるため変換候補文が複数取得される．そこで適切な文を選択するために\ref{EMD}節で説明した記事関連度計算方式を用いて難解語が含まれる元の文に意味が近い変換候補文を選択して変換を行う．図\ref{fig:tagigo}に具体的な変換候補文の選択方法を示す．

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f5.eps}
 \end{center}
 \caption{多義語の意味特定の具体例}
 \label{fig:tagigo}
\end{figure}

「日中」という語には図に示すように2つの意味が定義文として記載されており，多義語である．このような多義語の場合は，辞書のそれぞれの定義文と，難解語を含む元の記事文との間で記事関連度の算出を行い，値の高い変換候補文を語の変換に用いる．例の場合では「日中」は「日本と中国」という候補文が選択され，記事は「日本と中国の未来志向の…」と変換される．


\subsection{不自然さの排除}
\label{NoNeed}

辞書の定義文の中には，そのままの形で$N$語変換に用いると日本語として不自然になってしまうものがある．例えば「財政再生計画を策定する」という文中の「策定」は単語親密度が3.16の難解語であり，1語変換では関連度が閾値より大きい変換候補語が得られず，$N$語変換が行われる語である．この時，辞書における「策定」の定義文「政策や計画などを考えて決めること」をそのまま語の変換に用いてしまうと「財政再生計画を政策や計画などを考えて決めること」となり，日本語として不自然である．このような変換によって起こる不自然さの排除方法として，不要語の削除と記事中の情報の重複排除を行う．

まず，不要語の削除について述べる．不要語とは辞書によく出現する言い回しのうち，変換を行う際には必要の無い語の事を指す．この不要語を人手で判断してリスト化したものが不要語リストである．図\ref{fig:fuyougo}に具体的な不要語の一覧を示す．

\begin{figure}[b]
 \begin{center}
  \includegraphics{20-2ia2f6.eps}
 \end{center}
 \caption{不要語の一覧}
 \label{fig:fuyougo}
\end{figure}

例えば「蜀魂」という語の定義文は「ホトトギスの別名」となっているが，実際に「蜀魂」という語を変換する際に必要となる語は「ホトトギス」の部分のみである．このように辞書の定義文に存在する不要な言い回しは変換の際に削除する．

不要語を削除した後に記事中の情報の重複排除を行うが，これには意味理解システム\cite{Article_03}を利用する．このシステムは入力された文を，6W1H (Who, What, When, Where, Whom Why, How) と用言の8種類に分類する．意味理解システムの出力例を図\ref{fig:imirikai}に示す．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f7.eps}
 \end{center}
 \caption{意味理解システム}
 \label{fig:imirikai}
\end{figure}

入力文の「誰が」にあたる語は「妹」であり，これが意味理解システムではWhoに分類される．このシステムで元の記事文と辞書から得た変換候補文をそれぞれ処理し，分類が重複した場合には不自然にならないように不要部分を削除する．具体的な例を図\ref{fig:kakusaku}に示す．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f8.eps}
 \end{center}
 \caption{格重複の排除}
 \label{fig:kakusaku}
\end{figure}

図\ref{fig:kakusaku}の例では元の記事文「財政再生計画を策定する」と不要語を削除した変換候補文「政策や計画を考えて決める」の2文である．ここで元の記事文と変換候補文の間で分類に重複があった場合，どちらか一方を用いて出力する文を作成する．具体的には難解語ではない部分で分類の重複が起こった場合には元の記事文を，難解語の部分で分類の重複が起こった場合には変換候補文を用いる．図\ref{fig:kakusaku}を見るとWhatの重複は難解語ではない部分であるため，元の記事文である「財政再生計画」が選択される．逆に用言での重複は難解語の部分であるため，変換候補文である「考えて決める」が選択される．このようにして分類の重複を排除した上で，変換を行い結果を出力する．図\ref{fig:kakusaku}の例では最終的に「財政再生計画を策定する」という元の記事文が「財政再生計画を考えて決める」と変換される．



\section{提案手法の評価と考察}

\ref{First}章，\ref{Second}章で述べたとおり，人間が違和感を感じない語の変換を行うためには，人間と同じく1：1の変換と1：$N$の変換を組み合わせることが必要である．それを踏まえ，ここまでで提案してきた 1 語変換および$N$語変換の手法を統合した手法を，本稿で提案する難解語の変換手法としてその評価を行う．変換処理を統合したことによる有効性を示すため，提案手法，難解語を無理やり1語変換のみで変換した場合，$N$語変換のみで変換した場合の3種類の変換について評価を行った．評価実験の方法および評価結果について以下に述べる．

評価には朝日新聞から取得した50記事からランダムに選んだ記事文を利用した．全単語数は1567語，うち単語親密度の閾値によって難解語と判断された語は249語である．

まず著者，共著者以外の被験者3名（男性2名，女性1名）に対して記事中の全単語を提示し，それぞれの語について会話に出現する語としたときに難解と感じるか，平易と感じるかの判断を行った．多数決により全単語を難解と感じる語，平易と感じる語に分類し，人が変換すべきと判断した語と変換しなくてよいと判断した語の判別を行った．

次に評価に用いた記事を変換前と変換後のセットにして被験者に提示し，平易な表現となっている方の記事を選択させる．この際，被験者にはどちらが変換前でどちらが変換後かは示さない状態で記事を提示し，表現が分かりやすいと感じる方を選択させた．提案手法により変換された後の記事が平易であると選ばれた場合に○，変換前が選ばれた場合に×の評価とする．

最後に同じ被験者3名に対して変換前と変換後の記事を各々がどちらの記事であるか示した上で，変換後の記事が意味的に欠損したり違和感のある表現になっていないかという意味の保持性について評価を行った．意味が保持され，違和感もない場合には○，何らかの違和感を感じる場合には△，意味が違っていたり，日本語表現としておかしいといった意味が保持されていない場合に×の評価とした．

手法の評価は，人が変換すべきと判断した語と変換すべきでないと判断した語に分けて示す．まず人が変換すべきと判断した語については，変換手法により語が適切に変換されたか否かを評価した．なお，人が変換すべきと判断した語は222語，そのうち提案手法によって変換された語は206語であった．平易性に関する評価結果を図\ref{fig:hyouka1H}に，意味保持性に関する評価結果を図\ref{fig:hyouka1I}に示す．

提案手法では平易性の評価が75.7\%，意味保持性の評価が81.1\%となった．難解語となった249語について1語変換および$N$語変換のどちらで処理が行われたかの内訳は，1語変換によって処理された難解語が76語，$N$語変換によって処理された難解語が173語であった．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f9.eps}
 \end{center}
 \caption{変換すべき語の評価結果（平易性）}
 \label{fig:hyouka1H}
\end{figure}
\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f10.eps}
 \end{center}
 \caption{変換すべき語の評価結果（意味保持性）}
 \label{fig:hyouka1I}
\end{figure}

1語変換のみで変換を行った場合，平易性で58.7\%，意味保持性で52.9\%が×の評価となった．これは，1語変換では同義語および類義語が存在しない場合は変換することが出来ないため，変換すべき語の多くが変換できず難解語のまま残ってしまったためである．今回の評価ではすべての難解語のうち48.1\%にあたる99語が変換不可となった．

$N$語変換のみの場合は辞書に定義された語であれば変換可能であるため，変換不可の語は全体の7.3\%，15語に留まったが，こちらも提案手法と比べて平易性，意味保持性共に評価は低くなっている．


次に変換すべきでないと判断した1,345語についての評価を表\ref{tab:NoChange1}および表\ref{tab:NoChange2}に示す．

人が変換すべきでないと判断した語に関しては，変換が行われないもしくは変換されてしまったが平易である，意味が保持されている場合にそれぞれ○の評価としている．すべての手法において，○の評価は高くなっている．1語変換のみの場合には，前述したとおり変換がそもそも不可能である難解語が多かったため，変換すべきで無い語の多くが変換されないままとなり○の評価が高くなっている．

以下に実際の変換例を示す．まず表\ref{tab:1orTei}に1語変換のみを用いた場合と提案手法の変換例を示す．なお，括弧の中は各変換の評価を示す．

\begin{table}[t]
\caption{変換すべきでない語の評価結果（平易性）}
\label{tab:NoChange1}
\input{02table07.txt}
\end{table}
\begin{table}[t]
\caption{変換すべきでない語の評価結果（意味保持性）}
\label{tab:NoChange2}
\input{02table08.txt}
\end{table}
\begin{table}[t]
\caption{1語変換のみと提案手法の比較}
\label{tab:1orTei}
\input{02table09.txt}
\end{table}

「送還」という難解語は同義語，類義語ともに得られず，1語変換のみでは変換することができない．$N$語変換では送還の意味として「送り返すこと」が存在するため正しい変換が行えている．

「維持」の例では1語変換を行うと類義語から「持つ」という変換候補語が得られる．「持つ」は確かに「維持」を平易に変換したものだが，文脈から不自然であると判断されて意味保持性は×となった．これを提案手法で変換すると$N$語変換により「保ち続ける」という変換がされ，双方とも○の評価となった．

最後の例では難解語が2つ存在している．1語変換のみの場合には「破片」という難解語が「かけら」に変換されるが，「落下」に関しては変換候補語が得られずに変換できない．提案手法では$N$語変換により「落下」に関しても「下に落ちること」という定義文から変換が可能となり，結果として表のような変換が行えた．

次に，表\ref{tab:NorTei}に$N$語変換のみを用いた場合と提案手法の変換例を示す．

\begin{table}[t]
\caption{N語変換のみと提案手法の比較}
\label{tab:NorTei}
\input{02table10.txt}
\end{table}

表\ref{tab:NorTei}に示した例を見ると，$N$語変換のみを用いた場合の変換結果は意味的には元の記事文と相違ない．しかしこれらの表現が会話中に現れると想定すると多くの人は不自然であると感じる．$N$語変換は文章による変換であるため，この変換が多用されると変換後の記事が冗長であると感じやすく，結果として意味保持性において違和感を感じてしまい△の評価となる場合や，平易性の無い×の評価となっている．一方，提案手法ではこれらの記事は1語変換によって変換され，その変換結果は意味を損ねず，かつ違和感もないことがわかる．以上のことから，1語変換および{$N$}語変換を組み合わせることによってより人間にとって違和感の無い変換が行えることが分かる．

提案手法では難解語の判別に\ref{ikiti_hyouka}節で示した閾値を用いている．本評価では人が変換すべきと判断した222語のうち206語が難解語と判別されており，つまり変換すべき難解語16語がこの閾値では難解語と判断されていない．人が難解と感じる語を100.0\%判断できることを重視する場合には親密度の閾値を上げればよいが，閾値が高すぎると記事中の多くの語が難解語と判断されると考えられる．各変換処理によってそれらの語が全て別表現に変換されると変換後の記事が冗長になる可能性がある．そこで本評価において人が変換すべきと判断したが，提案手法では難解語と判別されなかった語のうち最も高い親密度であった「汚染」という語を基準として評価を行い，提案手法との比較を行った．具体的な親密度の閾値は6.15である．平易性に関する評価結果を図\ref{fig:hyoukananhen1}に，意味保持性に関する評価結果を図\ref{fig:hyoukananhen2}に示す．

結果として，難解語判別の閾値を6.15とした場合には平易性，意味保持性ともに評価が下がる結果となった．
表\ref{tab:IkitiChange}に提案手法による出力と難解語判別の閾値変更を行った場合の出力の比較を示す．

\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f11.eps}
 \end{center}
 \caption{難解語判別の閾値変更による評価結果（平易性）}
 \label{fig:hyoukananhen1}
\end{figure}
\begin{figure}[t]
 \begin{center}
  \includegraphics{20-2ia2f12.eps}
 \end{center}
 \caption{難解語判別の閾値変更による評価結果（意味保持性）}
 \label{fig:hyoukananhen2}
\end{figure}

難解語判別の閾値を高くしたことで，提案手法では変換されなかった「視野」や「交差点」といった語が難解語と判断されている．これらの語は目視では変換しなくて良い語と判断されていた語である．これらが難解語と判断されることによって，例えば「視野」という語は $N$ 語変換により「視線を固定したままの状態で見ることのできる範囲」と変換されている．これは意味としては正しいが，元の「視野」という1語の表現と比べて非常に冗長であるため，平易性において評価が×となっている．「交差点」の評価も「視野」と同様に冗長な表現で平易性を失っている．しかし同じ記事中の「右折」という語は，人が変換すべきと判断したが提案手法では変換されなかった16語の1つであり，これは「右へ曲がる」という平易な表現へ変換することが出来ている．

閾値を上げることで，人が変換すべきと判断したが提案手法では変換されなかった16語に対しての変換は行われたが，それに伴い人が変換しなくてよいと判断した語に対しても多くの変換が行われた．具体的には新たに88語が難解語となったが，これらの語は人の判断では変換せずとも平易であるとされており，変換を行うことで逆に平易性が損なわれやすい結果となった．このことより，\ref{ikiti_hyouka}節において示した閾値の設定は有効であると考える．

\begin{table}[t]
\caption{提案手法と難解語判別の閾値変更の出力比較}
\label{tab:IkitiChange}
\input{02table11.txt}
\end{table}

以上の評価結果より，会話中に出現する語の単語親密度によって難解語の判別を行い，1語変換と $N$ 語変換を組み合わせることで平易な表現への変換を行う提案手法の有効性を示した．


\section{おわりに}

本稿では，新聞記事中の難解な語を会話に適した平易な表現へ変換する手法を提案した．変換の際には人間が行う語の変換処理に沿い，1つの語を別の1語で変換する1語変換および文章で変換す$N$語変換を組み合わせることでより人間にとって自然な変換が行えることを示した．1語変換では難解な語を同義語・類義語により別の1語へ変換し，$N$語変換では1語では変換できないような語や具体物を示す語について文による変換を行った．この二つの変換を組み合わせた変換手法を提案，評価してその有効性を示した．また，処理の各段階において語概念連想により語と語，文と文の関連性の有無を判断することで変換前の語から変換後表現にかけて意味の保持を行った．最終的な結果として新聞記事50件，249語の変換を行い，変換すべき難解語を結果として変換すべき難解語を75.7\%の精度で平易な表現に，81.1\%の精度で正しい意味を保持した表現に変換することが出来た．これにより，ロボットと人間との自然な会話生成を担う技術の一端を示せたと考える．


\acknowledgment

本研究の一部は，科学研究費補助金（若手研究 (B) 24700215）の補助を受けて行った．


\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{天野\JBA 近藤}{天野\JBA 近藤}{1998}]{Article_20}
天野成昭\JBA 近藤公久 \BBOP 1998\BBCP.
\newblock 音声単語の語彙判断に対する新密度の影響.\
\newblock \Jem{日本音響学会秋季研究発表会講演論文集1}, \mbox{\BPGS\ 363--364}.

\bibitem[\protect\BCAY{天野\JBA 近藤}{天野\JBA 近藤}{1999}]{Book_01}
天野成昭\JBA 近藤公久 \BBOP 1999\BBCP.
\newblock \Jem{NTTデータベースシリーズ日本語の語彙特性（第1期CD-ROM版）}.
\newblock 三省堂.

\bibitem[\protect\BCAY{天野\JBA 近藤}{天野\JBA 近藤}{2008}]{Book_05}
天野成昭\JBA 近藤公久 \BBOP 2008\BBCP.
\newblock \Jem{日本語の語彙特性 第1巻 単語新密度 増補}.
\newblock 三省堂.

\bibitem[\protect\BCAY{Connine, Mullennix, Shernoff, \BBA\ Yelen}{Connine
  et~al.}{1990}]{Article_21}
Connine, C.~M., Mullennix, J., Shernoff, E., \BBA\ Yelen, J. \BBOP 1990\BBCP.
\newblock \BBOQ Word familiarity and frequency in visual and auditory word
  recognition.\BBCQ\
\newblock {\Bem Journal of Experimental Psychology. Leaning, memory
  andcognition}, {\Bbf 16}  (6), \mbox{\BPGS\ 1084--1096}.

\bibitem[\protect\BCAY{藤江\JBA 渡部\JBA 河岡}{藤江 \Jetal }{2009}]{Article_06}
藤江悠五\JBA 渡部広一\JBA 河岡司 \BBOP 2009\BBCP.
\newblock 概念ベースとEarth Mover's Distanceを用いた文書検索.\
\newblock \Jem{自然言語処理}, {\Bbf 16}  (3), \mbox{\BPGS\ 25--49}.

\bibitem[\protect\BCAY{藤沢\JBA 相原\JBA 神門}{藤沢 \Jetal }{2006}]{Article_16}
藤沢仁子\JBA 相原健郎\JBA 神門典子 \BBOP 2006\BBCP.
\newblock 文化遺産に関する説明文の対象ユーザに合わせた言い換えの提案.\
\newblock \Jem{電子情報通信学会技術研究報告. NLC,
  言語理解とコミュニケーション}, {\Bbf 106}  (109), \mbox{\BPGS\ 7--12}.

\bibitem[\protect\BCAY{Gonzalez \BBA\ Davis}{Gonzalez \BBA\
  Davis}{2006}]{Article_28}
Gonzalez, H.~S.\BBACOMMA\ \BBA\ Davis, C. \BBOP 2006\BBCP.
\newblock \BBOQ The bristol norms for age of acquisition, imageability, and
  familiarity.\BBCQ\
\newblock {\Bem Behavior Research Methods}, {\Bbf 38}  (4), \mbox{\BPGS\
  598--605}.

\bibitem[\protect\BCAY{Hassan, Csomai, Banea, Sinha, \BBA\ Mihalcea}{Hassan
  et~al.}{2007}]{Article_24}
Hassan, S., Csomai, A., Banea, C., Sinha, R., \BBA\ Mihalcea, R. \BBOP
  2007\BBCP.
\newblock \BBOQ UNT: SubFinder: combining knowledge sources for automatic
  lexical substitution.\BBCQ\
\newblock {\Bem SemEval '07 Proceedings of the 4th International Workshop on
  Semantic Evaluations}, \mbox{\BPGS\ 410--413}.

\bibitem[\protect\BCAY{Hoffman}{Hoffman}{1963}]{Book_06}
Hoffman, A.~J. \BBOP 1963\BBCP.
\newblock \BBOQ On simple linear programing problems.\BBCQ\
\newblock In {\Bem Proceedings of the 7th Symposium in Pure Mathmatics of the
  AMS}, \mbox{\BPGS\ 317--327}.

\bibitem[\protect\BCAY{Jauhar \BBA\ Specia}{Jauhar \BBA\
  Specia}{2012}]{Article_25}
Jauhar, S.~K.\BBACOMMA\ \BBA\ Specia, L. \BBOP 2012\BBCP.
\newblock \BBOQ UOW-SHEF: SimpLex: lexical simplicity ranking based on
  contextual and psycholinguistic features.\BBCQ\
\newblock {\Bem SemEval '12 Proceedings of the First Joint Conference on
  Lexical and Computational Semantics}, \mbox{\BPGS\ 477--481}.

\bibitem[\protect\BCAY{鍜治\JBA 黒橋\JBA 佐藤}{鍜治 \Jetal }{2001}]{Article_02}
鍜治伸裕\JBA 黒橋禎夫\JBA 佐藤理史 \BBOP 2001\BBCP.
\newblock 国語辞典に基づく平易文へのパラフレーズ.\
\newblock \Jem{情報処理学会研究報告}, {\Bbf 2001}  (69), \mbox{\BPGS\
  167--174}.

\bibitem[\protect\BCAY{鍜治\JBA 岡本\JBA 黒橋}{鍜治 \Jetal }{2004}]{Article_15}
鍜治伸裕\JBA 岡本雅史\JBA 黒橋禎夫 \BBOP 2004\BBCP.
\newblock WWWを用いた書き言葉特有語彙から話し言葉語彙への用言の言い換え.\
\newblock \Jem{自然言語処理}, {\Bbf 11}  (5), \mbox{\BPGS\ 19--37}.

\bibitem[\protect\BCAY{小島\JBA 渡部\JBA 河岡}{小島 \Jetal }{2001}]{Article_10}
小島一秀\JBA 渡部広一\JBA 河岡司 \BBOP 2001\BBCP.
\newblock
  常識判断のための概念ベース構成法：概念間論理関係を用いた概念属性の重み決定法
.\
\newblock \Jem{電子情報通信学会技術研究報告. AI, 人工知能と知識処理}, {\Bbf
  100}  (709), \mbox{\BPGS\ 57--64}.

\bibitem[\protect\BCAY{小島\JBA 渡部\JBA 河岡}{小島 \Jetal }{2002}]{Article_11}
小島一秀\JBA 渡部広一\JBA 河岡司 \BBOP 2002\BBCP.
\newblock
  連想システムのための概念ベース構成法—属性信頼度の考え方に基づく属性重みの決
定.\
\newblock \Jem{自然言語処理}, {\Bbf 9}  (5), \mbox{\BPGS\ 93--110}.

\bibitem[\protect\BCAY{国立国語研究所}{国立国語研究所}{2006}]{Book_03}
国立国語研究所 \BBOP 2006\BBCP.
\newblock \Jem{日本語話し言葉コーパスの構築法}.
\newblock 国立国語研究所.

\bibitem[\protect\BCAY{熊本\JBA 田中}{熊本\JBA 田中}{2008}]{Article_13}
熊本忠彦\JBA 田中克己 \BBOP 2008\BBCP.
\newblock 2種類の共起辞書を用いた語彙的言い換えに基づくWeb検索システム.\
\newblock \Jem{人工知能学会論文誌}, {\Bbf 23}  (5), \mbox{\BPGS\ 355--363}.

\bibitem[\protect\BCAY{松村}{松村}{1995}]{Book_04}
松村明 \BBOP 1995\BBCP.
\newblock \Jem{大辞林 第2版}.
\newblock 三省堂.

\bibitem[\protect\BCAY{McCarthy \BBA\ Navigli}{McCarthy \BBA\
  Navigli}{2007}]{Article_22}
McCarthy, D.\BBACOMMA\ \BBA\ Navigli, R. \BBOP 2007\BBCP.
\newblock \BBOQ SemEval-2007 task 10: English lexical substitution task.\BBCQ\
\newblock {\Bem SemEval '07 Proceedings of the 4th International Workshop on
  Semantic Evaluations}, \mbox{\BPGS\ 48--53}.

\bibitem[\protect\BCAY{中野\JBA 遠藤\JBA 菅原\JBA 乾\JBA 藤田}{中野 \Jetal
  }{2005}]{Article_12}
中野智子\JBA 遠藤淳\JBA 菅原昌平\JBA 乾健太郎\JBA 藤田篤 \BBOP 2005\BBCP.
\newblock Webサイトへのアクセシビリティ向上を目的とした難語の平易化.\
\newblock \Jem{電子情報通信学会技術研究報告}, {\Bbf 105}  (186), \mbox{\BPGS\
  11--14}.

\bibitem[\protect\BCAY{西村\JBA 田中\JBA 北野\JBA 田中\JBA 大林}{西村 \Jetal
  }{2009}]{Article_01}
西村健二\JBA 田中成典\JBA 北野光一\JBA 田中裕一\JBA 大林睦 \BBOP 2009\BBCP.
\newblock 児童向け新聞教材のための言い換え表現対の抽出に関する研究.\
\newblock \Jem{情報処理学会第71回全国大会}, \mbox{\BPGS\ 293--294}.

\bibitem[\protect\BCAY{NTTコミュニケーション科学研究所}{NTTコミュニケーション
科学研究所}{1997}]{Book_02}
NTTコミュニケーション科学研究所 \BBOP 1997\BBCP.
\newblock \Jem{日本語語彙体系}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{奥村\JBA 小島\JBA 渡部\JBA 河岡}{奥村 \Jetal
  }{2005}]{Article_09}
奥村紀之\JBA 小島一秀\JBA 渡部広一\JBA 河岡司 \BBOP 2005\BBCP.
\newblock 電子化新聞を用いた概念ベースの拡張と属性重み付与方式.\
\newblock \Jem{情報処理学会研究報告}, \mbox{\BPGS\ 55--62}.

\bibitem[\protect\BCAY{奥村\JBA 土屋\JBA 渡部\JBA 河岡}{奥村 \Jetal
  }{2007}]{Article_04}
奥村紀之\JBA 土屋誠司\JBA 渡部広一\JBA 河岡司 \BBOP 2007\BBCP.
\newblock 概念間の関連度計算のための大規模概念ベースの構築.\
\newblock \Jem{自然言語処理}, {\Bbf 14}  (5), \mbox{\BPGS\ 41--64}.

\bibitem[\protect\BCAY{Salton, Wong, \BBA\ Yang}{Salton
  et~al.}{1975}]{Article_08}
Salton, G., Wong, A., \BBA\ Yang, C.~S. \BBOP 1975\BBCP.
\newblock \BBOQ A Vector space model for automatic indexing.\BBCQ\
\newblock {\Bem Communications of the ACM}, {\Bbf 18}  (3), \mbox{\BPGS\
  613--620}.

\bibitem[\protect\BCAY{篠原\JBA 渡部\JBA 河岡}{篠原 \Jetal }{2002}]{Article_03}
篠原宜道\JBA 渡部広一\JBA 河岡司 \BBOP 2002\BBCP.
\newblock 常識判断に基づく会話意味理解方式.\
\newblock \Jem{言語処理学会第8回年次大会発表論文集}, \mbox{\BPGS\ 651--654}.

\bibitem[\protect\BCAY{Sinha}{Sinha}{2012}]{Article_26}
Sinha, R. \BBOP 2012\BBCP.
\newblock \BBOQ UNT-SimpRank: systems for lexical simplification ranking.\BBCQ\
\newblock {\Bem SemEval '12 Proceedings of the First Joint Conference on
  Lexical and Computational Semantics}, \mbox{\BPGS\ 493--496}.

\bibitem[\protect\BCAY{Specia, Jauhar, \BBA\ Mihalcea}{Specia
  et~al.}{2012}]{Article_23}
Specia, L., Jauhar, S.~K., \BBA\ Mihalcea, R. \BBOP 2012\BBCP.
\newblock \BBOQ SemEval-2012 task 1: English Lexical Simplification.\BBCQ\
\newblock {\Bem SemEval '12 Proceedings of the First Joint Conference on
  Lexical and Computational Semantics}, \mbox{\BPGS\ 347--355}.

\bibitem[\protect\BCAY{渡部\JBA 河岡}{渡部\JBA 河岡}{2001}]{Article_05}
渡部広一\JBA 河岡司 \BBOP 2001\BBCP.
\newblock 常識的判断のための概念間の関連度評価モデル.\
\newblock \Jem{自然言語処理}, {\Bbf 8}  (2), \mbox{\BPGS\ 39--54}.

\bibitem[\protect\BCAY{Wilson}{Wilson}{1988}]{Article_27}
Wilson, M. \BBOP 1988\BBCP.
\newblock \BBOQ The MRC Psycholinguistic Database: Machine Readable Dictionary,
  Version 2.\BBCQ\
\newblock {\Bem Behavior Research Methods}, {\Bbf 20}  (1), \mbox{\BPGS\
  6--11}.

\end{thebibliography}


\begin{biography}
\bioauthor{芋野美紗子}{
2009年同志社大学工学部知識工学科卒業．
2011年同大学院工学研究科情報工学専攻博士前期課程修了．
同大学院工学研究科情報工学専攻博士後期課程在学．
主に，概念処理の研究に従事．言語処理学会会員．
}
\bioauthor{吉村枝里子}{
2004年同志社大学工学部知識工学科卒業．
2006年同大学院工学研究科知識工学専攻博士前期課程修了．
2009年同大学院工学研究科知識工学専攻博士後期課程修了．
博士（工学）．同年より同志社大学理工学部研究員．
主に，知識処理，意味処理，会話処理の研究に従事．
言語処理学会，情報処理学会各会員．
}
\bioauthor{土屋　誠司}{
2000年同志社大学工学部知識工学科卒業．
2002年同大学院工学研究科知識工学専攻博士前期課程修了．
同年，三洋電機株式会社入社．
2007年同志社大学大学院工学研究科知識工学専攻博士後期課程修了．
同年，徳島大学大学院ソシオテクノサイエンス研究部助教．
2009年同志社大学理工学部インテリジェント情報工学科助教．
2011年同准教授．博士（工学）．
主に，知識処理，概念処理，意味解釈の研究に従事．
言語処理学会，人工知能学会，情報処理学会，日本認知科学会，電子情報通信学会各会員．
}
\bioauthor{渡部　広一}{
1983年北海道大学工学部精密工学科卒業．
1985年同大学院工学研究科情報工学専攻修士課程修了．        
1987年同精密工学専攻博士後期課程中途退学．
同年，京都大学工学部助手．
1994年同志社大学工学部専任講師．
1998年同助教授．
2006年同教授．工学博士．
主に，進化的計算法，コンピュータビジョン，概念処理などの研究に従事．
言語処理学会，人工知能学会，情報処理学会，電子情報通信学会，システム制御情報学会，精密工学会各会員．
}
\end{biography}

\biodate




\end{document}
