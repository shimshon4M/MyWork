<?xml version="1.0" ?>
<root>
  <jtitle>文書分類のためのNegationNaiveBayes</jtitle>
  <jauthor>古宮嘉那子伊藤裕佑佐藤直人小谷善行</jauthor>
  <jabstract>本論文は，文書分類のための新手法として，NegationNaiveBayes(NNB)を提案する．NNBは，クラスの補集合を用いるという点ではComplementNaiveBayes(CNB)と等しいが，NaiveBayes(NB)と同じ事後確率最大化の式から導出されるため，事前確率を数学的に正しく考慮している点で異なっている．NNBの有効性を示すため，オークションの商品分類の実験とニュースグループの文書分類の実験を行った．ニュースグループの文書分類では，一文書あたりの単語数（トークン数）を減らした実験と，クラスごとの文書数を不均一にした実験を行い，NNBの性質を考察した．NB，CNB，サポートベクターマシン(SVM)と比較したところ，特に一文書当たりの単語数が減り，クラスごとの文書数が偏る場合において，NNBが他のBayesianアプローチより勝る手法であること，また，時にはSVMを有意に上回り，比較手法中で最も良い分類正解率を示す手法であることが分かった．</jabstract>
  <jkeywords>文書分類，NaiveBayes分類器，ComplementNaiveBayes分類器</jkeywords>
  <section title="はじめに">文書分類においてNaiveBayes(NB)を利用するのは極めて一般的である．しかし，多項モデルを用いたNB分類器では，クラス間の文書数に大きなばらつきがある場合に，大きく性能が下がるという欠点があった．そのため，は「クラスに属する文書」ではなく「クラスに属さない文書」，つまり「補集合」を用いることによりNBの欠点を緩和したComplementNaiveBayes(CNB)を提唱した．しかし，CNBはNBと同じ式，つまり事後確率最大化の式から導くことができない．そこで我々は，事後確率最大化の式から導くことのできるNegationNaiveBayes(NNB)を提案し，その性質を他のBayesianアプローチと比較した．その結果，クラスごとの単語数（トークン数）が少なく，なおかつクラス間の文書数に大きなばらつきがある場合には分類正解率がNB，CNBをカイ二乗検定で有意に上回ること，また，これらの条件が特に十分に当てはまる場合には，事前確率を無視したCNBも同検定で有意に上回ることを示す．また，NNBは，Bayes手法以外の手法であるサポートベクターマシン(SVM)よりも，時に優れた結果を示した．本稿の構成は以下のようになっている．まず節でBayes手法のテキスト分類の関連研究について紹介する．節では提案手法であるNNBの導出について述べる．節では本研究で用いたデータと実験方法について述べ，節に結果を，節に考察を，節にまとめを述べる</section>
  <section title="関連研究">これまでに数多くの文書分類に関する研究がなされており，これらの中でも，Bayesの手法はよく用いられている．はhtmlファイルの自動分類でNBを使用し，ルールベースの手法や判別分析に比べて，プログラム開発者にかかる負担の低さとスケーラビリティの高さを指摘している．はNBを適用してテキスト分類を行う際に使用する事象モデルとして，多項モデルと多変量ベルヌーイモデルの違いを述べ，分類結果から多項モデルの優位性を示している．は，文書分類問題において単語と句，単語と句のクラスタ化の有無，全ての索引語を用いるか一部を用いるかの違いについて，分類精度の比較を行った．は，NBが前提とする単語間の独立が成り立たないとし，依存性の強い2単語の組が同時に生起する確率をNBに適用することによって分類精度の向上を図った．Church(2000)は，単語の重み付け方法としてIDF値のかわりに``Adaptation''という概念を用い，文書に含まれていないが内容に関連している単語を``Neighbor''として定義して，テキスト内の特徴的な単語の抽出を行った．さらには，NBにおけるクラスcを未知として拡張したDM(DirichletMixtures)やInfiniteDMを提案し，高村,Roth(2007)高村は，予測的尤度を用いて超変数を設定することなく，加算スムージングのパラメータを求めた．NBを発展させた研究として，補集合を用いて学習を行うCNBが有名である．CNBは，「クラスに属する文書」ではなく「クラスに属さない文書」，つまり「補集合」を用いることによりNBの欠点を緩和した手法である．本研究では，多項モデルを用いたNBとCNBに注目し，その分類における特徴を考慮して，Bayesのアプローチを用いた新しい分類手法NNBを提案する</section>
  <section title="Negation Naive Bayesの導出">NNBはCNBと同様に補集合を利用して文書分類を行うが，CNBと異なってNBと同じ事後確率最大化の式から導出が可能である．その結果，事前確率を数学的に正しく考慮することで，クラスごとの文書数が異なっているときにもより正確な文書分類を行えるようにした．本節ではNBの導出と，CNBの概念について触れた後，提案手法であるNNBの導出について述べる</section>
  <subsection title="Naive Bayes分類器">一般に確率モデルによる文書分類では，分類対象となる文書をd，ある一つのクラスをcとしたとき，事後確率P(c|d)を最大化するクラスcを求める．NB分類器を用いた文書分類では，事後確率にBayesの定理を適用する．文書の取り出される確率P(d)はすべてのクラスについて一定であることを考慮すると，事後確率が最大のクラスを推定することは，クラスの出現確率P(c)と各クラスでの文書の出現確率P(d|c)の積を最大化するクラスを推定することと等しくなる．式()において，P(c)は全文書中でクラスcに属する文書の割合を用いて容易に推定ができるが，P(d|c)を直接推定するのは難しい．そこで，まず文書dを単語列w_1,w_2,,w_nで近似する．次に，各クラスで単語が独立に生起すると仮定すると，式()はと近似される．したがって，dの属するクラスcは最終的に以下の式で求められる</subsection>
  <subsection title="Complement Naive Bayes分類器">多項モデルを用いたNB分類器では，クラス間の文書数に大きなばらつきがある場合に，文書数の小さいクラスでP(w_i|c)が大きくなる傾向がある．P(w_i|c)は「そのクラス中に出てきたそのトークンw_iの数／そのクラス中に出てきたそのトークンの総数」であるため，訓練事例の単語トークン数に大きな差ができた結果，大きいクラスのP(w_i|c)は比較的小さく，小さいクラスのP(w_i|c)はかなり大きくなることが予想できる．その結果，小さいクラスに出現した単語を含む文書が出現した場合，その文書は，その単語をもつ小さなクラスに割り当てられることになる．また，文書数の少ないクラスでは，新規文書に出現した単語がそのクラスに含まれていない割合が多くなり，データがスパースになりやすい．そこで，学習する文書数のばらつきを抑え，スパースネス問題を緩和するようNBを改良したのがのCNBである．具体的には，「クラスcに属す訓練事例」ではなく「クラスcに属さない訓練事例」すなわち「cに属する訓練事例（補集合）」を用いて学習を行う．図は，NBとCNBでの学習に用いる文書数の違いを表している．文書数10，10，20，40の4つのクラスがある場合，NBではこの文書数を自身のクラスの学習に使う．そのため，文書数が最も少ないクラスと最も多いクラスでは学習に使用する文書数に4倍の差がある．一方，CNBでは自身のクラスに属する文書以外の文書から学習を行うため，学習に用いる文書数は最小のもので40，最大のもので70となり，NBに比べてばらつきが小さくなる．CNBは，文書内にある単語の出現確率の積から尤度を計算し，分類するクラスを決めるという点ではNBと同じである．つまり，式()を用いて文書dの属するクラスcを推定する．しかし，CNBではP(w_i|c)を最尤推定で求めるのではなく，c以外のクラスcの尤度の積から推定する．つまり，dの属するクラスcは最終的に以下の式で求められる</subsection>
  <subsection title="Negation Naive Bayes分類器">前節で説明したCNBは，NBの持つ「クラス間の文書数のばらつきによって分類結果が偏る」という特徴を緩和する手法である．しかし，CNBはヒューリスティックによる解決法であって，事後確率最大化の式から導出することはできない．そこで本研究では，事後確率最大化の式から導出でき，かつ，CNBの「訓練にクラスの補集合を利用する」という長所をもつ分類器を作成する．以下でNBと同様の，事後確率最大化の式（式()）からの式の変形について述べる．まず，事後確率P(c|d)を最大化するクラスcを求める式を補集合を利用するように変形する．次に，Bayesの定理を用いて式()を変形する．そして，式()を近似する．P(d|c)は式()，()と同様にと近似される．したがって，文書dの属するクラスcを以下の式で推定する．なお，P(c)=1-P(c)であり，CNBと同じく最大化で表現すると以下の式になる．式()と比較すると，11-P(c)の最大化の部分，つまり事前確率P(c)の部分が異なっていることが分かる．式()は事後確率最大化の式から求められたため，事前確率を数学的に正しく考慮した式となっている．なお，Rennieらの研究では，式()において事前確率の扱いについてあまり注意を払っていないが，我々はクラスごとに単語数の偏りが大きいデータセットについて分類を行う場合には，P(c)を利用するか11-P(c)を利用するかの影響は必ずしも無視して良いとは言えないと考える．また，Rennieらの研究では，P(c)はP(w_i|c)に比べて分類結果への影響が小さいと判断し，事前確率は計算してもしなくても結果は同じと考え，実際の分類にはP(c)を無視してP(w_i|c)のみを計算しているため，P(c)なしのCNBについても参考として実験を行う</subsection>
  <section title="実験">NNBの性能を測りその特色を調べるため，ふたつのコーパスを用いた実験を行った．一つ目はオークションの商品分類の実験であり，二つ目はニュースグループの文書分類の実験である．これらの二つの実験において，形態素解析により得た表層形のbag-of-wordsを用いてNB，CNB，NNBの文書分類の性能を比較した．また，NBBとCNBの差は事前確率P(c)と11-P(c)の部分であるため，CNBとNNBから第一項を省略した形の式（P(c)なしのCNB）でも実験を行った．なお，形態素解析ソフトにはMeCabを利用した．また，スムージング手法としては，予備実験によりラプラススムージングとJeffreysPerks法を試し，JeffreysPerks法の方が結果がよかったため，これを採用した．さらに，Bayesではない手法の比較対象として，SVMについても実験を行った．この際，分類器としてはマルチクラス対応のSVM(libsvmcjlin/libsvm/)を使用した．カーネルは予備実験の結果，線形カーネルが最も高い正解率を示したため，これを採用した．また，学習の素性はBayesの手法とそろえ，表層形のbag-of-wordsの頻度ベクトルを使用した．すべての実験には五分割交差検定を用いた</section>
  <subsection title="オークションの商品分類の実験">オークションの商品分類の実験は，Yahoo!オークションの商品タイトルを商品カテゴリに分類する実験である．詳細はにならった．本実験では，「デスクトップ」「記念切手」「赤ちゃん用の玩具」の三つのジャンルカテゴリに含まれる商品を対象に実験を行った．これらのジャンルカテゴリは，以下のようにトップカテゴリ（オークション）から絞り込むことができる．オークション&gt;コンピュータ&gt;パソコン&gt;Windows&gt;デスクトップオークション&gt;アンティーク，コレクション&gt;切手，官製はがき&gt;日本&gt;特殊切手，記念切手オークション&gt;おもちゃ，ゲーム&gt;ベビー用ここで，&gt;の左が親カテゴリ，右が子カテゴリを示す．「デスクトップ」と「記念切手」は2012年6月26日に，「赤ちゃん用の玩具」は2012年6月29日に取得したデータである．ひとつの商品はひとつの葉カテゴリにのみ属しているものとし，出品者によって登録されたカテゴリを正しいカテゴリとして実験を行った．なお，例えばジャンルカテゴリが「デスクトップ」の場合，「ASUSの1,000円〜1,099円」や「IBMパソコン単体31,000円〜34,999円」といったものが葉カテゴリである．また，にならい，出品者個人による商品情報表記の癖などの偏りをなくすため，各カテゴリにつき1人の出品者の商品は1つしか使用しないものとし，商品タイトルの全単語を利用した実験と名詞のみを使用した二つの実験を行った．Tab:同じ出品者による商品をひとつにする前と後の商品数にそれぞれのジャンルカテゴリ中の葉カテゴリ数，同じ出品者による商品をひとつにする前と後の商品数を示す．ここで，商品数（処理前），商品数（処理後）はそれぞれ，同じ出品者による商品をひとつにする前と後の商品数である．なお，「赤ちゃん用の玩具」の商品数（処理後）には8205，8204と二つ数字があるが，8205は全ての品詞の分類，8204は名詞のみの分類による商品数を示している．「赤ちゃん用の玩具」のデータには，形態素解析の結果，全ての形態素が名詞以外の品詞に割りつけられた商品が1件あったため，このような結果になっている．また，Fig:pc，Fig:stamp，Fig:toyにそれぞれ「デスクトップ」，「記念切手」，「赤ちゃん用の玩具」のカテゴリごとの文書数，単語トークン数，名詞のトークン数を折れ線グラフにしたものを示す．横軸のカテゴリindexは，カテゴリを文書数で並べ替えたときに降順につけたものである．これらの図から，カテゴリの分類実験において，カテゴリごとに文書数，トークン数が非常に偏っていることが分かる．特に，「記念切手」が最も偏っていることが読みとれる．また，Tab:オークションのカテゴリ分類実験のデータにオークションのカテゴリ分類実験の訓練事例中の商品数の標準偏差，訓練事例中の文書数の標準偏差を訓練事例中の総文書数の平均で割った値（以降，標準偏差／平均と表記），トークン数，1商品当たりの平均単語数を示す．標準偏差／平均は，カテゴリ（またはクラス）ごとの商品数（または文書数）のばらつきを見るために示した．ばらつきを測るのには標準偏差を用いるのが一般的であるが，本実験のように全商品数（または文書数）が異なる実験設定同士を比べる際には，全商品数（文書数）の絶対値が大きくなるにつれて標準偏差も大きくなるという問題があったためである．標準偏差を平均で割ることによって，全商品数（文書数）のスケールに左右されないデータのばらつきを測った．Tab:オークションのカテゴリ分類実験のデータのこの「訓練事例中の商品数の標準偏差／平均」を見てみると，「記念切手」の値が「デスクトップ」や「赤ちゃん用の玩具」より高いことから，Fig:pc〜Fig:toyから読みとったように，「記念切手」が最も偏っていることが読みとれる</subsection>
  <subsection title="ニュースグループの文書分類の実験">ニュースグループの文書分類の実験のコーパスには20Newsgroupsを利用した．20Newsgroupsは，全20クラス，18774件のニュース記事からコーパスが構成されており，文書数はどのクラスもおよそ1000件である(cf.~Tab:クラスごとの文書数を不均一にした実験のクラスごとの文書数)</subsection>
  <subsubsection title="一文書あたりの単語数を減らした実験">CNBとNNBの式，式()と式()を比較してみると，事前確率P(c)と11-P(c)の部分が異なっていることが分かる．残りの_i=1^n1P(w_i|c)については等しい．しかし，単語数が少ない文書を分類する際には，単語数が多い文書を分類する際よりも，相対的に事前確率の影響が大きくなることが予想される．そのため，一文書あたりの単語数を減らして実験を行い，その分類正解率を比較する．この際，一文書あたりの単語数をnとし，パラメータをxとすると，一文書あたりの単語数をn/2^x（ただし割り切れない場合には1を加算する）として実験した．パラメータxは，0〜4を試した．xが0のときには，オリジナルの20Newsgroupsと等しい．ニュースグループの分類実験において一文書あたりの単語数を減らした実験の訓練事例中の単語数，1文書当たりの平均の単語トークン数をTab:一文書あたりの単語数を減らした実験のデータに示す．なお，このとき訓練事例中の総文書数はすべて18,774であり，訓練事例中の文書数の標準偏差はすべて95.95である．また，訓練事例中の文書数の標準偏差／平均は0.10になる</subsubsection>
  <subsubsection title="クラスごとの文書数を不均一にした実験">NNBは事前確率を数学的に正しく考慮しているため，文書分類ではクラスごとの文書数が不均一である際に効果を発揮すると考えられる．そのため，20Newsgroupsにおいて，クラスごとに文書を間引きすることによって，クラスごとの文書数を不均一にして実験を行い，比較する．この際，クラスのインデックスをi=1...20，パラメータをyとすると，i=1だけは常にオリジナルの文書数を保ったままとし，i=2から文書数を1/((i-1)y)に減らして実験を行った．例えば，y=1のときには，i=2，3，4の時にはそれぞれ1/1，1/2，1/3となり，y=2のときには，i=2，3，4の時にはそれぞれ1/2，1/4，1/6となる．パラメータyは，1〜4を試した．Tab:クラスごとの文書数を不均一にした実験のクラスごとの文書数に，クラスごとの文書数を不均一にした実験のクラスごとの文書数を示す．また，Tab:一文書あたりの単語数を減らした実験のデータにニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の訓練事例中の総文書数，文書数の標準偏差，標準偏差／平均，単語トークン数，1文書当たりの平均の単語トークン数を示す．また，ニュースグループの分類実験においてクラスごとの文書数を不均一にした実験の訓練事例中の総文書数，文書数の標準偏差，標準偏差／平均，単語トークン数，1文書当たりの平均の単語トークン数をTab:クラスごとの文書数を不均一にした実験のデータに示す</subsubsection>
  <section title="結果">Tab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率とTab:全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率（マクロ）に全ての品詞を使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示し，Tab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率とTab:名詞だけを使用したオークションのカテゴリ分類実験の分類正解率（マクロ）に名詞だけを使用したオークションのカテゴリ分類実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．また，Tab:一文書あたりの単語数を減らした実験の分類正解率とTab:一文書あたりの単語数を減らした実験の分類正解率（マクロ）にニュースグループの分類実験において，一文書あたりの単語数を減らした実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示し，Tab:クラスごとの文書数を不均一にした実験の分類正解率とTab:クラスごとの文書数を不均一にした実験の分類正解率（マクロ）に同分類実験において，クラスごとの文書数を不均一にした実験の分類正解率のマイクロ平均とマクロ平均をそれぞれ示す．なお，正解率は，（分類に成功したもの）／（実験データ数）として求めた．同じ文書集合の実験で，NB，CNB，NNBのうちで最も良かった正解率を太字で示した．さらに，次に良かった正解率との差がカイ二乗検定で有意だったものに関しては下線を引いた．また，P(c)なしのCNBとSVMに関しては，上記の三手法のうち最も良かった手法と同じか，それよりも良いものは太字で示し，その優劣にかかわらず，差がカイ二乗検定で有意だったものに関しては下線を引いた．さらに，参考として最頻出カテゴリ（クラス）を答えた場合の正解率も併記した</section>
</root>
