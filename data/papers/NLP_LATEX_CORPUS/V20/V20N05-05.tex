    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline


\Volume{20}
\Number{5}
\Month{December}
\Year{2013}

\received{2013}{5}{29}
\revised{2013}{7}{20}
\accepted{2013}{8}{8}

\setcounter{page}{727}

\jtitle{歴史的日本語資料を対象とした形態素解析}
\jauthor{小木曽智信\affiref{Author_1}\affiref{Author_2} \and 小町　　守\affiref{Author_3} \and 松本　裕治\affiref{Author_4}}
\jabstract{
単語情報がタグ付けされた本格的な通時コーパスを構築するためには，歴史的な日本語資料の形態素解析が必要とされるが，従来はこれを十分な精度で行うことができなかった．そこで，現代語用のUniDicに語彙の追加を行い，明治時代の文語文と平安時代の仮名文学作品のコーパスを整備することで，「近代文語UniDic」と「中古和文UniDic」を作成した．この辞書によりコーパス構築に利用可能な約96〜97\%での解析が可能になった．この辞書の学習曲線をもとに歴史的資料の形態素解析辞書に必要な訓練用のタグ付きコーパスのサイズを調査した結果，約5万語のコーパスで精度95\%を超える実用的な解析が可能になること，5,000語程度の少量であっても対象テキストの訓練コーパスを用意することが有効であることを確認した．
}
\jkeywords{古文，形態素解析，歴史コーパス，UniDic}

\etitle{Morphological Analysis of Historical Japanese Text}
\eauthor{Toshinobu Ogiso\affiref{Author_1}\affiref{Author_2} \and Mamoru Komachi\affiref{Author_3} \and Yuji Matsumoto\affiref{Author_4}} 
\eabstract{
To construct a richly annotated diachronic corpus of Japanese, the morphological analysis of historical Japanese text is required. However, conventional analysis of old Japanese texts with adequate accuracy is impossible. To facilitate such analyses, we extended dictionary entries from UniDic for Contemporary Japanese and prepared training corpora including articles illustrating the literary style of the Meiji Era and literature of the Heian Era, thus creating new dictionaries: ``UniDic-MLJ (Modern Literary Japanese)'' and ``UniDic-EMJ (Early Middle Japanese).'' These dictionaries achieve a high accuracy (96--97\%) as that required for constructing a diachronic corpus of Japanese. Moreover, we investigated the optimal size of the training corpus for the morphological analysis of historical Japanese text on the basis of the learning curves obtained by using these dictionaries. We confirmed that a 50,000-word corpus achieves an adequate accuracy of over 95\%, and even a small-sized corpus (only 5,000 words) is effective as long as the corpus is particularly constructed for the target domain.
}
\ekeywords{Classical Japanese, Morphological Analysis, Historical Corpus of Japanese, UniDic}

\headauthor{小木曽，小町，松本}
\headtitle{歴史的日本語資料を対象とした形態素解析}

\affilabel{Author_1}{国立国語研究所}{National Institute for Japanese Language and Linguistics}
\affilabel{Author_2}{奈良先端科学技術大学院大学}{Nara Institute of Science and Technology}
\affilabel{Author_3}{首都大学東京}{Tokyo Metropolitan University}
\affilabel{Author_4}{奈良先端科学技術大学院大学}{Nara Institute of Science and Technology}



\begin{document}
\maketitle

\section{はじめに}

『現代日本語書き言葉均衡コーパス (BCCWJ)』（国立国語研究所2011）\nocite{NINJAL2011}の完成を受けて，国立国語研究所では日本語の歴史をたどることのできる「通時コーパス」の構築が進められている\footnote{NINJAL通時コーパスプロジェクト http://www.historicalcorpus.jp/}\cite{近藤2012}．コーパスの高度な活用のために，通時コーパスに収録されるテキストにもBCCWJと同等の形態論情報を付与することが期待される．しかし，従来は十分な精度で古文\footnote{本稿では，様々な時代・文体・ジャンルの歴史的な日本語資料を総称して「古文」と呼ぶ．} の形態素解析を行うことができなかった．残された歴史的資料は有限であるとはいえ，その量は多く，主要な文学作品に限っても手作業で整備できる量を大きく超えている．また，均質なタグ付けのためには機械処理が必須である．

本研究の目的は，通時コーパス構築の基盤として活用することのできるような，歴史的資料の形態素解析を実現することである．通時コーパスに収録されるテキストは時代・ジャンルが幅広いため，必要性の高い分野から解析に着手する必要がある．明治時代の文語論説文と平安時代の仮名文学作品は，残されたテキスト量が多いうえ，日本語史研究の上でも価値が高いことから，これらを対象に，96\% 以上の精度での形態素解析を実現することを目指す．そして，他の時代・分野の資料の解析に活かすために，各種条件下での解析精度の比較を行い，歴史的資料を日本語研究用に十分な精度で解析するために必要な学習用コーパスの量を確認し，エラーの傾向を調査する．

本研究の主要な貢献は以下の通りである．

\begin{itemize}

\item 現代語用のUniDicをベースに見出し語の追加を行って古文用の辞書データを作成した．

\item 新たに古文のコーパスを作成し，既公開のコーパスとともに学習用コーパスとして，MeCabを用いたパラメータ学習を行い形態素解析用のモデルを作成した．
\item 同辞書を単語境界・品詞認定・語彙素認定の各レベルで評価し，語彙素認定のF値で0.96以上の実用的な精度を得た．また，同辞書について未知語が存在する場合の解析精度を実験により推測し，その場合でも実用的な精度が得られることを確認した．

\item 同辞書の学習曲線を描き，古文を対象とした形態素解析に必要なコーパス量が5〜10万語であること，5,000語程度の少量であっても専用の学習用コーパスを作成することが有効であることを確認した．

\item 高頻度エラーの分析を行い，特に係り結びに起因するものは現状の解析器で用いている局所的な素性では対処できないものであることを確認した．
\end{itemize}



\section{研究の背景}

\subsection{古文の形態素解析}

現代文を対象とした日本語形態素解析は1990年代には実用的になっていたが，古文を対象とした形態素解析は長い間実現せず，コンピュータによる古文の処理を行おうとする人々から待ち望まれていた．日本語学・国語学の分野においては，BCCWJの完成によってコーパスを用いた現代語の研究が盛んになりつつあるが，形態素解析は複雑な共起条件を指定した用例検索や，コロケーション強度の取得，テキストごとの特徴語抽出，多変量解析を用いた研究など，新しい手法による研究を可能にしている．歴史的資料の形態素解析が可能になることで，日本語の史的研究の分野においてもこれが可能になり新しい知見がもたらされることが期待される．

\citeA{村上2004}は，計量文献学の立場から，古典の研究資料としての価値を論じた上で「古典に関して計量分析で著者に関する疑問を解明できたなら，古典研究に大きな刺激を与えるにちがいない．ただ，残念なことに文章を自動的に単語に分割し，品詞情報等を付加する形態素分析のプログラムの開発が古文の場合，遅れている」(p.~191)と述べている．また，\citeA{近藤2009}は古典語研究の立場から「古典語は形態素解析の自動化がしにくいため，単語レベルの索引を作るには，すべて手作業で形態素解析を行う必要があるため，多くの資料を対象に語彙研究することは困難である」と述べている．

もっとも，古文の形態素解析の実現のための研究はこれまでにも行われてきた．早い時期の研究として，\citeA{安武1995}，\citeA{山本1996}などがある．しかし，古文の電子的な辞書やコーパスが不足していたこともあり，これらはいずれも試行のレベルにとどまっており，アプリケーションの公開も行われていない．また，研究の主眼が解析手法の開発自体にあるため，コーパスや辞書の整備も最小限しか行われてこなかった．このほか，\citeA{山元2007}が和歌集の言語学的分析を目的として和歌の形態素解析を実現しているが，これは和歌に特化したものであり，散文等の古文一般に適用できるものではない．このように，多くの資料を対象にした通時コーパス構築の基盤として利用可能な形態素解析のシステムは新たに作成する必要があった．


\subsection{UniDicと古文}

通時コーパスに先だって構築されたBCCWJでは，新しく開発された形態素解析辞書UniDic\footnote{http://download.unidic.org} を利用して形態論情報が付与された．UniDicは，(1) 見出し語として「短単位」という揺れが少ない斉一な単位を採用している， (2) 語彙素・語形・書字形・発音形の階層構造を持ち，表記の揺れや語形の変異をまとめ上げることができる， (3) 個々の見出し語に語種やアクセント型などの豊富な情報が付与されている，といった言語研究に適した特長を持っている\cite{伝2007}．

古文の形態素解析にとっても，上述のUniDicの特長は非常に有効である．たとえば，揺れの少ない斉一な単位は，テキストの解析結果を用いた語彙の比較を可能にする．従来の古典文学作品の総索引は単位認定や見出し付与の方針の違いにより相互の比較が難しい場合があった．しかし通時的なコーパスを構築する場合には，現代語コーパスと共通する一貫した原理に基づいた情報付与を行って，一作品・一時代にとどまらず古代から現代に至る「通時」的な観察を可能にする必要がある．UniDicをベースとすることで，作品間の比較が可能になるだけでなく，時代の違いを超え，各種のテキスト間で相互に語彙を比較することが可能になる．また，階層化された見出しを用いることで，文語形や旧字・旧仮名遣いの語を同一見出しの元にまとめることができるため，さまざまな時代のテキストに出現する語形・表記を統一的に扱うことができる． 

こうした理由から，本研究では現代語用のUniDicをもとにして，歴史的資料のための形態素解析辞書を作成することにした．UniDicでは，形態素解析器にMeCab\footnote{https://code.google.com/p/mecab/} \cite{Kudo2004}を用いている．MeCabはCRF\cite{Lafferty2001}にもとづく統計的機械学習によって高精度な形態素解析を実現しており，学習器も公開されている．したがって，古文の学習用コーパスを用意し，UniDicの見出し語を拡充することで古文に対応することができる．3.1節で示すように，見出し語を追加するだけでは実用的な解析精度を達成することはできず，学習用コーパスを用いて形態素解析器を再学習することが重要である．


\subsection{解析対象のテキスト}

一口に古文と言っても，その中身は極めて多様である．通時コーパスでは，時代幅としては8世紀から19世紀までが，ジャンルとしては和歌から物語，仏教説話，軍記物，狂言，また洒落本などの近世文学，さらに近代の小説や論説文，法律までが対象となる．これらのテキストの文体は，文法・語彙・表記にわたって極めて多様であって，単に「古文」としてひとくくりにして済むものではない\cite{小木曽2011}．

テキストに大きな違いがある以上，解析対象のテキストごとに最適の辞書を作成することができれば望ましいが，残された歴史的資料は有限であり，少量のテキストのために個別に辞書を作成することは現実的ではない．文体的に近いテキストを十分な量のグループにまとめ，グループごとに適した形態素解析辞書を用意することが適切である．

こうしたグループとしてまず考えられるのは，今から約1000年前の平安時代（中古）に書かれた仮名文学作品を中心とする和文系の資料である．中でも源氏物語は日本語の古典の代表的なものであり，その文体は，中世の擬古物語や近世・近代の擬古文に至るまで模倣されながら長い期間にわたって用いられている．もう一つのグループとしてあげられるのは，約100年前に広く用いられていた近代の文語文である．中でも明治普通文とも呼ばれる近代の文語論説文は，明治以降戦前にかけて広く用いられた文体であり，公文書から新聞・雑誌まで各種の資料がこれによって書かれている．表 1に二つのグループに属するテキストの例を挙げる．

\begin{table}[t]
\caption{中古和文と近代文語文のテキスト例}
\label{tab1}
\input{05table01.txt}
\end{table}

近代文語文は，平安時代以来の漢文訓読文の流れに位置づけられる文体である．漢文訓読文では漢語が多く用いられるのに対して，和文では漢語はわずかしか用いられない．また和文と漢文訓読文では使用する和語の語彙も大きく異なっていることが知られている．こうした語彙の違いからも，現代語からの時代的遠近という点からも，中古和文と近代文語文は対照的な位置にあり，この 2 つのグループについて形態素解析辞書を用意することは，通時コーパス全体の解析を目的とする上で有効であると考えられる．



\subsection{現代語用のUniDicによる古文の解析精度：ベースライン}

一般に公開されている現代語用の形態素解析辞書はこれによって古文を解析することは考慮されていない．古文では，特に助動詞などの機能語の用いられ方が大きく異なるため，現代語用の辞書で古文を解析することは困難であると考えられる．現代語用に作られたUniDicも同様であるが，新たに作成する古文用辞書と比較するためのベースラインとして，手始めに現代語用のUniDicで近代文語文と中古和文を解析した場合の精度を調査する．

評価に用いる現代語用UniDicは一般公開されているunidic-mecab-2.1.0である．UniDicの学習にはコーパスとしてBCCWJのコアデータのほか日本語話し言葉コーパスとRWCPコーパスの一部が用いられており，学習素性としては語彙素・語彙素読み・語種・品詞・活用型・活用形・書字形が用いられている\cite{Den2008}．UniDicの見出し語は，語彙素・語形・書字形・発音形の階層構造を持っている．そのため，解析結果の精度評価もこの階層ごとに行った．最も基礎的なレベルとして，単語境界の認定が正しく行われているかを見る「Lv.1境界」を設定した．またこれに加えて品詞・活用型・活用形の認定が正しいかどうかを見る「Lv.2品詞」，Lv.1・Lv.2に加えて語彙素（辞書見出し）としての認定も正しかったかどうかを見る「Lv.3語彙素」を設定した．Lv.3は，たとえば「金」が「キン」でなく「カネ」と正しく解析されているかどうかを見ることになる．さらに，Lv.1〜Lv.3が正しいことに加え，読み方が正しいかどうかを見る「Lv.4発音形」を設定した．Lv.4は，古文の場合には発音というよりは語形の違いが正しく認定されているかどうかを評価するものである．たとえば，「所」が文脈にあわせて「トコロ」ではなく「ドコロ」と正しく解析されているかどうかを見ることになる．

ところで，現代語の辞書で古文を解析した場合には，活用型が文語であるか口語であるかの違いによって誤りとされる例が多い．たとえば動詞「書く」は口語ではカ行五段活用（「五段-カ行」）だが，文語ではカ行四段活用（「文語四段-カ行」）で定義されているため両者が一致しないと品詞レベルで誤りと見なされる．しかし両者は本質的には同語であるといってよく，相互に容易に変換することができる．そこで，こうした口語・文語の活用型の対についてはいずれを出力した場合にも正解と見なした場合の精度についても調査した．具体的には，「文語形容詞-ク」と「文語形容詞-シク」を「形容詞」と同一視し，「文語四段」は「五段」，「文語サ行変格」は「サ行変格」，「文語下二段」は「下一段」，「文語上二段」は「上一段」と同一視した．さらに文語の「-ハ行」「-ワ行」を「-ア行」と同一視した．

以上の観点でまとめた解析精度の調査結果を表2に示す．評価コーパスは，後述する人手修正済みのコーパスから約10万語を文単位でランダムサンプリングしたものである．評価項目は次に示すPrecision（精度），Recall（再現率），F値（PrecisonとRecallの調和平均）である．
\begin{gather*}
\mbox{Precision} = \frac{正解語数}{システムの出力語数} \\[1ex]
\mbox{Recall} =  \frac{正解語数}{評価コーパスの語数} \\[1ex]
\mbox{F値} = \frac{2 * \mbox{Precision} * \mbox{Recall}}{\mbox{Precision} + \mbox{Recall}} 
\end{gather*}

活用型の補正なしの場合の語彙素レベルのF値でみると，近代語では0.6775，中古和文では0.5432となっており，予想通り通時コーパス構築の実用に耐える精度ではない．中古和文と比べ近代文語の方が比較的精度が良いが，これは現代語との年代差が少ないため使用される語彙が近いことによるものと考えられる．補正後は，近代語では0.7323，中古和文では0.5939となっている．補正による上昇は0.05ポイント程度であり，単純な活用型変換を行ってもさほど精度は向上しないことが分かる．

\begin{table}[t]
\caption{現代語用 UniDic による近代文語・中古和文の解析精度}
\label{tab2}
\input{05table02.txt}
\end{table}

このように古文の形態素解析のためには辞書への古文の見出し語追加が必須であり，また古文のコーパスで再学習を行うことで解析精度の向上が期待できる．以下，3節で見出し語の追加と学習用コーパスの構築について説明する．4 節では見出し語追加と再学習を行った提案手法による解析精度を他の手法と比較して確認し，その後この辞書による各種テキストの解析精度について議論する．


\section{見出し語の追加と学習用コーパスの作成}

\subsection{現代語用のUniDicに対する見出し語の追加}

古文用の形態素解析を行うために，現代語用の辞書に見出し語の追加を行った．UniDicでは見出し語を語彙素・語形・書字形・発音形の4段階で階層的に管理しているため，近代語解析に必要な語を各階層に整理して追加することができる．現代語としては使われなくなっている語は「語彙素」のレベルで，文語活用型の語は「語形」のレベルで，異体字や旧字形など表記の違いは「書字形」のレベルで追加することになる（図 1）．これにより，現代語のための見出し語と統一的に管理することができ，文語形と口語形，新字形と旧字形がそれぞれ関係を持つものであることを示すことができる．

\begin{figure}[t]
\begin{center}
\includegraphics{20-5ia5f1.eps}
\end{center}
\caption{UniDicの階層（語彙素・語形・書字形）と文語形・旧字形}
\label{fig1}
\vspace{-1\Cvs}
\end{figure}

これまでに近代文語文のために追加した語彙は，語彙素レベルで10,814語，語形レベルで12,417語，書字形レベルで25,224語であった．また，中古和文のために追加した語彙は，語彙素レベルで5,939語，語形レベルで7,351語，書字形レベルで13,763語であった．両者には共通の語彙も多いが近代文語文の語彙追加を先に行ったため，中古和文のための追加数が少なくなっている．もともとあった現代語の見出し語とあわせ，全体の見出し語数は，語彙素225,588語，語形253,061語，書字形413,897語となっている．

追加した見出し語は，現代語形から派生させた文語形や旧字形を追加するところからはじめ，既存の古語辞典やデータ集の見出し語からも追加を行った．しかし，形態素解析辞書の見出し語としては，UniDic体系に基づく詳細な品詞を付与し，実際に出現する表記形を入力する必要があるため，単なる辞典の見出し語リストは多くの場合，登録用のソースとして不十分である．そのため，大部分の語彙は，後述する学習用コーパスを整備する過程で不足するものを追加する形で行った．

見出し語の単位認定については，通時的な比較ができるようにするため，可能な限り現代語と共通の枠組みで処理を行った．しかし，語の歴史的変化や古文における使用実態を踏まえ，時代別に異なった扱いをしている語も少なくない．たとえば，指示詞について，現代語のUniDicでは「この」「その」などは 1 語の連体詞として扱っているが，「こ」「そ」が単独で指示代名詞として使われる中古語では，これらは代名詞＋格助詞として扱った方が適切である．このように，歴史的資料向けの辞書見出しの追加は単純な作業ではなく，通時的な共通性に配慮しつつ，各時代の言語の実態を反映させるかたちで見出し語を認定するという高度な判断にもとづくものである．その積み重ねによって作られた見出し語リストは，日本語の通時的な処理を行う上で基礎となる重要なデータであると言える．

また，中古和文UniDicの見出し語認定基準は規程集としてまとめ公開している\cite{小椋2012}\footnote{http://www2.ninjal.ac.jp/lrc/index.php?UniDic} が，これは通時的な比較を考慮した歴史的資料の処理にとって利用価値が高い資料である．中古和文用の規定はそのまま他の時代の資料に適用できるわけではないが，日本語の古典文法は中古和文を基準として作られたものであるため，この規定を中核として追加・修正を行うことで各時代向けの辞書を作成していくことが可能である．

語彙の追加と平行して活用表の整備も行った．UniDicはもともと文語の活用表を一部備えていたが，これを整備して網羅的なものとするとともに，通時コーパス構築に必要な活用形の追加を行った． 

UniDicは現代語用に整備されてきたため，古文では用いられない語彙を多く含んでいる．しかし，基礎語彙の多くは中古和文でも共通であり，どの語が不要であるかを事前に判断することは必ずしも容易ではない．また，古文の形態素解析辞書にとって見出し語の肥大化は大きな問題ではないうえ，不要語があることによる解析精度への悪影響は認められなかったため，現代語用の見出しも原則としてそのままとした．同様の理由から，近代文語UniDicと中古和文UniDicの間でも同一の語彙表を用いている．

\begin{table}[b]
\caption{古文用の見出し語を追加した現代語用UniDicによる解析精度}
\label{tab3}
\input{05table03.txt}
\end{table}

以上のような見出し語の追加だけであれば，学習用コーパスの作成に比べて低コストで行うことができる．そこで，見出し語の追加だけで十分な精度向上が見られるのかどうか確認するため，古文用の見出し語を追加した現代語用のUniDicを作成し，2.4節の表 2と同様に解析精度を調査した．その結果を表 3に示す．見出し語の追加によって，近代文語では，語彙素認定のF値で約0.06ポイント向上し0.7363，補正後の数字で0.797となっている．また，精度の低かった中古和文では，語彙素認定のF値で約0.07ポイント向上し0.6190，補正後の数字で0.664となっている．しかし，やはりこの精度は不十分であり，見出し語の追加だけでは通時コーパスの構築にとって十分なだけの精度は得られなかった．


\subsection{学習用コーパスの準備}

前節で確認したように，古文の形態素解析のためには，見出し語の追加だけでなく学習用コーパスの整備が必要となる．

近代文語では，主たる解析対象の明治期の文語論説文を中心に，表4の約64万語の人手修正済みのコーパスを作成した．
近代詩・小説・法令・論説文の大部分は「青空文庫」\unskip\footnote{http://www.aozora.gr.jp/} 所収のテキストを利用し，論説文としては他に上田修一氏作成の「文明論之概略」テキストデータ\footnote{http://web.keio.jp/\~uedas/bunmei.html} を利用した．
また，雑誌の本文は国立国語研究所の「太陽コーパス」「近代女性雑誌コーパス」\unskip\footnote{http://www.ninjal.ac.jp/corpus\_center/cmj/ なお，「太陽コーパス」「近代女性雑誌コーパス」は文書構造等がタグ付けされたコーパスで形態論情報は付与されていない．} の一部のテキストを利用した．
以上のテキストに対して独自にUniDicベースの形態論情報をタグ付けしたデータに加え，国立国語研究所で公開された形態論情報付き「明六雑誌コーパス」\unskip\footnote{http://www.ninjal.ac.jp/corpus\_center/cmj/meiroku/} を学習用のデータとして利用した．

\begin{table}[b]
\begin{minipage}[t]{0.5\textwidth}
\caption{近代文語のコーパス}
\label{tab4}
\input{05table04.txt}
\end{minipage}
\begin{minipage}[t]{0.5\textwidth}
\caption{中古和文のコーパス}
\label{tab5}
\input{05table05.txt}
\end{minipage}
\end{table}

中古和文では，2012年に国立国語研究所によって公開された「日本語歴史コーパス 平安時代編 先行公開版」\unskip\footnote{http://www.ninjal.ac.jp/corpus\_center/chj/}
のデータを学習に利用した．このコーパスは，表 5に示す平安時代の仮名文学作品を中心とした約82万語の人手修正済みの形態論情報を含んでいる．

学習用のコーパスは段落や改行，振り仮名などがタグ付けされたテキストに形態論情報を付与したもので，これを関係データベース上で辞書データと紐付けて管理している．近代語コーパスでは，さらに濁点が付されていない部分に濁点を付与するなど表記上の問題に対処するためのタグ付けを行い，また文末を認定してセンテンスタグを付与している．日本語の歴史的資料のコーパスを形態素解析辞書の機械学習に利用可能な形で整備したのはこれが初めての試みである．

近代文語文と中古和文は，同じ古文と言っても大きく性質の異なる文体である．近代文語文では低頻度語が多く，上記のコーパス中，書字形（基本形）で集計した場合，頻度1の語が18,120語，頻度2の語が5,943語含まれていた．一方，中古和文では，頻度1の語が6,198語，頻度2の語が2,134語にすぎない．近代文語文は，明治維新後に西洋の新たな文物を吸収していく時代において，新しい書き言葉を確立していく過程にあった文体であるため，新たに作られながらも定着しなかった語などの低頻度語が目立つ．また，書かれる内容が多様で文体差が大きい．一方，中古和文は，古代の宮廷における限られたコミュニティの中で当時の話し言葉に基づいて書かれた文章であり，内容的な幅も狭いため，語彙の広がりが小さい．こうした違いは，形態素解析の精度にも影響を及ぼしてくると考えられる．


\subsection{MeCabを用いたコーパスからのパラメータ学習}

MeCabでコーパスからのパラメータを学習する場合，設定ファイルrewrite.defとfeature.defによって，学習に用いる内部素性のマッピングと，内部素性からCRF素性を抽出するためのテンプレートを書き換えることができる．近代文語UniDicと中古和文UniDicの学習にあたっては，CRF素性を抽出するテンプレート (feature.def) は，どちらの辞書でも現代語用のものをそのまま用いている．利用している素性は，語彙素・語彙素読み・語種・品詞（大分類・中分類・小分類）・活用型・活用形・書字形（基本形と出現形）とその組み合わせである．UniDicでは語種を学習素性として利用しているのが特徴となっており\cite{Den2008}，この素性は古文の解析にも大きく寄与している．

一方，内部素性のマッピング (rewrite.def) は，現代語用UniDicのものを修正して，語彙化する見出し語を文語の助動詞・接辞に置き換えた．たとえば，次の助動詞については品詞ではなく，語彙のレベルで連接コストを計算している．

\begin{quote}
き，けむ，けらし，けり，こす，ごとし，ざます，ざんす，じ，ず，たり，つ，なり，ぬ，べし，べらなり，まし，まじ，む，むず，めり，らし，らむ，り，んす，んなり，んめり，非ず
\end{quote}

助詞・助動詞などの語彙化すべき見出し語については近代文語文と中古和文とで共通する部分が多いため，rewrite.defは近代文語UniDicと中古和文UniDicとで共通のものを利用した．


\section{解析精度の評価}

\subsection{解析精度}

上述の方法で作成した「近代文語UniDic」「中古和文UniDic」の解析精度を調査した．評価コーパスは，3.2節で示した人手による修正済みのコーパスから文単位でランダムサンプリングした10万語分とし，その残りを訓練コーパスとした．評価コーパスは，辞書ごとに固定して，以後の精度評価でも同一のものを用いている．2.4節での調査と同様に，単位境界・品詞・語彙素・発音形の4つのレベルで調査を行った結果を表 6に示す．なお，評価コーパスはもともと学習用に整備したものの一部を転用したものであるため，当初含まれていた未知語は辞書に登録されている．そのため，解釈不能語などを除いて原則として未知語を含んでいない．

\begin{table}[b]
\caption{「近代文語UniDic」「中古和文UniDic」の解析精度}
\label{tab6}
\input{05table06.txt}
\end{table}

語彙素認定のF値で，近代文語は0.9641，中古和文では0.9700となっており，ベースライン（表 2）や見出し語のみを追加した場合（表 3）と比較して大幅に精度が向上している．近代文語UniDicと中古和文UniDicを比較すると，すべてのレベルで中古和文の方が良い精度となっている．これには中古和文の方が訓練コーパスの量が多いことも影響しているが，それよりも3.2節で見たようなテキストの性質の違いによる影響が大きいと考えられる（4.4節参照）．

図 2に，再学習を行った提案手法と，2〜3節で確認した各種手法（現代語辞書によるベースライン，再学習を伴わず見出し語だけを追加した辞書）の解析精度を比較した結果を示す．精度は語彙素認定レベルのF値である．図中の「補正」とは活用型の文語形への変換を行った場合の精度である．

\begin{figure}[t]
\begin{center}
\includegraphics{20-5ia5f2.eps}
\end{center}
\caption{各種方法による解析精度の比較（語彙素レベル・F値）}
\label{fig2}
\end{figure}

このように，コーパスによる再学習によって初めて実用的な精度での解析が可能になる．BCCWJの構築に利用された現代語のUniDicの解析精度が語彙素認定のF値で約0.98であり，ジャンルによっては0.96程度に留まることと比較しても，コーパス構築に利用するために十分な精度が出ていると言える．



\subsection{未知語を考慮した解析精度}

表 6の精度は，基本的に未知語が存在しない状態のコーパスを評価対象とした場合のものであった．しかし，実際の解析対象には未知語が含まれているのが通常である．そこで，未知語を含んだテキストを解析した際の精度を検証した．

評価コーパスには同一のものを用いて，評価コーパスのみに現れ，それ以外の人手修正済みコーパス（＝学習用コーパス）には一度も出現しない語を，近代文語UniDic・中古和文UniDicそれぞれの辞書から削除して未知語を発生させた．削除した語数は，近代文語UniDicでは2,089語（評価コーパス中の出現回数3,128），中古和文UniDicでは795語（評価コーパス中の出現回数824）であった．3.2節で見たように，近代文語文には低頻度の語が多く含まれるため，中古和文に比べて未知語が多く発生することになる．この条件で作成し直した辞書の解析精度を表7に示す．
Precisionが特に低下しており，語彙素認定のF値で見ると，近代文語文では0.0376ポイント低下して0.9265，中古和文では0.0089ポイント低下して0.9611となっている．未知語が多い近代文語文では影響が大きいが，それでも十分に実用的な精度が得られている．

\begin{table}[t]
\caption{未知語の有無による解析精度比較}
\label{tab7}
\input{05table07.txt}
\end{table}

\subsection{未知の資料の解析精度}

前節で見たように学習用コーパスと同一の作品では十分な精度が得られたが，学習用コーパスとは完全に無関係な資料の解析精度を確認する必要がある．未知の資料には，当該辞書の適用対象といえるテキストと，文体差があり必ずしも適切な対象であるとはいえないテキストがある．ここでは，中古和文UniDicを例に，その適用対象内の文体で書かれたテキストであるといえる擬古物語『恋路ゆかしき大将』と，時代的には中古和文に近いが和漢混淆文と呼ばれる別種の文体である『今昔物語集』の一部の解析精度を調査する．調査対象のテキストはいずれも未知語を一部含んだ状態である．それぞれ，表8に示すような文体である．

中古和文UniDicによる擬古物語と和漢混淆文の解析結果を表 9に示す．擬古物語では，語彙素認定のF値で0.95以上の精度を確保している一方，和漢混淆文では0.85程度となっている．ここから，中古和文UniDicがターゲットとしていた文体であれば未知の資料であっても十分な解析が可能であること，一方ターゲットとしていない文体では十分な精度が得られず，再学習など新たな取り組みが必要であることが分かる．

\begin{table}[b]
\caption{擬古物語・和漢混淆文のテキスト例}
\label{tab8}
\input{05table08.txt}
\vspace{0.5\Cvs}
\end{table}
\begin{table}[b]
\caption{「中古和文UniDic」による擬古物語・和漢混淆文の解析精度}
\label{tab9}
\input{05table09.txt}
\end{table}


\subsection{学習に用いるコーパスの量の解析精度への影響}

\begin{figure}[b]
\begin{center}
\includegraphics{20-5ia5f3.eps}
\end{center}
\caption{各種UniDicの学習曲線（語彙素レベル・F値）}
\label{fig3}
\end{figure}

つづいて，学習に用いるコーパスの量の解析精度への影響を確認するために，コーパスの量を変化させて解析精度を評価した．評価コーパスは辞書ごとに固定した10万語で，4.1節・4.2節と同一のものである．学習用のコーパスは，評価コーパス以外の人手修正済みデータを文単位でランダムに並び替えた後，先頭から指定語数分取得している．語数は，2万語までは5,000語ごと，10万語までは2万語ごと，それ以上は10万語ごとに学習用コーパスを増やし，近代文語UniDicでは50万語，中古和文UniDicでは70万語まで評価している．比較のため現代語用のUniDicについても同様の方法で100万語まで評価した．現代語の学習・評価用コーパスにはBCCWJのコアデータを利用した．

この結果を図 3に示す．縦軸が語彙素認定のF値，横軸がコーパス量である．

現代語 $>$ 中古和文 $>$ 近代文語の順に解析精度が低くなるが，この傾向はコーパス量が同じであればどの段階においても同じであり，この差は各辞書が対象とするテキストの（短単位による形態素解析という観点での）難易度を反映したものだといえそうである．ただし，近代文語文の精度低下には，口語による表現が部分的に挿入される場合があることも影響している\footnote{近代文語文のコーパス中，口語表現が占める割合は，抜き取り調査にもとづく概算で1\% 程度である．}．口語表現を除外するようにコーパスを整備したり，口語表現の品詞認定基準を改めたりすることで，他の辞書との差は小さくなるものと思われる．

学習用のコーパス量が5,000語でも0.9以上のF値が得られているが，これは現代語のUniDicで解析した表 2や表 3の結果よりも遙かに良い数値である．古文の形態素解析では，少ない量であっても専用のコーパスを使って辞書を作成することが効果的であることがわかる．また，約5万語のコーパスで95\% の精度に達しており，どの辞書でも約10万語を境に精度向上が大幅に鈍化し飽和していく．短単位の形態素解析辞書を新たに作成するのに必要な学習用のコーパスは約5〜10万語というのが一つの目安であるといえる．



\section{エラー分析}

\subsection{高頻度の解析エラー}

\begin{table}[b]
\caption{高頻度の解析エラー}
\label{tab10}
\input{05table10.txt}
\end{table}

4.1節（表 6）の精度調査におけるエラーから，近代文語UniDic，中古和文UniDicのエラーの傾向を分析する．表 10に，境界認定・品詞認定・語彙素認定の各レベルにおいて特に高頻度のエラーをまとめた．表中括弧内の数字はエラー数である．以下，これらのエラーについてレベル別に確認する．


\subsection{境界認定レベルのエラー}

境界認定のレベルでは，近代文語UniDicは結果として過分割となっているものが272例，同数となるもの74例，過結合となるものが258例であった．中古和文UniDicは過分割となっているものが189例，同数となるものが25例，過結合となるものが176例であった．

中古和文・近代文語でともにエラーが多い「にて」「とも」は，語源にさかのぼると「に／て」「と／も」であり，複合してできた語を語源的に見て2語と扱うか，新たにできた1語として扱うかという認定基準の立て方の問題と関わる．歴史的な言語変化によって一語化が進展していくわけだが，もともと連続して出てきやすい語の連続であり，また全ての「に／て」「と／も」連続が一語化するわけではないため判別が難しい． 

近代文語の「然れども」は，現在の規程では，「しかれども」と読む場合には「然り」と「ども」に分割し，「されども」と読む場合には 1 語の接続詞として扱っている．したがって問題は「然れ」を「され」と読むか「しかれ」と読むかという点にあり，実質上は語彙素認定のエラーであるとも言える．「彼の」も同様で，「かれ（の）」と読めば2語になり，「か（の）」と読めば連体詞として 1 語と見なされる．このように近代語では漢字表記語が多く読みに曖昧さがあり，そこに語の歴史的変化による一語化が進展していることが複合して問題となっている．

一方，近代文語の「論派」は，「○○論派」とある場合に，UniDicの短単位規定で「（（○○）論）派」という語構成を考えて「-論」「-派」がいずれも接尾辞となって切り出されるのに対し，「論派」という 1 語の名詞も存在するためにこちらが優先されることによっている．漢語の多い近代語で目立っているが，これは現代語でも同種の現象が起きる問題であり，漢語の単位認定について，形態素解析では扱いきれない語構成の問題が短単位認定基準に取り込まれていることが要因であるといえる．


\subsection{品詞認定レベルのエラー}

品詞認定のレベルでは，品詞そのものの認定エラーと，活用形の認定のエラーが区別される． 

品詞そのものの認定で中古和文・近代文語ともに最多のものは「に」の認定が助動詞・格助詞・接続助詞の間で揺れるものである．「に」の判別は現代語においても助動詞「だ」連用形と格助詞「に」の間などで問題になるが，古文では接続助詞の「に」が高い頻度で用いられるためより曖昧性が高い．接続助詞「に」は連体形接続であるため，接続の上でも他と区別が付かない．このほか，中古和文では「を」の判別エラーが多い．現代語では格助詞以外の用法を持たないが，中古語では接続助詞・終助詞があるためエラーにつながっている．また，近代文語では「も」「で」の判別エラーが目立つが，いずれも同形の接続助詞があることで現代語よりも曖昧性が増している．さらに「で」は近代においては口語的な助動詞「だ」の連用形としての「で」が用いられることがあるため，現代語で発生する助動詞「だ」連用形と格助詞「で」の判別と同じ問題が生じている．

このように品詞の認定では，コピュラ助動詞（「なり」「だ」）の連用形と格助詞との判別という現代語でも見られるエラーがあることに加えて，古文では同形の接続助詞が存在するためにより曖昧性が高くエラーにつながっている．

活用形の認定では，高頻度の助動詞や動詞の終止形・連体形の判別と，助動詞「ず」・動詞「有り」の終止形と連用形の判別でエラーが多く発生している．

終止形・連体形の判別エラーは，係り結びに起因する古文特有のものである．古文では，文中に「ぞ」「か」「や」の係助詞や疑問詞（不定語）が存在する場合，係り結びの法則によって文末が終止形ではなく連体形になるという現象がある．ところが，四段活用では終止形と連体形が同形であるため，文末に位置する場合には文中に上述の要素（係り）が存在するかどうかによって同形の動詞を判別しなければならず，この困難がエラーにつながっている．係り結びは中古和文で特に多いため終止形・連体形の判別エラーも中古和文に多く，活用形間の誤り全体363例のうち214例がこのエラーである． 

助動詞「ず」・動詞「有り」の終止形と連用形の判別は，文末の認定に関わるものである．助動詞「ず」やラ行変格活用の語では終止形と連用形が同形であるが，終止形と連用形の違いは多くの場合，文が中止しているのかそこで終わっているのかの違いに相当する．ところが，近代文語文では，文末が句点として必ずしも明示されない\footnote{このため，近代語のコーパスでは人手によって文境界をタグ付けしている．古文の解析にとって文末の自動認定は残された重要な課題の一つである．}．句点と読点が区別されず，ともに「、」で表されている文が多く，こうした場合には中止か終止かの区別が極めて難しい．このことが終止形・連用形の選択エラーにつながっている．これも古文のテキスト特有のエラーである．


\subsection{語彙素認定のエラー}

語彙素認定では，中古和文における接頭辞「御」が「ミ」「オオン」の間で揺れる例が極めて多かった．これを含め中古和文における高頻度の語彙素認定エラーは，品詞が一致する上に語種までが同じ例である．近代文語で最多の「人」が「ジン」「ニン」で揺れる例も語種が同じものである．UniDicの見出し語中には，同一の漢字表記語が音読する漢語と訓読する和語に区別される例が多いが，学習素性に語種を利用していることもあり，語種をまたいだ誤りは比較的少なかった．語彙素認定のエラーは現代語でも生じうるタイプの誤りである．ただし，現代語では接頭辞「御」は漢語「ゴ」と和語「オ」でほぼ区別が付くが，中古和文では和語に複数の読みがあるため語種では判別ができないといった違いがある． 


\subsection{エラーのまとめ}

以上のエラーのうち古文特有といえる問題は，(1) 係り結びに起因する文末活用語の終止形・連体形の判別，(2) 文末表示の曖昧さに起因する文末活用語の終止形・連用形の判別 である．特に係り結びの問題に対処するには文中の離れた要素を考慮する必要があるが，提案手法では局所的な形態論情報だけを素性として利用しているため対応できていない．しかし，これらのエラーは比較的簡単なルールによって自動修正できるため，形態素解析後の後処理で対応することが可能である． 

その他のエラーは同種の問題が現代語でも発生しうるものである．しかし，「に／て」「と／も」，「に」「も」「を」などの助詞に関する判別は，古文の方が同音異義となる語彙が多いため曖昧性が増していた（「を」は現代語では曖昧性がない）．また，特に近代文語では漢字表記語の割合が大きく，その読みの曖昧性がエラーにつながる例が現代語よりも多い．中古和文の接頭辞「御」も同様で和語に絞っても多様な読みがあるため判別が困難である．

以上のように，エラーの原因には文法現象から語彙，表記法の違いまで，古文特有の現象が関わっているものが見られた．



\section{おわりに}

UniDicの見出し語を増補し，学習用のコーパスを整備することによって，「中古和文UniDic」と「近代文語UniDic」の二つの形態素解析辞書を作成した．これらの辞書により，語彙素認定のF値で，近代文語は0.9641，中古和文では0.9700という高い精度で解析することが可能になった．これにより，通時コーパス構築の基盤となる形態素解析システムが整ったといえる．これらの形態素解析辞書はすでにWeb上で一般公開を行っている\footnote{http://www2.ninjal.ac.jp/lrc/index.php?UniDic}．

開発過程で，古文の形態素解析には見出し語の追加だけでは十分な精度が得られないこと，5,000語程度の少量であっても専用の学習用コーパスを用意することが効果的であることが確認された．他分野の辞書による解析精度が低いこととあわせ，このことは，古文の形態素解析では，他分野のコーパスによって学習したパラメータの転用を図ることは有効ではないことを示唆している．また，短単位にもとづく形態素解析辞書の学習には，5〜10万語の学習用コーパスを用意すれば歴史的日本語コーパスの構築にとって十分であることが確認された．さらに，エラーの分析から，残されたエラーの多くは，現状の解析器と学習可能な素性では対処の難しいものであることが確認された．

近代文語と中古和文を比較すると，近代文語の解析精度が低かったが，その理由の一つは近代文語の中身が多様で，ドメインの分割がうまくできていないことにあるものと思われる．比較的少量の学習用コーパスで効果が見込まれることが確認されたことから，近代文語文をより小さなドメインに分割することで全体として精度を向上させられる可能性がある．同様に，会話文と地の文とで別の辞書を作成することでも精度の向上が期待できる．今後の課題としたい．

通時コーパスの構築のためには，今後，様々なタイプのテキストの解析を行っていく必要がある．今回の調査においても，中古和文と同時代の資料であっても和漢混淆文は中古和文UniDicでは十分な精度で解析できないことが確認された．今後，和漢混淆文をはじめとする多様なジャンルのテキストを対象とした形態素解析辞書を作成していく必要がある．その中では，仮名遣いのバリエーションへの対処や送り仮名の大幅な省略などの表記揺れへの対処も必要となる．今回得られた情報をもとに必要なコーパスを整備するとともに，新たな解析器も活用しつつ，通時コーパスのための形態素解析を行っていきたい．


\acknowledgment

本研究は2009〜2012年に行われた国立国語研究所の共同研究プロジェクト（統計と機械学習による日本語史研究）による研究成果の一部である．




\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{伝\JBA 小木曽\JBA 小椋\JBA 山田\JBA 峯松\JBA 内元\JBA
  小磯}{伝 \Jetal }{2007}]{伝2007}
伝康晴\JBA 小木曽智信\JBA 小椋秀樹\JBA 山田篤\JBA 峯松信明\JBA 内元清貴\JBA
  小磯花絵 \BBOP 2007\BBCP.
\newblock
  コーパス日本語学のための言語資源—形態素解析用電子化辞書の開発とその応用{（特集コーパス日本語学の射程）\unskip}.\
\newblock \Jem{日本語科学}, {\Bbf 22}, \mbox{\BPGS\ 101--123}.

\bibitem[\protect\BCAY{Den, Nakamura, Ogiso, \BBA\ Ogura}{Den
  et~al.}{2008}]{Den2008}
Den, Y., Nakamura, J., Ogiso, T., \BBA\ Ogura, H. \BBOP 2008\BBCP.
\newblock \BBOQ A proper approach to Japanese morphological analysis:
  Dictionary, model, and evaluation.\BBCQ\
\newblock In {\Bem Proceedings of the 6th Language Resources and Evaluation
  Conference (LREC 2008), Marrakech, Morocco}, \mbox{\BPGS\ 1019--1024}.

\bibitem[\protect\BCAY{国立国語研究所}{国立国語研究所}{2011}]{NINJAL2011}
国立国語研究所 \BBOP 2011\BBCP.
\newblock 現代日本語書き言葉均衡コーパス.

\bibitem[\protect\BCAY{近藤}{近藤}{2009}]{近藤2009}
近藤泰弘 \BBOP 2009\BBCP.
\newblock \Jem{古典語・古典文学研究における言語処理}, \mbox{\BPGS\ 472--473}.
\newblock 共立出版.

\bibitem[\protect\BCAY{近藤}{近藤}{2012}]{近藤2012}
近藤泰弘 \BBOP 2012\BBCP.
\newblock 日本語通時コーパスの設計.\
\newblock \Jem{NINJAL「通時コーパス」プロジェクト・Oxford
  VSARPSプロジェクト合同シンポジウム　通時コーパスと日本語史研究予稿集},
  \mbox{\BPGS\ 1--10}.

\bibitem[\protect\BCAY{Kudo, Yamamoto, \BBA\ Matsumoto}{Kudo
  et~al.}{2004}]{Kudo2004}
Kudo, T., Yamamoto, K., \BBA\ Matsumoto, Y. \BBOP 2004\BBCP.
\newblock \BBOQ Applying conditional random fields to Japanese morphological
  analysis.\BBCQ\
\newblock In {\Bem Proceedings of the 2004 Conference on Empirical Methods in
  Natural Language Processing , Barcelona, Spain.}, \mbox{\BPGS\ 230--237}.

\bibitem[\protect\BCAY{Lafferty, McCallum, \BBA\ Pereira}{Lafferty
  et~al.}{2001}]{Lafferty2001}
Lafferty, J.~D., McCallum, A., \BBA\ Pereira, F. C.~N. \BBOP 2001\BBCP.
\newblock \BBOQ Conditional random fields: Probabilistic models for segmenting
  and labeling sequence data.\BBCQ\
\newblock In {\Bem Proceedings of the 18th International Conference on Machine
  Learning, Williamstown, MA.}, \mbox{\BPGS\ 282--289}.

\bibitem[\protect\BCAY{村上}{村上}{2004}]{村上2004}
村上征勝 \BBOP 2004\BBCP.
\newblock \Jem{シェークスピアは誰ですか？—計量文献学の世界}.
\newblock 文春新書.

\bibitem[\protect\BCAY{小木曽}{小木曽}{2011}]{小木曽2011}
小木曽智信 \BBOP 2011\BBCP.
\newblock 通時コーパスの構築に向けた古文用形態素解析辞書の開発.\
\newblock \Jem{情報処理学会研究報告　人文科学とコンピュータ}, {\Bbf 2011-CH-92}
   (6), \mbox{\BPGS\ 1--4}.

\bibitem[\protect\BCAY{小椋\JBA 須永}{小椋\JBA 須永}{2012}]{小椋2012}
小椋秀樹\JBA 須永哲矢 \BBOP 2012\BBCP.
\newblock \Jem{中古和文 UniDic 短単位規程集（科研費
  基盤研究（C）課題番号21520492「和文系資料を対象とした形態素解析辞書の開発」研究成果報告書2）}.
\newblock 国立国語研究所.

\bibitem[\protect\BCAY{山元}{山元}{2007}]{山元2007}
山元啓史 \BBOP 2007\BBCP.
\newblock 和歌のための品詞タグづけシステム.\
\newblock \Jem{日本語の研究}, {\Bbf 3}  (22), \mbox{\BPGS\ 33--39}.

\bibitem[\protect\BCAY{山本\JBA 松本}{山本\JBA 松本}{1996}]{山本1996}
山本靖\JBA 松本裕治 \BBOP 1996\BBCP.
\newblock 日本語形態素解析システムJUMANによる古文の形態素解析とその応用.\
\newblock \Jem{情報処理語学文学研究会 第19回研究発表大会要旨}.

\bibitem[\protect\BCAY{安武\JBA 吉村\JBA 首藤}{安武 \Jetal }{1995}]{安武1995}
安武満佐子\JBA 吉村賢治\JBA 首藤公昭 \BBOP 1995\BBCP.
\newblock 古文の形態素解析システム.\
\newblock \Jem{福岡大学工学集報}, {\Bbf 54}, \mbox{\BPGS\ 157--165}.

\end{thebibliography}

\begin{biography}
\bioauthor{小木曽智信}{
1995年東京大学文学部日本語日本文学（国語学）専修課程卒．1997年東京大学大学院人文社会系研究科日本文化研究専攻修士課程修了．2001年同博士課程中途退学．修士（文学）．2001年より明海大学講師．2006年より独立行政法人国立国語研究所研究員を経て， 2009年より人間文化研究機構国立国語研究所准教授，現在に至る．現在，社会人学生として奈良先端科学技術大学院大学情報科学研究科博士後期課程に在学中．専門は日本語学，自然言語処理．言語処理学会，日本語学会，情報処理学会各会員．
}
\bioauthor{小町　　守}{
2005年東京大学教養学部基礎科学科科学史・科学哲学分科卒．2007年奈良先端科学技術大学院大学情報科学研究科博士前期課程修了．2008年より日本学術振興会特別研究員 (DC2) を経て，2010年博士後期課程修了．博士（工学）．同研究科助教を経て，現在，首都大学東京システムデザイン学部准教授．大規模なコーパスを用いた意味解析および統計的自然言語処理に関心がある．言語処理学会，人工知能学会，情報処理学会，ACL各会員．
}
\bioauthor{松本　裕治}{
1977年京都大学工学部情報工学科卒．1979年同大学大学院工学研究科修士課程情報工学専攻修了．同年電子技術総合研究所入所． 1984〜85年英国インペリアルカレッジ客員研究員．1985〜 87年財団法人新世代コンピュータ技術開発機構に出向．京都大学助教授を経て，1993年より奈良先端科学技術大学院大学教授，現在に至る．工学博士．専門は自然言語処理．計量国語学会，言語処理学会，情報処理学会，人工知能学会，認知科学会，AAAI, ACL, ACM各会員．情報処理学会フェロー．ACL Fellow．
}

\end{biography}


\biodate



\end{document}
