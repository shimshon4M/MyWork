<?xml version="1.0" ?>
<root>
  <section title="Introduction">Automaticevaluationoftranslationqualityisimportantfordevelopmentofmachinetranslationsystems;thus,itisanactiveareaofresearch.Humanevaluationresources,whichcanbeusedasfundamentaldatafortheresearch,havebeenpublished.NISTMetricsforMachineTranslation(MetricsMATR)publishedhumanevaluationresourcesforthenewsdomainandforArabic/Chinese-to-Englishtranslations.TheWorkshoponStatisticalMachineTranslation(WMT)publishedhumanevaluationresourcesfornewsandEuropeanParliamentProceedingsandtranslationsbetweenEuropeanlanguages.Thedatabaseofhumanevaluationsthatweintroduceinthispaperisdifferentfromtheabove-mentionedhumanevaluationresourcesinthatittargetsthepatentdomainandfocusesontranslationsthatincludetheAsianlanguagesofJapaneseandChinese.ThishumanevaluationdatabasewasproducedthroughthePatentMachineTranslationTask(PatentMT)atNTCIR-9.PatentMTatNTCIR-9buildsonthepreviouspatenttranslationtasksperformedatNTCIR-7andNTCIR-8andcontainstwoadditionsthatwerenotpresentintheprevioustwotasks:Chinese-to-Englishtranslationandacceptabilityevaluations.TheneedtotranslatepatentinformationfromtheChineselanguagehasincreased,andtherefore,aChinese-to-Englishsubtaskwasadded.AcomparisonofNTCIR-7,8,and9issummarizedinTable.Ahumanevaluationforacceptabilitywasconducted,aimingtorealizeamorepracticalevaluationthanisaffordedbyadequacy.Thehumanevaluationrevealsthenumberoftestsentencesthatcanbeunderstoodfromthetranslations.ThispapergivesabriefoverviewofNTCIR-9PatentMTanddescribesthehumanevaluationresultsobtainedatNTCIR-9PatentMT.Theeffectivenessofthedifferentstate-of-the-artmachinetranslationsystemscanbeevaluatedbycomparingthehumanevaluationresultsoftranslationsdonebythedifferentsystemsusingthesametestdata.Thedatabaseofthehumanevaluationsisusefulforresearchintheautomaticevaluationoftranslationquality.Thispaperisorganizedasfollows:Sectionexplainsthetaskdesign,Sectionliststheparticipantsandsubmissions,Sectiondescribesthehumanevaluationresults,Sectionshowsthevalidationofhumanevaluations,Sectiongivesameta-evaluationoftheautomaticevaluationmeasureofBLEU,Sectionshowsthemethodforobtainingthedatabase,andSectionconcludesthepaper.</section>
  <section title="Task design">PatentMThadthreepatentmachinetranslationsubtasks:ChinesetoEnglish(CE),JapanesetoEnglish(JE),andEnglishtoJapanese(EJ).Participantschosethesubtasksinwhichtheywishedtoparticipateandwereprovidedwithtrainingdata,developmentdata,andtestdata.ParticipantstranslatedthetestdatausingtheirmachinetranslationsystemsandsubmittedthetranslationstothePatentMTorganizers.ThePatentMTorganizersevaluatedthesubmittedtranslationsandreturnedtheevaluationresultstotheparticipants.Finally,theparticipantspresentedtheirresearchresultsattheNTCIR-9workshop.</section>
  <subsection title="Data provided to the participants">Theprovideddataconsistedoftrainingdata,developmentdata,testdata,contextdocuments,andreferencedata.Thereferencedatawasprovidedafterthesubmissionoftranslationresults.Thetrainingdataconsistedofaparallelcorpusandamonolingualcorpus.Theparallelsentencepairsforthetraining,development,andtest/referencedataweredrawnfrompatentdescriptionsentences(patentdocumentsconsistofatitle,abstract,claim,anddescription).Theparallelsentencepairsforthetrainingdatawereautomaticallyextractedfrompatentdocumentsusingbilingualdictionaries.TheChinese--EnglishparallelsentencepairswereextractedfromPatentCooperationTreaty(PCT)patentsinChineseandEnglish.TheJapanese--EnglishparallelsentencepairswereextractedfromthepatentfamilyinJapaneseandEnglish.Thetrainingdatawasbuiltfrompatentdocumentspublishedbetween1993and2005.Thenumberofpatentparallelsentencepairsforthetrainingdatawas:1millionforChinese--Englishandapproximately3.2millionforJapanese--English.Thetrainingdataofthemonolingualcorpuswasamonolingualpatentcorpusinthetargetlanguagespanning13years(1993--2005).Thetestdatawasbuiltbyrandomlyselectingparallelsentencesfromaportionoftheautomaticallybuiltpatentparallelsentencepairspublishedin2006and2007,manuallyjudgingwhetherthesentencepairswerecorrecttranslations,thenselecting2,000correctsentencepairsasthetestdataandtheirreferencedata.Thepatentdocumentsfromwhichthetestsentenceswereextractedwereprovidedascontextdocumentsforthetestdata.</subsection>
  <subsection title="Evaluation methodology">Weconductedhumanevaluationsandregardedtheseastheprimaryevaluation.Humanevaluationswerecarriedoutbypaidevaluationexpertsandemployedthecriteriaofadequacyandacceptability,whichwillbeexplainedlater.Foreachcriterion,threeevaluatorsevaluated100sentencespersystem.Thethreeevaluatorsevaluateddifferentsentences.Thus,300sentenceswereevaluatedpersystem.The300sentenceswererandomlyselectedfromthetestsentences.Inthisevaluation,theevaluatorslookedatasourcesentenceanditstranslationresultstobeevaluated.</subsection>
  <subsubsection title="Adequacy">Weconducteda5-scale(1to5)adequacyevaluation.Themainpurposeoftheadequacyevaluationwastocomparethesystems.Adequacycanbedefinedinmultipleways.Whitedefineditashowmuchoftheinformationfromafragmentofareferencesentenceiscontainedinthetranslationresults.Theyinsistedthatfragmentationisintendedtoavoidbiasingtheresultsinfavoroflinguisticcompositionalapproaches(whichmaydorelativelybetteronlonger,clause-levelstrings)orstatisticalapproaches(whichmaydobetteronshorterstringsnotassociatedwithsyntacticconstituency).However,thisevaluationcannotevaluatewhetherthesentencemeaningiscorrectornotbecausesimplycontainingallofthefragmentsofthereferenceinformationdoesnotguaranteeacorrectsentencemeaning.TheNTCIR-7PatentTranslationTaskconductedadequacyevaluationsusingacriterionbasedonthedegreeofpreservationofsentence-levelmeaninginsteadofthedegreeoffragmentsofthereferenceinformationcontained.Webelievedthatthedegreeofsentence-levelmeaningpreservationwasbetterthanthatoffragmentsofreferenceinformationcontainedfortheevaluationoftranslationquality.However,sincethecostofcheckingsentencemeaningsishigh,weevaluatedqualityconsideringtheclause-levelmeaningsforadequacy.TheinstructionsfortheadequacycriterionaregiveninAppendix.ExamplesofadequacyvaluesandtranslationsareshowninAppendix.Thesystemswererankedbasedonadequacyusingtheaveragesystemscores.</subsubsection>
  <subsubsection title="Acceptability">Weconducteda5-scaleacceptabilityevaluationasshowninFig..Themainpurposeofanacceptabilityevaluationistoclarifythepercentageoftranslatedsentencesforwhichthesourcesentencemeaningscanbeunderstoodfromrandomlyselectedtestsentences.Acceptabilityisanevaluationofsentence-levelmeaning.Theacceptabilitycriterionusedinthisevaluationisaimedmoreatpracticalevaluationasopposedtoadequacy.Forexample,iftherequirementofatranslationsystemisthatthesourcesentencemeaningcanbeunderstood,translationsofCorhigherareuseful;however,iftherequirementisthatthesourcesentencemeaningcanbeunderstoodandthesentenceisgrammaticallycorrect,thenonlytranslationsofAorhigherareuseful.Wecanthenknowthenumberofsentencesfromasystemwouldbeusefulforeachrequirement.Anadequacycriterioncannotanswertheserequirements.Acceptabilityalsocontainsanevaluationoffluencythatmeasuresfluencyinthetargetlanguage,sinceitalsoaffectsthedifferencesingradingfromCtoAA.Iftheadequacyofatranslationisverylow,thenthetranslationisnotcorrectevenifthefluencyishigh.Iftheintegratedevaluationscoreiscalculatedbyaveragingtheadequacyandfluencyscores,thenthosetranslationscouldbeovervalued.Acceptabilityavoidsthisproblem,allowingustoconsiderfluency.TheinstructionsfortheacceptabilitycriterionareshowninAppendix.ExamplesofacceptabilityvaluesandtranslationsareshowninAppendix.Werankedthesystemsbasedonacceptabilityusingapairwisecomparison,whichwillnowbeexplained.ThepairwisescoreforasystemAreflectshowfrequentlyitwasjudgedtobebetterthanorequaltoothersystems.Supposetherearefivesystemstobecompared.Foreachinputsentence,systemAisincludedinfourpairwisecomparisons(againsttheothersystems).SystemAisrewardedas1.0foreachofthecomparisonsinwhichsystemAisrankedthehighestofthetwo,and0.5foreachofthecomparisonsinwhichsystemAisinatie.SystemA'sscoreisthetotalrewardedscoreinthepairwisecomparisonsdividedbythetotalnumberofpairwisecomparisonsinvolvingsystemA.Notethattheaveragescoreofacceptabilitywasnotusedforsystemranking.Thereasonisasfollows.Hereweassumethatthedifferencesbetweenthegradesaremeasuredbygeneralusability.Itisimportanttobeabletounderstandthecontentsfromthesourcesentence.ThereisalargedifferenceinusabilitybetweenFandC.However,attheA-level,whilethetranslationsareatanon-nativelevel,thecontentsfromthesourcesentencescanbeunderstoodandtheyaregrammaticallycorrect;thus,theyhavethepotentialtobeusefulinmanycases.Thus,itisbelievedthatthedifferenceinusabilitybetweenAandAAissmallerthanthatbetweenFandC.Inaddition,wethinkthatusefulgradesdependonspecificusage.Therefore,itisdifficulttogiveanappropriatescoreforeachgrade,andweavoidedtheconversionofgradestoscoresandcalculationofaverages.</subsubsection>
  <subsubsection title="Human evaluation procedure">Weconductedhumanevaluationtrainingbeforethemainevaluationtonormalizetheevaluators'criteria.Inthetraining,allevaluatorsevaluated100translations,andameetingwasheldtodeterminecommonresultsforeachsubtask.Themainevaluationwasthenperformed.Thecommonresultsproducedatthetrainingwereusedasthereferenceresultsforthemainevaluation.TheinstructionsforthehumanevaluationprocedureareshowninAppendix.</subsubsection>
  <subsection title="Schedule">Translationsweredoneoveratwo-weekperiodinMay2011.</subsection>
  <section title="Participants and submissions">Wereceivedsubmissionsfrom21groups.Thenumberofgroupsforeachsubtaskwas:18forCE,12forJE,and9forEJ.TableshowstheGroupIDs,theparticipantorganizations,systemdescriptionpapers,andthesubtasksinwhichtheyparticipated.Thetypesoftranslationsystemsarestatisticalmachinetranslation(SMT),rule-basedmachinetranslation(RBMT),example-basedmachinetranslation(EBMT),orhybridsoftwoormoretypes(HYBRID).Inadditiontothesubmissionsfromtheparticipants,theorganizerssubmittedresultsforbaselinesystemsthatconsistedof2SMTsystems,5commercialRBMTsystems,and1onlineSMTsystem.ThebaselinesystemsareshowninTable.TheSMTbaselinesystemsconsistedofpubliclyavailablesoftware,andtheproceduresforbuildingthesystemsandtranslatingusingthesystemswerepublishedonthePatentMTwebpagesothatthosewiththetrainingdatacanbuildtheSMTbaselinesystemsandcomparetheirresults.ThecommercialRBMTsystemsandtheGoogleonlinetranslationsystemwereoperatedbytheorganizers.ThetranslationresultsfromtheGoogletranslationsystemwerecreatedbytranslatingthetestdataviatheirwebinterface.WenotethattheseRBMTcompaniesandGoogledidnotsubmitthemselves.SinceourobjectivedoesnotincludecomparingthecommercialRBMTsystemsofcompanieswhodidnotthemselvesparticipate,theSystemIDsofthecommercialRBMTsystemsarekeptanonymousinthispaper.Eachparticipantisallowedtosubmitasmanytranslatedresults(``runs'')asdesired,butthesubmittedrunsshouldbeprioritizedbythegroup.Inthispaper,wedistinguishtheirrunsusingaRunIDexpressedbyGroupID(orSystemIDforthebaselinesystems)andaprioritynumberconnectedby``-''.TheresourceinformationusedbyeachrunisindicatedbyResourceB:Thesystemusedthebilingualtrainingdataprovidedbytheorganizers.ResourceM:Thesystemusedthemonolingualtrainingdataprovidedbytheorganizers.ResourceE:Thesystemusedexternalknowledgeotherthandataprovidedbytheorgan-izersorthesystemusesarule-basedsystem.</section>
  <section title="Human evaluation results">Weevaluatedtheadequacyforatleastallofthefirstprioritysubmissions.However,becauseofbudgetlimitations,acceptabilitywasevaluatedforonlyselectedsystems.</section>
  <subsection title="Chinese to English"/>
  <subsubsection title="Adequacy evaluation">Tableshowstheresultsoftheadequacyevaluation.Tableshowstheresultsofthestatisticalsignificancetestoftheadequacyevaluationusingasigntest.Inthetablesshowingtheresultsofastatisticalsignificancetest,themarks(``'',``&gt;'',``-'')indicatewhethertheRunIDtotheleftofamarkissignificantlybetterthanthatabovethemark.Fromtheseresults,wecanobservethefollowing:AllofthetopsystemsareSMTsystems.Thetopsystem,BBN-1,showsasignificantlyhigheradequacythantheothersystems.TheadequacyscoreforMoses'hierarchicalphrase-basedSMTsystem(BASELINE1-1)ishigherthanthatforMoses'phrase-basedSMTsystem(BASELINE2-1).TheadequacyscoresforMoses'hierarchicalphrase-basedSMTsystem(BASELINE1-1)andMoses'phrase-basedSMTsystem(BASELINE2-1)arehigherthanthoseforthetwoRBMTbaselinesystems(RBMT2-1andRBMT1-1).Toimprovetranslationquality,thetopBBN-1systemusedthefollowingtechniques:generalizationofinfrequentnumericalexpressions,optimizationofChinesewordsegmentation,adaptationoflanguagemodels,additionoffeatures,andutilizationofEnglishdependencystructures.Effectivenessofthesystemusingthesetechniqueswasshown.</subsubsection>
  <subsubsection title="Acceptability evaluation">Tableshowstheresultsoftheacceptabilityevaluation.Tableshowstheresultsofthestatisticalsignificancetestoftheacceptabilityevaluationusingasigntest.Fromtheresults,wecanseethatthemeaningofthesourcelanguagecouldbeunderstood(C-rankandabove)for79.7%ofthetranslatedsentencesinthebest-rankedsystem(BBN-1).Thisresultsignificantlysurpassestheothers.</subsubsection>
  <subsection title="Japanese to English"/>
  <subsection title="English to Japanese"/>
  <section title="Validation of Human Evaluation Results">Todiscussreliabilityofthehumanevaluation,wepresentthecorrelationbetweentheevaluationresultsfordivideddata.Wevalidatedthereliabilityofhumanevaluationasfollows:Thehumanevaluationdatawasdividedintothefirsthalfdata(Half-1)andthesecondhalfdata(Half-2).Eachcontainshalfofallofthesentencesevaluatedbyeachevaluator.Scoresforthesystemsbasedonthehalveddatawerecalculated.Correlationofsystemcomparisonsbetweenthehalveddatawascalculated.Sincethetestdatawerebuiltbyrandomselection,itisassumedthattheevaluationisnotaffectedbydifferencesinthehalveddata.Underthisassumption,thefollowingistrue:Iftheevaluationisreliable,thetopsystemsbasedonthefirsthalfdatawillalsobethetopsystemsbasedonthesecondhalfdata,andthelower-rankingsystemsbasedonthefirsthalfdatawillalsobethelower-rankingsystemsbasedonthesecondhalfdata,i.e.,thereisgoodcorrelationbetweensystemcomparisonresultsofthetwohalveddata.Ontheotherhand,iftheevaluationisnotreliable,thetopsystemsbasedonthefirsthalfdatawouldbethelower-rankingsystemsbasedonthesecondhalfdata,orthelower-rankingsystemsbasedonthefirsthalfdatawouldbethetopsystemsbasedonthesecondhalfdata,i.e.,thereispoorcorrelationbetweensystemcomparisonresultsofthetwohalveddata.Therefore,wevalidatedthereliabilitybasedonthecorrelationbetweentheevaluationresultsforthedivideddata.Inthissection,pairwisescoresforsystemswereusedfornormalizationpurposes.Apairwisescoreforasystemreflectsthefrequencywithwhichitwasjudgedtobebetterthanorequaltoothersystems.AdetailedexplanationofthepairwisescoreisgiveninSection.Figures--showtheevaluationresultsforthefirsthalfofthedata(Half-1),thesecondhalfofthedata(Half-2),andallofthedata(All).Inthefigures,theverticalaxisisthepairwisescore,andthehorizontalaxisistheRunID.Althoughthereareslightdifferencesbetweenthehalfdata,therearenolargedifferencesthatreversethehigh-rankedandlow-rankedsystems.TableshowsthePearsoncorrelationcoefficientsofthesystemevaluationscoresbetweenthehalfdata.ThePearsoncorrelationcoefficientsarecloseto1.0forallofthedatapairs.Theseindicatethattheevaluationsof150sentencesarethoughttobeconsistentforsystemcomparison,andthisconsistencyshowsthereliabilityoftheevaluationresults.Theevaluationresultsof300sentencesarethoughttobemorereliablethantheevaluationresultsof150sentencesbecausethenumberofsentencesislarger.Inadditiontotheabovemainvalidationforreliability,wealsocheckedthedifferencesbetweenevaluators.Foreachsubtaskandcriterion,threeevaluatorsevaluatedthetranslationsof100differentsourcesentences.Wecheckedthecorrelationbetweentheevaluationresultsbasedonthe100sourcesentencesevaluatedbythesameevaluator.TableshowsthePearsoncorrelationcoefficientsforthesystemevaluationscoresbetweenevaluators.Thesevaluesindicatethatthereisahighcorrelationbetweenevaluators.Thus,evenwhentheevaluatorsandthedataaredifferent,theevaluationsarethoughttobeconsistentforsystemcomparison.</section>
  <section title="Meta-Evaluation of the Automatic Evaluation Measure of BLEU">WecalculatedtheBLEUscoresbasedonthe2,000testsentencestoinvestigatethereliabilityoftheautomaticevaluationmeasureofBLEU,whichiswidelyusedtoevaluatetranslationquality,inthepatentdomainforthelanguagepairsofCE,JE,andEJ.TheSpearmanrank-ordercorrelationcoefficientsandthePearsoncorrelationcoefficientsbetweenhumanevaluations(averageadequacyscores)andtheBLEUscoresareshowninTable.FromTable,itcanbeseenthattheBLEUscoreshaveahighcorrelationwiththehumanevaluationfortheCEevaluation,butdonothaveahighcorrelationwiththehumanevaluationfortheJEandEJevaluationsincludingRBMTsystems.TheSpearmanrank-ordercorrelationcoefficientsandthePearsoncorrelationcoefficientsbetweenhumanevaluationandtheBLEUscoresexcludingtheRBMTsystemsforJEandEJareshowninTable.ThecorrelationsexcludingRBMTsystemsforJEandEJarehigherthanthoseincludingtheRBMTsystems.Therefore,thereliabilityoftheBLEUscoresofthecomparisonsbetweensystemswithouttheRBMTsystemsishigherthanthatoftheBLEUscoresofthecomparisonsbetweensystemsincludingtheRBMTsystemsfortheautomaticevaluationofthequalityoftheJEandEJpatenttranslations.</section>
  <section title="Method for Obtaining the Database">Thissectionexplainsthemethodusedtoobtainresources.Theavailableresourcesforresearchpurposesconsistofahumanevaluationdatabase,testdata,referencedata,andsubmissiondata(translateddata).ResourcesareprovidedbytheNTCIRproject.ThemethodusedtoobtaintheresourcesisgivenattheURLsshowninTable.Applicantsareaskedtosignauseragreement(memorandumonpermissiontouse)toobtaintheresources.Theuseoftheseresourcesisfreeofcharge.</section>
  <section title="Conclusion">ThispaperpresentedinformationregardingthedatabaseofhumanevaluationsfromtheNTCIR-9PatentMachineTranslationTaskandtheknowledgeobtainedfromtheseevaluations.Theevaluationsshowedtheeffectivenessofanumberofmachinetranslationsystemsinthepatenttranslationfield.Databaseofhumanevaluationsisvaluablefortranslationqualityevaluationresearch.Theresourceswillalsobeusefulforsystemcombinationresearch.Resourcesincludingthehumanevaluationdatabase,translationresults,andtest/referencedataareavailablefromtheNTCIRprojectforresearchpurposes.wouldliketothankalloftheevaluatorsforconstructingthedatabaseofhumanevaluations.</section>
  <section title="Adequacy Criterion"/>
  <subsection title="Instructions for the Adequacy Criterion"/>
  <subsubsection title="Evaluation Criterion">Adequacyisscoredaccordingtohowwellthemeaningofatranslationmatchesthemeaningofthereference(source)translationforeachsentence.Adequacyevaluationsaredoneaccordingtothe5-levelscaleshowninTable.</subsubsection>
  <subsubsection title="Notes">Adequacyestimatesthesentencemeaningbyevaluatingfragmentsofasentence.Themainreasonforusingfragmentsistoreduceevaluationcosts.Whensentencesarelong,fragment-levelevaluationiseasierthansentence-levelones.Fragmentsize:Clause-level(firstpriority)or``subjectanditspredicate''level(secondpriority)orphrase-level(thirdpriority).Supplementarydefinitionstoreducecriterionambiguity:Ascoreof5indicatesthatthesentence-levelmeaning(subject,predicateandobject)iscorrect.Relativecomparison:Asentencewhosesentence-levelmeaningisnotcorrectwouldbeevaluatedas1--4notonlybytheabsolutecriterion(most,much,little,andnone)butalsoarelativecomparisonamongthemultipletranslationoutputs.Therelativecomparisonmustbeconsistentinallofthedata.</subsubsection>
  <subsection title="Example Values of Adequacy">ExamplesofadequacyvaluesandtranslationsareshowninTable.</subsection>
  <section title="Acceptability Criterion"/>
  <subsection title="Instructions for the Acceptability Criterion"/>
  <subsection title="Example Values of Acceptability">ExamplesofacceptabilityvaluesandtranslationsareshowninTable.</subsection>
  <section title="Instructions for the Human Evaluation Procedure"/>
  <subsection title="Evaluation Method for Training and Main Evaluations">Thecriteriaforevaluationarebasedontheguidelines.Oneinputsentence(oronereferencesentence)andallofthesystemoutputsareshownsimultaneouslytocomparesystems.Anevaluatorevaluatesallofthetranslationsforthesameinputsentence.TheMToutputsentencesforeachinputsentencearegiventotheevaluatorsinarandomorder.Theevaluatorscanreviewtheevaluations.</subsection>
  <subsection title="Training">Beforethemainevaluation,atrialevaluationisdone.Alloftheevaluatorsevaluatetranslationresultsforthetrialevaluations.Theconditionsforallevaluatorsarethesame.Afterthetrialevaluation,aconsensusmeetingisheldtomakecorrectionstothedifferencesintheevaluationsobtainedfromalloftheevaluatorsandtodecideoncommonevaluationsforthetranslationresultsforthetrialevaluation.document</subsection>
</root>
