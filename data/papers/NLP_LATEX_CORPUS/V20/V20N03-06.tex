    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline
\let\ulinej
\usepackage{lingmacros}
\newcommand{\NUM}[1]{}
\newcommand{\NUMS}[2]{}
\newcommand{\EX}[2]{}
\newcommand{\EXS}[2]{}

\Volume{20}
\Number{3}
\Month{June}
\Year{2013}

\received{2012}{11}{28}
\revised{2013}{2}{11}
\accepted{2013}{3}{25}

\setcounter{page}{461}

\jtitle{訂正パターンに基づく誤情報の収集と拡散状況の分析}
\jauthor{鍋島　啓太\affiref{Author_1} \and 渡邉　研斗\affiref{Author_1} \and 水野　淳太\affiref{Author_2} \and 岡崎　直観\affiref{Author_1}\affiref{Author_3} \and 乾　健太郎\affiref{Author_1}}
\jabstract{
 東日本大震災では，「コスモ石油の爆発で有害物質の雨が降る」などの誤情報
 の拡散が問題となった．本研究の目的は，東本日大震災後1週間の全ツイート
 から誤情報を網羅的に抽出し，誤情報の拡散と訂正の過程を分析することであ
 る．本稿では，誤情報を訂正する表現（以下，訂正パターン）に着目し，誤情
 報を認識する手法を提案する．具体的には，訂正パターンを人手で整備し，訂
 正パターンにマッチするツイートを抽出する．次に，収集したツイートを内容
 の類似性に基づいてクラスタリングし，最後に，その中から誤情報を過不足な
 く説明する1文を選択する．実験では，誤情報を人手でまとめたウェブサイトを
 正解データとして，評価を行った．また，誤情報とその訂正情報の拡散状況を，
 時系列で可視化するシステムを構築した．本システムにより，誤情報の出現・
 普及，訂正情報の出現・普及の過程を分析できる．
}
\jkeywords{Twitter, 誤情報，訂正，拡散}

\etitle{Extracting False Information on Twitter \\ and Analyzing its Diffusion Processes \\ by using Linguistic Patterns for Correction}
\eauthor{Keita Nabeshima\affiref{Author_1} \and Kento Watanabe\affiref{Author_1} \and Junta Mizuno\affiref{Author_2} \and \\
Naoaki Okazaki\affiref{Author_1}\affiref{Author_3} \and Kentaro Inui\affiref{Author_1}} 
\eabstract{
During the 2011 East Japan Earthquake and Tsunami Disaster, a
considerable amount of false information was disseminated on Twitter;
for example, after the Cosmo Oil fire, it was rumored that harmful
substances will come down with rain. This paper exhaustively extracts
pieces of false information from tweets within one week after the
earthquake, and analyzes the diffusion of false information and its
correction information.  By designing a set of linguistic patterns that
correct false information, this paper proposes a method for detecting
false information.  Specifically, the method extracts text passages that
match the correction patterns, clusters the passages into topics of
false information, and selects, for each topic, a passage explaining the
false information most suitably.  We report the performance of the
proposed method on the data set extracted manually from websites that
specialize in collecting false information.  In addition, we build a
system that visualizes emergences, diffusions, and terminations of a
piece of false information and its correction.  We also propose a method
for discriminating false information from its correction, and discuss
the possibility of alerting against false information.
}
\ekeywords{Twitter, False Information, Correction, Diffusion}

\headauthor{鍋島，渡邉，水野，岡崎，乾}
\headtitle{訂正パターンに基づく誤情報の収集と拡散状況の分析}

\affilabel{Author_1}{東北大学大学院情報科学研究科}{Graduate School of Information Science, Tohoku University}
\affilabel{Author_2}{独立行政法人情報通信研究機構}{National Institute of Information and Communications Technology (NICT)}
\affilabel{Author_3}{独立行政法人科学技術振興機構さきがけ}{Japan Science and Technology Agency (JST)}



\begin{document}
\maketitle


\section{はじめに}

2011年3月に発生した東日本大震災では，ソーシャルメディアは有益な情報源として大活躍した~\cite{nomura201103}．
震災に関する情報源として，ソーシャルメディアを挙げたネットユーザーは18.3\%で，インターネットの新聞社 (18.6\%)，インターネットの政府・自治体のサイト (23.1\%) と同程度である．
ニールセン社の調査~\cite{netrating201103}によると，2011年3月のmixiの利用者は前月比124\%，Twitterは同137\%，Facebook同127\%であり，利用者の大幅な伸びを示した．

東日本大震災後のTwitterの利用動向，交換された情報の内容，情報の伝搬・拡散状況などの分析・研究も進められている~\cite{Acar:11,Doan:11,Sakaki:11,Miyabe:11}．
Doanら~\cite{Doan:11}は，大震災後のツイートの中で地震，津波，放射能，心配に関するキーワードが多くつぶやかれたと報告している．
宮部ら~\cite{Miyabe:11}は，震災発生後のTwitterの地域別の利用動向，情報の伝搬・拡散状況を分析した．
Sakakiら~\cite{Sakaki:11}は，地震や計画停電などの緊急事態が発生したときのツイッターの地域別の利用状況を分析・報告している．
AcarとMurakiは~\cite{Acar:11}，震災後にツイッターで交換された情報の内容を分類（警告，救助要請，状況の報告：自身の安否情報，周りの状況，心配）している．

一方で，3月11日の「コスモ石油のコンビナート火災に伴う有害物質の雨」に代表されるように，インターネットやソーシャルメディアがいわゆるデマ情報の流通を加速させたという指摘もある．
東日本大震災とそれに関連する福島第一原子力発電所の事故では，多くの国民の生命が脅かされる事態となったため，人間の安全・危険に関する誤情報（例えば「放射性物質から甲状腺を守るにはイソジンを飲め」）が拡散した．
東日本大震災に関するデマをまとめたツイート\footnote{https://twitter.com/\#!/jishin\_dema}では，2012年1月時点でも月に十数件のペースでデマ情報が掲載されている．
このように，Twitter上の情報の信憑性の確保は，災害発生時だけではなく，平時においても急務である．

我々は，誤情報（例えば「放射性物質から甲状腺を守るためにイソジンを飲め」）に対してその訂正情報（例えば「放射性物質から甲状腺を守るためにイソジンを飲め\ulinej{というのはデマ}」）を提示することで，人間に対してある種のアラートを与え，情報の信憑性判断を支援できるのではないかと考えている．
訂正情報に基づく信憑性判断支援に向けて，本論文では以下に挙げる 3 つの課題に取り組む．
\begin{description}
\item[東日本大震災時に拡散した誤情報の網羅的な収集：] 「○○というのはデマ」「○○という事実は無い」など，誤情報を訂正する表現（以下，訂正パターン）に着目し，誤情報を自動的に収集する手法を提案する．
震災時に拡散した誤情報を人手でまとめたウェブサイトはいくつか存在するが，東日本大震災発生後の大量のツイートデータから誤情報を自動的，かつ網羅的に掘り起こすのは，今回が初めての試みである．
評価実験では，まとめサイトから取り出した誤情報のリストを正解データと見なし，提案手法の精度や網羅性に関して議論する．
\item[東日本大震災時に拡散した誤情報の発生から収束までの過程の分析：] 東日本大震災時の大量のツイートデータから自動抽出された誤情報に対し，誤情報の出現とその拡散状況，その訂正情報の出現とその拡散状況を時系列で可視化することで，誤情報の発生から収束までの過程をモデル化する．
\item[誤情報と訂正情報の識別の自動化：] 誤情報を訂正している情報を自然言語処理技術で自動的に認識する手法を提案し，その認識精度を報告する．提案手法の失敗解析などを通じて，誤情報と訂正情報を対応づける際の技術的課題を明らかにする．また，本研究の評価に用いたデータは，ツイートIDと\{誤情報拡散，訂正，その他\}のラベルの組として公開を予定しており，誤情報とその訂正情報の拡散に関する研究の基礎データとして，貴重な言語資源になると考えている．
\end{description}
なお，ツイートのデータとしては，東日本大震災ワークショップ\footnote{https://sites.google.com/site/prj311/}においてTwitter Japan株式会社から提供されていた震災後 1 週間の全ツイートデータ（179,286,297ツイート）を用いる．

本論文の構成は以下の通りである．まず，第 2 節では誤情報の検出に関する関連研究を概観し，本研究との差異を述べる．
第 3 節では誤情報を網羅的に収集する手法を提案する．
第 4 節では提案手法の評価実験，結果，及びその考察を行う．
第 5 節では，収集した誤情報の一部について，誤情報とその訂正情報の拡散状況の分析を行い，自動処理による訂正情報と誤情報の対応付けの可能性について議論する．
最後に，第 6 節で全体のまとめと今後の課題を述べる．



\section{関連研究}

近年，ツイッターは自然言語処理の分野においても研究対象として注目を浴びている．
言語処理学会の年次大会では「Twitterと言語処理」というテーマセッションが
2011，2012年に企画されていた．
また，国際会議のセッションや併設ワークショップにおいても，ソーシャルメディアに特化した情報交換の場が設けられることが珍しくない．
このような状況が映し出すように，ツイッターを対象とした研究は数多くあるが，本節ではツイートで発信される情報の真偽性や信憑性に関連する研究を紹介する．

Ratkiewiczら~\cite{Ratkiewicz:2011}は，米国の選挙に関連して，アストロターフィング\footnote{団体や組織が自発的な草の根運動に見せかけて行う意見主張のこと．一般市民を装って，特定の候補者を支持したり，否定する意見をツイートで発信し，複数のユーザアカウントを使って多勢を装ったり，一般市民のリツイートを誘発させるなどして，選挙活動を行う．}や誹謗中傷，誤情報の意図的な流布を行っているツイートを検出するシステムを提案した．
Qazvinianら\cite{Qaz2011}は，誤情報に関連するツイート群（例えば「バラク・オバマ」と「ムスリム」を含むツイート群）から，誤情報に関して言及しているツイート（例えば「バラク・オバマはムスリムである」）と，誤情報に関して言及していないツイート（例えば「バラク・オバマがムスリムのリーダーと面会した」）を分類し，さらに誤情報に関して言及しているツイート群を，誤情報を支持するツイートと否定するツイートに分類する手法を提案した．
Qazvinianらの研究は，誤情報に関連するツイート群（もしくはクエリ）が与えられることを想定しており，本研究のように大規模なツイートデータから誤情報をマイニングすることは，研究対象の範囲外である．

日本では，東日本大震災時にツイッター上で誤情報が拡散したという問題意識から，関連する研究が多く発表されている．
白井ら~\cite{Shirai}は，デマ情報とその訂正情報を「病気」とみなし，感染症疾患の伝染モデルを拡張することで，デマ情報・デマ訂正情報の拡散をモデル化した．
藤川ら~\cite{Fuji12}は，ツイートに対して疑っているユーザがどの程度いるのか，根拠付きで流言であると反論されているか等，情報に対するユーザの反応を分類することで，情報の真偽判断を支援する手法を提案した．
鳥海ら~\cite{Tori}は，あるツイートの内容がデマかどうかを判別するため，ツイートの内容語と「デマ」「嘘」「誤報」などの反論を表す語の共起度合いを調べる手法を提案した．

梅島ら~\cite{Ume11}は，東日本大震災時のツイッターにおけるデマと，デマ訂正の拡散の傾向を分析することを目標とし，「URLを含むリツイートはデマである可能性が低い」「デマは行動を促す内容，ネガティブな内容，不安を煽る内容が多い」「この 3 つのいずれかの特徴を持つツイートはリツイートされやすい」等の仮説を検証した．
彼女らのグループはその後の研究~\cite{Ume12,DemaCloud}で，誤情報のデータベースを構築するために，「デマ」や「間違い」といった訂正を明示する表現を用いることで，訂正ツイートの認識に有用であることを示した．
さらに彼女らは，訂正を明示する表現を含むツイートを収集し，各ツイートが特定の情報を訂正しているか，訂正していないのか\footnote{例えば「ツイート上には様々なデマが流れているので注意を！」というツイートには「デマ」という表現を含んでいるが，特定の情報を訂正しているわけではない}を識別する二値分類器を構築した．

これらの先行研究は，ツイートが誤情報を含むかどうか，もしくはツイートが特定の情報を訂正しているかどうかを認識することに注力しており，ツイート中で言及されている誤情報の箇所を同定することは研究対象の範囲外となっている．
したがって，大規模なツイートデータから誤情報を網羅的に収集する研究は，我々の知る限り本研究が最初の試みである．
誤情報の発生から収束までの過程を分析している研究としては
鳥海ら~\cite{Tori}の研究がある．鳥海らは「ワンピースの作
者が多額の寄付を行った」という誤情報をとりあげ，関連するツイートを誤情報
の拡散ツイートと訂正ツイートに振り分けて，時系列に基づく深い分析を行った．
彼らの手法は「ワンピース，作者，寄付」と共起するツイートを誤情報拡散ツ
イート，「ワンピース，作者，デマ」と共起するツイートを誤情報訂正ツイート
に機械的に振り分けるというものであったが，本研究ではツイートの内容を人間
が検証することにより，14トピックの誤情報の拡散・訂正状況を詳細に分析する．



\section{提案手法}
本研究では，ツイッター上で拡散している誤情報に対して，別の情報発信者がその情報を訂正すると仮定し，誤情報の抽出を行う．
例えば，「コスモ石油の爆発により有害な雨が降る」という誤情報に対して，ツイッター上で以下のような訂正情報を含むツイート（以下，訂正ツイート）が発信された．

\EXS{ex:tweet}{
\item [ex1] コスモ石油の爆発により、有害な雨が降る\ulinej{という事実はない。}
\item [ex2] コスモ石油の科学物質を含んだ雨が降る\ulinej{というデマ}がTwitter以外にも出回ってるので注意を
}

訂正ツイートは，訂正表現（下線部）と，その訂正対象である誤情報から構成される．
そこで，ツイート中の訂正表現を発見することで，誤情報を抽出できると期待できる．
本節で提案する手法の目標は，訂正表現を手がかりとして，ツイート本文から誤情報を説明する箇所を推定する抽出器を構築することである．
さらに，構築した抽出器によって，ツイート集合から誤情報を過不足なく収集したい．

図\ref{fig:zentai}に提案手法の流れを示す．手順は大きく4つに分けられる．ま
ず，ツイート本文に訂正パターン（後述）を適用し，訂正対象となる部分（被訂
正フレーズ）を抽出する（ステップ1）．次に，「昨日のあれ」のように具体的な
情報を含まないフレーズを取り除くために，ステップ2において被訂正フレーズに
含まれやすいキーワードを選択する．同一の被訂正情報を言及しているが，表現
や情報量の異なるフレーズをまとめるために，フレーズに含まれるキーワードを
クラスタリングする（ステップ3）．その結果，「コスモ石油」や「イソジン」と
いった，誤情報の代表的なキーワードを含むクラスタが構築される．図
\ref{fig:zentai}左上の表は，被訂正フレーズに含まれやすいキーワードが上位
に来るよう，クラスタをステップ2の条件付き確率（式\ref{eq1}，後述）で並べ替
えたものである．最後に，ステップ4で，各クラスタごとに誤情報を最もよく説明
しているフレーズを選択する．図\ref{fig:zentai}右上はステップ3で並べ替えた
クラスタからフレーズを抽出し，出力された誤情報のリストである．以降では，
各ステップについて詳細に説明する．


\begin{figure}[b]
\begin{center}
  \includegraphics{20-3ia21f1.eps}
\end{center}
 \caption{提案手法の流れ}
 \label{fig:zentai}
\end{figure}


\subsection{ステップ1：訂正パターンを用いた訂正フレーズの抽出}

\begin{figure}[b]
\begin{center}
\input{21fig02.txt}
\end{center}
 \caption{被訂正フレーズを含むツイートの構造}
 \label{fig:correct_pattern}
\end{figure}

ステップ1では，ツイート本文から被訂正フレーズを見つけ出す．被訂正フレーズ
は，「デマ」や「間違い」といった表現で，訂正や打ち消されている箇所のこと
である．被訂正フレーズは，「イソジンは被曝を防ぐ」といった単文や，「コス
モ石油の火災により有害な雨が降る」といった複文，「うがい薬の件」といった
名詞句もある．被訂正フレーズと訂正表現は，「という」や「のような」といっ
た連体助詞型機能表現で繋がれ，図\ref{fig:correct_pattern}に示す構造をとる．

被訂正フレーズに続く表現を，すなわち連体助詞型機能表現と訂正表現の組み合
わせを，「訂正パターン」と呼ぶ．例えば，図\ref{fig:correct_pattern}におい
て，「というデマ」，「といった事実はありません」が訂正パターンである．

全ツイートを
形態素解析し，訂正パターンに対して形態素レベルでのパターン照合を行う．マッチし
たツイートに対して，文頭から訂正パターンの直前までを被訂正フレーズとして
抽出する．
被訂正フレーズを漏れなく抽出するには，質のよい訂正パターンを整備することが重要である．そこで，どのような表現が訂正パターンになり得るのかを調べた．
具体的には，既知の誤情報15件を含むツイートを検索するようなクエリを考え，そのツイートの内容を確認することにより，訂正パターンを収集・整理した．
このようにして得られた訂正パターンの一覧を表\ref{tbl:teisei}に示した．
表\ref{tbl:teisei}の訂正パターンのいずれかを含むツイートに対して，文頭か
ら訂正パターンの直前までを被訂正フレーズとして抽出した例を図\ref{fig:correct_pattern_extraction}に示した．
図\ref{fig:correct_pattern_extraction}の下線部が訂正パターンである．

\begin{table}[t]
 \caption{訂正パターン}
 \label{tbl:teisei}
\input{21table01.txt}
\end{table}

\begin{figure}[t]
 \begin{center}
\input{21fig03.txt}
 \end{center}
 \caption{被訂正フレーズの抽出}
 \label{fig:correct_pattern_extraction}
\end{figure}


\subsection{ステップ2：キーワードの抽出}

前節で抽出された被訂正フレーズには，「昨日のあれ」のように具体的な情報が提示されていないフレーズも含
まれている．これらは誤情報としては不適切であるため，取り除く必要がある．
そこで，被訂正フレーズ中の名詞句が訂正情報中に偏って出現しているかどうか
を調べる．ここで分析の対象とする名詞句は，単名詞および名詞連続に限定する．具体
的には，ある名詞句がツイートで言及されるとき，その名詞句が被訂正フレーズ
に含まれる確率（条件付き確率）を算出する．被訂正フレーズ中には頻出し，そ
の他のツイート中では出現頻度の低い名詞句は，被訂正時にのみ頻出することか
ら，誤情報のキーワードとなる名詞句である可能性が高い．逆に，被訂正フレー
ズ以外でも頻出する名詞句は，一般的な名詞句であり，誤情報のキーワードとな
る可能性は低い．「昨日のあれ」の「昨日」や「あれ」は，被訂正フレーズ以外
でも頻出するため，一般的な名詞句であると判断できる．


フレーズ中の名詞句$w$が誤情報のキーワードらしいかどうか
を，式\ref{eq1}によって計算する．ここで，$D$は訂正フレーズ集合を表す．
\begin{equation}
 P(w \in D|w) = \frac{P(w \in D)}{P(w)} = \frac{wが訂正パターンを伴って
  出現するツイート数}{wを含むツイート数} \label{eq1}
\end{equation}

このように求めた条件付き確率が高い上位500個を，キーワー
ドとして選択する．
ただし，コーパス中での出現頻度が極端に低い名詞句を除くため，
コーパス全体での出現回数が10回以上かつ，被訂正フレーズ集合での出現回数が
2回以上の名詞句のみをキーワードとして認定する．
また，ひらがなや記号が半数以上の名詞句（例えば「◯◯町」）はキーワードとし
て不適切と考え，キーワードから取り除いた．


\subsection{ステップ3：キーワードのクラスタリング}

被訂正フレーズには，「コスモ石油の火災により有害物質を含む雨が降る」と
「コスモ石油の爆発は有害だ」のように，同一の被訂正情報を言及しているが，
表現や情報量の異なるフレーズが含まれている．誤情報を過不足なく抽出するた
めに，これらをまとめる必要がある．
そこで，ステップ2で抽出されたキーワードを，同一の被訂正情報を説明す
るキーワードがまとまるようにクラスタリングする．

クラスタリングにおけるキーワード間の類似度計算では，キーワードと文内で共
起する内容語（名詞，動詞，形容詞）を特徴量とした文脈ベクトルを用いた．こ
れは，周囲に同じ単語が表れていれば，2 つのキーワードは類似しているという
考えに基づく．文脈ベクトルの特徴量には，各単語との共起度合いを表す尺度で
ある自己相互情報量(PMI)を用いた．この値が0 以上の内容語を文脈ベクトルの特
徴量に加えた．各文脈ベクトルの類似度はコサイン類似度によって計算した．ク
ラスタリング手法は，階層クラスタリングの一種である最長距
離法を用いた．今回のデータでは，類似度の閾値を0.2に固定し
てクラスタリングを行ったところ，500個のキーワードから189個のクラスタが得
られた．

得られた各クラスタに対し，式\ref{eq1}の示す確率が最も高い
キーワードを代表キーワードとする．代表キーワードは，クラスタの誤情報を説明するために最も重要なキーワードであると考える．


\subsection{ステップ4：代表フレーズの選択}
\label{sec:selecting-representative-phrase}

クラスタごとに被訂正フレーズを抽出し，誤情報として出力
する．誤情報に相応しい被訂正フレー
ズは，誤情報を過不足なく説明できるような一文である．例えば，以下の例では，
bは説明が不足しており，cは冗長な情報が含まれているため，aを誤情報として出
力したい．

\EXS{ex:phrase_selection}{
\item[a] コスモ石油の火災により，有害物質を含む雨が降る
\item[b] コスモ石油の件で，有害な雨が降る
\item[c] コスモ石油が爆発したというのは本当で，有害な雨が降るから
傘やカッパが必須らしい
}
このような選択を可能にするため，内容語の種類と含有率に着目する．

まず，代表キーワードを含む被訂正フレーズを誤情報の候補として抽出する．
次に，この候補の中から誤情報の内容を過不足なく説明するものを抽出する．
文書自動要約における重要文抽出の考えから，前段で用いたキーワードとよく共起する
内容語を多く含むものは，より重要な文であると考えられる．そこで，共起度合
いを自己相互情報量(PMI)で計る．
\begin{equation}
 \mathrm{Score}_{p}(s,t) = \sum_{w \in C_s} \mathrm{PMI}(t,w) \label{eq_scorep}
\end{equation}

$s$は被訂正フレーズ，$t$は各クラスタの代表キーワード，$C_s$は$s$
中の内容語の集合を表す．ここで，内容語とは被訂正フレーズに含まれる名詞，
動詞，形容詞とする．この式により，誤情報クラスタを代表するキーワードと共
起性の強い内容語を多く含むフレーズに対して，高いスコアが付与される．

しかし，この式では，被訂正フレーズに含まれる内容語の数が多い，長い文ほど
高いスコアが付与されてしまう．そこで，代表キーワードを含む文の中でも，
典型的な長さの文に高いスコアを付与し，短い文および長い文に対して低いスコ
アを与える補正項を用いる．
\begin{equation}
 \mathrm{Score}_{n}(s,t) = \mathrm{hist}(\mathrm{len}_s, t) \label{eq_scoren}
\end{equation}

$\mathrm{len}_s$は被訂正フレーズ$s$の単語数を示す．$\mathrm{hist}(l, t)$は，
代表キーワー
ド$t$を含み，かつ単語数が$l$である文の出現頻度を表す．

最終的なスコアは，式\ref{eq_scorep}と式\ref{eq_scoren}を乗算したものとする（下式）．
\begin{equation}
 \mathrm{Score}(s,t) = \mathrm{Score_{p}} * \mathrm{Score}_{n} \label{eq_score_final}
\end{equation}

最後に，各クラスタから式\ref{eq_score_final}のスコアが最も高いフレーズを
一つずつ選択し，誤情報として出力する．



\section{実験}

評価実験では，東日本大震災時のツイートデータを用いて，誤情報の抽出を行い，
その精度と再現率を測った．抽出された誤情報を，その代表キー
ワードの式\ref{eq1}で並べ替え，上位100件を評価対象とした．考察で
は，ツイートデータから抽出できなかった事例や，誤って抽出された事例を分類
し，今後の対策について述べる．



\subsection{データセット}

誤情報の抽出元となるコーパスには，東日本大震災ビックデータワークショップ
でTwitter Japanから提供された2011年3月11日09:00から2011年3月18日09:00まで
の日本語のツイートデータ179,286,297ツイートを利用した．このデータのうち，
リツイート（自分の知り合いへのツイートの転送）は単順に同じ文が重複してい
るだけであるため，取り除いた．



\subsection{正解データ}

東日本大震災の際に発信された誤情報を網羅的にまとめたデータは存在しない．
評価実験の正解データは，誤情報を人手でまとめた以下の 4 つのウェブサイトに
掲載されている事例を利用した．
\begin{enumerate}
 \item 絵文録ことのは「震災後のデマ80件を分類整理して見えてきたパニック時の社会心理」\footnote{http://www.kotono8.com/2011/04/08dema.html}
 \item 荻上式 BLOG「東北地方太平洋沖地震，ネット上でのデマまとめ」\footnote{http://d.hatena.ne.jp/seijotcp/20110312/p1}
 \item 原宿・表参道.jp　地震のデマ・チェーンメール\footnote{http://hara19.jp/archives/4905}
 \item NAVERまとめ 注意！地震に関するデマ・チェーンメールまとめ\footnote{http://matome.naver.jp/odai/2130024145949727601}
\end{enumerate}

以上の4サイトに掲載されているすべての事例のうち，Twitterデータの投稿期間内（2011 3/11 09:00から2011 3/18 09:00まで）に発信されたと判断できる事例は60件存在
した．この60件の誤情報を正解データとした．作成した正解データの一部を以下に列挙する．

\begin{itemize}
 \item 関西以西でも大規模節電の必要性
 \item ワンピースの尾田栄一郎さん15億円寄付
 \item 天皇陛下が京都に避難された
 \item ホウ酸を食べると放射能を防げる
 \item 双葉病院で病院関係者が患者を置き去りにして逃げた
 \item いわき市田人で食料も水も来ていなく餓死寸前
 \item 宮城県花山村が孤立
 \item 韓国が震災記念Tシャツを作成
 \item 民主党がカップ麺を買い占め
\end{itemize}


\subsection{評価尺度}

抽出された誤情報の正否は，同等の内容が60件の正解データに
含まれるかどうかを一件ずつ人手で判断した．また，正解データに含まれていな
いが，誤情報であると判断できるものもある．そこで抽出された情報が正解デー
タに含まれなかった場合は，関連情報を検索することで，その正否を検証した．

本研究の目的は，出来るだけ多くの誤情報を抽出し，人に提示
することにある．しかし人が一度に見ることのできる情報には限界があり，出来
るだけ多くの誤情報を人に提示するには，提示する誤情報の中にある，冗長な誤
情報を取り除きたい．この目的のため，抽出した誤情報のうち，同
じ内容と判断できるものが複数ある場合は，正解は一つとし，
他の重複するものは不正解とした．
また，日本語として不自然なものも不正解とした．

提案手法はスコアの高い順にN件まで出力可能であるため，Nをいくつか変化させ
たときの精度@N，再現率@N，F値@Nによって評価した．精度には，
正解データに含まれるかどうかで判断したもの（精度@N（60件））と，人手
により検証を行ったもの（精度@N（人手検証））を用意した．
また，人手による検証に加え，重複を許した場合（精度@N（重複））も評価に加えた．
この評価を行うことで，目的の一つである「誤情報抽出」がどの程度達成されて
いるかを知ることができる．
それぞれは以下の式で表される．
\begin{align}
 精度@N（60件） & = \frac{N事例のうち，60件の誤情報に含まれる事例数（重複を除く）}{N}  \\[1zw]
 精度@N（人手検証） & = \frac{N事例のうち，人手で誤情報と検証された事例数（重複を除く）}{N} \\[1zw]
 精度@N（重複） & = \frac{N事例のうち，人手で誤情報と検証された事例数（重複を許す）}{N}  \\[1zw]
 再現率@N & = \frac{N事例のうち，60件の誤情報に含まれる事例数（重複を除く）}{正解の誤情報の数（60件）} \\[1zw]
 F値@N & = \frac{2*精度@N（60件） * 再現率@N}{精度@N（60件） + 再現率@N} 
\end{align}



\subsection{実験結果}

\begin{table}[b]
\vspace{-1\Cvs}
 \caption[評価]{実験結果}
 \label{kekka}
\input{21table02.txt}
\end{table}

評価結果を表\ref{kekka}に示す．
\pagebreak
Nが100のとき，提案手法が抽出した情報のうち，60件の正解デー
タにも含まれる情報は31件であった．さらに，正解データには含まれないが，
誤情報と判断できる事例が23件存在したことから，提案手法は54\%の精度で誤情報を抽出でき
た．

次に，上位N件に限定しない場合の再現率について述べる．「上
限(N=189)」は500個のキーワードをクラスタリングし得られた189個のクラスタか
ら，代表フレーズをすべて出力した時の再現率であり，「上限（クラスタなし）」
は，提案手法ステップ1で収集された被訂正フレーズ集合約2万件をすべて出力し
た時の再現率である．「上限(N=189)」は，キーワードを189個に絞った時の，ラ
ンキング改善による性能向上限界を表すに対し，後者はキーワードの選
択，ランキング，クラスタリング改善による性能向上限界，つまり訂正パターン
に基づく抽出手法の限界を表す．
被訂正フレーズ集合の段階でカバーされて
いる50件は，キーワードの選択やクラスタリングなど，後段の
処理を改善することで抽出できる可能性があるが，残る10件は，
訂正パターンに基づく抽出手法の改善が必要となる，難解な事例である．


\subsection{考察}

本節では，評価結果の誤りを分析する．抽出された誤情報の上位100件のうち，
31件は正解データに含まれていたが，残りの
69件は正解データに含まれていなかった．そこで，不正解データに対する誤判定の原因を調べたところ，8 種類の原因に分類できた．表
\ref{FP}に理由と件数を示す．

\begin{table}[b]
 \caption[評価]{精度に対する誤り分析}
 \label{FP}
\input{21table03.txt}
\end{table}

(a)から(d)は，明らかに誤抽出と判断できる事例である．
(e)と(f)は，正解データの構築に用いた 4 つの誤情報まとめサイト
に掲載されてはいなかったが，ウェブ上で調べることで，明ら
かに誤情報であると認められる事例である．(g)と(h)は，人手でも誤情報
であるかを判断できない事例である．

以下でそれぞれの詳細と，改善案を述べる．
\pagebreak

\begin{description}
\item[(a)] キーワード抽出による誤り\\
	    代表キーワードが誤抽出につながったと考えられ
	    る事例である．以下に例を示す．括弧の中は，選定に利用した代表
	    キーワードである．
	    \enumsentence{\ulinej{\mbox{陰謀論とか、「悪意の行動があった」}}とかいうデマを信じる人って…（悪意）}
	    「善意」や「悪意」といった単語は，元々「デマ」などの訂正表現
	    の周辺文脈に出現しやすい単語であるため，条件付き確率
	    (\ref{eq1})が高く，キーワードとして選ばれた．しかし，特定の誤
	    情報に関連するキーワードではないため，上記の例のように，具体
	    性に欠ける被訂正フレーズが誤情報として抽出された．
	    このようなキーワードは，誤情報の拡散時に限らず，通常時から訂
	    正表現と共起すると考えられる．そこで対策として，被訂正フ
	    レーズに含まれる確率（式\ref{eq1}）を使用するのではなく，通常時
	    の共起度合いを組み込むことで，改善が望めると考えらる．
	    
\item[(b)] クラスタリングによる誤り\\
	    抽出された誤情報上位100件のうち，同じ内容と判断できる誤情
	    報が重複している事例である．例を以下に示す．括弧の中は，選定
	    に利用した代表キーワードである．
	    \enumsentence{
	市原市のコスモ石油千葉製油所LPGタンクの爆発により，千葉県，
	    近隣圏に在住の方に有害な雨などと一緒に飛散する（コスモ石油千葉
	    製油所）\\
	千葉県の石油コンビナート爆発で，空気中に人体に悪影響な物質が
	    空気中に舞い雨が降ると酸性雨になる（石油コンビナート爆発）
	    }
	    これはステップ3でクラスタリングを行ったとき，同じクラスタに分
	    類できなかったため，重複として表れた．誤情報
	    検出の目的は達成できているものの，冗長な誤情報を抜き出してい
	    るため厳しめに評価して不正解とした．キーワー
	    ドのクラスタリングには，被訂正フレーズの中で共起する単語を素
	    性としているが，素性に表層の情報を加えることで，誤りを減らす
	    ことができると考えられる．

 \item[(c)] 内容が不正確な情報\\
	    抽出された誤情報の内容が，誤情報を説明するのに内容が不足して
	    いると思われる事例である．以下に例を示す．
	    \enumsentence{餓死者や凍死者が出た．}
	    正解データの中には「いわき市で餓死者や凍死者が出た」というも
	    のが存在するが，それと比べると具体性に欠けているため，不正解
	    とした．より的確な候補を抽出するには，候補が多いほど作成した
	    パターンの精度や再現率を考慮した選定が必要である．

 \item[(d)] 正しい情報\\
	    誤情報として抽出されたが，事実を確認したところ，誤情報ではな
	    かった事例である．以下に例を示す．
	    \enumsentence{東京タワーの先端が曲がった}
	    この例に関連するツイートを観察したところ，根
	    拠とされる写真を提示されても信じてもらえないほど，突拍子のな
	    い情報として扱われていた．そのため，訂正ツイートが多く投稿され
	    たようである．提案手法は訂正の数が多い情報ほど，ランキングが
	    上位になる仕組みになっているため，この事例は誤って抽出された．
	    本研究の目的は「誤情報の抽出」であることを考えると，(a)から
	    (c)の誤りに比べ，深刻な誤りである．
	    しかし，始めは誤情報として疑っていたユーザーの中には，誤情報
	    出なかったことを知り，以下のようなツイートをしている人も存在
	    した．
	    \enumsentence{
	東京タワーが曲がったってデマじゃなかったんだ\\
	東京タワー曲がったとかデマだと思ったら本当だった
	    }
	    このように，訂
	    正を訂正しているツイートも存在し，二重否定を判別することが出
	    来れば，この問題の改善につながると考えられる．
 \item[(e)] まとめサイトに掲載されていない誤情報（過去）\\
	    これは誤情報まとめサイトに掲載されていないが，
	    人手で検証したところ，誤情報と判別された事例である．その
	    中でも今回利用したツイートコーパスの期間より前の事象に関する
	    誤情報である．以下に例を示す．
	    \enumsentence{
	\ulinej{関東大震災の時「朝鮮人が井戸に毒を入れた」}というのはデマだったはず\\
	\ulinej{阪神淡路大震災は三時間後に最大の揺れが来た}というのは誤った情報のようです。\\
	\ulinej{\mbox{明治43年（1910年）}にハレー彗星が大接近した時、地球上の空気\mbox{が5分間}ほどなくなる}というデマが一部で広まり，…
	}
	    上記の例は訂正ツイートであり，下線部は被訂正
	    フレーズとして抽出された部分である．一度過去に誤情報として認
	    識されたことは間違いないが，人々に悪影響を与える可能性があり，
	    誤情報として抽出し，拡散・訂正の動向を監視する必要がある．
\item[(f)] まとめサイトに掲載されていない誤情報（現在）\\
	    これは誤情報まとめサイトに掲載されていないが，人手で検証を行っ
	    たところ，誤情報と判別された事例である．その中でも今回利用し
	    たツイートコーパスの期間中に発生した誤情報である．以下に
	    例を示す．
	\enumsentence{
	VIPで韓国の救助犬 1 匹が逃亡\\
	巷説にある遺体には感染症のリスクがある
	}
\item[(g)] 未来予測\\
        (h)の真偽不明の事例のうち，
	    未来に起こりうる事象について述べたものを抽出した事例である．以下に例を示す．
    	    \enumsentence{
	福島で核爆発が起こる\\
	富士山が噴火する
	}
	未来に起こりうる事象である以上，
	    現時点での真偽は不明である．抽出されたものの多くは，上記の例
	    のように人々の不安を煽る情報であり，パニックを防ぎたいと思い
	    訂正ツイートを発信した人が多かったため，抽出されたと考えられ
	    る．

 \item[(h)] 真偽不明\\
	        複数のウェブサイトを検索して検証を行ったが，
	    誤情報かどうかを判別できなかった事例である．
	    以下に例を示す．
    	\enumsentence{
	サントリーが自販機無料開放\\
	築地で魚が余っている
	}
\end{description}

次に，正解データにある誤情報60件のうち，抽出されなかった誤情報29件
についても同様に原因を調査したところ，3 つに分類できることが判明した．
3つの原因の件数と割合を表\ref{FN}に示す．

\begin{table}[b]
 \caption[評価]{再現率に対する誤り分析}
 \label{FN}
\input{21table04.txt}
\end{table}

\begin{description}
 \item[(i)] 訂正パターンで候補を抽出できなかったもの\\
	    今回作成した訂正パターンでは，抽出できなかった誤情報である．
	    「仙台市三条中学校が中国人・韓国人が 7 割の留学生の心ない行動
	    で避難所機能停止」という誤情報に対して，以下のようなツイート
	    が数多く存在した．
    \enumsentence{
	コレ本当? RT @XXXXX 今，祖母と叔母に確認．何と仙台市の三条
	中学校の避難所，閉鎖！避難所用救援物資を根こそぎ，近隣の外国人留学生
	（中国韓国で七割強）が運び出してしまい，避難所の機能停止だそうです． 
	}
	上の例では，明示的に誤情報だと否定している人は少ないが，元の
	ツイートコメントする形で，その情報を疑っている人は多かった．
	このことから，改善案とし訂正パターンのみではなく，懐疑を表す
	表現も利用できるのではないかと思われる．

 \item[(j)] 訂正パターンで抽出できたが，クラスタリングによる誤り\\
	    訂正パターンにより候補の抽出はできたが，クラスタリングにより，
	    誤って他の誤情報に含まれた事例である．
	    しかし，全体に比べ，事
	    例数が少ないため，それほど問題ではないと思われる．

 \item[(k)] 訂正パターンで抽出できたが，ランキング外\\
	    訂正パターンにより候補を抽出できたが，条件付き確率が低かった
	    ため，キーワードとして抽出できなかった事例である．例えば，
	    「東京電力を装った男が表れた」という誤情報では，「東京電力」
	    というキーワードは誤情報以外の話題でも頻出したため，条件付き
	    確率が低くなった．対策としては，キーワード単独をスコアリング
	    するのではなく，被訂正フレーズそのものをスコアリングするよう
	    な手法が必要である．
\end{description}



\section{誤情報の拡散状況の分析}

本節では，誤情報がどのように発生し，拡散・収束していくかを分析する．誤情
報およびその訂正情報の拡散状況を時系列で可視化することで，誤情報の拡散の
メカニズムを詳細かつ系統的に分析する．
分析対象とする誤情報は，将来的には自動抽出結果を用いる予
定だが，「東日本大震災の誤情報の拡散状況を正しく分析する」という目的から，
誤情報であると確認できた事例のみを用いた．

\begin{figure}[b]
\begin{center}
  \includegraphics{20-3ia21f4.eps}
\end{center}
\caption{誤情報拡散状況システム}
\label{fig:system}
\end{figure}

本節で想定しているシナリオは以下の通りである．前節までの手法で，ツイート
空間上で誤情報と考えられているフレーズ（例えば「コスモ石油のコンビナート
火災に伴い有害物質の雨が降る」）を抽出できる．この誤情報がどのように発生・
拡散し，その訂正情報がどのように発生・拡散したのかを調べるため，このフレー
ズの中からキーワードを選び，ツイート検索システムへのクエリ（例えば「コス
モ石油 AND 有害物質」）とする．このクエリを用いてツイートを検索すると，
誤情報を拡散するツイート，誤情報を訂正するツイートが混ざって得られる．そ
こで，本節ではツイートを誤情報の「拡散」と「訂正」の 2 グループに自動分類
する手法を提案する．
図 4 は実際に作成した，誤情報の拡散状況を提示するシステムである．
このシステムの処理をリアルタイム化すれば，被訂正情報
から抜き出したキーワードを誤情報の監視クエリとし，誤情報の拡散・訂正状況
をモニタリングしたり，誤情報を発信した（もしくは発信しようとしている）者
に，訂正情報の存在を通知することができる．

本節で提案する手法で「拡散」「訂正」ツイートの分類精度を測定するため，14
件の誤情報に関して，正解データを作成した．この正解データを利用すれば，提
案手法の性能を評価できるだけではなく，誤情報の拡散・訂正状況を精緻に検証
し，誤情報の発生から収束までのメカニズムをモデル化することができる．最後
に，自動手法の失敗解析を通じて，誤情報と訂正情報を対応づける際の技術的課
題を述べる．


\subsection{訂正表現による誤情報と訂正情報の自動分類}

\begin{table}[b]
 \caption{訂正情報を認識する精度}
 \label{kakusan}
\input{21table05.txt}
\end{table}

与えられたツイートに対して，誤情報の「拡散」もしくは「訂正」に分類する手
法を，順を追って説明する．まず，前節までの手法で獲得した誤情報に関連する
ツイートを集める．ツイートの収集には本研究室で開発されたツイート全文検索
システムを用いる．誤情報に関連するツイートを収集するために，獲得した誤情
報（例えば「東大が合格者の入学取り消し」）を適切なクエリ（例えば「東大
AND 入学」）に変換する．

次に検索によって得られた全ツイートを誤情報と訂正情報とに分類する．分類に
は「デマ」や「風説」などの訂正表現を含むツイートを「訂正情報」とし，含まな
いものを「訂正情報ではない」ツイートとする．訂正表現は震災時のツイートを
読みながら，121個用意した．

検索で得られるツイートの中には，「誤情報」や「訂正情報」
とは関係の無い「その他」のツイートが存在するが，後述する正解データの割合
を示した表\ref{kakusan}から分かるように，「その他」の割合は少ない．そこ
で本節では「訂正情報ではない」ツイートは誤情報の「拡散」ツイートとして見なす．


\subsection{実験と評価}

本手法の認識精度を評価するため，14件の誤情報に関連するツイート群を検索し，
それらのツイートを「誤情報」「訂正情報」「その他」の手作業で分類し，正解
データを作成した．評価対象の誤情報は，人手での作業の負荷
を考慮して14件とした．関連するツイート5,195件のうち，誤情報ツイートが2,462
件，訂正情報ツイートが2,376件，その他のツイートが357件であった（表
\ref{kakusan}）． 評価対象として14件の誤情報は，第
\ref{sec:selecting-representative-phrase}節で定義した条件付き確率（式\ref{eq1}）が高いものから誤った事例を人手で除き，順に選んだ．今回の実験
では被リツイート数の多いツイートを優先的に採用し，手作業による分類のコス
トを下げた\footnote{実際には，被リツイート数が$x$件以上のツイートのみを採
用した．誤情報によって関連するツイート数が異なるため，閾値$x$は誤情報毎に
調整した．}．

なお，評価対象のツイートは誤情報や訂正情報に関するものと仮定しているので，「その他のツイート」は評価の対象外とする．

表\ref{kakusan}に，提案手法が訂正情報を認識する精度（再現率・適合率・F1スコア）を示した．この評価では，リツイートは削除し，オリジナルのツイートのみを評価対象としている．
表\ref{kakusan}によると，ほとんどの誤情報について高い適合率が得られた．適合率が高いということは「デマ」などの訂正表現を含むツイートは，かなりの確度で訂正情報と見なせるということである．「デマ」という語を伴って誤情報の拡散を行うことは，通常では考えにくいので，これは直感的に理解できる結果である．これに対し，再現率はユーザが誤情報の訂正のために，「デマ」などの訂正表現をどのくらい使うのかを示している．再現率が高いということは，誤情報の訂正情報のほとんどが「デマ」等の表現を伴うということである（例えば，以下のツイートを参照）．
\begin{quote}
【拡散希望】トルコが日本に100億円の支援をするという内容のツイートが出回ってますが，誤情報だということです．情報を発信した本人が誤りだと言ってます．
\end{quote}
以上の結果から，訂正表現のマッチングに基づく提案手法でも，かなりの精度で誤情報の「拡散」と「訂正」のツイートを分離できることが示された．

しかし，量は少ないものの，訂正表現を含む誤情報拡散ツイートも見受けられる．
\begin{quote}
万が一原発から放射能が漏れ出した際，被爆しない為にイソジンを 15~cc 飲んでおいて下さい！原液です！ガセネタではありません．お医者さんからの情報です．これはRTではないので信じてください！
\end{quote}
このツイートでは，「ガセ」という訂正表現を含んでいるが，「ガセ」をさらに否定しているので，二重否定により誤情報の拡散ツイートと解釈できる．

さらに，訂正表現を用いずに誤情報を否定するツイートも存在する．
\begin{quote}
千葉のコスモ石油のタンク爆発事故で中身の有害物質が雲に付着して降ってくるというツイートをよく見かけますが、公式サイトでタンクの中身がLPだったので火災で発生した大気が人体に及ぼす影響はほとんどないみたいです。
\end{quote}
このツイートでは，「デマ」「嘘」などの訂正表現は一切使われていないが，誤情報の内容（「コスモ石油の火災により有害物質の雨が降る」）を訂正するツイートであると判断できる．
このようなツイートを訂正ツイートと認識するためには，深い
処理（例えば，「タンクの爆発事故」による「人体に及ぼす影響はほとんどない」と解釈する）や，ツイートやユーザ間の関係（例えば，このツイートをRTしているユーザが，訂正表現を用いてた別の訂正ツイートをRTしている，等の手がかり）を用いる必要がある．


\subsection{誤情報の拡散状況の分析}

本研究において構築した正解データを分析すれば，様々な誤情報の拡散状況を調
べることができる．そこで，誤情報の「拡散」ツイートと「訂正」ツイートの数
を，それぞれ一定時間おきに折れ線グラフにプロットし，誤情報の拡散状況を可
視化するシステムを開発した．可視化にはクロス・プラットフォームかつブラウ
ザ上で利用できるGoogle Chart Toolsを用いた．デモシステムでは，各時点でど
のようなツイートが拡散していたのか，ツイート本文を閲覧できるようになって
いる．なお，グラフにプロットするツイートの数はリツイート数も考慮し，ツイー
ト空間上での情報の拡散状況を表した．

14件の誤情報に対して，正解データからプロットされたグラフを観察すると，誤
情報の拡散状況は，以下の2つの要素で特徴付けらることが分かっ
た．
\begin{description}
\item[ツイートの量の違い：] 誤情報ツイート数と訂正ツイート数のどちらが多いか．
\item[収束時間の違い：] 誤情報の収束が遅いか速いか\footnote{収束時間（誤ツイートの発生から，誤ツイート量が0になるまでの時間）が一日未満であれば，速く，そうでなければ遅いと分類した．}．
\end{description}
この2つの要素の組み合わせにより，誤情報の拡散状況を4つにタイプ分けした．
（表\ref{type_kakusan}，図\ref{fig:four-kakusan}参照）

\begin{table}[t]
 \caption{拡散状況のタイプ}
 \label{type_kakusan}
\input{21table06.txt}
\end{table}

\begin{figure}[t]
\begin{center}
  \includegraphics{20-3ia21f5.eps}
\end{center}
\caption{4種類に分けられる拡散状況}
\label{fig:four-kakusan}
\end{figure}

\begin{description}
 \item[誤情報優勢・短時間収束型：]例えば，「サーバールームで身動きが取れない」という誤情報では，人間の危険や不安を伝えているため，誤情報を見たユーザが善意でツイートを拡散する傾向にある．このように，助けを求めたり，不安を煽るなどの情報は拡散しやすく，情報が間違いである場合は，訂正情報よりも誤情報の拡散ツイートの方が多くなりやすい．さらに，情報の発信者がジョークとしてつぶやいた情報や，情報の裏を検証することで真偽性を判定しやすいもの，救助などで緊急性を要するものは，短時間収束型になる傾向がある．他には，「阪神大震災では3時間後に最大の揺れが来た」などの誤情報が，このカテゴリに分類される．

 \item[誤情報優勢・長時間拡散型：]例えば，「支援物資の空中投下は法律で認められていない」という誤情報は，緊急性を要するものではあったが，真偽性を判断する情報源や専門家の数が少ないため，結果として誤情報が長く拡散する傾向にある．同じカテゴリの誤情報には，「イソジンを飲んで放射線対策」などが挙げられる．このカテゴリの誤情報は，長期間にわたって拡散し，訂正情報の数も少ないため，情報技術での対応が最も期待されるカテゴリであると考える．

 \item[訂正情報優勢・短時間収束型：]例えば，「被災地の合格者が期限までに書類を提出できないと東大の入学が取り消される」という誤情報は，このカテゴリに属する．このカテゴリの誤情報は，誤情報を否定する情報源がウェブ等に存在する等で，訂正が容易であったと考えられる．また，誤情報を否定する情報がすでにウェブ上に存在するか，否定情報が発表されるまでの期間が短いため，誤情報が短時間で収束した．他には，「阪神大震災時にはレイプが多発」など，既にソースがある誤情報がこのカテゴリに属する．
 \item[訂正情報優勢・長時間拡散型：]例えば，「コスモ石油の爆発で有害な雨が降る」という誤情報は，コスモ石油や厚生労働省などの信頼性の高い情報源から訂正情報が流れたため，訂正情報が優勢となった．ただ，訂正情報の公式発表が遅れたため，誤情報の収束までの時間が長くなった．また，誤情報の内容に緊急性が無い場合（例えば「トルコが100億円寄付」）も，長時間拡散型になりやすい．
\end{description}

このように，誤情報の拡散と訂正のメカニズムは，情報の緊急性や真偽の検証に必要な情報の入手性・信憑性により，様々であることが分かった．



\section{おわりに}

本研究では，誤情報を訂正する表現に着目し，誤情報を自動的に収集する手法を
提案した．実験では，誤情報を人手でまとめたウェブサイトから取り出した誤情
報のリストを正解データと見なして評価を行ったところ，出力数が100件のとき正
解データの約半数である31件を収集することができた．これは抽出した情報100件
の約3割であるが，残り69件の中には，まとめサイトに掲載されていない誤情報も
23件あり，54\%の精度で誤情報を抽出できた．また，収集された誤情報の中に真
実の情報が含まれていると深刻な問題であるが，誤って抽出された事例の多くは，
内容の重複する誤情報や真偽不明の事例であり，特に問題である真実の情報は
100件のうち1件と非常に少なく，提案手法は誤情報の自動収集に有用であること
を示した．

また，誤情報に対して，誤情報の出現とその拡散状況，その訂正情報の出現とそ
の拡散状況を可視化するシステムを構築した．本システムの訂正情報の認識精度
を測定したところ，多くの誤情報について高い精度を得ることができた．
実際に，本システムを用いて収集された誤情報の分析を行ったところ，拡散状況
を幾つかのタイプに分類を分類することができた．

今後の課題として，懐疑や反論といった，訂正パターン以外の情報を考慮した誤
情報の抽出が挙げられる．


\acknowledgment
本研究は，文部科学省科研費(23240018)，文部科学省科研費(23700159)，
およびJST戦略的創造研究推進事業さきがけの一環として行われた．
貴重なデータを提供して頂いた，Twitter Japan株式会社，および東日本大震災
ビッグデータワークショップに感謝いたします．

\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Acar \BBA\ Muraki}{Acar \BBA\ Muraki}{2011}]{Acar:11}
Acar, A.\BBACOMMA\ \BBA\ Muraki, Y. \BBOP 2011\BBCP.
\newblock \BBOQ Twitter for crisis communication: lessons learned from Japan's
  tsunami disaster.\BBCQ\
\newblock {\Bem International Journal of Web Based Communities}, {\Bbf 7}
  (3/2011), \mbox{\BPGS\ 392--402}.

\bibitem[\protect\BCAY{Doan, Vo, \BBA\ Collier}{Doan et~al.}{2011}]{Doan:11}
Doan, S., Vo, B.-K.~H., \BBA\ Collier, N. \BBOP 2011\BBCP.
\newblock \BBOQ An analysis of {Twitter} messages in the 2011 {Tohoku}
  {Earthquake}.\BBCQ\
\newblock In {\Bem 4th ICST International Conference on eHealth}, \mbox{\BPGS\
  58--66}.

\bibitem[\protect\BCAY{藤川\JBA 鍜治\JBA 吉永\JBA 喜連川}{藤川 \Jetal
  }{2011}]{Fuji12}
藤川智英\JBA 鍜治伸裕\JBA 吉永直樹\JBA 喜連川優 \BBOP 2011\BBCP.
\newblock
  マイクロブログ上の流言に対するユーザの態度の分類（テーマセッション,大規模マ
ルチメディアデータを対象とした次世代検索およびマイニング）.\
\newblock \Jem{電子情報通信学会技術研究報告. DE, データ工学}, {\Bbf 111}  (76),
  \mbox{\BPGS\ 55--60}.

\bibitem[\protect\BCAY{宮部\JBA 荒牧\JBA 三浦}{宮部 \Jetal }{2011}]{Miyabe:11}
宮部真衣\JBA 荒牧英治\JBA 三浦麻子 \BBOP 2011\BBCP.
\newblock 東日本大震災におけるTwitterの利用傾向の分析.\
\newblock \Jem{情報処理学会研究報告}, 17\JVOL.
\newblock 2011-DPS-148/2011-GN-81/2011-EIP-53.

\bibitem[\protect\BCAY{宮部\JBA 梅島\JBA 灘本\JBA 荒牧}{宮部 \Jetal
  }{2012}]{DemaCloud}
宮部真衣\JBA 梅島彩奈\JBA 灘本明代\JBA 荒牧英治 \BBOP 2012\BBCP.
\newblock 流言情報クラウド：人間の発信した訂正情報の抽出による流言収集.\
\newblock \Jem{言語処理学会第18回年次大会}, \mbox{\BPGS\ 891--894}.

\bibitem[\protect\BCAY{ネットレイティングス株式会社}{ネットレイティングス株式
会社}{2011}]{netrating201103}
ネットレイティングス株式会社 \BBOP 2011\BBCP.
\newblock ニュースリリース:
  震災の影響により首都圏ライフライン関連サイトの訪問者が大幅増.\
  http://csp.netratings.co.jp/nnr/PDF/\linebreak[2]Newsrelease03292011\_J.pdf.

\bibitem[\protect\BCAY{野村総合研究所}{野村総合研究所}{2011}]{nomura201103}
野村総合研究所 \BBOP 2011\BBCP.
\newblock プレスリリース：震災に伴うメディア接触動向に関する調査.\
\newblock http://www.nri.co.jp/news/2011/110329.html.

\bibitem[\protect\BCAY{Qazvinian, Rosengren, Radev, \BBA\ Mei}{Qazvinian
  et~al.}{2011}]{Qaz2011}
Qazvinian, V., Rosengren, E., Radev, D.~R., \BBA\ Mei, Q. \BBOP 2011\BBCP.
\newblock \BBOQ Rumor has it: identifying misinformation in microblogs.\BBCQ\
\newblock In {\Bem Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, EMNLP '11, \mbox{\BPGS\ 1589--1599},
  Stroudsburg, PA, USA. Association for Computational Linguistics.

\bibitem[\protect\BCAY{Ratkiewicz, Conover, Meiss, Goncalves, Patil, Flammini,
  \BBA\ Menczer}{Ratkiewicz et~al.}{2011}]{Ratkiewicz:2011}
Ratkiewicz, J., Conover, M., Meiss, M., Goncalves, B., Patil, S., Flammini, A.,
  \BBA\ Menczer, F. \BBOP 2011\BBCP.
\newblock \BBOQ Truthy: mapping the spread of astroturf in microblog
  streams.\BBCQ\
\newblock In {\Bem Proceedings of the 20th international conference companion
  on {World Wide Web}}, WWW '11, \mbox{\BPGS\ 249--252}.

\bibitem[\protect\BCAY{Sakaki, Toriumi, \BBA\ Matsuo}{Sakaki
  et~al.}{2011}]{Sakaki:11}
Sakaki, T., Toriumi, F., \BBA\ Matsuo, Y. \BBOP 2011\BBCP.
\newblock \BBOQ Tweet Trend Analysis in an Emergency Situation.\BBCQ\
\newblock In {\Bem Special Workshop on Internet and Disasters (SWID 2011)},
  \mbox{\BPGS\ 3:1--3:8}.

\bibitem[\protect\BCAY{白井\JBA 榊\JBA 鳥海\JBA 篠田\JBA 風間\JBA 野田\JBA
  沼尾\JBA 栗原}{白井 \Jetal }{2012}]{Shirai}
白井嵩士\JBA 榊剛史\JBA 鳥海不二夫\JBA 篠田孝祐\JBA 風間一洋\JBA 野田五十樹\JBA
  沼尾正行\JBA 栗原聡 \BBOP 2012\BBCP.
\newblock
  Twitterにおけるデマツイートの拡散モデルの構築とデマ拡散防止モデルの推定.\
\newblock \Jem{人工知能学会全国大会予稿集, IC3-OS-12-1}.

\bibitem[\protect\BCAY{鳥海\JBA 篠田\JBA 兼山}{鳥海 \Jetal }{2012}]{Tori}
鳥海不二夫\JBA 篠田孝祐\JBA 兼山元太 \BBOP 2012\BBCP.
\newblock ソーシャルメディアを用いたデマ判定システムの判定精度評価.\
\newblock \Jem{デジタルプラクティス}, {\Bbf 3}  (3), \mbox{\BPGS\ 201--208}.

\bibitem[\protect\BCAY{梅島\JBA 宮部\JBA 荒牧\JBA 灘本}{梅島 \Jetal
  }{2011}]{Ume11}
梅島彩奈\JBA 宮部真衣\JBA 荒牧英治\JBA 灘本明代 \BBOP 2011\BBCP.
\newblock 災害時Twitterにおけるデマとデマ訂正RTの傾向.\
\newblock \Jem{情報処理学会研究報告．データベース・システム研究会報告}, {\Bbf
  2011}  (4), \mbox{\BPGS\ 1--6}.

\bibitem[\protect\BCAY{梅島\JBA 宮部\JBA 灘本\JBA 荒牧}{梅島 \Jetal
  }{2012}]{Ume12}
梅島彩奈\JBA 宮部真衣\JBA 灘本明代\JBA 荒牧英治 \BBOP 2012\BBCP.
\newblock マイクロブログにおける流言マーカー自動抽出のための特徴分析.\
\newblock \Jem{第4回データ工学と情報マネジメントに関するフォーラム (DEIM Forum
  2012), F3-2}.

\end{thebibliography}

\begin{biography}
\bioauthor{鍋島　啓太}{
2012年東北大学工学部情報知能システム情報学科卒業．同年，同大学情報科学研
 究科博士課程前期に進学，現在に至る．自然言語処理の研究に従事．情報処理
 学会学生会員．
}
\bioauthor{渡邉　研斗}{
2013年東北大学工学部情報知能システム情報学科卒業．同年，同大学情報科学研究科博士課程前期に進学，現在に至る．自然言語処理の研究に従事．情報処理学会学生会員．
}
\bioauthor{水野　淳太}{
2012年奈良先端科学技術大学院大学情報科学研究科博士課程修了．同年より東北大学大学院情報科学研究科研究員．2013年より独立行政法人情報通信研究機構耐災害ICT研究センター研究員．博士（工学）．自然言語処理，耐災害情報通信の研究に従事．情報処理学会，人工知能学会各会員．
}
\bioauthor{岡崎　直観}{
2007年東京大学大学院情報理工学系研究科・電子情報学専攻博士課程修了．同大学院情報理工学系研究科・特別研究員を経て，2011年より東北大学大学院情報科学研究科准教授．自然言語処理，テキストマイニングの研究に従事．情報理工学博士．情報処理学会，人工知能学会，ACL 各会員．
}
\bioauthor{乾　健太郎}{
1995年東京工業大学大学院情報理工工学研究科博士課程修了．同研究科助手，九州工業大学助教授，奈良先端科学技術大学院大学助教授を経て，2010年より東北大学大学情報科学研究科教授，現在に至る．博士（工学）．自然言語処理の研究に従事．情報処理学会，人工知能学会，ACL，AAAI各会員．
}

\end{biography}


\biodate




\end{document}
