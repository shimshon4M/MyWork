    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline


\Volume{20}
\Number{3}
\Month{June}
\Year{2013}

\received{2012}{12}{14}
\revised{2013}{3}{6}
\accepted{2013}{3}{31}

\setcounter{page}{367}

\jtitle{質問応答に基づく対災害情報分析システム}
\jauthor{後藤　　淳\affiref{Author_1} \and 大竹　清敬\affiref{Author_1} \and 
	Stijn De Saeger\affiref{Author_1} \and 橋本　　力\affiref{Author_1} \and\\ 
	Julien Kloetzer\affiref{Author_1}\and 川田　拓也\affiref{Author_1} \and 鳥澤健太郎\affiref{Author_1}}
\jabstract{
本論文では，地震や津波などの災害時に個人からソーシャルメディア上に発信さ
れる大量の書き込みから，救援者や被災者が欲している
情報を自動的に取得する情報分析システムについて報告する．このシステムでは，
質問応答技術により，災害時の被災地の状況や救援状況を俯瞰的に把握し，被災
地からの想定外も含めた情報を取得することを目的としている．システムで利用
している質問応答処理では構文パターンの含意に基づき質問文を拡張し，ソーシャルメディアへの書き込みに対して地名・場所名を補完することにより，
幅広い質問に対応する．さらに，本システムを拡張することにより，被災地からの重要な情報
提供が必ずしも救援者へ届かない問題に対応できることについて述べる．NPOや
自治体などの救援者が状況把握のための質問を予め登録しておけば，
救援を望む被災者がTwitterやBBS等へ書き込んだ時点で，情報を求める
側と提供する側の双方に自動的に通知できる．これにより救援者と被
災者の双方向のコミュニケーションが担保され，救援活動がより効率的になると
期待される．本システムの質問応答性能を我々が用意した300問のテストセット
のうち回答が対象データに含まれる192問を用いて評価したところ1質問あたり平
均605.8個の回答が得られ，再現率は0.519，適合率は0.608であった．
}
\jkeywords{情報システム，質問応答，災害，ビッグデータ}

\etitle{A Disaster Information Analysis System\\ Based on Question Answering}
\eauthor{Jun Goto\affiref{Author_1} \and Kiyonori Ohtake\affiref{Author_1}\and Stijn De Saeger\affiref{Author_1} 
	\and Chikara Hashimoto\affiref{Author_1} \and \\ 
	Julien Kloetzer\affiref{Author_1} \and Takuya Kawada\affiref{Author_1} \and Kentaro Torisawa\affiref{Author_1}}
\eabstract{
In this paper we introduce an information analysis system that
automatically acquires from social media like Twitter the kind of
vital information that rescue workers or disaster victims need
in case of large-scale disasters like earthquakes or tsunami. This
system uses
question-answering (QA) technology with the aim of helping users get a
comprehensive overview of the state of affairs and the various conditions of
ongoing rescue efforts in the afflicted areas, and detect potentially
unanticipated information from the disaster areas. The system expands
the input question with various entailment expressions, and
augments the original social media input data by analyzing the mentioned
place names
in order to handle a wide variety of questions relevant to disaster
scenarios. Moreover, we extend this system to address rescue workers'
crucial problem of getting access to relevant information from the
disaster areas in times of crisis. To tackle this problem we introduce
a mechanism by which rescue workers from NPOs or municipalities can
register certain questions for situation assessment in advance, so
that when a disaster victim posts some urgent requests for food, 
medicines or other essentials on Twitter or some other BBS, both
information sender and information requester are automatically
notified of this. We expect that such a mechanism can safeguard the
two-way communication between rescue workers and disaster victims, and
ultimately lead to a more effective rescue effort. We evaluate the
system on a test set of 300 questions and their answers. For
192 questions whose answers are actually included in our system's index, 
we obtained on average 605.8 answers per question, with 51.9\% recall
and 60.8\% precision.}
\ekeywords{Information Analysis, Question Answering, Disaster, Big Data}

\headauthor{後藤，大竹，De Saeger, 橋本，Kloetzer, 川田，鳥澤}
\headtitle{質問応答に基づく対災害情報分析システム}

\affilabel{Author_1}{情報通信研究機構}{National Institute of Information and Communications Technology}



\begin{document}
\maketitle


\section{はじめに}
\label{Introduction}

2011年3月11日に起こった東日本大震災では，テレビ，ラジオなどの既存
メディアが伝えきれなかった局所的な情報を，Twitterなどの個人が情報発信できるソーシャルメディアが補完する可能性を改めて知ることとなった．一方で，
Twitter等で発信された大量の情報を効率的に把握する手段が
なかったために，被災地からの切実な要望や貴重な情報が，政府，地方自治体，
NPOなどの救援団体に必ずしも届かず，救援活動や復興支援が最大限の効率で進
展しなかったという可能性も高い．
我々が震災時のTwitterへの書き込み (tweet) を調査したところ，少なくとも救援者が何らかの
対応をしたことを示すtweetが存在しない要請tweetも非常に多く存在した．さら
には大量に飛び交うデマを含む情報に振り回された人も多く出た．

こうした状況に対応するため，
自然言語処理を用いてTwitter上の安否情報を整理することを目指した「ANPI\_NLP」の
取り組みが行われたが，開発の速度や多数のボランティアを組織化するには
課題があったことが報告されている\cite{Neubig2011}．実際に災害が発生してから，新た
にTwitter等のソーシャルメディアに自然言語処理を適用し，情報を整理する技
術を開発するのは非常に困難であろう．我々は，将来起きる災害に備えて，事前
にそうした技術を開発しておくことが極めて重要であると考えている．

また，我々が被災地で行ったヒアリングでは，現地からの要望とその支援とのミスマッ
チも明らかになっている．例えば，テレビや新聞などのマスメディアで伝えられ
た「被災地で防寒着が不足している」という情報に呼応して，多くの善意の人か
ら防寒着の上着が大量に現地に送られたが，津波被害にあい泥水の中で復旧作業
をする必要のあった人々がより切実に求めていたのは，防寒のズボンであった．
別の例では，全国から支援物資として届けられた多くの衣類はどれも通常
サイズのものばかりで，4Lサイズなどの大きな衣類が必要な人が一月以上も被
災時の衣類を着続ける必要があった．これらは，大規模
災害発生時に生じる被災者の要望の広範さや事前にそうした要望を予測しておく
ことの困難を示す事例と言えよう．さらに，本論文で提案するシステムで実際に
tweetを分析したところ，被災地で不足しているものとして，「透析用器
具」「向精神薬」「手話通訳」など平時ではなかなか予想が困難な物資が実際に
不足している物品としてtweetされていることも判明している．こうしたいわば
想定外の要望を拾い上げることができなれば，再度要望と支援のミスマッチを招
くこととなる．

以上が示唆することは，次回の大規模災害に備えて，ソーシャルメディア上の
大量の情報を整理し，上述した想定外の要望も含めて，必要な情報を必要な人に把握が容易
なフォーマットで届ける技術の開発を災害発生以前に行っておくことの重要性で
ある．また，我々が備えるべき次の災害が，今回の震災と類似している保証はな
い．以上のような点に鑑みて，我々は想定外の質問も含め，多様な質問に対して，
ソーシャルメディア上に書き込まれた膨大な情報から抽出された回答のリストを提示し，状況の俯瞰的把握を助ける
ことができる質問応答システムが，災害時に有効であると考えている．

ここで言う俯瞰的把握とは，災害時に発生する様々な事象に関して，それらを地
理的，時間的，意味的観点から分類した上でそれらの全体像を把握することを言
う．別の言い方をすれば，その事象がどのような地理的，時間的位置において発
生しているのか，あるいはそもそもその事象がどのような事象であるのか，つま
りどのような意味を持つ事象であるのか，等々の観点でそれら事象を分類し，ま
た，それらを可能な限り網羅的，全体的に眺めわたし，把握するということであ
る．このような俯瞰的把握によって，救援者サイドは，例えば，重大な被害が生
じているにもかかわらず，炊き出し，救援物資の送付等が行われていないように
見える地点を割り出し，なんらかの齟齬の確認や，救援チームの優先的割当を行
うことが可能になる．あるいは各地において不足している物資を，例えば医薬品，
衣類，食料といった観点で整理して，救援物資のロジスティクスを最適化するな
どの処置も可能になる．さらに，こうした俯瞰的把握によって，上で述べたよう
な想定外の事象の発見も可能になり，また，それらへの対処も容易になろう．逆
に言えば，誰かがこうした俯瞰的把握をしていない限り，各種の救援活動は泥縄
にならざるを得ず，また，想定外の事象に対してはシステマティックな対応をす
ることも困難となる．

また，被災者自身も現在自分がいる地点の周辺で何がおきているか，あるいは周
辺にどのようなリソースが存在し，また，存在しないかを全体として把握するこ
とにより，現地点にとどまるべきか，それとも思い切って遠くまで避難するかの
判断が容易になる．
避難に至るほど深刻な状況でなかったとしても，周辺
地域での物資，サービスの提供の様子を全体として把握することで，物資，サー
ビスを求めて短期的な探索を行うか否かの決断も容易になろう．我々の最終的な
目標は，多様な質問に回答できるような質問応答システムを開発することによっ
て，災害時に発生するtweet等のテキストデータが人手での処理が不可能な量と
なっても，そこに現れる多様で大量の事象を意味的観点から分類，抽出可能にし，
さらに回答の地図上への表示や，回答に時間的な制約をかけることのできるイン
ターフェースも合わせて提供することにより，以上のような俯瞰的把握を容易に
することである．

本論文では，以上のような考察に基づき，質問応答を利用して，災害時に個人か
ら発信される大量の情報，特に救援者や被災者が欲している情報をtweetから取
得し，それらの人々の状況の俯瞰的把握を助ける対災害情報分析システムを提案
する．将来的には本システムを一般公開し，被災地の状況や救援状況を俯瞰的に
把握し，被災地からの想定外の要望をも取得し，効率的な救援活動につなげるこ
とを目指す．本論文では提案したシステムを実際に東日本大震災時に発信された
tweetに適用した評価実験の結果を示すが，この評価においては以上のような被
災状況の俯瞰的把握を助ける能力を評価するため，質問応答の再現率に重点をお
いた評価を行う．逆に言えば，いたずらに回答の上位の適合率を追うことはせず，
再現率の比較的高いところでの評価に集中する．また，本システムを拡張するこ
とで，被災者と救援者の間でより適切な双方向のコミュニケーションが実現可能
であることも示す．こうした双方向のコミュニケーションはより適切かつ効率的
な救援活動のために極めて重要であると考えている．

本論文で提案するようなシステムは非常に多くのモジュールからなり，その新規
性を簡潔にまとめることは難しいが，本論文においては以下の手法・技術に関し
て我々のタスクにおける評価，検証を行った．特にCについては，新規な技術で
あると考えている．
\begin{description}
 \item[A] 固有表現認識 (NER) の有効性
 \item[B] 教師有り学習を用いた回答のランキング
 \item[C] 含意関係認識における活性・不活性極性\cite{Hashimoto2012}の有用性
\end{description}

ここで，A，Bに関しては本論文における実験の目標ならびに設定では有効性は
認められず，最終的なシステムではこれらの技術を採用しなかった．これらに関
して現時点での我々の結論は以下の通りである．NERはそれ単体では，我々のタ
スクでは有効ではなく，その後の処理やそこで用いられる辞書等との整合性がと
れて初めて有効になる可能性がある．また，回答のランキングは，我々の目標，
つまり，少数の回答だけではなく，想定外も含めた回答を可能な限り網羅的に高
精度で抽出することには少なくとも現状利用可能な量の学習データ，素性等では
有効ではなかった．
一方で，含意関係認識において活性・不活性極性を利用した場合，再現
率が50％程度のレベルにおいて，適合率が7％程度上昇し，顕著な性能向上が見
られたことから，提案手法にこれを含めている．

本論文の構成は以下の通りである．まず，\ref{Disaster}節において本論文で提
案する対災害情報分析システムの構成とその中で使われている質問応答技術につ
いて述べる．\ref{Experiments}節では，人手で作成した質問応答の正解データを用いたシステム
の評価について報告する．\ref{Prospects}節にて上述した双方向のコミュニケーションの実現
も含めて今後の本研究の展望を示す．さらに\ref{Related_work}節にて関連研究をまとめ，最後に
\ref{Conclusion}節にて本論文の結論を述べる．


\section{質問応答に基づく対災害情報分析システム}
\label{Disaster}


\subsection{システム構成}

本システムは，「宮城県で孤立しているのはどこですか」，「福島県で何が不足
しているか」など，自然言語の質問を入力とし，大規模なtweetコーパスからそ
の回答と思われる表現を抽出し，ユーザに提示する．（なお，現在，システムは
Twitterを主たる情報源としているが，掲示板や一般のWeb文書などにももちろん
適用可能である．）図 \ref{overview_fig}に示すように，システムは tweetか
ら構文パターンを抽出しインデックスを作成する回答インデックス作成モジュールと，
回答検索時に使用する含意パターンデータベースを作成する含意パターン獲得モ
ジュール，作成されたインデックスを用いて回答を抽出する質問応答モジュール，
ユーザから入力された質問に対する大量の回答を効果的に提示する入出力モジュー
ルから成る．

\begin{figure}[b]
\begin{center}
\includegraphics{20-3ia3f1.eps}
\end{center}
\caption{対災害情報分析システムの概要}
\label{overview_fig}
\end{figure}

各モジュールの動作の概要は次の通りである．回答インデックス作成モジュールでは，
まずtweetを文単位で形態素解析，構文解析し，地名補完モジュールにて処理さ
れた構文解析結果から，詳細については後述するパターンや周辺名詞句を抽出し，これを回答インデックスに含める．

含意パターン獲得モジュールは，大規模なWebコーパスを形態素解析，構文解析
したデータから，含意関係にあるパターン（例えば，「XからYまで歩く」は「X
からYまで移動する」を含意する）を自動的に抽出し，含意パターンデータベー
スを作成する．

質問応答モジュールは，ユーザから入力された質問をインデックス作
成モジュールと同様に形態素解析，構文解析を行い，質問文から
パターンや周辺名詞句を取得する．
次に，質問文に含まれるパターンを用いて，含意パターンデータベースを参照し，
最大で数千個程度の含意パターンに拡張する．拡張されたパターンや周辺名詞句
を用いて回答インデックスを検索し，回答を得る．

入出力モジュールは，2種類ある表示モードの選択，質問文の入力フォームなどを
備え，ユーザーから入力があるとそれを質問応答モジュールに渡す．
質問応答モジュールから回答を受けとると，表示モードに応じてユーザに回答を
表示する．

以下では，これらのモジュールの各々について説明する．


\subsection{回答インデックス作成モジュール}
\label{making_index}

回答インデックス作成モジュールは，大規模なtweetのデータを対象に，高速に質問
応答を行うためのインデックスを作成するモジュールである．回答インデックスの作成には，Apache Jakarta Projectのもとで開発が進められているLucene\footnote{http://lucene.apache.org/core/}を利用する．
以下ではこのインデックスを回答インデックスと呼び，その役割と作成手順，作成に際して注意
が必要な地名の補完処理について説明する．


\subsubsection{回答インデックスの作成}

回答インデックスは，ユーザーから入力された質問文から生成したクエリを用いて
高速に回答を取得するためのインデックスである．
回答インデックスには，構文情報が充分に存在する文から抽出される情報を格納
する回答インデックス1と構文情報が充分にない文から抽出される情報も格納の対象とす
る回答インデックス2の2種類がある．

回答インデックスの作成手順として，まず，対象(tweet)を文単位で形態素解析，構文解析処理を行う．
形態素解析にはMeCab\footnote{http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html 
辞書はJUMAN体系のものを使用．}，構文解析には日本語係り受け解析器
J.DepP\footnote{http://www.tkl.iis.u-tokyo.ac.jp/{\textasciitilde}ynaga/jdepp} を使
用する．

次に，回答インデックス1に格納するデータを作成するために
構文解析結果における任意の名詞句2つとそれらをつなぐ文節係り受けの
パスを構成する表層上の連鎖を取得する．
例えば，
「[宮城県の][炊き出し]」からは，「宮城県」と「炊き出し」という名詞句に係り受けのパスが
あるので「宮城県の炊き出し」が取得される．一方，
「[宮城県で][炊き出しが][行われる]」という結果
からは，「宮城県」と「炊き出し」という名詞句の間に「行われる」という
文節で媒介されるパスが存在するので「宮城県で炊き出しが行われる」が取得される．
このパスを構成する2つの名詞句それぞれを変数で
置き換えたものを構文パターン，あるいはパターンと呼び，また構文パターンと
それに含まれる変数に対応する名詞句2つの三つ組みをパターントリプルと呼ぶ．
上記の「宮城県で炊き出しが行われる」という文からは，構文パターンとして
「XでYが行われる」，変数X，Yに対応する2つの名詞句として「宮城県」
と「炊き出し」の三つ組みがこの文から抽出されるパターントリプルとなる．
またパターントリプルを含むtweet内の名詞句を全てを周辺名詞句として取得す
る．最終的に，回答インデックス 1 には，パターンとして「XでYが行われる」，
変数に対応する名詞句としてそれぞれ「宮城県」「炊き出し」がキーに登録さ
れ，その値には変数に対応する名詞句と当該tweetのIDが格納される．


回答インデックス2は，回答インデックス1に比べて，構文情報が不十分な文も
対象とするために用いる．したがってこのインデックスを用いた
回答の信頼性は高くないが，より広範な回答を得るために使用する．
このインデックスでは構文パターンのかわりに部分パターンと呼ばれるパターン
とその周辺名詞句をキーとする．構文パターンは，構文解析結果において
二つの名詞句をつなぐパスから作られたが，部分パターンは名詞句一つと動詞，
名詞，形容詞のいずれかへの係り受け関係から作られる．例えば，「宮城県です．透析用器具が足りません．」といったtweetからは任意の名詞句2つの間に係り受けが存在しないため，構文パターンを抽出することはできな
い．したがって，「透析用器具が足りない」という情報は回答インデックス1には反映されない．
そこで，構文解析結果において「透析用器具」が助詞「が」を介して「足りません」
へ係っているので，係り元の名詞句を変数として部分パターンを抽出す
る．この場合は「X（＝透析用器具）が足りません」が抽出され，それと回答インデック
ス1同様に周辺名詞句である「宮城県」「状況」「透析用器具」とをキーとして，
変数に対応する名詞句，すなわち「透析用器具」とtweetのIDとを値として回答イ
ンデックス2に登録する．

以上2種類の回答インデックスのキーと値を表\ref{answer_index}にまとめる．
回答インデックス1は上述したパターントリプルを用いて作成し
たインデックスであり，回答インデックス2は，パターントリプルが取得できな
いtweetにも対応することで，更に幅広い回答を取得するためのインデックスで
ある．以下に，回答インデックスを用いて，どのように回答を取得するかを説明する．

\begin{table}[b]
\caption{回答インデックス}
\label{answer_index}
\input{03table01.txt}
\end{table}

回答インデックス 1 では，例えば，「震災後，宮城県で透析用器具が不足し
ています」というtweetからは，パターンとして「XでYが不足しています」，
名詞句対（名詞句1，名詞句2）としてそれぞれ「宮城県」「透析用器具」，
周辺名詞句として「震災後」「宮城県」「透析用器具」「不足」がキーに登録さ
れ，その値には変数に対応する名詞句と当該tweetのIDが格納される．
このようなエントリは，例えば「宮城県で何が不足しています
か？」といった質問の回答を取得する際に使われる．この場合，インデックス検
索時のクエリは「XでYが不足しています」というパターンと，「宮城県」という
名詞句1であり，検索の結果，上述したtweetの例から生成されるインデックス
のエントリに値として登録されている名詞句2の「透析用器具」が回答として，
tweetのIDとともに出力される．また，「どこで透析器具が不足していますか？」
という質問であった場合には，「XでYが不足しています」というパターンと「透
析用器具」という名詞句2を持つクエリが生成され，値に登録されている名詞句
1の「宮城県」が回答として，tweetのIDとともに出力される．なお，上では周辺
名詞句がキーとして登録されると説明したが，Luceneのインデッ
クスのメカニズムでは，キーの一部を省略することが可能であり，例えば，上の
質問の例では，パターントリプルを抽出してきたtweetにあった
「震災後」という名詞句はクエリ中のキーとして現れないが，適切に検索が行われる．

一方，回答インデックス2のエントリは，例えば，「宮城県で何が足りませんか？」
という質問に対する回答を得るためにも使うことができる．質問中では，「宮城県」
は「足りません」という動詞にかかっているが，この宮城県を周辺名詞句として
とらえ直し（回答が含まれるtweetとして「宮城県です．〜が足りません」のよう
なものもあると想定する），「何が足りませんか」という質問中の部分から「Xが足りません」と
いう部分パターンを作成すると回答インデックス2を検索できる．本来で
あれば，先のtweetの解析時に照応解析等を行い，「透析器具が足りません」と
いう文には「宮城県で」という表現が省略されていることを認識した上で処理を
進めるべきであるが，そもそも照応解析等の精度が高くない現状に鑑み，照応，
省略表現を一括して周辺名詞句として扱うことで柔軟な回答の抽出を狙っている
ことになる．

なお，いずれのインデックスの作成時においても，retweetが入力として与えら
れた場合には，同一内容のretweetがあるかをチェックし，もし存在すれば
1 つのretweetのみを登録し，これと同一内容の複数あるretweetはインデックス
には登録しない．一方ですべてのretweetのIDのリストは別途保存しておく．こ
れはretweetの処理によって質問応答の処理時間がのびるのを防ぐための処理であ
る．



\subsubsection{地名補完モジュール}
\label{Augment_place}

地名補完モジュールは，回答インデックスの作成の際に，tweetなどのソーシャルメディアへの書き込みで省略されがちな地名や場所名を補完するモジュールである．
地名補完モジュールでは大きく分けて次の二つの処理を行う．(1) まず，構文
解析結果をその入力とし，地名補完の対象となるエンティティを認識する．(2)
認識されたエンティティの詳細な住所情報を取得し，元のエンティティの周辺情報に基づいて後述する場所の
包含性や，場所の非明示性の問題に対処する補完処理を行い構文木に適宜補完要
素を挿入する．

災害に関する情報では，効率的な救援活動などのため，位置情報や地名が極めて
重要である．Twitterでは，携帯端末等GPS情報を付加できる装置からの書き込み
の場合，位置情報の開示設定がされていれば，そのtweetが書き込まれた場所を
特定できる．しかしながら，多くのユーザは，プライバシー等の問題から該当機
能を有効にはしていない．災害時の要望等については，この機能を有効とすべき
であるが，かならずしもすべての情報に位置情報が記述されている訳ではない．
さらに，通信が不可能なほど壊滅的な被害が発生した場所から，通信が可能な地
域に移動し，当該地域についてtweetする場合など，tweetがなされる位置とその
tweetが言及している位置が，一致しない場合もある．そのため，
tweet内の地名を特定し，適切に処理することが重要である．しかしながら，
地名の処理には以下のような問題があり，極めて難しい課題となっている．

\begin{description}
 \item[場所の非明示性：]Twitterなどへの書き込みには，明示的に県や市の名称
	    が書かれていないことが多い．さらには，tweetに限らず，一般的
	    に，イベントが起きた場所を指す名詞句がイベントを表す動詞等に
	    明示的には係らないことも多く，動詞で表されたイベントと地名を
	    結びつけることはそれほど容易ではない．
 \item[場所の包含性：] 場所には包含性がある．例えば，仙台市が宮城県の中に
	    あることを正しく認識しても，それを処理する手だてがなければ，たと
	    え文中に「仙台市」と記述されていても，「宮城県で」と問う質問
	    には回答できないということが起きる．
 \item[場所の曖昧性：]  一部の地名は非常に大きな曖昧性を持ち，上記の包含
	    性を扱おうとする場合に，特に問題となる．例えば，「福島」とい
	    う地名は日本全国に50以上もあり，そこから正しい一つを選ぶ必要
	    がある．
\end{description}

地名補完モジュールにて解決したい問題とほぼ同一の問題に取り組んでいるプロ
ジェクトとしてGeoNLP\footnote{http://agora.ex.nii.ac.jp/GeoNLP/} がある．
また，地名をはじめとする固有表現の認識とい
う点では，近年Twitter等のソーシャルメディアに対する固有表現認識の難しさ
や，問題点が広く知られ，報告も多くなりつつある
\cite{Liu2013,Ritter2011,Cheng2010}．
Liuらはtweetを対象としてK-Nearest NeighborsとConditional Random Fieldsを
組み合わせた新しい固有表現認識器を提案している．
RitterらはLabled LDAにdistant supervisionを適用す
ることで高い性能を持つ固有表現認識器を実現している．
また，Chengらは，tweetのみならずWebコーパスを用いた教師なし学習による
固有表現認識器を提案している．

前述した問題に完全に対応することは
難しいが，現在のシステムは以下の手続きによって，地名とイベントとを対応付
けている．具体的には，まず，現在入手可能なデータから大規模な地名・場所名
辞書を自動生成し，さらに，地名等の包含性，曖昧性の一部をヒューリスティックスに
よって対処しつつ，回答インデックスに地名の情報を取り込んでいる．
以下ではこの各々のステップについて説明する．


\subsubsection{地名・場所名辞書の作成}

地名補完の対象となるエンティティを特定するため，
日本郵便が公開している郵便番号データとWikipediaに基づく上位下位関
係\cite{Yamada2009}を利用して，地名・場所名辞書を作成した．


まず，日本郵便が公開している郵便番号データを用いて地名辞書を作成した．郵便番号
データからは，「都道府県／市区町村／町域」で表される住所の情報
から，用いられる可能性がある地名文字列とその詳細な住所との対
応を取り出す． 
地名文字列は「山元」のよ
うに断片的なものである場合が多いが，こうした対応づけを用いて，
断片的な文字列から「宮城県亘理郡山元町」のようなより詳細な住
所が入手可能となる．さらに，「都道府県／市区町村／町域」という
住所の階層性は，先に挙げた場所の包含性に対処するための情報源
となる．このようにして，2,486,545のエントリを持つ辞書（地名
辞書）を作成した（地名文字列—住所の対の数は5,129,162）．そのうち，
84,633エントリが曖昧性をもつ地名であった． 

また，Twitterなどへの書き込みでは，住所のような地名の他に学校や施設，ランドマー
ク的名称の正式名称から通称までが幅広く用いられる．そこで，Wikipediaから抽出した上位下位関係\cite{Yamada2009}から，
上位語として自治体をとり，「（自治体名）の(*X)」（Xは「施設」
「学校」など）というパターンにマッチする下位語を取り出して利
用した．例えば，「名取市の増田小学校」などである．これは，
「学校」などの，郵便番号データには載っていないような場所にも
その詳細な住所を対応づけるためである．上位語中の自治体名を，
地名辞書で検索して下位語に住所を付与する．最終的に，255,273エ
ントリを持つ場所辞書を作成した． 

地名辞書と場所辞書をマージすることで，2,741,818エントリを持つ辞書が得ら
れる．地名辞書も場所辞書もほぼ全自動で作成しているため，それをそのまま文字
列マッチによる単純な地名検出手法とともに適用した場合には，問題となる場合
がある．
例えば，「枝野官房長官」の名字と同じ「枝野」が宮城県の地名として使われている場合があるなど，
地名には人名と同じものが多くあり周辺の情報から適切に処理
される必要がある．また，高頻出な普通名詞をいずれかの辞書のエントリとして
含んでおり，誤って地名処理される場合もある．そこで，このような問題となる
エントリを可能な限りマージした辞書から人手で取り除いた．その結果，
2,726,944エントリを持つ地名・場所名辞書が得られた．

地名・場所名辞書は，地名補完モジュールの性能を決定する極めて重要な知識で
ある．人工物に対する固有表現ほど新規エントリや，変更があるとは考えていな
いが継続的にメンテナンスされる必要がある．このような知識は，ひとたび整備
されれば，その多くは長期にわたって利用可能であるためコストをかけ整備する
価値があると考える．


\subsubsection{地名・場所名特定}

回答インデックスを作成するために形態素解析，構文解析がされた解析結果の各文節に対し，形
態素をその単位として最長の名詞句を抽出し，地名・場所名辞書を用いて地名・
場所名を特定し，当該名
詞句に詳細な住所候補を付与する．その際，名詞句全体がマッチしない場合でも，
その範囲内で最左のマッチを選び，できるだけ住所を付与する．なお，1 文字の
地名・場所名は誤ったマッチである可能性が大きいため，無視する．

現在のシステムの地名・場所名の特定方法は，形態素を単位とする表層文字列が
地名・場所名辞書に存在するか否かによって行うため，
一般名詞等を誤って地名・場所名として扱う場合がある．
そこで，地名・場所名の特定に関して，通常の固有表現認識器を用いることが考えられる．風間らの報告
    (風間, De~Saeger, 鳥澤, 後藤, Varga 2012)\nocite{Kazama2012b}では，固有表現認識器の有効性が確認されておらず，
我々の実験においてもその有効性を確認できなかったため，現在のシステムでは，
固有表現認識器を用いていない．実験の詳細については，\ref{Experiments}節
にて述べる．

上記の問題以外にも，本システムでは，情報が無ければ最も広範囲な地域を表す住所，直前に曖昧性解
消された住所がある場合には，それと最も整合性のある住所を選ぶルールに基づ
く曖昧性の解消を行っている．候補のうち，県・郡・市 （郡部の場合は町）部
分がtweet中の文字列と一致すれば，より広い地域レベルで文字列と一致してい
るものを優先する．例えば，「福島」の場合には，「福島県：福島市」，「大阪
府：大阪市：福島区」等数多くの曖昧性があるが，最も広範囲な「福島県」が選
択される．


\subsubsection{地名補完処理と回答インデックスへの反映}

本システムでは，
「イベントの場所は文中で直前に出現した地名・場所である」という仮定を置き，
元の文の構文解析結果を操作し，
直前の地名・場所（tweetが複数文の場合は前方の文も考慮する）に場所を表す
助詞「で」を加えたものを，イベントを表す動詞等に係るように付け加えた新た
な構文解析（補完構文解析）結果を生成する．

例えば，
「気仙沼中学校へ避難しています」という
文があった場合，「避難」イベントの場所は，直前の場所である「気仙沼中学校」
と認識され，さらに地名・場所辞書により「気仙沼中学校 →宮城県／気仙沼市」
であると分かっているとすると，
「宮城県で」，「気仙沼市で」などの助詞「で」で終わる複数の文節が元の構文木に挿入
される．こうしてできた補完構文解析結果を利用することで，補完された場
所に関連する質問に対応したインデックスが生成される．これにより，例えば，
元の文には「宮城県」という表現が含まれていないにもかかわらず
「宮城県でどこへ避難していますか」という質問に対し回答（＝気仙沼中学校）
できる．


\subsection{含意パターン獲得モジュール}
\label{extract_entailment}

含意パターン獲得モジュールでは，大規模なコーパスから含意パターンを獲得し，
それをデータベース化する．含意パターンとは，簡単に言うと，あるパターン「X
からYまで移動する」を含意する「XからYまで歩く」のようなパターンのことで
あるが，含意が成立するための名詞句X，Yにある制約等を考慮するといくつか種
類が考えられる．ここでは，クラス依存のパターン，クラス非依存のパターンと
部分パターンという三種類の構文パターンの含意パターン獲得及びそのデータベー
ス化について説明する．


\subsubsection{クラス依存のパターン}

クラス依存パターンとは，パターン中の変数に対応する名詞の意味クラスに制約
を掛けた構文パターンである．構文パターンにクラス制約を掛けることでパター
ンの多義性が解消できる．例えば，「YのためのX」という構文パターンは
「Y\underline{\mbox{:病名}}のためのX\underline{\mbox{:薬品}}」のように，Yが病名，Xが薬
品の意味クラスの単語の場合は，XとYの治療関係とでも呼べる関係を表し，上記
のパターン「X\underline{\mbox{:薬品}}でY\underline{\mbox{:病名}}が治
る」の含意パターンとみなせるであろう．一方，「X\underline{\mbox{:作業}}のための
Y\underline{\mbox{:道具}}」の場合は手段または道具という意味的関係を表現する．こ
のようにして構文パターン
と共起する単語を特定の意味クラスに限定することで，構文パターンの曖昧性が
大きく減らされ，高頻度で曖昧なパターンが活用可能になり，より大量の回答を
獲得できる\cite{De_Saeger2009}．

意味クラスは，Kazamaら\cite{Kazama2008}が提案した単語クラスタリング法によって
自動獲得する．この手法では大規模Webコーパスから得られる名詞と動詞の係り
受け関係の統計データを用いて，名詞の隠れクラスへの事後確率の分布を求める．
ある名詞の所属確率が0.2以上の隠れクラスを，その名詞の意味クラスとする．
現状では名詞100万個を500クラスに分類したクラスタリングデータを用いる．

クラス依存の含意パターンの認識にはKloetzerらが提案したクラス依存パターン
間の教師付きの含意獲得手法\cite{Kloetzer2012}を用いる．詳細については
\cite{Kloetzer2012}を参照されたいが，含意パターンを認識するSVM分類器は主
に次の 3 種類の手がかりを用いる．

\begin{enumerate}
 \item パターンの表層的素性（表層／構造を考慮した素性）．これらの素性は，
       表層上似ているパターンは含意関係にある可能性が高いという前提で，
       パターンに含まれる形態素，内容語，構文木の部分木などのbag of
       words表現を基に計算した様々な類似尺度から成る．
 \item 分布類似度に基づいた素性．ある構文パターンとその含意パターンの候
       補に関しては，6億ページの日本語Web文書からパターンの変数に当ては
       まる名詞句対を検出し，それらの名詞句対の相対的なオーバーラップを
       計算する．例えば，「XでYを提供」と「XでYを配っている」という 2 つ
       のパターンはXとYの変数に頻出する共通の単語対（例えば，「石巻市，
       救援物資」）が多ければ多いほど，これらの構文パターンがお互いの言
       い換え表現となっている可能性が高いと考えられる．似た文脈に出現す
       る語は似た意味をもつというのは，分布仮説\cite{Harris1954}と呼ばれ
       る言語学におけるよく知られた仮説である．これらの素性はクラス依存
       のパターンの意味クラスに属する単語対に基づいて計算した類似尺度か
       ら成る．
 \item 言語資源に基づいた素性．これらの素性は高度言語融合フォーラム
       ALAGIN で公開された動詞含意関係データベース（ALAGINリソースA-2），
       日本語異表記対データベース（ALAGINリソースA-7），基本的意味関係の事
       例ベース（ALAGINリソースA-9）と日本語形態素解析器JUMAN の辞書から
       得られた異表記と反対語データを言語資源として参照し，両パターンに
       含まれる内容語が同義語あるいは異表記である場合，または含意関係や
       対義関係にある場合など，これらの言語資源に含まれる意味的関係にあ
       る時にその情報を素性に加える．更に，Hashimotoらが提案した「活性・
       不活性テンプレート」\cite{Hashimoto2012}も素性として用いる．この
       活性・不活性テンプレートについては後述する．
\end{enumerate}

学習データは51,900サンプルであり，SVMでの学習には2次の多項式カーネルを用
いた．図\ref{entailment_recog}は，学習データとは異なる5,338の評価セット
を用いて評価した本分類器から得られるクラス依存パターン含意の認識精度であ
る．

\begin{figure}[b]
\begin{center}
\includegraphics{20-3ia3f2.eps}
\end{center}
\caption{構文パターン間の含意認識の適合率}
\label{entailment_recog}
\end{figure}

図\ref{entailment_recog}から分かるように，上述した条件ではこの手法の上位
1億対（データサンプル数49）では約85％の適合率を示し，上位2.37億にて約70％
の適合率を保持している．
本論文のシステムで利用される含意パターンデータベー
スは，後述する方法により質問文から得られる可能性のある構文パターンの含意
パターンをSVMスコアが高いものにしぼって格納しているので，回答検索に用い
る含意パターンの適合率は図\ref{entailment_recog}に示される上位の適合率に相当するものと考えられる．

本システムで利用する含意パターンデータベースを構築するため，まず，
\cite{Kloetzer2012}と同様に，500意味クラスの任意のペアのうちで，同じ名詞句対を異なり数で3つ以上共有するパターン対すべてを考える．
こうしたパター
ン対の総数は108億個存在するが，そのすべてに対して，分類器を適用してSVMスコアを求める．
ついで，SVMスコアが計算されたパターン対の内，以下の手続きで最終的な含
意パターンデータベースを構築する．まず，上述のパターン対に含まれるパター
ンを「含意されるパターン」Pとして一つ選択し，SVMスコアが 0 以上のパターン
を「含意するパターン」Qとしてスコア上位から順に取得する．「含意するパター
ン」Qが500個を超えた場合は，スコア上位500個のみを「含意されるパターン」P
と対にしてデータベースに格納する．この操作を108億個のパターン対に含まれ
るパターン各々を「含意されるパターン」Pと仮定して繰り返す．
なお，上位500個という数値は決定的なものではなく，システムのパラメータの
ひとつであるが，求める性能と応答速度のトレードオフによって決まる．現在の
500という数値は，さまざまな質問をシステムに投入し，経験的に決めたもので
ある．


\subsubsection{クラス非依存パターン}

クラス依存のパターンでは，特定の意味クラスの組み合わせにふさわしい含意表
現を発見しやすい．一方，なるべく広い文脈で含意表現として通用する
パターンも回答抽出に利用したい．そのために，入力パターンとそのクラス依存の言い
換えパターンの集合をクラス非依存の含意パターン，つまり名詞句に何らの意味
的制約が加えられていないパターンで補完する．多くの意味クラス対で含意パター
ンとして通用するものは恐らく非常にロバストで一般的な言い換え表現であると
いう前提を基に，クラス依存パターン間の各意味クラス対でのSVMスコアを平均
したパターン対のデータベースを用意する．あるパターンのクラス非依存の含意
パターンは上記のクラス依存のケースと同様のアルゴリズムで選別する．例外処
理として 1 つの意味クラス対としか共起しないパターンを除外する．


さらに，
「QがPを含意する」という関係におけるパターンQとパターンPにおいて，通常の
「QがPを含意する」場合のスコアと，逆向きの「PがQを含意する」場合のスコア
が両方向ともに0以上のパターン対のみに限定する．これは確かに片方向の論理
的含意関係が成立しているものの，あまりに意味的にかけ離れているパターン対
で回答を認識するのを防ぐためである．こうして集められた「含意するパターン」Qは，スコア上位500までの「含意されるパターン」Pと共にデータベースに格納される．
得られたQが500個未満の場合には，その時点までに登録されたすべてのQと同じ内容語（動詞，名詞または形容詞）を持つPをスコアの高いものから順に取得し，データベースに登録する．
 

\subsubsection{部分パターン}

ソーシャルメディアから得られるテキストはインフォーマルな
書き方で知られている．特に
Twitterの場合では，tweetが140文字以内という制限があるので，必要最低限の
情報しか含まないtweetが多い．そのため，二つの名詞句の存在を前提とするク
ラス依存パターンやクラス非依存パターンがうまく適用できない場合が非常に多
い．この問題に対処するために上記のクラス非依存のパターンを一つの名詞句の
存在を前提とする部分パターンに分割する．例えば，「XがYで孤立する」という
構文パターンはそれを構成する係り受け関係「Xが孤立する」と「Yで 孤立する」
に分割される．

部分パターンの含意パターンデータベースを次のように用意する．
既に説明したクラス非依存パターンの含意データベースを入力とし，それらのパ
ターン対を分割し，変数毎に部分含意パターンの候補ペアを生成する．例えば，
（「XがYで孤立する」，「YではXに連絡できない」）というクラス非依存パター
ン対から（「Xが孤立する」，「Xに連絡できない」）と（「Yで孤立する」，
「Yでは連絡できない」）という2つの部分パターン対を含意候補として生成
する．この部分パターン対の含意スコアはクラス非依存の含意パターンと同様
に，その生成元の
 クラス非依存の
全含意パターン対のスコアの平均とする．ただし，生成元の
含意パターン対が 1 つしかない部分含意パターンは一般性に欠けていると考え，
除外する．さらに，クラス非依存パターンと同様に，「QがPを含意する」と「PがQを含
意する」の両方向のスコアが0以上のパターン対のみをデータベースに登録する．


\subsubsection{部分パターン対のクリーニング}

以上の方法で作成した部分パターン対は，それがもたらされたクラス非依存パター
ン対のスコアを平均した値をスコアとして持っているが，パターンに含まれる用
言相当表現と変数との関係を全く考慮していないため，信頼性を欠く場合がある．
そこで，次の2つの方法で，部分パターン対をクリーニングする．
\begin{itemize}
 \item 活性・不活性極性\cite{Hashimoto2012}を用いて部分パターン対を構成する2つ
のパターンの極性が異なる部分パターン対は削除する．
 \item 部分パターン対 (P-Q) においてパターンを構成する動詞がPとQにおいて同
一であるが，変数とその動詞を媒介する助詞が異なる部分パターン対は削除する．
例えば，「Xが不足する」と「Xに不足する」などの部分パターン対である．
ただし，助詞「は」と「が」の組み合わせは許容し，削除しない．
\end{itemize}

ここで，活性・不活性極性とは，Hashimotoらが提案した新しい意味極性であり，
助詞と動詞の組，すなわち本論文で言うところの部分パターンに対して活性，不
活性，中立の 3 つの極性が付与されている．活性極性が付与された部分パターン
はそれを埋める名詞の主たる機能，効果，目的，役割，影響が準備あるいは活性
化することを意味し，その典型例としては「Xを引き起こす」「Xを使う」「Xを
買う」が挙げられる．不活性の部分パターンは逆にそれを埋める名詞の主たる機
能，効果，目的，役割，影響が抑制あるいは不活性化されることを意味し，典型
例は「Xを防ぐ」「Xが不足する」「Xを破壊する」などが挙げられる．中立の部
分パターンは活性，不活性のいずれも付与できない意味的性質を持つものである．

本研究で含意関係を持つものとして生成された部分パターン対には「Xが不足する」
「Xが足りる」のように意味的には真逆であり，含意が成立していないものが多
数含まれた．これは含意パターン認識で使われている分布類似度がこうした意味
的差をとらえられないためであると考えられる．一方で，活性・不活性極性に従
えば，「Xが不足する」は不活性，「Xが足りる」は活性であり，それらの差を見
ることによって，意味的差異をとらえることができる．我々は，活性部分パ
ターンを11,276個，不活性部分パターンを2,764個，中立部分パターン7,523個を
人手でアノテーションしており，このデータを用いて，部分パターン対で極
性が異なるものを削除した．

以上のクリーニングによって，当初9,192,475個の部分パターン対か
ら1,819,651個のパターン対が削除され，最終的に8,033,759個の部分パターン対
がデータベースに格納された．なお，このうち，活性・不活性極性によるフィル
タリングの結果除かれた部分パターン対は1,158,716個であった．


\subsection{質問応答モジュール}

質問応答モジュールは，ユーザが入力した質問文から回答集合を出力するまでの
一連のモジュールで構成される．具体的には，質問文から構文パターンを抽出す
る質問文解析モジュールと，インデックスから回答を検索する回答検索モ
ジュールから構成される．以下に各々の説明を述べる．


\subsubsection{質問文解析モジュール}

質問文解析モジュールでは，自然言語で入力された質問文の格助詞の変更や疑問代名詞の位置の入れ替えなどをルールベースで行う．これは，複数の質問構文パターンを用いてより多くの含意パターンを獲得し，幅広い回答を取得するための処理である．次に，ルールベースで言い換えられた質問文の構文解析結果から疑問代名詞以外の名詞句一つと疑問代名詞を特定し，その間の係り受け関係パス上にある表現から構文パターンを取得する．例えば，「宮城県で何が不足していますか」という質問が入力された場合，「X（＝宮城県）でY（＝何）が不足している」という基本的な構文パターンに加え，「YがXで不足している」（格要素の入れ替え），「YはXで不足している」「YがXでは不足している」「XでYは不足している」「XではYが不足している」（助詞の変換），「Xで不足しているY」（ガ格疑問代名詞の被連体修飾化）などの構文パターンが得られる．このようにして得られた構文パターンを用いて，後述する回答検索モジュールで回答インデックスを検索するクエリが生成される．例えば，「X（＝宮城県）でY（＝何）が不足している」からは，パターンに「XでYが不足している」，Xに対応する名詞句 1 に「宮城県」を指定したクエリと，部分パターンとして「Yが不足している」，周辺名詞に「宮城県」を指定したクエリが得られる．

疑問代名詞以外に 2 つ以上の名詞句が含まれる場合は，疑問代名詞と名詞句一つとそれをつなぐ文節で表される複数のパターンを抽出する．例えば，「宮城県ではどこで携帯が充電できますか」が入力された場合，「X（＝宮城県）ではY（＝どこ）で充電できる」，「Y（＝どこ）でX（＝携帯）が充電できる」の構文パターンが取得される．この結果から，パターンに「XではYで充電できる」，Xに対応する名詞句 1 に「宮城県」，周辺名詞句に「携帯」が指定されたクエリと，パターンに「YでXが充電できる」，名詞句 1 に「携帯」，周辺名詞句に「宮城県」が指定されたクエリが生成される．同時に，部分パターンとして「Yで充電できる」，周辺名詞句に「宮城県」「携帯」が指定されたクエリも生成される．なお，クエリで指定される周辺名詞句は，質問文に含まれる全名詞句から，パターンや名詞句１に含まれる名詞句を除外し作成される．

質問文解析モジュールでは，質問構文パターンの獲得のほか，疑問代名詞に助詞「は」とともに直接係る名詞がある場合，その名詞を主題語として取得する．例えば，「被災地で不足している食べ物は何ですか」という質問が入力された場合，名詞「食べ物」を主題語として取得する．この主題語は，得られた回答との分布類似度\cite{Kazama2008}により，回答候補を選別するための情報として利用される．例えば，「食べ物」に対して分布類似度が高い上位の名詞には，「お菓子」,「酒」, 「魚」,「肉」, 「ワイン」, 「チョコレート」などの食べ物が含まれている．逆に食べ物と関連性の薄い「タオル」や「電化製品」の分布類似度は非常に低い．このように，主題語と回答候補との分布類似度は，質問の回答として相応しくない回答候補を除外する特徴として利用できる．


\subsubsection{回答検索モジュール}

最終的な回答の取得に際しては，質問文解析モジュールによって得られた複数の
質問構文パターンから，\ref{extract_entailment}節で説明した含意パターンデー
タベースを引くことで質問構文パターンを含意する含意パターン集合が取得され
る．ついで，質問構文パターンと質問文中で共起する疑問代名詞以外の名詞句と
含意パターン，質問文中の周辺名詞句などをキーとして回答インデックスが引か
れ，回答と回答が抽出されたtweetのIDが得られる．

より具体的に
述べると，一つの質問から得られる複数個の質問構文パターンの各々につき，最
大で1,500個の質問構文パターンの含意パターンが生成される．その内訳はそれぞ
れデータベースに格納されているクラス依存パターンが最大で500個，クラス非
依存パターンが最大で500個，部分パターンが最大で500個となる．これらのパター
ンは質問文中に出現する名詞句と組み合わせて回答インデックスの検索に使
われる．また，各々の回答インデックスは本論文の実験では数千万件レベルの大
量のtweetをカバーしているため，如何にこの回答インデックスを引く操作を高
速化するかが重要になる．現在のシステムでは，Bloom
Filter\cite{Bloom1970}を利用して，回答インデックスに共起がないパターンと
名詞句の組み合わせから成るパターントリプルをメモリー上の操作のみで近似的
に検出し，ディスクアクセスを伴う回答インデックスの検索回数を劇的に減らし
ており，これにより実用的な速度を得ている．

これまでにも述べたとおり，二つの名詞句をつなぐ構文パターンと周辺名詞句をキーとする回答インデックス1は，質問文から
パターントリプルが取得できた際に検索される．
部分パターンをキーとする回答インデックス2は，二つの名詞句をつなぐ構文パターンが質問文から抽出されたときも含め，
部分パターンが得られる場合すべてにおいて使用される．さらに，回答インデックス 2 に
対して，パターンやその内容語を周辺名詞句として検索することで，パターンに直
接係り受けがない回答も取得できる．
また，部分パターンに含まれる内容語のみをとりだし，それを周辺名詞句として検
索することも行う．これは例えば「何が不足しているか？」という質問に対して，
「不足」のみを周辺名詞句として検索することに相当する．


なお，抽出された回答にはストップワードフィルター，場所名フィルター，非場
所名フィルターが適用される．ストップワードフィルターは，あらかじめ用意し
たストップワードリストに回答が含まれる場合にそれを回答リストから削除する
ものである．ここで使用しているストップワードリストは含意パターンデータベー
ス構築の際に用いた6億ページのWeb文書から形態素
態素解析器を使って自動的に認識された名詞句（複合語および単語）のうちで，
明らかに解析ミスであり語として認められないものや非常に漠然としており明確
な概念を指しているとは言えないもの（例：「皆さん」「双子以上」「その他」），
さらには主として機能語的に利用される語（例：「理由」「モノ」）を人手で
集めたものである．これは現在164,064個の名詞句を含んでいる．

場所名フィルターは，疑問代名詞「どこ」を含む質問に関して，前述した地名・
場所名辞書にある語を含む回答，前述した単語クラスタリングの結果から場所名
をさす語を多く含む48クラスに含まれる語を含む回答，あらかじめ用意した
`.*ホテル'，`.*センター' などの場所名のためのパターン113個に合致する回
答のいずれでもないものを回答リストから削除する．一方で疑問代名詞「何」を
含む質問に関しては，非場所名フィルターを適用する．これは場所名フィルター
を逆に用いて地名フィルターでは削除される回答のみを最終的な回答リスト
に含めるフィルターである．

なお，回答が一文字の場合には，そもそも誤答である可能性が高く，また，後述
する再現率の計算において問題になるため，そもそも回答リストに含めないこと
とした．


\subsection{入出力モジュール}
\label{input_output}

入出力モジュールは，ユーザーから入力される質問を質問文解析モジュールに送
信し，回答検索モジュールから出力される質問に対する複数の回答を提示する．
本モジュールはWeb ブラウザーを用いたインターフェースを備えており，一連の
操作はWeb ブラウザー上で操作できる．また，回答検索モジュールか
ら出力される大量の回答の俯瞰的な把握を可能にするために，次に述べる 2 種
類のモードで結果を表示する．ひとつは，回答結果を単語の意味クラス毎にまと
めて表示するモードであり，もう一方は，場所を尋ねる質問に適した結果の表示
方法として，地図上に回答を表示するモードである．
以下で，それぞれについて説明する．


\subsubsection{意味クラスを利用した回答表示モード（意味マップモード）}

\begin{figure}[b]
\begin{center}
\includegraphics{20-3ia3f3.eps}
\end{center}
 \caption{意味マップモードでの実行例} 
\label{sem_map}
\end{figure}

意味クラスを利用した回答表示モードでの実行例を図\ref{sem_map}に示す．こ
の回答表示モードでは，回答が意味クラスごとにまとめられ，異なる色で表示さ
れる．色には意味はなく，異なる意味クラスクラスタであることを示すのみであ
る．意味クラスは\cite{Kazama2008}で計算されたものを用いるが，意味クラスの計算対
象外であるような長い名詞句に対しては，部分マッチを適用するなどして対応す
る．この表示方法によって，回答を俯瞰的に把握することが可能となる．
回答の文字列を
クリックすると，回答を抽出してきた情報源 (tweet)へのリン
ク，もしくは回答を抽出してきたtweetそのもの表示するウィンドウがポップアップし，回答が抽出
されたtweetの内容を確認できる．

また，画面下部にあるスライダーによって，情報抽出源のテキストの発信時刻に
よる回答の限定が可能である．回答が抽出されたテキストの発信時刻は，一般の
Web ページを対象とする場合は特定が困難であるが，Twitter や SNS (Social
Networking Service) であ
れば，その情報を発信した時刻を容易に特定できる．スライダーによって時間帯
を指定すると，その時間帯に発信されたテキストから抽出された回答のみが
表示される．特定の期間に発信されたテキストからの回答が欲しい場合や，
古くなった情報を非表示にしたい場合などには，この機能を用いて必要とする
期間に回答をフィルタリングできる．


\subsubsection{地図上へ回答を表示するモード （googleマップモード）}

回答を地図上へ表示するモードでの実行例を図\ref{google_map}に示す．この表
示方法では，質問の回答となる場所の位置が地図上で表示される．例えば，「宮
城県のどこで炊き出しをしていますか」という質問に対して，炊き出しが行われ
ている地点が容易に把握できるようになる．この表示モードにおいて，質問応答
サーバーから受け取る情報は，意味マップモードの場合と同一である．このモー
ドでは，地図上に回答を表示するために，次のことを行う．
\begin{enumerate}
\item 質問が場所を尋ねる質問（〜はどこですか，どこで〜できますかなど）の
      場合，回答は地名・場所名であることから，回答に対応する詳細な記述を
      後述する地名・場所名辞書から得る．
\item (1)で得られた記述を使って，geocoding\footnote{https://developers.google.com/maps/documentation/geocoding/}を用いて住所やランドマーク名か
      ら緯度経度の獲得を行いgoogleマップに表示する．
\item 場所を尋ねる質問以外の場合，回答の情報抽出源一つ一つに対し，
      \ref{Augment_place}節で述べた地名補完処理で取得した地名の詳細な記
      述を得る．
\item (3)で得られた記述を使ってgeocodingを行い，地図上に表示する．
\end{enumerate}

\begin{figure}[t]
\begin{center}
\includegraphics{20-3ia3f4.eps}
\end{center}
\caption{googleマップモードでの実行例}
\label{google_map}
\end{figure}

地図上に配置されたマーカーをクリックすると，対応する回答と，その回答が抽
出されたtweetへのリンクが表示される．意味マップモード同様に，googleマッ
プモードもスライダーによって情報抽出源の発信時刻による回答の限定が可能で
ある．


\section{システムの評価実験}
\label{Experiments}

本節では，ここまでで述べた方法を実装したシステムを評価する実験について述
べる．システムが実際に運用される場面を想定したシステムの性能を評価するこ
とが望ましいが，本論文で提案するシステムは非常に多くのモジュールから構成
され，その複雑性や，開発途上にあることを考慮して，システムの基本機能，す
なわち質問応答に関して評価を行った．したがって，本論文での実験では入出力
モジュールは，直接的にもシステムに組み込まれた形でも評価されていない．

システムを評価するために用いたのは，2011年3月9日から同年4月4日までの
tweetデータ（約2億2千万tweet，（株）ホットリンク提供）である．
ただし，実験では，災害に関連する345個のキーワードに
よりフィルターした約5,400万のtweetを用いた．この全tweetから，システ
ムが回答を取得するためのインデックスとして，約1億2千万エントリを持つ回答
インデックス1と，約7億6千万エントリの回答インデックス2（部分パターン用）
が生成された．

また，提案システムの評価に加え，次の項目について実験を行った．(1) 含意
関係認識における活性・不活性極性の有用性を確認する実験．(2) 固有表現認
識器 (NER) の有効性を確認する実験．(3) 教師有り学習を用いた回答のランキ
ングの有効性を確認する実験． このそれぞれについても本節で報告する．


\subsection{実験の条件}

災害時における膨大な情報を整理・分析し，全体的な把握を可能とする本シス
テムでは，入力された質問に対して対象データにおいて目立った回答だけでは
なく，想定外も含めたロングテール部分に存在する被災者の要望や事実を回答
として網羅的に取得する必要がある．そのため，その再現率が重要な評価指標
である．

本システムの性能を評価するためにこれまで我々が大規模に作成して
きた評価セットを用いる\cite{Kawada2013}．この評価セットは，6名
で予め作成した質問300問の各々について，質問に関連するキーワードでシステ
ムが対象とするtweetを全文検索した結果をランダムに1,000件を取得し，その結
果から人手で回答を抽出することができた192問とその正しい回答（以下，正答
と呼び，その数は17,524個である）のセットである．
評価セットの正答には質問とは表層的に大きく異なる表現で記載された表現から
抽出されたものも多数含まれる．我々が用意した質問は回答が一意に求まるもの
ではなく，ひとつの質問に対して複数の正解が存在する．
また，この評価セットは単に質問と正答，つまり名詞句のペアを
データベース化しただけではなく，正答
が抽出されたtweetも含んでいる．実験では，この評価セットを用い
た．再現率は，評価セットに含まれる正答のうちいくつシステムが回答できた
かで評価する．当然ながら，評価セットに含まれていないが，
正解と判定される回答をシステムが出力することが考えられるが，
それを考慮して再現率を計算すると，新たな正解が見つかる度に
再現率がかわるため，評価セットに含まれる正答のみ考慮して再現率を求めた．一方，
適合率は，システムの回答をランダムサンプルし，正解かどうかを人間が判定し
て求めた．表\ref{Q_example}に実験に利用した質問の一部を示す．
 
\begin{table}[t]
\caption{実験に利用した質問例}
\label{Q_example}
\input{03table02.txt}
\end{table}


\subsection{システムの質問応答性能}
\label{Eval_QA}

評価では，再現率を計算する際に，システムの回答が正答を部分文
字列として含んでいるか，システムの回答が正答に部分文字列とし
て含まれているいずれかの場合を正解とした．その結果，再現率0.519 (9,099/17,524) 
が得られた．この部分文字列による照合では，正答かシステムの回答が一文字である場合に，多数の回答にマッチし，評価の精度が問
題になる可能性があるが，前述したように提案システムは一文字からなる単語を
回答として出力しない．また，評価セットの正答で一文字のもの
は全部で106個あったが，システムの出力でそれらにマッチしたものは67個であっ
た．これはシステムの回答の4\%程度に相当する．しかし，これらすべてを回答
から除外した場合の再現率は，0.519 ($=(9,099-67)/(17,524-106)$)と変わら
ず，この影響は小さいと考える．
また，192の質問ごとに再現率を求め，その平均をとると0.428 であった．
これは，もともとの正答数が小さい質問において，再現率が0となっ
てしまう場合が多い（192問中41問，そのうち回答数が0のものは32問）ためであ
り，このことから，逆に質問の正解が得られた場合の再現率は，この数値よりも
大きい場合が多いことを期待できる．
 
適合率に関しては，全回答から質問と回答のペア250個をランダムサンプルし3名の
評価者で正解かどうかを調べ，その多数決により正解を決めた．評価者間の一致
度合はKappa値\cite{Fleiss1971}が0.507であった．回答の評価に際しては，回答が抽出
された元のtweetが非常に大量の場合があるが，ランダムに選択した最大 3 個の
tweetから正解かどうかを判断した．評価の結果，250問の適合率は，
0.608 (152/250) となった．

例えば，構文パターンを利用した質問では，「どこで風評被害が起きていますか」
という質問の回答では，「YでX（＝風評被害）が出ている」
「X（＝風評被害）がYで発生している」「Yで起きているX（＝風評被害）」「X（＝
風評被害）がYで起こる」「X（＝風評被害）がYで起きている」などのパターンに
より回答を取得している．

また，部分パターンを利用した質問では，「なにが汚染していますか」という質問で「Yが
汚染されてしまう」「Yが汚染される」「Yの汚染」などのほか，「Yから検出さ
れる」「Yからは検出される」などの部分パターンが含意パターンデータベースから取得され利用された．これにより「4 号機，
正門，ヘリ」などのtweetに「汚染」を含んでいない回答も得ることができてい
る．

再現率を下げている要因の一つとしては，回答がまったく取得できない質問が32
問あることがある．これらの多くは，質問文を構成する名詞句がtweetにおいて
非常に低頻度であり，手掛かりとして役に立たない場合である．例えば，
「専門職ボランティア」，「被災者相談窓口」，「被ばく相談」，「被災者就労
支援」などの複合名詞や，「津波肺」「クラッシュ症候群」「誤嚥性肺炎」など
の固有名である．これらは，該当する複合名詞や固有名が回答インデックスに存
在しないか登録されていても非常に少数であった．対応策としては，「被災者相
談窓口」を「被災者の相談窓口」とするなどの複合語の分割が有効であり，さら
にサ変名詞を語尾にもつ「被ばく相談」「就学支援」のように複合名詞が「行う」
「できる」「実施する」などに係る場合は，「被ばくを相談する」，「就学を支
援する」などのより汎用的な表現に変換することが必要である．今後，複合語の
構造解析手法などを取り入れ，より幅広い質問にも対応できるようにする予定で
ある．

また，適合率を評価した回答250についてより詳細に分析した．これらの
回答がどういった処理によって抽出されるかを見るとまず，クラス依存，クラス
非依存をふくめて「XがYで不足している」のように二つの変数を含むパターンに
よって得られた回答は全体の 6\%（15個）であり，その適合率は0.933であっ
た．また，「Yが不足している」のような部分パターンで抽出された回答は72％
（180個）を占め，適合率は0.656であった．さらに部分パターンの内容語を抽出
して得られた回答は22％（55個）であり適合率は0.364であった．期待されるよ
うに制約の強いパターンで取得されている回答は適合率が高いものの，変数を二
つ含む複雑なパターンの適用例はきわめて少なかった．これは「どこが渋滞して
いますか？」のようなそもそも二つの変数を含むパターンが抽出できない比較的
簡単な質問が我々の評価セットに多かったことも理由である．今後「宮城県のどこで
渋滞していますか？」のようなより複雑な質問を評価セットに加えると，この
制約が強いパターンが適用される割合も増加するものと考える．

誤った回答が抽出された要因を見ていくと，もちろん，パターン間の含意の認識
誤りも含まれてはいるが，むしろ目立つのは「水は不足していますか？」「水
が不足したりして」「水は不足していません」などのように単純な肯定文以外の
文から「Xが（は）不足する」のようなパターンが抽出されている場合であ
る．これらの文をムード等の分析ルーチンを導入することによって除くことで
最大で10％以上の適合率改善ができると予想している．一方で，「水は不
足していますか？」のような質問や要望，「水が不足していたとしたら」のような仮定も，災害時において非常に有用な
情報であり，個別に認識することは重要な課題だと考えている． 

また，地名補完処理の誤りによって，パターンやその内容語から離れた位置に出
現する場所名が誤って回答として抽出されるケースがあった．これらは今後，
省略，照応解析を導入することで改善していく予定である．


\subsection{部分パターン対のクリーニングの効果}

\ref{extract_entailment}節で述べた部分パターン間の含意関係のクリーニング
が質問応答全体に及ぼす影響について評価を行った．部分パターン間の含意関係
とは，例えば「Xが崩落する」「Xが崩壊する」の間に成立する含意関係である．
\ref{extract_entailment}節で述べたように，このクリーニングにおいては，
活性・不活性極性を用いたクリーニング（活性・不活性クリーニング），な
らびに同一の動詞を含む部分パターン間で助詞のみが異なるものを削除する
クリーニング（助詞クリーニング）の二種類を行った．

まず，提案システムの再現率は0.519，適合率は0.608であったが，部分パターン
間の含意関係に対して助詞クリーニングのみ適用し，活性・不活性クリーニングを適用しなかった場合
の回答を，提案システムと同様に回答250サンプル（評価者 3 名によ
る評価）を抽出し，評価したところ，表\ref{cleaning_effect}に示すとおり，再現率0.524，
適合率が0.536となった．つまり，再現率は0.005とわずかに向上したが，適合率
が0.072と大きく低下したことになる．さらに，活性・不活性クリーニング，助詞クリーニングの両方を適用しなかったときの性能は，再現率が0.533，
適合率が0.448となり，やはり再現率がわずかに向上したものの適合率の大幅な低下が見
られた．最終的にいっさいクリーニングを行わなかった場合と提案手法を比べ
ると，再現率が0.014程度向上するのに対して，適合率は0.160と大幅に低下してい
る．
まとめると，部分パターン対のクリーニングは最終的な回答の質に
おいて非常に重要であるということが分かった．特に，一見含意関係とは関係の
薄い，活性・不活性という意味極性がそのクリーニングにおいて重要な役割を
果たすことが確認できた．

\begin{table}[b]
\caption{部分パターン対のクリーニングの効果}
\label{cleaning_effect}
\input{03table03.txt}
\end{table}


\subsection{固有表現認識器の効果}

本研究での提案システムは地名補完モジュールにNERを使
用しなかったが，それは以下の実験結果により，NERの有用性が本システムにお
いて認められなかったからである．

まず，IREX固有表現コーパス \cite{Sekine2000}において
LOCATIONタグのみを残し，これをNER学習データ1とした．次に，Twitter APIを
使用して，実験で用いるtweetとは異なる期間のtweet 22万5千件を取得し，これ
に対し，災害関連のキーワード345個のいずれかを含む11万tweetに対して学習デー
タ1から作成した既存のNERを適用し，LOCATIONタグを付与した．この結果のう
ち4万文を人手で修正し，これをNER学習データ2とした．これらのNER学習データ
1ならびに2をあわせてNER構成用学習データとし，
CRF++\footnote{http://crfpp.googlecode.com/svn/trunk/doc/index.html}を用
いて形態素単位のNERを構成した．
素性テンプレートはCRF++パッケージのサンプルとして含
まれているものをそのまま利用した．

このNERを評価するために，我々が対象としている5,400万のtweetから1,000 tweet
（3,017文）をランダムサンプルし，構成したNERを適用した．その結果を人手で
修正し，評価用テストセットを作成した．この評価用テストセットの形態素数は
約33,000であり，LOCATIONとされる名詞句は，521（866形態素）存在する．これ
を用いて構成したNERを評価したところ適合率は0.930，再現率は0.839であった．

次に我々の質問応答システムで，地名補完モジュールにおける処理対象の特定に
NERを組み入れた場合と，形態素単位の文字列によって直接辞書引きすることで
特定する場合との違いがシステム全体の質問応答性能に与える
影響を調べた．実験に使用したのは，部分パターン対のクリーニングを行う前のシ
ステムであるが，NERの効果を調べるには問題がないと考える．表
\ref{NER_effect}に示すとおり，実験結果は，NERを用いない場合が再現率0.533，
適合率0.448であり，NERを用いた場合には再現率 0.516，適合率0.392と再現率，
適合率ともに低下した．この結果から，あるエンティ
ティが地名・場所名辞書に存在しているにもかかわらず，NERがそれを特定でき
なかった場合や，逆にNERが地名補完モジュールでの処理対象を特定できても地
名・場所名辞書に登録されていない場合などがあり，地名・場所名辞書を直
接辞書引きしたほうが，より高い性能を発揮できたと考える．

\begin{table}[b]
\caption{固有表現認識器 (NER) の効果}
\label{NER_effect}
\input{03table04.txt}
\end{table}

より具体的に，NERで特定されたものがどれだけ地名・場所名辞書を用いて地名
補完処理されたかを見てみると次のようになった．NERはテストセットに521ある
エンティティのうち，437（再現率0.839）相当を正しく特定できているが，この
うち，地名補完処理の対象となったのは，わずか157個である．この数字が小さ
い理由は，現在の地名補完処理はシステムの持つ地名・場所名辞書にあるエント
リしか処理対象としないからであり，さらにはNERの認識結果と地名・場所名辞
書との食い違いが大きいからである．一方，地名補完モジュールにて行っている
処理では，214個の地名・場所名を特定し，地名補完処理がなされた．もちろん，
この地名補完処理がなされた地名・場所名には誤ったものも多数含まれていよ
う．もともとNERを導入した動機は，NERによって一般名詞や人名等を地名として誤認識することを防げるかもしれないということであった．つま
り，地名補完処理対象認識の適合率の向上をねらったということである．おそら
く，地名・場所名の誤認識がNERによって防がれたケースもあったものと推測されるが，そもそも
地名補完処理が起動されないことのデメリットの方が大きく，最終的な質問回答
の性能が低下したものと考える．

もちろん，今後NERの認識結果を地名・場所名辞書に追加していくことによって，
性能向上を見ることは可能かもしれない．しかしながら，そこで障害となるのは
エンティティの基準と，地名補完処理において処理対象とするエンティティ，す
なわち地名・場所名辞書のエントリの認定基準とが異なっていることである．例
えば，NERの認識結果には外国の地名などあきらかに本タスクでは不要と思われ
るものも多数存在するし，複合名詞中，例えば「富士スピードウェイ」の「富士」
が地名として認識されるといった問題も存在する．また，地名・場所名辞書では
地名間の包含関係が情報として含まれているが，NERの認識結果にはそうしたも
のは含まれない．これらの問題をどう解決していくかが，今後の課題の一つとな
る．

    まとめると，風間ら(風間 他 2012)の報告と同様に提案システ
ムにおけるNERの効果は確認出来なかった．これをうけて，我々の提案システム
ではNERを使用していない．この理由は，現状の地名補完処理では，固
有表現特定後に地名・場所名辞書にて詳細な地名情報を取得する必要があり，こ
の辞書の網羅性等が性能に影響するためである．さらには，
地元でだけ用いられる通称など考慮しなければならない点もあり，これらの
問題点をいかに低コストで解決していくかも重要な点であると考えている．
今後，自治体などの協力を得て，そうした通称や未登録の避難所をリストアップ
していくなどの作業も必要であろう．
したがって，システムの性能を
向上させるためには，NERの認定基準と本タスクで必要とされる地名・場所名の
認定基準との擦り合わせ，さらには地名・場所名辞書との整合性をとる自明でな
い作業が必要となる．


\subsection{回答のランキング}

本論文におけるシステムでは，ロングテールに存在する回答についてもす
べて出力するという目的から，再現率を重視し，今まで述べてきた手法で発見で
きたすべての回答を出力している．一方で，自明な拡張は回答にランキングメカ
ニズムを導入し，さらなる拡張を図ることである．本来，再現率を重視しつつ，
ランキングを導入し，提案手法よりも高い性能を達成するためには，提案手法よ
りも公汎な回答を出力し，ランキングに基づいて回答の足切りを行うべきである
が，現状はそこまでの実験は行えていない．代わりに，提案システムが出力する
回答全部を教師あり学習に基づいてランキングした結果について報告する．

今回行った実験で使ったランキング手法は，回
答とパターンに関する素性をもとに学習したSVMのスコアによりランキングを行うものである．
表\ref{feature}に，SVMの学習に利用した素性を示す．

\begin{table}[b]
\caption{回答のランキングに使用する素性一覧}
\label{feature}
\input{03table05.txt}
\end{table}

まず，パターンの属性に基づく素性として，質問構文パターン，クラス依存パターン，クラス
非依存パターン，部分パターンからのいずれのパターンで回答が得られた
か，あるいは部分パターンと部分パターンの内容語によるキーワード検索を用
いたかを示す2値の素性を用いる．これに加え，クラス依存パターン，クラス非
依存パターン，部分パターンの各スコアを用いる．ある回答が複数の異
なるパターンから得られた場合には，その全パターン数，パターンが回答を連体修
飾していないどうか，全パターン数と回答を連体修飾していないパターンとの比率を利用する．また回答を
抽出した含意パターンや部分パターンが，質問構文パターンと共通の漢字を持つ
かどうかも利用する．

回答の属性に基づく素性では，まず，様々なパターンから得られた同じ回答の個
数，その文字数及び形態素数を用いる．次に，回答の意味的な情報として，回答の意
味クラス，その意味クラスを特定する際に部分文字列を用いたか，
回答のクラスが未特定かどうかの2値の素性を用いる．また，回答を獲得したパ
ターントリプルの構文パターンと2つの名詞句の意味クラスのPMI （相互情報量：
Point-wise Mutual Information），質問構文パターンと質問文中の名詞に基づく回答の意味クラスの尤度\cite{De_Saeger2009}を利用する．
また質問文から得られる疑問
代名詞と主題語を利用した素性として，疑問代名詞タイプ，回答が疑問代名詞の
対応するクラスに属するかどうか，回答と主題語との分布類似度，回答が主題語
の下位概念となるかどうか，回答の末尾に主題語を含むかどうかを用いる．

上記の素性を用いて，線形，多項式（二次），放射基底関数（RBF, 比例定数 1）の
各カーネルを用いてSVMの学習を行い，いずれのカーネル関数を用いるべきか検
討した．学習データは，災害に関連の深い質問60問（これまでの評価で利用した
質問とは別である）と，システムが出力した回答のペア合計5,044個に対して正
解／不正解のラベルを付与したデータである．なお，このデータは提案システム
の古いバージョン，つまり，場所名フィルターや部分パターン含意データベースのクリー
ニングを行っていないシステムの出力を含んでおり，現在の提案システムでは出
力できない回答も含まれている．10分割交叉検定の結果，線形カーネルでF値
0.642（適合率0.681，再現率0.607），多項式カーネルでF値0.631（適合率0.626，再現
率0.634）, RBFカーネルでF値0.529（適合率0.719，再現率0.419）が得られた．本シ
ステムではF値が最も高かった線形カーネルにより学習された分類器の出力する
スコアを利用することを検討した．

\begin{figure}[b]
\begin{center}
\includegraphics{20-3ia3f5.eps}
\end{center}
\caption{回答のランキング結果}
\label{recall_prec_pic}
\end{figure}

\ref{Eval_QA}節の実験にて利用した250個の回答サンプル（適合率0.608）を以上の分類器
のスコアでランキングした結果が図\ref{recall_prec_pic}である．グラフの再
現率は提案システムの出力すべてをSVMのスコアにしきい値をもうけて足切りを
行い，足切りを生き延びた回答集合を17,254件の正解データに照らし合わせて計
算されたものである．これによると，再現率が0.1前後のところでは適合率が
0.90前後でており，きわめて高いものとなっている一方，システムの全回答の再
現率0.508に近いところ，例えば，再現率0.4前後のところでは提案手法の適合率
に比して，わずかな適合率の向上（0.05前後）しか見られず，また，もうすこし離
れたデータポイント（例えば，再現率0.3前後のデータポイント）までの適合率
の改善具合もきわめてなだらかである．

この評価はあくまで現状のシステムの出力結果のみをランキングしているため，
確定的なことは言えないが，前述したように学習データは現在のシステムが出力
できない回答に関するものも含まれていないことも考え合わせると，仮に現在の
システムをより大量の回答を出力するように改変し，ランキングによる足切りを
おこなったとしても，例えば，再現率0.5前後の部分での適合率向上はきわめて
小さなものになる可能性が高いと考えられる．これは再現率を重視するという我々
の立場とは相容れないものであり，提案システムにはランキング手法は導入しな
かった．

一つ今後システムを改善できる可能性があるとすれば，今後さらに学習データを
増やしていくことが重要であるが，現在でも約5,000件という少なくない量の学
習データを利用していること，また，次回の災害はおそらく東日本大震災とは大
きく異なることが予想され，東日本大震災に特化した学習データを作ることは望
ましくないと考えられることから，少なくともランキング手法の導入については
慎重に検討する必要があると考えている．
実際に大規模な災害が発生した後，アノテーションをクラウ
ドソーシングなどで行い，質問応答の精度を高めるといったシナリオは魅力的に
見えるかもしれない．しかし，そうしたシナリオを実現するためには， NERの場
合と同様にシステム全体としての最適化の枠組みなどが必要だということかもし
れず，これも慎重に検討する必要があると考えている．


\section{さらに行き届いた被災情報の活用を目指して}
\label{Prospects}

本システムはインターネット経由で得られる情報を収集・分析し，ユーザからの質問に備える．図\ref{practicalimage}は，本システムを災害時にどのように運用するかを示
したイメージ図である．
各種救援団体，例えば，炊き出しを行う
ボランティア団体などは，自らの炊き出し実施場所を決めるためにどこで
炊き出しを行っているかをシステムに質問し，そのすべての回答を地図上に表示
することで，炊き出しが行われていないエリアを確認できる．一方，被災者など
個人レベルで本システムを利用する場合には，自分の周辺の状況を把握し，意思
決定の助けとするような使い方や，また把握した状況に基づき，
自らの周辺状況や救援要請を発信するなどの使い方を考えている．
このように，本システムは災害時において，ソーシャルメディア等に溢れる情報
を整理し，救援団体や，自治体，被災者らに対して被災状況の全体的把握を容易
にする情報をわかりやすく提示することで，被災者の救援・支援に有効である．

\begin{figure}[t]
\begin{center}
\includegraphics{20-3ia3f6.eps}
\end{center}
\caption{災害時における提案システム運用イメージ}
\label{practicalimage}
\end{figure}

一方で，災害時においては，通信状況等様々な制約から，回答のすべてを確認することが
困難な状況も考えられる．そこで，重要と考えられる回答の一部を表示するため
に，結果をランキングできることが望ましいが，質問に対する一般的な回答の
適切さのみならず，過去5分以内に挙げられた情報を求
める場合のように情報の新鮮さを重視する場合や，
回答の利用目的（見落としているかもしれない
ものにはやく気づきたい）などによっていくつかの基準が考えられる．
時刻による限定は，現在機能として有しているが，ランキングの基準とあわせて
今後利用者にとってさらに使いやすくすべきである．

さらに，
インターネット経由でつぎつぎ
に情報（テキスト）が流れ込んでくる状況においては，
システムが大規模コーパスから獲得して利用している知識，例えば，意味クラ
ス辞書や，含意パターンデータベースを拡張可能かもしれない．
しかしながら，これらのデータベースは，一度，大規模なコーパスから獲得して
しまえば，大部分のものは長く使えるものである．特に含意パターンデータベー
スは，名詞句が変数となっており，その経時的変化は非常にゆるやかであると
考える．災害発生後にそれまで使っていたパターンとは全く異なるパターンで
情報発信することは考えにくい．したがって，事前に大規模なコーパスから獲得
した知識を用いていることによって損なわれる有用性は非常に限定されると考え
る．
もちろん，オンライン学習等によって常時知識が更新されつづけるようシステム
に拡張すべきであることは言うまでもない．

本論文の冒頭で示唆したように，今回の震災時には被災者からのtweetが必ずし
も救援者へ届いていないという問題があったようである．本システムは，被災地
からの情報を全体的俯瞰的に把握することを可能とする．しかしながら，一度質
問した内容でも，対応する情報は被災地の各地から質問後も不定期に投稿される
可能性が高く，その情報は常に更新される．比較的落ち着いた時期になれば，定
期的に分析システムを利用すればよいが，災害時に様々な対応が必要な自治体な
どの支援者側は思うようには反応することができないことが予想される．また，
情報発信を行っている被災者サイドでも発信した情報が適切な救援者に届いてい
るか否かが不明な状況では，例えばさらに遠くへ避難するか，それとも救助を待
つかといった切迫した判断を行えないといった問題が生じえる．

\begin{figure}[b]
\begin{center}
\includegraphics{20-3ia3f7.eps}
\end{center}
\caption{被災者と救援者の双方向のコミュニケーション}
\label{two-way-communication}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{20-3ia3f8.eps}
\end{center}
\caption{掲示板上での動作例}
\label{BBS-example}
\end{figure}

そこで，我々は，図\ref{two-way-communication}に示すように，本システムの回答インデックス作成モジュールを拡張し，予め救援
者がシステムに登録した質問に対しては，以後のtweetや指定したBBS，掲示板に
情報が発信された場合に，システムがその内容が登録済みの質問の回答となるか
をリアルタイムで判断し，救援者サイドの情報のアップデートを行うとともに，
情報提供者にも，質問を登録した救援者にその情報が届いたことが通知される枠
組みを開発している．この処理により，図\ref{BBS-example}のように，情報提供者，被災者は自らの発信した情報
が救援者に届いたことがわかりその後の意思決定が容易になるとともに，救援者
側は欲している情報をリアルタイムで定常的に取得することができ，支援のスピー
ドアップにつながると考えられる．こうした一連の操作は，一言で言えば，現状
のマイクロブログ，SNS，掲示板等のいわば一方通行の情報提供から，
被災者サイドと支援団体等救援者サイドの双方向のコミュニケーションを担保することとも言え，こうした操作に
よってよりスピーディかつ適切な救援，避難等が実現できるのではないかと考え
ている．

こうした処理は，これまでに説明した質問応答の処理の方向を大幅に変更するこ
となく実現できる．通常の質問応答処理では，パターントリプルもしくは部分パ
ターンの形式でインデッ
クスに登録されたtweetからの情報を，質問から取得したパターントリプル等を
含むクエリにより検索するが，ここでは，あらかじめ登録された質問に対して，
含意パターンなどの獲得を事前にやっておき，含意パターンも含むようなパター
ントリプル等をキー，質問を値とする別種のいわば質問のインデックスを作成し
ておく．

例えば，「宮城県で不足しているのは何ですか？」といった質問が登録
されているとするならば，「Xで足りないY」といった含意パターンや，「宮城県」
といった名詞句を含むパターントリプルをキーとし，「宮城県で不足しているの
は何ですか」という質問を値とするような質問のインデックスが作成される．掲
示板等の記事やtweetが新規にシステムに渡されると，将来問われる質問にそな
えてこれまでに説明してきた回答インデックスが作成されるが，その際，生成さ
れるパターントリプルをキーとして，過去に登録された質問のインデックスを検
索する．もしこの質問のインデックスの検索がヒットすれば，値となっている登
録済み質問の回答をアップデートするとともに，対応する新規のtweet，記事等
の作者に対して，登録された質問への回答として提供された情報が認識されたこ
とを通知する．現状は，こうした枠組みをサーバー一台の上で動作させることが
できており，今後，大規模な計算機クラスタ上等で想
定されるような大量の情報がやってきたときでもリアルタイムの処理が可能なシ
ステムを開発していく予定である．

\begin{figure}[t]
\begin{center}
\includegraphics{20-3ia3f9.eps}
\end{center}
\caption{「放射能に効くのは何ですか」という質問に対するシステム出力}
\label{radiation_example}
\end{figure}

本システムのもう一つの応用としては，ソーシャルメディア上で流通している様々なデマ
の早期発見とエキスパートによる反論を支援するものが考えられる．例えば，図
\ref{radiation_example}で「放射能に効くのは何ですか」という質問に対して
のシステム出力を示す，「イソジン」，「わかめ」，「活性炭」など，デマと思
われるものが大量に含まれる．このような質問も予めにシステムに登録すること
で，信頼性が低い情報あるいは有害情報が爆発的に拡散される前に，書き込まれ
た時点に認識され，デマが大量に拡散する以前にエキスパートによってデマを打
ち消す情報をスピーディに発信することが可能となると考えられる．

また，本システムが提示する回答にはそもそも大量のデマが含まれている可能性
があるが，我々は本システムを東北大学で開発されている言論マップ
    (水野, Nicoles, 渡邉, 村上, 松吉, 大木, 乾, 松本 2011) \nocite{Mizuno2011}と組み合わせることで回答を閲覧したユーザが回答のデマ性
についてより適切な判断を下すことができるようになると考えており，実際に言
論マップとの統合を計画している．現在の言論マップでは，例えば「イソジンは
放射能に効く」という情報に対して，それを肯定している情報と否定している情
報をソーシャルメディア上の情報から発見して提示することが可能である．こう
した肯定的情報，否定的情報は通常のソーシャルメディアの閲覧環境では簡単に
見つけることは難しいが，本システムに言論マップを組み合わせることで，回答
には常に肯定的情報，否定的情報
をあわせて表示することが可能となり，ユーザは疑わしい情報に関しては，こう
した情報を参考にしつつその真偽を判断する材料とすることができる．


\section{関連研究}
\label{Related_work}

近年では，検索エンジンや質問応答システムなど，情報へのアクセス手段の進歩
が目覚ましい．例えば，質問応答システムとしてはIBM社のWatson
\cite{Ferrucci2010} がクイズ番組の人間のチャンピオンに圧勝し一躍有名になっ
た．Watsonは，Wikipediaを含む辞書，辞典や台本などJeopardyというクイズ番
組の分野に関連する確かな知識を予め選別し，データベース化している．少なく
とも我々の知る限り，情報のリアルタイム更新については想定していないため，
逐次更新される災害時の情報などには対応していない．また，災害時に必要なの
は，多数の情報を俯瞰的に閲覧することであるが，すくなくともJeopadyにおい
て質問はその回答が一意に定まるものに限られており，Watsonが現状すぐに災害
時の情報などに適用できるかどうかは不明確である．

また，日本においても，「しゃべってコンシェル」\cite{Yoshimura2012}と呼ば
れる携帯電話のサービスが注目を浴びている．このシステムは，携帯電話を用い
て質問応答を行うものであり，Webの更新データに対応している．このサービス
での質問応答では，「ハリーポッターの監督は誰」のようなある対象物（ハリー
ポッター）の属性（監督）を聞くタイプの質問は，回答が一意に定まる知識につ
いてWatsonと同じように予め知識のデータベース化を行っている．また，天気や
ニュースなどについては専用のサービスの結果を返し，それ以外の質問は，キー
ワード検索と固有表現による質問応答手法を利用している．それでも見つからな
い場合はキーワードによる検索結果を出力する．

我々のシステムは，上記のシステムとは異なり，これまでの含意獲得の研究をも
とに，質問文からの含意パターンや部分パターンを取り出し，そのパターンを元
に回答を求めている．そのため，質問文から何らかのパターンが獲得できれば，
高い精度で回答が可能である．また，固有表現でない一般名詞が回答の場合や，
これまでの固有表現\cite{Sekine2000,Sekine2008}では対象としていない表現に
ついても，回答を出力できる．固有表現は，特定の質問に対しては重
要な要素であることは間違いないため，今後，回答のランキングに固有表現に関
する素性を取り入れて行く予定である．また，災害時の質問にも，一意に定まる
質問がされる可能性はあるため，Wikipediaなどの知識を利用した手法
\cite{Buscaldi2006}もシステムも取り入れて行く．


\section{おわりに}
\label{Conclusion}

本論文では，想定外のものもふくめて，災害時の情報を俯瞰的に把握するために
開発した，質問応答に基づく情報分析システムについて述べ，また，東日本大震
災時のtweetデータを利用した性能評価について報告した．さらに，本システム
を拡張することによって，比較的実現容易な形で，リアルタイムで被災者と救援
者が双方向のコミュニケーションを行うことを可能とし，より効率的な救援活動
やより適切な避難行動等を支援する枠組みについても提案した．また，東北大学
で開発されている言論マップ技術との統合や，リアルタイムでの回答の更新によっ
て，東日本大震災時に問題となったデマに対処する枠組みも提案した．
 
様々な質問に対して回答を提示できるようにする
ために，本システムでは，質問応答処理において構文パターンの言い換えに基づ
く質問文の拡張を行い，さらに場所や地名の補完処理を加えることで，幅広い質
問に対応した．また，得られた回答を意味クラスごとにまとめるインターフェー
スと回答を地図上に表示するインターフェースを用意することで被災地の状況や
救援状況の俯瞰的把握を可能とした．人手で作成した質問を基にした評価実験で
は，複合語処理の問題や要望，疑問，仮定を含むtweetの特定の必要性が明らか
になった．必要な情報を必要な人に行き渡らせるためには，たとえその回答を必
要としている人が一人であっても，回答を提示することが望ましい．こうした点
に鑑み，ロングテール部分に存在する被災者の要望にも応えることができる情報
分析システムの構築を今後も進めていく予定である．

より具体的には，現在5万件以上からなる災害に関連の深い含意パターンの学習
データを人手で構築しつつあり，さらに，その他の言語資源も構築中である．今
後，こうしたリソースを活用しつつ，また，新規のアルゴリズムを導入すること
によって性能向上を図っていく予定である．



\acknowledgment

本研究で利用しているデータは，株式会社ホットリンク様より
ご提供頂きました．ここに記して感謝致します．


\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Bloom}{Bloom}{1970}]{Bloom1970}
Bloom, B. \BBOP 1970\BBCP.
\newblock \BBOQ Space/time Trade-offs in Hash Coding with Allowable
  Errors.\BBCQ\
\newblock {\Bem Communications of the ACM}, {\Bbf 13}  (7), \mbox{\BPGS\
  422--426}.

\bibitem[\protect\BCAY{Buscaldi \BBA\ Rosso}{Buscaldi \BBA\
  Rosso}{2006}]{Buscaldi2006}
Buscaldi, D.\BBACOMMA\ \BBA\ Rosso, P. \BBOP 2006\BBCP.
\newblock \BBOQ Mining Knowledge from Wikipedia for the Question Answering
  Task.\BBCQ\
\newblock In {\Bem Proceedings of the International Conference on Language
  Resources and Evaluation (LREC)}, \mbox{\BPGS\ 727--730}.

\bibitem[\protect\BCAY{Cheng, Caverlee, \BBA\ Lee}{Cheng
  et~al.}{2010}]{Cheng2010}
Cheng, Z., Caverlee, J., \BBA\ Lee, K. \BBOP 2010\BBCP.
\newblock \BBOQ You Are Where You Tweet: A Content-Based Approach to
  Geo-locating Twitter Users.\BBCQ\
\newblock In {\Bem Proceedings of the 19th ACM International Conference on
  Information and Knowledge Management (CIKM)}, \mbox{\BPGS\ 759--768}.

\bibitem[\protect\BCAY{De~Saeger, Torisawa, Kazama, Kuroda, \BBA\
  Murata}{De~Saeger et~al.}{2009}]{De_Saeger2009}
De~Saeger, S., Torisawa, K., Kazama, J., Kuroda, K., \BBA\ Murata, M. \BBOP
  2009\BBCP.
\newblock \BBOQ Large Scale Relation Acquisition using Class Dependent
  Patterns.\BBCQ\
\newblock In {\Bem Proceedings of the IEEE International Conference on Data
  Mining (ICDM)}, \mbox{\BPGS\ 764--769}.

\bibitem[\protect\BCAY{Ferrucci, Brown, Chu-Carroll, Fan, Gondek, Kalyanpur,
  Lally, Murdock, Nyberg, Prager, Schlaefer, \BBA\ Welty}{Ferrucci
  et~al.}{2010}]{Ferrucci2010}
Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek, D., Kalyanpur,
  A.~A., Lally, A., Murdock, J.~W., Nyberg, E., Prager, J., Schlaefer, N.,
  \BBA\ Welty, C. \BBOP 2010\BBCP.
\newblock \BBOQ Building Watson: An Overview of the {DeepQA} Project.\BBCQ\
\newblock {\Bem {AI} Magazine}, {\Bbf 31}  (3), \mbox{\BPGS\ 59--79}.

\bibitem[\protect\BCAY{Fleiss}{Fleiss}{1971}]{Fleiss1971}
Fleiss, J. \BBOP 1971\BBCP.
\newblock \BBOQ Measuring Nominal Scale Agreement among Many Raters.\BBCQ\
\newblock {\Bem Psychological Bulletin}, {\Bbf 76}  (5), \mbox{\BPGS\
  378--382}.

\bibitem[\protect\BCAY{Harris}{Harris}{1954}]{Harris1954}
Harris, Z. \BBOP 1954\BBCP.
\newblock \BBOQ Distributional Structure.\BBCQ\
\newblock {\Bem Word}, {\Bbf 10}  (23), \mbox{\BPGS\ 142--146}.

\bibitem[\protect\BCAY{Hashimoto, Torisawa, De~Saeger, Oh, \BBA\
  Kazama}{Hashimoto et~al.}{2012}]{Hashimoto2012}
Hashimoto, C., Torisawa, K., De~Saeger, S., Oh, J., \BBA\ Kazama, J. \BBOP
  2012\BBCP.
\newblock \BBOQ Excitatory or Inhibitory: A New Semantic Orientation Extracts
  Contradiction and Causality from the Web.\BBCQ\
\newblock In {\Bem Proceedings of the 2012 Joint Conference on Empirical
  Methods in Natural Language Processing and Computational Natural Language
  Learning (EMNLP-CoNLL)}, \mbox{\BPGS\ 619--630}.

\bibitem[\protect\BCAY{川田\JBA 大竹\JBA 後藤\JBA 鳥澤}{川田 \Jetal
  }{2013}]{Kawada2013}
川田拓也\JBA 大竹清敬\JBA 後藤淳\JBA 鳥澤健太郎 \BBOP 2013\BBCP.
\newblock 災害対応質問応答システム構築に向けた質問・回答コーパスの構築.\
\newblock \Jem{言語処理学会第19回年次大会発表論文集}, \mbox{\BPGS\ 480--483}.

\bibitem[\protect\BCAY{風間\JBA {De~Saeger,~S.}\JBA 鳥澤\JBA 後藤\JBA
  {Varga,~I.}}{風間 \Jetal }{2012}]{Kazama2012b}
風間淳一\JBA {De~Saeger,~S.}\JBA 鳥澤健太郎\JBA 後藤淳\JBA {Varga,~I.} \BBOP
  2012\BBCP.
\newblock 災害時情報への質問応答システムの適用の試み.\
\newblock \Jem{言語処理学会第18回年次大会講演論文集}, \mbox{\BPGS\ 903--906}.

\bibitem[\protect\BCAY{Kazama \BBA\ Torisawa}{Kazama \BBA\
  Torisawa}{2008}]{Kazama2008}
Kazama, J.\BBACOMMA\ \BBA\ Torisawa, K. \BBOP 2008\BBCP.
\newblock \BBOQ Inducing Gazetteers for Named Entity Recognition by Large-Scale
  Clustering of Dependency Relations.\BBCQ\
\newblock In {\Bem Proceedings of the 46th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies (ACL-08: HLT)},
  \mbox{\BPGS\ 407--415}.

\bibitem[\protect\BCAY{Kloetzer, De~Saeger, Torisawa, Sano, Goto, Hashimoto,
  \BBA\ Oh}{Kloetzer et~al.}{2012}]{Kloetzer2012}
Kloetzer, J., De~Saeger, S., Torisawa, K., Sano, M., Goto, J., Hashimoto, C.,
  \BBA\ Oh, J. \BBOP 2012\BBCP.
\newblock \BBOQ Supervised Recognition of Entailment between Patterns.\BBCQ\
\newblock \Jem{言語処理学会第18回年次大会講演論文集}, \mbox{\BPGS\ 431--434}.

\bibitem[\protect\BCAY{Liu, Wei, Zhang, \BBA\ Zhou}{Liu et~al.}{2013}]{Liu2013}
Liu, X., Wei, F., Zhang, S., \BBA\ Zhou, M. \BBOP 2013\BBCP.
\newblock \BBOQ Named Entity Recognition for Tweets.\BBCQ\
\newblock {\Bem ACM Transactions on Intelligent Systems and Technology}, {\Bbf
  4}  (1), \mbox{\BPGS\ 1--15}.

\bibitem[\protect\BCAY{水野\JBA {Nicoles,~E.}\JBA 渡邉\JBA 村上\JBA 松吉\JBA
  大木\JBA 乾\JBA 松本}{水野 \Jetal }{2011}]{Mizuno2011}
水野淳太\JBA {Nicoles,~E.}\JBA 渡邉陽太郎\JBA 村上浩司\JBA 松吉俊\JBA
  大木環美\JBA 乾健太郎\JBA 松本裕治 \BBOP 2011\BBCP.
\newblock 言論マップ生成技術の現状と課題.\
\newblock \Jem{言語処理学会第17回年次大会講演論文集}, \mbox{\BPGS\ 49--52}.

\bibitem[\protect\BCAY{Neubig, Matsubayashi, Hagiwara, \BBA\ Murakami}{Neubig
  et~al.}{2011}]{Neubig2011}
Neubig, G., Matsubayashi, Y., Hagiwara, M., \BBA\ Murakami, K. \BBOP 2011\BBCP.
\newblock \BBOQ Safety Information Mining---What Can {NLP} Do in a
  Disaster---.\BBCQ\
\newblock In {\Bem Proceedings of the 5th International Joint Conference on
  Natural Language Processing (IJCNLP)}, \mbox{\BPGS\ 965--973}.

\bibitem[\protect\BCAY{Ritter, Clark, Mausam, \BBA\ Etzioni}{Ritter
  et~al.}{2011}]{Ritter2011}
Ritter, A., Clark, S., Mausam, \BBA\ Etzioni, O. \BBOP 2011\BBCP.
\newblock \BBOQ Named Entity Recognition in Tweets: An Experimental
  Study.\BBCQ\
\newblock In {\Bem Proceedings of the 2011 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, \mbox{\BPGS\ 1524--1534}.

\bibitem[\protect\BCAY{Sekine}{Sekine}{2008}]{Sekine2008}
Sekine, S. \BBOP 2008\BBCP.
\newblock \BBOQ Extended Named Entity Ontology with Attribute
  Information.\BBCQ\
\newblock In {\Bem Proceedings of the International Conference on Language
  Resources and Evaluation (LREC)}.

\bibitem[\protect\BCAY{Sekine \BBA\ Isahara}{Sekine \BBA\
  Isahara}{2000}]{Sekine2000}
Sekine, S.\BBACOMMA\ \BBA\ Isahara, H. \BBOP 2000\BBCP.
\newblock \BBOQ {IREX}: {IR} and {IE} Evaluation Project in {J}apanese.\BBCQ\
\newblock In {\Bem Proceedings of the International Conference on Language
  Resources and Evaluation (LREC)}, \mbox{\BPGS\ 1475--1480}.

\bibitem[\protect\BCAY{Yamada, Torisawa, Kazama, Kuroda, Murata, De~Saeger,
  Bond, \BBA\ Sumida}{Yamada et~al.}{2009}]{Yamada2009}
Yamada, I., Torisawa, K., Kazama, J., Kuroda, K., Murata, M., De~Saeger, S.,
  Bond, F., \BBA\ Sumida, A. \BBOP 2009\BBCP.
\newblock \BBOQ Hypernym Discovery Based on Distributional Similarity and
  Hierarchical Structures.\BBCQ\
\newblock In {\Bem Proceedings of the 2009 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, \mbox{\BPGS\ 1172--1181}.

\bibitem[\protect\BCAY{吉村}{吉村}{2012}]{Yoshimura2012}
吉村健 \BBOP 2012\BBCP.
\newblock しゃべってコンシェルと言語処理.\
\newblock {\Bem IPSJ SIG Technical Report Vol. {\upshape\textbf{2012-SLP-93}
  (4)}}, \mbox{\BPGS\ 1--6}.

\end{thebibliography}

\begin{biography}
\bioauthor{後藤　　淳}{
1993年徳島大学大学院工学研究科修士課程修了．同年日本放送協会入局．2011年より独立行政法人情報通信研究機構専門研究員．現在，総合研究大学院大学博士課程在学．
}
\bioauthor{大竹　清敬}{
2001年豊橋技術科学大学大学院博士後期課程修了．博士（工学）．同年より
株式会社ATR音声言語コミュニケーション研究所．2006年より独立行政法人情報通信研究機構．音声言語処理，自然言語処理の研究に従事．
}

\bioauthor[:]{Stijn De Saeger}{
2006年北陸先端科学技術大学院大学博士課程修了．博士（知識科学）．独立行政法人情報通信研究機構専攻研究員を経て，現在同機構主任研究員．知識の自動獲得の研究に従事．言語処理学会第16回年次大会優秀発表賞等受賞．
}

\bioauthor{橋本　　力}{
2005年京都大学研究員，2007年山形大学助教，2009年独立行政法人情報通信研究機構専攻研究員．現在，同機構主任研究員．博士（言語科学，情報学）．情報処理学会論文賞，言語処理学会論文賞，同学会優秀発表賞等受賞．
}

\bioauthor[:]{Julien Kloetzer}{
2006年パリ第6大学卒業，2010年北陸先端科学技術大学院大学博士課程修了．博士（情報科学）．2011年独立行政法人情報通信研究機構入所．現在，同機構情報分析研究室研究員．
}

\bioauthor{川田　拓也}{
2003年国際基督教大学教養学部卒業．2010年京都大学大学院文学研究科博士後期課程修了．博士（文学）．現在，独立行政法人情報通信研究機構情報分析研究室研究員．言語資源の設計と構築に従事．
}

\bioauthor{鳥澤健太郎}{
1995年東京大学大学院理学系研究科中退．同年同専攻助手．北陸先端科学技術大学院大学助教授を経て，現在，独立行政法人情報通信研究機構・情報分析研究室室長及び情報配信基盤研究室室長．博士（理学）．日本学術振興会賞など受賞．
}

\end{biography}


\biodate


\end{document}
