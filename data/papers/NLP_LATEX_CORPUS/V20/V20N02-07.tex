    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline
\usepackage{array}
 \newcommand{\citep}[1]{} 
\newcommand{\iz}[1]{}
\newcommand{\izk}[1]{}
\newcommand{\izs}[1]{}
\newcommand{\izj}{}
\newcommand{\ind}[1]{}
\newcommand{\best}{}
\newcommand{\rand}{}
\newcommand{\evaB}{}
\newcommand{\evaR}{}
\newcommand{\added}{}
\newcommand{\fixed}{}
\newcommand{\sel}{}
\newcommand{\cand}{}
\newcommand{\border}{}
    \newcommand{\tfidf}{}
 \usepackage{relsize,xspace}
 
 \usepackage{avm}
    \newcommand{\refsec}[1]{} 
\newcommand{\lxd}{}
\newcommand{\hk}{}
\newcommand{\wpd}{}
\newcommand{\WN}{}
\newcommand{\IN}{}
\newcommand{\PN}{}
\newcommand{\CL}{}
\newcommand{\OCAL}{}
    \newcommand{\ano}{}
\newcommand{\IO}{}
\newcommand{\MAJOR}{}
\newcommand{\MINOR}{}
\newcommand{\MONO}{}
\newcommand{\mono}{}
\newcommand{\syn}{} 
\newcommand{\hyp}{} 
\newcommand{\bl}{} 
\newcommand{\gogi}[1]{}
    \newcommand{\changed}[1]{}

\Volume{20}
\Number{2}
\Month{June}
\Year{2013}

\received{2012}{11}{7}
\revised{2013}{2}{6}
\accepted{2013}{3}{26}

\setcounter{page}{223}

\jtitle{画像検索を用いた語義別画像付き辞書の構築}
\jauthor{藤田　早苗\affiref{Author} \and 平　　博順\affiref{Author} \and 永田　昌明\affiref{Author}}
\jabstract{
既存のテキストのみからなる辞書に対し，インターネット上にある膨大な画像を
関連付けることができれば，文字列情報からだけでは得られない，視覚的な情報
を利用できるようになり，用途が広がると期待できる．
そのため，本稿では，辞書の出来る限り広い語義に対して画像を付与すること
を考える．
作成・維持コストを考えれば，なるべく自動的に画像を付与することが望ましい
が，大量の辞書エントリに対して，高い精度で画像を付与することは容易ではな
い．
また，そもそもどういった語義には画像を付与できるのか，あるい
はできないのかといった調査が大規模になされた例はなく，画像が付与できる語
義を自動的に判別することも困難である．
そこで本稿では，まず語義別に画像が付与された辞書を人手で構築す
ることを第一の目標とする．その上で，画像が付与できる語義とできない語義に
ついて，品詞や意味クラスとの関連性に着目して分析する．
具体的には，名詞，動詞，形容詞，形容動詞，副詞を含む25,481 語，39,251 語義
を対象に画像付与実験と分析を行ない，その結果，全語義の94.0\%は画像付与
が可能であること，品詞や意味クラスに応じて画像付与の可否が変わることを示
す．
また，幅広い語義に適切な画像を付与するため，インターネットから画像検
索によって画像を獲得する．検索時に重要となるのが検索語である．
本稿の第二の目標は，語義毎に適切な画像を得るための検索語を調査することで
ある．本稿では，複数の検索語の組合せ（以下，検索語セット）の中から最も適切
な画像を得られる検索語セットを作業者に選択してもらい，適切な検索語セット
がない場合には修正してもらう．こうして最終的に利用された検索語セットを分
析し，提案手法の改良点を探る．
さらに，検索語セットの優先順位の決定方法も提案，
その妥当性を示すことを本稿の第三の目標とする．
新しい辞書への適用等を考えると，人手による画像付与が
できない場合でも，優先順位の高い検索語セットによる検索結果が利用できれば，
有用だと考えられるからである．
提案手法では，対象語義がメジャーな語義かどうかで優先順位を変化させる．
実験では，2種類の評価方法を通してその妥当性を示す．
}
\jkeywords{オントロジ，同義語，多義語，意味クラス，検索}

\etitle{Enrichment of a Dictionary with Images from the Internet}
\eauthor{Sanae Fujita\affiref{Author} \and Hirotoshi Taira\affiref{Author} \and Masaaki Nagata\affiref{Author}} 
\eabstract{
The Internet is an immense resource storehouse for images. 
Establishing a connection
between images and dictionary definitions would enable the creation of
rich dictionary resources with multimedia information. Therefore, this
study aims at providing several suitable images for dictionary
definitions. In this study, we targeted 25,481 words, including nouns,
verbs, adjectives, and adverbs, split into 39,251 senses by querying an
image search engine. 
The results showed that 94\% of word senses could be defined as
suitable images.
Then, we analyzed the relationship
between the vis\-ualization of each word sense and parts of speech or
semantic classes. To obtain images for each word sense, we expanded the
query by appending queries extracted from definitions for each word
sense. Second, we analyzed both manually-selected and fixed queries and
examined query expansion methods more deeply. 
This paper proposes a
method to set queries in priority order depending on the primary word
sense. 
Third, we show the suitability of our method through two types of
evaluations because in the application of new dictionaries or new target
senses, it is valuable to obtain images automatically using
high-priority queries.
}
\ekeywords{Ontology, Synonym, Polysemous Word, Semantic Class, Query Expansion}

\headauthor{藤田，平，永田}
\headtitle{画像検索を用いた語義別画像付き辞書の構築}

\affilabel{Author}{NTT コミュニケーション科学基礎研究所}{NTT Communication Science Laboratories}



\begin{document}
\maketitle



\section{はじめに} \label{sec:introduction}

文字による記述だけでなく，画像も付与された辞書は，
教育分野 \cite{Popescu:Millet:etc:2006}や言語
\linebreak
横断検索
\cite{Hayashi:Bora:Nagata:2012j}での利用，
子供や異なる言語の話者\cite{Suwa:Miyabe:Yoshino:2012j}，
文字の認識に困難を
\linebreak
伴うような人とのコミュニケーションを助けるツール
\cite{Mihalcea:Leong:2008,Goldberg:Rosin:Zhu:Dyer:2009}
の構築に使うことができるなど，様々な潜在的な可能性を持っている．
そのため，本稿では，できるだけ広範な語義に対して画像が付与された
辞書を構築することを第一目標とする．

辞書やシソーラスに画像を付与する研究はこれまでにもいくつか存在する．
特に，見出し語を含む検索語を用いて画像検索を行ない，インターネットから
画像を獲得する研究は複数存在する．
\PN \cite{PicNet} や\IN \cite{ImageNet}といったプロジェクトでは，
\WN{} \cite{_Fellbaum:1998}のsynset に対し，
画像検索で獲得した候補画像の中から適切な画像を人手で選択して付与している．
\PN{}や\IN{}では，
近年発達してきた Amazon Mechanical Turk サービス
\footnote{http://www.mturk.com/}を始めとする，
データ作成を行なう参加者をインターネット上で募り，
大量のデータに対して人手でタグを付与する仕組みを用いて
大量の画像の収集とタグ付けを行なっている．
これらの手法は，大量のデータを精度良く集めること
ができるため有望である．しかし，現在は対象synsetが限定されている
ため，辞書全体に対するカバー率や，多義語の複数語義に対する網羅性には疑問が残る
\footnote{\IN{} の場合，HP (http://www.image-net.org/)
によると，2010年4月30日時点で，\WN{} の
約 100,000 synsets のうち，21,841 synset には画像が付与されているとしている．
多義性に関する報告はない．}．
また，\PN{}や\IN{}では，上位語や同義語にあたる語で検索語を拡張し
て用いているが，どのような語による拡張がより有効かといった調査は報告され
ていない．


また，\IO{}
\cite{Popescu:Millet:etc:2006,Popescu:Millet:etc:2007,Zinger:Millet:etc:2006}
でも，\WN{} のsynset に対してインターネットから獲得した画像を付与している．
\IO{}では，不適切な画像を取り除くために，人の顔が含まれるかどうかによる
自動的フィ
ルタリングや，画素情報による分類などを用いている．
この手法は，自動的に大量のデータを集めることができるため有望である．
しかし，\PN{}や\IN{}と同様，現在は対象synsetが具体物などに限定されている
ため，辞書全体に対するカバー率や，多義語の複数語義に対する網羅性には疑問が残る
\footnote{\cite{Popescu:Millet:etc:2007} は実験対象を\WN{} の
    \textit{placental} 配下の 1,113 synsets に限定しており，多義性に関する報告は
ない．}．

一方，
語の多義性に着目し，
多義のある語に対しても語義毎に適切な画像を付与
する研究として，\cite{Bond:Isahara:Fujita:Uchimoto:Kuribayashi:Kanzaki:2009} 
や\cite{Fujii:Ishikawa:2005a}がある．
\cite{Bond:Isahara:Fujita:Uchimoto:Kuribayashi:Kanzaki:2009} では，
日本語\WN\footnote{http://nlpwww.nict.go.jp/wn-ja/}のsynset
に対し，Open Clip Art Library (\OCAL)
\footnote{http://openclipart.org/} 
から獲得した画像を付与している．
彼らは，\OCAL{}と\WN{}の階層構造を比較し，両方の上位階層で同じ語が出
現する画像のみを候補として残すことで，多義性に対応している．
さらに，候補の画像の中から
各synsetの画像として適切な画像を人手で選択している．
\OCAL{} は著作権フリーで再配布可能という利点があるが，
含まれる画像が限られるため，画像を付与できる語義も限られている．


\cite{Fujii:Ishikawa:2005a} では，インターネットから収集した画像を
事典検索システム \CL\footnote{http://cyclone.cl.cs.titech.ac.jp/}におけ
る語義と対応付ける実験を行なっている．
彼らは，辞書の見出し語を検索語として用い，インターネットから候補となる画
像とそのリンク元テキストを収集し，テキストの曖昧性解消をおこなうことによって，
画像の意味を推定している．
これは，多義性に対応できる手法であるが，
出現頻度の低い語義の画像収集は困難だという問題がある．
なぜなら，見出し語のみを検索語としてインターネット検索を行なった場合，
得られる画像のほとんどは，最も出現頻度の高い語義に関連する画像になるから
である．
例えば，「アーチ」という語には，“上部を弓の形にして支えやすくした建物．”
や，“野球で，本塁打．”などの語義があるが，見出し語である「アーチ」
を検索語とした場合に得られた画像のうち，上位500画像には後者の語義
に対応する画像はない\footnote{Google画像検索の結果（2009年12月実施）
}．


本稿の第一目標は，できるだけ広範な語義に対して画像が付与され
た辞書を構築することである．本稿では，基本語データベース\lxd{}
\cite{Amano:Kobayashi:2008j}の内容語（一般名詞，サ変名詞，動詞，形容詞類，
副詞類）を対象に画像付与を試みる．
幅広い語義に画像を付与するため，
インターネットから画像検索によって画像を獲得する．また，多義性のある語に
も語義毎に適切な画像を付与するため，語義毎に検索語セットを
用意する．

第二の目標は，画像検索を行なう時に重要な問題である検索語の設定方法につい
ての知見を得ることである．
本稿では，作業者が対象語義に画像が付与できるかどうかという判断を行なった後，
用意した検索語セットの中から適切な検索語セットを選択・修正して画像検索に
用いる．最終的に利用された検索語セットを分析することで知見を得たい．

第三の目標は，提案する検索語セットの優先順位，特に，最も優先順位が
高い検索語セットをデフォルトの検索語セットとして利用することの妥当性を示
すことである．今後の作成・維持コストや，新しい辞書への適用を考えると，人
手による画像付与ができない場合でも，優先順位の高い検索語セットによる検索
結果が利用できれば，有用だと考えられるからである．



以降，\ref{sec:resource}章では画像付与の対象である\lxd{}について紹介する．
\ref{sec:make-query}章では，まず，200語義を対象として行なった予備実験
\cite{Fujita:Nagata:2010}を紹介する（\refsec{sec:pre-exp}）．その結果を踏ま
えた上で，画像検索に用いる検索語セットの作成方法を紹介し
（\refsec{sec:queryset}），検索語セットの優先順位の決定方法を提案する
（\refsec{sec:query-order}）．\ref{sec:all-lxd-exp}章では，作成した検索語セッ
トを用いた画像獲得方法，および，評価方法について述べる．
\ref{sec:ana-rand-best}章では，第三の目標である提案した優先順位の決定方法
の妥当性を示す．\ref{sec:all-lxd-analysis}章では，第二の目標である最終的
に利用された検索語に関する分析と，改良点の調査を行なう．ここまでの実験で，
第一の目標である\lxd{}の広範な語義に対する画像付与を行ない，
\ref{sec:ana-cannot}章では，構築した辞書を用いて画像付与可能／不可能な語
義について，意味クラスや品詞などの特徴から分析を行なう．最後に，
\ref{sec:conclusion}章で本稿の実験と分析をまとめる．



\section{言語資源} \label{sec:resource}


\subsection{言語資源の概要} \label{sec:lexeed}

本章では，用いる言語資源についての概略を説明する．画像付与対象の辞
書である
\lxd{}と，関連する言語資源から得られる情報の例を図~\ref{fig:arch-lxd}に
まとめて提示する．

\begin{figure}[t]
\input{07figure01.txt}
\vspace{0.5zw}\small 但し，下付き文字で表される番号は語義番号を示している．\par
\caption{\lxd と \hk の例：アーチ}
\label{fig:arch-lxd}
\end{figure}


\subsubsection{基本語データベース：語義別単語親密度 (Lexeed)} 

本稿では，「基本語データベース：語義別単語親密度」(\lxd{})を画像付与の対象
とする．\lxd{}は，心理実験により，対象語の日本人の成人にとっての平均的な
馴染み深さを「親密度」として測定し，日本人の95 \%以上が知っていると推定さ
れる語を基本語として収録したものである．
収録語数は約29,000語である．各語は平均1.7語義からなり，語義数では約
48,000語義収録されている．各エントリは，見出し語，読み，品詞，見出し語の親密度，および，
語義毎の親密度，定義文と例文から構成される．
ここで，見出し語には，複数の表記が含まれる場合がある．それらは代
表的な表記（以下，代表表記）とそれ以外（以下，表記ゆれ）に分けられている．
例えば，「たまねぎ」の場合，見出し語には「たまねぎ」「玉葱」が含まれるが，
「たまねぎ」が代表表記，「玉葱」は表記ゆれになっている．代表表記は，必ず
一つ以上記載されているが，表記ゆれは，全エントリに記載されているわけでは
ない．なお，語義は，「アーチ$_1$」のように下付き文字で語義番号を
付与した形で示す．


\subsubsection{檜オントロジと檜センスバンク} 

\lxd{}の各エントリには，「檜」プロジェクトにより様々な付加情報が付与され
ている．「檜」プロジェクトでは，\lxd{}を用いたセンスバンクやツリーバンク
の構築\cite{Bond:Fujita:Tanaka:2006}，語義文からの半自動的な
オントロジ構築\cite{Bond:Nichols:Fujita:Tanaka:2004}
，日本語語彙大系
\cite{GoiTaikeij}や\WN{}などの既存言語資源とのリンク構築\cite{Nichols:Bond:Tanaka:Fujita:Flickinger:2006}
などが行なわれた．本稿では，「檜」プロジェクトで構築された檜オントロジ，
檜センスバンク，日本語語彙大系の一般名詞カテゴリ（以下，意味クラス）とのリ
ンクから得られる情報を用いる．

檜オントロジは，\lxd{}の定義文の構文解析結果とルールにより，見出し語に対
する上位語や同義語，分野情報などを抽出したものである（図~\ref{fig:arch-lxd}の
\ul{下線部}）．

檜センスバンクは，\lxd{}の語義を付与したコーパスである．
\lxd{}の語義文と例文，京都大学テキストコーパス
\footnote{http://www-lab25.kuee.kyoto-u.ac.jp/nl-resource/corpus.html}，
Senseval-2 日本語辞書タスク \cite{Shirai:2003j}の訓練データ等，
約 194,000文が含まれ，その内容語のうち約1,403,000語に語義が付与されている．

日本語語彙大系は深さ0から11までの階層構造をもつシソーラスである．意味クラ
スは，2,710個存在し，各意味クラスには，固有の番号とクラス名が付与されてい
る．番号は深さ優先で振られており，例えば，3から999番までの意味クラスはす
べて\izs{2:具体}の配下であり，具体的な事物を表すことを示している．また，
1000以上の番号を持つ意味クラスはすべて\izs{1000:抽象}の配下であり，抽象的
な事物を表すことを示している．なお，意味クラス同士の関係の 97.9\%はis-a
関係\footnote{is-a 関係とは，包含関係を示している．例えば，
\izs{531:星} is a \izs{527:天体}など．}残りの2.1\%はhas-a関係
\footnote{has-a関係とは，全体部分関係を示している．例えば，
\izs{0555:顔} has a \izs{0571:耳}など．}である．


\subsection{画像付与実験対象語} \label{sec:all-lxd-target}

\lxd{}の内容語（一般名詞，サ変名詞，動詞，形容詞類，副
詞類）のエントリを画像付与実験の対象とした．
ただし，檜オントロジ構
築時と出版時のバージョンの違いにより檜オントロジや意味クラス等の付加情報が
付与されていないエントリは，これらの情報との関係分析が行なえないため対象外とした．
その結果，画像付与実験の対象語は，25,481 語，39,251 語義となっ
た．
\lxd{}出版版の収録語のうち内容語は，27,787 語，47,106 語義であるた
め，今回の対象語により，語単位で91.7\%，語義単位で83.3\%をカバー
することになる．

\begin{table}[b]
\caption{対象語数と品詞内訳}
\label{tb:lxd-all-target}
\input{07table01.txt}
\end{table}


表~\ref{tb:lxd-all-target}に，対象語全体の数を品詞毎に示す．ただし，名詞は，すべ
ての語義が\izs{1000:抽象}配下，すべての語義が\izs{2:具体}配下，
\izs{1000:抽象}配下と\izs{2:具体}配下の両方含む，および，サ変名詞に分割
し，それらの小計も表示
している．ここで，\izs{2:具体}配下かどうか等は，\lxd{}の各語義
にリンクされた意味クラスで分類している．例えば，図~\ref{fig:arch-lxd}の
「アーチ$_1$」には意味クラス\izs{865:家屋（本体）}と\izs{2435:類型}が付与さ
れており，それぞれ\izs{2:具体}配下と\izs{1000:抽象}配下にあるため，両
方含む，と分類される．



\section{検索語の拡張} \label{sec:make-query}


\subsection{画像付与予備実験の概要 (\ano)}
\label{sec:pre-exp}

辞書の語義毎に適切な画像をWebから獲得する方法を提
案した予備実験について紹介する．予備実験では，\lxd （図~\ref{fig:arch-lxd}）と
\wpd{}という，非常に傾向の異なる2種類の辞書を対象としているが，本章では，
\lxd を対象とした実験について紹介する．

\ref{sec:introduction}章で述べたように，見出し語（代表表記）のみで画像検索
した場合，最もメジャーな語義の画像しか得られないことが多く，
複数の語義に適切な画像を獲得することは難しい．そこで予備実験では，語
義毎に適切な画像を得るため，あらかじめ検索語を語義毎に拡張し，その効果を
評価した．
予備実験で検索語として利用したのは，次の4通りである．\\
(1) 代表表記のみ (\bl)，
(2) 代表表記と同義語類 (\syn)，
(3) 代表表記と上位語等 (\hyp)，
(4) 基本的に代表表記のみ利用するが，代表表記がひらがなの場合のみ
表記ゆれも利用 (\mono)\footnote{例えば，「たまねぎ」の場合，表記揺れである
「玉葱」も利用する．}． 

また，具体物かどうか，単義語か多義語か，によって傾向と難しさが異なると考
えられるため，\lxd{}の対象語義を次の4つのタイプに分類した．``具体物で単義
語''，``具体物で多義語''，``具体物以外で単義語''，``具体物以外で多義語''
である．本稿と同様，\izs{2:具体}配下の意味クラスだけが付与されている場合
を具体物とした．対象語義は，各タイプからランダムに50語義ずつ選択，合計
200語義について，適切な画像を付与できるかどうか，また，どの検索語がより良
い画像を得るのに有効かを調べた．

\subsubsection{予備実験結果の概要}
\label{sec:pre-exp-conclusion}

予備実験では，\bl{}，\syn{}，\hyp{}，\mono{} のそれぞれの検索語によって
獲得した画像\footnote{画像検索は，2009年9月に実施．}を人手評価した．
その結果，以下のようなことがわかった．
\begin{itemize}
 \item いずれのタイプに対しても\syn{}の方が\hyp{}による画像より適合率が
高い．つまり，同義語類の方が上位語等より適切な画像に絞る効果がある．
 \item 検索語の拡張は特に多義語に対して効果が高い．
 \item 逆に具体物の単
義語の場合，\syn{}，\hyp{}共に適合率は\bl{}より下がる．これは，単
義語の具体物の場合，対象語義自体がメジャーな語義になるため，拡張するとむ
しろ典型的な画像が獲得できなくなるためだと考えられる．
 \item 具体物の単義語でも，\mono{} だけ
は\bl{}より良くなる．つまり，ひらがな以外の語の利用は，語義を絞る上で効果が
ある．
 \item 検索で得られた画像の適合率は，各タイプの語義に対して，
``具体物で単義語''の場合\mono{}で 87.7 \%，
``具体物で多義語''の場合\syn{}で 69.2 \%，
``具体物以外で単義語''の場合\mono{}で 66.7 \%，
``具体物以外で多義語''の場合\syn{}で 66.3 \%だった．
\end{itemize}

また，画像獲得がうまくいかなかった原因を調べた結果，以下のようなことがわかった．
\begin{itemize}
 \item 多義語でもメジャーな語義に対しては，単義語と同様拡張しないほうが
       よい．
 \item 拡張に使った語の語義がマイナーだった場合，メジャーな語義の画像が
       得られて適合率が下がるため，マイナーな語義は拡張に使わない方がよ
       い．
\end{itemize}


本稿では，こうした予備実験の結果を反映して，検索語セットの作成
（\refsec{sec:queryset}），および，優先順位の決定方法を提案する
（\refsec{sec:query-order}）．


\subsection{検索語セットの作成方法}
\label{sec:queryset}

\refsec{sec:pre-exp}の結果から，
特に多義語の場合，複数の語義に適切な画像を獲得する
ためには，検索語の拡張が有効であることがわかっている．
また，同義語類による拡張が，適切な画像を獲得するために有効な
ことがわかっている．しかし，同義語類はすべての語義で得られるわけではな
い．また，他の関連語の効果もより詳細に調査し
，今後の改良につながる知見を得たい（第二の目標）．
そのため，本稿では
辞書から得られるできるだけ多くの関連語から検索語セットを作成，比較する．
検索語セットに利用する情報は以下の通りである．


\subsubsection{見出し語：代表表記と表記ゆれ（\refsec{sec:lexeed}参照）}

代表表記は，\lxd{}では必ず一つ以上記載されており，
最も代表的な表記と考えられる．そこでまず，代表表記のみを用いた検索語セット
を作成する（以下，$q_{代表}$）．
単義語の場合など，拡張しない方が良い検索結果が得られる場合が考
えられるためである．


また，代表表記がひらがなの場合は漢字の表記ゆれを追加し，ひらがな以外の場
合は代表表記のみを用いた検索語セットを用意する（以下，$q_{基本}$）．これは，
予備実験の\mono{}にあたり，曖昧性を軽減するのに有効だったためである．以
降の検索語セットはすべて，$q_{基本}$に1 語追加して作成する．例えば，「たま
ねぎ」の場合，$q_{代表}$は「たまねぎ」，$q_{基本}$は「たまねぎ」「玉葱」
となる．
$q_{基本}$で利用しなかった表記ゆれは，同音異表記の同義語といえるため，
檜オントロジの同語義と同様に扱う．
なお表記ゆれは，全エントリに記載されているわけではなく，49,245エントリ中，11,083語にのみ存
在した．


\subsubsection{檜オントロジ（\refsec{sec:lexeed}参照）}

檜オントロジでは，定義文から獲得した同義語，分野情報，上位語など
の関連語を，語義ごとに抽出している．これらの関連語1語ずつを$q_{基本}$に追
加することで，検索語セットを作成する（以下，$q_{関連語}$）．
\refsec{sec:pre-exp}の結果から，特に多義語では，関連語（特に同義語）による
検索語の拡張が有効であることがわかっているが，
関連語ごとに検索語セットを作成・比較することで，適切な画像を獲得す
るために有効な検索語の特徴を詳細に調査する．
なお，関連語は檜オントロジでは語義番号を含めた語義として抽出されているが，
検索語セットでは語義番号は含めず，語として利用する．
表~\ref{tb:hinoki-ont-data-new}に，利用する檜オントロジの内訳を示す．

\begin{table}[t]
\caption{檜オントロジの内訳}
\label{tb:hinoki-ont-data-new}
\input{07table02.txt}
\end{table}

檜オントロジは，対象語義側から関連語を参照する（以下，順方向）ように構築され
ているが，カバー率をあげるため，本稿では逆方向の参照も行なう（以下，逆方向）．
例えば，「アーチ$_3$」の同義
語は「ホームラン$_1$」なので，逆に「アーチ$_3$」を「ホームラン$_1$」の同
義語として用いることができる．


\subsubsection{定義文中，例文中の特徴的な語}

 定義文中，および，例文中に出現する内容語のうち特徴的な語を$q_{基本}$に追
 加する（以下，$q_{定義文}$，$q_{例文}$）．そうした語は語義
 を特徴付け，適合率の高い画像を得るのに有効な可能性があると考えたためであ
 る．
特徴的かどうかは，各語の\tfidf{} \cite{Tokunaga:1999j}によって決定する．
\tfidf{}の計算は，式(\ref{s:tfidf})を用いる．
\begin{equation}
 \mathit{tf}\cdot\mathit{idf}_{i,j} =  \frac{n_{i,j}}{\sum_{k}^{} n_{k,j}}\times \log {\frac{D}{df_i}}
 \label{s:tfidf}
\end{equation}
ここで，$n_{i,j}$ は，文$j$中で，ある語義$_i$の出現する回数，
 $\sum_{k}^{} n_{k,j}$は，文$j$に含まれる内容語の数，
 $D$は全文数，$df_i$は語義$_i$の出現する文の数を表している．
\tfidf{}の計算は，定義文と例文で別個に行ない，
檜オントロジですでに関係が獲得されている語を除き，
最も\tfidf{}の高い語をそれぞれ検索語の拡張に利用した．
例えば「アーチ」（図~\ref{fig:arch-lxd}）の場合に得られる
$q_{定義文}$と$q_{例文}$は表~\ref{tb:tfidf}の通りである．
ここで， 「アーチ$_3$」で$q_{定義文}$がないのは，定義文中の内容語がすべ
 て，檜オントロジですでに関係が獲得されているためである．

\begin{table}[t]
\caption{「アーチ」（図~\ref{fig:arch-lxd}）の定義文／例文から得られる検索語セット} 
\label{tb:tfidf}
\input{07table03.txt}
\end{table}


 \subsubsection{検索語セットに利用しない語}

 前述の情報を用いて検索語セットを作成するが，以下の様な語は利用しない．
 \begin{itemize}
 \item 同じ見出し語の語義間で共通する語は用いない．\\
語義間で共通する語では，別の語義に関連する画像が
得られる可能性があるためである．
       例えば，「口紅$_1$」 \gogi{化粧品の一種。唇に\ul{塗る}\ul{紅}。…}
       と，「口紅$_2$」 \gogi{物の周り、特に陶磁器の周囲に赤い色を\ul{塗る}こと。また、そ
 の\ul{紅}。} の場合，「塗る」「紅」は両方の定義文に出現するため利用しない．

 \item 低頻度語義は利用しない．\\
ここで低頻度語義とは，語としては一定回数以上出現するにも関わらず，
その語義としてはほとんど利用されない語義である．低頻度語義を利用すると，意図
した語義ではなく，同じ見出し語のもっとメジャーな語義に関する画像が得られ
る可能性があるためである．本稿では，檜センスバンク全体で5回以上出現する語
にも関わらず，自分自身の例文以外には利用されていない語義を低頻度語義とし
た．
逆に，語としての出現回数が少ない場合でも，
例えば100 \%対象語義として利用されているような場合，意図した語義以外の画像が得
       られる可能性は低いため，対象外とする必要はないと判断した．\\
 例えば，「アイス」は檜センスバンク全体で9回出現するが，
「アイス$_3$」\gogi{高利貸し$_1$ ．}の語義はほ
 とんど出現しない．
 檜オントロジでは，「高利貸し$_1$」は，「アイス$_3$」の順方向の
同義語として獲得されており，「アイス$_3$」の検索語の拡張に利用する．しかし，
 逆に「高利貸し$_1$」の拡張に「アイス$_3$」を利用することはない．

 \item 見出し語側に完全に含まれる語は利用しない．\\
冗長だと考えられるためである．\\
 例えば，「アイス$_1$」は「アイスキャンデー$_1$」の同義語だが，完全に含
       まれるので，利用しない．


  \item 檜オントロジで関係が「部分全体」「分野」の場合，逆方向に参照され
	た語は利用しない．\\
	同義語類とは異なり，逆方向では同じ関係にならないためであ
	る．\\
  例えば，「アーチ$_3$」の分野として「野球$_1$」が獲得
  されているが，「野球$_1$」の拡張に「アーチ$_3$」は利用しない．

 \end{itemize}


\subsection{検索語セットの優先順位}
\label{sec:query-order}

\begin{figure}[b]
\input{07figure02.txt}
\caption{検索語セットの優先順位決定方法}
\label{fig:query-order}
\end{figure}
\begin{table}[b]
\caption{検索語セットと優先順位の例} 
\label{tb:query-set-arch}
\input{07table04.txt}
\end{table}


\refsec{sec:queryset}では検索語セットの作成方法を述べた．この方法では複数
の検索語セットが作られる．
人手で画像付与を行なう場合，これらの検索語セットによる検索結果
をすべて表示し，最も良い画像を選べば良いだろう．
しかし，辞書のエントリが増えた場合や，
他の辞書に画像を付与したい場合など，
いつでも人手で画像付与ができるわけではない．そのため，
デフォルトで利用する検索語セットを設定し
ておくことは重要である．そこで本稿では，
予備実験（\refsec{sec:pre-exp}）の結果とヒューリスティックスから，
複数の検索語セットの優先順位を決定する方法を提案する（図~\ref{fig:query-order}）．
付与した優先順位，特に最も高い優先順位を与えたものがよかったかどうかは，
後の実験で検証する．
また，検索語セットと優先順位の例を表~\ref{tb:query-set-arch}に示す．


\section{実験方法}
\label{sec:all-lxd-exp}

本章では，対象語義に適切な画像を付与する実験手順について述べる\footnote{実験は，google画像検索を利用して，2011年1月から12月にかけて実施した．}．
\refsec{sec:exp-steps}では，画像付与，および，評価の手順について，
\refsec{sec:exp-eva}では，画像自体の評価基準について述べる．


\subsection{画像付与・優先順位の妥当性評価方法}
\label{sec:exp-steps}

本稿では，複数の検索語セットを用意し，それらに優先順位を付与する方法を提
案した．そこでまず，第三の目標としてあげたように，付与した優先順位の妥
当性を評価する．特に，自動的に画像を付与する場合，最も優先順位が高くなっ
た検索語セット（以下，\best{}）を用いて適切な画像が得られるかどうかが重要で
ある．

\begin{figure}[b]
\input{07figure03.txt}
\caption{評価方法：\evaR{}}
\label{tb:eva-method-rand}
\vspace{-1\Cvs}
\end{figure}

そこで，検索語セットの提示方法として2通りの方法を試し，結果を比
較する．つまり，すべての検索語セットによる検索結果をランダムに表示する方
法（\evaR{}，図~\ref{tb:eva-method-rand}）と，\best{}による検索結果を最初
に表示し，その段階で高い評価の画像が十分獲得できれば，他の検索語セットは
利用しない方法（\evaB{}，図~\ref{tb:eva-method-best}）である．いずれの方法
でも，用意した検索語セットでは適切な画像が得られない場合，作業者に自由に
検索語を修正してもらう（図~\ref{tb:eva-method-rand}，Step 2-1）．
なお，そもそも画像表示できない語義の場合，どのような方法であっても画像を
付与できないため，そのような語義かどうかを判断する箇所も設けてある
（図~\ref{tb:eva-method-rand}，Step-1）．

\begin{figure}[b]
\input{07figure04.txt}
\caption{評価方法：\evaB{}}
\label{tb:eva-method-best}
\end{figure}
\begin{figure}[b]
\input{07figure05.txt}
\caption{画像の適合度評価例}
\label{tb:eva-ex}
\end{figure}

比較に用いるのは，10,500語義\footnote{10,500語義の品詞割合は，名詞（\izs{2:具体}）
20.5\%,名詞（\izs{1000:抽象}）27.6\%, 名詞（両方）15.7\%, サ変名詞13.5\%, 動詞13.7\%, 形容詞類 4.8\%, 副詞類 4.3\%}ずつ，合計21,000語義であ
り，作業者は各語義につき一人である．
画像の適合度評価（図~\ref{tb:eva-method-rand}，Step 3）まで含めた作業
にかかる時間は，用意した検索語セットから選択する場合，1語義につき平均約
3分，作業者が検索語を修正する場合，平均約 4分と報告されている．


\subsection{画像の適合度評価}
\label{sec:exp-eva}

図~\ref{tb:eva-method-rand}のStep 3において，作業者には，各語義5枚の画像を
選択してもらい，各画像の適合度を評価してもらった．評価値は，1--5の5段階
であり，数字が大きい方が適合度が高い．なお，画像表示可能と評価された語義
には，評価値3以上の画像が少なくとも1枚以上付与されるように作業している．
図~\ref{tb:eva-ex}に評価例を示す．


\section{優先順位の妥当性の評価}
\label{sec:ana-rand-best}


本章では，提案した優先順位，特に，\best{}が妥当かどうかを評価する（第三の
目標）．そのため，\evaR{}と\evaB{}のそれぞれの場合で最終的に選択された検索
語セットの優先順位を比較する．比較のため10,500語義ずつを選び，それぞれの
方法によって作業を行った．選択された検索語セットの優先順位の占める割合を
図~\ref{fig:used-query-order}に示す．なお，画像表示が出来ないと判断された
語義は除いて集計した．
両者の対象語義は異なるので厳密な比較はできないが，各評価における対象語義の
品詞割合は同じであり
傾向調査としては十分な量であると考える．

\begin{figure}[b]
\begin{center}
\includegraphics{20-2ia7f6.eps}
\end{center}
\small
ここで，\sel{}は全拡張語候補中から作業者が検索語を選び直した場合，\added{}は作業者により検索語が追加された場合，\fixed{}は全組合せ中にない検索語が用いられた場合を示す．
\vspace{0.5\Cvs}
\caption{画像獲得のために利用された検索語セットの優先順位：\evaR{}と\evaB{}の比較}
\label{fig:used-query-order}
\end{figure}

図~\ref{fig:used-query-order}から，\evaR{}でも\evaB{}でも，最も多く利用さ
れた検索語セットは，\best{}，つまり，最も良いと予想した検索語セットである
ことがわかる．検索結果はStep-1ではランダムに表示されており，作業者には優
先順位はわからないにも関わらず，利用された検索語セットの割合は優先順位の
通りになっている．そのため，提案した検索語セットの優先順位は妥当だといえ
る．

さらに，\evaB{}の場合，\best{}が利用された割合は，\evaR{}の場合より非常に
高い（全体で，+23 \%）．これは，最初に\best{}を表示し，そこで十分な画像が
獲得できれば，終了しているためである．つまり，ランダムに表示すれば，同じ
くらいよい結果があれば他の検索語セットを利用する可能性があるが，\best{}を
先に表示することで，\best{}で十分だと判断されることが多くなっているのだと
考えられる．
つまり，特に，人手で画像付与ができずに自動的な検索結果を用いる場合，デフォ
ルトの検索語セットとして\best{}を利用しておくことは妥当であるといえる．


\section{検索語に関する分析}
\label{sec:all-lxd-analysis}

本章の目的は，最終的に利用された検索語の調査である（第二の目標）．
検索を行なう場合に，どのような検索語を利用すれば良いかは重要な問題である．
\ref{sec:ana-rand-best}章では，提案した優先順位の決定方法の妥当性を示した
が，\evaB{}の場合でも，全体の46.6\%は \best{}以外の検索語
が利用されている．そこで本章では，最終的に利用された検索語をより詳細に調
査し，できれば改良につながる知見を得たい（\refsec{sec:ana-query}，
\refsec{sec:ana-add-fixed}）．また，利用された検索語を手がかりに
センスバンクや語義親密度との関係分析も行なう（\refsec{sec:judge-major}）．

本稿では，\ref{sec:ana-rand-best}章
で比較のために\evaB{}を用いた10,500 語義以外は，\evaR{}によって画像付与実験
を行なっている．
そこで本章では，評価方法の違いによるバイアスを避けるため，\evaR{}に
よる画像付与実験結果を対象に，最終的に利用された検索語を分析する
\footnote{ただし，すべての語義を対象として同様の分析を行なっ
た場合でも，傾向はほぼ変わらなかった．}．


\subsection{利用された検索語セット}
\label{sec:ana-query}

\evaR{}における評価実験で，作業者によって最終的に選択された検索語セットの
内訳を図~\ref{fig:used-query}に示す．図~\ref{fig:used-query}による
と，図~\ref{fig:query-order}で定義した\MONO{}と\MAJOR{}の場合，最も利用
されている検索語セットは代表表記のみを用いたものであり，それぞれ
44.9\%，31.3\%を占める．\MINOR{}の場合でも，12.9\%は代表表記のみが用いられている．多義語にも関わらず代表表記のみで検索さ
れている語義は，少なくとも画像検索では最も出現頻度が高い語義であるといえ
るだろう．なお，代表表記のみが利用された場合の分析は
\refsec{sec:judge-major}で行なう．

\begin{figure}[b]
\begin{minipage}{212pt}
\includegraphics{20-2ia7f7.eps} 
\caption{画像獲得に利用された検索語セットの内訳}
\label{fig:used-query}
\end{minipage}
\hfill
\begin{minipage}{188pt}
\setlength{\captionwidth}{188pt}
\begin{center}
\includegraphics{20-2ia7f8.eps} 
\end{center}
\hangcaption{図~\ref{fig:used-query}の作業者による\added{}，\fixed{}，\sel{}で利用された検索語の内訳}
\label{fig:used-query-fixed}
\end{minipage}
\end{figure}

\MINOR{}の場合最も多いのは，人手で追加・修正・削除された検索語セットが用
いられた割合であり，あわせて約59\%を占める．これは，こうした語義に適切な
検索語セットを自動的に用意することの難しさを示している．\MONO{}や
\MAJOR{}でも人手で追加・修正・削除された場合は多いが，それらを除くと，上
位語，定義文から，同義語，例文からの情報が，よく用いられている．これらの
間には，高々1--2\%程度の差分しかなく，予備実験で得られた結果のように明らか
に同義語の方が良いとはいいがたい．
ただし，すべての語義について同義語が獲得できているわけではないことを考慮
する必要がある．つまり，同義語があれば同義語の方が良いが，ないので上位語
が用いられた可能性もある．そこで，各タイプ毎に，作成された検索語
セットのうち，最終的に利用された検索語セットの割合を
表~\ref{tb:used-query-inall}に示す．

\begin{table}[t]
\caption{作成された検索語セットのうち，実際に利用されたものの割合}
\label{tb:used-query-inall}
\input{07table05.txt}
\end{table}

表~\ref{tb:used-query-inall}によると，同義語を用いて作られた検索語セット
のうち，24.9\%は最終的に利用されている．
また，同義語の一種である略称（正式名称への展開）や別称も利用される割合が高い．
分野情報は作られた数自体が少ないが，
特に\MINOR{}でよく選択されている．
逆に，上位語の場合は，作られた検索語セットのうち，実際に利用されたのは
8.4\%であり，同義語類に比べるとかなり低い割合である．
つまり，同義語が存在する場合には，同義語は比較的利用される割合が高いとい
える．
ただし，\MONO{}，\MAJOR{}，\MINOR{}のそれぞれにおいて，利用され
た検索語セットの割合は相当異なっており，同じ同語義類でも，\MONO{}では同
義語のうち31.6\%が利用
されているが，\MINOR{}では10.2\%に留まり，代わりに略称や別称などが利用
される割合が高くなっている．今後は，優先順位の決定において，タイプ別に
これらの優先順位を決定することも考えられる．


\subsection{人手で追加／修正／選択された検索語}
\label{sec:ana-add-fixed}

図~\ref{fig:used-query}（\refsec{sec:ana-query}）に示した様に，
人手で検索語が追加／修正／選択され
た割合は，それぞれ，21.3\%, 16.1\%, 7.7\%と高い．
これらの，人手によって追加／修正／選択されて作られた検索語セットに
含まれる語
のタイプを分類した（図~\ref{fig:used-query-fixed}）．
検索語セットには複数の語が含まれることがあるが，語毎に分割して
集計してある．同義語類には，同義語，略称，別称などをまとめた．

図~\ref{fig:used-query-fixed}によると，新しく追加された語の割合
が最も多い．
次いで，代表表記が利用される割合が高く，定義文，例文からの語が続く．
定義文からの語とは，定義文中に出現する語のうち，檜オントロジでは
同義語や上位語といった関係にない語になる．
また，同義語や上位語などもあり，こうした語や代表表記に，何らか
の語句が追加されているというパターンが多く見られた．

ここで，追加された検索語のトップ10を表~\ref{tb:added-queries}に示す．追加
された語で最も多いのは「イラスト」で，3,612 回と際だって多く追加
されている．「イラスト」が追加された語の品詞を集計すると，多い順
に，動詞 (34.4\%)，サ変名詞 (25.3\%)，名詞\izs{1000:抽象} (19.7\%)と続
いており，特に動作を表すような語義や抽象的な語義に対し，イラスト化された画
像を得るために多く利用されたことが推測できる．それ以外にも，「イメージ」「グ
ラフ」「写真」「図」など，語自体が図や画を想起させる語が多く追加されてい
る．これは画像検索ならではの特徴だと思われる．

\begin{table}[t]
\caption{\changed{画像獲得のために追加された検索語のトップ10}} 
\label{tb:added-queries}
\input{07table06.txt}
\end{table}

また，典型的と思われる事物や用法に具体化するための検索語の追加も多く見受けられる．
例えば，
「くたくた$_1$」\gogi{布や衣服などが使い古されて，張りを失い弱くなった様
子．}に対して「服」が追加され，「くたくたになっている服」の画像が選ば
れたり，「災難$_1$」\gogi{不意に起こる不幸な出来事．}に対し，「事故」が
追加され，事故場面の写真が選ばれたりしている．



\subsection{代表表記のみで検索された語義}
\label{sec:judge-major}


図~\ref{fig:used-query}（\refsec{sec:ana-query}）によると，
\MINOR{}，つまり，多義語において高頻度語義だと判断しなかった語義でも，
検索には代表表記のみが利用された語
義が12.9\%（1,646 語義）存在する．
同じ見出し語に対し，語義が複数存在するにもかかわらず，代表表記のみ
で検索されているということは，これらの語義は，
少なくとも画像検索では最も出現頻度が高い語義であるといえるだろう．

本実験では，檜センスバンクで5回以上出現する語の，出現率が80\%以上の語義を
高頻度語義としている（\refsec{sec:query-order}参照）．この条件はヒューリス
ティックに設定しており，厳しかった可能性もある．そこで，檜センスバンクに
おける出現率と，多義語のうち代表表記のみが利用された語義の関係を調べる．
図~\ref{fig:major-hyouki}に，多義語のうち10 回以上出現する語についての関係
を示す\footnote{足きりする出現回数を変えても，同様の傾向を示した．}．出現率は10\%単位でまとめて集計してある．

また，檜センスバンクは，新聞と辞書定義文，辞書例文からなるが，これらのコー
パスにおける語義の出現率と人間の感覚は異なっている
可能性も考えられる．本実験で利用した辞書\lxd{}には，語義別の親密度が付与
されており，これは，各語義に対する馴染み深さを心理実験により付与したもの
である．そこで図~\ref{fig:psy-hyouki}に，語義親密度と，多義語のう
ち代表表記のみが利用された語義の関係を示す．
語義親密度は1 から7 の間の値で表わされ，数値が大きくなる
ほど親密度が高い．図~\ref{fig:psy-hyouki}では，1 以上2 未満，2 以上3 未
満というようにまとめて集計してある．

\begin{figure}[b]
\begin{minipage}[t]{183pt}
\setlength{\captionwidth}{181pt}
\includegraphics{20-2ia7f9.eps}
\hangcaption{檜センスバンクにおける出現率と，代表表記のみを検索語に利用した語義の割合} 
\label{fig:major-hyouki}
\end{minipage}
\hfill
\begin{minipage}[t]{178pt}
\setlength{\captionwidth}{176pt}
\includegraphics{20-2ia7f10.eps}
\hangcaption{語義親密度と，代表表記のみを検索に利用した語義の割合}
 \label{fig:psy-hyouki}
 \end{minipage}
\vspace{-1\Cvs}
\end{figure}

まず図~\ref{fig:major-hyouki}から，基本的には，センスバンクでの出現率が高
ければ高いほど，代表表記のみが利用される割合も高くなっていることがわかる
\footnote{センスバンクにおける出現率と代表表記のみ利用された語義の相関係
数は，0.35であり，弱い相関があると言える．}．そのため，デフォルトの検索語
セットを用意する場合，出現率が高い語は代表表記のみを利用するのは妥当と言
えるだろう．

しかしながら，図~\ref{fig:major-hyouki}からは，センスバンクでの出現率が高
ければ必ず代表表記のみが用いられたわけではないこともわかる．
出現率が90 \%以上と非常に高い場合であっても，代表表記のみ検
索に利用されたのは該当する語義の53 \%程度であり，残り47 \%程度は異なる検
索語が利用されている．

出現率が高いにも関わらず，代表表記以外で検索されている語を確認したところ，
語からイメージされる，代表的シーンを示す様な検索語が利用されていることが
多かった．例えば，「悔やむ$_1$」の場合は「悔やむ，マウンド」，「封鎖$_1$」
の場合は「事件現場」が利用されている．
両方，センスバンクでの出現率は100 \%である．


逆に，出現率が低い（10 \%以下）にも関わらず，代表表記で検索されている語も存
在する．例えば，「チェック」の6つの語義のうち，代表表記のみが検索に用いら
れているのは，「チェック$_3$」\gogi{洋服地の碁盤の目のような柄．}である．
この語義の出現率は，2.1\%（96回のうち2回）と非常に低い．それに対し，最も
出現率の高い(89 \%)語義は，「チェック$_6$」\gogi{照合の印を付けること．ま
た，その印．また，照合して検査すること．}であるが，検索語は作業者による自
由修正によって，「チェックマーク，イラスト」が用いられている．なお，
「チェック$_3$」の語義親密度は4.225，「チェック$_6$」の語義親密度は5.300
であり，語義親密度についても「チェッ\mbox{ク$_6$」}の方が高かった．


同様に語義親密度との関係（図~\ref{fig:psy-hyouki}）でも，基本的に，
語義親密度が高くなれば代表表記のみが利用される割合は高くなる\footnote{語
義親密度と代表表記のみ利用された語義の相関係数は，0.27であり，弱い相関が
あると言える．}．
ただし，やはり例外も存在する．
語義親密度が低いにも関わらず代表表記のみが利用されている語を
調べると，語義の親密度以外に，その語義に関連する画像の存在する量も影響し
ている可能性がある．
例えば，「縄張り$_2$」 \gogi{建築の敷地に縄を張って建物の位置を定めるこ
と．}は，語義親密度が1.825 とかなり低いが，代表表記のみが利用されている．
「縄張り$_2$」は家を建てる時に行なわれ，記念，記録として撮られたらしい
写真が多く存在する．
逆に，「縄張り」の
中で，最も親密度が高い語義は，「縄張り$_5$」\gogi{動物の個体や集団が，他
の侵入を許すまいと努める地域．テリトリー．}
（語義親密度 5.225）だが，こちらは比較的画像で表しにくく\footnote{本実験で
は，犬などがテリトリーの匂い付け行動をしている写真などが付与されている．}，
関連する画像の量自体が少ないのだと思われる．

つまり，画像検索での出現率と，人間のその語義に対する親密度，あるいは，
センスバンクでの出現率は，関連はするものの，完全一致ではなく，
画像として表現しやすいかどうか，画像として残されやすいかどうか，という条
件を加味しなければ，
画像検索に代表表記のみを利用すればよい語義を正確に推定することはできないだろう．



\section{画像表示可能／不可能な語義の分析}
\label{sec:ana-cannot}

\vspace{-0.2\Cvs}
第一の目標として，辞書のほとんどの内容語を対象として
画像付与実験を行なったが，対象語義の中には，そもそも画像表示でき
ない語義も存在している．そのため評価時に，そもそも画像表示可能な語義かど
うかを判断している（\refsec{sec:exp-steps}，図~\ref{tb:eva-method-rand}，
Step 1-2）．これまでの分析では，画像表示可能と判断されたものだけを対象にし
てきたが，本章では，そもそも画像表示可能，あるいは，不可能と判断された語
義はどのような特徴を持つのかを調査する．まず，
\refsec{sec:pos-cannot}では品詞との関係について，\refsec{sec:iz-cannot}で
は意味クラスとの関係について定量的に調査する．また，
\refsec{sec:ex-cannot}では，画像表示不可能な語義の傾向について述べる．


\subsection{品詞と画像表示可能／不可能の関係}
\label{sec:pos-cannot}


本章では，品詞と画像表示可能／不可能と判断された語義の関係について述べる．
図~\ref{fig:pos-cannot}に，画像表示が可能，あるいは，不可能と判
断された語義の品詞毎の割合を示す．
どの品詞でも「可能」と判定された語義が最も多くなった．特に，動詞は97.8\%が「可能」と判断されており，\izs{2:具体}配下の名詞よりも割合が高い．最
も「可能」と判断された語義の割合が少なかったのは，副詞類だが，それでも
60.1\%は「可能」と判断されている．

ただし，本実験は，できるかぎり画像を付与するという方針で行なっているため，
画像表示が「可能」と判断されていても，適合度が高い画像が獲得できていると
は限らない．そこで，画像表示可能と判定された語義に付与された画像のうち，
評価値が5（適切），および，4（適合度\_高）と評価された画像の枚数を
図~\ref{fig:eva4-5}に示した．評価の高い画像を多く獲得できている
ということは，それだけ画像付与が容易な語義であるといえる．実験では，30枚
の検索結果から，各語義につき5枚ずつ，評価の高い画像から獲得するようにして
おり，最大獲得枚数は5枚である．
図~\ref{fig:eva4-5}からは，\izs{1000:抽象}配下の名詞，形容詞類，副詞類の場合，
評価値4以上の画像が1枚も獲得できていない語義が最も多いことがわかる．

\begin{figure}[b]
\begin{minipage}[t]{188pt}
\setlength{\captionwidth}{186pt}
\includegraphics{20-2ia7f11.eps}
\hangcaption{画像表示可能／不可能と判断された語義の割合}
\label{fig:pos-cannot}
\end{minipage}
\hfill
\begin{minipage}[t]{184pt}
\setlength{\captionwidth}{182pt}
\includegraphics{20-2ia7f12.eps}
\hangcaption{画像表示可能な語義に付与された画像のうち，評価値が4（適合度\_高）以上の画像の枚数}
\label{fig:eva4-5}
\end{minipage}
\vspace{-0.5\Cvs}
\end{figure}

評価自体は作業者によってゆれがあるため，各画像について評価値毎の詳細な区
別は難しい\footnote{ランダムに選択した100語義500画像の適合度評
価について，二人の作業者間の一致率を調べたところ，Cohenの重み付きkappa係数は
0.602 となり実質的に一致しているといえた．}．
しかし，このように評価値の高い画像が何枚とれたか，という観点
でみると，品詞と，画像としての表現しやすさとの傾向が良くわかる．「可能」
か「不可能」かという点だけをみると，動詞は非常に「可能」の割合が高い
が，評価値が4の画像が5枚獲得されているのは，24.0\%のみである．
図~\ref{fig:eva4-5}から，評価値の高い画像が獲得できている品詞は，順に，名
詞（\izs{2:具体}），名詞（両方含む），サ変名詞，動詞，副詞類，名詞（\izs{1000:抽象}），
形容詞類となる．


\subsection{意味クラスと画像表示可能／不可能の関係} \label{sec:iz-cannot}

\refsec{sec:pos-cannot}では，品詞と画像表示可能／不可能の関係について調べ
た．ただし，名詞は，\izs{2:具体}配下か，\izs{1000:抽象}配下か，その両方を
含むか，によって分割している．しかし，意味クラスは2,710クラス存在しており，
本章では，さらに詳細な意味クラスとの関係を調査する．

本章では，各語義に付与された意味クラス毎に，その語義が「可能」「不可能」
と判断された数をカウントする．ただし，各語義に複数の意味クラスが付与され
ている場合，すべての意味クラスでカウントしている．例えば，アーチ$_1$の場
合，\izs{865:家屋（本体）}と\izs{2435:類型}が付与されているため，両方でカウ
ントする．

50回以上利用されている意味クラスの中で，属する語義が「可能」あるいは「不
可能」と判断されている割合を調べた．その結果，すべての語義が「可能」と判
断された意味クラスは，\izs{2:具体}配下では，\izs{677:作物}，
\izs{818:衣服（本体）}，\izs{920:出版物}などの23クラス，\izs{1000:抽象}配下では
\izs{1048:絵画}，\izs{2360:天気}，\izs{2498:構造} 
などの7クラスだった．なお，すべての語義が「不可能」
と判断された意味クラスはなかった．

このことから，画像表示が不可能な語義を，属する意味クラスのみから判定するこ
とは難しいが，逆に，いくつかの意味クラスに関しては，新規の語義であっても，
画像表示が可能である可能性は高いといえる．

また，個別の意味クラスだけでなく，配下のすべての意味クラスで，
属する語義がすべて「可能」と判断されている場合もある．
表~\ref{tb:cats-cannot}に，配下の意味クラスに属する語義す
べてが画像表示可能と判断された意味クラスを列挙した\footnote{なお，同様に
すべてが画像表示不可能と判断された意味クラスはなかった．}．こうした意味ク
ラスには，\izs{838:食料}，\izs{671:植物}，\izs{925:目印・象徴物}などが存
在する．画像表示可能かどうかの判別には，個別の意味クラスだけでなく，こう
した階層構造も重要だろう．

\begin{table}[p]
\hangcaption{配下のすべての意味クラスに属する語義が，画像表示可能と判断された意味クラス（累計100回以上出現する意味クラスのみ）}
\label{tb:cats-cannot}
\input{07table07.txt}
\end{table}



\subsection{画像表示不可能な語義の傾向}
\label{sec:ex-cannot}

画像表示不可能と判断された語義として，作業者から報告された語義の傾向は以
下の通りである．

\begin{enumerate}
 \item 否定的な意味をもつ語義
 \item[例]
「干す$_4$」 \gogi{仕事などを与えない．}\\
「無給$_1$」 \gogi{給料が無いこと．給料を支給しないこと．}

 \item 言語表現
 \item [例]
「悪しからず$_1$」 \gogi{悪く思わないで．よろしく．相手の気持ちを考えないで物事をしたときなどに了承を得るために使う言葉．}

 \item 仮定表現
 \item[例]
「ひょっとしたら$_1$」\gogi{もしかすると．ひょっとすると．}

 \item 相対表現
 \item[例]
「絶品$_1$」 \gogi{比べるものが無いほど優れた品物や作品．}\\
「別件$_1$」 \gogi{別の用件．別の事件．}

 \item 内容を厳密には表せない語義（\ul{下線部}の意味が画像で表現でき
       ない）
 \item[例]
「だて眼鏡$_1$」 \gogi{\ul{実際には掛ける必要が無いのに}、お洒落のために掛け
	  る眼鏡．}\\
「テストパイロット$_1$」 \gogi{新しく製造された航空機の\ul{試験飛行をする}パイロット．}
\end{enumerate}

画像表示不可能な語義かどうかの判別の自動化の可能性について考えてみると，
上記(5)の「だて眼鏡$_1$」「テストパイロット$_1$」のような語義では，
自動化は困難だと思われる．

一方，上記(1)から(4)については，語義文からある程度の手がかりは獲得できるかもしれない．
例えば，(2)にあたるものとして，上位語が「言葉」や「語」の語義は「不可能」
と判断される可能性が高いかもしれない．
実際に「不可能」とされたのは，
本稿での対象語のうち上位語が
「言葉」である語義の11.0\%
\footnote{上位語が「言葉」の語義で，「可能」と判断されたのは，「お世辞$_1$」
「見出し$_1$」
「歌詞$_2$」
「気障$_1$」など．逆に「不可能」と判断されたのは，「一言$_2$」
「禁句$_2$」
「殺し文句$_1$」
「片言$_1$」など．}
，「語」である語義の25.7\%\footnote{上位語が「語」の
語義で，「可能」と判断されたのは，
「謙譲語$_1$」
「流行語$_1$」
「反意語$_1$」
「結び$_3$」など．
逆に「不可能」と判断されたのは，
「ご存じ$_1$」
「良く$_5$」
「むしろ$_1$」
「何なら$_1$」など．}
だった．この割合は，全体の割合に比べればかなり高い
が（図~\ref{fig:pos-cannot}），必ず「不可能」と判断されたわけでもない．
なお，これらの語義で，「可能」と判断された語義には，
その語が利用される典型的なシーンの画像が付与されることが多かった．


\subsection{画像の多様性}
\label{sec:disc-diver}

本章ではこれまで画像表示が可能かどうか，といった観点で調べてきたが，「可
能」と判断された語義の中にも，一つの画像だけでなく，多様な画像が求められ
る場合がある．

例えば，同じ\izs{537:獣}という意味クラスに含まれる語であっても，
「シロナガスクジラ$_1$」ならシロナガスクジラの画像のみだが，
「家畜$_1$」は，豚，鶏，牛など，複数種類の動物の画像が付与されている．
どれか一種類の動物の画像だけであれば，「家畜$_1$」がその動物を指すのだと
いう誤解を招くおそれがあるが，複数種類の動物の画像を付与することで，
これらすべてを含むような概念であるとわかる．

また，「牛$_1$」のような場合でも，細分類すると，白黒の斑のあるホルスタイ
ン種，茶色いジャージー種，黒毛の和牛など様々な種類があり，本実験にお
いても出来る限り多くの種類の画像が付与されている．
このように，一つの語義に対して複数の画像を付与するのは，イメージの固定化
を防ぎ\cite{Suwa:Miyabe:Yoshino:2012j}，対象語義の範囲を
示す上で重要だと思われる．

また，より具体的な下位概念の方が
適切な画像を付与しやすい場合も多い．
作業者によって検索語に追加された語に，
対象語義を典型的と思われる事物や用法に具体化するための語句が多く含まれた
のもそのためだろう（\refsec{sec:ana-add-fixed}）．
\cite{Popescu:Millet:etc:2007} では，\WN{}のある対象synset 配下のリーフ
ノードのみを画像付与の対象にしており，上位synset は上下関係から間接的に
カバーされると述べられている．
同様に，動植物など一部の上下関係に対しては，より具体性の高い下位語義（概
念）に対して画像を付与し，
上位概念はその集合として扱うことも可能かもしれない．
こうした方法は，作業量の削減や画像の多様性確保に効果がある可能性がある．
ただし，抽象的な概念への適用はかなり難しいと考えられるため，適用範囲に
注意する必要がある．


\section{まとめと今後の課題}
\label{sec:conclusion}


画像が付与された辞書は，教育分野や言語横断検索での利用，子供や異なる言語
の話者，文字の認識に困難を伴うような人とのコミュニケーションを助けるツー
ルの構築，セマンティックギャップを埋めるための研究利用など，様々な用途が
考えられる．

作成・維持コストを考えれば，なるべく自動的に画像を付与することが望ましい
が，大量の辞書エントリに対して，高い精度で画像を付与することは容易ではな
い．また，そもそもどういった語義には画像を付与できるのか，あるい
はできないのかといった調査が大規模になされた例はなく，画像が付与できる語
義を自動的に判別することも困難である．


そこで，まず語義別に画像が付与された辞書を人手で構築す
ることを第一の目標とした．
幅広い語義に適切な画像を付与するため，インターネットから画像検
索によって画像を獲得する．
そこで，語義毎に適切な画像を得るための検索語を調査す
ることを第二の目標とした．
さらに，本稿では検索語セットの優先順位の決定方法も提案した．
今後の作成・維持コストや，新しい辞書への適用を考えると，人手による画像付与が
できない場合でも，優先順位の高い検索語セットによる検索結果が利用できれば，
有用だと考えられるからである．
そのため，
提案した優先順位の決定方法の妥当性を示すことを第三の目標とした．


まず第一の目標に関して，本稿全体では，辞書\lxd{}
の名詞，動詞，形容詞，副詞類の25,481語，39,251語義を対象として，画像付与
実験を行なった．
その結果，対象語義全体の 94.0\% に画像付与が可能と判断され，画像が付与できた．
構築した辞書を用いて，\ref{sec:ana-cannot}章では，
画像付与が可能／不可能な語義の特徴を，品詞との関係や
意味クラスとの関係に着目して調査した．
品詞との関係では，語義との適合度が高い画像が獲得できた品詞は，順に，
名詞（\izs{2:具体}），名詞（両方含む），サ変名詞，動詞，副詞類，名詞（\izs{1000:抽象}），
形容詞類であることを示した．
意味クラスとの関係分析では，意味クラスによってはほぼ確実に画像
付与可能なクラスが存在し，さらに，画像付与が可能かどうかの判断には階層構造
も考慮することが有効だと思われることを示した．

第二，第三の目標は，辞書の構築過程に関係している．

本稿では，語義毎に，上位語や同義語，例文中の語など，辞書から得られる様々
な語を用いた検索語セットを用意し，それらに優先順位を付与する手法を提案し
た．提案手法では，対象語義が単義語や多義語のメジャーな語義の場合には代表
表記のみを利用した検索語セットを優先させ，それ以外の語義の場合は同義語に
よって拡張した検索語セットを優先させた．
本稿では，用意した検索語セットによる検索結果
を作業者に提示し，最も適切な検索語セットを選択してもらった．
ここで，2 通りの提示方法を試すことで，
デフォルトとして自動的な検索結果を表示する場合でも，最も優先順位の高い検索語
セットによる検索結果を利用することが妥当であることを示した
（\ref{sec:ana-rand-best} 章，第三の目標）．


第二の目標に関しては，最終的に作業者によって選択された検索語を分析するこ
とで改良点を探った（\ref{sec:all-lxd-analysis} 章）．その結果，同義語類，分
野情報は検索語として選択されやすいことや，メジャーな語義かどうかによって
優先順位の決定方法を改良すればよいことがわかった．こうした知見は，今後追
加されるエントリや，新しい辞書への適用時に有効である．


また，検索語については更に2種類の分析をおこなった．まず，適切な検索語セッ
トが候補にない場合に，追加・修正された検索語の分析を行なった．その結果，
追加された検索語には，「イラスト」や「イメージ」など，語自体が図や画を想
起させる語や，典型的と思われる事物や用法に具体化するための語が多く含まれ
ることがわかった．

さらに，多義語であるにも関わらず，代表表記のみが検索語として利用された語
義は，少なくとも画像検索においては最頻語義だと考えられるという点に着目し，
こうした語義のセンスバンクでの出現率，語義親密度との関連性についても分析
した．その結果，センスバンクでの出現率や語義親密度と，画像検索における最
頻語義は相関関係があるが，完全一致ではなく，画像として表現しやすいか，画
像として残されやすいかどうか，という条件を加味しなければ，
画像検索における最
頻語義を正確に推定することは困難であることがわかった．



このように，本稿では，様々な品詞を含む幅広い語義に対して画像を付与する実
験と分析を行なった．
今後はさらに，画像研究者と協力し，色や輪郭などの画像自体の特徴と言語的特徴の両面から，
語義と画像の関係分析を行なっていきたい．

また，提案した検索語セットは，語義曖昧性解消のための学習データ獲得
にも利用できるかもしれない．例えば，単義の同義語によって検索語を拡張し，
Web検索によって得られた文を訓練データとして利用する方法も提案されている
\cite{Mihalcea:Moldovan:1999,Agirre:Martinez:2000}．同様に，本稿での提案
手法によって優先順位が高くなった検索語セットや，作業者によって選ばれた検
索語セットを用いて\footnote{ただし，作業者によって追加された語で，「イメー
ジ」のように画像検索特有だと思われる語を除く必要はある．}学習データを獲得
した場合，語義曖昧性解消の精度向上に貢献できるかどうか調査したい．





\bibliographystyle{jnlpbbl_1.5}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Agirre \BBA\ Martinez}{Agirre \BBA\
  Martinez}{2000}]{Agirre:Martinez:2000}
Agirre, E.\BBACOMMA\ \BBA\ Martinez, D. \BBOP 2000\BBCP.
\newblock \BBOQ {Exploring Automatic Word Sense Disambiguation with Decision
  Lists and the Web.}\BBCQ\
\newblock In {\Bem Proceedings of COLING-2010 Workshop on Semantic Annotation And Intelligent},
\mbox{\BPGS\ 11--19}.


\bibitem[\protect\BCAY{天野\JBA 小林}{天野\JBA
  小林}{2008}]{Amano:Kobayashi:2008j}
天野成昭\JBA 小林哲生 \BBOP 2008\BBCP.
\newblock \Jem{基本語データベース：語義別単語親密度}.
\newblock 学習研究社.


\bibitem[\protect\BCAY{Bond et~al.}{Bond
  et~al.}{2006}]{Bond:Fujita:Tanaka:2006}
Bond, F., Fujita, S., \BBA\ Tanaka, T. \BBOP 2006\BBCP.
\newblock \BBOQ {The Hinoki Syntactic and Semantic Treebank of Japanese.}\BBCQ\
\newblock {\Bem Language Resources and Evaluation}, {\Bbf 40}  (3--4),
  \mbox{\BPGS\ 253--261}.
\newblock (Special issue on Asian language technology).

\bibitem[\protect\BCAY{Bond et~al.}{Bond
  et~al.}{2009}]{Bond:Isahara:Fujita:Uchimoto:Kuribayashi:Kanzaki:2009}
Bond, F., Isahara, H., Fujita, S., Uchimoto, K., Kuribayashi, T., \BBA\
  Kanzaki, K. \BBOP 2009\BBCP.
\newblock \BBOQ {Enhancing the Japanese WordNet.}\BBCQ\
\newblock In {\Bem Proceedings of the Joint conference of the 47th Annual
  Meeting of the Association for Computational Linguistics and the 4th
  International Joint Conference on Natural Language Processing of the Asian
  Federation of Natural Language Processing: ACL-IJCNLP-2009}, \mbox{\BPGS\
  1--8}.

\bibitem[\protect\BCAY{Bond et~al.}{Bond et~al.}{2004}]{Bond:Nichols:Fujita:Tanaka:2004}
Bond, F., Nichols, E., Fujita, S., \BBA\ Tanaka, T. \BBOP 2004\BBCP.
\newblock \BBOQ {Acquiring an Ontology for a Fundamental Vocabulary.}\BBCQ\
\newblock In {\Bem Proceedings of the 20th International Conference on
  Computational Linguistics: COLING-2004}, \mbox{\BPGS\ 1319--1325},\ Geneva.

\bibitem[\protect\BCAY{Borman et~al.}{Borman et~al.}{2005}]{PicNet}
Borman, A., Mihalcea, R., \BBA\ Tarau, P. \BBOP 2005\BBCP.
\newblock \BBOQ {PicNet: Pictorial Representations for Illustrated Semantic
  Networks.}\BBCQ\
\newblock In {\Bem Proceedings of the AAAI Spring Symposium on Knowledge
  Collection from Volunteer Contributors}.

\bibitem[\protect\BCAY{Deng et~al.}{Deng et~al.}{2009}]{ImageNet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., \BBA\ Fei-Fei, L. \BBOP
  2009\BBCP.
\newblock \BBOQ {ImageNet: A Large-Scale Hierarchical Image Database.}\BBCQ\
\newblock In {\Bem IEEE Computer Vision and Pattern Recognition (CVPR)}, 
pp. 248--155.

\bibitem[\protect\BCAY{Fang \BBA\ Zhai}{Fang \BBA\ Zhai}{2006}]{Fang:Zhai:2006}
Fang, H.\BBACOMMA\ \BBA\ Zhai, C. \BBOP 2006\BBCP.
\newblock \BBOQ Semantic term matching in axiomatic approaches to information
  retrieval.\BBCQ\
\newblock In {\Bem Proceedings of the 29th annual international ACM SIGIR
  conference on Research and development in information retrieval}, SIGIR '06,
  \mbox{\BPGS\ 115--122}, ACM.

\bibitem[\protect\BCAY{Fellbaum}{Fellbaum}{1998}]{_Fellbaum:1998}
Fellbaum, C.\BED\ \BBOP 1998\BBCP.
\newblock {\Bem {WordNet}: An Electronic Lexical Database}.
\newblock MIT Press.

\bibitem[\protect\BCAY{Fujii \BBA\ Ishikawa}{Fujii \BBA\
  Ishikawa}{2005}]{Fujii:Ishikawa:2005a}
Fujii, A.\BBACOMMA\ \BBA\ Ishikawa, T. \BBOP 2005\BBCP.
\newblock \BBOQ {Image Retrieval and Disambiguation for Encyclopedic Web
  Search.}\BBCQ\
\newblock In {\Bem Proceedings of the International Joint Conference on
  Artificial Intelligence: IJCAI-2005}, \mbox{\BPGS\ 1598--1599}.


\bibitem[\protect\BCAY{Fujita \BBA\ Nagata}{Fujita \BBA\
  Nagata}{2010}]{Fujita:Nagata:2010}
Fujita, S.\BBACOMMA\ \BBA\ Nagata, M. \BBOP 2010\BBCP.
\newblock \BBOQ Enriching Dictionaries with Images from the Internet -
  Targeting Wikipedia and a Japanese Semantic Lexicon: Lexeed -.\BBCQ\
\newblock In {\Bem Proceedings of the 23rd International Conference on
  Computational Linguistics: COLING-2010}, \mbox{\BPGS\ 331--339},\ Beijing,
  China. 


\bibitem[\protect\BCAY{{Goldberg et~al.}}{{Goldberg et~al.}}{2009}]{Goldberg:Rosin:Zhu:Dyer:2009}
{Goldberg, A.~B., Rosin, J., Zhu, X. and Dyer, C.~R.} \BBOP
  2009\BBCP.
\newblock \BBOQ Toward Text-to-Picture Synthesis.\BBCQ\
\newblock In {\Bem NIPS 2009 Mini-Symposia on Assistive Machine Learning for
  People with Disabilities}.

\bibitem[\protect\BCAY{林 \Jetal}{林 \Jetal}{2012}]{Hayashi:Bora:Nagata:2012j}
林良彦\JBA 永田昌明\JBA サワシュ・ボラ \BBOP 2012\BBCP.
\newblock 言語横断情報検索における画像手がかりを用いたインタラクティブな翻訳曖昧性解消
の評価.
\newblock \Jem{情報処理学会論文誌 データベース}, {\Bbf 5}  (2), \mbox{\BPGS\
  26--35}.


\bibitem[\protect\BCAY{井手\JBA 柳井}{井手\JBA 柳井}{2009}]{Ide:Yanai:2009j}
井手一郎\JBA 柳井啓司 \BBOP 2009\BBCP.
\newblock セマンティックギャップを越えて :
  画像・映像の内容理解に向けて.\
\newblock \Jem{人工知能学会誌}, {\Bbf 24}  (5), \mbox{\BPGS\ i--ii, 691--699}.


\bibitem[\protect\BCAY{池原\Jetal}{池原\Jetal }{1997}]{GoiTaikeij}
池原悟\JBA 宮崎雅弘\JBA 白井諭\JBA 横尾昭男\JBA 中岩浩巳\JBA 小倉健太郎\JBA
  大山芳史\JBA 林良彦 \BBOP 1997\BBCP.
\newblock \Jem{日本語語彙大系}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{海野\Jetal}{海野\Jetal}{2008}]{Unno:Miyao:Tsujii:2008j}
海野裕也\JBA 宮尾祐介\JBA 辻井潤一 \BBOP 2008\BBCP.
\newblock 自動獲得された言い換え表現を使った情報検索.\
\newblock \Jem{言語処理学会第14回年次大会 (NLP-2008)}, \mbox{\BPGS\ 123--126}.


\bibitem[\protect\BCAY{Mihalcea \BBA\ Leong}{Mihalcea \BBA\
  Leong}{2008}]{Mihalcea:Leong:2008}
Mihalcea, R.\BBACOMMA\ \BBA\ Leong, C.~W. \BBOP 2008\BBCP.
\newblock \BBOQ Toward communicating simple sentences using pictorial
  representations.\BBCQ\
\newblock {\Bem Machine Translation}, {\Bbf 22}  (3), \mbox{\BPGS\ 153--173}.

\bibitem[\protect\BCAY{Mihalcea \BBA\ Moldovan}{Mihalcea \BBA\
  Moldovan}{1999}]{Mihalcea:Moldovan:1999}
Mihalcea, R.\BBACOMMA\ \BBA\ Moldovan, D. \BBOP 1999\BBCP.
\newblock \BBOQ {An Automatic Method for Generating Sense Tagged Corpora.}\BBCQ\
\newblock In {\Bem Proceedings of the American Association for Artificial
  Intelligence (AAAI-1999)}, \mbox{\BPGS\ 461--466}.

\bibitem[\protect\BCAY{Nichols  et~al.}{Nichols
  et~al.}{2006}]{Nichols:Bond:Tanaka:Fujita:Flickinger:2006}
Nichols, E., Bond, F., Tanaka, T., Fujita, S., \BBA\ Flickinger, D. \BBOP
  2006\BBCP.
\newblock \BBOQ {Robust Ontology Acquisition from Multiple Sources.}\BBCQ\
\newblock In {\Bem Proceedings of COLING-2006 2nd Workshop on Ontology Learning
  and Population: Bridging the Gap between Text and Knowledge}, \mbox{\BPGS\
  10--17},\ Sydney.

\bibitem[\protect\BCAY{Popescu et~al.}{Popescu
  et~al.}{2007}]{Popescu:Millet:etc:2007}
Popescu, A., Millet, C., \BBA\ Mo{\"e}llic, P.-A. \BBOP 2007\BBCP.
\newblock \BBOQ Ontology Driven Content Based Image Retrieval.\BBCQ\
\newblock In {\Bem Proceedings of the ACM International Conference on Image and
  Video Retrieval}, 
pp. 387--394.

\bibitem[\protect\BCAY{Popescu et~al.}{Popescu et~al.}{2006}]{Popescu:Millet:etc:2006}
Popescu, A., Millet, C., Mo{\"{e}}llic, P.-A., \BBA\ H{\`{e}}de, P. \BBOP
  2006\BBCP.
\newblock \BBOQ Automatic Construction of a Grounded Multimedia Ontology of
  Objects to Illustrate Concepts in a Learning Process.\BBCQ\
\newblock In {\Bem NETTIES 2006 Conference: Advanced Educational Technologies
  for a Future e-Europe}.

\bibitem[\protect\BCAY{白井}{白井}{2003}]{Shirai:2003j}
白井清昭 \BBOP 2003\BBCP.
\newblock {SENSEVAL-2} 日本語辞書タスク.\
\newblock \Jem{自然言語処理}, {\Bbf 10}  (3), \mbox{\BPGS\ 3--24}.

\bibitem[\protect\BCAY{諏訪 \Jetal}{諏訪 \Jetal}{2012}]{Suwa:Miyabe:Yoshino:2012j}
諏訪智大\JBA 宮部真衣\JBA 吉野孝 \BBOP 2012\BBCP.
\newblock Webページにおける文化差可視化システムの開発.\
\newblock \Jem{平成24年情報処理学会関西支部大会}, E-14, pp. 1--4..

\bibitem[\protect\BCAY{徳永}{徳永}{1999}]{Tokunaga:1999j}
徳永健伸 \BBOP 1999\BBCP.
\newblock \Jem{情報検索と言語処理}, \Jem{言語と計算シリーズ}, 5\JVOL.
\newblock 東京大学出版会.

\bibitem[\protect\BCAY{Voorhees}{Voorhees}{1994}]{Voorhees:1994}
Voorhees, E.~M. \BBOP 1994\BBCP.
\newblock \BBOQ Query Expansion using Lexical-Semantic Relations.\BBCQ\
\newblock In {\Bem the 17th Annual International ACM SIGIR Conference on
  Research and Development in Informaion Retrieval}, \mbox{\BPGS\ 61--69}.


\bibitem[\protect\BCAY{Zinger et~al.}{Zinger et~al.}{2006}]{Zinger:Millet:etc:2006}
Zinger, S., Millet, C., Mathieu, B., Grefenstette, G., H{\`e}de, P., \BBA\
  Mo{\"e}llic, P.-A. \BBOP 2006\BBCP.
\newblock \BBOQ Clustering and semantically filtering web images to create a
  large-scale image ontology.\BBCQ\
\newblock In {\Bem {SPIE 18th Annual Symposium Electronic Imaging, Internet
  Imaging VII}}, \lowercase{\BVOL}\ 6061, \mbox{\BPGS\ 89--97}.


\end{thebibliography}

\begin{biography}

\bioauthor{藤田　早苗}{
1999年奈良先端科学技術大学院大学情報科学研究科博士前期課程修了．
同年，NTT日本電信電話株式会社入社．
現在，コミュニケーション科学基礎研究所研究主任．
工学博士．自然言語処理の研究に従事．
言語処理学会，ACL各会員．
}

\bioauthor{平　　博順}{
1994年東京大学理学部化学科卒業．1996年同大学院修士課程修了．同年，日本電信電
話株式会社入社，
2002年奈良先端大学院大学情報学専攻博士後期課程修了．博士（工学）． 2005年〜
2007年株式会社NTTデータ技術開発本部．現在，NTT コミュニケーション科学基礎研究所研究主
任．
自然言語処理の研究に従事．情報処理学会，人工知能学会，言語処理学会，ACL各会員．
}


\bioauthor{永田　昌明}{
1987年京都大学大学院工学研究科修士課程修了．
同年，日本電信電話株式会社入社．現在，コミュニケーション科学研究所主
幹研究員（上席特別研究員）．工学博士．統計的自然言語処理の研究に従事．電
子情報通信学会，情報処理学会，人工知能学会，言語処理学会，ACL各会員．
}
\end{biography}

\biodate   

\end{document}


