<?xml version="1.0" ?>
<root>
  <jtitle>訂正パターンに基づく誤情報の収集と拡散状況の分析</jtitle>
  <jauthor>鍋島啓太渡邉研斗水野淳太岡崎直観乾健太郎</jauthor>
  <jabstract>東日本大震災では，「コスモ石油の爆発で有害物質の雨が降る」などの誤情報の拡散が問題となった．本研究の目的は，東本日大震災後1週間の全ツイートから誤情報を網羅的に抽出し，誤情報の拡散と訂正の過程を分析することである．本稿では，誤情報を訂正する表現（以下，訂正パターン）に着目し，誤情報を認識する手法を提案する．具体的には，訂正パターンを人手で整備し，訂正パターンにマッチするツイートを抽出する．次に，収集したツイートを内容の類似性に基づいてクラスタリングし，最後に，その中から誤情報を過不足なく説明する1文を選択する．実験では，誤情報を人手でまとめたウェブサイトを正解データとして，評価を行った．また，誤情報とその訂正情報の拡散状況を，時系列で可視化するシステムを構築した．本システムにより，誤情報の出現・普及，訂正情報の出現・普及の過程を分析できる．</jabstract>
  <jkeywords>Twitter,誤情報，訂正，拡散</jkeywords>
  <section title="はじめに">2011年3月に発生した東日本大震災では，ソーシャルメディアは有益な情報源として大活躍した~．震災に関する情報源として，ソーシャルメディアを挙げたネットユーザーは18.3%で，インターネットの新聞社(18.6%)，インターネットの政府・自治体のサイト(23.1%)と同程度である．ニールセン社の調査~によると，2011年3月のmixiの利用者は前月比124%，Twitterは同137%，Facebook同127%であり，利用者の大幅な伸びを示した．東日本大震災後のTwitterの利用動向，交換された情報の内容，情報の伝搬・拡散状況などの分析・研究も進められている~．Doanら~は，大震災後のツイートの中で地震，津波，放射能，心配に関するキーワードが多くつぶやかれたと報告している．宮部ら~は，震災発生後のTwitterの地域別の利用動向，情報の伝搬・拡散状況を分析した．Sakakiら~は，地震や計画停電などの緊急事態が発生したときのツイッターの地域別の利用状況を分析・報告している．AcarとMurakiは~，震災後にツイッターで交換された情報の内容を分類（警告，救助要請，状況の報告：自身の安否情報，周りの状況，心配）している．一方で，3月11日の「コスモ石油のコンビナート火災に伴う有害物質の雨」に代表されるように，インターネットやソーシャルメディアがいわゆるデマ情報の流通を加速させたという指摘もある．東日本大震災とそれに関連する福島第一原子力発電所の事故では，多くの国民の生命が脅かされる事態となったため，人間の安全・危険に関する誤情報（例えば「放射性物質から甲状腺を守るにはイソジンを飲め」）が拡散した．東日本大震災に関するデマをまとめたツイートでは，2012年1月時点でも月に十数件のペースでデマ情報が掲載されている．このように，Twitter上の情報の信憑性の確保は，災害発生時だけではなく，平時においても急務である．我々は，誤情報（例えば「放射性物質から甲状腺を守るためにイソジンを飲め」）に対してその訂正情報（例えば「放射性物質から甲状腺を守るためにイソジンを飲めというのはデマ」）を提示することで，人間に対してある種のアラートを与え，情報の信憑性判断を支援できるのではないかと考えている．訂正情報に基づく信憑性判断支援に向けて，本論文では以下に挙げる3つの課題に取り組む．なお，ツイートのデータとしては，東日本大震災ワークショップにおいてTwitterJapan株式会社から提供されていた震災後1週間の全ツイートデータ（179,286,297ツイート）を用いる．本論文の構成は以下の通りである．まず，第2節では誤情報の検出に関する関連研究を概観し，本研究との差異を述べる．第3節では誤情報を網羅的に収集する手法を提案する．第4節では提案手法の評価実験，結果，及びその考察を行う．第5節では，収集した誤情報の一部について，誤情報とその訂正情報の拡散状況の分析を行い，自動処理による訂正情報と誤情報の対応付けの可能性について議論する．最後に，第6節で全体のまとめと今後の課題を述べる．</section>
  <section title="関連研究">近年，ツイッターは自然言語処理の分野においても研究対象として注目を浴びている．言語処理学会の年次大会では「Twitterと言語処理」というテーマセッションが2011，2012年に企画されていた．また，国際会議のセッションや併設ワークショップにおいても，ソーシャルメディアに特化した情報交換の場が設けられることが珍しくない．このような状況が映し出すように，ツイッターを対象とした研究は数多くあるが，本節ではツイートで発信される情報の真偽性や信憑性に関連する研究を紹介する．Ratkiewiczら~は，米国の選挙に関連して，アストロターフィングや誹謗中傷，誤情報の意図的な流布を行っているツイートを検出するシステムを提案した．Qazvinianらは，誤情報に関連するツイート群（例えば「バラク・オバマ」と「ムスリム」を含むツイート群）から，誤情報に関して言及しているツイート（例えば「バラク・オバマはムスリムである」）と，誤情報に関して言及していないツイート（例えば「バラク・オバマがムスリムのリーダーと面会した」）を分類し，さらに誤情報に関して言及しているツイート群を，誤情報を支持するツイートと否定するツイートに分類する手法を提案した．Qazvinianらの研究は，誤情報に関連するツイート群（もしくはクエリ）が与えられることを想定しており，本研究のように大規模なツイートデータから誤情報をマイニングすることは，研究対象の範囲外である．日本では，東日本大震災時にツイッター上で誤情報が拡散したという問題意識から，関連する研究が多く発表されている．白井ら~は，デマ情報とその訂正情報を「病気」とみなし，感染症疾患の伝染モデルを拡張することで，デマ情報・デマ訂正情報の拡散をモデル化した．藤川ら~は，ツイートに対して疑っているユーザがどの程度いるのか，根拠付きで流言であると反論されているか等，情報に対するユーザの反応を分類することで，情報の真偽判断を支援する手法を提案した．鳥海ら~は，あるツイートの内容がデマかどうかを判別するため，ツイートの内容語と「デマ」「嘘」「誤報」などの反論を表す語の共起度合いを調べる手法を提案した．梅島ら~は，東日本大震災時のツイッターにおけるデマと，デマ訂正の拡散の傾向を分析することを目標とし，「URLを含むリツイートはデマである可能性が低い」「デマは行動を促す内容，ネガティブな内容，不安を煽る内容が多い」「この3つのいずれかの特徴を持つツイートはリツイートされやすい」等の仮説を検証した．彼女らのグループはその後の研究~で，誤情報のデータベースを構築するために，「デマ」や「間違い」といった訂正を明示する表現を用いることで，訂正ツイートの認識に有用であることを示した．さらに彼女らは，訂正を明示する表現を含むツイートを収集し，各ツイートが特定の情報を訂正しているか，訂正していないのかを識別する二値分類器を構築した．これらの先行研究は，ツイートが誤情報を含むかどうか，もしくはツイートが特定の情報を訂正しているかどうかを認識することに注力しており，ツイート中で言及されている誤情報の箇所を同定することは研究対象の範囲外となっている．したがって，大規模なツイートデータから誤情報を網羅的に収集する研究は，我々の知る限り本研究が最初の試みである．誤情報の発生から収束までの過程を分析している研究としては鳥海ら~の研究がある．鳥海らは「ワンピースの作者が多額の寄付を行った」という誤情報をとりあげ，関連するツイートを誤情報の拡散ツイートと訂正ツイートに振り分けて，時系列に基づく深い分析を行った．彼らの手法は「ワンピース，作者，寄付」と共起するツイートを誤情報拡散ツイート，「ワンピース，作者，デマ」と共起するツイートを誤情報訂正ツイートに機械的に振り分けるというものであったが，本研究ではツイートの内容を人間が検証することにより，14トピックの誤情報の拡散・訂正状況を詳細に分析する．</section>
  <section title="提案手法">本研究では，ツイッター上で拡散している誤情報に対して，別の情報発信者がその情報を訂正すると仮定し，誤情報の抽出を行う．例えば，「コスモ石油の爆発により有害な雨が降る」という誤情報に対して，ツイッター上で以下のような訂正情報を含むツイート（以下，訂正ツイート）が発信された．ex:tweet[ex1]コスモ石油の爆発により、有害な雨が降るという事実はない。[ex2]コスモ石油の科学物質を含んだ雨が降るというデマがTwitter以外にも出回ってるので注意を訂正ツイートは，訂正表現（下線部）と，その訂正対象である誤情報から構成される．そこで，ツイート中の訂正表現を発見することで，誤情報を抽出できると期待できる．本節で提案する手法の目標は，訂正表現を手がかりとして，ツイート本文から誤情報を説明する箇所を推定する抽出器を構築することである．さらに，構築した抽出器によって，ツイート集合から誤情報を過不足なく収集したい．図に提案手法の流れを示す．手順は大きく4つに分けられる．まず，ツイート本文に訂正パターン（後述）を適用し，訂正対象となる部分（被訂正フレーズ）を抽出する（ステップ1）．次に，「昨日のあれ」のように具体的な情報を含まないフレーズを取り除くために，ステップ2において被訂正フレーズに含まれやすいキーワードを選択する．同一の被訂正情報を言及しているが，表現や情報量の異なるフレーズをまとめるために，フレーズに含まれるキーワードをクラスタリングする（ステップ3）．その結果，「コスモ石油」や「イソジン」といった，誤情報の代表的なキーワードを含むクラスタが構築される．図左上の表は，被訂正フレーズに含まれやすいキーワードが上位に来るよう，クラスタをステップ2の条件付き確率（式，後述）で並べ替えたものである．最後に，ステップ4で，各クラスタごとに誤情報を最もよく説明しているフレーズを選択する．図右上はステップ3で並べ替えたクラスタからフレーズを抽出し，出力された誤情報のリストである．以降では，各ステップについて詳細に説明する．</section>
  <subsection title="ステップ1：訂正パターンを用いた訂正フレーズの抽出">ステップ1では，ツイート本文から被訂正フレーズを見つけ出す．被訂正フレーズは，「デマ」や「間違い」といった表現で，訂正や打ち消されている箇所のことである．被訂正フレーズは，「イソジンは被曝を防ぐ」といった単文や，「コスモ石油の火災により有害な雨が降る」といった複文，「うがい薬の件」といった名詞句もある．被訂正フレーズと訂正表現は，「という」や「のような」といった連体助詞型機能表現で繋がれ，図に示す構造をとる．被訂正フレーズに続く表現を，すなわち連体助詞型機能表現と訂正表現の組み合わせを，「訂正パターン」と呼ぶ．例えば，図において，「というデマ」，「といった事実はありません」が訂正パターンである．全ツイートを形態素解析し，訂正パターンに対して形態素レベルでのパターン照合を行う．マッチしたツイートに対して，文頭から訂正パターンの直前までを被訂正フレーズとして抽出する．被訂正フレーズを漏れなく抽出するには，質のよい訂正パターンを整備することが重要である．そこで，どのような表現が訂正パターンになり得るのかを調べた．具体的には，既知の誤情報15件を含むツイートを検索するようなクエリを考え，そのツイートの内容を確認することにより，訂正パターンを収集・整理した．このようにして得られた訂正パターンの一覧を表に示した．表の訂正パターンのいずれかを含むツイートに対して，文頭から訂正パターンの直前までを被訂正フレーズとして抽出した例を図に示した．図の下線部が訂正パターンである．</subsection>
  <subsection title="ステップ2：キーワードの抽出">前節で抽出された被訂正フレーズには，「昨日のあれ」のように具体的な情報が提示されていないフレーズも含まれている．これらは誤情報としては不適切であるため，取り除く必要がある．そこで，被訂正フレーズ中の名詞句が訂正情報中に偏って出現しているかどうかを調べる．ここで分析の対象とする名詞句は，単名詞および名詞連続に限定する．具体的には，ある名詞句がツイートで言及されるとき，その名詞句が被訂正フレーズに含まれる確率（条件付き確率）を算出する．被訂正フレーズ中には頻出し，その他のツイート中では出現頻度の低い名詞句は，被訂正時にのみ頻出することから，誤情報のキーワードとなる名詞句である可能性が高い．逆に，被訂正フレーズ以外でも頻出する名詞句は，一般的な名詞句であり，誤情報のキーワードとなる可能性は低い．「昨日のあれ」の「昨日」や「あれ」は，被訂正フレーズ以外でも頻出するため，一般的な名詞句であると判断できる．フレーズ中の名詞句wが誤情報のキーワードらしいかどうかを，式によって計算する．ここで，Dは訂正フレーズ集合を表す．このように求めた条件付き確率が高い上位500個を，キーワードとして選択する．ただし，コーパス中での出現頻度が極端に低い名詞句を除くため，コーパス全体での出現回数が10回以上かつ，被訂正フレーズ集合での出現回数が2回以上の名詞句のみをキーワードとして認定する．また，ひらがなや記号が半数以上の名詞句（例えば「◯◯町」）はキーワードとして不適切と考え，キーワードから取り除いた．</subsection>
  <subsection title="ステップ3：キーワードのクラスタリング">被訂正フレーズには，「コスモ石油の火災により有害物質を含む雨が降る」と「コスモ石油の爆発は有害だ」のように，同一の被訂正情報を言及しているが，表現や情報量の異なるフレーズが含まれている．誤情報を過不足なく抽出するために，これらをまとめる必要がある．そこで，ステップ2で抽出されたキーワードを，同一の被訂正情報を説明するキーワードがまとまるようにクラスタリングする．クラスタリングにおけるキーワード間の類似度計算では，キーワードと文内で共起する内容語（名詞，動詞，形容詞）を特徴量とした文脈ベクトルを用いた．これは，周囲に同じ単語が表れていれば，2つのキーワードは類似しているという考えに基づく．文脈ベクトルの特徴量には，各単語との共起度合いを表す尺度である自己相互情報量(PMI)を用いた．この値が0以上の内容語を文脈ベクトルの特徴量に加えた．各文脈ベクトルの類似度はコサイン類似度によって計算した．クラスタリング手法は，階層クラスタリングの一種である最長距離法を用いた．今回のデータでは，類似度の閾値を0.2に固定してクラスタリングを行ったところ，500個のキーワードから189個のクラスタが得られた．得られた各クラスタに対し，式の示す確率が最も高いキーワードを代表キーワードとする．代表キーワードは，クラスタの誤情報を説明するために最も重要なキーワードであると考える．</subsection>
  <subsection title="ステップ4：代表フレーズの選択">クラスタごとに被訂正フレーズを抽出し，誤情報として出力する．誤情報に相応しい被訂正フレーズは，誤情報を過不足なく説明できるような一文である．例えば，以下の例では，bは説明が不足しており，cは冗長な情報が含まれているため，aを誤情報として出力したい．ex:phrase_selectionコスモ石油の火災により，有害物質を含む雨が降るコスモ石油の件で，有害な雨が降るコスモ石油が爆発したというのは本当で，有害な雨が降るから傘やカッパが必須らしいこのような選択を可能にするため，内容語の種類と含有率に着目する．まず，代表キーワードを含む被訂正フレーズを誤情報の候補として抽出する．次に，この候補の中から誤情報の内容を過不足なく説明するものを抽出する．文書自動要約における重要文抽出の考えから，前段で用いたキーワードとよく共起する内容語を多く含むものは，より重要な文であると考えられる．そこで，共起度合いを自己相互情報量(PMI)で計る．sは被訂正フレーズ，tは各クラスタの代表キーワード，C_sはs中の内容語の集合を表す．ここで，内容語とは被訂正フレーズに含まれる名詞，動詞，形容詞とする．この式により，誤情報クラスタを代表するキーワードと共起性の強い内容語を多く含むフレーズに対して，高いスコアが付与される．しかし，この式では，被訂正フレーズに含まれる内容語の数が多い，長い文ほど高いスコアが付与されてしまう．そこで，代表キーワードを含む文の中でも，典型的な長さの文に高いスコアを付与し，短い文および長い文に対して低いスコアを与える補正項を用いる．len_sは被訂正フレーズsの単語数を示す．hist(l,t)は，代表キーワードtを含み，かつ単語数がlである文の出現頻度を表す．最終的なスコアは，式と式を乗算したものとする（下式）．最後に，各クラスタから式のスコアが最も高いフレーズを一つずつ選択し，誤情報として出力する．</subsection>
  <section title="実験">評価実験では，東日本大震災時のツイートデータを用いて，誤情報の抽出を行い，その精度と再現率を測った．抽出された誤情報を，その代表キーワードの式で並べ替え，上位100件を評価対象とした．考察では，ツイートデータから抽出できなかった事例や，誤って抽出された事例を分類し，今後の対策について述べる．</section>
  <subsection title="データセット">誤情報の抽出元となるコーパスには，東日本大震災ビックデータワークショップでTwitterJapanから提供された2011年3月11日09:00から2011年3月18日09:00までの日本語のツイートデータ179,286,297ツイートを利用した．このデータのうち，リツイート（自分の知り合いへのツイートの転送）は単順に同じ文が重複しているだけであるため，取り除いた．</subsection>
  <subsection title="正解データ">東日本大震災の際に発信された誤情報を網羅的にまとめたデータは存在しない．評価実験の正解データは，誤情報を人手でまとめた以下の4つのウェブサイトに掲載されている事例を利用した．絵文録ことのは「震災後のデマ80件を分類整理して見えてきたパニック時の社会心理」荻上式BLOG「東北地方太平洋沖地震，ネット上でのデマまとめ」原宿・表参道.jp地震のデマ・チェーンメールNAVERまとめ注意！地震に関するデマ・チェーンメールまとめ以上の4サイトに掲載されているすべての事例のうち，Twitterデータの投稿期間内（20113/1109:00から20113/1809:00まで）に発信されたと判断できる事例は60件存在した．この60件の誤情報を正解データとした．作成した正解データの一部を以下に列挙する．関西以西でも大規模節電の必要性ワンピースの尾田栄一郎さん15億円寄付天皇陛下が京都に避難されたホウ酸を食べると放射能を防げる双葉病院で病院関係者が患者を置き去りにして逃げたいわき市田人で食料も水も来ていなく餓死寸前宮城県花山村が孤立韓国が震災記念Tシャツを作成民主党がカップ麺を買い占め</subsection>
  <subsection title="評価尺度">抽出された誤情報の正否は，同等の内容が60件の正解データに含まれるかどうかを一件ずつ人手で判断した．また，正解データに含まれていないが，誤情報であると判断できるものもある．そこで抽出された情報が正解データに含まれなかった場合は，関連情報を検索することで，その正否を検証した．本研究の目的は，出来るだけ多くの誤情報を抽出し，人に提示することにある．しかし人が一度に見ることのできる情報には限界があり，出来るだけ多くの誤情報を人に提示するには，提示する誤情報の中にある，冗長な誤情報を取り除きたい．この目的のため，抽出した誤情報のうち，同じ内容と判断できるものが複数ある場合は，正解は一つとし，他の重複するものは不正解とした．また，日本語として不自然なものも不正解とした．提案手法はスコアの高い順にN件まで出力可能であるため，Nをいくつか変化させたときの精度@N，再現率@N，F値@Nによって評価した．精度には，正解データに含まれるかどうかで判断したもの（精度@N（60件））と，人手により検証を行ったもの（精度@N（人手検証））を用意した．また，人手による検証に加え，重複を許した場合（精度@N（重複））も評価に加えた．この評価を行うことで，目的の一つである「誤情報抽出」がどの程度達成されているかを知ることができる．それぞれは以下の式で表される．精度@N（60件）&amp;=N事例のうち，60件の誤情報に含まれる事例数（重複を除く）N[1zw]精度@N（人手検証）&amp;=N事例のうち，人手で誤情報と検証された事例数（重複を除く）N[1zw]精度@N（重複）&amp;=N事例のうち，人手で誤情報と検証された事例数（重複を許す）N[1zw]再現率@N&amp;=N事例のうち，60件の誤情報に含まれる事例数（重複を除く）正解の誤情報の数（60件）[1zw]F値@N&amp;=2*精度@N（60件）*再現率@N精度@N（60件）+再現率@Nalign</subsection>
  <subsection title="実験結果">評価結果を表に示す．が100のとき，提案手法が抽出した情報のうち，60件の正解データにも含まれる情報は31件であった．さらに，正解データには含まれないが，誤情報と判断できる事例が23件存在したことから，提案手法は54%の精度で誤情報を抽出できた．次に，上位N件に限定しない場合の再現率について述べる．「上限(N=189)」は500個のキーワードをクラスタリングし得られた189個のクラスタから，代表フレーズをすべて出力した時の再現率であり，「上限（クラスタなし）」は，提案手法ステップ1で収集された被訂正フレーズ集合約2万件をすべて出力した時の再現率である．「上限(N=189)」は，キーワードを189個に絞った時の，ランキング改善による性能向上限界を表すに対し，後者はキーワードの選択，ランキング，クラスタリング改善による性能向上限界，つまり訂正パターンに基づく抽出手法の限界を表す．被訂正フレーズ集合の段階でカバーされている50件は，キーワードの選択やクラスタリングなど，後段の処理を改善することで抽出できる可能性があるが，残る10件は，訂正パターンに基づく抽出手法の改善が必要となる，難解な事例である．</subsection>
  <subsection title="考察">本節では，評価結果の誤りを分析する．抽出された誤情報の上位100件のうち，31件は正解データに含まれていたが，残りの69件は正解データに含まれていなかった．そこで，不正解データに対する誤判定の原因を調べたところ，8種類の原因に分類できた．表に理由と件数を示す．(a)から(d)は，明らかに誤抽出と判断できる事例である．(e)と(f)は，正解データの構築に用いた4つの誤情報まとめサイトに掲載されてはいなかったが，ウェブ上で調べることで，明らかに誤情報であると認められる事例である．(g)と(h)は，人手でも誤情報であるかを判断できない事例である．以下でそれぞれの詳細と，改善案を述べる．次に，正解データにある誤情報60件のうち，抽出されなかった誤情報29件についても同様に原因を調査したところ，3つに分類できることが判明した．3つの原因の件数と割合を表に示す．</subsection>
  <section title="誤情報の拡散状況の分析">本節では，誤情報がどのように発生し，拡散・収束していくかを分析する．誤情報およびその訂正情報の拡散状況を時系列で可視化することで，誤情報の拡散のメカニズムを詳細かつ系統的に分析する．分析対象とする誤情報は，将来的には自動抽出結果を用いる予定だが，「東日本大震災の誤情報の拡散状況を正しく分析する」という目的から，誤情報であると確認できた事例のみを用いた．本節で想定しているシナリオは以下の通りである．前節までの手法で，ツイート空間上で誤情報と考えられているフレーズ（例えば「コスモ石油のコンビナート火災に伴い有害物質の雨が降る」）を抽出できる．この誤情報がどのように発生・拡散し，その訂正情報がどのように発生・拡散したのかを調べるため，このフレーズの中からキーワードを選び，ツイート検索システムへのクエリ（例えば「コスモ石油AND有害物質」）とする．このクエリを用いてツイートを検索すると，誤情報を拡散するツイート，誤情報を訂正するツイートが混ざって得られる．そこで，本節ではツイートを誤情報の「拡散」と「訂正」の2グループに自動分類する手法を提案する．図4は実際に作成した，誤情報の拡散状況を提示するシステムである．このシステムの処理をリアルタイム化すれば，被訂正情報から抜き出したキーワードを誤情報の監視クエリとし，誤情報の拡散・訂正状況をモニタリングしたり，誤情報を発信した（もしくは発信しようとしている）者に，訂正情報の存在を通知することができる．本節で提案する手法で「拡散」「訂正」ツイートの分類精度を測定するため，14件の誤情報に関して，正解データを作成した．この正解データを利用すれば，提案手法の性能を評価できるだけではなく，誤情報の拡散・訂正状況を精緻に検証し，誤情報の発生から収束までのメカニズムをモデル化することができる．最後に，自動手法の失敗解析を通じて，誤情報と訂正情報を対応づける際の技術的課題を述べる．</section>
  <subsection title="訂正表現による誤情報と訂正情報の自動分類">与えられたツイートに対して，誤情報の「拡散」もしくは「訂正」に分類する手法を，順を追って説明する．まず，前節までの手法で獲得した誤情報に関連するツイートを集める．ツイートの収集には本研究室で開発されたツイート全文検索システムを用いる．誤情報に関連するツイートを収集するために，獲得した誤情報（例えば「東大が合格者の入学取り消し」）を適切なクエリ（例えば「東大AND入学」）に変換する．次に検索によって得られた全ツイートを誤情報と訂正情報とに分類する．分類には「デマ」や「風説」などの訂正表現を含むツイートを「訂正情報」とし，含まないものを「訂正情報ではない」ツイートとする．訂正表現は震災時のツイートを読みながら，121個用意した．検索で得られるツイートの中には，「誤情報」や「訂正情報」とは関係の無い「その他」のツイートが存在するが，後述する正解データの割合を示した表から分かるように，「その他」の割合は少ない．そこで本節では「訂正情報ではない」ツイートは誤情報の「拡散」ツイートとして見なす．</subsection>
  <subsection title="実験と評価">本手法の認識精度を評価するため，14件の誤情報に関連するツイート群を検索し，それらのツイートを「誤情報」「訂正情報」「その他」の手作業で分類し，正解データを作成した．評価対象の誤情報は，人手での作業の負荷を考慮して14件とした．関連するツイート5,195件のうち，誤情報ツイートが2,462件，訂正情報ツイートが2,376件，その他のツイートが357件であった（表）．評価対象として14件の誤情報は，第節で定義した条件付き確率（式）が高いものから誤った事例を人手で除き，順に選んだ．今回の実験では被リツイート数の多いツイートを優先的に採用し，手作業による分類のコストを下げた．なお，評価対象のツイートは誤情報や訂正情報に関するものと仮定しているので，「その他のツイート」は評価の対象外とする．表に，提案手法が訂正情報を認識する精度（再現率・適合率・F1スコア）を示した．この評価では，リツイートは削除し，オリジナルのツイートのみを評価対象としている．表によると，ほとんどの誤情報について高い適合率が得られた．適合率が高いということは「デマ」などの訂正表現を含むツイートは，かなりの確度で訂正情報と見なせるということである．「デマ」という語を伴って誤情報の拡散を行うことは，通常では考えにくいので，これは直感的に理解できる結果である．これに対し，再現率はユーザが誤情報の訂正のために，「デマ」などの訂正表現をどのくらい使うのかを示している．再現率が高いということは，誤情報の訂正情報のほとんどが「デマ」等の表現を伴うということである（例えば，以下のツイートを参照）．以上の結果から，訂正表現のマッチングに基づく提案手法でも，かなりの精度で誤情報の「拡散」と「訂正」のツイートを分離できることが示された．しかし，量は少ないものの，訂正表現を含む誤情報拡散ツイートも見受けられる．このツイートでは，「ガセ」という訂正表現を含んでいるが，「ガセ」をさらに否定しているので，二重否定により誤情報の拡散ツイートと解釈できる．さらに，訂正表現を用いずに誤情報を否定するツイートも存在する．このツイートでは，「デマ」「嘘」などの訂正表現は一切使われていないが，誤情報の内容（「コスモ石油の火災により有害物質の雨が降る」）を訂正するツイートであると判断できる．このようなツイートを訂正ツイートと認識するためには，深い処理（例えば，「タンクの爆発事故」による「人体に及ぼす影響はほとんどない」と解釈する）や，ツイートやユーザ間の関係（例えば，このツイートをRTしているユーザが，訂正表現を用いてた別の訂正ツイートをRTしている，等の手がかり）を用いる必要がある．</subsection>
  <section title="おわりに">本研究では，誤情報を訂正する表現に着目し，誤情報を自動的に収集する手法を提案した．実験では，誤情報を人手でまとめたウェブサイトから取り出した誤情報のリストを正解データと見なして評価を行ったところ，出力数が100件のとき正解データの約半数である31件を収集することができた．これは抽出した情報100件の約3割であるが，残り69件の中には，まとめサイトに掲載されていない誤情報も23件あり，54%の精度で誤情報を抽出できた．また，収集された誤情報の中に真実の情報が含まれていると深刻な問題であるが，誤って抽出された事例の多くは，内容の重複する誤情報や真偽不明の事例であり，特に問題である真実の情報は100件のうち1件と非常に少なく，提案手法は誤情報の自動収集に有用であることを示した．また，誤情報に対して，誤情報の出現とその拡散状況，その訂正情報の出現とその拡散状況を可視化するシステムを構築した．本システムの訂正情報の認識精度を測定したところ，多くの誤情報について高い精度を得ることができた．実際に，本システムを用いて収集された誤情報の分析を行ったところ，拡散状況を幾つかのタイプに分類を分類することができた．今後の課題として，懐疑や反論といった，訂正パターン以外の情報を考慮した誤情報の抽出が挙げられる．</section>
</root>
