



\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{71}
\setcounter{巻数}{9}
\setcounter{号数}{5}
\setcounter{年}{2002}
\setcounter{月}{10}
\受付{2002}{2}{4}
\再受付{2002}{4}{24}
\採録{2002}{7}{17}

\setcounter{secnumdepth}{2}

\title{確率的判定尺度を用いた比喩性検出手法}
\author{桝井 文人\affiref{MIE} \and 福本 淳一\affiref{RITS} \and 椎野 努\affiref{AIT} \and 河合 敦夫\affiref{MIE}}

\headauthor{桝井，福本，椎野，河合}
\headtitle{確率的判定尺度を用いた比喩性検出手法}

\affilabel{MIE}{三重大学工学部情報工学科}
{Department of Information Engineering, Mie University}
\affilabel{RITS}{立命館大学理工学部情報学科}
{Department of Computer Science, Ritsumeikan University}
\affilabel{AIT}{愛知工業大学工学部情報通信工学科}
{Department of Information Engineering, Aichi Institute of Technology}

\jabstract{
本論文では，テキスト中に出現する比喩表現を認識するために，確率的な尺度を用いて，
概念(単語)間の比喩性を検出する手法について述べる．比喩性を検出するための確率的な
尺度として，``顕現性落差"と``意外性"を設定する．``顕現性落差''は，概念対を比較
したときに，クローズアップされる顕現特徴の強さをはかる尺度であり，概
念同士が理解可能か否かの判断に用いる．``顕現性落差''は，確率的なプロトタイプ概念記述を用い
て，概念の共有属性値集合が持つ冗長度の差で定量化する．``意外性''は，概念の組み合
わせがどれほど稀であるかをはかる尺度であり，概念同士が例示関係であるか否かの判断
に用いる．``意外性"は，単語間の意味距離を用いて定量化する．二つの尺度を併用する
ことによって，比喩関係を持つ概念対，すなわち，比喩性の判定が可能となる．二つの尺
度を計算するために，コーパス中から抽出した語の共起情報を利用して知識ベースを利用
する．両尺度を用いた比喩性検出手法を検証するために，1年分の新聞記事コーパスから
構築した知識ベースと，比喩関係・例示関係・無意味の各単語対が混在するデータ100組
を用いて，単語対の判別実験を行った．その結果， 70\%以上の適合率で比喩関係単語対
が判別できることがわかり，本手法の有効性が確認できた．
}
\jkeywords{比喩性，顕現性落差，意外性，大規模知識ベース}

\etitle{A Method of Metaphoricity Detection\\ using Probabilistic Measurements}
\eauthor{Fumito Masui\affiref{MIE} \and Jun'ichi Fukumoto\affiref{RITS} \and Tsutomu Shiino\affiref{AIT} \and Atsuo Kawai\affiref{MIE}} 

\eabstract{
We propose a method to detect metaphoricity between words with 
probabilistic measurements.  In order to detect metaphoricity, we have 
introduced two probabilistic measurements: ``$salience$ $gap$" and ``$novelty$."  
The salience gap measures strength of closed-up property set between a 
concept pair and has contribution to separate concept pairs into 
anomalous and others.  The measurement can be computed by 
probabilities of properties in each concept representation.  The novelty 
measures how surprisingly a concept combination is, and contributes to 
extract anomalous relation from concept pairs.  The measurement can 
be calculated using word similarity.  Using both measurements, 
concept pairs can be classified into metaphorical, literal and anomalous.  
For the evaluation of our metaphoricity detection model, we have used 
one-year newspaper articles and 100 sets of word combinations 
including three kinds of relations: metaphorical, literal and anomalous.  
In the experimental results, precision attained 70 percent for dividing 
metaphorical word pairs from others.   It can be considered that 
performance of our method is useful.  
}

\ekeywords{metaphoricity, salience gap, novelty, huge knowledge base}

\begin{document}
\maketitle
\thispagestyle{empty}


\section{まえがき}\label{intro}
比喩とは，ある概念を他の概念によって説明または強調する修辞的手法の一つであ
り\cite{Lakoff1986,Yoshiga1990j}，様々な分野で研究対象として取り上げられている
\cite{Shinohara2000j}．
自然言語処理の分野においても，比喩表現はしばしば問題となる．
例えば，機械翻訳において，現状のシステムでは意訳や再解釈などの深い処理は行
われないため，目的言語に翻訳された比喩表現は，意図した内容と異なった出力
となってしまう場合がある\cite{Masui1995j}．
``水のような価値''という比喩表現は，日本語では「価値が低い」という
意味として理解されるが，言語によっては，「非常に価値が高い」ことを意味
する場合がある．
これは，``水''が持つ特徴が言語間で異なるからであり，この違いを補正する
ためには，原言語における「価値が低い」という特徴を保持したまま，対象言語
において，同様の特徴を持った言葉を選び出す必要がある．
しかし，現状の機械翻訳では，このような，言語間の意味の相違を考慮した処理
は不可能である．
このような場合，その表現が比喩であるかどうかを判断し，``as worth as water''
 や ``value like as water''と直訳されることを防ぐだけでも有効であると思われる．
また，李\cite{Yoshiga1990j}によれば，新聞記事などの実用文においても，比喩
表現は数多く出現し，その割合は小説や雑誌と大差はない．
したがって，自然言語処理の対象を一般的な文書へ拡大し，柔軟な処理を行うた
ためには，比喩表現の処理は重要である．

従来，比喩に関する研究は，心理学の分野において発展してきた．
Ortony\cite{ortony79}やGentner\cite{gentner94}をはじめ，多くの比喩理解の
理論的モデルが，提案されている．
楠見\cite{Kusumi1996jb,Kusumi1996ja}は，
心理学的実験手法によって，比喩理解に必要な知識
を計測し，いくつかの理論的モデルの検証を行っている．
しかしながら，上記で述べたような心理学実験は，被験者に対するアンケートや
テストによって知識を得る手法であるため，汎用的な大規模知識ベースを構築す
るという目的に対しては，被験者数の確保や被験者集団の知識
の偏り，個人差の是正の困難さやコストの面で大きな制限がある．

比喩理解の過程を計算機上で実現するためには，比喩の理解過程を，
なんらかの形でモデル化して扱う必要がある．
岩山らは，プロトタイプ理論\cite{rosch75}に基づいて概念を生起確率を持った
属性値集合として記述し，比喩を構成するときの特徴の移動を定量化する計算モ
デルを提案しており\cite{Iwayama1991j}，内海も同様の計算モデルを用いて，
心理学実験データに基づく知識ベースを用いた比喩理解の実験を行い，人間の判
断結果と比較している
\cite{Utsumi1997j}．
彼らのモデルでは，
比喩の理解過程は
比喩表現として尤も強調される特徴(顕現特徴)が，たとえる概念(source概念)から
たとえられる概念(target概念)へ移動するプロセスとして扱われている．
しかしながら，楠見ら\cite{Kusumi1996ja,Iwayama1991j}が指摘するように，比喩理解において，
比喩性を有する概念間の共有属性値は必ずしも一つとは限らず，複数の顕現特徴
を扱う場合については議論の余地がある．
また，彼らも，人手によって知識ベースを構築しており，知識の大規模化，汎用
化の問題は解消されていない．

そこで，本論文では，テキスト中に出現する比喩表現を認識するために，確率的な
尺度を用いた比喩性検出手法を提案する．
比喩性を検出するための確率的な尺度として，``顕現性落差"と``意外性"を設定する．
``顕現性落差''は，概念対を比較したときに，クローズアップされる顕現特徴の強
さをはかる尺度であり，概念の組合せが理解可能である否かの判断に用いる．
``顕現性落差''は，確率的な
概念記述を用いて，概念の共有属性値集
合が持つ冗長度の差で定量化する．
``意外性''は，概念の組み合わせがどれほど斬新であるかをはかる尺度であり，概念
同士が例示関係であるか否かの判断に用いる．
``意外性"は，単語間の意味距離を用いて定量化する．
二つの尺度を併用することによって，比喩関係を持つ概念対，すなわち，比喩性の
判定が可能となる．
二つの尺度を計算するために，コーパス中から抽出した語の共起情報を利用して知
識ベースを構築する．

以下，2章で，比喩性を検出するための尺度として，``顕現性落差''と
``意外性''が利用できることを示し，
3章で，``顕現性落差''を，確率的
概念記述モデルに基づいて定量
化する方法と，計算に用いる知識ベースを，コーパス中の共起関係を
利用して構築する方法について述べ，
4章で，``意外性''を，単語間の意味距離を利用して定量化する方法と，
コーパス中の共起情報に基づく知識ベース構築の方法について説明する．
5章では，両尺度を併用した単語対の判別実験と評価を行い，6章で，
評価結果について考察する．

\section{比喩性の尺度}
本論文では，与えられた表現が比喩であるかを判断する基準として，「クローズ
アップされる特徴がいかに明確か」という点と，「与えられた表現がどの程度新
鮮か」という点が重要であることに着目する．
比喩表現の理解とは，概念が持つ，ある特徴を強調することによって，新たな理
解を促すものであるから，強調される特徴が明確でなければならない．
``顕現性落差"は，クローズアップされる特徴を抽出し，それらの特徴がいかに明
確であるかをはかる尺度である．
また，比喩表現として対比される概念が新鮮であることは，その表現に強い印象
を与え，理解を促すことになる．
``意外性"は，対比される概念の組み合わせの新鮮さをはかる尺度である．
このような，二つの尺度を設定することで，その表現の比喩らしさ，すなわち，
比喩性を検出できると考えられる．
以下，``顕現性落差''および``意外性''について，比喩性との関係を説明し，
両尺度が，比喩性検出にどのように利用できるかについて述べる．

Ortny\cite{ortony79}は，比較される概念間の共有特徴が少ない場合でも，それ
らの類似性が認識されて比喩性が理解される点や，類似性の非対称性に着目し，
相互作用モデルを示した．
例えば，``卵のような車''という比喩の場合，たとえる言葉(source概念)``卵''と
たとえられる言葉(target概念)``車''の共有特徴
$(卵{\cap}車)=\{丸い，白い，小さい，…\}$は，
``車''においては顕著な特徴ではない
が，``卵''においては，これらの共有特徴は非常に顕著な特徴(顕現特徴)
である
．
したがって，``車''に対して，``卵''のイメージを重ね合わせることによって，
``車''における$\{丸い，白い，小さい，…\}$などの特徴を同時に強調し，
その結果，``顕現性落差''が生じて，比喩性が検出される．
``顕現性落差''からは，類似性の非対称性が生じるので，
同じ概念を比較した場合でも，``車のような卵''という表現
\footnote{このような表現を反転比喩という．}
からは，比喩性は検出されにくい．

また，source概念が顕著な特徴を持っていたとしても，対比される概念間に共有
特徴が認められない場合は，``顕現性落差''が生じないため，比喩性は認識されない．
例えば，``谷底のような車''という表現では，
``谷底''と``車''の間には共有特徴が見つけられないので，
``顕現性落差''は生じず，比喩性も生じない．
``自動車のような車''では，組み合わせ概念が類似概念であるため，両者の顕現
特徴もほとんど共通である．この場合も，``顕現性落差''は生じにくく，比喩性も
あらわれにくいと考えられる．

さらに，比喩とは，意表を突いた言葉(ここでは単語)の組合せによって，伝えた
い内容をより鮮明にしたり，強調する働きを持つ．
例えば，``スポーツカーのような車''という比喩の場合，``スポーツカー''と
``車''の共有特徴($スポーツカー{\cap}車$)=\{速い，格好いい，燃費が悪い…\}は，
``車''においては顕著な特徴ではない
が，``スポーツカー''において非常に顕著である．
したがって，``車''に対して，``スポーツカー''のイメージを重ね合わせるこ
とによって，``車''における\{速い，恰好いい，…\}などの特徴を同時に強調
するが，比喩性は認識されにくい．
この理由は，両概念が上位下位関係を持つために，重複する特徴が多く，かつ，
ありふれた組み合わせであるために，表現の新鮮さに欠けるからと考えられる．
本論文では，このような単語間の組合せの新鮮さの度合を``意外性''として扱う．

一般に，同一話題中に頻出する単語対は，たとえ2章の``顕現性落差''の条件を
満たしていても，``意外性''が低い．
その結果，比喩としての「新しさ」や「意外さ」が認識されず，比喩性を高
める要因とはならない．
反対に，めったに同一話題中に現れない単語対は``意外性''が高く，「新鮮」で
「意外」であると認識され，比喩性を高める要因となる．

\begin{table}[tb]
  \begin{center}
     \caption{顕現性落差と意外性に基づく概念対の分類}
     \label{tbl:relation}
\begin{tabular}{|c|c|c|c|c|}
\hline
   &           &\multicolumn{3}{|c|}{顕現性落差}\\
\hline
   &	&  大   & 小     	&  負\\
\hline
意 & 高 & 比喩 & 比喩／例示	& 無意味\\
\cline{2-5}
外 & ： & ：   & ： 		& ： 	\\
\cline{2-5}
性 & 小 & 例示  & 比喩／例示	& 無意味？ 	\\
\hline
\end{tabular}
  \end{center}
\end{table}

上記の見地から，``顕現性落差''が大きく，かつ``意外性''も大きい概念対
ほど，特徴が明確であり，表現も新鮮に受け取られ，比喩性も大きくなると考
えられる．
この考え方と，概念対(比喩・例示・無意味)の区別を対応付け
ると，表\ref{tbl:relation}のような関係が仮定できる．
概念対において，``顕現性落差''によって，無意味な概念対(無関係対)と意味
のある概念対(比喩関係対・例示関係対)が区別でき，``意外性''によって，例
示関係対と非例示の概念対(比喩関係対・無関係対)が区別できる．
よって，両者を統合的に利用することで，比喩関係にある概念対が区別できる
\footnote{
ただし，共有特徴がない場合については，本論文では議論の対象外とする．
}．

\section{顕現性落差の定量化}
\subsection{確率的プロトタイプを用いた顕現性落差の計算}
2章で述べたような共有特徴の顕現性落差を扱うために，
属性値集合を用いた，確率的な概念記述
を用いる．
確率的な
概念記述モデルでは，概念は属性値とその生起確率の集合として記
述される\cite{Iwayama1990,Masui1999}．
概念$\ast(W)$が属性値$w_i$をもち，その生起確率が$p_i$であるとき，
$\ast(W)$ は以下のように，確率的な属性値集合として記述できる
(式(\ref{exp:collection}))．
\begin{eqnarray}
\label{exp:collection}
	{\ast}(W) = \{p_1\#w_1,p_2\#w_2,...,p_i\#w_i,...,p_m\#w_m\}
\end{eqnarray}
このとき，概念の顕現性は，これらの属性値集合の冗長度(ばらつき具合)から予
測可能である．
(\ref{exp:collection})で示した概念${\ast}(W)$が，$m$種類の属性値から成る
属性値集合として記述される場合，その冗長度$r(W)$は，
式(\ref{exp:info})を用いて定量化できる\cite{Iwayama1991j}．
\begin{eqnarray}
\label{exp:info}
r(W) = &
	\left\{\begin{array}{cc}
	 1 - \frac{\sum_{i=1}^{m}{p_i}\log{\frac{1}{p_i}}}{\log{m}} & (m{\neq}1)\\
	{1} & (m=1)
		\end{array}\right \}
\end{eqnarray}

\begin{figure}[tb]
    \begin{center}
      \epsfile{file=proto2.eps,scale=0.5}
\caption{確率的な概念記述における特徴集合の顕現性落差}
\label{fig:rep-kage}
\end{center}
\end{figure}
ところで，比喩表現の顕現特徴は，比較される概念間の共有特徴から選ばれるが，
同時に，source概念の顕現特徴になっているはずである．
よって，source概念の属性値集合から主要な属性値を取り出し，それらと，
target概念の属性値との間で共有できるものを取り出すことで，顕現性落差を考
えるためにクローズアップされる共有属性値集合が取り出される
\footnote{
比喩表現を構成する概念の間で共有される属性値は，必ずしも一つではない
\cite{Kusumi1996ja}ので，計算対象となる共有属性値は集合でもよい．
もちろん，概念が共有する属性値の数が少なければ少ないほど，顕現特徴が特定
しやすいため，結果として比喩として理解されやすいといえる．}．
取り出された共有属性値集合について，source概念とtarget概念の各々における
生起確率を用いて冗長度を計算することで，顕現性落差が予測できる．
したがって，
source概念${\ast}(W_s)$ が，降順で整列した$m$個の属性値から成る属性値集合
で記述される場合を考えると，まず，生起確率上位から，閾値$\alpha$までの範
囲内に存在する$n$個の属性値(${\sum_{i=1}^{n}{p_i} > {\alpha}}$)を，その概
念の主要な属性値集合とみなして取り出し(式(\ref{exp:set}))，
\begin{eqnarray}
\label{exp:set}
	&{\ast}(W_s) = \{p_1\#w_1,p_2\#w_2,...,p_n\#w_n,...,p_m\#w_m\} \nonumber\\
	if &(p_1>p_2>...>p_n)\ \cap \sum_{i=1}^{n}{p_i} > \alpha\\
	 then &  T(W_s) = \{p_1\#w_1,p_2\#w_2,...,p_n\#w_n\} \nonumber
\end{eqnarray}
次に，取り出した属性値集合$T(W_s)$と，target概念${\ast}(W_t)$との間で
共有される属性値を探し，それらを，各々の概念における相対頻度の値とともに
取り出す．
(\ref{exp:set})に関して，source概念$\ast(W_s)$の主要な属性値集合$T(W_s)$と，
target概念${\ast}(W_t)$の間で共有される属性値集合は，
$W_{s,(T(W_s)\cap{\ast}(W_t))}$，$W_{t,(T(W_s)\cap{\ast}(W_t))}$であり，
それらの主要な共有属性値集合(属性値数$x$個，$y$個)は，
式(\ref{exp:set1}),(\ref{exp:set2})のように表せる．
さらに，それぞれの共有属性値集合の冗長度，
$r(T(W_{s,(T(W_s)\cap{\ast}(W_t))}))$，$r(T(W_{t,(T(W_s)\cap{\ast}(W_t))}))$は，
式(\ref{exp:var1})，(\ref{exp:var2})のように
計算できる．
\begin{eqnarray}
\label{exp:set1}
&T(W_{s,(T(W_s)\cap{\ast}(W_t))})
 = \{p_{s,1}\#w_1,p_{s,2}\#w_2,...,p_{s,x}\#w_x\} \\
\label{exp:set2}
&T(W_{t,(T(W_s)\cap{\ast}(W_t))})
 = \{p_{t,1}\#w_1,p_{t,2}\#w_2,...,p_{t,y}\#w_y\} 
\end{eqnarray}

ここで，上記の手順で求められた冗長度は，単に属性値のばらつき具合を示しているにすぎない．
そのため，source概念における共有属性値集合の冗長度が，target概念のそれよ
り小さい(ばらついている)場合でも，共有属性値の生起確率が概念記述全体に対し
て占める割合が大きいと，顕現特徴となる場合があり，
冗長度の差のみでは，顕現性落差を正確に反映できない．
そこで，顕現性落差を反映させるために，対象となる属性値がどの程度主要である
かによって冗長度に重み付けをする．
例えば，図\ref{fig:rep-kage}では，属性値$\{幼い\}$の生起確率は，概念
$\ast(子供)$において$0.222$であり，概念$\ast(顔)$において$0.003$である．
この場合，属性値$\{幼い\}$は，概念$\ast(子供)$において最も主要な属性値
であるが，概念$\ast(顔)$においてはそれほど主要ではないといえる．

このように，ある属性値集合における属性値が，集合全体に対して，どの程度主要
であるかということは，その属性値が集合内において保持する生起確率から把握できる．
主要な属性値を用いた冗長度と，主要でない属性値を用いた冗長度を比較した場合，
前者が主要であることが，顕現性の強調に影響すると考えられる．
よって，各々の冗長度に対して，対象となった共有属性値集合の生起
確率の総和を乗じて重み付けをし，比較した結果を顕現性落差として判断する
(式(\ref{exp:dif}))．
比較した結果が正の場合，顕現性落差は比喩性を上げるように働き，負の場合は
比喩性を下げるように働く，または生じないとみなす．
\begin{eqnarray}
\label{exp:var1}
r(T(W_{s,(T(W_s)\cap{\ast}(W_t))})) = &
   \left\{ \begin{array}{cc}
	 1 - \frac{\sum_{i=1}^{x}{{p_{s,i}}\log{\frac{1}{p_{s,i}}}}}{\log{x}}&(x{\neq}1)\\
	{1} & (x=1)
      \end{array}\right\}\\
\label{exp:var2}
r(T(W_{t,(T(W_s)\cap{\ast}(W_t))})) = &
   \left\{ \begin{array}{cc}
	 1 - \frac{\sum_{i=1}^{y}{{p_{t,i}}\log{\frac{1}{p_{t,i}}}}}{\log{y}}&(y{\neq}1)\\
	{1} & (y=1)
      \end{array}\right\}
\end{eqnarray}
\begin{eqnarray}
\label{exp:dif}
Gap(W_s,W_t) =  & 
	r(T(W_{s,(T(W_s)\cap{\ast}(W_t))}))×\sum_{i=1}^{x}{p_{s,i}} \nonumber \\
&	- r(T(W_{t,(T(W_s)\cap{\ast}(W_t))}))×\sum_{i=1}^{y}{p_{t,i}}
\end{eqnarray}

\subsubsection*{計算例}
以下に，顕現性落差の計算手法についての具体例を示す．
``子供のような顔''という比喩表現に関して，二つの構成概念，${\ast}(子供)$と
${\ast}(顔)$が図\ref{fig:rep-kage}のように，記述されている．
仮に，主要な属性値集合を決める閾値$\alpha$を0.5とした場合，
source概念${\ast}(子供)$における上位の属性値集合$T(子供)$は，
$\{幼い，小さい，たくましい，可愛い，健康だ，弱い，いたいけだ\}$
(合計0.505)となる．
さらに，$T(子供)$と${\ast}(顔)$の共有属性値として，
$\{幼い，たくましい\}$が得られるので，クローズアップされる属性値集合は
以下のように表せ，
\begin{eqnarray}
\label{exp:int}
T(子供_{T((子供)\cap\ast(顔))}) = &\{幼い\#0.222，たくましい\#0.030\}\\%$，
\label{exp:int2}
T(顔_{T((子供)\cap\ast(顔))}) = &\{幼い\#0.003，たくましい\#0.005\}
\end{eqnarray}
それぞれの冗長度は次のように計算できる．
\begin{eqnarray}
\label{exp:int1-2}
r(T(子供_{T((子供)\cap\ast(顔))})) = &
1 - \frac{
	{0.222}\log{\frac{1}{0.222}}+{0.030}\log{\frac{1}{0.030}}
	}{\log{2}}
& = 0.471\\
\label{exp:int2-2}
r(T(顔_{T(子供)\cap\ast(顔)})) = &
1 - \frac{
	{0.003}\log{\frac{1}{0.003}}+{0.005}\log{\frac{1}{0.005}}
	}{\log{2}}
& = 0.082
\end{eqnarray}
共有属性値の生起確率の総和によって重み付けをして，両者を比較すると，
\begin{eqnarray}
Gap(子供,顔) = & 
0.471{\ast}0.253 - 0.082{\ast}0.008 = & 0.118
\end{eqnarray}
$0.118$という``顕現性落差''が得られ，この概念対は，
$\{幼い，たくましい\}$という
属性値に関して，比喩性を高めるようにはたらくと判断する．

\subsection{顕現性落差計算のための知識ベース構築}
本節では，顕現性落差の定量化に用いる知識ベースの構築について述べる．
前節で説明した顕現性落差を定量化するためには，
対象となる単語を表現できる属性値集合に関する知識ベースが必要である．
知識ベース構築において，従来のように被験者を用いた心理学的実験に基
づいた場合，妥当性の高い知識は期待できるが，同手法によって，数万，
数十万と，知識を大規模化することは，極めて困難である．
コンピュータを用いた汎用的な比喩性判定を考えた場合，大規模な知識ベー
スを効率良く構築することも非常に重要である．
よって，大規模コーパスを利用した統計的なアプローチも
有効な手段の一つである．

そこで，我々は，従来の心理学的実験手法を用いず，統計的手法を用いて，
テキストコーパスから大規模な知識を自動的に抽出し，知識ベースを構築する．
具体的には，対象とするテキストコーパスを形態素解析
\footnote{茶筅 $version 2.02$\cite{Chasen1999j}を用いた．}し，得られた
結果から，``修飾語−名詞''の共起関係とその共起頻度を抽出する．
抽出された共起情報は，確率的プロトタイプモデルに基づいて，
知識ベース化する．
\begin{itemize}
\item[] 例文(1) {\em 第一日目には，赤い花が一本売れた\cite{Dazai1947j}．}
\item[] 例文(2) {\em 二人は白い花のイバラの影から出て，水蓮の咲いている小さい沼の方へ歩いて行きます\cite{Dazai1988jb}．}
\end{itemize}
例えば，例文(1)を形態素解析した結果から，共起関係``花−赤い''が抽出される．
この関係を共起頻度とともに，``$花 = \{赤い\#1\}$ ''のように記録する．
同様に，例文(2)を処理すると，共起関係``花−白い''と``沼−小さい''が抽出
できる．
その結果，知識は，``$花 = \{赤い\#0.50, 白い\#0.50\}，
沼 = \{小さい\#1.0\}$''に更新される．

上記の方法に従って，1年分の新聞記事コーパス\cite{Mainichi1995j}から知識
ベースを構築した．
知識ベース構築に際して，知識を抽出する共起範囲は1文とした
\footnote{
抽出される知識は名詞とその名詞にかかる修飾語である．
したがって，例え頻度が少なくとも，それは偶然出現したものではなく，
名詞の属性を表現するために用いられているため，属性値となる語句の範囲
が正しく抽出できれば，頻度に関わりなく，属性値として適切なはずである．
また，比喩的関係を考える場合には，通常は思い付きにくい属性値がクロー
ズアップされる可能性があることから，低頻度の属性値を用いることにも
意味があると判断し，頻度に対する閾値を設けなかった．
}．
知識として抽出された共起ペアは79,712組，属性値集合は27,958組であった．
属性値集合あたりの属性値数は1〜339，平均は2.5であった．

表\ref{tbl:nov-ex0}に知識ベースの例を示す．
``山：高い''，
``海：青い''，
``学生：若い''，
など，概念の顕現特徴を示す属性値が概ね上位に位置した．
下位の順位においても，
``山：険しい''，
``海：暗い，神秘的だ''，
``学生：無気力だ，忙しい''，
のように，概念の特徴として連想可能な属性値を見ることができる．

構築した知識ベースから，ランダムに100組を抜きだし，人手による大まかな評
価を行った.
評価は，(A)見出しの属性値として連想し易い，(B)見出しの属性値とし
て連想することが可能，(C)見出しの属性値として連想不可能，の三段階
に分類することで行った．
その結果，(A)が85組，(B)が15組，(C)が5組となった．
したがって，抽出した属性値のうち，85\%程度は顕現特徴として理解でき，
95\%程度は連想可能なものであると考えられる．

\begin{table}[tb]
\begin{center}
\caption{知識ベースの例}
\label{tbl:nov-ex0}
\begin{tabular}{|c|l|}
\hline
概念	&\multicolumn{1}{|c|}{属性値集合}\\
\hline
山&
高い\#0.111,
青い\#0.063,
静かだ\#0.048,
小高い\#0.048,
深い\#0.048,
低い\#0.048,
\\&
なだらかだ\#0.032,
丸い\#0.032,
巨大だ\#0.032,
厳しい\#0.032,
いい\#0.016,
\\&
いろいろだ\#0.016,
さびしい\#0.016,
のどかだ\#0.016,
ふしぎだ\#0.016,
\\&
険しい\#0.016,
悪い\#0.016,
遠い\#0.016,
楽しい\#0.016,
美しい\#0.016,
...\\
\hline
海&
青い\#0.228,
きれいだ\#0.087,
美しい\#0.087,
豊かだ\#0.065,
真っ青だ\#0.054,
\\&
新鮮だ\#0.054,
静かだ\#0.043,
穏やかだ\#0.043
浅い\#0.033,
暗い\#0.022,
\\&
黒い\#0.022,
真っ暗だ\#0.022,
豊富だ\#0.022,
遠い\#0.011,
輝かしい\#0.011,
\\&
広い\#0.011,
新しい\#0.011,
神秘的だ\#0.011,
素晴らしい\#0.011,
壮大だ\#0.011,
...\\
\hline
学生&
若い\#0.176,
優秀だ\#0.118,
高い\#0.059,
困難だ\#0.059,
未熟だ\#0.039,
いい\#0.039,
\\&
近い\#0.039,
まじめだ\#0.020,
よい\#0.020,
フレキシブルだ\#0.020,
暗い\#0.020,
\\&
活発だ\#0.020,
賢い\#0.020,
厳しい\#0.020,
素直だ\#0.020,
貧乏だ\#0.020,
\\&
不自由だ\#0.020,
無気力だ\#0.020,
練習熱心だ\#0.020,
忙しい\#0.020
...\\
\hline
子供&
幼い\#0.222,
小さい\#0.162,
弱い\#0.030,
たくましい\#0.030,
可愛い\#0.030,
\\&
健康だ\#0.030,
いたいけだ\#0.022,
愛らしい\#0.022,
可愛らしい\#0.022,
高い\#0.022,
\\&
長い\#0.022,
必要だ\#0.022,
未熟だ\#0.022,
あやふやだ\#0.010,
いい\#0.010,
\\&
かわいい\#0.010,
ほほえましい\#0.010,
やんちゃだ\#0.010,
悪い\#0.010,
...\\
\hline
米国&
強い\#0.091,
多い\#0.091,
厳しい\#0.055,
高い\#0.055,
広大だ\#0.036,
重要だ\#0.036,
\\&
積極的だ\#0.036,
薄い\#0.036,
必要だ\#0.036,
ワイルド\#0.036,
いい\#0.018,
\\&
さまざまだ\#0.018,
一般的だ\#0.018,
及び腰だ\#0.018,
好きだ\#0.018,
好調だ\#0.018,
\\&
広い\#0.018,
国際的だ\#0.018,
慎重だ\#0.018,
新しい\#0.018,
敏感だ\#0.018,
...\\
\hline
夢&
怖い\#0.061,
悪い\#0.061,
ささやかだ\#0.051,
遠い\#0.051,
壮大だ\#0.041,
\\&
ルナティックだ\#0.031,
不思議だ\#0.031,
変だ\#0.031,
でかい\#0.031,
\\&
はかない\#0.031,
ふさわしい\#0.020,
いい\#0.020,
こわい\#0.020,
むなしい\#0.020,
\\&
明るい\#0.020,
甘い\#0.020,
恐ろしい\#0.020,
嫌だ\#0.020,
長い\#0.020,
...\\
\hline
書類&
必要だ\#0.464,
いろいろだ\#0.107,
膨大だ\#0.107,
簡単だ\#0.071,
高い\#0.071,
\\&
さまざまだ\#0.036,
形式的だ\#0.036,
短い\#0.036,
不必要だ\#0.036,
分厚い\#0.036,
...\\
\hline
クリスマス&
寂しい\#0.222,
よい\#0.111,
楽しい\#0.111,
巨大だ\#0.111,
孤独だ\#0.111,
\\&
豪華だ\#0.111,
神聖だ\#0.111,
暖かい\#0.111
\\
\hline
イチゴ&
甘い\#0.333,
新鮮だ\#0.333,
真っ赤だ\#0.333,
\\
\hline
\end{tabular}
\end{center}
\end{table}

上の評価結果は，個々の属性値が妥当かどうかを測るものであり，
評価後の数値がそのまま属性値集合の妥当性を示すものではないが，
大規模な知識を，概ね直観に合うレベルで抽出することができたといえる．

一方で，以下に述べるような，方式限界の存在も明らかになった．
属性値の中には，ほとんどの概念と頻繁に共起するために，
概念の特徴を示す属性値とはならないケースが見られた．
``よい''や``いい''がその一例である．
これらの語は，概念によっては，その特徴を反映していない場合も多く，
属性値集合のノイズとなってしまうことがわかった．
他にも，``夢''の属性値の例があげられる．
文献\cite{GJDict1996}に記載されている``夢''の語義文を参考にして属性値を
考えると，``はかない''，``非現実的だ''，``実現困難だ''，``理想的だ
''が得られる．
上記手法によって構築された知識ベース(表\ref{tbl:nov-ex0})の``夢''の属性
値集合をみると，``はかない''以外の属性値が抽出されていないことがわかる．
これは，コーパス中において，``非現実的な''，``実現困難な''，``理想的な
''などは，非制限的な属性であり，``夢''の属性値としては一般的過ぎるため
に，修飾語として出現しにくいためと考えられる．

上で述べたような問題点は，
以降で扱う，比喩性判定の過程に影響を与えることが予想
されるが，本論文では，これを本構築手法の限界と考えている\footnote{
この問題については，6章でも議論する．}
．

以上の見地から，本手法によって構築される知識ベースは，
強調されやすい属性値の集合によって表現される，確率的な概念記述であると
いえ，概念の顕現特徴やそれらの集合を近似することは可能である．
したがって，比喩性の判定という目的においては，十分利用可能である．
\begin{table}[tb]
\begin{center}
\caption{``$AのようなB$''におけるAB間の顕現性落差の例}
\label{tbl:gap-ex}
\begin{tabular}{|c|c|c|c|}
\hline
分類	&A	&B 	&顕現性落差\\
\hline
比喩	&神様	&人	&0.993 \\
比喩	&粉	&骨	&0.811 \\
比喩	&影	&人物	&0.387 \\
比喩	&オウム&宗教	&0.231 \\
比喩	&ジャズ&リズム	&0.196 \\
例示 	&サリン	&毒物	&0.033 \\
例示 	&中国	&国	&0.008 \\
例示 	&フランス&大国	&0.000 \\
無意味 	&人間	&キャラクター	&-0.009 \\
無意味 	&夢	&馬	&-0.024 \\
無意味 	&キャンペーン	&形	&-0.042 \\
例示 	&米国	&リストラ&-0.136 \\
\hline
\end{tabular}
\end{center}
\end{table}

構築した知識ベースを用いて，単語間の顕現性落差を計算した例を表
\ref{tbl:gap-ex}に示す．
$A,B$の項の単語対は，前述のコーパスから，``$AのようなB$''というパター
ンで現れる表現の構成単語である．
表\ref{tbl:gap-ex}から，顕現性落差が大きい単語対は，比喩または例示の組
み合わせが多く，顕現性落差が小さい単語対は，例示や無意味単語対が多いこ
とがわかる．

\section{意外性の定量化}
\subsection{単語間の意味距離を用いた意外性の定量化}
2章で述べたように，比喩表現の``意外性''とは，構成概念の組み合わせの
新鮮さである．
単語同士の組み合わせがいかに新鮮かを決める要因として，それらの単語
が，日常的に用いられる文章中でどれほど頻繁に共起するか，という点があげら
れる．
よって，テキストデータ中の単語の共起情報に基づく意味距離を利用すれば，
単語組み合わせの``意外性''を定量化できるはずである．
大規模なテキストデータから，単語の共起頻度を用いて単語間の意味距離を定
量化する手法は，これまでにも数多く提案されている
\cite{Salton1989,Church1990,Smaja1993}．
本論文では，計算対象となる頻度が小さい場合でも，比較的信頼できる結果が
得られる dice係数を利用する．
 dice係数は，本来，単語間の意味距離を示す値であるため，単語間の結び付きが
強い程値が小さな値をとる．
これは，``意外性''の定義とは反対の概念であるため，dice係数の逆数を
``意外性''の値として用いることにする．
したがって，あるテキスト中において出現する二つの単語$W_s$，$W_t$が，それ
ぞれ，$p_s$，$p_t$の頻度で出現しており，そのうち両者が共起する頻度が
$p_s・p_t$である場合，``意外性''$Nov(W_s,W_t)$は，式
(\ref{exp:novelty})で表される．
\begin{eqnarray}
\label{exp:novelty}
Nov(W_s,W_t) = & \frac{p_s＋p_t}{2(p_s・p_t)}
\end{eqnarray}

この計算方法では，dice係数の値が0となる場合，すなわち，対象とする
単語間の共起頻度が0の場合は値が得られない．
共起頻度が得られないということは，単語の抽出元であるコーパス中か
らは，意外性を判断するための基本情報が得られなかったと判断できる．
したがって，単語間の共起頻度が0であった場合は，判定不能として扱う
．
この場合，顕現性落差の計算が可能であったとしても，比喩性の判定は
不能となる．

\begin{table}[tb]
\begin{center}
\caption{``$AのようなB$''における$AB$間の意外性の例}
\label{tbl:nov-ex}
\begin{tabular}{|c|c|c|c|}
\hline
分類	&A	&B 	&意外性\\
\hline
無意味	&人間 &キャラクター	&2917\\%A
比喩	&神様 &人	&1429\\%M
無意味	&キャンペーン &形&837\\%A
比喩	&矢 &パス	&595\\%M
比喩	&少年 &笑顔	&308\\%M
比喩	&夢 &存在	&226\\%M
例示	&フランス &主張	&131\\%S
例示	&中国 &大国	&94\\%S
比喩	&ジャズ &リズム	&39\\%M
例示	&サリン &物質	&14\\%S
\hline
\end{tabular}
\end{center}
\end{table}

\subsubsection*{計算例}
以下，意外性の計算手法について，具体例を示す．
``山のような書類''という比喩表現に関して考える．
ある新聞記事\cite{Mainichi1995j}では，二つの単語``山''および``書類''の頻度は
それぞれ，2695，1033であり，両者の共起頻度が4である．
このとき``意外性''は，
\begin{eqnarray}
\label{calc:novelty1}
Nov(山,書類) = & \frac{2695＋1033}{2{\ast}4} = 466
\end{eqnarray}
となる．
同様に，``文書のような書類''という表現の場合，
二つの単語``文書''および``書類''の頻度はそれぞれ，1898，1633，両者の共起頻度
が20なので，``意外性''は，
\begin{eqnarray}
\label{calc:novelty2}
Nov(文書,書類) = & \frac{1898＋1633}{2{\ast}20} = 88.25
\end{eqnarray}
となり，``山，書類''と比較して意外性が小さいことがわかる．

\subsection{意外性計算のための知識ベース構築}
顕現性落差同様，テキストコーパスから，統計的手法を用いて大規模な知識を取
り出し，意外性の定量化に用いる知識ベースを構築する．
具体的には，対象とするテキストを形態素解析\cite{Chasen1999j}し，得られた
その処理結果から，全ての名詞とその出現頻度，および，1文をスコープとした場合
の名詞共起とその共起頻度を抽出して構築する．

例文(2)には5つの名詞``二人''，``花''，``イバラ''，``影''，``水蓮''，``沼''
が存在する．
共起範囲を一文として各名詞のペア組合せを考えると，14組の名詞ペアが考えら
れる．
このとき，各名詞の出現頻度と共起頻度，それらに基づいて名詞間の意味距離
が計算できる．
以上の結果を知識ベースとして，$\{二人,花：29,32,4\}$のように記録する．


表\ref{tbl:nov-ex}に，単語間の意外性の例を示す．
これらは，1年分の新聞記事コーパス\cite{Mainichi1995j}を利用して
構築した知識ベースを用いて，計算した結果である．
知識ベース構築のための共起範囲は1文とし，共起頻度5以上のものを対象とした．
$A,B$の項の単語対は，前述のコーパスから，``$AのようなB$''というパターン
で現れる表現の構成単語である．
表\ref{tbl:nov-ex}から，意外性が高い単語対は比喩または無関係の組み合わせ
が多く，意外性が下位のものは例示の組み合わせが多いことがわかる．

\section{評価}
\subsection{評価方法}
3章で用いた新聞記事コーパス1年分約11万記事，436MB\cite{Mainichi1995j}か
ら，二種類の知識ベースを構築した．
知識ベース構築のための共起範囲は1文とした．
顕現性落差計算用の知識ベースについては全てを，意外性計算用の
知識ベースについては，共起頻度5以上のものを対象とした．
検証のためのデータとして，以下のような二種類の単語対データ計100組
を用意した．
\begin{enumerate}
\item[データ(1)]
	知識ベース構築に用いた新聞記事コーパス\cite{Mainichi1995j}中に現
	れる，``$AのようなB$''というパターンで現れる表現の構成単語のうち，
	知識ベースから検索可能な単語対$(A，B)$：70組
\item[データ(2)]
	知識ベースとは関係のない新聞記事コーパス\cite{Mainichi1998ja}中
	に現れる，``$AのようなB$''というパターンで現れる表現の構成単語の
	うち，知識ベースから検索可能な単語対$(A，B)$：30組
\end{enumerate}
$(A,B)$の単語対は，比喩指標``ような''を含む文を取り出して形態素解析
\cite{Chasen1999j}し，``ような''の両端に，名詞が位置するものを取り出し，
さらに，指示語や代名詞，を取り除いて作成した．
これらの単語対は，あらかじめ人手で比喩関係対・例示関係対・無意味対，
の三種類の区別を行った．
区別は，対象の単語対を用いて，`$AのようなB$'という表現を構成した場合
に，どのように理解できるかという点を重視し，以下のように行った．
\begin{itemize}
\item[(a)] 比喩表現として理解可能な場合…`比喩関係対' ，
\item[(b)] 例示表現として理解可能な場合…`例示関係対'， 
\item[(c)] いずれの表現としても理解不能な場合…`無意味対'\footnote{
機械的に抽出したため，複合語を構成する単語が単独で取り出された場合に，
無意味な組合せとなる場合がある．}， 
\end{itemize}

以上の単語対データに対して，顕現性落差および意外性を計算し，
二つの尺度値に基づいて単語対を区別した．
主要な共有属性値を決める閾値$\alpha$は，属性値集合全体における過半数を
占める属性値を主要であると考えて 0.5とし，単語対の区別は
表\ref{tbl:relation}に対応させた．
分類の基準として閾値を設定した．
顕現性落差については，計算結果が0未満($Gap(A,B) < 0)$の場合に無意味単語
対であると判定した．
意外性については，データ(1)の意外性の各計算値において，例示と非例示(比喩，
無意味)のカバー範囲を分析して閾値を設定した．
例示と非例示の双方を網羅する平均カバー率が，最も広い値(平均カバー率が最
も大きい)値は$Nov(A,B)=146$であるので(図\ref{tbl:nov-cover})，意外性の
計算結果が146以下の場合($Nov(A,B) {\leq} 146$)に例示であると判定した．

\begin{figure}[tb]
  \begin{center}
     \epsfile{file=balance.eps,scale=0.4}
     \caption{意外性の境界と例示・非例示単語対カバー率}
     \label{tbl:nov-cover}
  \end{center}
\end{figure}

次に，データ(2)に対しても顕現性落差と意外性を計算し，データ(1)で設定
した閾値を適用して，その判別性能を調べた．
このとき，計算過程において，クローズアップされる共有属性値やその集合
が，比喩の顕現特徴として順当なものであるかどうかについては考慮しない．
対照実験として，全ての単語組合せを比喩，例示，無意味のいずれか一種類
と判断した場合三例の実験と，三種をランダムに判定した実験を行った．

\subsection{評価結果}
表\ref{tbl:eval1}は，データ(1)における評価結果であり，知識ベースと単語対
が関連している可能性がある場合についての検証である．
ここで，実際の比喩単語対は48組，提案手法によって比喩単語対と判別された単
語対は30組，そのうち正しく判別できた数は25組であった．
よって，データ(1)に対する本手法の比喩単語対の判別能力は，適合率
$83.3\%$，再現率$52.1\%$となる．
同様に，例示単語対の判別能力は，適合率$50.0\%$，再現率$52.2\%$，無意味単
語対については，適合率$22.2\%$，再現率$80.0\%$であった
．

表\ref{tbl:eval2}は，データ(2)における評価結果であり，知識ベースと単語対
が全く関連のない場合についての検証である．
ここで，実際の比喩単語対は13組，提案手法によって比喩単語対と判別された単
語対は11組，そのうち正しく判別できた数は8組であった．
よって，データ(2)に対する本手法の比喩単語対の判別能力は，
適合率$72.7\%$，再現率$61.5\%$となる．
同様に，例示単語対の判別能力は，適合率$75.0\%$，再現率$50.0\%$，無意味単
語対については，適合率$57.1\%$，再現率$80.0\%$であった
．

上記の結果と，四種類の対照実験結果とを比較したものを，表
\ref{tbl:eval1b}，\ref{tbl:eval2b}に示す．
各表中では，各単語対毎の認識結果について，適合率と再現率を示している．
総合的な性能\footnote{
全ての単語対については結果が得られているので，適合率のみが議論の対象とな
る．
}
については，
データ(1)では，提案手法の性能は54.3\%，
全てを比喩と判定した結果が68.6\%，
全て例示と判定した場合は，24.3\%，
全て無意味と判定した場合は，7.1\%，
ランダムに判定した場合は 38.6\%であった．
データ(2)では，提案手法の性能が60.0\%，
全てを比喩と判定した結果は43.3\%，
全て例示と判定した場合は40.0\%，
全て無意味と判定した場合は16.7\%，
ランダムに判定した場合が 26.7\%であった．

\section{考察}
\begin{table}[tb]
  \begin{center}
     \caption{顕現性落差と意外性に基づく概念対の判別結果：(データ(1))}
     \label{tbl:eval1}
\begin{tabular}{|c|c|c|c|c||c|}
\hline
   &	&	&$Gap(A,B){\geq}0$ & $Gap(A,B)<0$&\\
   &{顕現性落差}&{分類}	&(比喩単語対	&(無意味単語対)	&total\\
   &		&	&・例示単語対)	&	&\\
\hline
   \cline{2-6}
   & $Nov(A,B)>146$   	& 比喩   &{\bf 25}&11	&36 \\
         \cline{3-6}
意 & (比喩単語対・	& 例示   &4	&3	&7 \\	
         \cline{3-6}
外 &  無意味単語対)  	& 無意味 &1	&{\bf 4}&5 \\
   \cline{2-6}
性 &$Nov(A,B){\leq}146$	& 比喩   &9	&3	&12\\
         \cline{3-6}
   & (例示単語対)	& 例示   &{\bf 9}&1	&10\\
         \cline{3-6}
   &		   	& 無意味 &0	&0	&0 \\
\hline
\hline
\multicolumn{2}{|c|}{}
   			& 比喩	&34	&14	&48\\
         \cline{3-6}
\multicolumn{2}{|c|}{total}
   			& 例示	&13	&4	&17\\
         \cline{3-6}
\multicolumn{2}{|c|}{}
   			& 無意味&1	&4	&5\\
\hline
\multicolumn{5}{l}{データ：毎日新聞1995年度CD-ROMから抽出(70組)}\\
\multicolumn{5}{l}{知識ベース：毎日新聞1995年度CD-ROMから構築(約28,000組)}\\
\end{tabular}
\end{center}
\end{table}
\begin{table}[tb]
  \begin{center}
     \caption{顕現性落差と意外性に基づく概念対の判別結果(データ(2))}
     \label{tbl:eval2}
\begin{tabular}{|c|c|c|c|c||c|}
\hline
   &		  &	&$Gap(A,B){\geq}0$ & $Gap(A,B)<0$&\\
   &{顕現性落差}&{分類}&(比喩単語対	&(無意味単語対)	&total\\
   &		&	&・例示単語対)	&	&\\
\hline
   \cline{2-6}
   & $Nov(A,B)>146$& 比喩     &{\bf 8}	&1	&9 \\
         \cline{3-6}
意 & (比喩単語対・	& 例示&3	&2	&5 \\	
         \cline{3-6}
外 & 無意味単語対) 	& 無意味&0	&{\bf 4}&4 \\
   \cline{2-6}
性 & $Nov(A,B){\leq}146$& 比喩  &2	&2	&4\\
         \cline{3-6}
   & (例示単語対)	&例示&{\bf 6}&1	&7\\
         \cline{3-6}
   &	& 無意味 	&0	&1	&1 \\
\hline
\hline
\multicolumn{2}{|c|}{}
	& 比喩		&10	&3	&13\\
         \cline{3-6}
\multicolumn{2}{|c|}{total}
	& 例示		&9	&3	&12\\
         \cline{3-6}
\multicolumn{2}{|c|}{}
	& 無意味	&0	&5	&5\\
\hline
\multicolumn{5}{l}{データ：毎日新聞1998年度(a)CD-ROMから抽出(30組)}\\
\multicolumn{5}{l}{知識ベース：毎日新聞1995年度CD-ROMから構築}\\
\end{tabular}
\end{center}
\end{table}

まず，総合的な性能について考察する．
表\ref{tbl:eval1}では，全てを比喩と判定した場合の性能が提案手法を上回っ
た．
これは，全てを一種類に判定する手法の性能については，正解となる単語対デー
タ数が，全体に占める割合を反映する性質を持つことに起因する．
したがって，データ(1)では，比喩単語対の割合が多いために，同手法の性能が高
くなったが，データ(2)では，は43.3\%と，比喩単語対の判別能力が著しく低下し
いる．
これに対し，提案手法は，データ(2)においても72.7\%の比喩単語対判別能力を得
ており，対照実験と比較して，安定しているといえる．

適合率についてみると，表\ref{tbl:eval1b}では，比喩と例示において，
表\ref{tbl:eval2b}では全てにおいて，提案手法が最も良い結果であった．
再現率については，ランダムの場合との比較のみが意味を持つが，この場合，い
ずれの種類においても，提案手法が最も良い結果であった．

比喩単語対に限って言えば，本手法の評価結果は，概ね$70\%$以上の適合
率と$50\%$以上の再現率が得られており，本手法による比喩性検出は有効である
と考えられる．
例示関係対については，データ(1)よりもデータ(2)の結果の方が良
い結果を示した．
これは，データ(1)では，(a)意外性が高いと判断された例示単語対が多かったこ
とが再現率を下げ，(b)例示単語対と判断された比喩単語対が多かったことが適
合率を下げたためである．
無意味単語対についても同様で，データ(2)の方が良い結果であった．
再現率はどちらも80.0\%であるから，データ(1)において，他の表現を無意味単
語対と誤認識した場合が多かったことが原因であるといえる．

表\ref{tbl:eval1}では，
比喩単語対を無意味語対とあやまって判定したものが14組(29.2\%)，
比喩単語対を例示単語対とあやまって判定したものが9組(18.8\%)，
例示単語対を比喩単語対とあやまって判定したものが4組(23.5\%)，
例示単語対を無意味単語対とあやまって判定したものが4組(23.5\%)，
無意味単語対を比喩単語対とあやまって判定したものが1組(20.0\%)あった．
表\ref{tbl:eval2}では，
比喩単語対を無意味語対とあやまって判定したものが3組(23.1\%)，
比喩単語対を例示単語対とあやまって判定したものが3組(15.4\%)，
例示単語対を比喩単語対とあやまって判定したものが3組(25.0\%)，
例示単語対を無意味単語対とあやまって判定したものが3組(25.0\%)，
無意味単語対を比喩単語対とあやまって判定したものはなかった．
この結果からみると，比喩単語対を無意味対とあやまって判定するケースと，
例示単語対を比喩単語対とあやまるケースが多いことがわかる．

\begin{table}[tb]
  \begin{center}
     \caption{対象実験結果との比較：(データ(1))}
     \label{tbl:eval1b}
\begin{tabular}{|c|c|r|r|r|r|r|}
\hline
\multicolumn{2}{|c|}{}
		&本手法&全比喩 & 全例示 & 全無意味 & ランダム\\
\hline
比&適合率	&{\bf 83.3}	&68.6	&-	&-	&37.1\\
喩&再現率	&52.1		&{\bf 100}&0	&0	&16.7\\
\hline
例&適合率	&{\bf 50.0}	&-	&24.3	&-	&20.6\\
示&再現率	&52.2		&0	&{\bf 100}&0	&25.5\\
\hline
無&適合率	&{\bf 22.2}	&-	&-	&7.1	&9.5\\
意味&再現率	&80.0		&0	&0	&{\bf 100}&40.0\\
\hline
\end{tabular}
\end{center}
\end{table}
\begin{table}[tb]
  \begin{center}
     \caption{対象実験結果との比較：(データ(2))}
     \label{tbl:eval2b}
\begin{tabular}{|c|c|r|r|r|r|r|}
\hline
\multicolumn{2}{|c|}{}
		&本手法&全比喩 & 全例示 & 全無意味 & ランダム\\
\hline
比&適合率	&{\bf 72.7}	&43.3	&-	&-	&37.1\\
喩&再現率	&61.5		&{\bf 100}&0	&0	&33.3\\
\hline
例&適合率	&{\bf 75.0}	&-	&40.0	&-	&20.0\\
示&再現率	&50.0		&0	&{\bf 100}&0	&10.7\\
\hline
無&適合率	&{\bf 57.1}	&-	&-	&16.7	&50.0\\
意味&再現率	&80.0		&0	&0	&{\bf 100}&26.7\\
\hline
\end{tabular}
\end{center}
\end{table}

以下，評価結果から，正解例および失敗例を，各単語対別に，表
\ref{tbl:correct}，表\ref{tbl:false}に示し，問題点に関して詳述する．

\begin{table}[tb]
\begin{center}
\caption{判別結果の正解例}
\label{tbl:correct}
\begin{tabular}{|l|r|r|l|}
\hline
\multicolumn{1}{|c|}{A,B}&Nov(A,B)&Gap(A,B)&\multicolumn{1}{|c|}{クローズアップされた共有属性値}\\
\hline
\multicolumn{4}{|c|}{比喩単語対}\\
\hline
離宮，建物	&1363   &0.992  &美しい\\
友達，父       &654    &0.200  &良い\\
枝，柱         &1017   &0.181  &黒い\\
水，人間       &225    &0.040  &冷たい\\
夢，話	&158    &0.001  &悪い,怖い,遠い,不思議だ,変だ,いい,\\
	&	&	&こわい,ふさわしい\\
\hline
\multicolumn{4}{|c|}{例示単語対}\\
\hline
惑星，星       &132    &0.622  &美しい\\
自分，人間     &43     &0.234  &新しい, ダメだ\\
インド，国     &144    &0.018  &多い,強い,広い\\
米国，国       &47     &0.010  &強い,多い,厳しい,高い,広大だ,重要だ,\\
		&	&	&積極的だ,薄い\\
米国，社会     &88     &0.005  &多い,厳しい,高い,積極的だ\\
\hline
\multicolumn{4}{|c|}{無意味単語対}\\
\hline
青春，心       &755    &-0.001 &ナイーブだ,懐かしい\\
ゲーム，いじめ &1877   &-0.007 &さまざまだ,新しい\\
東京，モノ     &1314   &-0.058 &高い\\
動物，脳       &217    &-0.059 &さまざまだ\\
機械，技術     &73     &-0.007 &古い,特殊だ\\
\hline
\end{tabular}
\end{center}
\end{table}
\begin{table}[tb]
\begin{center}
\caption{判別結果の失敗例} 
\label{tbl:false}
\begin{tabular}{|l|r|r|l|}
\hline
\multicolumn{1}{|c|}{A,B}&Nov(A,B)&Gap(A,B)&\multicolumn{1}{|c|}{クローズアップされた共有属性値}\\
\hline
\multicolumn{4}{|c|}{比喩単語対以外のものを比喩単語対と誤判定した例}\\
\hline
睡眠薬，薬     &194    &0.983  &強力だ\\
アメリカ，社会 &435    &0.340  &良い\\
遺書，地域 	&1101	&0.293	&新ただ\\
清水，地域 	&186	&0.238	&悪い\\
田舎，関係 	&2012	&0.127	&深い\\
\hline
\multicolumn{4}{|c|}{例示単語対以外のものを例示単語対と誤判定した例}\\
\hline
牛刀，刃物     &45     &0.750  &鋭い\\
波，流れ       &506    &0.483  &新しい\\
影，人物       &25	&0.118 &暗い\\
鬼，形相       &97     &0.133  &恐ろしい\\
報道，発言     &32     &0.026  &冷静だ,いろいろだ\\
\hline
\multicolumn{4}{|c|}{無意味単語対以外のものを無意味単語対と誤判定した例}\\
\hline
夢，世界       &94     &-0.001 &遠い,不思議だ,いい,ふさわしい\\
少年，表情     &314    &-0.008 &優しい,げだ\\
米国，対応     &65	&-0.022 &厳しい,積極的だ,必要だ\\
小説，読み物   &246    &-0.155 &面白い\\
日本，戸籍     &734	&-0.924 &新しい\\
\hline
\end{tabular}
\end{center}
\end{table}

(1)
本論文では，比喩性判定処理において，比較される概念間の共有属性値の妥当性
は特に考慮していない．
しかし，厳密な意味で比喩理解を考えた場合，クローズアップされる共有属性値
の尤もらしさも考慮の対象となる．
例えば，「枝のような柱」では，``黒い''という共有属性値が，顕現特徴として
クローズアップされている．

1章で述べたように，比喩理解が，複数の顕現特徴に基づくと考えれば，``黒い''
が，クローズアップされる属性値の一つであると考えることもできる．
しかし，厳密には，``細い''や``長い''などの語が，より上位の共有属性値とし
て選ばれた方が，人間の直観に合う．
この問題は，2章で述べたように，
極めて一般的な属性値が，コーパス中に現れにくく，結果として抽出に失敗する
という知識ベース構築手法の方式限界に関連している．
問題解消のためには，概念辞書や語義文から属性値を取り出すなどして，
属性値を補完する必要がある．

(2)
総合評価で述べた例示単語対の誤認識において，(a)については，``遺書''と
``文書''や``清水''と``地域''のように，上位下位関係にあるが，一方が固有名
詞であったり，分野依存性が強い場合には極端な頻度差が生じ，結果として意外
性の値が高くなってしまう場合や，``日本のような戸籍''のように，一方の比較
対象が単語として現れていない場合であり，比較する単語と，比較する意味にズ
レが生じ
\footnote{この場合は，``日本で採用されている戸籍制度''を``国勢管理手段''
の例として取り上げている．}，
単語の共起を元に計算された意外性の値が，意味的な意外性と食い違ってしまっ
たことが原因と考えられる．

前者の問題に対しては，新聞記事以外のコーパスや，複数の分野に関するコーパ
スを知識源として知識ベースを構築することで対応できそうである．
固有名詞については，形態素解析で網羅できない場合もあると思われる．
よって，固有表現抽出処理を利用することによって，固有名詞の出現頻度をさら
に詳細に網羅することも有効であろうと考えられる．
後者については，表層に現れていない比較対象概念を導き出さなければならない．
そのためには，表現が現れた箇所の文脈解析や照応解析が必要である．

(3)
総合評価で述べた例示単語対の誤認識において，(b)については，``ジャズのよ
うなリズム''や，``けん銃のような音''のように，一方の比較対象が単語として
現れていない場合が多い．
したがって，(2)の場合と同様に，表層に現れていない比較対象概念を導き出す
必要がある．
この問題への対策として，中村\cite{Nakamura1977}による「比喩関係からみた
言語形式の分類」と概念辞書を用いて，他の単語対と区別して処理する方法が考
えられる．

(4)
共有属性値集合の中に，``よい''や``いい''など，ひらがなで表記される形容詞
が多く見られた．
これは，3章で述べた，知識ベース構築手法の方式限界に関する問題である．
これらの語は，通常，様々な名詞への修飾語として数多く出現するため，
多くの概念の属性値となり易いと考えられる．
その結果，顕現性落差を計算する場合に，共有属性値として抽出される確率
も高く，頻度が多くなるために，属性値内の順位も上位となり易い．
このような，極端に高頻度であったり，多数の名詞と共起する単語については，
属性値候補から削除するというような対策が必要であると思われる．

(5)
比喩単語対を無意味単語対とあやまって判定したものは，ほとんどが``夢''を
source概念$(A)$とした単語対であった．
特にデータ(1)ではこの傾向が顕著で(14組中11組)，無意味単語対の適合率低下
にも大きく影響している(再現率は80\%だが，適合率が22\%にとどまった)．
無意味単語対と判定された原因は，``夢''という単語が，共有属性値集合におい
て，他の単語より特徴が少ないということ，様々な単語との意味距離が近いと判
断されたためである．
すなわち，``夢''という語が様々な特徴を持っており，様々な場面で用いられて
いるということになるのだが，``夢のような計画''や``夢のような世界''は，明
らかに比喩であると判定されるべきである．
対策として，本来比喩的な性質を持つ語というものを他と区別して定義して扱
う，辞書や語義文を用いて，一般的な修飾語としては現れにくい属性値を取り
出す，などが考えられる．

(6)
``新しい''，``あたらしい''，``新ただ''や，``美しい''，``きれいだ''は，
概念の特徴としては，同じ意味を示すものであるが，異なる属性値として扱わ
れている．
これは，知識ベース構築時における単語の区別を，形態素解析結果をそのまま利
用しており，同義性が考慮されていないためである．
これらの，意味的に同一または類似である異表記単語を同一のものとしてクラス
タリングできれば，知識ベースにおける各属性値集合を意味的な属性値集合とし
て構成でき，各尺度に基づく計算の誤差も小さくなるはずである．
そのためには，属性値となる形容詞や形容動詞について，概念辞書や語彙体
系などを用いてクラス分類する必要がる．

(7)
顕現性値の計算結果が0となる場合があった．
しかし，実際には，ある概念の特徴が全く思い付かない場合というのはいかにも
不自然である．
この原因は，知識ベースにおいて，属性値集合の各属性値が全て同じ頻度である
場合に，「完全に発散した状態」として計算されるためである．
この場合，顕現性落差計算における重み付け効果も無くなるため，正確な比較が
できていなかったといえる．
上記の問題に対しては，コーパスの規模を拡大することによって，全体的な属性
値の頻度を増やす方法や，辞書や語彙体系を利用して，属性値に重みを付ける方
法が考えられる．

(8)
評価結果において，``インドのような国''や，``フランスのような主張''に
ついては，単語対の共有属性値としては，$\{多い，広い\}$や，$\{強い\}$など
が取り出された．
これらは，一般的な概念として考えても，知識源である新聞記事内の意味におい
ても，正しい結果であるといえる．
しかし，これらの表現は，``インド''や``フランス''を，ある特徴を示す国の例
として取り上げている例示の場合と，他の国を指して，``フランスの主張''や
``中国''にそっくりであるとして表現する比喩の場合がある．
どちらに決定されるかは，上記の表現を含む文脈に強く依存する．
ところが，今回は，単語の知識のみを用いて比喩性を判断しているため，この
ような場合には対応できない．

\section{むすび}\label{conc}
本論文では，一般的な文書に出現する比喩表現を認識するために，
確率的な尺度を用いて，単語間の比喩性を検出する手法について述べた．
比喩性を検出するための尺度として，
比喩構成語が理解可能かどうかに関わる``顕現属性落差''と，
語の組合せがどれ程斬新かに関わる``意外性''を定義し，
確率的なプロトタイプ概念記述および単語間の意味距離を利用して定量化した．
さらに，コーパス中の共起関係に基づいて構築した知識ベースを用いて
比喩性判定実験評価を行った結果，
提案モデルが有効であることが確認された．
今後は，考察で得られた知見に基づいて，
単語の同義性を考慮した知識ベースを構築した本手法の精緻化，
比喩的な機能を持つ特殊な語の扱い，
新聞記事以外のコーパスや概念辞書の利用，を進めていく予定である．

また，今回の性能評価では，知識ベース中に共有属性値が存在しなかった場合の
顕現性落差や，コーパス中から共起頻度が得られなかった単語対の意外性につい
ては，評価対象外とした．
これは，それぞれ，
``共有属性値が存在しない原因としては，実際に比較対象概念間に共有特徴が
存在しない場合と，知識ベース中の属性値集合間に共有属性値が存在しなかった
場合が考えられるが，両者の区別は簡単ではない''，
``共起頻度が得られない原因としては，コーパス中に単語共起が存在しないと
いう事実が，すなわちそれらの単語対が一般的に共起しないことを証明するも
のではない''という理由による．
しかしながら，``共有属性値がない場合は，無意味対である可能性が高い''とい
うことや，``個々の単語がそれぞれ有意な出現頻度を示していながら，共起が生
じない場合は，意外性は非常に高い''ということは，容易に推測できる．
したがって，これらの推測過程の妥当性を確認し，本手法へ適用することにより，
判別性能を精緻化することを考えている．

本研究の具体的な応用事例研究としては，1章で述べた機械翻訳への適用の他に，
比喩表現を検索要求として扱える検索システムや，質問応答における比喩表現
を用いた応答文生成などを考えている．



\bibliographystyle{jnlpbbl}
\bibliography{jpaper}

\newpage
\begin{biography}
\biotitle{略歴}
\bioauthor{桝井 文人}{
1990年岡山大学理学部地学科卒業．
同年，沖電気工業（株）入社．
2000年三重大学工学部情報工学科助手．
現在に至る．
質問応答システム，情報抽出の研究に従事．
電子情報通信学会，人工知能学会，言語処理学会各会員．}
\bioauthor{福本 淳一}{
1984年広島大学工学部第２類卒業．
1986年同大学院工学研究科博士前期課程修了．
同年沖電気工業株式会社入社．
1992〜1994年英国マンチェスター科学技術大学言語学部Ph.D.コース在学．
Ph.D.
2000年立命館大学理工学部情報学科助教授．
現在に至る．
質問応答システム，情報抽出，自動要約の研究に従事．
情報処理学会，人工知能学会，言語処理学会，ACL各会員．}
\bioauthor{椎野 努}{
1964年名古屋大学工学部電気学科卒業．
同年沖電気工業（株）入社.
1990年三重大学工学部情報工学科教授．
2002年愛知工業大学工学部情報通信工学科教授．
現在に至る．
自然言語処理，画像処理，感性情報処理の研究に従事．
工学博士．
電子情報通信学会，人工知能学会，言語処理学会，IEEE各会員．}
\bioauthor{河合 敦夫}{
1980年名古屋大学理学部化学科卒業．
1985年同大学大学院工学研究科博士課程修了．工学博士．
同年日本電信電話（株）入社.
1992年三重大学工学部情報工学科助教授，現在に至る．
自然言語処理，色画像理解の研究に従事．
情報処理学会，電子情報通信学会，言語処理学会各会員．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}
\end{biography}
\end{document}
