<?xml version="1.0" ?>
<root>
  <title>確率的判定尺度を用いた比喩性検出手法</title>
  <author>桝井文人福本淳一椎野努河合敦夫</author>
  <jabstract>本論文では，テキスト中に出現する比喩表現を認識するために，確率的な尺度を用いて，概念(単語)間の比喩性を検出する手法について述べる．比喩性を検出するための確率的な尺度として，``顕現性落差&quot;と``意外性&quot;を設定する．``顕現性落差''は，概念対を比較したときに，クローズアップされる顕現特徴の強さをはかる尺度であり，概念同士が理解可能か否かの判断に用いる．``顕現性落差''は，確率的なプロトタイプ概念記述を用いて，概念の共有属性値集合が持つ冗長度の差で定量化する．``意外性''は，概念の組み合わせがどれほど稀であるかをはかる尺度であり，概念同士が例示関係であるか否かの判断に用いる．``意外性&quot;は，単語間の意味距離を用いて定量化する．二つの尺度を併用することによって，比喩関係を持つ概念対，すなわち，比喩性の判定が可能となる．二つの尺度を計算するために，コーパス中から抽出した語の共起情報を利用して知識ベースを利用する．両尺度を用いた比喩性検出手法を検証するために，1年分の新聞記事コーパスから構築した知識ベースと，比喩関係・例示関係・無意味の各単語対が混在するデータ100組を用いて，単語対の判別実験を行った．その結果，70%以上の適合率で比喩関係単語対が判別できることがわかり，本手法の有効性が確認できた．</jabstract>
  <jkeywords>比喩性，顕現性落差，意外性，大規模知識ベース</jkeywords>
  <subsubsection title="">*計算例以下に，顕現性落差の計算手法についての具体例を示す．``子供のような顔''という比喩表現に関して，二つの構成概念，(子供)と(顔)が図のように，記述されている．仮に，主要な属性値集合を決める閾値を0.5とした場合，source概念(子供)における上位の属性値集合T(子供)は，幼い，小さい，たくましい，可愛い，健康だ，弱い，いたいけだ(合計0.505)となる．さらに，T(子供)と(顔)の共有属性値として，幼い，たくましいが得られるので，クローズアップされる属性値集合は以下のように表せ，T(子供_T((子供)(顔)))=&amp;幼い#0.222，たくましい#0.030%，T(顔_T((子供)(顔)))=&amp;幼い#0.003，たくましい#0.005eqnarrayそれぞれの冗長度は次のように計算できる．r(T(子供_T((子供)(顔))))=&amp;1-	0.22210.222+0.03010.030	2&amp;=0.471r(T(顔_T(子供)(顔)))=&amp;1-	0.00310.003+0.00510.005	2&amp;=0.082eqnarray共有属性値の生起確率の総和によって重み付けをして，両者を比較すると，Gap(子供,顔)=&amp;0.4710.253-0.0820.008=&amp;0.118eqnarray0.118という``顕現性落差''が得られ，この概念対は，幼い，たくましいという属性値に関して，比喩性を高めるようにはたらくと判断する．</subsubsection>
  <section title="まえがき">比喩とは，ある概念を他の概念によって説明または強調する修辞的手法の一つであり，様々な分野で研究対象として取り上げられている．自然言語処理の分野においても，比喩表現はしばしば問題となる．例えば，機械翻訳において，現状のシステムでは意訳や再解釈などの深い処理は行われないため，目的言語に翻訳された比喩表現は，意図した内容と異なった出力となってしまう場合がある．``水のような価値''という比喩表現は，日本語では「価値が低い」という意味として理解されるが，言語によっては，「非常に価値が高い」ことを意味する場合がある．これは，``水''が持つ特徴が言語間で異なるからであり，この違いを補正するためには，原言語における「価値が低い」という特徴を保持したまま，対象言語において，同様の特徴を持った言葉を選び出す必要がある．しかし，現状の機械翻訳では，このような，言語間の意味の相違を考慮した処理は不可能である．このような場合，その表現が比喩であるかどうかを判断し，``asworthaswater''や``valuelikeaswater''と直訳されることを防ぐだけでも有効であると思われる．また，李によれば，新聞記事などの実用文においても，比喩表現は数多く出現し，その割合は小説や雑誌と大差はない．したがって，自然言語処理の対象を一般的な文書へ拡大し，柔軟な処理を行うたためには，比喩表現の処理は重要である．従来，比喩に関する研究は，心理学の分野において発展してきた．OrtonyやGentnerをはじめ，多くの比喩理解の理論的モデルが，提案されている．楠見は，心理学的実験手法によって，比喩理解に必要な知識を計測し，いくつかの理論的モデルの検証を行っている．しかしながら，上記で述べたような心理学実験は，被験者に対するアンケートやテストによって知識を得る手法であるため，汎用的な大規模知識ベースを構築するという目的に対しては，被験者数の確保や被験者集団の知識の偏り，個人差の是正の困難さやコストの面で大きな制限がある．比喩理解の過程を計算機上で実現するためには，比喩の理解過程を，なんらかの形でモデル化して扱う必要がある．岩山らは，プロトタイプ理論に基づいて概念を生起確率を持った属性値集合として記述し，比喩を構成するときの特徴の移動を定量化する計算モデルを提案しており，内海も同様の計算モデルを用いて，心理学実験データに基づく知識ベースを用いた比喩理解の実験を行い，人間の判断結果と比較している．彼らのモデルでは，比喩の理解過程は比喩表現として尤も強調される特徴(顕現特徴)が，たとえる概念(source概念)からたとえられる概念(target概念)へ移動するプロセスとして扱われている．しかしながら，楠見らが指摘するように，比喩理解において，比喩性を有する概念間の共有属性値は必ずしも一つとは限らず，複数の顕現特徴を扱う場合については議論の余地がある．また，彼らも，人手によって知識ベースを構築しており，知識の大規模化，汎用化の問題は解消されていない．そこで，本論文では，テキスト中に出現する比喩表現を認識するために，確率的な尺度を用いた比喩性検出手法を提案する．比喩性を検出するための確率的な尺度として，``顕現性落差&quot;と``意外性&quot;を設定する．``顕現性落差''は，概念対を比較したときに，クローズアップされる顕現特徴の強さをはかる尺度であり，概念の組合せが理解可能である否かの判断に用いる．``顕現性落差''は，確率的な概念記述を用いて，概念の共有属性値集合が持つ冗長度の差で定量化する．``意外性''は，概念の組み合わせがどれほど斬新であるかをはかる尺度であり，概念同士が例示関係であるか否かの判断に用いる．``意外性&quot;は，単語間の意味距離を用いて定量化する．二つの尺度を併用することによって，比喩関係を持つ概念対，すなわち，比喩性の判定が可能となる．二つの尺度を計算するために，コーパス中から抽出した語の共起情報を利用して知識ベースを構築する．以下，2章で，比喩性を検出するための尺度として，``顕現性落差''と``意外性''が利用できることを示し，3章で，``顕現性落差''を，確率的概念記述モデルに基づいて定量化する方法と，計算に用いる知識ベースを，コーパス中の共起関係を利用して構築する方法について述べ，4章で，``意外性''を，単語間の意味距離を利用して定量化する方法と，コーパス中の共起情報に基づく知識ベース構築の方法について説明する．5章では，両尺度を併用した単語対の判別実験と評価を行い，6章で，評価結果について考察する．</section>
  <section title="比喩性の尺度">本論文では，与えられた表現が比喩であるかを判断する基準として，「クローズアップされる特徴がいかに明確か」という点と，「与えられた表現がどの程度新鮮か」という点が重要であることに着目する．比喩表現の理解とは，概念が持つ，ある特徴を強調することによって，新たな理解を促すものであるから，強調される特徴が明確でなければならない．``顕現性落差&quot;は，クローズアップされる特徴を抽出し，それらの特徴がいかに明確であるかをはかる尺度である．また，比喩表現として対比される概念が新鮮であることは，その表現に強い印象を与え，理解を促すことになる．``意外性&quot;は，対比される概念の組み合わせの新鮮さをはかる尺度である．このような，二つの尺度を設定することで，その表現の比喩らしさ，すなわち，比喩性を検出できると考えられる．以下，``顕現性落差''および``意外性''について，比喩性との関係を説明し，両尺度が，比喩性検出にどのように利用できるかについて述べる．Ortnyは，比較される概念間の共有特徴が少ない場合でも，それらの類似性が認識されて比喩性が理解される点や，類似性の非対称性に着目し，相互作用モデルを示した．例えば，``卵のような車''という比喩の場合，たとえる言葉(source概念)``卵''とたとえられる言葉(target概念)``車''の共有特徴(卵車)=丸い，白い，小さい，…は，``車''においては顕著な特徴ではないが，``卵''においては，これらの共有特徴は非常に顕著な特徴(顕現特徴)である．したがって，``車''に対して，``卵''のイメージを重ね合わせることによって，``車''における丸い，白い，小さい，…などの特徴を同時に強調し，その結果，``顕現性落差''が生じて，比喩性が検出される．``顕現性落差''からは，類似性の非対称性が生じるので，同じ概念を比較した場合でも，``車のような卵''という表現からは，比喩性は検出されにくい．また，source概念が顕著な特徴を持っていたとしても，対比される概念間に共有特徴が認められない場合は，``顕現性落差''が生じないため，比喩性は認識されない．例えば，``谷底のような車''という表現では，``谷底''と``車''の間には共有特徴が見つけられないので，``顕現性落差''は生じず，比喩性も生じない．``自動車のような車''では，組み合わせ概念が類似概念であるため，両者の顕現特徴もほとんど共通である．この場合も，``顕現性落差''は生じにくく，比喩性もあらわれにくいと考えられる．さらに，比喩とは，意表を突いた言葉(ここでは単語)の組合せによって，伝えたい内容をより鮮明にしたり，強調する働きを持つ．例えば，``スポーツカーのような車''という比喩の場合，``スポーツカー''と``車''の共有特徴(スポーツカー車)=速い，格好いい，燃費が悪い…は，``車''においては顕著な特徴ではないが，``スポーツカー''において非常に顕著である．したがって，``車''に対して，``スポーツカー''のイメージを重ね合わせることによって，``車''における速い，恰好いい，…などの特徴を同時に強調するが，比喩性は認識されにくい．この理由は，両概念が上位下位関係を持つために，重複する特徴が多く，かつ，ありふれた組み合わせであるために，表現の新鮮さに欠けるからと考えられる．本論文では，このような単語間の組合せの新鮮さの度合を``意外性''として扱う．一般に，同一話題中に頻出する単語対は，たとえ2章の``顕現性落差''の条件を満たしていても，``意外性''が低い．その結果，比喩としての「新しさ」や「意外さ」が認識されず，比喩性を高める要因とはならない．反対に，めったに同一話題中に現れない単語対は``意外性''が高く，「新鮮」で「意外」であると認識され，比喩性を高める要因となる．上記の見地から，``顕現性落差''が大きく，かつ``意外性''も大きい概念対ほど，特徴が明確であり，表現も新鮮に受け取られ，比喩性も大きくなると考えられる．この考え方と，概念対(比喩・例示・無意味)の区別を対応付けると，表のような関係が仮定できる．概念対において，``顕現性落差''によって，無意味な概念対(無関係対)と意味のある概念対(比喩関係対・例示関係対)が区別でき，``意外性''によって，例示関係対と非例示の概念対(比喩関係対・無関係対)が区別できる．よって，両者を統合的に利用することで，比喩関係にある概念対が区別できる．</section>
  <section title="顕現性落差の定量化"/>
  <subsection title="確率的プロトタイプを用いた顕現性落差の計算">2章で述べたような共有特徴の顕現性落差を扱うために，属性値集合を用いた，確率的な概念記述を用いる．確率的な概念記述モデルでは，概念は属性値とその生起確率の集合として記述される．概念(W)が属性値w_iをもち，その生起確率がp_iであるとき，(W)は以下のように，確率的な属性値集合として記述できる(式())．	(W)=p_1#w_1,p_2#w_2,...,p_i#w_i,...,p_m#w_meqnarrayこのとき，概念の顕現性は，これらの属性値集合の冗長度(ばらつき具合)から予測可能である．()で示した概念(W)が，m種類の属性値から成る属性値集合として記述される場合，その冗長度r(W)は，式()を用いて定量化できる．r(W)=&amp;	eqnarrayところで，比喩表現の顕現特徴は，比較される概念間の共有特徴から選ばれるが，同時に，source概念の顕現特徴になっているはずである．よって，source概念の属性値集合から主要な属性値を取り出し，それらと，target概念の属性値との間で共有できるものを取り出すことで，顕現性落差を考えるためにクローズアップされる共有属性値集合が取り出される．取り出された共有属性値集合について，source概念とtarget概念の各々における生起確率を用いて冗長度を計算することで，顕現性落差が予測できる．したがって，source概念(W_s)が，降順で整列したm個の属性値から成る属性値集合で記述される場合を考えると，まず，生起確率上位から，閾値までの範囲内に存在するn個の属性値(_i=1^np_i&gt;)を，その概念の主要な属性値集合とみなして取り出し(式())，	&amp;(W_s)=p_1#w_1,p_2#w_2,...,p_n#w_n,...,p_m#w_m	if&amp;(p_1&gt;p_2&gt;...&gt;p_n)_i=1^np_i&gt;	then&amp;T(W_s)=p_1#w_1,p_2#w_2,...,p_n#w_neqnarray次に，取り出した属性値集合T(W_s)と，target概念(W_t)との間で共有される属性値を探し，それらを，各々の概念における相対頻度の値とともに取り出す．()に関して，source概念(W_s)の主要な属性値集合T(W_s)と，target概念(W_t)の間で共有される属性値集合は，W_s,(T(W_s)(W_t))，W_t,(T(W_s)(W_t))であり，それらの主要な共有属性値集合(属性値数x個，y個)は，式(),()のように表せる．さらに，それぞれの共有属性値集合の冗長度，r(T(W_s,(T(W_s)(W_t))))，r(T(W_t,(T(W_s)(W_t))))は，式()，()のように計算できる．&amp;T(W_s,(T(W_s)(W_t)))=p_s,1#w_1,p_s,2#w_2,...,p_s,x#w_x&amp;T(W_t,(T(W_s)(W_t)))=p_t,1#w_1,p_t,2#w_2,...,p_t,y#w_yeqnarrayここで，上記の手順で求められた冗長度は，単に属性値のばらつき具合を示しているにすぎない．そのため，source概念における共有属性値集合の冗長度が，target概念のそれより小さい(ばらついている)場合でも，共有属性値の生起確率が概念記述全体に対して占める割合が大きいと，顕現特徴となる場合があり，冗長度の差のみでは，顕現性落差を正確に反映できない．そこで，顕現性落差を反映させるために，対象となる属性値がどの程度主要であるかによって冗長度に重み付けをする．例えば，図では，属性値幼いの生起確率は，概念(子供)において0.222であり，概念(顔)において0.003である．この場合，属性値幼いは，概念(子供)において最も主要な属性値であるが，概念(顔)においてはそれほど主要ではないといえる．このように，ある属性値集合における属性値が，集合全体に対して，どの程度主要であるかということは，その属性値が集合内において保持する生起確率から把握できる．主要な属性値を用いた冗長度と，主要でない属性値を用いた冗長度を比較した場合，前者が主要であることが，顕現性の強調に影響すると考えられる．よって，各々の冗長度に対して，対象となった共有属性値集合の生起確率の総和を乗じて重み付けをし，比較した結果を顕現性落差として判断する(式())．比較した結果が正の場合，顕現性落差は比喩性を上げるように働き，負の場合は比喩性を下げるように働く，または生じないとみなす．r(T(W_s,(T(W_s)(W_t))))=&amp;r(T(W_t,(T(W_s)(W_t))))=&amp;eqnarrayGap(W_s,W_t)=&amp;	r(T(W_s,(T(W_s)(W_t))))×_i=1^xp_s,i&amp;	-r(T(W_t,(T(W_s)(W_t))))×_i=1^yp_t,ieqnarray</subsection>
  <subsection title="顕現性落差計算のための知識ベース構築">本節では，顕現性落差の定量化に用いる知識ベースの構築について述べる．前節で説明した顕現性落差を定量化するためには，対象となる単語を表現できる属性値集合に関する知識ベースが必要である．知識ベース構築において，従来のように被験者を用いた心理学的実験に基づいた場合，妥当性の高い知識は期待できるが，同手法によって，数万，数十万と，知識を大規模化することは，極めて困難である．コンピュータを用いた汎用的な比喩性判定を考えた場合，大規模な知識ベースを効率良く構築することも非常に重要である．よって，大規模コーパスを利用した統計的なアプローチも有効な手段の一つである．そこで，我々は，従来の心理学的実験手法を用いず，統計的手法を用いて，テキストコーパスから大規模な知識を自動的に抽出し，知識ベースを構築する．具体的には，対象とするテキストコーパスを形態素解析し，得られた結果から，``修飾語−名詞''の共起関係とその共起頻度を抽出する．抽出された共起情報は，確率的プロトタイプモデルに基づいて，知識ベース化する．例文(1)第一日目には，赤い花が一本売れた．例文(2)二人は白い花のイバラの影から出て，水蓮の咲いている小さい沼の方へ歩いて行きます．例えば，例文(1)を形態素解析した結果から，共起関係``花−赤い''が抽出される．この関係を共起頻度とともに，``花=赤い#1''のように記録する．同様に，例文(2)を処理すると，共起関係``花−白い''と``沼−小さい''が抽出できる．その結果，知識は，``花=赤い#0.50,白い#0.50，沼=小さい#1.0''に更新される．上記の方法に従って，1年分の新聞記事コーパスから知識ベースを構築した．知識ベース構築に際して，知識を抽出する共起範囲は1文とした．知識として抽出された共起ペアは79,712組，属性値集合は27,958組であった．属性値集合あたりの属性値数は1〜339，平均は2.5であった．表に知識ベースの例を示す．``山：高い''，``海：青い''，``学生：若い''，など，概念の顕現特徴を示す属性値が概ね上位に位置した．下位の順位においても，``山：険しい''，``海：暗い，神秘的だ''，``学生：無気力だ，忙しい''，のように，概念の特徴として連想可能な属性値を見ることができる．構築した知識ベースから，ランダムに100組を抜きだし，人手による大まかな評価を行った.評価は，(A)見出しの属性値として連想し易い，(B)見出しの属性値として連想することが可能，(C)見出しの属性値として連想不可能，の三段階に分類することで行った．その結果，(A)が85組，(B)が15組，(C)が5組となった．したがって，抽出した属性値のうち，85%程度は顕現特徴として理解でき，95%程度は連想可能なものであると考えられる．上の評価結果は，個々の属性値が妥当かどうかを測るものであり，評価後の数値がそのまま属性値集合の妥当性を示すものではないが，大規模な知識を，概ね直観に合うレベルで抽出することができたといえる．一方で，以下に述べるような，方式限界の存在も明らかになった．属性値の中には，ほとんどの概念と頻繁に共起するために，概念の特徴を示す属性値とはならないケースが見られた．``よい''や``いい''がその一例である．これらの語は，概念によっては，その特徴を反映していない場合も多く，属性値集合のノイズとなってしまうことがわかった．他にも，``夢''の属性値の例があげられる．文献に記載されている``夢''の語義文を参考にして属性値を考えると，``はかない''，``非現実的だ''，``実現困難だ''，``理想的だ''が得られる．上記手法によって構築された知識ベース(表)の``夢''の属性値集合をみると，``はかない''以外の属性値が抽出されていないことがわかる．これは，コーパス中において，``非現実的な''，``実現困難な''，``理想的な''などは，非制限的な属性であり，``夢''の属性値としては一般的過ぎるために，修飾語として出現しにくいためと考えられる．上で述べたような問題点は，以降で扱う，比喩性判定の過程に影響を与えることが予想されるが，本論文では，これを本構築手法の限界と考えている．以上の見地から，本手法によって構築される知識ベースは，強調されやすい属性値の集合によって表現される，確率的な概念記述であるといえ，概念の顕現特徴やそれらの集合を近似することは可能である．したがって，比喩性の判定という目的においては，十分利用可能である．構築した知識ベースを用いて，単語間の顕現性落差を計算した例を表に示す．A,Bの項の単語対は，前述のコーパスから，``AのようなB''というパターンで現れる表現の構成単語である．表から，顕現性落差が大きい単語対は，比喩または例示の組み合わせが多く，顕現性落差が小さい単語対は，例示や無意味単語対が多いことがわかる．</subsection>
  <section title="意外性の定量化"/>
  <subsection title="単語間の意味距離を用いた意外性の定量化">2章で述べたように，比喩表現の``意外性''とは，構成概念の組み合わせの新鮮さである．単語同士の組み合わせがいかに新鮮かを決める要因として，それらの単語が，日常的に用いられる文章中でどれほど頻繁に共起するか，という点があげられる．よって，テキストデータ中の単語の共起情報に基づく意味距離を利用すれば，単語組み合わせの``意外性''を定量化できるはずである．大規模なテキストデータから，単語の共起頻度を用いて単語間の意味距離を定量化する手法は，これまでにも数多く提案されている．本論文では，計算対象となる頻度が小さい場合でも，比較的信頼できる結果が得られるdice係数を利用する．dice係数は，本来，単語間の意味距離を示す値であるため，単語間の結び付きが強い程値が小さな値をとる．これは，``意外性''の定義とは反対の概念であるため，dice係数の逆数を``意外性''の値として用いることにする．したがって，あるテキスト中において出現する二つの単語W_s，W_tが，それぞれ，p_s，p_tの頻度で出現しており，そのうち両者が共起する頻度がp_s・p_tである場合，``意外性''Nov(W_s,W_t)は，式()で表される．Nov(W_s,W_t)=&amp;p_s＋p_t2(p_s・p_t)eqnarrayこの計算方法では，dice係数の値が0となる場合，すなわち，対象とする単語間の共起頻度が0の場合は値が得られない．共起頻度が得られないということは，単語の抽出元であるコーパス中からは，意外性を判断するための基本情報が得られなかったと判断できる．したがって，単語間の共起頻度が0であった場合は，判定不能として扱う．この場合，顕現性落差の計算が可能であったとしても，比喩性の判定は不能となる．</subsection>
  <subsection title="意外性計算のための知識ベース構築">顕現性落差同様，テキストコーパスから，統計的手法を用いて大規模な知識を取り出し，意外性の定量化に用いる知識ベースを構築する．具体的には，対象とするテキストを形態素解析し，得られたその処理結果から，全ての名詞とその出現頻度，および，1文をスコープとした場合の名詞共起とその共起頻度を抽出して構築する．例文(2)には5つの名詞``二人''，``花''，``イバラ''，``影''，``水蓮''，``沼''が存在する．共起範囲を一文として各名詞のペア組合せを考えると，14組の名詞ペアが考えられる．このとき，各名詞の出現頻度と共起頻度，それらに基づいて名詞間の意味距離が計算できる．以上の結果を知識ベースとして，二人,花：29,32,4のように記録する．表に，単語間の意外性の例を示す．これらは，1年分の新聞記事コーパスを利用して構築した知識ベースを用いて，計算した結果である．知識ベース構築のための共起範囲は1文とし，共起頻度5以上のものを対象とした．A,Bの項の単語対は，前述のコーパスから，``AのようなB''というパターンで現れる表現の構成単語である．表から，意外性が高い単語対は比喩または無関係の組み合わせが多く，意外性が下位のものは例示の組み合わせが多いことがわかる．</subsection>
  <section title="評価"/>
  <subsection title="評価方法">3章で用いた新聞記事コーパス1年分約11万記事，436MBから，二種類の知識ベースを構築した．知識ベース構築のための共起範囲は1文とした．顕現性落差計算用の知識ベースについては全てを，意外性計算用の知識ベースについては，共起頻度5以上のものを対象とした．検証のためのデータとして，以下のような二種類の単語対データ計100組を用意した．	知識ベース構築に用いた新聞記事コーパス中に現	れる，``AのようなB''というパターンで現れる表現の構成単語のうち，	知識ベースから検索可能な単語対(A，B)：70組	知識ベースとは関係のない新聞記事コーパス中	に現れる，``AのようなB''というパターンで現れる表現の構成単語の	うち，知識ベースから検索可能な単語対(A，B)：30組(A,B)の単語対は，比喩指標``ような''を含む文を取り出して形態素解析し，``ような''の両端に，名詞が位置するものを取り出し，さらに，指示語や代名詞，を取り除いて作成した．これらの単語対は，あらかじめ人手で比喩関係対・例示関係対・無意味対，の三種類の区別を行った．区別は，対象の単語対を用いて，`AのようなB'という表現を構成した場合に，どのように理解できるかという点を重視し，以下のように行った．比喩表現として理解可能な場合…`比喩関係対'，例示表現として理解可能な場合…`例示関係対'，いずれの表現としても理解不能な場合…`無意味対'，以上の単語対データに対して，顕現性落差および意外性を計算し，二つの尺度値に基づいて単語対を区別した．主要な共有属性値を決める閾値は，属性値集合全体における過半数を占める属性値を主要であると考えて0.5とし，単語対の区別は表に対応させた．分類の基準として閾値を設定した．顕現性落差については，計算結果が0未満(Gap(A,B)&lt;0)の場合に無意味単語対であると判定した．意外性については，データ(1)の意外性の各計算値において，例示と非例示(比喩，無意味)のカバー範囲を分析して閾値を設定した．例示と非例示の双方を網羅する平均カバー率が，最も広い値(平均カバー率が最も大きい)値はNov(A,B)=146であるので(図)，意外性の計算結果が146以下の場合(Nov(A,B)146)に例示であると判定した．次に，データ(2)に対しても顕現性落差と意外性を計算し，データ(1)で設定した閾値を適用して，その判別性能を調べた．このとき，計算過程において，クローズアップされる共有属性値やその集合が，比喩の顕現特徴として順当なものであるかどうかについては考慮しない．対照実験として，全ての単語組合せを比喩，例示，無意味のいずれか一種類と判断した場合三例の実験と，三種をランダムに判定した実験を行った．</subsection>
  <subsection title="評価結果">表は，データ(1)における評価結果であり，知識ベースと単語対が関連している可能性がある場合についての検証である．ここで，実際の比喩単語対は48組，提案手法によって比喩単語対と判別された単語対は30組，そのうち正しく判別できた数は25組であった．よって，データ(1)に対する本手法の比喩単語対の判別能力は，適合率83.3%，再現率52.1%となる．同様に，例示単語対の判別能力は，適合率50.0%，再現率52.2%，無意味単語対については，適合率22.2%，再現率80.0%であった．表は，データ(2)における評価結果であり，知識ベースと単語対が全く関連のない場合についての検証である．ここで，実際の比喩単語対は13組，提案手法によって比喩単語対と判別された単語対は11組，そのうち正しく判別できた数は8組であった．よって，データ(2)に対する本手法の比喩単語対の判別能力は，適合率72.7%，再現率61.5%となる．同様に，例示単語対の判別能力は，適合率75.0%，再現率50.0%，無意味単語対については，適合率57.1%，再現率80.0%であった．上記の結果と，四種類の対照実験結果とを比較したものを，表，に示す．各表中では，各単語対毎の認識結果について，適合率と再現率を示している．総合的な性能については，データ(1)では，提案手法の性能は54.3%，全てを比喩と判定した結果が68.6%，全て例示と判定した場合は，24.3%，全て無意味と判定した場合は，7.1%，ランダムに判定した場合は38.6%であった．データ(2)では，提案手法の性能が60.0%，全てを比喩と判定した結果は43.3%，全て例示と判定した場合は40.0%，全て無意味と判定した場合は16.7%，ランダムに判定した場合が26.7%であった．</subsection>
  <section title="考察">まず，総合的な性能について考察する．表では，全てを比喩と判定した場合の性能が提案手法を上回った．これは，全てを一種類に判定する手法の性能については，正解となる単語対データ数が，全体に占める割合を反映する性質を持つことに起因する．したがって，データ(1)では，比喩単語対の割合が多いために，同手法の性能が高くなったが，データ(2)では，は43.3%と，比喩単語対の判別能力が著しく低下しいる．これに対し，提案手法は，データ(2)においても72.7%の比喩単語対判別能力を得ており，対照実験と比較して，安定しているといえる．適合率についてみると，表では，比喩と例示において，表では全てにおいて，提案手法が最も良い結果であった．再現率については，ランダムの場合との比較のみが意味を持つが，この場合，いずれの種類においても，提案手法が最も良い結果であった．比喩単語対に限って言えば，本手法の評価結果は，概ね70%以上の適合率と50%以上の再現率が得られており，本手法による比喩性検出は有効であると考えられる．例示関係対については，データ(1)よりもデータ(2)の結果の方が良い結果を示した．これは，データ(1)では，(a)意外性が高いと判断された例示単語対が多かったことが再現率を下げ，(b)例示単語対と判断された比喩単語対が多かったことが適合率を下げたためである．無意味単語対についても同様で，データ(2)の方が良い結果であった．再現率はどちらも80.0%であるから，データ(1)において，他の表現を無意味単語対と誤認識した場合が多かったことが原因であるといえる．表では，比喩単語対を無意味語対とあやまって判定したものが14組(29.2%)，比喩単語対を例示単語対とあやまって判定したものが9組(18.8%)，例示単語対を比喩単語対とあやまって判定したものが4組(23.5%)，例示単語対を無意味単語対とあやまって判定したものが4組(23.5%)，無意味単語対を比喩単語対とあやまって判定したものが1組(20.0%)あった．表では，比喩単語対を無意味語対とあやまって判定したものが3組(23.1%)，比喩単語対を例示単語対とあやまって判定したものが3組(15.4%)，例示単語対を比喩単語対とあやまって判定したものが3組(25.0%)，例示単語対を無意味単語対とあやまって判定したものが3組(25.0%)，無意味単語対を比喩単語対とあやまって判定したものはなかった．この結果からみると，比喩単語対を無意味対とあやまって判定するケースと，例示単語対を比喩単語対とあやまるケースが多いことがわかる．以下，評価結果から，正解例および失敗例を，各単語対別に，表，表に示し，問題点に関して詳述する．(1)本論文では，比喩性判定処理において，比較される概念間の共有属性値の妥当性は特に考慮していない．しかし，厳密な意味で比喩理解を考えた場合，クローズアップされる共有属性値の尤もらしさも考慮の対象となる．例えば，「枝のような柱」では，``黒い''という共有属性値が，顕現特徴としてクローズアップされている．1章で述べたように，比喩理解が，複数の顕現特徴に基づくと考えれば，``黒い''が，クローズアップされる属性値の一つであると考えることもできる．しかし，厳密には，``細い''や``長い''などの語が，より上位の共有属性値として選ばれた方が，人間の直観に合う．この問題は，2章で述べたように，極めて一般的な属性値が，コーパス中に現れにくく，結果として抽出に失敗するという知識ベース構築手法の方式限界に関連している．問題解消のためには，概念辞書や語義文から属性値を取り出すなどして，属性値を補完する必要がある．(2)総合評価で述べた例示単語対の誤認識において，(a)については，``遺書''と``文書''や``清水''と``地域''のように，上位下位関係にあるが，一方が固有名詞であったり，分野依存性が強い場合には極端な頻度差が生じ，結果として意外性の値が高くなってしまう場合や，``日本のような戸籍''のように，一方の比較対象が単語として現れていない場合であり，比較する単語と，比較する意味にズレが生じ，単語の共起を元に計算された意外性の値が，意味的な意外性と食い違ってしまったことが原因と考えられる．前者の問題に対しては，新聞記事以外のコーパスや，複数の分野に関するコーパスを知識源として知識ベースを構築することで対応できそうである．固有名詞については，形態素解析で網羅できない場合もあると思われる．よって，固有表現抽出処理を利用することによって，固有名詞の出現頻度をさらに詳細に網羅することも有効であろうと考えられる．後者については，表層に現れていない比較対象概念を導き出さなければならない．そのためには，表現が現れた箇所の文脈解析や照応解析が必要である．(3)総合評価で述べた例示単語対の誤認識において，(b)については，``ジャズのようなリズム''や，``けん銃のような音''のように，一方の比較対象が単語として現れていない場合が多い．したがって，(2)の場合と同様に，表層に現れていない比較対象概念を導き出す必要がある．この問題への対策として，中村による「比喩関係からみた言語形式の分類」と概念辞書を用いて，他の単語対と区別して処理する方法が考えられる．(4)共有属性値集合の中に，``よい''や``いい''など，ひらがなで表記される形容詞が多く見られた．これは，3章で述べた，知識ベース構築手法の方式限界に関する問題である．これらの語は，通常，様々な名詞への修飾語として数多く出現するため，多くの概念の属性値となり易いと考えられる．その結果，顕現性落差を計算する場合に，共有属性値として抽出される確率も高く，頻度が多くなるために，属性値内の順位も上位となり易い．このような，極端に高頻度であったり，多数の名詞と共起する単語については，属性値候補から削除するというような対策が必要であると思われる．(5)比喩単語対を無意味単語対とあやまって判定したものは，ほとんどが``夢''をsource概念(A)とした単語対であった．特にデータ(1)ではこの傾向が顕著で(14組中11組)，無意味単語対の適合率低下にも大きく影響している(再現率は80%だが，適合率が22%にとどまった)．無意味単語対と判定された原因は，``夢''という単語が，共有属性値集合において，他の単語より特徴が少ないということ，様々な単語との意味距離が近いと判断されたためである．すなわち，``夢''という語が様々な特徴を持っており，様々な場面で用いられているということになるのだが，``夢のような計画''や``夢のような世界''は，明らかに比喩であると判定されるべきである．対策として，本来比喩的な性質を持つ語というものを他と区別して定義して扱う，辞書や語義文を用いて，一般的な修飾語としては現れにくい属性値を取り出す，などが考えられる．(6)``新しい''，``あたらしい''，``新ただ''や，``美しい''，``きれいだ''は，概念の特徴としては，同じ意味を示すものであるが，異なる属性値として扱われている．これは，知識ベース構築時における単語の区別を，形態素解析結果をそのまま利用しており，同義性が考慮されていないためである．これらの，意味的に同一または類似である異表記単語を同一のものとしてクラスタリングできれば，知識ベースにおける各属性値集合を意味的な属性値集合として構成でき，各尺度に基づく計算の誤差も小さくなるはずである．そのためには，属性値となる形容詞や形容動詞について，概念辞書や語彙体系などを用いてクラス分類する必要がる．(7)顕現性値の計算結果が0となる場合があった．しかし，実際には，ある概念の特徴が全く思い付かない場合というのはいかにも不自然である．この原因は，知識ベースにおいて，属性値集合の各属性値が全て同じ頻度である場合に，「完全に発散した状態」として計算されるためである．この場合，顕現性落差計算における重み付け効果も無くなるため，正確な比較ができていなかったといえる．上記の問題に対しては，コーパスの規模を拡大することによって，全体的な属性値の頻度を増やす方法や，辞書や語彙体系を利用して，属性値に重みを付ける方法が考えられる．(8)評価結果において，``インドのような国''や，``フランスのような主張''については，単語対の共有属性値としては，多い，広いや，強いなどが取り出された．これらは，一般的な概念として考えても，知識源である新聞記事内の意味においても，正しい結果であるといえる．しかし，これらの表現は，``インド''や``フランス''を，ある特徴を示す国の例として取り上げている例示の場合と，他の国を指して，``フランスの主張''や``中国''にそっくりであるとして表現する比喩の場合がある．どちらに決定されるかは，上記の表現を含む文脈に強く依存する．ところが，今回は，単語の知識のみを用いて比喩性を判断しているため，このような場合には対応できない．</section>
  <section title="むすび">本論文では，一般的な文書に出現する比喩表現を認識するために，確率的な尺度を用いて，単語間の比喩性を検出する手法について述べた．比喩性を検出するための尺度として，比喩構成語が理解可能かどうかに関わる``顕現属性落差''と，語の組合せがどれ程斬新かに関わる``意外性''を定義し，確率的なプロトタイプ概念記述および単語間の意味距離を利用して定量化した．さらに，コーパス中の共起関係に基づいて構築した知識ベースを用いて比喩性判定実験評価を行った結果，提案モデルが有効であることが確認された．今後は，考察で得られた知見に基づいて，単語の同義性を考慮した知識ベースを構築した本手法の精緻化，比喩的な機能を持つ特殊な語の扱い，新聞記事以外のコーパスや概念辞書の利用，を進めていく予定である．また，今回の性能評価では，知識ベース中に共有属性値が存在しなかった場合の顕現性落差や，コーパス中から共起頻度が得られなかった単語対の意外性については，評価対象外とした．これは，それぞれ，``共有属性値が存在しない原因としては，実際に比較対象概念間に共有特徴が存在しない場合と，知識ベース中の属性値集合間に共有属性値が存在しなかった場合が考えられるが，両者の区別は簡単ではない''，``共起頻度が得られない原因としては，コーパス中に単語共起が存在しないという事実が，すなわちそれらの単語対が一般的に共起しないことを証明するものではない''という理由による．しかしながら，``共有属性値がない場合は，無意味対である可能性が高い''ということや，``個々の単語がそれぞれ有意な出現頻度を示していながら，共起が生じない場合は，意外性は非常に高い''ということは，容易に推測できる．したがって，これらの推測過程の妥当性を確認し，本手法へ適用することにより，判別性能を精緻化することを考えている．本研究の具体的な応用事例研究としては，1章で述べた機械翻訳への適用の他に，比喩表現を検索要求として扱える検索システムや，質問応答における比喩表現を用いた応答文生成などを考えている．document</section>
</root>
