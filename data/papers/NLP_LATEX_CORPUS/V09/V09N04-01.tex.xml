<?xml version="1.0" ?>
<root>
  <title>検索結果表示向け文書要約における情報利得比に基づく語の重要度計算</title>
  <author>森辰則</author>
  <jabstract>本稿では，情報検索の結果として得られた文書集合中の各々の文書を要約する一手法を提案する．この場合の要約の質は，検索質問-要約文書間の関連性判定が，検索質問-原文書の間の関連性判定に一致する度合で評価されるので，検索を考慮した要約が必要となる．検索質問により語の重みにバイアスを与え，語の重要度を求める従来手法とは異なり，我々の方法では，検索された文書間の表層的類似性を適切に説明する語に高い重みを付与する．具体的には，検索文書集合に階層的クラスタリングを適用することにより，文書間の類似性構造を抽出するとともに，各クラスタにおける各語の出現確率から，その構造を説明するのに寄与する単語により高い重みを与える．我々は，その重みづけに情報利得比を用いることを提案する．そして，この語の重み付けに基づき重要文抽出方式による検索文書要約システムを実装した．このシステムを評価型情報検索ワークショップであるNTCIR2におけるTextSummarizationChallengeの情報検索タスクにより評価した結果，関連性判定において検索質問バイアス付きTF方式，リード文方式によるベースライン手法ならびに，他参加システムよりも，良好な結果を示した．</jabstract>
  <jkeywords>文書要約，重要文抽出，情報利得比，情報検索，文書クラスタリング</jkeywords>
  <section title="はじめに">近年，Internet上の検索エンジンなど，情報検索システムが広く利用されるようになってきた．システムが提示する検索結果には，文書の表題やURIだけではなく，対応する文書の内容を示す短い要約文書が併せて提示されていることが多い．これは，利用者に対して要約文書を提示することが，原文書が実際に利用者の欲するものかを判断する際に有力な手掛かりとなるためである．この際，情報検索結果文書に対する要約の質の良さは，要約文書-検索質問間の関連性判定と原文書-検索質問間の関連性判定の一致の良さで測ることができよう．しかしながら，現在実用に供されている多くの検索エンジンでは，原文書の最初の数バイトを出力したり，検索要求文に含まれる語の周囲を提示するといった単純な方法が採用されている．このような単純な戦略により生成された要約の品質は関連性判定の観点からみると，十分な品質であるとは言い難い．そのため，多くの場合，利用者はシステムの提示した検索結果が適切なものであるかどうかを原文書を見て判断せざるを得ない．このような状況を改善するためには，関連性判定を重視した，より質の高い自動要約技術が必要となる．自動要約の手法としては，Luhnの研究に端を発する重要文抽出法が基本かつ主要な技術であり，依然として様々なシステムで利用されている．これは，文書の中から重要な文を，所望の要約文書の長さになるまで順に選び，それら抽出された文を文書中での出現順に並べて出力することで，要約とする手法である．このとき，文の重要度は，語の重要度，文書中での位置，タイトルや手がかり表現などに基づいて計算している．その中でも，重要文は主要キーワードを多く含むという経験則により，語の重要度に基づく重要文抽出が最も基本的な手法となっている．特に，語の出現頻度は，簡単に求められ，語の重要性と比較的高い相関にあるために語の重みとして広く利用されている．語の出現頻度は個別文書によって決まる性質であるが，一方で，検索文書の要約においては，原文書が検索要求の結果として得られた複数の文書であることを考慮することが要約の品質向上につながる．例えば従来提案されている基本的な考え方として，検索要求中の語の重要度を高くするという「検索質問によるバイアス方式」がある．この手法は直観的であり，かつ，比較的良好に機能するが，検索された文書自身の情報を考慮しないなど幾つかの欠点が存在する．以上の点を踏まえて，本稿では，検索文書集合から得られる情報を語の重みづけに利用し，検索文書の要約に役立てる新しい手法を提案する．検索質問によるバイアス方式とは異なり，我々の手法では語の重みづけにおいて検索質問の情報を陽に利用しない．その代わりに，複数の検索文書の間に存在する類似性の構造を階層的クラスタリングにより抽出し，その構造を適切に説明するか否かに応じて語に重みをつける．文書間の類似性構造を語の重みに写像する方法として，我々は，各クラスタ内での語の確率分布に注目し，情報利得比(InformationGainRatio,IGR)と呼ばれる尺度を用いる．そして，この重みと従来提案されている他の重みづけを組み合わせることにより，最終的な語の重みとし，これを用いて各文の重要度を計算する．特に，情報利得比に基づく語の重みづけについては，次のように考えることができる．あるクラスタにおける語の情報量に注目した場合，そのクラスタを部分クラスタに分割した後のその語の持つ情報量の増分(情報利得)が，クラスタの分割自身により得られる情報量に比して大きければ，その語は部分クラスタの構造を決定する際に役立っていると考えられる．その度合を定量化した値が情報利得比である．情報利得比自身は機械学習において属性の品質の尺度として，すでに提案されているものである．また，種々のクラスタリングアルゴリズムの過程からすれば，文書のクラスタ構造の決定に際して，各々の語の確率分布が部分的な要因となっていることは自明である．しかしながら，あるクラスタ構造が確定した時に，ある語がそのクラスタ構造の決定に際して最終的に寄与したか否かに注目し，定量化するという研究は，我々の知る限り従来存在しない．そして，本稿は，その定量化において，情報利得比が利用できることを示すものである．</section>
  <section title="検索文書集合中の語に対する情報利得比に基づく重みづけ"/>
  <subsection title="検索文書要約の特質">検索文書の要約は，以下の点で通常の文書要約と異なる．検索質問文が与えられている．複数の要約文書が同時に得られている．そして，ある一度の検索の結果という点において文書間に類似性が認められる．いずれの情報も，検索文書の要約においては有効な手がかりと考えられる．ここでは，これらの手掛かりを語の重みづけに用いることを考察する．まず初めに考えられる手法は，Tombrosらが提案するように，検索質問中の語を重要語として考え，他の語よりも重みを高する方法である．これは，検索質問中の語や句は利用者の情報要求を端的に示すので，要約文書にもその語や句が含まれるべきであるという直観に基づくもので，「検索質問バイアス方式に基づく要約(Query-biasedSummarization)」と呼ばれる．この方法は，検索質問を考慮するだけであるので，実装が簡単であり，ある程度の効果が報告されているが，次の欠点が存在する．検索質問中の表現をそのまま用いるために，検索エンジンにおける工夫が要約文書に反映されない．例えば，各種フィードバックや検索質問の拡張などは，検索質問を修正/更新することによって検索効率を上げている．検索エンジンは検索質問文に関連する文書ばかりではなく，関連性の低い文書も結果として返すことがある．検索質問との関連性が低い文書に対しては，検索質問バイアス方式は通常の文書要約になってしまう．そこで，我々は二番目の選択肢である，検索質問文を使わずに，検索文書集合のみを用いて重みづけることを考える．検索結果の質が非常に悪くない限り，検索文書集合には検索質問に関する情報が暗に含まれていると期待できるので，その情報を引き出すのである．しかし，各文書に共通する語を抽出するといった単純な方法では精度が良くないことは容易に想像される．なぜならば，検索結果の文書集合には，もちろん検索質問との関連性が高い文書も含まれるが，関連性の低い文書も含まれるからである．しかも，その度合は検索エンジンの精度に依存してしまう．よって，単純に文書に共通する語などを取り出すだけでは達成できない．我々は以上の点を踏まえて次節に示す枠組を提案する．</subsection>
  <subsection title="提案手法の概略">我々の提案手法の概略を図に示す．これは，次の2つの指針の組み合わせたものである．検索文書集合に対し階層的クラスタリングを行ない，文書間の類似性の構造を抽出する．文書間の類似性の構造と語の確率分布に基づいて各語の重み付けを行なう．ステップにおいては，検索質問に関連する文書とそうでない文書がクラスタ構造の中で分離されることが期待され，なおかつ，それらの文書部分集合においても類似性に基づく細分類がなされると考えられる．我々の手法では，語を次元とする文書ベクトルの類似度による階層的クラスタリングを用い，クラスタリングアルゴリズムとしては最大距離アルゴリズムを採用した．ここで注意すべきことは，検索されなかった文書，すなわち，文書データベース中の残りの文書の存在を類似性構造の中に組み込む必要があることである．なぜならば，クラスタ構造において，一番上位のクラスタは与えられた構造として扱う以外になく，類似性の解析の対象とならないからである．検索文書全体の類似性構造は，検索されなかった文書集合との対比によって，初めて明らかになる．この類似性構造は，全文書集合と検索質問との間の類似性を反映するので，非常に重要なものである．このため，図に示すように検索文書集合から得られたクラスタ構造の根の上にもう一つ仮想的なクラスタを設ける．そのクラスタには，検索文書の属する部分クラスタとそれ以外の文書が属する部分クラスタが存在する．ここで，我々の方法では，検索文書の属する部分クラスタだけが，クラスタリングアルゴリズムにる部分クラスタ解析の対象となる(図の左部分木)のに対し，検索されなかった文書の属するクラスタ(図の右部分木)についてはそれ以上の解析が不要である点に注意されたい．後に述べる情報利得比の計算においては，検索されなかった文書の属するクラスタについては，その中に存在する語の頻度だけが分かればよい．これは，あらかじめ求めておいた文書データベース中の語の頻度より，簡単に求めることができる．よって，我々の手法において実際に文書クラスタリングが行なわれるのは，検索結果として利用者に提示する文書に限定される．これは通常数十文書程度であるから，文書クラスタリングにおける計算量はあまり問題とならない．このようにして求められた類似性構造は文書を一つの単位とする巨視的な情報であるので，要約のためには，これを文や句，単語を単位とするより微視的な情報に還元する必要がある．これがステップである．このステップにおいては，各クラスタが部分クラスタに分割されるにあたって，句や単語などより微視的な単位がどれ位寄与しているかを表す指標を定め，これをその語句の重要度とする．我々はその指標として情報利得比を用いる．このようにして求められた情報利得比を，既存の方法でも用いられている重みである，語の文書内頻度(termfrequency,TF)，文書頻度の逆数(inversedocumentfrequency,IDF)と組み合わせることにより，総合的な語の重要度をとする．これら三種類の重みは，以下の通り，異なる文書情報から得られるものであることに注意されたい．よって，これらの組み合わせにより，検索文書の要約に適した総合的な重みが得られると期待できる．語の文書内頻度個別の文書における各語の分布より決まる重要度で，ある文書中でのその語の重要度を表す．クラスタ分割に対する語の出現確率に関する情報利得比検索文書の類似性構造であるクラスタの分割により決まる重要度で，そのクラスタ構造におけるその語の重要度を表す．文書頻度の逆数検索対象の全文書により決まる重要度で，全検索対象文書集合におけるその語の重要度を表す．</subsection>
  <subsection title="最大距離アルゴリズムによる階層的クラスタリング">検索された文書集合の類似性の解析には，文書間の距離の定義とその距離に基づく文書集合の構造化が必要となる．これには様々な方法が考えられるが，本稿では文書間の距離として，様々な場面で利用され，かつ，簡便なTF・IDF法ならびにベクトル空間法に基づく方法を採用する．また，文書集合の類似性に関する解析には，階層的クラスタリングを用いる．階層的クラスタリングアルゴリズムには，併合法などが良く用いられる．しかし，この種の方法はクラスタ構造を無理に二分木に当てはめるため，文書間距離の順序関係は構造に反映されるものの，その絶対値については捨象されてしまう．ここでは，文書の類似度に応じて多分岐構造を生成でき，文書間距離の絶対値情報がなるべく保存されるアルゴリズムが望ましい．そのようなアルゴリズムとして，我々は最大距離アルゴリズムを採用した．この最大距離アルゴリズムは，本来，非階層的なクラスタを生成するものであるが，これを分割の結果得られた部分クラスタに再帰的に適用することにより階層構造を得る．この方法では，各クラスタが3以上のクラスタに分割されることもある．</subsection>
  <subsubsection title="文書間距離">ベクトル空間モデルに基づき，各文書D_iをn次元空間上の点(weight_i1,weight_i2,,weight_in)により表現する．weight_ikは文書D_iにおいて語w_kに割り当てられた重みである．重みweight_ikとしては語w_kのTF・IDF値とする．このとき，文書D_iと文書D_jの距離dを文書ベクトル間のユークリッド距離を用いて，次のように定義する．d(D_i,D_j)&amp;=&amp;_k(weight_ik-weight_jk)^2,weight_ik&amp;=&amp;tf(D_i,w_k)idf(w_k),tf(D_i,w_k)&amp;=&amp;freq(D_i,w_k)|D_i|,idf(w_k)&amp;=&amp;1+_2Ndf(w_k),eqnarrayただし，である．後に述べる実験においては，語として，名詞のみを扱った．文書からの名詞抽出には形態素解析器JUMAN3.61を用いた．また，df(w_k),Nは検索対象である毎日新聞94年，95年，97年，98年のすべての記事から求めた．</subsubsection>
  <subsubsection title="最大距離アルゴリズム">最大距離アルゴリズムにおいては，まず文書集合から2個以上のクラスタ中心を選択し，次に，残りの文書を最近のクラスタ中心と同じクラスタに配置する．その主要部分はクラスタ中心を求める部分であり，以下の手続きからなる．文書集合DSから距離の最も大きい二文書を取り出し，これらを要素とする集合を作成する．これを初期のクラスタ中心の集合Cとする．クラスタ中心集合Cにおいて，クラスタ中心間での最大距離を求める．これを，d_maxとする．DS中の各文書D_iについて，すべてのクラスタ中心との距離を求め，その最小値を既存クラスタ中心からの距離d(D_i,C)とする．既存クラスタ中心からの距離が最も大きい文書D_dをDSから取り出す．もし，d(D_d,C)d_maxならば，その文書をクラスタ中心集合Cに追加する．そうでなければ，終了．なお，は0.5&lt;1.0なる定数であり，値が大きいほどクラスタの分割数が少なくなる．一般には0.5とすることが多い．以上のアルゴリズムは，単一の文書集合を文書間距離にしたがって複数個の部分クラスタに分割する非階層的なアルゴリズムである．これを各部分クラスタに対して再帰的に適用することにより，階層的なクラスタ構造を生成する．</subsubsection>
  <subsection title="情報利得比に基づく語の重要度">クラスタの木における各接点(内点)は，あるクラスタとそれを分割して得られた互いに素な部分クラスタの関係，すなわち，クラスタの分割の仕方を表現している．この分割の仕方はクラスタ内の文書の類似度に従って決定されるので，これを文書内の語の重みに反映させることができれば，複数文書間の類似性という巨視的な情報を，文書内の語の重みという微視的な情報に還元できると考えられる．我々は，この考え方に基づき，次の2つの段階から構成される方法を提案する．各クラスタについて，その部分クラスタの構造から，各語の重みを決定する．一つの文書は，クラスタの木の根接点から対応する葉接点に至るクラスタ分割の系列によって指し示される．よって，各文書における語の重みは，各分割で得られた語の重みを統合して得る．このうち，特に重要なのはである．その基本的な考え方は，クラスタの分割構造を決定することに寄与する語に高い重みを与えるというものである．例として，図のように，あるクラスタC_0が3つの部分クラスタ(C_1,C_2,C_3)に分割されている場合を考える．図中，記号A,B,D〜Gは各々単語に対応するとする．さて，語AはクラスタC_0における頻度が最も高いので，このクラスタの特徴を表す語と考えることができる．しかし，各部分クラスタに注目すると，いずれも均等に出現しているため，部分クラスタの選択においては役立たないことがわかる．一方，語FはクラスタC_0において頻度はさほど高くはないが，部分クラスタC_3に集中して登場している．この場合，語Fが出現しているか否かを調べることによって，部分クラスタを言い当てることができるので，クラスタの分割構造に対する寄与度は，語Fは語Aよりも高いと考えられる．我々はこの寄与度を適切に表す尺度として，次に述べる情報利得比を用いる．</subsection>
  <subsubsection title="情報利得比">情報利得比は，決定木学習システムC4.5において属性選択を行なうために導入された．C4.5においては，ある属性を決定木の分岐におけるテストとしたときに，その属性がどれくらい適切にクラスの出現を予測できるかを表す尺度として用いられている．我々は，表に示す対応の下，クラスタの構造を決定木の構造と見なすことにより，情報利得比を用いる．C4.5においては属性の評価値として情報利得比を用いていたが，我々の方法においては，属性ではなくクラスに対応する単語に対する評価値として情報利得比を用いる．クラスタCにおける単語wの情報利得比gain_r(w,C)は次の様に求められる．gain_r(w,C)&amp;=&amp;gain(w,C)split_info(C)gain(w,C)&amp;=&amp;entropy(w,C)-entropy_p(w,C)entropy(w,C)&amp;=&amp;-p(w|C)_2p(w|C)&amp;&amp;-(1-p(w|C))_2(1-p(w|C))p(w|C)&amp;=&amp;freq(w,C)/|C|entropy_p(w,C)&amp;=&amp;_i|C_i||C|entropy(w,C_i)split_info(C)&amp;=&amp;-_i|C_i||C||C_i||C|freq(w,C)&amp;:&amp;C_i&amp;:&amp;|C_i|&amp;:&amp;eqnarray情報利得gain(w,C)は，クラスタCの分割の前後における，語wの確率分布に関するエントロピーの減少量を表す．split_info(C)は，クラスタCの分割に関するエントロピーである．情報利得比gain_r(w,C)は，これらの比として定義される．例として，図における各語について，上述の方法により情報利得比を計算してみると次の通りとなる．[gain_r(,C_0)gain_r(,C_0)&gt;gain_r(,C_0)=gain_r(,C_0)&gt;gain_r(,C_0)&gt;gain_r(,C_0)][gain_r(,C_0)=0.000,gain_r(,C_0)=0.161,gain_r(,C_0)=0.031,][gain_r(,C_0)=0.080,gain_r(,C_0)=0.157,gain_r(,C_0)=0.080]BやFのようにクラスタ構造に沿って現れる語は値が大きく，語Aのように網羅的に分布する場合には値が小さいことは既に述べたとおりである．一方，語Dのように一部のクラスタに集中してはいるものの，他のクラスタにも低い確率ではあるが出現する場合には，値が低くなることがみてとれる．さらに，語Fとほぼ同じく偏りがあるが出現確率が低い語Eについては，その値が相対的に低くなる．</subsubsection>
  <section title="重要文抽出に基づく要約文書生成">語の重みは要約生成における基本要素であるから，ほとんどの要約手法に我々の手法を組み込むことができると考えられる．しかし，我々の目的は，前節で述べた語の重みづけが検索文書要約において有効であることを示すことである．そこで，次に示す，語の重要度だけによる最も基本的な要約手法を以降の評価実験で用いる．文書D中の文sの重要度は次式の通り，文中のキーワードの重みの和を文の長さで正規化したものとする．	s_imp(s,D)&amp;=&amp;_wkeyw(s)weight(w,D)|s|	keyw(s)&amp;:&amp;|s|&amp;:&amp;eqnarrayある決められた要約の長さに達するまで，原文書から重要度の高い順に文を取り出していく．取り出した文を原文書における出現順に並べ変えて要約文書を得る．</section>
  <section title="評価">本節では，我々の要約方式について，二通りの視点から評価を行なう．まずは，検索タスクの精度・効率の良さと言う観点から，評価型情報検索ワークショップであるNTCIR2におけるTSC(TextSummarizationChallenge)における「課題BIRタスク用要約」(以下，TSCTaskBと呼ぶ)に基づいて評価を行なう．つぎに，幾つかの例により，我々の方式が各語に与える重要度を，検索質問を考慮しない語の重みづけ手法(TF値，TF・IDF値)と比較することにより，我々の重要度計算手法の特徴を定性的に評価する．なお，我々の評価実験においては，要約生成の手順に以下の条件を加えた．記事の表題(見出し文．Headline)と本文を区別せずに要約の入力とする．名詞をキーワードとする．文書からの名詞抽出には形態素解析器JUMAN3.61を用いた．IDF値等の計算においては，当初TSC実行委員会から発表された使用新聞記事データである毎日新聞1994年，1995年，1998年に加えて，手元にあった1997年を全文書集合とした．最大距離アルゴリズムにおけるパラメタは0.5とする．要約を一覧形式で提示することを想定すると，要約文書の長さが統一されているほうが，見やすい．そのため，要約文書の長さは要約率ではなく，絶対的な長さにより決定する．具体的には，150形態素をしきい値とする．文書の総形態素数が150より短い場合には要約をせずに原文書を提示する．要約生成に当たって，原文書の文が省略されている箇所には「…」を加え，原文書の段落箇所には改行を加える．</section>
  <subsection title="情報検索タスクにおける要約品質の評価実験の概要">図に情報検索タスクにおける要約品質の評価実験の概要を示す．TSCTaskBにおいては，TSC実行委員会より配布されたデータセットに，12のトピックがあり，それぞれ，検索要求1，検索文書50文書から構成されている．検索文書は1998年の毎日新聞の記事集合から検索されたものである．TSCへの参加者は各自のシステムを用いて，これらの文書を要約し，実行委員会に提出する．提出された要約文書に対して，TSC実行委員会による被験者を用いた評価が行なわれた．被験者は学生36名で，各検索要求につき，3人が割り当てられている．被験者は各要約を読むことによって，それが検索要求に適合しているか否かの判断を行う．その判断と，あらかじめ原文書に対して付与されている関連性評価(以下，関連度ともいう)を比較することにより，要約の品質が評価される．すなわち，両者が一致する度合が高いシステムほど有効な要約を生成すると考えることができる．原文書に付与されている関連性評価はA,B,Cの三段階である．ここで，Aはその文書が検索要求に適合すること，Bは関係のある文書であること，Cは関係のない文書であることを表す．これに対して，被験者らには関連性の有無(YES/NO)という二段階で提示してもらう．よって，両者の一致の判定においては，A判定の文書だけを関連文書とする場合(AnswerLevelA)と，A判定に加えてB判定の文書も関連文書とする場合(AnswerLevelB)が考えられる．</subsection>
  <subsection title="総合評価">表に個別の評価尺度についての結果を他の参加システム(8システム)ならびにTSC実行委員会が準備したベースラインシステム(3システム)と比較して示す．ベースラインシステムは，「全文提示(Fulltext)」(要約率100%)，「質問バイアス付きTFに基づく方式(TFwithQB)」(要約率20%)，「文書の先頭を採るリード方式(Lead)」(要約率20%)である．質問バイアス付きTF法は，TFを語の重みとして重要文抽出を行なうものであるが，この時に，検索質問に現れる語について2倍の重みを与えている．これらのシステムの概略については，付録を参照されたい．評価尺度には以下のものを用いた．いずれの値も，全てのトピックを通じて集計したものである．被験者が1検索要求に関するタスク(50文書)に要した時間(TIME)タスクをどの程度適切に行なえたかを示す指標．	すなわち，再現率(Recall)，適合率(Precision)，F値	(F-measure),	=,	=2RecallPrecisionRecall+Precision．	．要約文書の長さ(1文書あたりの平均文字数,LENGTH)</subsection>
  <subsection title="適合性判断のための所要時間とその精度に関する評価">情報検索の結果の文書に対する要約においては，利用者が行なう適合性判断のための時間の短さと，適合性判断の正確さが共に達成されることが必要である．一方で，両者はトレードオフの関係にある．例えば，長い要約文書を提示すれば，タスク遂行の時間が長くなるが，一方で，精度は概ね向上すると考えられる．よって，両者を同時に評価する尺度が必要とされるが，未だ良いものが提案されていない．そこで，我々のシステムを含む各システムの再現率，適合率，F値について，適合性判断のための所要時間との関係をプロットした．AnswerLevelA,Bの場合を図にぞれぞれ示す．また，判定時間と要約文書の平均文字数の間の関係を図に示す．</subsection>
  <subsection title="トピック毎の適合性判断の精度に関する評価">これまで示した結果では，全てのトピックに亙る平均値を用いてタスクの遂行精度を議論してきたが，当然，トピックによって各システムの精度が異なるはずである．そこで，我々の手法と各ベースライン手法による要約において，トピック毎のタスク遂行精度をプロットした．AnswerLevelA,Bの場合をそれぞれ図に示す．なお，図中`Ave.'は全トピックに亙る平均値である．</subsection>
  <subsection title="適合と判断した被験者の数による要約の質の定量的評価">要約文書の質を今少し詳細に検討するために，各々の文書に対して，関連性有り(YES)と答えた被験者の人数を調べる．この人数はトピックに対する生成された要約文書の関連度の高さを表す尺度と考えられる．そこで，原文書を関連性判定(A,B,C)によって分類し，その要約に対してYESと判定した人数毎に文書頻度を集計し，プロットした．結果を図に示す．</subsection>
  <subsection title="語の重み付けに対する評価">語の重みづけについては正解というものがないので，定量的にその評価をすることが難しい．ここでは，最も基本的な重みづけである，TF値，TF・IDF値による重みと，本手法の重みづけを実例により比較し，定性的に我々の語の重要度決定手法の特徴を検討する．ここでは，典型的な語の重みがどの様になっているかを調べることが主眼であるので，我々のシステムで最もF値の高かったトピック1027に注目した．このトピックの内容を表に示す．このトピックについて，原文書の関連度がそれぞれ，A，B，Cであるものを一つずつ選択し，各種の語の重みけを行なった結果について，上位10位までを求めた．表,,にその結果を示す．表においてIGRsumは式()に示される情報利得比の和であり，TFIDFIGRsumはTF・IDF値にIGRsumを乗じた値である．</subsection>
  <section title="考察"/>
  <subsection title="タスク遂行の精度">TSCTaskBは，利用者(被験者)が要約文書を読むことにより，原文書のトピックに対する関連度を推定するタスクであった．よって，この場合の要約は報知的(informative)である必要はなく，指示的(indicative)でありさえすれば良い．このような要約においては，原文書に関する細かいニュアンスが伝達されるエレガントな要約文書が生成される必要はなく，適切なキーワードの選択とそのキーワードがどのような文脈で現れているかを説明する文書部分の抽出が適切にできればよいと考えられる．この考え方に従えば，キーワードの抽出の精度が高ければ，我々が用いた程度の文抽出による要約機構でもタスクを十分遂行できる要約文書が得られるはずである．以下ではAnswerLevelA,Bに分けて，上記の観点からタスク遂行の精度を考察する．</subsection>
  <subsubsection title="Answer Level A">本節では検索質問に対して適合文書(A判定)のみを正解とした評価(AnswerLevelA)について考察を行なう．表によると，我々の手法は，再現率，適合率，F値すべてにおいて，他のすべての参加システムよりも高い値を示している．ベースラインシステムとの比較においては，我々のシステムの適合率はLead手法よりも1.5ポイント低い値を示しているものの，それ以外は勝っている．Lead手法は，再現率が他の手法に比べて一番低いため総合指標であるF値においてはさほど高くなく，我々のシステムよりも7.7ポイント低い．すなわち，Lead手法は適合率重視の手法と見なすことができる．質問バイアス付きTF法と比較してみると，再現率において10.9ポイント，適合率において2.7ポイント，F値において7.0ポイント勝っている．このことは，検索文書の要約においては，必ずしも検索要求を直接使用しなくても，検索文書群だけで同等以上の質を持つ要約が可能であることを示している．次に，適合性判断の所要時間とタスク遂行の精度について考える．まず，表によると，所要時間単独についていえば，我々のシステムが生成した要約に対し，被験者が適合性判定に要した時間は，1トピック(50文書)あたり8分33秒であった．これは，TSCに参加した9システム中，3番めに短いものであった．また，すべての参加システムの平均タスク時間は1トピック当たり9分8秒であり，我々の要約の適合性判定に要する時間はこれよりも短い．そして，所要時間と各種評価値の関係を示す図(A)においては，概ね，左上に位置するシステムの性能が良いと考えられるので，我々のシステムは他のシステムに勝っていると言えよう．特に，再現率は適合率に比べてシステム間での格差が大きく，我々のシステムの再現率の高さが見てとれる．図(A)によれば，他のベースラインシステムはトピックによって，再現率が大きく変動しているが，我々のシステムはトピックにあまり依存せず安定して高い再現率を示している．これは，被験者が，関連文書(関連度A)の要約に対して適合すると概ね正しく判断したことを示す．一方，適合率についていえば，他のベースラインシステムとほぼ同様の傾向で，我々のシステムもトピックによってその精度が大きく変動している．これは，トピックによっては，我々のシステムが，非関連文書(関連度B,C)に対して一見すると関連性があると見誤る文を抽出し，要約の一部として提示していることを表す．以上をまとめると，まず，我々の手法は，トピックに関連する文を原文書から積極的に抽出していることがわかる．一方，そのような文の周囲の文脈については，抽出を促す戦略を採っていないことから，それらの抽出洩れにより，非関連文書に対して関連性があると見誤るような要約を生成する可能性もあることがわかる．なお，図をみると，要約文書長と適合性判定の所要時間は一定時間のオフセット(5分52秒)がついているものの，システムの違いによらず，ほぼ，比例関係となっている．一方，各システムの出力する要約文書については，適合性判定の精度にばらつきが見られる．よって，要約文書の適合性判定時間は適合性判定の結果によらず，要約文書の長さのみに依存していると考えられる．</subsubsection>
  <subsubsection title="Answer Level B">本節ではB判定まで含めた評価(AnswerLevelB)について考察を行なう．他のシステムと比較して，再現率が第2位と高いものの，適合率は第7位，F値は第4位と相対順位が低くなった．AnswerLevelBの評価においては，AnswerLevelAよりも正解の数が多くなるので，一般に，AnswerLevelAに比べて，再現率が下降し，適合率が高くなる．再現率についていえば，AnswerLevelAにおいて，高い適合率となったシステムほど減少が激しくなる．一方，適合率については，B判定のものがAnswerLevelAでの誤判定となっているのであれば，その値の上昇が著しい．我々のシステムの場合，再現率が0.907から0.754へと激しく低下しており，図(B)に示される通り，トピック毎の変動が大きくなっている．しかし，その順位について言えば，2位であるので相対的には他のシステムよりも高いことがわかる．つまり，関連文書(評価A,B)に対して正しく関連性の判定が行なわれた要約文書の数は他のシステムよりも多い．一方で，適合率の上昇は他のシステムより低いので，被験者が関連度評価Cの文書の要約に対しても適合であると判定を下した数が多かったことになる．これは，AnswerLevelAの考察で述べたことを裏付けており，トピックに関連する文の抽出は成功しているものの，その文脈が脱落する場合も少なからずあることを示している．ただし，図(B)や図(B)が示すとおり，適合率のシステム間の差異は再現率ほど大きくなく，また，AnswerLevelAの適合率に比べてもシステム間の格差が小さくなっている．</subsubsection>
  <subsubsection title="提案手法とベースラインとの差異に関する検定">前節までに述べたタスクの遂行精度において，提案手法と他の手法の間に有意な差があるか否かを検証するためには，統計検定を行なう必要がある．しかし，TSC実行委員会が提供する結果情報において，トピック毎の個別の評価が得られるのは自システムならびにベースライン三種のみだけである．そこで，ここでは，提案手法がベースライン三種との間に有意な差があるかを検証する．総合性能を表すF値についてトピック毎の値の差に基づきWilcoxonの符号順位検定を行なった．提案手法と各ベースラインを比較した時に「F値に差が無い」という帰無仮説に対する有意確率pを表に示す．この表によると，AnswerLevelAにおいては，提案手法がベースラインTFwithQBならびにLeadに対して，有意水準5%の下で，差を持つことが示されている．Fulltextとの比較については，有意水準5%の下での差異を示すことができなかったが，帰無仮説を採択する確率が5.2%程度で同有意水準との差は僅差である．一方，AnswerLevelBにおいては，ベースラインとの差がAnswerLevelAほど顕著ではない．有意水準5%の下で差がある事が示されたのはLead手法との対比だけであった．</subsubsection>
  <subsection title="語の重み付けに関する考察">我々の提案する語の重みづけについてその特徴を実例(検索トピック1027,「ハイビジョンテレビ」)により考察する．表において，我々が最終的に用いる語の重みであるTFIDFIGRsumの列に示されるように，関連度Aの文書においては，検索トピックに陽に示されている語はもちろんのこと，「BS」，「番組」，「デジタル」，「申請」，「衛星」，「郵政省」など，そのトピックに関連する語も上位に重み付けられていることが分かる．その一方で，TF・IDF値では上位にあった非関連語「SDTV」(標準テレビ)については，上位10位から姿を消している．これらの効果は，TF・IDFの列とIGRsumの列を比較すれば分かるが，IGRsumの成分が主に寄与している．そして，このような重みづけは質問バイアス付きTF手法では，質問拡張などを別途行なわない限り実現できないものである．関連度BやCの文書についても，表,に示されるとおり，トピックに関連の深い語が上位に重み付けられていることが見てとれる．また，関連度Cの例では，IGRsumの値が低いものも上位に見られるが，いずれもトピックとは関係の薄い語である．</subsection>
  <subsection title="語の重みづけの品質と検索文書の数ならびに品質に関する考察">本手法による重みづけは，クラスタリングの対象となる文書の件数ならびに検索結果の質と密接な関係にある．本来ならば，TSCTaskBと同一条件の下で，要約の対象となる文書数ならびに検索結果の質を変化させての追加検証が必要であるが，TSCTaskBと同一被験者による再実験が困難であるため，ここでは，定性的な考察を行なう．定量的な考察は今後の課題としたい．さて，本手法で語の重みに用いている情報利得比の和は，クラスタ構造に則した分布をしている語に高い重みを与えるものであるから，検索文書をクラスタリングした結果，どのようなクラスタ構造が形成されるかによって，各語の重みが決まる．クラスタ構造は対象となる文書間の類似性により求めるので，検索文書のうち，クラスタリングの対象となる文書群(以下，単に検索文書群と呼ぶ)について，その数と文書間の類似度に密接な関係がある．さらに，本手法では，図に示すように文書データベース中の全文書が所属するクラスタを最上位に考え，検索文書群とそれ以外の文書群の間の差異についても重みに反映しているので，全体のクラスタ構造は情報検索の精度とも関係がある．そこで，以下では，上記二点について個別に考察を行なう．</subsection>
  <subsubsection title="語の重みづけの品質と検索文書数に関する考察">採用する文書が少ない場合と多い場合について考察する．まず，採用する文書数が少ない場合について，検索文書群と残りの文書群との対比から得られる重み，ならびに，検索文書群をクラスタリングした結果から得られる重みがどのようになるかを考える．最終的な語の重みはこれらの和である．文書数が少ない場合には，文書集合中の総単語数ならびに個々の単語の頻度も小さくなるので，平滑化(smoothing)をせずに単語頻度から語の出現確率を直接推定すると，語の頻度の小さな差異が語の出現確率の大きな変化となることがある．この時，残りの文書群における単語の出現確率との差が大きくなれば，その語の重みが不当に高くなる可能性がある．本稿では用いてはいないが，単語出現確率の推定においては平滑化を考慮すべきであろう．検索文書のクラスタリングについては，クラスタ中の文書数ならびにクラスタ構造の枝分かれが少なくなるので，各文書間の類似性関係がクラスタ構造に大きな影響を与える．そして，情報利得比の計算においては，語の重要度が個別文書における語の現れ方に敏感になる．一方，採用する文書数が大きい場合には，個々の単語の出現頻度が相対的に大きくなることと，個々の文書間の類似度がクラスタ構造に与える効果が分散・平滑化されることにより，上記と逆の傾向があると考えられる．ただし，検索質問との関連性が低い文書が数多くなってくると，検索質問に述べられたトピックとは関連性の低い語がクラスタ形成の際に支配的になる事も有り得る．この場合は，本来のトピックに関連する語には相対的に低い重みしか与えられない．これは，検索文章群において，より重要な項目を強調するという点では正しい重みの付き方ではあるが，本来のトピックとの関連性判定という観点からは，誤らせる方向にバイアスがかかってしまう．このような場合にはTombrosらの提案するような検索質問によるバイアス方式の方が適切な結果を与えるので，両者を併用する方法も検討すべきであろう．</subsubsection>
  <subsubsection title="語の重みづけの品質と情報検索の品質に関する考察">検索結果の質も，検索文書群と残りの文書群との対比から得られる語の重み，ならびに，検索文書群をクラスタリングした結果から得られる語の重みの両者に影響を与える．まず，検索文書群と残りの文書群との対比から得られる語の重みについて考える．この段階で検索質問に関連する語に比重がおかれた適切な重みづけがなされるためには，残りの文書集合と比較して検索文書集合側に関連文書が多く存在し，それに伴い関連する語の出現確率が偏る必要がある．情報検索の質が非常に悪く，文書集合からほぼランダムに検索文書が取り出されるのであれば，検索文書集合とそれ以外の文書集合の間で各語の出現確率に見られる差異は小さく，対比によって得られる語の重みはいずれも小さな値に留まる．一方，検索エンジンが，検索質問に従って，ある程度分布の偏った文書集合を返すとすれば，その度合に応じて，検索質問に関連する語の重みも高くなる．次に検索文書群をクラスタリングした結果から得られる語の重みについて考える．節でも述べた通り，検索質問との関連性が低い文書が多くなると，検索質問に述べられたトピックとは関連性の低い語が，クラスタ形成の際に支配的になる事も有り得る．この場合は，本来のトピックに関連する語とは別の語に高い重みが与えられる．この時には，検索質問によるバイアス方式の方が性能が良いと考えられる．前項とともに以上をまとめると，我々の重み付け方式が十分な効果を発揮するためには，の二点を満足することが必要であると考えられる．また，これらの条件を満足しない場合，特に，条件2を満たさない場合にも対応できるためには，検索質問によるバイアス方式との併用を検討することも重要であろう．本節の定量的な評価とともに今後の課題としたい．</subsubsection>
  <section title="関連研究">節でも述べたように，検索結果の文書要約は，通常の文書要約とは次の点で異なる．検索要求文が与えられている．複数の文書が同時に得られている．そして，ある一度の検索の結果という点において文書間に類似性が認められる．本研究においては()の情報を用いたが，()の情報を利用した手法もある．Tombrosらは,文書中のタイトル情報，文書中での位置情報，文書中での単語の出現頻度に基づいた，従来通りの文の重要度に，検索要求文中の単語が文中に出現する頻度に応じたスコアを加味することで，検索要求文に依存した重要文抽出を実現している．塩見らも，文書中の単語の出現頻度に基づいた文の重要度に，検索要求中の単語が文中に出現する頻度に応じたスコアを加味する手法を提案している．しかし，これらの手法は，スコアの制御が難しいことが問題点である．また，節で述べた通り，各種フィードバック，検索要求中の単語のシソーラスによる拡張などといった情報検索システムにおける工夫が反映されないという問題点がある．また，()の情報を利用するという点では，Eguchiら，Fukuharaら，Radevらの手法が関連する．Eguchiらは，適合性フィードバックに基づく検索システムを構築している．このシステムでは，検索結果を文書間の類似度に基づいてクラスタリングし，各クラスタごとにクラスタに多く含まれる語と，そのクラスタを代表する文書のタイトルを，そのクラスタの要約として出力する．ユーザに，出力されたクラスタの中から選択してもらい，そのクラスタに含まれる文書を用いて適合性フィードバックを行なっている．FukuharaらやRadevらも，Eguchiらと同様に検索結果を文書間の類似度に基づいてクラスタリングし，各クラスタごとに要約を出力している．Fukuharaらの手法では，まず，文書中の単語の出現頻度を考慮し，クラスタごとのトピックを表す語を抽出する．そして，それらトピックを含む文を抽出し，焦点−主題連鎖を考慮して並べ替え，各クラスタの要約としている．Radevらの手法では，各クラスタについて，その重心ベクトルをTF・IDF値を用いて計算し，その重心における各語の成分を語の重みの主要な成分としている．これらの手法では，クラスタリングを文書のグループ分けのみに利用しており，グループ化された後では，各クラスタにおける語の分布だけを用いて重みを計算している．また，語の重要度としては単純にクラスタ内のTFやIDFを用いているだけである．直接の比較は今後の課題とするが，我々の手法においては，文書間の類似性構造の情報も取り入れて重みづけしているので，より高い分解能ならびに精度が得られていることが期待される．TSCTaskBにおける評価では，検索文書集合が与えられてはいるものの，最終的には個別文書の要約になっていた．一方，に代表されるように，複数文書から一つの要約文書を生成するという研究も近年注目を集めている．特にCarbonellらは，極大限界適合度(MaximalMarginalRelevance,MMR)という概念を導入し，検索質問と検索文書の類似度ならびに，ある文書とそれよりも上位の文書との間の冗長性に基づいて，検索文書の再順位づけを行なうとともに，これを，パッセージ検索に利用することによって要約生成を行なう手法を提案している．我々の重み付け手法は複数文書を一つの要約にする場合にでも，効果を発揮することが期待されるが，文書間の融合過程においては，冗長性の制御を陽に行なうMMRのような手法との組み合わせも必要になってくるであろう．</section>
  <section title="おわりに">本稿では，複数の検索文書の間に存在する類似性の構造を階層的クラスタリングにより抽出し，その構造を適切に説明するか否かに応じて情報利得比に基づき語に重みをつける手法を提案した．TSCでの実験の結果，この方法に基づく重要文抽出型の要約手法は，検索文書の要約において，非常に有効であることが示された．今後の課題としては，節に述べたように本手法と検索文書の数ならびに品質の間の定量的な関係を明らかにすることが挙げられる．また，情報利得比に基づく語の重みを，対話型の情報検索インタフェース中で利用することを検討することも課題である．本稿では，クラスタ構造の全部分を均一に語の重みに反映させて要約を作成した．一方で，対話型のインタフェースとしては，利用者が部分クラスタを選択しながら，目的の情報に辿りつくというものも考えられる．この場合，提示された箇所のクラスタ構造のみを考慮して，要約を生成することができると考えられる．さらに，複数文書の要約において我々の枠組がどの様に役立つのかも検討したい．</section>
  <section title="NTCIR2 TSC Task B に参加した他システムの概要">NTCIR2TSCTaskBに参加した他システムについて，NTCIR2Workshop論文集に基づきその概略を述べる．なお，システムSys7については，その詳細は不明である．</section>
  <subsection title="ベースライン TF with QB">TSC実行委員会が提供するベースラインの一つで，文抽出型でスコアの上位の文から指定の要約率になるまで抽出．要約率は20%(文を単位とする)．各文のスコアは，内容語(名詞，動詞，形容詞，未定義語)のTFの和であるが，検索トピック中の語にはバイアスが与えられ，2倍の重みとする．この「2倍」という定数がどのように決定されたか，例えば，何らかのチューニングが施されているかなどは不明である．</subsection>
  <subsection title="ベースライン Lead">TSC実行委員会が提供するベースラインの一つで，文抽出型で本文の先頭から指定の要約率になるまで抽出．要約率は20%(文を単位とする)．</subsection>
  <subsection title="ベースライン Fulltext">TSC実行委員会が提供するベースラインの一つで，原文書のうち，表題(見出し文)ならびに本文をそのまま返すもの．要約率は100%(文を単位とする)．</subsection>
  <subsection title="システム Sys 1, Sys 2">CRL+NYUグループ文抽出型でスコアの上位の文から指定の要約率になるまで抽出．要約率は10%(Sys1)ならびに50%(Sys2)．文のスコアは，次の3つの値を重み付きで加算したものである．(1)文書中の文の位置に基づくスコアで，文書の先頭ならびに文末に高い重みを付与する．(2)文長に基づくスコアで長いものに高い重みをつける．(3)名詞のTF・IDF値の和をスコアとしたもの．ただし，見出しに含まれる名詞ならびに固有表現(NamedEntity)については，そのTF・IDF値を加算し，トピック中のDESCRIPTIONおよびNARRATIVEフィールドの名詞に対しては，さらに，TF・IDF値を2倍にする．</subsection>
  <subsection title="システム Sys 3, Sys 4">富士Xerox語と語の間の重要な関係を見つけ出し，それを元に要約を句レベルで生成する．その関係の重みは各語の重みの和に関係の重みを乗じたものである．各語の重みはTF・IDF値で求めるが，トピック中の語については高い重みを与える(詳細は不明)．語の間の関係については，格による依存関係には高い値を，等位接続などには低い値を与える．要約文書の長さは文字数で与えられ，100文字以内(Sys3)もしくは150文字以内(Sys4)である．</subsection>
  <subsection title="システム Sys 6">NTT通信研文抽出型で，ハニング関数を用いた窓により各パッセージの重要度を計算し，その	中から重要文を抽出する．パッセージの重要度計算においてはトピック内の語のみに注目する．また，文書の先頭部分は無条件に加える．要約率は明示されていないが，35%程度である．</subsection>
  <subsection title="システム Sys 8, Sys 9">富士通研グループ文抽出型で，与えられたキーワードを網羅する文を優先しつつ，全てのキーワードが要約文書に出現するまで文を抽出する．キーワードは，文書タイトル，文書の先頭段落(Sys8のみ)，話題構造の境界にある文中の語(Sys9のみ)，トピック中のDESCRIPTIONならびにNARRATIVEから，それぞれ，名詞，動詞，形容詞を取り出したものである．document</subsection>
</root>
