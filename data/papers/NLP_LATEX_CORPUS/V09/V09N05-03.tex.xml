<?xml version="1.0" ?>
<root>
  <title>文字列をk回以上含む文書数の計数アルゴリズム</title>
  <author>梅村恭司真田亜希子</author>
  <jabstract>この論文で計算するものは，ある文字列をk回以上含むドキュメントの総数(df_k)である．全ての部分文字列に対してこれらの統計量を保存する場合O(N^2)の表が必要となり，コーパスの大きさを考えると，この表は実用的でなく，通常の計算機では実際に作ることは難しい．しかし，k=1の場合，SuffixArray，文字列のクラス分けを利用して，統計量をクラス毎に保存することで，これをO(N)の表にできるという報告がある．このクラスは同じ統計量を持つ文字列の集合であり，コーパス内の全ての文字列の統計量はクラス毎に作成した統計量の表から取り出すことができる．しかし，この方法はk2の場合には使用できない．我々は，k2の場合にも使用でき，表を用いることによって文字列の統計量を計算するアルゴリズムを提案する．本稿ではdf_kの性質を述べた後，単純な計算方法と提案するアルゴリズムとの比較を行う．このアルゴリズムは，前処理として表を作成するためにO(NN)の計算時間とO(N)のメモリを使用し，その表を用いてO(N)時間で文字列の統計量を取り出すことができる．</jabstract>
  <jkeywords>文字列頻度，文書頻度，SuffixArray</jkeywords>
  <section title="はじめに">ある文字列をk回以上含むドキュメント数には，文字列の意味に関連する性質がある．この論文では，このドキュメント数を重複度kのドキュメント頻度と呼び，特にkを指定しない場合には，重複条件付きドキュメント頻度と呼ぶことにする．図は，332,918個の日本語アブストラクトの本文を対象に，様々な文字列に対し，kを変化させて，重複度kのドキュメント頻度を計測したものである．文字列が意味のある単語の部分である場合には，kの増加にしたがっても，文書数の減少は緩やかである．たとえば，「メ」「メデ」「メディ」「メディア」などについては，kが一つ増加するごとに，ドキュメントの数が半減する傾向が観察される．一方，単語の切れ目を含む文字列の場合，kが増えるにしたがって文章数が1/4以下になることが観測できる．この性質を使って，文書中のキーワードを辞書を使わないで検出するということが可能であるという報告がある．重複条件付きドキュメント頻度を単語の境界の検出に使用するには，任意の文字列について，その重複度付ドキュメント頻度を求めることが必要である．たとえば，文献の文書分析では，頻度３を越える文字列について重複条件付きドキュメント頻度を計算しており，平均440バイト程度の1ドキュメントについて，1400個程度の文字列が調査の対象となっている．単純な方法で重複度付ドキュメント頻度を求めると，文字列ごとにコーパス長に比例する計算時間がかかることになり，後述するように一つのドキュメントを処理するのも大変である．さらに，キーワードをドキュメントの全体にわたって調査すると，この処理を332,918回繰り返すことになり，単純な方法では計算時間がかかりすぎるという問題がある．ここで，重複度を考慮しないドキュメント頻度（単純ドキュメント頻度）については，ドキュメント頻度が同じ文字列をクラス分けができ，そのクラスごとに頻度を計測することが可能であるという報告がある．例中の「メディアを用」と「メディアを用い」の二つの文字が同じドキュメント頻度を持っているが，このような文字列が一つのクラスに属する文字列の例である．報告によると，コーパスの文字数をNとした場合に，クラス数は最大で2N-1である．よって，O(N)の大きさの表に，任意の文字列の単純ドキュメント頻度を保持することができる．しかし，重複度を考慮した場合に同じクラス分けが使えるかどうか明らかではないという問題が残る．また，クラス分けをして，表を作成するならば，重複条件付きのドキュメント頻度は，クラスごと，つまりそのクラスを代表する一つの文字列についてのみ求めればよいが，単純な方法では，代表の文字列の個数がO(N)，それぞれの計算にO(N)かかることになり，全体でO(N^2)の処理となる．Nがおよそ10^8程度のコーパスでは，実際に前処理が終わらないという問題が残る．文献は単純ドキュメント頻度について，この問題の解決方法を示している．この方法は，文字出現頻度から重複を除いて単純ドキュメント頻度を求めている．しかし，重複の構造が複雑な重複条件付きドキュメント頻度の計測には，重複を除くという考え方が使用できない．この論文では，重複条件付きドキュメント頻度の計測についても，クラス分けが使用できることを示し，その前処理として重複度の上限を与えた場合に，O(N)で，クラスごとの重複条件付きドキュメント頻度の表を作ることができることを示す．そのときに，重複条件付き文字列頻度という概念を提案し，重複条件付き文字列頻度の関数として重複条件付きドキュメント頻度が求まることを示す．最後に，実際に動作するシステムを作成し，332,918個のドキュメントで，69,312,280文字からなるコーパスで計測した計算時間を示す．ここで示すアルゴリズムは，kを固定したとき，ある文字列がk回以上出現するドキュメントの数を数え上げる問題について，ドキュメントの全文字数をNとすると，前処理は計算時間O(NN)，メモリ使用量O(N)であり，その後に値を求めるときには計算時間O(N)，メモリ使用量O(N)である．</section>
  <section title="記号の定義">tf(d,x)を，ドキュメントdに含まれる文字列xの個数と定義する．この論文で扱う頻度は，tf(d,x)で定義できるものである．cf(x)は，文字列頻度と呼ばれるものであり，df(x)は単純ドキュメント頻度と呼ばれるものである．cf(x):ドキュメント集合中に文字列xが出現する数cf(x)=_dtf(d,x)df(x):文字列xが1回以上出現するドキュメントの数df(x)=d|tf(d,x)1われわれが求めたい重複条件付きドキュメント頻度もtf(d,x)から求められるものである．df_k(x):文字列xがk回以上出現するドキュメントの数df_k(x)=d|tf(d,x)k</section>
  <section title="Suffix Array">クラス分けのために，SuffixArrayというデータ構造を用いる．SuffixArrayは文献によって示されたデータ構造である(図)．このデータ構造はあるテキストがあったときに，そのテキストのすべての文字からテキストの終了までの文字列(suffix;接尾辞)の集合を考え，その集合を辞書順に並べたものである．ここで，テキストの本体がメモリにあるとすると，一つの文字列を格納するのに，文字列の開始場所という一つの整数を格納すれば良い．このため，任意の部分文字列の場所を知ることができるにもかかわらず，必要な記憶容量はO(N)で済む．SuffixArrayは以下のルーチンで生成できる．ドキュメント頻度を計算する場合，ドキュメントの長さに上限があればコーパス中の文字列はドキュメント毎に区切られていると見なすことができる．この条件の下で上記のアルゴリズムを使ってデータ構造を作成するためには，O(NN)時間必要である．</section>
  <section title="文字列のクラス分け">文字列の文献の文字列のクラス分けの方法を使用するが，この論文では，重複条件付きドキュメント頻度を求める場合にもクラス分けを使用できることを述べる．クラス分けはsuffixを用いて定義される．SuffixArrayのsuffixは辞書順に並んでいるので，文字列の先頭部分が次のsuffixと共通であることが多い．そこで，common[i]をsuffix[i]とsuffix[i+1]の文字列の先頭からの共通部分とする．文献のクラスの定義を下に示す．ここで，定義の記述を簡単にするためj-1&lt;iの場合min_k=i^j-1=∞とする．そして，common[-1]=-1，common[N]=-1とする．区間の境界でのcommonの大きい方であるoutgoing(i,j)=max(common[i-1],common[j])と定義し，区間内部でのcommonの最小のものinner(i,j)=min_k=i^j-1(common[k])と定義する．[定義]区間[i,j]がクラスを形成するとは，inner(i,j)&gt;outgoing(i,j)であることをいう．inner(i,j)は区間全体で共通部分となる文字列の長さであり，inner(i,j)&gt;outgoing(i,j)であるとは区間を広げると全体で共通となる文字列が短くなるという意味となる．区間[i,j]がクラスを形成するとき，区間[i,j]に共通する「長さoutgoing(i,j)+1からinner(i,j)までの部分文字列」の集合を，その区間に対応する文字列のクラスと定義する．図で，区間[i,j]=[2,2]，[i,j]=[1,4]，[i,j]=[1,3]を見た場合，となり，区間[2,2]はinner(2,2)&gt;outgoing(2,2)，区間[1,4]はinner(1,4)&gt;outgoing(1,4)となるのでクラスを形成するが，区間[1,3]はinner(1,3)&lt;outgoing(1,3)となるのでクラスを形成しない．文献によると，クラス数は最大でも2N-1であり，その表は作成し記憶することが実際的な大きさである．[occurence(C)の定義]クラスCで定まる区間[i,j]について，集合suffix[i],...,suffix[j]をoccurence(C)とする．occurence(C)は，出現場所を示す整数の集合となる．[性質1]クラスCがあったとき，Cの任意の2要素x，yについて，任意のドキュメントをdとすると，tf(d,x)=tf(d,y)である．証明tf(d,x)は，dの中に出現するxの個数であるが，これは，xの出現する場所で，その場所がドキュメントdに属する回数に等しい．xの出現する場所は，xの属するクラスCのoccurence(C)で求まる．tf(d,x)は，occurence(C)の各要素である整数が，ドキュメントdに属しているかどうかで求めることができる．つまり，xの属するCについて，xの出現する位置の集合occurence(C)を求めて，それからtf(d,x)を決定できる．ここで，yがxと同じクラスの属していれば，両方ともoccurence(C)が同じであるため，tf(d,x)=tf(d,y)となる．[性質2]クラスCがあったとき，Cの任意の2要素x，yについて，cf(x)=cf(y)df(x)=df(y)df_k(x)=df_k(y)が成立する．証明性質1より，tf(d,x)=tf(d,y)なので，tf(d,x)を使用して定義できる頻度はすべて等しい．すなわち，cf(x)=_dtf(d,x)=_dtf(d,y)=cf(y)df(x)=d|tf(d,x)1=d|tf(d,y)1=df(y)df_k(x)=d|tf(d,x)n=d|tf(d,y)n=df_k(y)証明は単純であるが，df_k(x)の性質は未知であるため，同じクラスに属する文字列について，その値が等しいことを示すことは必要である．</section>
  <section title="クラスの階層関係">クラスごとの頻度の表を高速に作成するために，クラス間の階層関係を利用するが，まず，クラスの階層関係を定義する．区間[i_1,j_1]がクラスC_1を形成し，区間[i_2,j_2]がクラスC_2を形成していて，区間[i_1,j_1]が区間[i_2,j_2]に含まれているとき，C_1はC_2の下位のクラスと定義する．また，C_2はC_1の上位のクラスと定義する．[性質4]2つのクラスC_1，C_2に交わりがあったときには，C_1はC_2の上位のクラスであるかC_1はC_2の下位のクラスであるかのどちらかである．証明C_1とC_2に交わりがあるということは，のいずれかである．(1)の場合，i_1&lt;i_2であると仮定する．区間[i_1,j_1]ではmax(common[i_1-1],common[j_1])&lt;min_k_1=i_1^j_1-1(common[k_1])となるので，common[j_1]&lt;common[k_1](i_1k_1j_1-1)である．一方，区間[i_2,j_2]では，k_1=i_2-1，k_2=j_1(i_2k_2j_2-1)となるk_1，k_2が存在する．従って，common[k_1]=common[i_2-1]&gt;common[k_2]=common[j_1]となり，区間[i_2,j_2]はmax(common[i_2-1],common[j_2])&lt;min_k_2=i_2^j_2-1(common[k_2])を満たさず，i_1&lt;i_2の場合クラスC_2を形成しないのでC_1とC_2に交わりはない．i_1=i_2j_1j_2の場合はクラスの階層の定義より，C_2がC_1の上位クラスである，または，等しいクラスである．(2)も(1)と同様に証明できる．また，(3)の場合はクラスの階層の定義より，C_1がC_2の上位クラスであるか等しいクラスであり，(4)の場合は，C_2がC_1の上位クラスである，または，等しいクラスである．以上より，2つのクラスに交わりがある場合は，一方がもう一方の上位クラス，または，下位クラスとなる．[性質5]Arrayにおいて，すべてのsuffixはクラスによって階層構造を形成する．証明common[-1]=common[N]=-1より，最上位クラスは，すべてのsuffixを含むクラスである．また，性質4よりあるクラスが他のクラスの部分クラスでない限り交わることはない．このとき，部分クラスでは上位クラスよりその区間が短くなる．以上のことから，すべての文字列の出現場所は文字列クラスによって階層構造を形成する．[性質6]任意の区間[i,j]について，[i,j]を含む区間でクラスを形成する区間がある．区間[i,i]においてoutgoing(i,i)&lt;∞，inner(i,i)=∞なので，inner(i,i)&gt;outgoing(i,i)となり，区間[i,i]は1つのsuffixからなる最下位クラスを形成する．証明性質5より，SuffixArrayのすべてのsuffixはクラスによって階層構造を形成する．[記号]任意の区間[i,j]について，それを含むクラスを形成する区間のうち，もっとも下位のものを[i,j]から定まるクラスとし，Class^([i,j])と記述する．任意の区間について，それを含むもっとも下位のクラスが一意に定まることは，計算量を押さえたアルゴリズムを構成するときに必要な性質である．Class^([i,j])は，後述する頻度を計数するところで使用する．</section>
  <section title="重複条件付きドキュメント頻度の計測における問題点">すべてのクラスについて，それに属する文字列のドキュメント頻度を単純な方法で求めるとすると，通常の計算機では実用上問題がある．クラスの大きさが高々2Nであったとしても，df(x)，df_2(x)，df_3(x)のように条件を満たす集合を作って，その大きさを計測すると，各xの処理にO(N)時間かかり，xがN個あれば，全体ではO(N^2)時間必要となる．これは，コーパスの大きさから考えて，通常の計算機では実行できない処理となる．文字列の出現頻度であれば，クラス階層に従って頻度の合計を求めることができる．すなわち，下位のクラスの文字列頻度を合計して，上位の文字列頻度とすることができる．言い換えれば，長い文字列の頻度から，短い文字列の頻度をもとめることができる．しかし，ドキュメント頻度は，直接寄せ集めることができない．たとえば，図のようなコーパスについて考える．文字列abcは6回出現し，それが出現するドキュメントの数が4個である．また，文字列abxは7回出現し，それが出現するドキュメントの数が5個である．このとき文字列abに続く文字のパターンがabcとabxの2つだけであったとすると，suffixの構造は図に示されたような構造になる．この状況で，abの出現回数は6+7回である．しかし，この状況で，abが出現するドキュメントの数は9個とはいえない．abcとabxが両方出現するドキュメントを2個と数えることが間違いだからである．で示されるように，単純なドキュメント頻度の計数であれば，重複して数えているところを差し引くという方法があるが，ドキュメントを計測する条件が，その文字列が2回以上出現するドキュメント数であった場合，クラスの上下によるドキュメント頻度の変化はさらに複雑になり，重複を差し引くという方法は使用できない．</section>
  <section title="出現場所の重複条件">重複条件付きドキュメント頻度の計測行う準備として，この論文で新しく使用する「文字列の出現場所ごとの重複条件」を定義する．重複条件付きドキュメント頻度の計測のために，クラス階層で寄せ集められる数を定義し，その数の関数として重複条件付きドキュメント頻度を求めることを行う．ここで使用する頻度を定義するために，文字列の出現場所の重複度と重複条件を使用する．すべての文字列の出現場所は，SuffixArray内の配列の番号で順序づけることができる．この順序をsuffix順と定義し，これを利用して文字列の出現場所の重複条件と重複度を定義する．[定義]ある文字列xの出現場所の重複度がkであるとは，suffix順でその出現場所以下の場所で，かつ同一のドキュメントに属する文字列xの出現場所がk個あることとする．図に重複度の例を示す．順でabx(suffix[3])以下の場所にあるのは，abc(suffix[0])とabd(suffix[1])，abe(suffix[2])，abx(suffix[3])である．ここで，文字列abxについてdocument#1での文字列abの重複度kを求めると，ドキュメント中に文字列abc，abd，abxが出現するので，k=3である．[性質7]文字列xがドキュメントiにt個出現するとき，t個の出現場所について，すべて重複度を求め，それをsuffix順に並べると1,...,tとなる．</section>
  <section title="重複条件付き文字列頻度">[記号]xを文字列としたとき，重複条件付き文字列頻度cf_k(x)と重複条件付きドキュメント文字列頻度tf_k(d,x)と書く．[定義]cf_k(x)はコーパス中で，重複度がk以上の文字列xの出現数とする．[定義]tf_k(d,x)はドキュメントd中で，重複度がk以上の文字列xの出現数とする．[性質8]x,yC,k;d;tf_k(d,x)=tf_k(d,y)文字列xの属するクラスをCとする．重複度は，場所と文字列に関係するので注意が必要であるが，suffix順で順番をつけるので，occurence(C)が定まれば，それぞれの要素についての重複度が一意に定まる．したがって，tf_k(d,x)はtf(d,x)と同様にdとoccurence(C)の関数となる．</section>
  <section title="重複条件付き文字列頻度とドキュメント頻度の関係">ドキュメント頻度と重複条件付き文字列頻度には下の単純な関係がある．[定理文字列頻度とドキュメント頻度の関係]df_k(x)=cf_k(x)-cf_k+1(x)証明tf(d,x)=tのとき，ktについて，tf_k(d,x)-tf_k+1(d,x)=1tf(d,x)=tのときtf_t(d,x)=1,tf_t+1(d,x)=0,tf_t+2(d,x)=0,以下0が続くので，k&gt;tについて，tf_k(d,x)-tf_k+1(d,x)=0cf_k(x)=_dtf_k(d,x)であるので，cf_k(x)-cf_k+1(x)&amp;=&amp;_d(tf_k(d,x)-tf_k+1(d,x))&amp;=&amp;d|tf(d,x)k&amp;=&amp;df_k(x)eqnarray*あるテキストにおいて，cf_kとdf_kを実際に求めた例を図に示す．図の3つのドキュメントで，文字列abについてcf_k，df_kを求める．まず，cf_kを計算する．tf(1,ab)=78，tf(3,ab)=68である，ドキュメント#1，#3は，重複度k8となる文字列abが存在しないため，cf_8の数え上げに関係しない．ドキュメント#2では，tf(2,ab)=8であるので重複度k8となる文字列abが一つだけ(tf-k+1=1)存在する．したがって，cf_8(ab)=1．同様に，cf_7(ab)は，tf(1,ab)-k+1=7-7+1=1，tf(2,ab)-k+1=8-7+1=2となり，ドキュメント#1，#2によってそれぞれ1と2がカウントアップされるので，cf_7(ab)=1+2=3となる．他も同様である．この様にcf_kが求められたので，定理「文字列頻度とドキュメント頻度の関係」を用いることで，df_kを計算できる．[性質9]あるクラスCがあったとき，その要素x,yについては任意のkについて，cf_k(x)=cf_k(y)証明cf_k(x)=_dtf_k(d,x)，tf_k(d,x)=tf_k(d,y)なので，cf_k(x)=_dtf_k(d,x)=_dtf_k(d,y)=cf_k(y)</section>
  <section title="重複度判定のためのデータ構造">ここでは重複度を判定するためのデータ構造であるpreviousリンク(文献[DF1])について説明する．previousリンクはそれぞれのsuffixについて，同じドキュメントに属し，かつsuffix順で前にある最も近いsuffixの順位を記録しておく．もしそのような場所がなければ，-1をpreviousリンクとする．このデータ構造はコーパスの大きさに比例した大きさのメモリ領域である．文字列xのある出現重複度がk以上であることの判定は，その出現場所からpreviousリンクをk回たどれるかどうかと，たどれる場合，その文字列がまだ出現しているかを計測することで判定できる(図)．このデータ構造を作るには，ドキュメント数と同数の整数配列を用意して，それぞれの文字列の出現ごとに，ドキュメントの番号を求め，その配列からpreviousリンクの場所の情報を求めると同時に，その表を現在の場所に更新すればよい．リンクを作成するプログラムは以下のような構造になる．このデータ構造を作成するには，ドキュメント数と同じメモリ領域を用意し，コーパス全体を一度スキャンすることになる．/*id_max:ドキュメント数，size:コーパスの文字数*/for(i=0;i&lt;id_max;i++)last_suffixes[i]=-1;for(i=0;i&lt;size;i++)suffix[i].previous_suffix=last_suffixes[suffix[i].id];last_suffixes[suffix[i].id]=i;verbatim重複度判定は，このpreviousリンクをk回たどることができ，かつその文字列が同じドキュメントにあるかどうかで判定できる．(注)実際のプログラムでは，計算量を押さえるため，単純に重複度を判定せず，この重複度の判定と別の処理を同時に行っている．</section>
  <section title="クラス検出のアルゴリズム">クラスを検出するアルゴリズムの概略は以下のように行う．SuffixArrayをsuffix順が小さいものから見て行く．クラスの開始場所を見つける．クラスの終了場所を探す．クラスは階層構造になっているため，そのクラスの終了場所が見つかる前に，他のクラスの開始場所が見つかることがある．この場合は，スタックにその開始場所をプッシュする．クラスの終了場所が見つかれば，報告しスタックを回復する．上記のアルゴリズムでクラスを求めていったとき，求めるクラスの先頭が発見できていて，まだ，その終りが発見できていないクラスを計算中のクラスと呼ぶことにする．アルゴリズムでは，スタック中のクラスを現在計算中のクラスとする．common[i]はコーパスの文字列と同じ大きさの配列で，SuffixArrayで次のsuffixと文字列が一致している長さである．この文字列はドキュメントの長さを越えることはなく，したがって，計算量のオーダを増やすことはない．文字列のクラスは，common[i]の増減にしたがっている．common[i]が増加したときは，現在計算中のクラスを計算終了していないクラスとして登録し，新しいクラスが開始したものとして処理する．common[i]が減少しているときは次の2つのケースがある．現在のクラスは終了するが，実は現在のクラスと同じsuffixの場所から始まったクラスが，現在のクラス以外にもある場合．現在のクラスを終了し，スタックトップのクラスの処理を	継続しなければならない場合．2番目のケースで，スタックトップの計算途中のクラスの処理を継続するときには，このクラスがすぐに終了しているかどうかの検査から処理を継続する．クラスの発見をするにはcommon[i]ごとに，クラス終了判定の操作を行うことになる．2番目のケースでは，計算途中のクラスの数だけ繰り返しが起きるのだが，その繰り返しの数を合計してもクラスの最大数を越えることはない．したがって，クラスの最大数とcommon[i]の個数からこの操作はO(N)で完了できる．現在計算中のクラスについて，以下の性質が成り立つ．[性質10]現在計算中のsuffixから始まり，ドキュメントの区切りまでの文字列を属するクラス毎に分類すると，そのクラスは現在計算中のクラスとなる．</section>
  <section title="単純な重複条件付き文字列頻度の計数">重複度kが与えられていたとき，すべての文字列xに対して重複度がk以上であるcf_k(x)を求めることを考える．重複度は文字列と場所の関数であるが，同一クラスに属する文字列の重複度が異なることはない．また，同一クラスに属する文字列について，cf_k(x)は等しい．そこでクラスの数だけのカウンタを用意し，各suffixについて処理を行なうことでも計数できる．これを単純な方法とよぶ．この方法はメモリ領域O(N)であるが，計算時間が問題となる．計数の方法は，ある場所について，そこから始まるクラスの集合を求め，すべてのクラスに対してカウンタを用意し，クラス毎に重複度がk以上であるかを判定して，カウンタに1を加えるというものである．この方法を単純に行うと，一つのsuffixに関連するクラスが多数になり得るため，O(NN)以下の計算量では収まらない場合がある．具体的には同じ文字が長く連続するようなデータがこのケースになる．</section>
  <section title="重複条件付き文字列頻度の計数">重複条件付き文字列頻度の計数を単純な方法で行うと，一つのsuffixに対し，それが含まれるクラスをすべて求め，そのクラスのすべてに対してカウンタの更新を行わなければならない．しかし，以下の性質を利用することですべてのクラスに対しカウンタを更新することを避けられる．[性質11]ある場所が与えられたとき，そのsuffixの先頭の文字列に対応するクラスの集合が求められるが，そのクラスには一意の階層関係がある．[性質12]ある場所が与えられたとき，そこのsuffixの先頭の文字列に対応するクラスのうち，あるクラスの文字列について重複度がkであったとすると，そのクラスより上位のクラスの重複度はk以上である．この２つの性質のため，カウンタの加算を一つのsuffixと一つの重複度kにに対して一つにすることができる．つまり，あるsuffixで重複度k以上となるクラスのうち，最下位のクラスのカウンタだけを加算しておき，下位クラスの計数が終了したときに，上位のクラスのカウンタにその計数値を加算していくことで，すべてのクラスの計数値を得ることができる．</section>
  <section title="クラスの発見と頻度計算"/>
  <subsection title="クラスの始まりを発見したときの処理">あるクラスの始まりはcommon[i]が増加したことで発見できる．このとき，現在計測している重複条件付き文字列頻度の情報はほかのクラスの情報と同様にスタックに待避させ，重複条件付き文字列頻度は0に初期化して新たに計数する．</subsection>
  <subsection title="重複度判定とクラス選択の融合">ある場所で，重複度がkより大きいクラスのなかで最も下位のクラスを特定する操作は，重複度判定と融合することができる．重複度の判定はpreviousリンクをk回たどった場所iと，現在の場所jの区間が一つのドキュメントに含まれるかどうかで行うので，逆にその区間を含むクラスの集合を求めておき，その中でClass^([i,j])を求めることができる．この操作は，さらにクラスの検出と同時に行うことができる．これは，「ある場所で，重複度がkより大きいClass^([i,j])」を定める区間[i,j]が，現在の場所jを終りに持つため，検出の途中では計算未終了のクラスとなっていることを利用する．具体的には，まず，previousリンクをk回たどったところにある文字列の出現を求める．次に，その出現場所と最初の出現場所を含む文字列から，共通かつ計算中のClass^([i,j])を特定する．そのクラスの重複条件付き文字列頻度を加算する．</subsection>
  <subsection title="クラスの終了を発見したときの処理">あるクラスの終了はcommon[i]が減少することで発見できる．このとき，上位クラスへ計数の値を伝える処理をする．下位クラスの計数が終了したときに上位クラスのカウンタに，その計数値を加算することで，結果的にすべてのクラスに加算するのと同じ値を得ることができる．</subsection>
  <section title="実行例">サンプルとして処理するデータは以下のファイルである．一行が一つのドキュメントになっている．abcabcabcabcdabcdebcdeverbatim</section>
  <subsection title="Suffix Arrayの作成とクラス検出の準備">第一段階では，SuffixArrayを作成し，commonをもとめ，PreviousLinkを作成する．例に対しては以下のようなデータが作成される．先頭から，suffixの番号suffixが属するドキュメントの番号同じドキュメントに属しているsuffixで，直前に現れたものの番号直後のsuffixと「先頭から一致している文字列」の長さそのsuffixの文字である．00-10:11-10:22-10:33-10:4003:abc5046:abcabc6053:abcabcabc7114:abcd8220:abcde9062:bc10095:bcabc110102:bcabcabc12173:bcd13284:bcde14330:bcde150111:c160154:cabc170161:cabcabc181122:cd192133:cde203140:cde211181:d222192:de233200:de242221:e253230:everbatim</subsection>
  <subsection title="求められたクラスの表の例">本文で説明した方法で，cfが2より大きなクラスを求める．これを，クラスの先頭の場所を第1キー，長さを第2キーにしてソートし，同時に，重複条件付き文字列頻度から，文書頻度に変換する．その結果は，以下のようになる．この例では，cfが2より大きなクラスは全部で14個ある．クラスごとに，対応する区間，次に長さ，それぞれのクラスに対する統計値とクラスを代表する文字列となっている．クラスを代表する文字列とは，そのクラスのなかで最長の文字列である．この中には，区間の大きさが1のクラスは含まれていない．この情報の中にはクラスに含まれる最短の文字列が何であるかという情報が含まれていない．そのような文字列は，クラスを代表する文字列と先頭から比較していき，最も長く一致するものの中で最も上位のクラスの情報を取り出すことで対処している．クラスのソートで，区間の先頭を第1キーにすることでほぼ辞書順に並ぶ．区間の先頭が同じ場合には，長さが短いほうが優先されることで，結果としてクラスの代表する文字列は辞書順に並ぶ．total=14Class[4,8]L=3tf=5df1=3df2=1df3=1df4=0S=&quot;abc&quot;Class[5,6]L=6tf=2df1=1df2=1df3=0df4=0S=&quot;abcabc&quot;Class[7,8]L=4tf=2df1=2df2=0df3=0df4=0S=&quot;abcd&quot;Class[9,14]L=2tf=6df1=4df2=1df3=1df4=0S=&quot;bc&quot;Class[10,11]L=5tf=2df1=1df2=1df3=0df4=0S=&quot;bcabc&quot;Class[12,14]L=3tf=3df1=3df2=0df3=0df4=0S=&quot;bcd&quot;Class[13,14]L=4tf=2df1=2df2=0df3=0df4=0S=&quot;bcde&quot;Class[15,20]L=1tf=6df1=4df2=1df3=1df4=0S=&quot;c&quot;Class[16,17]L=4tf=2df1=1df2=1df3=0df4=0S=&quot;cabc&quot;Class[18,20]L=2tf=3df1=3df2=0df3=0df4=0S=&quot;cd&quot;Class[19,20]L=3tf=2df1=2df2=0df3=0df4=0S=&quot;cde&quot;Class[21,23]L=1tf=3df1=3df2=0df3=0df4=0S=&quot;d&quot;Class[22,23]L=2tf=2df1=2df2=0df3=0df4=0S=&quot;de&quot;Class[24,25]L=1tf=2df1=2df2=0df3=0df4=0S=&quot;e&quot;verbatim</subsection>
  <subsection title="文字列に対する処理">与えられた任意の文字列に対して，上記の表を二分探索することでtf，df_1(=df)，df_2，df_3，df_4を求めることができる．二分探索であり，表の大きさはO(N)であるので，この処理はO(N)で終了する．abc--Class[4,8]に該当（代表文字列）53110abcabcabc--Class[5,6]に該当（代表文字列）21100abcabcabcd--Class[7,8]に該当（代表文字列）22000abcdabca--Class[5,6]に該当（代表文字列でない）21100abcaabcab--Class[5,6]に該当（代表文字列でない）21100abcababcabc--Class[5,6]に該当（代表文字列）21100abcabcabcabca--表になく，コーパスに存在する11000abcabcaabcabcab--表になく，コーパスに存在する11000abcabcababcabcabc--表になく，コーパスに存在する11000abcabcabcabcabcabca--表になく，コーパスに存在しない00000abcabcabcaverbatim</subsection>
  <section title="実行時間の計測">実行時間の計測は，どのようなドキュメントを用いても良いが，ここでは，技術用語のアブストラクトの集合を使用した．そこからアブストラクトの本文だけを抜き出し，一行を一つのドキュメントに整形したものである．332,918文書，69,312,280文字，130,993,215バイトのコーパスである．測定には，AthlonMP1.2Mhz，3GByteメモリのシステムを使用した．</section>
  <subsection title="ボトムラインシステム">最初の比較対象のシステムは，一番単純な方法で計測した場合である．文字列と重複度kが与えられたときに，kのドキュメント頻度をは，コーパスの先頭から順番に見るという方針で求めるものである．具体的には，以下のようなプログラムで求める．これば，クラス分けもクラスの階層構造も利用しないシステムとなっている．このシステムは定義が単純であるため速度の比較だけでなく，プログラムの動作の正答を用意し，提案するシステムが正しく動作していることの確認にも使用した．このシステムをlinearと呼ぶことにする．/*s1の先頭がs2で始まっているかどうかを検査する関数*/staticintstring_sub(char*s1,char*s2)while(*s2)if(*s1!=*s2)return0;s1++;s2++;return*s1;/*改行までの間に，文字列がk回出現するかどうか調べ，出現した回数をカウントする回数．*/intdfn(intk,char*s)inti;/*stringposition*/intt;/*termfrequencyinadocument*/intn;/*documentfrequency*/n=0;t=0;for(i=0;i&lt;size;i++)if(string_sub(&amp;text[i],s))t++;if(text[i]=='')if(t&gt;=k)n++;t=0;returnn;verbatim</subsection>
  <subsection title="ベースラインシステム">ベースラインシステムは，クラス分けを使用しているが，表を作成するときにクラスの階層構造を使用しないシステムである．クラスの検出のあと，下のCのプログラムを使って，df_1からdf_5までを同時にもとめて表にする．このシステムをbaseと呼ぶことにする．/*重複条件付きドキュメント頻度を一斉に求める関数結果は，staticな配列に保存する．*/staticintdfn[MAX_C];staticvoidcount_dfn(char*s,intlen)inti;/*stringposition*/intt;/*termfrequencyinadocument*/intn;/*documentfrequency*/intk;n=0;t=0;for(k=0;k&lt;MAX_C;k++)dfn[k]=0;;for(i=0;i&lt;size;i++)if(strncmp(&amp;text[i],s,len)==0)t++;if(text[i]=='')for(k=0;k&lt;MAX_C;k++)if(t&gt;k)dfn[k]++;t=0;verbatim</subsection>
  <subsection title="提案システム">提案するシステムはこの論文で記述した方法を用いたものであり，クラスの表を作成し，表の数値を計数するときに，クラスの階層の性質を使用したものである．このシステムをclassと呼ぶことにする．</subsection>
  <subsection title="計測">実験は，10個のドキュメントのなかに含まれる文字列頻度が3をこえるすべての文字列について，cf，df_0，df_1，df_2，df_3，df_4，df_5を求めることを行った．コーパスの文字数Nによる効果を測定するために，使用するコーパスを，先頭から，316ドキュメント，1000ドキュメント，3162ドキュメント，10000ドキュメント，31623ドキュメント，100000ドキュメント，332918ドキュメントと変化させた実行時間を計測した．実行時間は，前処理の時間と，重複条件付きのドキュメント頻度を求める時間とに分けて計測した．表にlinear，base，classの実行時間を示す．表の中の時間は，処理装置の使用時間を秒で示したものである．また，すべてのプログラムが同一の頻度を出力することも確認した．重複条件付きドキュメント頻度の分析対象とした文字列は，10ドキュメント，4156バイト，2190文字の部分文字列で，統計的に安定な頻度が3を越える文字列である．この文字列の数は，コーパスが大きくなるにつれ増加するが，その増加は緩やかである．linearシステムは，前処理は必要なく，前処理の時間はテキストを読む時間だけである．この計測ではファイル処理の時間は除外しているので，前処理の時間は0.0となる．linearシステムは直ちに結果を出力し始めるがコーパスのドキュメント数が増加することに比例して一つあたりの分析時間が大きくなっていく．10個のドキュメントの分析という小さな問題であっても，実用的に使用できるのは，ドキュメントの数が１万程度までである．baseシステムは，分析時間は高速になるが，前処理にO(N^2)の時間がかかることが観測される．実用的に使用できるのは，ドキュメントの数が数千個程度までである．提案するシステム(class)の実行時間は，実データにおいて，前処理O(NN)となっている．そして，分析時間を分析対象の文字数で割ることで求められる1文字列あたりの時間は，最大でも0.036ミリ秒であり，1000ドキュメントより大きなコーパスにおいて，O(N)となっている．332,918ドキュメントの前処理の時間は1223.4とO(NN)に比べて大きい．ほかに比べて増加しているのは，実験に使用したコンピュータの実装メモリに近いプロセスの大きさになったためだと考えられる．以上，クラス分けによる表の作成と，クラスの階層構造を利用することによって，はじめて10万を越えるドキュメント数に対して分析ができるようになったことがわかる．*4em</subsection>
  <subsection title="メモリ容量負荷">プログラムで使用するメモリの量を示すために，実行しているプロセスの大きさを計測する．これを表に示す．計測では分析する重複度の上限は5に設定している．表より，提案するシステムのメモリ負荷は，O(N)となっていることがわかる．そして，表の作成に，1クラスあたり100バイト，表の検索に，1クラスあたり50バイト使用していることがわかる．表の検索のプログラムは，クラス分けの表とSuffixArrayを保持しており，プロセスの大きさの主要な部分は，その大きさである．表を作成するには，クラス検出のためのデータ構造や，重複度判定のためのデータ構造などがあり，分析処理よりもメモリを多く必要とする．</subsection>
  <section title="そのほかの応用">任意の文字列について，前処理の後にO(N)で重複条件付きドキュメント頻度の分析を行うことは，文字列の統計処理の基本技術であり，ここで述べた単語の境界の分析以外にも応用範囲がある．</section>
  <subsection title="情報検索への応用">日本語，中国語などの情報検索では２文字の文字列に対して，ドキュメント頻度を計測して，2文字に対して情報検索の重みを計算することが行われている．df_2(x)/df_1(x)は，Adaptationと呼ばれる量で，ドキュメントの確率という空間において，ドキュメントにある文字列が出現するということを条件としたとき，そのドキュメントに2回文字列が出現する確率の推定値である．文献は英語において，その確率が統計的に単語の性質を識別できることを示している．この量を使って検索対象の文字列を区分けすると検索精度が向上するという報告がある．あらかじめ表を作成するのが難しいため，この報告の処理対象は2文字に限られていたが，ここで述べた方法を使って，任意の長さの文字列から検索に効果のある文字列を選びだし，情報検索の性能を向上させるのは有望な応用の一つだと考えられる．</subsection>
  <subsection title="遺伝子情報への応用">文献は，自然言語で書かれたドキュメントを分析対象として，辞書を使わず，重複条件付きドキュメント頻度からキーワードを抽出していたが，これは「あるドキュメントに繰り返し現れる文字列」を効果的に取り出すシステムと解釈できる．これを遺伝子情報に適用して，「遺伝子に繰り返し現れるDNA配列」を検出するのは有望な応用の一つと考えられる．遺伝子の長さを考えると，ここで示した方法をつかってはじめて，遺伝子のドキュメント頻度の分析ができるようになると考えられる．</subsection>
  <subsection title="プログラミングツールへの応用">文献は，文字列の頻度を分析して，プログラム中にまれにしか現れない文字列を検出し，それがプログラムの欠損の判定に効果があることを示している．このツールにおいて，使用しているのは文字列の総出現頻度だけであるが，重複条件付きドキュメント頻度はプログラム中の構造がより精密に判定できる情報源である．あらたな情報が提供されれば，このようなツールの検出性能が向上することが期待できる．</subsection>
  <section title="まとめ">この論文では，重複条件付きドキュメント頻度の性質を述べたあと，それを前処理で表にする方法を述べた．その経過において，まず，出現場所の集合という概念を示すことで，既存のクラス分けの方法が重複条件付きドキュメント頻度の計数に使えることを述べた．次に，クラスの階層関係を利用して計数できる重複条件付文字列頻度を説明し，それを用いて重複条件付きドキュメント頻度の表を構成できることを述べた．最後に，クラス分けの効果とクラスの階層構造の利用が処理に効果があることを，332,918個のドキュメントをもつコーパスで検証し，ドキュメントの長さをNとするとき，前処理の処理時間がO(NN)であり，表を引く処理がO(N)であることを確かめた．最後に，実行中のプロセスの大きさを調べることでメモリの負荷がO(N)であることを確認した．そして，この方法で10万を越える数のドキュメントについて，任意文字列に対する重複度付きドキュメント頻度の分析を行えたことを報告する．</section>
</root>
