<?xml version="1.0" ?>
<root>
  <title>ベイズ統計の手法を利用した決定リストのルール信頼度推定法</title>
  <author>鶴岡慶雅近山隆</author>
  <jabstract>統計的クラス分類器としての決定リストは，近年自然言語処理における様々な分野でその有効性を示している．決定リストを構成する上で最も重要な問題の一つは，ルールの信頼度の算出法である．決定リストを用いた多くの研究では，最尤推定法と簡単なスムージングにより信頼度を算出しているが，理論的な根拠に欠け推定精度も高くないという問題がある．そこで本論文では，ベイズ学習法を利用してルールの信頼度を算出する手法を示す．さらに，証拠の種類ごとに異なる事前分布を利用することで，より正確な信頼度の推定が可能になり，決定リストの性能が向上することを示す．本手法の有効性を確かめるために，語義曖昧性解消の問題に決定リストを適用して実験を行なった．英語に関してはSenseval-1のデータを用い，日本語に関しては疑似単語を用いた．その結果，ベイズ学習による信頼度推定手法が，ルールの確率値の推定精度を高め，決定リストの分類性能を向上させることを確認した．</jabstract>
  <jkeywords>決定リスト，ベイズ学習，事前分布，語議曖昧性解消</jkeywords>
  <section title="実験 ">提案手法の有効性を確かめるため，決定リストを用いて，英語の語義曖昧性解消と，日本語の疑似単語判定問題に関して実験を行なった．語義曖昧性解消とは，多義語の語義を文脈から判定する問題で，自然言語処理における典型的なクラス分類問題である．また，疑似単語判定とは，複数の単語をシステムの側からは単一の単語にしか見えないようにしておき，どの単語であるのかを文脈から判定させるという問題である．この問題は，人工的な語義曖昧性解消問題ということができる．実験によって評価すべき点は二つある．一つはもちろん，クラス分類の正解率である．従来手法と比べて，正解率が向上するかどうかを評価する．もう一つは，出力する確率値の正確さである．つまり，ルールの確率値が，どの程度正確に推定できているかということである．それを評価するために，「期待正解率」というものを考える．これは，それぞれの分類に用いられたルールの確率値を平均したものである．もし，確率値の推定が理想的に行なわれたとすれば，実際の正解率と，期待正解率はほぼ等しくなるはずである．すなわち，実際の正解率と期待正解率のずれは，確率値の推定の「悪さ」を表すことになる．比較対象とする従来手法は以下の二つである．間引き出現回数が閾値未満の証拠のルールは使用しないようにする手法．ルールの確率値は式（），すなわち最尤推定により算出する．確率値が等しい場合は，出現回数の多いルールを優先する．対数尤度比式（）を用いる手法．文献などで用いられている．この場合，式（）の分母が0になってしまう可能性があるため，頻度の比の式の分母と分子に小さな値を足す．このようにすることで，分母が0になってしまう問題を防げる．また，同じ確率であれば，頻度の高い証拠のルールを優先することとした．</section>
  <section title="はじめに">決定リストとは統計的なクラス分類器である．自然言語処理の多くは，クラス分類問題として捉えることが可能であり，近年，様々な自然言語処理において，決定リストによる手法の有効性が示されている．特に，語義曖昧性解消問題に対しては，語義曖昧性解消システムの性能を競う競技会であるSenseval-1において，決定リストを階層的に拡張した手法が最も良い成績をあげている．クラス分類器としては，分類精度の点だけでいえば，最近ではサポートベクタマシンやアダブーストといった手法が，その性能の高さから注目を集めている．しかし，それらの手法は，学習結果が人間にとってブラックボックスなのに対して，決定リストによる手法では，作成された分類器がif-then形式のルールの並びであるために，人間が容易に理解可能であるというメリットがある．学習した決定リストに人間の手を入れることで，性能を向上させることができるとの報告もある．決定リストを作成する上で最も重要な問題は，ルールの信頼度の算出法である．信頼度を計算するためには，限られた事例から，ルールに関する条件付き確率を計算する必要がある．事例の数が多ければ，確率値を最尤推定法によって頻度の比として推定することにほとんど問題はない．しかし，事例の数が少ない場合，最尤推定法による推定値の誤差は非常に大きくなってしまう．このような問題に対し，決定リストを用いた多くの研究では，事例の数が少ないルールを間引いたり，簡単なスムージングを行なうことによって対処している．しかし，ルールを間引く手法では重要なルールを取りこぼしてしまう危険があり，計算式に適当な数値を足してスムージングを行なう手法では加算する値の設定の理論的な指針がないという問題がある．他方，決定リスト手法の改良として，特徴の種類ごとに異なった信頼度の重み付けを与える手法が提案され，日本語の同音異義語解消の実験によってその有効性が示されている．このことは，特徴の種類によって，ルールの信頼度に最尤推定法では考慮することのできない違いが存在することを示唆している．そこで本論文では，ルールの確率値の推定にベイズ統計の手法を利用する．ベイズ統計では，確率変数に関する推定を行なう際に，学習者の持っている事前知識を活用することができる．そのため，適切な事前知識を利用することができれば，最尤推定よりも正確な推定を行なうことができる．また，上記の，証拠の種類による信頼度の違いも，事前分布の違いとして自然に導入することができる．本論文では，語義曖昧性解消の問題を例にとり，ベイズ学習による信頼度の算出が，決定リストの性能を向上させることを示す．本論文の構成は以下の通りである．2章で決定リストによるクラス分類の手法を説明する．3章で，ベイズ学習による確率値の算出法を示す．4章で，他のルールの確率値を利用して事前分布を構成する方法を示す．5章で，決定リストを語義曖昧性解消問題に適用した実験結果を示す．6章で，まとめを行なう．</section>
  <section title="決定リスト">決定リストとは，クラス分類のためのルールを，その信頼度の高い順に並べたものである．それぞれのルールは，「もし（証拠E_i）ならば，クラスはC_jである」という形式をしている．証拠というのは，判定の手がかりとなる事例の特徴である．例として，英語の多義語plant（A:植物,B:工場）に関してYarowskyが行なった実験での決定リストを表に示す．最上位のルールは，「右隣にlifeという単語があったら，語義はA」という意味，4番目のルールは，「距離2〜10単語以内にmanufacturingという単語があったら，語義はB」という意味である．実際にクラスの分類を行なう際には，その事例に対して適用可能なルールのうち，最も上位のルールを用いて分類が行なわれる．例えば入力文が，であるとすると，適用可能なルールのうち最上位なのは3番目のルールであるから，plantの語義はAだと判定されることになる．このように，決定リストによる手法では，他の多くの機械学習手法と異なり，特徴を単独で利用する．単独でしか利用しないのは一見不利なようであるが，語義曖昧性解消などの，文脈の語彙的な特徴を利用する問題に関しては，単独の証拠が分類の決定的な証拠になることが多いため，決定リストによる手法が有効であるといわれている．本論文で提案する決定リストのルール信頼度の推定手法は，特定の自然言語処理に特化したものではないが，本論文では，決定リストの適用例として，上記のような語義曖昧性解消の問題を取り上げる．ここで，本論文で用いる文脈上の特徴を以下に示す．Windowターゲットから，距離10単語以内に出現する単語Adjacentターゲットの左隣に出現する単語ターゲットの右隣に出現する単語Pairターゲットの左隣にある単語対ターゲットを挟む単語対ターゲットの右隣にある単語対すなわち，文脈情報としての詳細さが異なる三つのタイプの特徴を利用する．文脈情報として最も詳細なのはPairであり，最も粗いのがWindowである．</section>
  <subsection title="ルールの信頼度">決定リストは，事例とその正解ラベルを含む訓練コーパスから作成される．決定リストの作成において最も重要な問題は，それぞれのルールの信頼度の計算法である．文献では，次の式に従って信頼度を計算している．すなわち，証拠E_iのもとでクラス（語義）がAである確率と，同じ証拠E_iのもとでクラスがBである確率との比の対数をとったものである．従来の決定リストを用いた自然言語処理の研究では，ルールの信頼度の算出法として，式（），あるいは，式（）をクラスが3つ以上の場合でも適用できるように変形した次の式，が用いられることが多い．また，対数をとらずに，とする場合もある．ここで，式（）と式（）を見比べてみると，式（）は，式（）に関して単調増加であり，決定リストでは信頼度の大小関係しか問題にならないのだから，後述するスムージングの問題を考慮しなければ，式（）を用いた場合と，式（）を用いた場合では，結果的に作成される決定リストは等価になる．一般にクラス分類器の目標は，分類の正解率を最大にすることであるから，ルールの信頼度としては，そのルールが正解する確率である式（）を用いるのが自然である．また，クラス分類器が，自然言語処理システムの一部を構成している場合，分類の信頼度は確率として出力された方が扱いやすいことが多い．そこで本論文では，ルールの信頼度として式（）を用いることにする．式（）の値は，訓練事例が多ければ，ベルヌーイ試行における最尤推定により，次のように計算することができる．ただし，f(C_A,E_i)は，クラスAに属するターゲットと証拠E_iが同時に出現した回数．f(E_i)は，証拠E_iの出現回数である．ところが，通常は出現回数が少ない証拠も多い．例えば，の場合，信頼度は1/1=1と計算されるが，たった一つの事例しかないのに，その信頼度は100%，すなわち最も信頼度の高いルールだとみなされてしまう．このように，出現回数の少ない事例において，そのままでは統計的に信頼性のある確率値が算出できないことをスパースネスの問題という．そこで本論文では，ベイズ学習の手法を用いてこの問題の解決を試みる．</subsection>
  <section title="ベイズ学習によるルール確率値の推定">いま，求めたいルールの確率値をとする．最尤推定の枠組では，確率モデルの尤度が最大となるようにを決定するが，ベイズ学習の枠組では，を確率変数と考えて，その確率分布を求める問題と考える．本論文では，得られた確率分布を決定リストのルールの信頼度として利用したいのだから，その確率分布からの期待値を計算して利用すればよい．訓練コーパスにおいて，確率を求めたいルールに関する事例がn個あり，そのうちのk個において，そのルールが正しいというデータがあるとする．このデータをyとすると，データyを観測した後のの事後密度は，	p(|y)&amp;=&amp;p()p(y|)p(y)	&amp;=&amp;p()p(y|)_0^1p()p(y|)deqnarrayで与えられる．ここで，事象yはベルヌーイ試行と考えられるから，その確率は二項分布により次のように与えられる．これを式（）に代入して，	p(|y)&amp;=&amp;p()_nC_k^k(1-)^n-k_0^1p()_nC_k^k(1-)^n-kd	&amp;=&amp;p()^k(1-)^n-k_0^1p()^k(1-)^n-kdeqnarrayを得る．ここで，事前分布p()をどのように設定するのか，という問題が浮上する．事前分布は，について学習者が持っている事前知識を表す．ベイズ学習における事前分布の設定方法に関しては，大きく分けて2つのアプローチがある．一つは，できるだけ公平で無知の状態を表すように事前分布を設定する方法である．そのような事前分布としては，一様分布やJeffreysの無情報事前分布などが提案されている．もう一つは，学習者が事前に持っている知識を積極的に表現するような事前分布を設定する方法である．</section>
  <subsection title="一様分布">まず，無知の状態を表す事前分布として，一様分布を用いた場合について説明する．いま，あるルールの確率に関して，事前知識が全くないものと考えると，すべての確率値の事前確率について同じ値とするのが自然である．は[0,1]を定義域とする連続の確率変数であり，p()は密度関数であるから，とすればよい．そうすると，事後分布は次のようになる．p(|y)&amp;=&amp;^k(1-)^n-k_0^1^k(1-)^n-kd	&amp;=&amp;^(k+1)-1(1-)^(n+2)-(k+1)-1_0^1^(k+1)-1(1-)^(n+2)-(k+1)-1deqnarrayこの確率分布は，ベータ分布と呼ばれ，期待値は次式で与えられる．いま，kとnは，それぞれ，f(C_A,E_i)とf(E_i)に対応しているのだから，となる．結論は非常にシンプルである．すなわち，頻度f(C_A,E_i)とf(E_i)をそのまま用いる代わりに，f(C_A,E_i)+1とf(E_i)+2を用いればよい，ということである．</subsection>
  <section title="事前分布の利用による確率値の正確な推定">前章では，ベイズ学習において事前情報が全くないものとし，事前分布を一様分布として事後分布の導出を行なった．しかし，章で述べる実験結果から明らかなように，実際の正解率と，ベイズ学習による確率から計算された期待正解率との間には開きがある．これは，推定された確率が真の確率からずれていることを示している．この原因には，以下の3つが考えられる．トレーニングデータvs.テストデータもし，学習のためのトレーニングデータと，テストデータの性質が異なっている場合，実際の正解率は低下する．これは，コーパスベースの手法の本質的な問題である．Globalvs.history-conditional決定リストにおいて，あるルールが適用されるということは，そのルールより上位のルールが，その文脈に適用できなかったことを示している．したがって，確率値はその条件を反映したものでなければならない．ところが，式（）では，そのような条件を考慮せず，単に事例全体の中での確率しか考慮していない．そのような条件を考慮した確率値を算出するためには，決定木を構成するように，決定リストにルールを追加するたびに，それに適合する事例を削除していく，というようなことをする必要がある．しかし，そのようにすると，下位にいくにしたがって事例の数が少なくなっていくため，確率値の推定誤差が大きくなってしまうことや，計算量が事例数の2乗に比例するようになってしまうという問題がある．文献では，ルールの確率値を，上記の２つの確率，すなわち事例全体の中での確率と，上位のルールにマッチしなかったという条件付き確率との重み付き平均をとることによって計算している．事前分布前章では，事前分布を一様分布と仮定した．しかし，例えば，分類すべきクラスの数が5個あり，学習者が全く情報を持たないとすれば，特定のクラスを出力するルールが正解する確率の事前分布としては0.2を期待値とするような分布であるべきであろう．しかし，一様分布の期待値は0.5である．この例からもわかるように，一様分布はどんな場合でも適切な事前分布というわけではない．上記の三つの問題に対して，最初の二つの問題については本論文では扱わない．本章では，他のルールの確率値を利用して適切な事前分布を設定する手法を提案する．事前分布とは，に関するデータがない段階で仮定される，がとる値の確率分布である．いま，は，あるルールの確率を表しているが，ここでを単独で考えるのではなく，は，同じ証拠タイプ内の他の多くのルールの確率値と同じような性質を持っていると考えることにする．つまり，あるルールの事前分布を，他のルールの確率値を利用して構成するまず，ルールの確率値の分布がどのような性格を持っているのかを見るために，実際のルールの確率値の分布の例を図に示す．これは，章の実験で用いられた多義語accidentにおいて，それぞれの証拠のタイプに属するルールの確率値の，正規化されたヒストグラムを示したものである（グラフ中の曲線については後述する）．ただし，各々のルールの確率値は，事前分布を一様分布としたベイズ学習により算出し，出現回数が10回未満のルールは除いている．ここで，ルールの確率値の統計的性質は，そのルールの証拠の事例数に依存しないと仮定すれば，図に示したような，事例の数が多いルールの実際の確率値の分布を利用して，事前分布を構成することができる．事前分布の確率分布としては，ベータ分布を採用する．ベータ分布は，ベルヌーイ試行において自然共役事前分布と呼ばれる確率分布であり，事後分布の導出が解析的に可能であることが知られている．ベータ分布は，2つのパラメータによって決定されるが，本論文では最も簡単なパラメータ推定法の一つであるモーメント法によってパラメータを決定する．モーメント法とは，母集団j次モーメントと，標本j次モーメントがそれぞれ等しいと置いた連立方程式を得くことでパラメータa,bを計算する方法である．図のグラフ中の曲線は，ヒストグラムで示した確率値のデータから，モーメント法によって得たベータ分布を表している．以下に事前分布をベータ分布とした場合の，事後分布の導出の過程を示す．まず，ベータ分布は次の式で与えられる．ただし，B(a,b)はベータ関数である．ベータ分布の1次モーメントは，2次モーメントは，で与えられるから，同じタイプの証拠に属し，出現頻度が閾値（本論文では10とした）以上のルールの確率値の，1次モーメント，2次モーメントをそれぞれ_1,_2とすれば，ベータ分布の2つのパラメータは，a&amp;=&amp;_1(_1-_2)_2-_1^2&amp;=&amp;(_1-_2)(1-_1)_2-_1^2eqnarrayと指定すればよい．この事前分布を式（）に代入することにより，事後分布は次のようになる．事後分布の期待値，すなわちルールの信頼度は次のように得られる．このように，信頼度は最終的に加算スムージングのような形式で得られることから，信頼度の計算自体は非常に簡単に行なうことができる．</section>
  <subsection title="Senseval-1データセットによる実験">英語の語義曖昧性解消については，語義曖昧性解消の競技会であるSenseval-1のデータセットが公開されているので，それを利用して実験を行なった.Senseval-1データセットには，訓練データが利用可能な多義語が36個含まれている．表に，それぞれの多義語の語義数，訓練事例数，テスト事例数を示す．（品詞がpとは品詞情報が判定システムに与えられないことを示す）flushrighttable*本実験では，品詞タグ付けなどの前処理は行わず，生のテキストデータを利用して決定リストの学習と評価を行なった．従来手法に関しては，最も良い場合と比較するため，間引きの閾値を変化させて，最も正解率が高くなる値を採用した．本データセットに関しては，最も良い閾値は2であった．また，対数尤度比でのスムージングのパラメータに関しても0.1きざみで変化させ，最も正解率が高くなる値を採用した．本データセットに関しては，最も良いは0.9であった．表に結果を示す．表中の数字は正解率を表している．正解率の右側にある括弧内の数字は，先に述べた「期待正解率」との差の絶対値を表している．この値が小さいほど，確率値の推定が正確であることを示している．（括弧内の数字は正解率と期待正解率との差）flushrighttable*まず，正解率に関して見ると，間引きの正解率が最も低い．これは，間引きによって重要なルールを捨ててしまっていることが原因だと考えられる．対数尤度比による手法と，事前分布を一様分布としてベイズ学習による手法が，ほぼ同じ正解率である．ただし，ここで注意するべきなのは，対数尤度比による手法では，スムージングのパラメータに関して，正解率が最もよくなるようにチューニングがなされたうえでの結果だということである．事前分布を一様分布としたベイズ学習による手法は，そのようなチューニングを全く必要としないにもかかわらず，それとほぼ同じ正解率を達成している．また，期待正解率と実際の正解率とのずれに関しても，最尤推定（間引き）に比べてかなり小さく，ベイズ学習による推定の有効性を示している．最も正解率が高いのは，他のルールの確率値を利用してベータ分布によって事前分布を構成する手法である．これは，適切な事前分布によって，ルールの確率値の推定が正確になり，本当に信頼できるルールが上位に位置するようになったからだと考えられる．そのことを裏付けるように，実際の正解率と期待正解率のずれが，一様分布の場合と比較して半減している．つまり，確率値の推定がそれだけ正確になったということを示している．</subsection>
  <subsection title="日本語の疑似単語判定の実験">日本語の語義曖昧性解消に関しては，Senseval-1のようなデータセットが公開されていないことから，疑似単語を用いて実験を行なった．疑似単語とは，複数の異なる単語を判定システムの側からは同一の単語にしか見えないようにし，文脈からどの単語であるのかを判定させる手法である．例えば，「銀行」という単語と，「土手」という単語を用いて疑似単語を作ったとすると，判定システムからは，入力文は例えば，のように見える．＊＊の部分が疑似単語である．そして，文脈から，「銀行」であるのか「土手」であるのかを判定させるというわけである．これは，文脈から多義語の語義の判定を行う多義性解消の問題とかなり似た問題になる．実験に用いる疑似単語に関しては，ベースラインとしての正解率（単純に最も出現頻度の高い単語を選ぶ方法の正解率）が高くならないように，一つの疑似単語を構成する各々の単語の出現頻度がほぼ等しくなるようにして構成した．コーパスとしては，「CD-毎日新聞97年版」をJUMANversion3.6で形態素解析したものを用いた．事例の数に関しては，各々の疑似単語について，1024の訓練事例，1000のテスト事例を重なりがないようにコーパスからランダムに抽出して，トレーニングとテストを行なった．（括弧内の数字は正解率と期待正解率との差）flushrighttable*table*従来手法のパラメータに関しては，英語の多義語での実験と同様に，正解率が最も高くなる値を採用した．間引きの閾値に関しては3，対数尤度比のスムージングパラメータに関しては0.4とした．表に結果を示す．傾向は，表に示した英語の多義語での結果とほとんど同じである．最も正解率が悪いのは，間引きによる手法である．一様分布のベイズ学習は，対数尤度比とほぼ同じ正解率を達成している．最も正解率が高いのは，他のルールの確率値を利用してベータ分布によって事前分布を構成する手法である．ここで，事前分布をベータ分布とした場合の，証拠のタイプによる事前分布の違いを見るために，表に事前分布の期待値を示す．この表からわかるように，事前分布の期待値の傾向は，Window&lt;Adjacent&lt;Pairとなっている．すなわち，あるルールに関して何もデータがなければ，そのルールがWindowであるよりもAdjacentである方が，さらに，AdjacentであるよりもPairである方が信頼できるということである．これは，より詳細な文脈情報を用いた方が正確な判断ができるという我々の直感とも一致する．また，これらの事前分布に影響によって，最終的な信頼度も全体として，PairやAdjacentのルールが上位に位置することになる．</subsection>
  <section title="おわりに">本論文では，統計的クラス分類器である決定リストに対して，二つの改善方法を示した．ベイズ学習によるルール確率値の推定決定リストを作成するにあたって最も重要なことは，ルールの信頼度をどのようにして計算するかということである．本論文では，ベイズ学習の手法を用いることにより，理論的な裏付けのあるスムージングによる計算が可能なことを示した．証拠の種類ごとに事前分布を設定することによる精度向上証拠の種類ごとに，他のルールの確率値を利用して事前分布を構成することによって，より正確な確率値の推定ができることを示した．また，その結果，決定リストにおいて，より信頼性の高いルールが上位に位置するようになり，決定リストの分類性能が向上することを示した．本論文では，ベイズ学習の枠組で証拠の種類ごとに異なった確率値を算出することで，決定リストの性能を向上させることができることを示した．このように，証拠のタイプごとに信頼度の値を変えることで決定リストの性能向上を図った研究として，がある．この研究では，決定リストによる同音異義語判別において，複合語からの証拠に重みを付けることで，分類精度の向上を図っている．そこでは，決定リストの信頼度として，式（）を用い，複合語からの証拠には，信頼度に重み付けのための係数を掛けることで，複合語からの証拠を用いたルールを優先させている．本論文では，証拠の種類ごとに対する異なった重みづけをベイズ推定の枠組における事前分布を使用して行なったと考えることができる．本手法の利点は，どの種類の証拠にどの程度重み付けをするのかを，言語学的な直観に頼ることなく，実際のルールの確率値の分布から事前分布を構成することによって自動的に決定できるという点であるといえる．また，本論文で提案した手法は，決定リストの分類性能を向上させるだけでなく，出力する確率値の推定精度も向上させる．クラス分類器は，大きな自然言語処理システムの構成要素として用いられることも多い．その場合，各構成要素であるクラス分類器の出力は，その後の処理に利用されることになるが，出力された信頼度自体が不正確では，それらを利用する後の処理の性能を低下させる恐れがある．したがって，分類性能だけでなく，分類器の出力確率の精度も向上させる本手法は，そのような場合にさらに有効になる可能性があるだろう．本論文では，似たような性質を持つ他の多くの確率値を利用することで，少ない事例から計算される確率値の精度を高められることを示した．この手法は同様の性質をもつ他の統計的手法に適用できると考えられる．例えば，最大エントロピー法では素性の確率を求める必要がある．最大エントロピー法を利用した多くの研究では，素性の確率値を最尤推定法によって求めているが，その場合，本論文で指摘したような確率値の推定誤差の問題がある．実際には，事例の数が少ない素性を使用しないようにすることが多いためにその問題が顕在化することは少ないが，本論文で示した手法によって，事例の数が少ない素性も利用することで最終的な性能向上につながる可能性もあり，興味深い課題といえる．document</section>
</root>
