<?xml version="1.0" ?>
<root>
  <title>最大エントロピー法を用いた対訳単語対の抽出</title>
  <author>佐藤健吾斎藤博昭</author>
  <jabstract>機械翻訳などの多言語間自然言語処理で用いられる対訳辞書は現在，人手によって作成されることが多い．しかし，人手による作成には一貫性・網羅性などの点で限界があることから対訳コーパスから自動的に対訳辞書を作成しようとする研究が近年盛んに行われている．本論文では，最大エントロピー法を用いて対訳コーパス上に対訳関係の確率モデルを推定し，自動的に対訳単語対を抽出する手法を提案する．素性関数として共起情報を用いるモデルと品詞情報を用いるモデルを定義した．共起情報により対訳関係にある単語の意味を制約し，品詞情報により対訳関係にある単語の品詞を制約する．本手法の有効性を示すために日英対訳コーパスを用いた対訳単語対の抽出実験を行い，本論文で提案した手法が従来の手法よりも精度・再現率において優れた結果となり，また，テストコーパスによる実験では学習コーパスに出現しなかった単語対に関しても学習データに現れたものとほぼ同等の精度・再現率で抽出できることを示した．</jabstract>
  <jkeywords>対訳辞書，機械翻訳，最大エントロピー法</jkeywords>
  <section title="はじめに">機械翻訳などの多言語間システムの構築において対訳辞書は必要不可欠であり，その品質がシステム全体の性能を左右する．これらに用いられる対訳辞書は現在，人手によって作成されることが多い．しかし，人手による作成には限界があり，品質を向上するためには膨大な労力が必要であること，辞書の記述の一貫性を保つことが困難であることが問題となる．このことからコーパスから自動的に対訳辞書を作成しようとする研究が近年盛んに行われている．本論文では，最大エントロピー法を用いて対訳コーパス上に対訳単語対の確率モデルを推定し，自動的に対訳単語対を抽出する手法を提案する．本論文では対訳関係にある単語の組を対訳単語対と呼ぶ．最大エントロピー法は，与えられた制約の中でエントロピーを最大化するようなモデルを推定するという最大エントロピー原理に基づいており，未知データに対しても確率値をなるべく一様に配分するため，自然言語処理においてしばしば問題となるデータスパースネスに比較的強いという特徴を持っている．このため，構文解析，文境界の同定，動詞の下位範疇化モデルなどに応用されている．また我々の手法は，既存の対訳辞書を必要とせず，文対応の付いた対訳コーパスさえあれば，対訳コーパスの分野を限定することなく対訳単語対を抽出できるという特徴を持つ．本論文の構成は以下の通りである．節では最大エントロピー法について説明し，節では最大エントロピー法を用いて対訳単語対を抽出する手法を述べる．節では我々が提案した手法の有効性を示すために行った実験の結果とそれに対する考察を述べ，関連研究との比較を行う．節でまとめを述べる．</section>
  <section title="最大エントロピー法">一般に確率モデルは，履歴とその時の出力の関係を既知のデータから推定される確率分布によって表す．この際，履歴の種類を多くすればより正確に出力を予測することができるが，履歴の種類を多くしすぎるとそれぞれの履歴における既知データの数が少なくなり，データスパースネスに陥ってしまう．最大エントロピー法では履歴と出力の関係を素性関数で表し，それぞれの素性関数に関して既知データにおける確率分布の期待値と推定すべき確率分布の期待値が等しくなるという制約のもとで，確率分布のエントロピーが最大となるようなモデルを推定する．この操作は，既知データにおいて出現しなかったもの，あるいは稀であったものに対しても一様分布に近づいていくということを意味しており，このため最大エントロピー法はデータスパースネスに対して比較的強いとされている．この性質は，言語モデルのように既知データにおいて全ての事象を扱うことが難しい現象を扱うのに適したものであると言える．最大エントロピー法では，以下のように確率分布を推定する．Xを履歴の集合，Yを出力の集合とする時，既知データの集合(x_i,y_i)|x_iX,y_iYから確率分布P(y|x)を推定することを考える．まず，求めたい確率モデルの統計的特性(素性)によって集合XYを二つの集合に分割する2値関数f:XY0,1を定義する．このような関数は素性関数と呼ばれる．この時，既知データにおける確率分布P(x,y)に関するfの期待値と推定すべき確率分布P(y|x)に関するfの期待値が等しくなるという制約を与える．計算量の観点から右辺のP(x)の代わりにP(x)で近似することが多い．ここで，P(x,y),P(x)は既知データにおける(x,y),xの出現頻度c(x,y),c(x)から得られる相対頻度を用いる．[P(x,y)=c(x,y)_v,wc(v,w)][P(x)=c(x)_vc(v)]モデル化の過程において重要であると思われるn個の素性関数f_iがある時，すべてのf_iについて式()を満たすような確率分布は一般的には複数存在するため，これらの中から最も一様な確率分布を選択するのが自然である．条件付き確率分布P(y|x)の一様性の数学的な尺度としては条件付きエントロピーがよく用いられ，これを最大とする確率分布が求めるべき確率分布となる．このような確率分布は唯一存在し，以下のような_iをパラメータとする形式で表すことができる．P_(y|x)=1Z_(x)(_i_if_i(x,y))Z_(x)=_y(_i_if_i(x,y))eqnarrayパラメータ_iの推定にはImprovedIterativeScalingアルゴリズムなどが用いられる．</section>
  <section title="最大エントロピー法による対訳単語対の抽出">本節では，最大エントロピー法を対訳単語対の抽出に適用する手法を述べる．まず，確率分布の事象の定義を行い，次に対訳単語対の確率分布を推定する際に用いる素性関数を定義する．最後に，得られた確率分布を用いて対訳単語対を抽出する手法を述べる．</section>
  <subsection title="事象の定義">原言語のコーパスX,目的言語のコーパスYが対訳となっており，それらの間で単語間の対訳関係が観測されたとする．この時，観測値から得られる同時出現確率は以下の式で表される．ここでc(x,y)は単語xとyが対訳関係で出現した回数である．しかし実際には対訳コーパスから単語間の対訳関係を計数することは膨大な労力が必要であるため，文対応があらかじめ付いている対訳コーパスを用いた場合は対訳文の単語数に応じて出現回数を均等に割り振り，式()のように出現回数を近似する．ここで，X_iは原言語のコーパスXのi番目の文，Y_iは目的言語のコーパスYのi番目の文を表す．すなわちX_iとY_iは対訳関係にあるものとする．また，|X_i|,|Y_i|はそれぞれX_i,Y_iの文中に含まれる単語数を表し，c'_i(x,y)はi番目の文においてxとyが出現した回数である．このようにして観測値から得られたP(x,y)から，原言語の中にxが出現した時に目的言語においてxがyに翻訳される確率P(y|x)を推定する．</subsection>
  <subsection title="素性関数の定義">どのような素性関数を定義するかという問題は最大エントロピー法によるモデル化において最も重要である．本論文では以下の4種類のモデルの素性関数を定義した．</subsection>
  <subsubsection title="対訳文中に現れる単語対の情報を用いた素性関数 (素性タイ  プ 1)">対訳コーパスにおいて対応する文で出現したことのある単語対x,yは対訳関係にある可能性がある．これを確率モデルに反映させるために以下のような素性関数を定義する．</subsubsection>
  <subsubsection title="原言語における共起情報を用いた素性関数 (素性タイプ 2)">一般に，単語はそれと共起する単語によってある程度意味を限定することができる．このことを利用し，原言語のコーパスXにおける単語の共起情報を用いて素性関数を定義する．ただしW(d,w)はコーパス中でwXからd語以内に出現する単語の集合である．今回の実験ではd=5とした．f_w(x,y)はxがyに翻訳されることに対してxと共起関係にあるwが予測力を持っているかどうかということを表す(図)．</subsubsection>
  <subsubsection title="原言語と目的言語における共起情報を用いた素性関数 (素性  タイプ 3)">節で述べた素性関数に目的言語のコーパスYにおける共起情報を付け加えたものを定義する．f_w,v(x,y)はxがyに翻訳されることに対してxと共起関係にあるwとyと共起関係にあるvが予測力を持っているかどうかということを表す(図)．</subsubsection>
  <subsubsection title="品詞情報を用いた素性関数 (素性タイプ 4)">対訳文において対訳関係にある単語同士は同じような形態素的意味を持つ品詞であることが望ましい．しかし，それぞれの言語における形態素解析器の品詞タグセットが全く同じであることは稀である．そこで本論文では各言語の形態素解析器が出力する品詞タグ情報をそのまま使用し，その組み合わせで素性関数を定義する．ここでPOS(x)は言語Xにおける単語xの品詞タグ，POS(y)は言語Yにおける単語yの品詞タグである．f_t,s(x,y)はxがyに翻訳されることに対してxに割り当てられた品詞tとyに割り当てられた品詞sが予測力を持っているかどうかということを表す(図)．</subsubsection>
  <subsection title="対訳単語対の抽出アルゴリズム">本節では，前節までに述べた手法によって得られた確率モデルを用いて対訳単語対を抽出する手法を述べる．本手法では1単語対1単語の対訳関係を仮定し，CompetitiveLinkingAlgorithmと類似した抽出アルゴリズムを採用する．閾値th[0,1]を決める．すべての(x,y)XYについてP(y|x)を計算し，P(y|x)thとなる(x,y)をリストに保持する．リストをP(y|x)について降順にソートする．P(y|x)が最大となる(すなわちリストの先頭にある)(x',y')を対訳単語対として抽出する．本手法では1単語対1単語の対訳関係を仮定しているので，x'やy'を含む単語対は二度と抽出されない．したがって(x',v)|vYや(w,y')|wXに含まれるような単語対をリストから削除する．抽出すべき単語対がまだ存在すれば4.へ戻る．</subsection>
  <section title="実験と考察">本節では本論文で述べた手法による実験結果を示し，それに対する考察を述べる．最後に関連研究との比較を行う．</section>
  <subsection title="実験結果">本論文でここまで述べた手法を用いて英語日本語間の対訳単語対を抽出する実験を行った．今回の実験では対訳コーパスとして通産省電子技術総合研究所において電子化された講談社和英辞典に含まれる例文のうち30,287文を用い，原言語のコーパスXとして英語文，目的言語のコーパスYとして日本語文を使用した．そのうち，学習コーパスとして27,258文，テストコーパスとして3,029文を用いた．日英対訳例文に対して日本語文は茶筌，英語文はBrillTaggerを用いて形態素解析を行った．助詞，助動詞などの機能語，出現回数が極めて多い単語(出現回数1,000回以上)，出現回数が極めて少ない単語(出現回数3回以下)を推定から除外した．その結果今回の実験の対象となる単語の語彙数は表の通りとなった．学習コーパス中で観測された素性の総数はおよそ4,350万個であった．そのうち確率モデルの推定には学習コーパスで5回以上観測された素性12,368個を用いた．表にその内訳を示す．これらの素性を用いて最大エントロピー法により対訳単語対の確率分布の推定を行った．その際のパラメータ推定にはImprovedIterativeScalingを採用し，その反復回数は400回に設定した．表に本手法による対訳単語対抽出の実験結果を示す．対訳単語対の抽出の際に用いる閾値thは0.5からはじめ，0.1刻みに0.1まで下げた．閾値の段階別に対訳単語対として抽出された総抽出数，そのうちの正解数，精度(=正解数/総抽出数)，再現率(=正解数/日本語語彙数)を記す．対訳単語対が正解であるかどうかは既存の辞書を用いて人手により判定した．表の左側は学習コーパスにおける抽出結果である．右側は学習コーパスで学習したパラメータを使用してテストコーパスに対して抽出アルゴリズムを適用したときの結果である．表に本手法による対訳単語対抽出の実験によって抽出された対訳単語対の正解例を示す．</subsection>
  <subsection title="未知語と解析精度">本論文で提案した手法によるテストコーパスにおける抽出実験において，テストコーパスにのみ現れた未知の日本語単語と学習コーパスにも現れた日本語単語に分けて精度と再現率を計算した結果を表に示す．抽出アルゴリズムにおける閾値thは0.1を用いた．未知語の場合でも，既知の単語とほぼ同等の精度と再現率が得られることが分かる．最大エントロピー法では履歴と出力の関係を素性で表すため，学習データにおいて現れなかった事象でも素性さえ観測できれば確率値を計算することができる．したがって，学習コーパスに特化しない素性を用いてパラメータ推定を行い，その結果を使って対訳単語対の抽出を行えばテストコーパスにおいてもほぼ同等の抽出結果を得ることができるということをこの結果は示している．</subsection>
  <subsection title="抽出誤りについて">学習コーパスでの対訳単語対の抽出結果において誤りとなったものから無作為に100個を選び，それぞれについて誤りとなった原因を調べた．抽出アルゴリズムにおける閾値thは0.1を用いた．以下は誤った単語対の英単語側に着目した時の誤った原因の内訳である．訳語が抽出対象コーパスに一回も出現しない10個訳語が抽出対象コーパスには存在するが，抽出対象には含まれない49個形態素の区切りが異なる15個形態素解析誤り4個その他22個1.はある英単語に対応する日本語単語が抽出対象コーパス中に一回も出現していない場合である．対訳文を見ると，以下のようないわゆる「意訳」に近いものであったり慣用句的な表現であった．flushleftこの例の場合では``driver''の訳として``運転手''あるいは``ドライバー''を推定するためには意味解析などのより高度な解析が必要になることから，現時点ではこのような対訳文だけから正しい対訳単語対を抽出することは難しいと思われる．2.はある英単語に対応する日本語単語が抽出対象コーパス中には出現するが，出現回数の制限により抽出対象である6,796語に含まれない場合である．対訳文を見ると，日本語単語の表記の揺れにより出現回数が分散してしまうことが原因であった．例えば``solemnly''の訳語候補として``厳粛に'',``粛々と'',``荘厳に''のように複数の正しい訳語が対訳文中に現れているが，出現回数がそれぞれに分散し出現回数の閾値の下限を下回り実験対象に含まれない．これに対しては，日本語のシソーラスを利用して複数の訳語を同一視することで抽出が可能になると思われる．3.は英単語と日本語単語の形態素の区切りが異なる場合である．``shoulder''に対する訳語は``肩''となるべきであるが，日本語コーパスの形態素解析の結果には``肩''という単語は含まれていなかったため，``右肩''という単語が出力される結果となった．本手法が1単語対1単語の対訳関係を仮定していることが原因であると考えられる．では統計情報から得られる連語や係り受け解析結果から得られる文節を単位として対訳関係を推定することにより精度を上げており，統計的意味的にまとまりのある単位で対応付けを行う方が良いことを示している．対訳文においては，形態素単位では対応が取れない場合であっても統計的意味的にまとまりのある単位では対応が取れることが多いと考えられる．したがって本手法でも，単語単位でなく連語や文節を単位として推定を行うことで精度が向上すると思われる．</subsection>
  <subsection title="素性と解析精度">表に，それぞれの素性を削除したことによる精度と再現率の増減を示した．括弧内は素性一個あたりの増減である．抽出アルゴリズムにおける閾値thは0.1を用いた．素性一個あたりでもっとも抽出結果に影響していると考えられるのは，品詞情報を用いた素性関数(素性タイプ4)であることがこの表からわかる．このことは翻訳候補を選択する際には品詞情報が重要であるという直感的な判断と合致する．逆にもっとも影響していないと考えられるのは，対訳文中に現れる単語対のみを用いた素性(素性タイプ1)である．他の素性は共起情報や品詞情報によって単語対に対して制約を与えているのに対して，タイプ1の素性は対訳文中に現れたことがあるかどうかということのみを扱うため，翻訳候補を選択するには制約が弱いと考えられる．このことから，係り受け情報やシソーラスの情報などによる制約を素性として表し，それらを加えていくことにより抽出結果の改善を期待することができる．ただし，必要以上に素性を増やしていくことは過学習の危険があるので注意が必要である．</subsection>
  <subsection title="関連研究との比較">本手法と同様に対訳文の文対応が既に付いていることを前提にしている研究にはがあげられる．は単語対の対応度として^2統計を用い，相互情報量より有用であることを示している．はDice係数に対して単語対の出現頻度の対数で重み付けする重み付きDice係数を提案し，これを単語対の対応度として採用した．はCompetitiveLinkingAlgorithmと2つのパラメータに対する山登り法を組み合わせて単語対の対応度を求める手法を提案した．これらの研究に共通する特徴は，単語対の対応度の計算手法において単語対の共起頻度がベースになっているために未知語に弱いということである．学習コーパスと異なるコーパスでは未知語が出現するために単語対の対応度を計算することは不可能となり，対訳単語対を抽出するためには新たに学習しなおさなければならない．これに対して本論文で提案している手法では節で述べたように，注目している単語対の前後の文脈や品詞情報を用いた素性を用いているため，未知語の場合にも既知の単語と同様に対応度の計算を行うことができる．本手法と異なり，対訳文の文対応が付いていることを前提としない代わりに，既存の対訳辞書を用いている研究にはがあげられる．これらの手法は一方の言語で共起する単語の訳語は他方の言語でも共起することを仮定している．では既存の辞書に含まれる単語との共起集合間の共通部分の大きさで対応度を計算している．では既存の辞書に含まれる単語との重み付き相互情報量を要素とするベクトルを計算し，その内積を対応度として採用している．現状では文対応の付いた対訳コーパスはあまり多くないため，文対応を前提としないこれらの手法は適用できる範囲は広いが，文対応が付いたコーパスを用いた手法よりも精度が劣る．一方，本手法の前提となっている文対応済の対訳コーパスは，原文に忠実に翻訳した対訳コーパスであれば，で提案されている手法により作成することができる．対応する文がなかったり，1つの文が複数の文に対応している場合には人手による後編集が必要になるが，その労力は全て人手による対応付けに比べて比較にならないほど少ないと考えられる．学習コーパスを用いて相対頻度(y|x)=c(x,y)_vYc(x,v)]と計算し，抽出アルゴリズムにおいてP(y|x)の代わりにP(y|x)を使用して対訳単語対の抽出を行った．と重み付きDice係数f_X(x)+f_Y(y)]ここでf(x,y)はxとyが対訳文中に出現した回数，f_X(x),f_Y(y)はそれぞれコーパスX,Y内でx,yが出現した回数である．抽出アルゴリズムにおいてP(y|x)の代わりにsim(x,y)を使用して対訳単語対の抽出を行った．で使用されている対訳単語対抽出アルゴリズムは本論文で示した手法とは異なるが，比較のために本論文で示した手法と同じ抽出アルゴリズムを用いた．による比較実験を行った．図は，抽出アルゴリズムの閾値を徐々に下げていきながら対訳単語対を抽出した時の，抽出された対訳単語対100個ごとの精度(左)と再現率(右)を示したグラフである．重み付きDice係数は単語対の共起回数が2回以下の場合は対応度が0になってしまうため，2,700個までしか抽出することができなかった．このグラフを見ると大体の場合において本手法がもっとも良い結果となっていることがわかる．相対頻度による抽出は本手法や重み付きDice係数に比べて悪い結果となっている．対訳単語対(x,y)について考えた時，xとよく共起する単語x'が存在すると(x',y)の対応度も高くなり(x',y)が抽出されてしまう誤りが多く見られ，これが原因であると考えられる．この問題に対して，重み付きDice係数による抽出では単語対の出現回数の対数によって重み付けし，(x,y)と(x',y)の対応度の差をより広げることによって対処している．本論文で提案した手法では，共起情報や品詞情報を素性として用いてより多くの制約を与えることによりこの問題による誤りを減少させていると考えられる．</subsection>
  <section title="おわりに">本論文では，最大エントロピー法を用いて対訳コーパス上の対訳単語対の確率モデルを推定し，自動的にこれを抽出する手法を提案した．素性関数として共起情報を用いるモデルと品詞情報を用いるモデルを定義した．本手法の有効性を示すために日英対訳コーパスを用いた対訳単語対の抽出実験を行い，本論文で提案した手法が相対頻度や重み付きDice係数による手法よりも精度・再現率において優れた結果となった．また，テストコーパスによる実験では学習コーパスに出現しなかった単語対に関しても学習データに現れたものとほぼ同等の精度・再現率で抽出できることが分かった．しかし，対訳コーパス中に現れる意訳，単語の表記の揺れ，2言語間の形態素の分かち方の違いに対しては有効ではない．これらを克服するために，連語や係り受け解析結果から得られる文節を単位としたりシソーラスを利用して対訳関係を抽出することが今後の課題である．</section>
</root>
