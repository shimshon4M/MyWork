\documentstyle[jnlpbbl]{jnlp_j_b5}

\setcounter{page}{97}
\setcounter{巻数}{9}
\setcounter{号数}{4}
\setcounter{年}{2002}
\setcounter{月}{7}
\受付{2001}{9}{28}
\再受付{2001}{12}{21}
\採録{2002}{4}{5}

\setcounter{secnumdepth}{2}

\title{テキスト自動要約に関する最近の話題}
\author{奥村 学\affiref{TITech} \and 難波 英嗣\affiref{TITech}}

\headauthor{奥村，難波}
\headtitle{テキスト自動要約に関する最近の話題}

\affilabel{TITech}{東京工業大学精密工学研究所}
{Precision and Intelligence Laboratory, Tokyo Institute of Technology}

\jabstract{　
本稿では，1999年の解説の後を受
け，テキスト自動要約に関する，その後の研究動向を概観する．
本稿では，その後の動向として，特に最近注目を集めている，以下の3つの話
題を中心に紹介する．
\begin{enumerate}
 \item 単一テキストを対象にした要約における，より自然な要約作成に向け
 ての動き，
 \item 複数テキストを対象にした要約研究のさらなる活発化，
 \item 要約研究における，要約対象の幅の広がり
\end{enumerate}
}

\jkeywords{テキスト自動要約，首尾一貫性，読み易さ，冗長性，自由作成要
約，テキストのジャンル，要約の書き換え，要約の言語モデル，複数テキスト
要約，話し言葉の要約}

\etitle{New Topics on Automated Text Summarization}
\eauthor{Manabu Okumura\affiref{TITech} \and Hidetsugu Nanba\affiref{TITech}}

\eabstract{　
In this article, we try to survey the current trends in the field of
automated text summarization, especially concentrating on the
following three topics: researches on producing more natural summaries
in single document summarization, farther activation of researches on
multi-document summarization, and more variety of summarization inputs
in the researches.
}

\ekeywords{automated text summarization, coherence, readability,
redundancy, human-written summaries, genre of texts, revision,
language modeling, multi-document summarization, speech summarization}

\begin{document}
\maketitle

\section{はじめに}

電子化されたテキストが世の中に満ち溢れる現状から，テキスト自動要約研究
が急速に活発になり，数年が早くも経過している．研究の活発さは依然変わら
ず，昨年もNAACLに併設する形で要約に関するワークショップが6月に開催され
た．また，日本では，国立情報学研究所の主催する評価型ワークショップNTCIR-2
のサブタスクの1つとしてテキスト自動要約(TSC: Text Summarization
Challenge)が企画され，日本語テキストの要約に関する初めての評価として，
また，TipsterにおけるSUMMACに続く要約の評価として関心を集め，昨年3月にその
第1回(TSC1)の成果報告会が開催された
(http://research.nii.ac.jp/ntcir/index-ja.html)．一方，アメリカでは，
SUMMACに続く評価プログラムとして，DUC(Document Understanding
Conference)が始まり，第1回の本格的な評価が昨年夏行なわれ，9月に開催さ
れたSIGIRに併設する形でワークショップが開催された
(http://www-nlpir.nist.gov/projects/duc/)．

このような背景の元，本稿では，1999年の解説\cite{okumura:99:a}の後を受
け，テキスト自動要約に関する，その後の研究動向を概観する．
1999年の解説では，これまでのテキスト自動要約手法として，重要文(段落)抽
出を中心に解説するとともに，当時自動要約に関する研究で注目を集めつつあっ
た，いくつかの話題として，「抽象化，言い換えによる要約」，「ユーザ
に適応した要約」，「複数テキストを対象にした要約」，「文中の重要個所抽
出による要約」，「要約の表示方法」について述べている．
本稿では，その後の動向として，特に最近注目を集めている，以下の3つの話
題を中心に紹介する．
\begin{enumerate}
 \item 単一テキストを対象にした要約における，より自然な要約作成に向け
 ての動き，
 \item 複数テキストを対象にした要約研究のさらなる活発化，
 \item 要約研究における，要約対象の幅の広がり
\end{enumerate}
(1)の動きは，後述するように，1999年の解説における「抽象化，言い換えに
よる要約」，「文中の重要個所抽出による要約」という話題の延長線上にある
と言うことができる．以下，2, 3, 4節でそれぞれの話題について述べる．

なお，TSC1およびDUC2001にはそれぞれ多数の参加があ
り，興味深い研究も多い．しかし，TSC1の多くの研究は重要文抽出に基づくも
のであり，本稿に含めるのは適当でないと考えた．また，DUC2001に関しては，
ワークショップが開催されたのが9月13, 14日であり，本稿に含めるのは時間
的余裕がなく断念せざるを得なかった．これらについては，稿を改めて，概観
することとしたい．

\section{より自然な要約作成に向けて}

ここ1, 2年テキスト自動要約研究者が関心を持っている話題に，単一テキスト
を対象にした要約において，人間にとってよ
り自然な要約を目指すというものがある．

これまでの要約手法である重要文抽出には，問題点として，テキスト中の色々
な個所から抽出したものを単に集めているため，抽出した複数の文間のつなが
り(首尾一貫性)が悪いことが指摘されている．抽出した文中に指示詞が含ま
れていても，その先行詞が要約中に存在しない可能性があったり，また，不要
な接続詞があったりするということだが，こういうことが起きていると，
読みにくいということはもちろんだが，最悪の場合，要約テキストの内
容を読み間違えてしまう可能性もある．
また，
文を重要として要約に含める際，他の文とは独立に抽出を行なっており，そ
のため，結果として要約中に抽出された文の内容に類似のものがいくつも含まれると
いうことが生じる可能性がある．

このような，これまでの要約手法の問題点を受けて，「より読み易い要約」，
「より冗長性の少ない要約」を目指す動きが近年活発になっており，また，人間
の自由作成要約(human-written summary)を元に要約手法を検討する動きも盛ん
になってきている．

人間が自由に要約を作成する際，原文に基づかず一から要約を「書く」場合もあ
るが，多くの場合，原文を元に，原文の断片を適切に「切り貼り」し，その後そ
れに編集を加えることで，要約を作成しているという観察を元に，そういった人
間の要約作成過程を計算機上にモデル化しようという研究も，後述するように
(2.2節)始
まっている\cite{jing:00:b}．人間の要約作成モデルに基づく要約手法なら，人
間の要約に(ある程度)近い要約を作成できる可能性があり，注目すべ
き研究と言える．

もう一つ特筆すべき研究として，自然言語生成システムを利用した要約手法の提
案も始まっている\cite{mckeown:99:a,barzilay:99:a}．詳細は3節で述べるが，
複数テキスト中の重要個所を，
FUF/SURGEという生成システムにより，つなぎ合わせることで要約として生成し
ている．

要約の過程は，大きくテキストの解釈(文の解析とテキストの解析結果の生成)と
(テキスト解析結果中の重要部分の)要約としての生成に分けられるとされてき
たが，これまでの研究では，要約を生成するということは実際にはほとんど実現
されていなかった．今後，より自然な要約作成を目指す過程で，自然言語生成技
術の利用は不可欠となっていくであろう．

これまでも，要約の読みにくさ，首尾一貫性の悪さに対しては，対処法が提案さ
れてきているが(たとえば，Mathisら\cite{mathis:73:a}や\cite{okumura:99:a}の2.3節を
参照)，いずれもad hocな手法という印象が強い．
これに対して，抽出した重要文集合を書き換える(revise)ことで，文間のつな
がりの悪さを改善し，より読み易い要約作成を目指す研究が最近試みられてい
る\cite{nanba:99:b}．まだ技術的に難しい問題がいろいろあるが，興味深い．

また，重要文抽出ではなく，文中の重要個所抽出，不要個所削除による要約手法
はすでに\cite{okumura:99:a}で紹介されているが，この要約手法も，より自然な
要約を作成するための第一歩と言える．2.4節で紹介する「要約の言語モデル」
は，この要約手法を統計的に定式化した枠組とも考えられる．

以下，各小節で，「より冗長性の少ない要約作成」，「人間の自由作成要約を
元にした要約手法」，「抽出した重要文集合の書き換えによる，より自然な要
約作成」，「要約の言語モデル」の4つの話題について言及する．

\subsection{冗長性の少ない要約に向けて}

複数テキストを対象にした要約では，複数のテキストから抽出した内容を要約とする際，
内容が重複することを避ける手法がとられることが一般的である．単一テキスト
を対象にした要約作成でも，要約中に類似した文が含まれていれば冗長であ
り，冗長性を削減することで，他の有用な情報を要約に加え，要約中の情報の密
度を増すことができる．近年単一テキ
ストの場合にも，要約中の冗長度を下げ，同じ長さの要約に，より多くの情報を
含められるよう考慮した要約手法がいくつか提案されている．

Baldwinら\cite{baldwin:98:a}は，照応解析に基づき，query-sensitiveで
indicative(指示的)な要約を作成する手法を提案している．テキスト中の文を選択するの
だが，検索要求中の句がすべて要約の中にカバーされるように選択する．テキス
ト中の句がその句と相互参照していれば，検索要求中の句はカバーされていると
する．

文を選択する基準は，その文により新たにカバーされる(すでに選択された文
ではカバーされていない)検索要求中の句が多い文を選択する．この文選択を
すべての句がカバーされるまで繰り返す．これにより，要約の冗長性を最小にし
ている．

Baldwinらの手法は，なるべく冗長な参照句を含まないように文を選択している
ことに相当する．また，先行詞を要約中に含まない代名詞は，可能なら先行詞に
置き換える，不要と考えられる，前置詞句，同格の名詞句，関係節は除去するな
どの後処理も施している．

MMR(Maximal Marginal Relevance)\cite{carbonell:97:a,carbonell:98:a}は，
テキスト検索，単一テキスト要約，複数テキスト要約において利用可能な尺度
であり，検索要求との適合度と，情報の新規性(すでに選択されたものとの異
なり度)をともに考慮する尺度である．MMRは，テキスト検索を例にすれば，以
下の式で定義される．
\[ MMR(Q,R,S) = Argmax_{D_i \in R \setminus S} [ \lambda Sim_1(D_i,Q) - \]
\[ (1-\lambda) max_{D_j \in S} Sim_2(D_i,D_j) ] \]
ここで，
\begin{description}
\item[$Q$:] 検索要求，
\item[$R$:] システムによって検索された(ランク付けられた)テキスト群，
\item[$S$:] すでに選択されたRの部分集合
\item[$R \setminus S$:] RとSの差集合
\end{description}
であり, $\lambda$は, 検索要求との適合度($Sim_1(D_i,Q)$)と, すでに選択
されたものとの異なり度\footnote{$max_{D_j \in S} Sim_2(D_i,D_j)$が類似
度を表しているので, それを引くことで, 異なり度としている. }に関する重
みづけ(どちらを重視するか)に関するパラメタである. なお, 検索要求との適
合度, すでに選択されたものとの類似度を計算する尺度$Sim_1, Sim_2$には, 
任意のものが利用できるが, 単語を要素とするベクトル間の距離尺度(たとえ
ば, コサイン, 内積等)を利用することが多い.

MMRを用いた要約では，query-relevantな要約を作成するが，単一テキスト要
約では，検索要求に関連するパッセージ(文)の集合を($Sim_1$のみを利用して) 
まず抽出した後(これが$R$)，それらをMMRで再順序付け，要約の長さまで文を
選択し，原文での順序，MMRのスコアの順序等を元に出力する．したがって, 1 
文目は, 検索要求と最も適合する文が選択され, 2文目以後は, それまでに選
択された文(2文目の場合は, 最初に選択された文)との異なり度も合わせて考
慮して選択される.
MMRを用いることで，要約は互いに(最大限)異なる文により構成される．
MMRを用いた複数テキスト要約は3節で紹介する．

加藤ら\cite{kato:00:a}は，放送ニュースを対象にした重要文抽出法として，ま
ず1文目(リード文)を抽出した後，それ以後の文のうち，リード文と内容が重複
しない文を重要として抽出する手法を提案している．内容の重複は，文間の単語
の対応の度合を元に計算している．この手法は，重要文抽出に，テキスト中での
位置情報とMMRの考え方を併用していると言うことができる．

石ざこら\cite{ishizako:99:a}は，同一の事象を表す表現が複数回テキスト中に
出現した場合，2回目以後の出現を重複部分として削除する手法を提案している． 

\subsection{人間の自由作成要約を目指して}

人間は，単に重要文を抽出するだけでなく，それらを編集することで要約を作
成していると考えられる．Jingら\cite{jing:99:a,jing:00:b}は，人間の自由作
成要約と原文の対応を分析し，抽出された文を編集する6つの操作を同定してい
る．それらは，不要な句の削除(文短縮)，(短縮した)文を他の文と結合する(文
の結合)，構文的変形，句を言い替える(語彙的言い替え)，句をより抽象的/具体 
的な記述に置き換える，抽出した文を並べ替える，の6つである．
一方，人間が原文に基づかず，一から書いている文も自由作成要約には含まれて
おり，その割合は，300要約を調べたところ，19\%であったと報告している．

Jingら\cite{jing:00:b}は，人間の自由作成要約の分析から得られた6つの編集操作を用
いた「切り貼り」に基づく要約手法を提案している．システムは，抽出され
た重要文を編集し，不要な句を削除し，結果として残った句をまとめ上げるこ
とで一貫性のある文を作成する．
Jingらの切り貼りに基づく要約システムは，まず重要文を抽出
した後，抽出した文を，6つの操作で(文短縮，文の結合のみが実装されてい
る)編集し，その結果を要約として出力する．文の結合に関しては，対応コーパ
スを分析し，人手で規則を作成して実現している．文の結合は，2つの構文解析
木に対する，結合，部分木の置換，ノードの追加というTAG上の操作とし
て実装されている．

一方，文短縮は，抽出された重要文から，不要な句を自動的に削除するが，人間
の自由作成要約と原文の対応コーパスから得られた統計情報，構文的知識，
文脈情報を利用して，削除する句を決定している\cite{jing:00:a}．

原文は，構文解析され，構文解析木中の必須要素と考えられる部分は印が付け
られ，後の処理で削除され，文法的でない文が作成されることを防止する．次
に，文中の句で話題ともっとも関連するものを決定する．また，対応コーパス
を構文解析した結果を用いて，どの句がどういう条件でどの程度削除され易い
か(たとえば，主動詞が`give'のとき，`when'節が削除される確率)を計算する．
また，句が短縮される(部分が削除される)確率，句が変化しない確率も合わせ
て計算される．そして，必須でなく，話題とあまり関係がなく，人間が削除し
ている確率がある程度ある句を削除の対象とする．

人間の削除個所との一致度に基づく評価では，平均で81.3\%の精度を得ており，
すべての前置詞句，節，to不定詞，動名詞を削除する場合をbaselineと考える
なら，baselineの精度は43.2\%だった．また，システムは平均で文の長さを
32.7\%短くしていたが，人間の場合は41.8\%だった．システムの出力における
誤りの原因は，50文を分析した結果では，8\%が構文解析誤りによるものだっ
た．

このJingらの研究と同様，(重要文抽出ではなく，)人間が自由に作成した要約の
コーパスに基づいた要約研究が近年数多く見られる．これらの研究では，人間の
自由作成要約と原文を対応付けた(aligned)コーパスが必要であるため，要約と
原文の間の対応づけ(alignment)を行なう手法に関する提案もいくつか見られる．

Jingら\cite{jing:99:a}の対応づけプログラムは，人間の自由作成要約中の句を
原文中の句に自動的に対応付ける．要約中で隣接する2単語は，原文中でも隣接
して現れ易い，遠く離れた文中に現れないというようなヒューリスティックスを
元にしたHMMに基づいており，要約中の各単語が原文中のどこに位置するかを
Viterbiアルゴリズムにより決定する．
50要約中の305文に対する対応関係を人手で調査したところ，93.8\%の文で正
しい対応関係を得ていると報告している．

Marcu\cite{marcu:99:a}は，原文と自由作成要約をともに，出現する単語のベク
トルで表現し，その間の類似度をコサイン距離で計算する．そして，自由作成要
約と類似度がもっとも大きくなるように，原文から節を削除してい
くことで，対応する抜粋を決定している．

Bankoら\cite{banko:99:a}は，文を単位とし，文を文中の単語の出現頻
度のベクトルで表し，ベクトル間の距離で文間の類似度を計ることで，自由作成
要約中の文と原文中の文をもっとも類似度が大きくなるように対応付けている．
BankoらとMarcuの手法はともに，abstractから抜粋(extract)を生成するこ
とを目的としているため，対応させる単位が文，節と大きい．

望主ら\cite{mochinushi:00:a}も，自由作成要約を原文と対応付けるツールを作
成し，対応結果から，自由作成要約，重要文抽出による要約の相違点の分析を行
なっている．
また，\cite{okumura:99:a}で紹介されている加藤らは，要約知識の自動獲得を目的に，
単語の部分一致を考慮したDPマッチングによる対応づけ手法を示している．

このようにして，自由作成要約と原文を対応付ける(あるいは，対応する抜粋を
生成する)と，自由作成要約と抜粋の間の比較・分析が可能になる．

Marcu\cite{marcu:99:a}は，人間の要約に含まれる内容をすべて含むように，
テキストの抜粋を作成する場合，どの程度の長さの抜粋が必要であるかを調査
している．新聞記事を対象にした場合，対応する要約と比べ，抜粋は2.76倍
の長さが必要であるという結果を示している．この結果は，抜粋中の冗長性を
除去したり，さらに文をより短くするなど，抜粋をさらに加工する必要がある
ことを示しているとも言える．

また，Jingらは，自由作成要約は，対応する抜粋と比較すると，52\%の長さで
あるという報告をしている．Goldsteinら\cite{goldstein:99:b}の報告では，平
均して抜粋の長さは，自由作成要約に比べ，20\%長くなるという．

\subsection{要約における言い替え，書き換えの役割}

2.2節で述べたように，人間の要約過程は，単に重要文を抽出するだけでなく，
それらを編集する操作が含まれていると考えられる．この編集の操作には，書き換
え(revision)や言い替え(paraphrase)が含まれている．本節では，書き換えや言い
替えが用いられた要約研究を概観する
\footnote{川原\cite{kawahara:89:a}は，人間の要約作成過程において，どのよ
うに書き換えが役割を果たしているかを調査している．}．

抽出した重要文集合である抜粋を書き換える目的には，少なくとも次の2つがある
と考えられる．
\begin{enumerate}
 \item 文の長さを短くする
 \item 抜粋を読み易くする
\end{enumerate}

片岡ら\cite{kataoka:99:a}は，連体修飾節を含む名詞句を「AのB」の形に言い
替えることで要約を行なう手法を示しているが，これは前者に該当すると言える．
また，\cite{okumura:99:a}で紹介されている，概念辞書等を用いて語句を抽
象化する言い替えを行ない要約する手法である「抽象化，言い換えによる要約手
法」(3節)や，加藤，若尾らのような手法(6節)は，言い替えを行なうことで，文
字列を削減する要約手法と言うことができる．

また，Maniら\cite{mani:99:b}は，抜粋を書き換えることで，質の向上を目指し
ている．3つの操作，elimination, aggregation, smoothingを示している．それ
らを抜粋に繰り返し適用することで，抜粋の読み易さを低下させずに
informativenessを向上できたと主張している．このことから，Maniらの主眼は，
書き換えにより，要約内の情報の量を向上させること(抜粋中の不要な個所を削
除することで，他の個所の情報を要約に加える)であると言える．

eliminationがJingらの
文短縮，aggregationとsmoothingが文の結合にそれぞれ対応している．
eliminationでは，文頭の前置詞句，副詞句を削除する．smoothingには，読み易
さ(首尾一貫性)を改善するための操作が一部含まれる．

一方，後者の研究としては，難波ら\cite{nanba:99:b}の研究がある．難波らは，
人間に抜粋を書き換えてもらう心理実験を行な
い，抜粋の読みにくさの要因を分析した後，要因ごとに読みにくさを解消する
ための書き換えを定式化している．接続詞を追加したり，削除したり，また，冗長
な単語の繰り返しを代名詞化したり，省略したり，逆に，省略されている単語を
補完したり，などである．そして，そのうちいくつかを実装している．

大塚ら\cite{otsuka:01:a}は，「この」等の指示形容詞を含む名詞句に対して
照応処理を行なうことで，対応する先行名詞句を特定し，指示形容詞を含む名
詞句を対応する先行名詞句に置き換えることで，抽出した重要文集合のつなが
りの悪さを改善する手法を示している．

\subsection{要約の言語モデル}

原文と自由作成要約の組がコーパスとして大量に存在するなら，人間
の要約過程を模倣するようにモデルを訓練することが可能である．Knightと
Marcu\cite{knight:00:a}は，このような考え方に基づき，文要約(文短縮)
において，文法的で，しかも，内容としては原文の情報の重要な部分を維持する
ような手法を2つ示している．2つの手法は，確率的noisy-channelモデ
ルと決定木をそれぞれ用いている．入力として，単語列(1文)を与えると，
単語列中の単語の部分集合を削除し，残った単語が要約を構成する
\footnote{原文と抜粋の組のコーパスから重要文抽出のためのモデルを学習する
手法については\cite{okumura:99:a}の2.2節ですでに紹介されている．}．

確率的noisy-channelモデルは，統計的機械翻訳の場合と同様，次の2つのモデル
で構成される．
\begin{itemize}
 \item Source Model:\\
要約を構成する文$s$の確率$P(s)$．文sが生成される確率を示す．この確率は，
       文法的でない文の場合低くなり，要約が文法的であるかどうかの指標と
       なる．単純にはbigramでモデル化される．
 \item Channel Model(Translation model):\\
単語列の組$\langle s, t \rangle$の確率$P(t|s)$．要約sから, より長い単
語列t(原文)が得られる確率．原文中の各単語が要約に出てくる確からしさを
示しており，各単語の確からしさの積をその単語列が要約となる確からしさと
する．重要な内容を保持しているかどうかの指標となる．
\end{itemize}

KnightとMarcuは，上の2つの確率を単語列に対してではな
く，それを構文解析した結果得られる木に対して計算している．
$P_{tree}(s)$は，木sを得る際に利用される文法規則に対して計算される標準
的な確率文脈自由文法のスコアと，木の葉に現れる単語に対して計算される標
準的な単語のbigramのスコアの組合せである．

確率的なchannelモデルでは，拡張テンプレートを確率的に選択する．たとえ
ば，NPとVPを子ノードとして持つノードSに対して，確率$P(S \rightarrow NP
\: VP \: PP | S \rightarrow NP \: VP)$を元に，子ノードPPを追加する．

そして，単語列tからそれに対応する要約sを選択する際，$P(s|t)$を最大にす
るものを選択する．これは，$P(s)\times P(t|s)$を最大にするsを選択するこ
とと同じである．原文中の単語列の部分集合で，上の2つの確率の積を最大に
するものをViterbiビームサーチを用いて選択する．

Ziff-Davisコーパス中の1067組の文を対象にし訓練を行なっている．拡張テン
プレートは，原文と要約文をともに構文解析し，その木の対応関係から抽出し
ている．

一方，決定木に基づく手法としては，原文に対応する木tを与えると，それを
要約文に対応する，より小さな木sに書き換えるモデルを示している．拡張し
た決定的shift-reduce構文解析の枠組に基づき，空のスタックと，入力の木t
を入れた入力リストを用いて処理を開始し，より小さな木へ書き換えるべく，
shift (入力リストの先頭をスタックへ移動), reduce(スタック上のk個の木を
組み合わせて新たな木を構成し，スタックにプッシュ), drop(入力リスト中の
構成素を削除)の操作を繰り返し実行する．

決定木に基づく手法は，noisy-channelモデルに基づく手法よりも，より柔軟
であり，原文の構造と要約文の構造が著しく異なる場合にも対処可能である．
どの操作を選択するかは，訓練データ(原文-要約文の組の集合から構成される
操作の系列の集合)から，決定木学習を行なうことで学習される．

このように，文要約のモデルを，訓練コーパスから自動的に訓練することで得る手
法は，WitbrockとMittal\cite{witbrock:99:a}が，原文とabstractの組で直接訓
練した確率モデルを適用したのが最初の研究とされる．
これ以外は，前節で紹介したJingらの研究や，\cite{okumura:99:a}で紹介さ
れている，文中の重要個所抽出，不要個所削除による要約手法を含め，いずれも，
人手で作成した，あるいは半自動で得た規則を元に，冗長な情報を削除したり，
長い文をより短い文に縮めたり，複数の文をまとめたりしている．

堀之内ら\cite{horinouchi:00:a}は，「日本語らしく，かつ意味的に重要個所を
含む」ように，文を短縮する統計的手法を示している．日本語らしさの評価のた
めにn-gramモデル，意味的に重要個所を含むかどうかの評価のためにidfをそれ
ぞれ利用している．この2つを重み付けした重要度を文中の断片に与え，重要度
の小さい断片を繰り返し削除することで文を短縮していく．

小堀ら\cite{kobori:00:a}は，あらかじめ原文から抽出された重要文節データを
元に学習した決定木を用いて重要文節を抽出する手法を示している．

BergerとMittal\cite{berger:00:b}は，query-relevantな要約を作成する統計
的言語モデルを示している．FAQのコーパスを訓練データとして，文書$d$とク
エリ$q$の組に対して，
\[ p(s|d,q) = p(q|s,d)*p(s|d) \approx p(q|s)*p(s|d) \]
を最大にする$s$を要約として求める．そして，そのための確率$p(q|s),
p(s|d)$をそれぞれ訓練データから学習する．確率$p(q|s), p(s|d)$はそれぞ
れ，(クエリに対する要約の)適切性(relevance)，(テキストに対する要約の)
忠実性(fidelity)と呼ばれている．
\

\section{複数テキストを対象にした要約手法}

これまでの複数テキスト要約研究では，あらかじめ人間が用意した比較的小規模
なテキスト集合をシステムの入力として要約を作成するのが中心的であったと
言える．しかし，近年，情報検索システムの検索結果を直接要約システムの入
力に用いるなど，より大規模なテキスト集合を要約対象とする実用
性の高いシステムがいくつか提案されてきている．

要約システムの入力として想定されるテキスト集合は，(1) すべてが同一トピッ 
クのものと，(2) 情報検索システムの検索結果のように，複数のトピックが混
在しているものの大きく2種類存在すると考えられる．どちらのテキス
ト集合を対象とするかで，要約作成手法，要約システムの位置付けも次のよう
に異なってくる．
\begin{enumerate}
 \item 要約システムに与えるテキスト集合中のテキストはどれも同じトピッ
       クについて書かれたものであり，そのため，似たような内容のテキス
       トが複数含まれる可能性がある．この場合，すべてのテキストの内容
       を要約に含めると，冗長な要約が作成されてしまう．そこで，テキス
       ト(あるいはテキスト中のパッセージ)間の
       類似度を考慮し，内容がなるべく重複しないように要約を作成する.
 \item 情報検索の結果得られたテキスト集合を要約システムの入力に用いるよ
       うな場合，そのテキスト集合には，ユーザの目的と合致しないテキス
       トが数
       多く含まれている可能性がある．このような場合，目的のテキスト集
       合へユーザをナビゲートする支援システムは有用であり，そのような
       システムでは，テキスト集合を自動的に分類
       し，グループごとに，グループのテキスト集合の要約を作成しラベル
       として付与する．
       ユーザは，自分の必要なテキストがグループに含まれているかどうかを
       付与されたラベルを見て判断する.
\end{enumerate}

\cite{okumura:99:a}では複数テキスト要約のポイントとして，図
\ref{fig:multi-text-sum}に示す3点を挙げて，この3点に沿って研究を概観し
ていた．本節でも同様にこの3点に沿って，この分野の最近の研究動向を，上
の分類に即して，紹介する.
\begin{figure}[h]
\[
\left\{ 
 \begin{array}{lll}
  a & 関連するテキストの自動収集 &\\
  b & 関連する複数テキストからの情報の抽出 & 
\left\{ 
 \begin{array}{ll}
  b-1 & 重要個所の抽出\\
  b-2 & テキスト間の共通点の検出\\
  b-3 & テキスト間の相違点の検出\\
 \end{array}
\right.
\\
  c & テキスト間の文体の違い等を考慮した & \\
 & 要約文書の生成 & \\
 \end{array}
\right.
\]
\caption{複数テキスト要約のポイント\label{fig:multi-text-sum}}
\end{figure}

\subsection*{分類1: 同一トピックのテキスト集合からの要約作成}

分類1の要約手法にはGoldsteinら\cite{goldstein:00:a}，Radevら
\cite{radev:00:a}，Steinら\cite{stein:99:a}，Barzilayら
\cite{barzilay:99:a,barzilay:01:a}，McKeownら\cite{mckeown:99:a}のもの
がある.

Goldsteinら\cite{goldstein:00:a}は新聞記事を対象とし，記事集合中からある
検索クエリに関するパッセージを抽出，収集し(a)，それらを並べて要約を作成
するMMR-MD(Maximal Marginal Relevance Multi-Document)という手法を提案し
ている．検索されたパッセージを単純にクエリとの適合度の高い順に並べただけ
では，パッセージ間で重複する個所が存在する可能性があり，要約として望まし
くない．そこで，MMR-MDでは，クエリに対するパッセージの適合度を考慮しつつ，
すでに上位にランクされているパッセージと類似度の低いもの(重複個所が少な
いと思われるパッセージ)(b-3)を選択して順に出力することで，冗長性の少ない
複数テキスト要約の作成を行っている．また，パッセージの出力順序を決める際，
記事が書かれた日時なども考慮している.

Radevら\cite{radev:00:a}は新聞記事集合をあらかじめクラスタリングし，各ク
ラスタごとに要約を作成する手法を提案している(a)．クラスタ中の記事中
の各文の重要度をまず計算し，次に要約率に応じて記事集合から重要度の高い文を
抜き出し，抜き出された文を記事の書かれた日付順に並べて，要約として出力す
る．文の重要度は，クラスタの特徴を表す語を文が含む割合(b-2)，文の位置
(lead)(b-1)により決定する．また，Goldsteinらと同様，自分より重要度の高い
文と内容が重複するような文は重要度を下げることで，冗長性の少ない要約の作
成を目指している(b-3)．

Steinら\cite{stein:99:a}は，あらかじめテキストごとの要約を作成し(b-1)，作
成された要約をクラスタリングし，似たような内容の要約をグルー
ピングしている．そして，各クラスタ中で最も代表的な要約をクラスタの要約と
して抽出する(b-2)．また，クラスタの要約同士の類似度を計算し，隣接する2つ
の要約の類似度が高くなるよう並べ換えて出力している．

Barzilayら\cite{barzilay:99:a}，McKeownら\cite{mckeown:99:a}は，複数の
新聞記事間で言い回しは異なるが同じ内容の文を，7種類の言い換え規則
を用いて同定している(b-2)．同定された文は，構文解析器を用いて述語
項構造に変換され，文間で共通な句が抽出される．その後，文生成器を用いて抽
出された共通語句を統合し，要約文として出力する(c)．さらにこれらの要約
文は記事の日付順およびテキスト中の出現順にソートされ，それらが最終的な
要約文書となる．

要約文書の構成要素となるトピック(文)を並べる順序を決定するこれまでの方法
は，文間のつながりを考慮する方法\cite{goldstein:00:a,stein:99:a}と，
記事が書かれた時間順に並べる方法\cite{radev:00:a,mckeown:99:a}の2つ
に分けられる．一般にはさまざまなトピックの並べ方が存在するが，人間が複
数のテキストから要約を作成する場合，何らかの原理に基づいて並べる順序を
決定していると考えられる．Barzilayら
\cite{barzilay:01:a}は，複数の記事から抽出されたいくつかの重要文のセット
を10人の被験者に与え，それらを並べ換えることで要約を作成してもらっている．
そして，その結果を比較することで，次のような知見を得ている．
\begin{quote}
すべての文の
順序が被験者間で完全に一致することはあまりない．しかし，順序が入れ替わっ
ても，常に隣り合って出現する文のペアがいくつかある．これらのペアは関連し
たトピックの文で構成されている．したがって，複数テキスト要約において文間の結
束性を考慮することは重要である．
\end{quote}

このような知見に基づき，Barzilayら\cite{barzilay:01:a}は，要約文の順序を
決定する方法を考案している．基本的にはトピックを時間順に並べるが，関連し
たトピックの文は必ず隣接して出力する．この方法により，作成される要約文書
はある程度結束性が保たれる．Barzilayらは，この手法を先に述べた「記事
が書かれた時間順に並べる方法」と比較し，前者の手法の方が優れていることを
示している．

\subsection*{分類2: 複数のトピックを含んだテキスト集合からの要約作成}

分類2の要約手法にはEguchiら\cite{eguchi:99:a}，Fukuharaら
\cite{fukuhara:99:a}，Andoら\cite{ando:00:a}，上田ら\cite{ueda:00:a}，
Kanら\cite{kan:01:a}のものがある.

Eguchiら\cite{eguchi:99:a}は，WWW上のテキストを対象にした
関連性フィードバックに基づく検索システムを構築している．このシステムでは，
検索結果(a)をテキスト間の類似度に基づいてクラスタリングし，各クラスタ
ごと
にクラスタに多く含まれる語と，そのクラスタを代表するテキストのタイトルを，
そのクラスタの要約として出力する(b-2)．出力されたクラスタをユーザに選択
してもらい，そのクラスタに含まれるテキストを用いて関連性フィードバックを行っ
ている.

Fukuharaら\cite{fukuhara:99:a}も，Eguchiらと同様に検索結果をクラスタリン
グし(a)，クラスタごとに要約出力を行っている．Fukuharaらは，テキスト中の単
語の出現頻度分布を考慮し，クラスタごとの話題を表す語とそれらを含んだ文を抽
出する．さらに，抽出された文を，焦点-主題連鎖を考慮して並べ替え，クラス
タごとの要約として出力している(b-2).

Andoら\cite{ando:00:a}は，ベクトル空間モデルを用いて新聞記事集合中の記
事間の類似度を計算し，それらをsemantic spaceと呼ばれる2次元空間上に配置
し表示するシステムを構築している．semantic space上では各記事はドットで表
現され，またトピックの似た記事はsemantic space上で隣接して配置される．マ
ウスでsemantic space上のドットを指せば，そのドット(記事)と関連のあるドッ
ト(記事)が強調され(a)，さらに関連記事中の頻出単語(topic term)や頻出単語
を多く含む文(topic sentence)(b-2)が表示される.

上田ら\cite{ueda:00:a}は，クラスタリングによりある程度同じ話題でまとめら
れたテキスト集合を対象に，各クラスタの特徴を表す文を自動的に作成する手法
を提案している(a)．上田らもBarzilayら，McKeownらと同様に，テキスト中の各
文を構文解析し，テキスト間で構文木同士を比較することで，テキスト間の共通
個所を同定するという手法を提案している(b-2)．構文木の比較には２種類の方
法を提案している．１つは，例えば「フーバー社が携帯電話を発売」という文を，
意味的に等価な「携帯電話がフーバー社から発売」などに構文レベルで変換し，
同一内容の異なる２文を同定し，クラスタのラベルとして出力するという方法で
ある．もう１つは，シソーラスを用いて「ホウレンソウからダイオキシンが検出
された」と「白菜からダイオキシンが検出された」の２文から「野菜からダイオ
キシンが検出された」といったように，より抽象度の高いレベルで融合し，ラベ
ルとして出力するという方法である.

これまで分類2で述べてきた要約作成手法は，形態素，あるいは構文レベルでテ
キスト間の比較を行っているが，個々のテキストからいくつかの属性値を抽出し
た後，テキストを属性レベルで比較し，要約を作成する試みがある．

Kanら\cite{kan:01:a}は，ある検索クエリで検索された医療関係のテキスト集合
を比較し，ユーザがどのテキストを読むべきか判断するのに有用な
indicative(指示的)な
要約を生成する手法を提案している．このシステムを利用することで，例えば喉
頭炎(angina)を検索クエリとした場合，「検索結果は23件あります．結果には喉
頭炎のガイド(`the AMA Guide to Angina')が含まれています．」「喉頭炎に関
する定義やリスクに関して述べたテキストがあります．」「喉頭炎の関連情報を
含んだテキストがあります．」といった要約が出力される．このような要約を
生成するために，Kanらは，まず個々のテキストを，セクションの情報に基づいて，
そのテキストのトピックの構造を示す木(トピックツリー)で表現する．次に検索
クエリがトピックツリーのどこに位置するのか(クエリとテキストのメイントピッ
クとの関連)，テキストの平均的な属性値と比較して，テキストに含まれるいく
つかのトピックがどの程度重要であるのか(他のテキストと異なっているのか)
(b-1, b-3)といった情報をテキストの属性値として抽出する．これらの値を用い
て要約生成を行い，検索結果として出力する．

\subsection*{その他の要約作成手法}

これまでの複数テキスト要約の研究は，複数のテキストから得られた情報をいか
に統合して要約を作成するかに主眼が置かれてきたと言える．一方，ある種の
テキスト集合には，集合全体の内容をまとめたテキスト(パッセージ)が存在する
ことがある．例えば，ある分野の研究動向をまとめたサーベイ論文や，ある事件
に関する解説記事などがこれに相当する．このようなテキストを見つけ出すこと
ができれば，それ自体を複数テキストの要約とみなすことができる．

橋本ら\cite{hashimoto:01:a}は，ある事件に関して過去の主要な出来事が新聞記者の
観点で要約されている個所をサマリパッセージと呼び，このような個所を記事集
合から自動的に抽出する手法を提案している．サマリパッセージは，解説記事や
社説など何らかの意見が述べられている記事(意見記事)中に含まれている．また
事件の経緯を時系列に箇条書でまとめた個所もサマリパッセージと考えることが
できる．橋本らは，表層的な情報を用いてこれらのサマリパッセージの抽出を試
みている．例えば，記事のタイトルに「社説」や「解説」を含む記事，意見文を
多く含む記事は，意見，解説記事として抽出される．また，新聞固有の箇条書の
形式を認定することでまとめ記事が抽出できる．こうして抽出されたパッセージ
は人間が作成したものであるため，これまでの複数テキスト要約で問題とされて
きた要約の一貫性が保証されている．

\section{要約対象の幅の広がり}

これまでの自動要約研究の多くは，その要約対象のテキストのジャンルとして，新
聞記事，論文を扱ってきた．これに対し，近年これ以外のジャンルのテキスト
を要約対象とする研究が見られるようになってきた．たとえば，web pageを対
象とした研究としてはOCELOT\cite{berger:00:a}等があり，また，mailを対象
とした研究としては\cite{toyama:00:a}等がある．

さらに，テキストではなく，音声(あるいは，その書き起こしである話し言葉
のデータ)を対象とする要約研究がいくつか見られるようになってきた．これ
には，講演音声のようなmonologueと，2人以上による対話(dialogue)の両方が
含まれる．話し言葉を対象とした要約では，
(1) テキストとしての情報以外に他の音響的情報が利用できる，(2) 音声認識
結果を入力とすることから，入力にノイズが含まれる，(3) 後述するように，
話し言葉の特性としての冗長性が入力には含まれる等，
テキストを対象とした場合とは異なり，新たに考慮しなければいけない点が存
在する．そこで，本節では，以下，
これらの話し言葉を対象とした要約研究を概観する．なお，これまでにも，
\cite{okumura:99:a}で紹介されている字幕作成における要約のように，入力
としてニュース原稿の読み上げ音声を対象とした研究は存在する．

堀と古井\cite{hori:01:a}は，講演音声を自動要約する手法として，各発話文
から重要な単語を抜き出し，それらを接合することで要約文を作成する手法を
提案している．要約は，要約のもっともらしさを示す要約スコアを最大にする
文中の部分単語列をDPマッチングにより決定し得ている．要約スコアは，単語の
重要度(頻度に基づく)，単語連鎖の言語スコア(単語のtrigram)，音声認識時
の各単語の音響的，言語的信頼度，および原文中の単語の係り受け構造に基づ
く単語間遷移確率の重みつき和として定義される．

講演は，自然な発話(spontaneous speech)に比べれば整っているが，フィラー
や言い直しなど，多くの冗長表現を含み，話し言葉に近い特性をもつ．
この特徴を利用し，幅田と奥村\cite{habata:01:a}は，冗長表現を不要個所と
して削除することで，情報を欠落させずに要約を行う手法を示している．
人手によって講演音声の要約を行っている要約筆記データの分析をまず行い，
その分析結果を元に，文短縮型の要約システムを開発している．
分析の結果，フィラー，言い直し・繰り返し表現，挿入句表現，丁寧表現，「〜
という〜」表現が削除または言い替えの対象として得られている．
削除率および，要約筆記データを正解データとした場合の精度を尺度
として要約システムを評価したところ，削除率18.0\%，精度79.8\%が
得られている．この研究は，聴覚障害者のための情報
保証手段の一つして人手で現在行なわれている要約筆記の自動化を目指すもの
と言うことができる．

笠原と山下\cite{kasahara:01:a}は，講演音声を対象とした要約の自動作成の
ため，重要文と韻律的特徴の関係についての分析を行なっている．

Zechnerら\cite{zechner:01:a}は，
対話を書き起こしたものを入力とし，MMRにより文をランク付けし，要約の長
さまで，テキストの順序で文を出力する手法を示している．しかし，この手法
では，質問に対応する応答が要約に含まれないため，一貫性に欠ける要約がで
きる可能性がある．そのため，
複数の話者の発話にまたがる局所的一貫性(この研究では，質問・応答の組の
み)を検出し，それを要約の際考慮に入れる(その一部がMMRで選択された場合
組全体を要約に含める)ことで，要約の読み易さが向上することを人間の主観
評価により示している．

Reithingerら\cite{reithinger:00:a}は，
音声翻訳システムVERBMOBILを用いた，日程調整，ホテル予約のような領域に
おける「交渉」対話を対象にした要約手法を示している．
話し手の意図を発話行為クラスとして同定し，その情報を用いて，意図が
suggestならその内容を候補とし，rejectなら棄却，give\_reasonなら無視する 
というように，情報の選択の際に利用する．また，キーワードスポッティング
により，発話の内容を属性-値の組として同様に抽出する．
そして，交渉対話では，話し手全員が合意したことに関心があるという前提を
利用し，
suggestされた内容で，acceptされたものを同定し，それを生成器で生成する
ことで要約を作成している．

\section{おわりに}

1999年の解説\cite{okumura:99:a}の後を受け，テキスト自動要約の研究分野に
おいて，ここ数年関心が高まっている話題を3つ紹介した．

テキスト自動要約は，必要性が高まっていることもあり，今後も活発に研究が
進められていくことと思われる．今後は，複数テキスト要約だけでなく，さらに
対象範囲を広げ，複数の言語で書かれたテキスト(translingual
summarization)，複数のメディアの情報を対象にした(テキストだけでなく，画
像や音声も対象にする)要約(multi-media summarization)
なども注目を集めそうである．
今後も，テキスト自動要約の研究分野の動向には目が離せない．


また，テキスト自動要約技術の応用として，いくつかの新しい方向性が明確に
なってきたことも，ここ数年の話題と言えるかもしれない．これまでも，サー
チエンジンにおける検索結果の表示や，ユーザのナビゲーションにおいて要約
を利用する研究や，字幕作成，文字放送用に要約手法を利用することは試みら
れていた．これに加えて，ここ数年で，携帯端末における情報提示のための要
約の利用(たとえば，\cite{buyukkokten:01:a,corston:01:a})や，(高齢者，
視聴覚障害者といった)情報弱者のための情報保証への要約の利用(たとえば，
自動要約筆記\cite{habata:01:a}やユーザの視覚特性に合わせたトランスコー
ディング\cite{maeda:01:a})といった，新しい有望な応用分野が要約には付け
加わったと言える．研究分野の動向とともに，今後，要約の応用分野の動向に
も目が離せないと言える．

最後に，新しい参考文献をいくつか紹介しておく．
1999年に出版された\cite{mani:99:a}は，この分野の論文を，古典から最新のもの
まで集めた論文集であり，テキスト自動要約の最初の研究とも言われる
\cite{luhn:58:a}も入っている．この分野で研究を始める人には必読と言える．

TipsterのText Program Phase IIIの論文集\cite{tipster:99:a}も出版され
ている．SUMMAC参加システムの概要がいくつか収録されており，また，SUMMACの
dryrunの報告も含まれている．

また，昨年自動要約に関する教科書も出版されている\cite{mani:01:a}．自動
要約に関する話題をわかり易く記述してあり，この本もこの分野で研究を始め
る人には必読と言える．なお，この本の翻訳の出版計画も進んでいる．



\bibliographystyle{/lr/data/sty/nlpsty/jnlpbbl}
\bibliography{summarize}

\begin{biography}
\biotitle{略歴}
\bioauthor{奥村 学}{
1962年生．1984年東京工業大学工学部情報工学科 卒業．1989年同大学院 博士課
程修了．同年，東京工業大学工学部情報工学科 助手．1992年北陸先端科学技術
大学院大学情報科学研究科 助教授，2000年東京工業大学精密工学研究所 助教授，
現在に至る．工学博士．自然言語処理，知的情報提示技術，語学学習支援，テ
キストマイニングに関する研究に従事．情報処理学会，人工知能学会, AAAI，
言語処理学会，ACL, 認知科学会，計量国語学会各会員．
e-mail: oku@pi.titech.ac.jp, http://oku-gw.pi.titech.ac.jp/\~{}oku/.
}
\bioauthor{難波 英嗣}{
1996年 東京理科大学理工学部電気工学科 卒業．
1998年 北陸先端科学技術大学院大学情報科学研究科 博士前期課程修了．
2001年 北陸先端科学技術大学院大学情報科学研究科 博士後期課程修了．
同年，日本学術振興会 特別研究員．
2002年 東京工業大学精密工学研究所 助手．現在に至る．
博士(情報科学)．
自然言語処理, 特にテキスト自動要約の研究に従事．
情報処理学会, 人工知能学会, ACL, ACM各会員．
nanba@pi.titech.ac.jp，http://oku-gw.pi.titech.ac.jp/\~{}nanba/
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}
