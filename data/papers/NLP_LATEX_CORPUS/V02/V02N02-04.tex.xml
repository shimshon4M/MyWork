<?xml version="1.0" ?>
<root>
  <title/>
  <author/>
  <jkeywords/>
  <section title="Introduction">Therehavebeenanumberoftheoreticalstudiesdevotedtothenotionofsublanguage.Someofthemclaimthatthenotionisimportantinprocessingnaturallanguagetext,owningtolexical,syntacticorsemanticrestrictions,etc.Anumberofthesestudieshaveobservedactualtextstoverifytheclaim.Furthermore,therearesomesuccessfulnaturallanguageprocessingsystemswhichhaveexplicitlyorimplicitlyaddressedthesublanguagerestrictions.Forexample,TAUM-METEOisamachinetranslationsysteminwhichonlysentencesintheweatherforecastdomainaredealtwith,anditworksremarkablywell.However,twomajorproblemsarestillunsolvedtoutilizethesublanguagenotion.AutomaticdefinitionanddynamicidentificationofatexttosublanguageAutomaticlinguisticknowledgeacquisitionforsublanguage.Owingtotheappearanceoflargemachine-readablecorpora,therearenownewopportunitiestoaddresstheseissues.Theexplosionoflargecorporahasleadtoafloweringofresearchonlinguisticknowledgeacquisitionfromcorpora.Amongthem,severalstudieshavementionedtheimportanceofthesublanguagenotion.Althoughthesearestillsmallexperimentsintermsofaccuracyandcoverage,theyaddressedthesecondproblemlistedabove,andcouldleadtoabreakthroughforfutureN.L.P.systemsbyreducingthecostlyanderrorsometaskoflinguisticknowledgeencodingbyhumanlinguists.Thefirstproblemhasnotreceivedsomuchattention.IntheprevioussublanguageN.L.P.systems,thedomainthesystemisdealingwithwasdefinedmanually.Forexample,thesublanguagesof``weatherforecasts'',``medicalreports''or``computermanuals''areartificiallyorintuitivelydefinedbyahuman.Thisisactuallyonemethodtodefinethesublanguageofthetext,and,inasense,itseemstoworkwell.However,itisnotalwayspossibleandsometimesitmaybewrong.Forexample,inalargevocabularyspeechrecognitionsystem,whichmayhastohandleavarietyofdomains,itisimpossibletotunetoasublanguageinadvance.Also,ifwetakethe``computermanualdomain''asasublanguage,thedomaincontainsamixtureoflinguisticphenomena.Because``computermanualdomain''rangesfroma``wordprocessormanualfornovices''toa``UNIXreferencemanual'',andtheirlinguisticusagesaredifferent.Inshort,anewstepislong-awaitedtoexpandthesublanguageresearch.</section>
  <section title="Two Definitions of Sublanguage">Thenotionofsublanguagehasbeenwelldiscussedinthelastdecades.Wecanfindtwokindsofdefinitions,althoughthedifferencehasnotreceivedseriousattentionuptonow.OnedefinitioncanbeinferablefromZelligHarris:Certainpropersubsetsofthesentencesofalanguagemaybeclosedundersomeoralloftheoperationsdefinedinthelanguage,andthusconstituteasublanguageofit.quotationFromthisdefinition,wecaninferthatasublanguagecanbedefinedempiricallybyobservinglanguagebehavior.TheothertypeofdefinitionisexemplifiedbythefollowingsentenceinBross,ShapioandAnderson:Informally,wecandefineasublanguageasthelanguageusedbyaparticularcommunityofspeakers,say,thoseconcernedwithaparticularsubjectmatterorthoseengagedinaspecializedoccupation.quotationInthispaper,theformerdefinitionwillbecalledan`inductivedefinition',sinceasublanguagecanbedefinedbyobservationofdata.Thelatterdefinition,ontheotherhand,willbecalleda`deductivedefinition',sinceitisbasedontheprinciplethataparticularsubjectmatterwoulddefineasublanguage.Manypracticalprojectshavebeenusingthedeductivedefinitionintentionallyorunintentionally.Forexample,theTAUMprojecttooktwosubjectdomainsfortheirMTapplications;oneisweatherforecastsandtheotherisaircraftmaintenancemanuals.Thisisadeductivedefinitionofsublanguage,becausetheytookaparticularsubjectastheirtarget.However,thedeductivedefinitionisnotalwayspossibleandsometimesitmaybewrong,aswediscussedbefore.</section>
  <section title="Benefit from Large Corpora">Recently,anumberoflargecorporahavebecomeavailableinmachine-readableform.Theappearanceoflargecorporawouldbeofbeneficialtosublanguagestudy.Inparticular,itcanbeusefulfortheinductivedefinitionofsublanguage.AlthoughHarris'snotionwasmainlyconcernedwiththeoperationsonsentences,thereareseveralotherfactorswhicharerelatedtothesublanguagenotion.Forexamplelexical,syntacticandsemanticrestrictions,ahighfrequencyofcertainconstructionsanduseofspecialsymbols(thesefactorsareborrowedfromLehrberger).Thesefactorscanbeusefulfortheinductivedefinitionofsublanguage,aswellasthemselvesbeingcharacteristicsofsublanguage.Inotherwords,wemaybeabletofindsublanguagesbyobservingtextsintermsofsimilaritiesofthesecharacteristics.TheotherfactorsinLeherberger'slistofsublanguagecharacteristics-limitedsubjectmatter,deviantrulesofgrammarandtextstructure-arehardertoutilizefortheinductivedefinitionofsublanguage.Thestrategyforinductivedefinitionofasublanguageusingcorporaistoanalyzethecorporaintermoflexical,syntacticorsemanticcharacteristics,andthenmakeclustersinwhichthevaluesofthefactorsaresimilar.However,inpractice,itisstilldifficulttoanalyzeasentencecorrectlyintermofsyntaxandsemantics,sothepreliminaryexperimentinthispaperemploysonlythelexicalfactortobuildupasublanguageasaninitialattempt.</section>
  <section title="Sublanguage Definition">Ourexperimentscanbedividedintotwoparts:thedefinitionofsublanguageandtheidentificationofanewtexttothesublanguage.Wewilldescribetheexperimentofthesublanguagedefinition,first,inthissection,andinthenextsection,wewilldiscusstheexperimentsofthesublanguageidentification.Weuseanewspaper(7.5MBofSanJoseMercury,2147articles)inourexperiments.Eacharticleinthenewspaperisregardedasaunitofdata,andasublanguagewillbeformedbygatheringsimilarunitsintermofwordappearance.Thisisalmostidenticaltothetextclusteringtechnique,whichhasbeenwellstudiedinthefieldofinformationretrieval.Howevertheaimoftheirstudyisslightlydifferentfromours.Theytrytomakeclusterswhichareusefulforhumaninformationretrievalpurposes,sothelinguisticfeaturesoftheclustersarenotsoimportant.Incontrast,ourpurposeistofindasublanguagewhichisusefulforN.L.P.systems,soweareveryinterestedinthelinguisticfeaturesofclusters.Oneoftheproblemsinmakingclustersishowtodefinethenumberandsizeofclusters.Thenumberofclustercanrangefrom1,withallthearticlesinthecluster,tothenumberofarticles,eachclustercontainsjustonearticle.Theproblemhereisthatwehavenoobjectivemeanstodecidethenumberandthesize.Thisproblemisverycrucialforautomaticsublanguagedefinition,becauseotherwiseweneedmanualinterventionorartificialthresholds.Inordertoexplorethisproblem,weintroducethefollowingstatistics.PerplexityandExpectedPerplexityflushleftPerplexity,moreprecisely`uni-gramperplexity'usedinthispaper,isanotionfromInformationTheory.TheformaldefinitionofitisdefinedbyusingUni-gramEntropyH:Herep(w)isaprobabilityofatokenwinthesource.Thisprobabilitymaybeestimatedfromatextbydividingthenumberofthetokenbythenumberoftokeninthetext.Fromthisestimatedprobability,wecangetestimatedentropyandperplexity.Roughlyspeaking,perplexityindicatestheamountofinformationinthesource.Onconditionthatthesizesoftwotextsarethesameintermsofnumberoftokens,thenwecanroughlysaythatthetextwithlargerperplexityhasthegreatervarietyofthetokens.Wecanalsocalculateperplexityforasetoftexts,treatingthesetasasingletext.Iftwotextshavelargenumberofoverlappingtokens,whichmeansthetwotextsaresimilarintermsofwordapparency,theperplexityforthecombinedtextwillbesmallerthanthatofatextwhichhastokenschosenatrandomfromtheentirecorpus.Inshort,iftheperplexityforatextsetissmallincomparisontoperplexityforarandomtext,wemaysaythatthesethassublanguagetendency.Inordertoobserveperplexitiesoftexts,wemadeclustersbasedonsimilaritiesofarticles.Clustersaregrownfromoneinitialarticlebyaddingsimilararticlesintheorderoftheirsimilaritytotheinitialarticle.Thesimilaritymeasurementisborrowedfrominformationretrievalresearch.TheideaoftheformulaisbasedonInverseddocumentfrequency(IDF)asbeshowninthefollowing:Here,S(A,B)isthesimilaritybetweenarticleAandB,F_wisfrequencyofwordwthroughoutthecorpus,andN_XisthenumberoftokensinthearticleX.Wesetthecut-of-number200(tokenswhichoccurmorethan200timesinthecorporaarenottakenintoaccount),theminimumoccurrence2(onlythetokenswhichoccur2ormoretimesinthearticleisconsidered)andtheminimumco-occurrence2(relationshipwouldbeestablishedisthetwoarticlehave2ormoretokensoverlapped).Thoseparametersandnumbersareexperimentallydecided.Wegrowaclusterinthiswayaroundeacharticleinthecorpus.Inordertomakeobjectivemeasurement,wewanttocomparetheseestimatedperplexityvaluewiththeperplexityofrandomtext.Becausetheestimatedperplexitydependsonthesizeofthesampletext,weneedtocomparetheclustertoasampletextofthesamesizetextobtainedbyselectingtokensatrandomfromtheentirecorpus.Theexpectedperplexitiesusedintheexperimentistheaverageofthreeofthesetrials.Figureshowssomeexamplesoftherelationshipbetweennumberoftokensinclustersandratioofitsperplexitytothatofrandomestimation.Thepointsinthegraphstartingfromtheleftsideindicatedataforthefirstarticle,thefirstarticleandtheclosestarticlecombined,andsoon.ObservationsontheGraphflushleftItisnaturalthattheratiomovestoward1.0asthenumberoftokensbecomesbigger,becausetheclusterisapproachingthesetofallarticlescombined.However,wecanseethatinallofthefourexample,thereisaminimumpointatasmallnumberoftokens.Thiscouldhappenifthecombiningtextshavelargernumberofoverlappingwordsthanexpected.Now,weproposethatthisminimumpointsuggestsoneofthedefinitionsofsublanguageintermsofwordappearance.Thisphenomenaisobservednotonlyatthefourexamplesshown,butalsoformanyoftheotherclusters.Wehaveexaminedthearticlesinvolvedandwefindapromisingpattern.InExample2,all9articlesfromthebeginninguntiltheminimumpointareallobituaries,whilethenextthreearerealestatearticles.InExample1,thefirstarticleand54%ofarticlesuptotheminimumpointarecollegebasketballarticles.Therestareeitherhigh-schoolandprofessionalbasketball(24%and8%,respectively),hockey(8%)orfootball(4%)articles.Ontheotherhand,only16%ofthenext25articlesand6%oftherestofthearticlesuptothe185tharecollegebasketballarticles.Theseexampleintuitivelysupporttheclaimthattheminimumpointofeachlineatthegraphwouldbeanobjectiveindicatorofthesizeofatextclusterorasublanguage.SublanguageClustersflushleftWetakethearticlesfromthebeginninguntiltheminimumpointasasublanguage.Theseclustersareusedinthenextexperiment,identificationofanewtexttosublanguage.Asthereare2147articlesinthecorpus,thesamenumberofclustersexist(notnecessarydistinct).Thenumberofarticleinaclusterrangesfromoneto31,andtheaveragenumberis4.26articles.</section>
  <section title="Sublanguage Identification for a New Text">Wetake244testarticlesfromnewSanJoseMercuryarticleswhicharenotusedintheexperimentofsublanguagedefinitiondescribedabove.Inthissection,themethodtoidentifytheclosestclusterforeachtestarticlewillbedescribed.Foreachtestarticle,similaritymeasurestoalltheclustersarecalculatedtofindtheclosestone.Basically,thesimilaritymeasureisthesameastheoneinthepreviousexperiment.Thesimilaritybetweenatestarticleandaclusterissettoequaltothemaximumsimilaritybetweenthetestarticleandanyofthearticlesinthecluster.Ifthereisatie,theclusterwhichcontainsthesmallestnumberofarticleswins.Thiscalculationisnotexpensive,becausewehavealimitednumberofthewordswhichhavetobetakenintoaccountinthecalculation.Thenumberisnormallymuchlessthanthenumberoftokensinthetestarticles.Also,thenumberofclusterstobeexaminedforeachwordislessthanthecutoffnumber(50intheexperiment).Sothiscalculationisalmostlinearinthenumberofwordsinthetestarticle,ifthereisenoughspacetostorethewordindex.Inthisexperiment,wesettheparametersforsimilaritycalculationslightlydifferentfromtheonesinthedefinitionexperiment.Thecutoffnumberis50,minimumoccurrenceis1andminimumco-occurrenceissetto3,basedonempiricaladjustments.ResultofIdentificationflushleftTheresultoftheidentificationexperimentwillbedescribed.Theevaluationmeasureisbasedonhowmanytokensinthetestarticlealsoexistintheclosestcluster,i.e.numberoftokenswhichoverlapbetweenthetestarticleandtheclosestcluster.Astraightforwardmeasurementisitscoverage,whichishowmanytokensareoverlappingagainstthenumberoftokensinthearticle.Thisfigurecouldbeusefulindecidinghowusefulthismethodis,butitmightstillbedifficulttomakeanobjectivedecision.Then,thenumberofoverlappingtokensiscomparedwithanexpectednumberofoverlappingtokens.Itiscomputedbytakingtwosetsrandomlywhichhavethesamenumberoftokenstothetestarticleandtheselectedcluster,thencalculateaveragenumberofoverlappingtokensbetweenthem.Thisexpectednumber(E)iscalculatedbythefollowingformula.Here,thedenominatoristheexpectednumberoftokensinthearticle,thenumeratorisexpectednumberofoverlappingtokensbasedonexpectednumberoftoken,andEisadjustednumberofoverlappingtokens.N_t,n_tarethenumbersoftokensinthetestarticle,N_cisthenumberoftokensinthecluster,Nisthenumberoftokensintheentirecorpus,andf_wisthefrequencyofwordw.Theexpectednumberofoverlappingtokenscanbeclassifiedintocertainfrequencyrangesapplyingthevariablesf_wandn_ttotherange.Itiswellknownthathighfrequencywordslike``the''or``of'',arerelativelycommonregardlessofthetopicorsublanguage.Ontheotherhand,lowfrequencywords,whichareoftenregardedasindicatingthetopic,areexpectedtoco-occurtogetherinsamearticles.So,wecananticipateinthisevaluationthatlowfrequencywordsoverlapbetweentestarticlesandtheclosestclustersmorethanexpectedvalues.(Notethat,becausewordswithf_w&lt;50areusedinthesimilaritycalculation,thosewordsmustbespeciallytreatedintheevaluation.)Toobservesuchdetails,weclassifiedtheresultbasedondocumentfrequencyofwordsintheentirecorpus.Tableshowsanexampleoftheresults.Inthisexample,thenumberoftokensinthearticleis129andthenumberoftokensintheclusteris1265andtheclusterconsistsof5articles.Thefirstcolumnshowsthenumberoftokensanditsexpectednumberinthebracketsbeloweachnumber.Forexample,theexpectednumberoftokenswhosefrequencyrangesfrom100to199is12.0,butisactually25inthearticle.Thesetwofiguresshowthebalanceofthewordfrequencydistributioninthearticle,andwecanseethatmostofthemarebalanced.Thesecondcolumnshowsinformationaboutoverlappingtokens.Forexample,95tokensoutof129intheentirearticleareoverlappingtotheclosestcluster.Thethirdcolumnshowsthecoverageofoverlappingtokensinthetestarticle.Wecanseetheentireoverallcoveragewas73.6%inthissample.Thefigureinthefourthcolumnindicatesthattokensinthearticleareoverlapping1.23timesoftheexpectedvalue.Also6.01and2.40timesofexpectednumberofoverlappingtokensarefoundinthearticleinfrequencyrangesfrom1to49andfrom50to99,respectively.Asmentionedbefore,theresultforwordswhosefrequencyrangesbetween1to49cannotbeevaluateddirectlybythefigure.Asthemethodtofindtheclosestclusterislikethesinglelinkagetechnique,sothewordsintheclosestarticleisusedintheclustersearch.Thenumberoftokensoverlappingbetweenthetestarticleandtheclosestarticleinfrequency1to50,i.e.numberoftokensusedinthesimilaritycalculation,is3forthissample(notshowninthetable).Thismeansthatoutof5overlappingtokensbetweenthetestarticleandtheclosestcluster,3tokensarefoundintheclosestarticleandtheother2tokensarefoundintherestofthearticlesinthecluster.Sothesefiguresshowthebenefitoftheclusteringinincreasingtheoverlappingtokens.Theaverageofthecoverageandtheratiothroughoutthe236testarticlesaregiveninTable.Notethat,8articlescan'tfindtheirclosestclustersbecauseofthethresholds.Thesecondcolumnofthetableshowsthepercentageofoverlappingtokensinthetestarticles,andthethirdcolumnshowstheaverageratioofoverlappingtokenstoexpectedoverlappingtokens.FromthefiguresinTable,wecanobservethesuccessofthemethod.Forexample,tokenswhosefrequencyrangefrom50to99arefoundwith1.94timesoftheexpectedvalueintheclosestcluster.Alsotheratioinrangefrom100to199is1.90,whichiswellmorethan1.0.Thesecanbeexplainedbysayingthatlowerfrequencywordsco-occurtogethermorethanexpected.Thisistheveryfactthatwehadexpectedandprovetheexistenceofsublanguage.Ontheotherhand,ratioathigherfrequencyisabout100%.Itmeansthenumberofthesewordsarealmostsameasthatofexpected.Thiscanbeunderstandable,becausemanyhighfrequencywordsareclosedclasswordsandthesewordscanoccurinanyofthearticles.Sotheexpectednumberofoverlappingisaboutthesameasthenumberoftokens,ascanbeseeninTable.Actually,almostallofthewordswhosefrequencyismorethan1000areclosedclasswords,like``the'',``of''or``it''andoccurinmanyofthearticles(thereareonly68wordswhichhavefrequenciesover1000.Thetotalnumberofwordsis39217).</section>
  <section title="Experiment with First Two Sentences">ForsomeN.L.P.applications,itmaybeimpossibletoseeallthesentencesofatextinadvanceoftheprocessing.Forexample,spontaneousspeechrecognitionsystemshavetoprocesseachutteranceatatime.Thealgorithmdescribedabovecan'tbeappliedtotheseapplicationsdirectly,becausethesystemcan'tpre-scanthematerialbeforetheprocessing.Thereforeweconductedanexperimentusingthefirsttwosentencesinthetestarticles,insteadofallthesentencesinthearticle,tofindtheclosestcluster.Thisprocesscanbecalleddynamicsublanguageidentification,becauseitutilizestheknowledgewhichcouldbeacquiredduringtheprocess.Ifitcanfindagoodcluster(i.e.sublanguage)whichisusefulfortherestofthearticle,wecansaythedynamicsublanguageidentificationiswellperformed.Tableshowstheresultofthisexperiment.Surprisingly,theresultisalmostthesameasthepreviousone.Actually,72.5%ofthetestarticles(177outof244articles)selectthesameclusterwhichwasselectedinthepreviousexperiment.Thisresultisintuitivelyunderstandable,becausethefirstsentencesinnewspaperarticlesnormallyindicateitstopicandthesentencescouldbehelpfultoidentifyitssublanguage.Thisresultindicatesthatthismethodcanbeapplicabletospeechrecognitionsystemsorothersinwhichitisimpossibletopre-scanallthesentencesbeforeprocessing.</section>
  <section title="Discussion">Wepropose``Inductivedefinitionofsublanguage''and``Dynamicsublanguageidentification''.Wedon'tdenythemetricoftheconventionalapproachtosublanguagedefinition.Obviously,thedomainofatextisoneoftheveryimportantkeysofsublanguagedefinition.However,theinductivedefinitioncouldbeusefulinsituationswherethedomainnameisnotavailableorthedomaindefinitionistoovague.Ourresultssuggestthattheperplexitymeasurementcanplayasignificantroleinautomatingthedefinitionprocess.Thisisoneofthefruitfulresultsinthispaper.Theresultofsublanguageidentificationusingthefirsttwosentencessuggeststhepossibilityofpracticalapplicationsofthismethod.Forexample,wecanconstructanadaptablemachinetranslationsystem,whichcantakeinputsfromanykindsofsubjectdomainorsublanguage.Thesystemwouldfindwhichsublanguagetheinputbelongstoinitsinitialprocess,andadaptknowledgeofthesublanguagetoanalyzethefollowingsentences.Intuitively,thisprocedurelooksverysimilartowhatahumanisdoing.Asitiseasilyinferablefromthesublanguageliterature,thedefinitionofsublanguagemaydifferbasedonitsobjectiveorusage.Inthisexperiment,thesublanguagenotionisaimedtoutilizelanguagerestrictions(wordusage),sotheinductivedefinitionbasedonlexicalappearanceissuitable.Inthefuture,wecouldprobablyextendthistechniquebyusingothersublanguagecharacteristics,i.e.syntacticandsemanticrestrictions.OneoftherecentcorpusobservationbyGaleetal.supportstheusefulnessofsemanticrestrictions.Furthermore,wecouldseekahybridconceptofthetwo,deductiveandinductivesublanguagedefinitions,inordertomaximizetheprofitofthesublanguagenotion.Wecanidentifyseveraldirectionsforfuturestudy.Oneis,ofcourse,torefinethealgorithmandtomakelargerexperiments.Withregardtoapplications,ashasbeenrepeatedlymentioned,speechrecognitionisoneofthemostinterestingapplications.Theresultofthatsortofexperimentsmaytellusmuchmoreaboutthevalueofthisapproach.Thewayinwhichitisappliedmayheavilydependonthefeaturesoftheapplicationsystem.However,webelievethatsublanguageconceptisoneofthecommonproblemsformanykindofN.L.P.systems.</section>
  <section title="Conclusion">Inconclusion,itappearsthattheinductivedefinitionofsublanguagecouldbecomerealisticbyusinglargescalecorpus.Thiswouldbeverybeneficialfornaturallanguageprocessingsincetheevaluationresultsshowthatautomaticallyidentifiedsublanguageknowledgeisusefulinprocessingofanewtext.Thesecondexperimentprovesthatthemethodisapplicablenotonlyforstaticapplicationswhichcanpre-scanthematerialbeforeitsactualprocessing,butalsoforapplicationswhichprocessthesentencesequentially,suchasaspeechrecognitionsystem.</section>
  <section title="Acknowledgments">TheworkreportedherewassupportedbytheAdvancedResearchProjectsAgencyundercontractDABT63-93-C-0058fromtheDepartmentoftheArmy.WewouldliketothankourcolleaguesatNYU,inparticularProf.Grishman,whosecommentshavebeenveryuseful.document</section>
</root>
