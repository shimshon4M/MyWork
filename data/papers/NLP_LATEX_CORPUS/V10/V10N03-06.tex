



\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{87}
\setcounter{巻数}{10}
\setcounter{号数}{3}
\setcounter{年}{2003}
\setcounter{月}{4}
\受付{2002}{4}{30}
\再受付{2002}{9}{27}
\採録{2002}{11}{12}

\setcounter{secnumdepth}{1}

\title{用例に基づく手法と機械学習モデルの\\組み合せによる訳語選択}
\author{内元 清貴\affiref{CRL} \and 関根 聡\affiref{NYU} 
  \and 村田 真樹\affiref{CRL} \and 井佐原 均\affiref{CRL}}

\headauthor{内元，関根，村田，井佐原}
\headtitle{用例に基づく手法と機械学習モデルの組み合せによる訳語選択}

\affilabel{CRL}{独立行政法人通信総合研究所}
{Communications Research Laboratory}
\affilabel{NYU}{ニューヨーク大学コンピュータサイエンス学科}
{Computer Science Department, New York University}

\jabstract{
  本論文では，機械翻訳における訳語選択の手法について述べる．
  我々のシステムは，入力文と対象単語が与えられたとき，
  翻訳メモリと呼ばれる対訳用例集合と入力文との類似度を求め，
  類似度が最大となる用例集合を用いて対象単語の訳語選択を行なう．
  類似度は，用例に基づく手法と機械学習モデルを用いて計算される．
  類似度の計算には，文字列の類似性や入力文における対象単語周辺の単語，
  入力文中の内容語とその訳語候補の対訳コーパスおよび日英の単言語コーパスに
  おける出現頻度などを考慮する．
  入力文と対象単語が与えられると，
  まず用例に基づく手法を適用し，類似した用例が見つからなかった場合に
  機械学習モデルを適用する．機械学習モデルは複数用意し，クロスバリデーション
  などにより単語毎に最適な学習モデルを選択する．
  本論文では，2001年の春に開催された単語の多義性解消のコンテスト
  第2回\sc{Senseval}での結果をもとに，提案手法の有効性と，
  どのような情報が精度向上に有効であったかについて述べる．
}

\jkeywords{訳語選択，用例に基づく手法，
  機械学習モデル，対訳コーパス，単言語コーパス}

\etitle{Word Translation\\ by Combining an Example-Based Method\\
  and Machine Learning Models}
\eauthor{Kiyotaka Uchimoto\affiref{CRL} \and Satoshi Sekine\affiref{NYU} 
  \and Masaki Murata\affiref{CRL} \and Hitoshi Isahara\affiref{CRL}} 

\eabstract{
  We describe the method for word selection in machine translation. 
  Given an input sentence and a target word in the sentence, 
  our system first estimates the similarity 
  between the input sentence and parallel example sets called 
  ``Translation Memory.''  
  It then selects an appropriate translation of the target word 
  by using the example set with the highest similarity. 
  The similarity is calculated using an example-based method 
  and a machine learning model, which assesses the similarity 
  based on the similarity of a string, words to the left 
  and right of the target word in the input sentence, 
  frequencies of content words of the input sentence 
  and those of their translation candidates 
  in bilingual and monolingual corpora in English and Japanese. 
  Given an input sentence and a target word in the sentence,
  an example-based method is applied to them in the first step. 
  Then, if an appropriate example set is not found, a machine learning model 
  is applied to them. The most appropriate machine learning model is selected 
  for each target word from several machine learning models 
  by a certain method such as cross-validation on the training data. 
  In this paper, we show the advantage of our method 
  and also show that what kinds of information contributed 
  to improving the accuracy based on the results of the second 
  contest on word sense disambiguation, {\sc Senseval-2}, 
  which was held in Spring, 2001. 
}

\ekeywords{Word translation, Example-based method, 
  Machine learning models, Bilingual corpora, Monolingual corpora}

\input{prepictex}
\input{pictexwd}
\input{postpictex}
\def\q{}
\def\p{}

\begin{document}
\thispagestyle{empty}
\maketitle


\section{はじめに}
\label{sec:introduction}

単語の多義性解消は自然言語処理の重要な基本技術のひとつとして認識されている．
単語の多義性というのは，例えば，「買う」という単語について「本を買う」と
「反感を買う」とでは意味が違うというように，同じ単語でも文脈によって意味の違い
があるという性質のことを言う．そして，その意味の違いのことを単語の多義と言う．
単語の多義は細かく定義すればきりがない．
したがって，多義をどこまで区別するべきかはタスクの目的に依存して決めることに
なる．

機械翻訳の問題では，適切な翻訳(訳語/訳句)が選択できればよく，
単語の多義はその翻訳の異なりとして定義できる．
機械翻訳における単語の多義性解消の方法，
つまり，訳語選択の方法は，これまでにも数多く提案されてきた．
それらの方法を，利用している言語資源という観点から分類すると，
対訳コーパスを用いるもの
\cite{Nagao81,Sato90,Brown:90,Brown:93,berger:cl96,Sumita:2000,Baldwin:2001}，
対訳単語辞書と目的言語の単言語コーパスを用いるもの
\cite{Dagan:cl94,Kikui:98}，
対訳単語辞書と，
原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いるもの
\cite{Kikui:99,Koehn:2000}，
原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いるもの
\cite{Tanaka:96}
に大別できる．
我々は，多様な情報を用いれば用いるほど良い結果が得られると考え，
対訳単語辞書，対訳コーパス，および，
原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いる．
対訳コーパスには
大きくパラレルコーパスとコンパラブルコーパスの二種類があり，
我々はそのうちパラレルコーパスを用いる．
さらに，文対応をとる際の誤りを軽減するために，
パラレルコーパスとして，
対訳用例(句/文)集合(翻訳メモリ，トランスレーション・メモリー，以下TM)を用いる．

我々のシステムは，入力文と対象単語が与えられると，
その対象単語に関して入力文と対訳用例集合との類似度を求め，
類似度が最大となる用例集合を用いて対象単語の訳語選択を行なう．
類似度は，用例に基づく手法と機械学習モデルを用いて計算される．
類似度の計算には，文字列の類似性，入力文における対象単語の前後の数単語，
入力文中の内容語とその訳語候補のコーパスにおける出現頻度などを考慮する．
このシステムで用いた訳語選択のためのモデルは次のような特徴を持つ．
\begin{itemize}
\item 各対訳用例内の単語対応をとり，
  同じ対訳単語ペアを持つ対訳用例をまとめてひとつの用例集合とする．
  そして，そのペアの原言語(対象単語と同じ言語)の単語が同じである
  用例集合をまとめ，そのまとまりごとにモデルを作成する．

  以降で，各用例集合内で共通する対訳単語ペアを見出し語と呼ぶ．
  そして，そのペアの各単語をそれぞれ原言語見出し語，目的言語見出し語と呼ぶ
  (原言語が日本語，目的言語が英語の場合，それぞれ日本語見出し語，
  英語見出し語と呼ぶ)．
\item 対象単語に関して入力文と表層的にほぼ同じ用例が
  用例に基づく手法により見つかった場合にはその用例を優先的に翻訳に使う．
  見つからなかった場合には，機械学習モデルに基づく手法により
  対象単語に関して入力文と最も類似した用例集合を選択して翻訳に使う．
\item 言語資源としては，
  対訳単語辞書，対訳コーパス，および，
  原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いる．
\end{itemize}

2001年の春，単語の多義性解消のコンテスト第2回{\sc Senseval}が開催された
\cite{senseval2:homepage}
．
このコンテストは1998年に，英語と二つのヨーロッパ言語(イタリア語とフランス語)
を対象として始まったものである．
2001年には新たに他のいくつかの言語に関するタスクが追加された．
我々はそのうち日本語に関して追加された翻訳タスクに参加した．
本論文では，そのコンテストでの結果をもとに，我々が本論文で提案する手法の
有効性および精度向上にどのような情報が有効であったかについて述べる．

\section{{\sc Senseval}日本語翻訳タスク}

このタスクでは，単語の多義は翻訳(訳語/訳句)として定義された．

コンテストでは，予め日英のTMが訓練データとして配布された．
具体的には，TMでは，日本語見出し語に対して，
それを含む日本語表現とその英語翻訳のペア(以下これを用例と呼ぶ)の集合が
与えられた．図~\ref{fig:tm_example} がそのTMのサンプルである．

\begin{figure*}[htbp]
  \begin{center}
    \begin{tabular}[c]{l}
      $<$entry id=``1'' headword=``遠慮''$>$\\
      \q  $<$sense id=``1-1''$>$\\
      \q\q    $<$jexpression$>$母に遠慮する$<$/jexpression$>$\\
      \q\q    $<$eexpression$>$to feel constrained for one's mother
      $<$/eexpression$>$\\
      \q  $<$/sense$>$\\
      \q  $<$sense id=``1-2''$>$\\
      \q\q    $<$jexpression$>$母への遠慮$<$/jexpression$>$\\
      \q\q    $<$eexpression$>$constraint toward one's mother
      $<$/eexpression$>$\\
      \q\q    $<$transmemo$>$UC$<$/transmemo$>$\\
      \q  $<$/sense$>$\\
      \q  $<$sense id=``1-3''$>$\\
      \q\q    $<$jexpression$>$献金を遠慮してもらう$<$/jexpression$>$\\
      \q\q    $<$eexpression$>$to request to refrain from donation
      $<$/eexpression$>$\\
      \q  $<$/sense$>$\\
      \q  ......\\
      $<$/entry$>$\\
    \end{tabular}
    \caption{TMの例}
    \label{fig:tm_example}
  \end{center}
\end{figure*}

コンテストのテストでは，対象単語にマークのついたテスト文章が配布された．
参加者には，対象単語に対して，その翻訳に利用できるTMの用例番号，または，
翻訳そのものを提出することが求められた．
翻訳の場合は，その語単独の翻訳でも，前後の適当な範
囲の翻訳でも，文全体の翻訳でもよいものとされた．

テストの各対象単語には正解が用意された．正解は必ずしもひとつではなく，
複数の場合もある．
評価は，システムの出力のうち正しく推定できたものの割合(精度)により行なわれた．
システムの出力がTMの用例番号の場合は，
その出力が正解のいずれかと一致するとき，正しく推定できたものと見なされた．
システムの出力が翻訳の場合は，すべての可能な翻訳を用意することは難しいため，
その出力が正しいかどうかは人間の判断に委ねられた．

\section{訳語選択モデル}
\label{sec:model}

入力文と対象単語が与えられたとき，対象単語の適切な訳語を選択するタスクを
考える．そして，このタスクで，対象単語に関して入力文との類似度が最大となる
用例あるいは用例集合を用いて対象単語の訳語を選択するモデルを考える．
本論文ではこのモデルを訳語選択モデルと呼ぶことにする．
以降では，原言語として日本語を，翻訳の目的言語として英語を仮定して説明する．
入力文と用例との類似度は次の二つの方法により求める．
\begin{enumerate}
\item 文字列の類似性に基づく方法 (手法1)

  類似度は，入力文と日本語用例との間で一致した文字列に基づいて計算する．

\item 機械学習モデルに基づく方法 (手法2)

  類似度は，対象単語の各訳語候補に対して機械学習モデルにより求められる
  確率値あるいは確信度と定義する．

\end{enumerate}

入力文と対象単語が与えられたとき，まず手法1で対象単語に関して
入力文との類似度が閾値以上となる用例があるかどうかを調べ，
ある場合はその類似度が最大となる用例の番号あるいはその用例の英語見出し語を
出力し，ない場合は，手法2で対象単語に関して入力文と最も類似した用例集合を
選択し，その英語見出し語を出力する．

以降で，各方法について詳細に述べる．

\subsection{文字列の類似性に基づく方法(手法1)}
\label{sec:metho1}

対象単語に関して入力文との類似度が高い日本語用例があれば，
TMを信頼しその用例の番号あるいはその英語見出し語を出力する．

入力文と一致する割合を調べる際，日本語用例には文末処理(句末の場合も含む)を
施しておく．文末処理としては，機能語，動詞や形容詞の活用部分，
サ変動詞をすべて削除するということを行なった．
例えば，図~\ref{fig:tm_example} の用例にこの文末処理を施すと
それぞれ，「母に遠慮」「母への遠慮」「献金を遠慮」となる．
入力文との一致する割合は，
動的計画法により入力文と日本語用例を文字単位で比較して差異を求め，
一致した文字列の割合として求める．実験では，この差異を
UNIXのdiffコマンドを用いて求めた
\footnote{
  文献\cite{murata2002_mdiff}には，
  差異の抽出にdiffコマンドが利用できるような自然言語処理の例が
  いくつかあげられている．
}．
類似度は以下の式により求める．
\begin{eqnarray}
  \label{eq:sim1}
  類似度 & = & 
  \frac{入力文との{\rm diff}をとったときに一致した文字数}
  {文末処理を施した日本語用例の文字数}
\end{eqnarray}
このとき，用例が複数の部分に分割されて一致する場合があり，
類似度が大きくても多くの部分に分割されてしまう場合は
類似用例としてふさわしくない場合が多い．
そこで，分割数に閾値を設け，閾値より分割数が多い用例は選択対象外とする．
類似度が最大となる用例が複数ある場合には，
最長の日本語用例を持つ用例の番号を返す．
ただし，一致した部分が日本語見出し語の長さより長い場合に限る．

しかしながら，TMに全ての可能な用例を登録することは難しく，
常に入力文と表層的にほぼ同じものがあることは期待できないため，
類似度が最大となる用例が常に訳語選択に最適な用例であるとは限らない．
そこで，類似度に閾値を設け，閾値以上の類似度を持つ用例がない場合は
次節に述べる方法を用いる．

\subsection{機械学習モデルに基づく方法(手法2)}
\label{sec:method2}

入力文と表層的にほぼ同じ用例がない場合，
より多様な情報を用いて類似度を求める必要があると考えられるが，
そのために複雑な規則を作成するのは避けたいため，
類似度の計算には機械学習モデルを用いることにした．

機械学習モデルによって分類するクラスは対象単語の訳語/訳句候補とした．
訳語選択モデルは，\ref{sec:introduction}節でも述べたように，
同じ日英対訳単語ペアを持つ対訳用例をまとめてひとつの用例集合とし，
そのペアの日本語単語が同じである用例集合をまとめ，そのまとまりごとに作成する．
したがって，各モデルでは，同じ見出し語を持つ用例は同じクラスとなり，
入力文に対しすべて同じ類似度となる．
そして，日英の見出し語つまり各用例集合内で共通する対訳単語ペアのうち，
日本語見出し語は共通で，英語見出し語が訳語/訳句候補となるため，
各用例集合の英語見出し語がモデルにより分類するクラスとなる．
TMでは見出し語は予め人手で与える．
例えば，図~\ref{fig:tm_example} の場合，日本語見出し語は「遠慮」
であり，英語見出し語はそれぞれ，「feel constrained」，
「constraint」，「refrain」となる．これらを$<$ehead$>$$<$/ehead$>$のタグで
明示すると図~\ref{fig:tm_example2} のようになる．
英語見出し語が動詞の場合はすべての語尾変化形を基本形で代表させる．
さらに，TMの各日本語見出し語を対訳辞書で索き，TMになかった訳語/訳句候補が
見つかれば，それらも新たなクラスとして追加する．
\begin{figure*}[htbp]
  \begin{center}
    \begin{tabular}[c]{l}
      $<$entry id=``1'' headword=``遠慮''$>$\\
      \q  $<$sense id=``1-1''$>$\\
      \q\q    $<$jexpression$>$母に遠慮する$<$/jexpression$>$\\
      \q\q    $<$eexpression$>$to $<$ehead basic=``feel constrained''$>$\\
      \q\q    feel constrained$<$/ehead$>$ for one's mother$<$/eexpression$>$\\
      \q  $<$/sense$>$\\
      \q  $<$sense id=``1-2''$>$\\
      \q\q    $<$jexpression$>$母への遠慮$<$/jexpression$>$\\
      \q\q    $<$eexpression$>$$<$ehead basic=``constraint''$>$constraint$<$/ehead$>$ \\
      \q\q    toward one's mother$<$/eexpression$>$\\
      \q\q    $<$transmemo$>$UC$<$/transmemo$>$\\
      \q  $<$/sense$>$\\
      \q  $<$sense id=``1-3''$>$\\
      \q\q    $<$jexpression$>$献金を遠慮してもらう$<$/jexpression$>$\\
      \q\q    $<$eexpression$>$to request to 
      $<$ehead basic=``refrain''$>$refrain$<$/ehead$>$ \\
      \q\q    from donation$<$/eexpression$>$\\
      \q  $<$/sense$>$\\
      \q  ......\\
      $<$/entry$>$\\
    \end{tabular}
    \caption{TMの例}
    \label{fig:tm_example2}
  \end{center}
\end{figure*}

学習には，TMの用例だけでなく，他の対訳辞書あるいは対訳コーパスから
抽出した用例も用いる．
抽出する用例は，TMの各用例集合と同じ日英見出し語を含む対訳用例とし，
抽出した用例はTMの各用例集合に追加する．

以降で，用例数および学習文数は，
ともに各日本語見出し語に対しその語を含む用例の数を意味するものとし，
TMに最初に含まれていた用例の総数を用例数，
他の言語資源から抽出して追加した後の用例の総数を学習文数と呼んで区別する．
また，クラス数とは各日本語見出し語に対するクラスの数つまり，
訳語/訳句候補の種類の数を意味するものとする．

機械学習モデルとしては SVM (Support Vector Machine)，
ME (Maximum Entropy)，DL (Decision List)，SB (Simple Bayes)を用いる．
日本語見出し語ごとに，各モデルを用いて学習データでクロスバリデーション
を行ない，平均精度が最も高いモデルをテストに用いる．
各クラスの確率値あるいは確信度は基本的に，
文脈の集合を$B$，クラスの集合を$A$とするとき，
文脈$b (\in$$B)$でクラス$a (\in$$A)$となる事象$(a,b)$の確率分布$p(a,b)$として
求められる．SVMではこのような確率分布は得られないが，
便宜的に最適のクラスに対して確信度を1，その他のクラスに対して0とする．

次に，各機械学習モデルの説明，各種パラメータ等の設定について述べる
\footnote{基本的に文献\cite{Murata2001a}の方法に準ずる．}．

\subsubsection{シンプルベイズ}

このモデルでは，ベイズの定理に基づき，
文脈$b$のときにクラス$a$が生起する確率を推定する．
そして，確率値が最も大きいクラスを最適なクラスとする．
文脈$b$のときにクラス$a$が生起する確率は次の式で与えられる．
{
\begin{eqnarray}
  p(a|b)  & = & \frac{p(a)}{p(b)}p(b|a)\\ 
  \label{eq:simple_bayes}
  & \simeq & \frac{\tilde{p}(a)}{p(b)} \prod_i \tilde{p}(f_i|a)
\end{eqnarray}
}
ここで文脈$b$は，
予め設定しておいた素性$f_j (\in F, 1\leq j\leq k)$の集合である．
$p(b)$は，文脈$b$の生起確率で，
今回の場合，クラス$a$には依存せず定数のため計算しない．
$\tilde{p}(a)$と$\tilde{p}(f_i|a)$は，
ともに学習データから推定される確率で，それぞれ，
クラス$a$の出現の確率，クラス$a$のときに素性$f_i$を持つ確率を意味する．
最尤推定により求めた$\tilde{p}(f_i|a)$の値は0になることが多く，
式(\ref{eq:simple_bayes})の値が0になり本来求めるべきクラスが
正しく求まらない場合が多い．
このため，本論文では次の式によりスムージングを行なう．
{
\begin{eqnarray}
  \label{eq:simple_bayes2}
  \tilde{p}(f_i|a) = \frac{freq(f_i,a)+\epsilon*freq(a)}{freq(a)+\epsilon*freq(a)}
\end{eqnarray}
}
ここで，$freq(f_i,a)$と$freq(a)$は，それぞれ，
素性$f_i$を持ちかつクラスが$a$である事例の個数，
クラスが$a$である事例の個数を意味する．
$\epsilon$は実験で定める定数であり，実験では0.0001に固定した．

\subsubsection{決定リスト}

このモデルでは，素性$f_i$とクラス$a$の組を規則として，
予め定めた優先順序でリストに蓄えておき，
リストで優先順位の高いところから，
入力と素性が一致する規則を適用してクラスを求める\cite{Yarowsky:ACL94}．
本論文では優先順序として次の式で表わされるものを用いる．
{
\begin{eqnarray}
  \label{eq:decision_list_order}
  \tilde{p}(a|f_i)
\end{eqnarray}
}
これは，ある文脈$b$でクラス$a$を出力する確率$p(a|b)$がもっとも高い
クラス$a$を解とすることと等価であり，
本論文では次の式を用いて最適なクラスを特定する．
{
\begin{eqnarray}
  \label{eq:decision_list}
  p(a|b) = \tilde{p}(a|f_{max})
\end{eqnarray}
}
ここで，$f_{max}$ は次の式によって与えられる．
{
\begin{eqnarray}
  \label{eq:decision_list2}
  f_{max} = argmax_{f_j\in F} \ max_{a_i\in A} \ \tilde{p}(a_i|f_j)
\end{eqnarray}
}
また，$\tilde{p}(a_i|f_j)$ は学習データで素性$f_j$を
文脈とするクラス$a_i$の出現の割合である．

\subsubsection{最大エントロピーモデル}

このモデルでは，素性$f_j (1\leq j\leq k)$の集合を$F$とするとき，
式(\ref{eq:constraint})を制約とし，式(\ref{eq:entropy})
で表わされる目的関数つまりエントロピーを最大にするような確率分布$p(a,b)$を
求め，その確率分布にしたがって求まる各クラスの確率のうち，
最も大きい確率値を持つクラスを最適なクラスとする
\cite{berger:cl96,ristad97,ristad98}．
{
\begin{eqnarray}
  \label{eq:constraint}
  \sum_{a\in A,b\in B}p(a,b)g_{j}(a,b) 
  \ = \sum_{a\in A,b\in B}\tilde{p}(a,b)g_{j}(a,b)\\
  \ for\ \forall f_{j}\ (1\leq j \leq k) \nonumber
\end{eqnarray}
}
{
\begin{eqnarray}
  \label{eq:entropy}
  H(p) & = & -\sum_{a\in A,b\in B}p(a,b)\ log\left(p(a,b)\right)
\end{eqnarray}
}
ただし，$A,B$はそれぞれクラスと文脈の集合を意味し，
$g_{j}(a,b)$は文脈$b$に素性$f_j$があってかつクラスが$a$の場合1となり
それ以外で0となる二値関数である．
また，$\tilde{p}(a,b)$は，既知データでの$(a,b)$の出現の割合を意味する．

\subsubsection{サポートベクトルマシン}

サポートベクトルマシンとは，空間を超平面で分割することにより
2つのクラスからなるデータを分類する二値分類器のことである．
2つのクラスを正例，負例とすると，
学習データにおける正例と負例の間隔(マージン)を
最大にする超平面を求めそれを用いて分類を行なう．
通常は，学習データにおいてマージンの内部領域に
少数の事例が含まれてもよいとする拡張(ソフトマージン)や，
超平面の線形の部分を非線型とする拡張(カーネル関数の導入)などがなされたものが
用いられる．
これらの拡張によりクラスを判別することは，
以下の識別関数の出力値が正か負かによってクラスを判別することと等価である
\cite{SVM,kudoh_svm}．
{
\begin{eqnarray}
  \label{eq:svm1}
  f({\bf x}) & = & sgn \left( \sum^{l}_{i=1} \alpha_i y_i K({\bf x}_i,{\bf x}) + b \right)\\
  b & = & -\frac{max_{i,y_i=-1}b_i + min_{i,y_i=1}b_i}{2}\nonumber\\
  b_i & = & \sum^l_{j=1} \alpha_j y_j K({\bf x}_j,{\bf x}_i) \nonumber
\end{eqnarray}
}
ここで${\bf x}$ は識別したい事例の文脈(素性の集合)を，
${\bf x}_{i}$と$y_i(i=1,...,l, y_i\in\{1,-1\})$は
学習データの文脈とクラスを意味する．また，関数$sgn(x)$は，
$x \geq 0$のときに1，$x < 0$のときに$-1$となる二値関数であり，
各$\alpha_i$は式(\ref{eq:svm5})と式(\ref{eq:svm6})の制約のもと
式(\ref{eq:svm4})の$L(\alpha )$を最大にするものである．
{
\begin{eqnarray}
  \label{eq:svm4}
  L({\alpha}) & = & \sum^l_{i=1} \alpha_i - \frac{1}{2} \sum^l_{i,j=1} \alpha_i \alpha_j y_i y_j K({\bf x_i},{\bf x_j})
\end{eqnarray}
}
{
\begin{eqnarray}
  \label{eq:svm5}
  0 \leq \alpha_i \leq C \, \, (i=1,...,l)
\end{eqnarray}
}
{
\begin{eqnarray}
  \label{eq:svm6}
  \sum^l_{i=1} \alpha_i y_i = 0 
\end{eqnarray}
}
また，関数$K$はカーネル関数と呼ばれ様々なものが提案されているが，
本論文では次の式で表わされる多項式カーネルを用いる．
{
\begin{eqnarray}
  \label{eq:svm3}
  K({\bf x},{\bf y}) & = ({\bf x}\cdot{\bf y} + 1)^d
\end{eqnarray}
}
ここで，$C,d$は実験的に設定される定数である．
本論文では$C$,$d$はそれぞれ1と2に固定した．

サポートベクトルマシンは二値分類器であるため，
クラスの数が2であるデータしか扱えないが，
これにペアワイズ手法を組み合わせることにより，
クラスの数が3以上のデータを扱えるようになる\cite{kudoh_chunk_nl2000}．

ペアワイズ手法とは，N個のクラスを持つデータの場合，
異なる二つのクラスのあらゆるペア(N(N-1)/2 個)を作り，
各ペアごとにどちらがよいかを
サポートベクトルマシンなどの二値分類器で求め，
最終的にN(N-1)/2個の二値分類器のクラスの多数決により，
最適なクラスを求める方法である．

実験では，サポートベクトルマシン(TinySVM\cite{kudoh_svm}を利用)
とペアワイズ手法を組み合わせて用いた．

\subsubsection{素性}

上述のように文脈$b$は素性の集合で表わされる．
実験に用いた素性は以下のものである．

\begin{enumerate}
\item 形態素情報(素性集合1)

  入力文における対象単語の前後三形態素ずつについて
  の文字列，基本形，品詞(大分類，細分類)，活用型，活用形．

\item 最大一致となる用例に関する情報(素性集合2)

  入力文の文字列と連続して一致する部分が最大となる用例を調べ，
  その用例の英語見出し語および一致した長さをそれぞれ素性として用いる．

\item 内容語とその訳語候補の出現頻度(素性集合3)

  まず，各英語見出し語(各クラス)ごとに次の六種類の文集合を定義する．
  \begin{enumerate}
  \item 文集合1 : 該当する英語見出し語を含む用例において日本語用例を
    取り出した集合
  \item 文集合2 : 該当する英語見出し語を含む用例において英語用例を
    取り出した集合
  \item 文集合3 : 文集合1の類似文の集合．
    類似文は日本語の単言語コーパスから抽出する．
  \item 文集合4 : 文集合2の類似文の集合．
    類似文は英語の単言語コーパスから抽出する．
  \item 文集合5 : 文集合1と文集合3の和集合
  \item 文集合6 : 文集合2と文集合4の和集合
  \end{enumerate}

  ある用例の類似文とは，
  その用例の見出し語とその単語のまわりの文脈の一部を含む文とする．

  入力文における各内容語とその訳語候補について，
  上記の各文集合における出現頻度を調べ，それぞれ素性として用いる．
  内容語は入力文を形態素解析したときに得られる単語のうち，その品詞が
  名詞，動詞，形容詞，副詞，連体詞であるものとする．ただし，対象単語は除く．
  内容語の訳語候補は内容語を対訳辞書で索いたときに候補としてあがる単語とする．
  この素性は文集合，英語見出し語，内容語の出現頻度の和，
  の組み合せによって表わされ，
  頻度の和がn回の場合，頻度1からnまでの素性値をもつ素性が
  すべて観測されたと仮定する．頻度は1以上のもののみ考慮する．
  例えば，入力文に見出し語以外の内容語がひとつあり，
  その内容語がクラス「buy」の文集合1に3回出現した場合には，
  「文集合1：buy：1」，「文集合1：buy：2」，「文集合1：buy：3」の
  素性が観測されたとする．
  この素性により，日英の各コーパスにおいて見出し語と
  共起する単語の頻度を訳語選択の手がかりとして考慮する．
\end{enumerate}

\section{実験と考察}
\label{sec:experiment}

\subsection{実験の条件}
\label{sec:test}

入力，評価は{\sc Senseval-2}日本語翻訳タスクのものに従った．
TMは320語のもの(1見出し語に対する用例数は約20)が2001年3月中旬に配布された．
この中から40語(名詞20語，動詞20語)がコンテストの対象単語として選択され，
それぞれについて30語(30出現)ずつテストデータが用意された．対象単語の
のべ数は1,200語であった．

対訳単語辞書および対訳コーパスとしてはニフティで利用可能な英辞郎を用いた．
ここから対訳用例を抽出する際，
日英見出し語が対応関係にないものを抽出してしまった場合でも，
抽出の際に検索語として用いた日英見出し語が正しい対応関係にあると
仮定して学習に用いた．
単言語コーパスとしては毎日新聞(1991年から2000年)，
日経新聞(1995年から1999年)，産経新聞(1994年から1999年)，
LDCデータ(1994年，1995年のデータで Wall Street Journal やAP通信，
ニューヨークタイムズなど数年分の新聞記事が含まれる)を用いた．

コンテストでは，
手法1で類似度最大として選択された用例についてはその用例番号を，
手法2で類似度最大として選択された用例集合についてはその英語見出し語を
出力して提出した．
以下にその際の条件について述べる．
手法1における類似度の閾値は1.0，分割数の閾値は0とした．
手法2の形態素解析にはJUMAN
\cite{JUMAN3.61}
を用いた．
手法2における類似文としては，
日本語用例に対しては，
文末処理を施して得られる文字列を含む文を，
英語用例に対しては，英語見出し語を含む文を抽出した．
機械学習モデルについては，時間の制約があったため，
単語によっては学習が終了しない場合があり，
クロスバリデーションにより最適なモデルを選択することはできなかった．
コンテストで最終的に選択したモデルの内訳は以下の通りであった．

\begin{itemize}
\item SVM : 23単語(名詞12，動詞11)
\item DL : 12単語(名詞8，動詞4)
\item SB : 5単語(動詞5)
\end{itemize}

\subsection{実験結果}
\label{sec:results}

コンテストの結果を表~\ref{tab:result} にあげる．
我々のシステムの精度は63.4\,\%であった．
単語ごとの精度と用例数，学習文数，クラス数との関係は
表~\ref{tab:result2} の通りである．

\begin{table}[htbp]
  \begin{center}
    \caption{コンテストの結果}
    \label{tab:result}
    \begin{tabular}[c]{|l|l|}
      \hline
      参加システム & 精度 \\
      \hline
      AnonymX & 79.1\,\% (949/1,200)\\
      AnonymY1 & 73.4\,\% (881/1,200)\\
      {\bf CRL-NYU} & {\bf 63.4\,\% (761/1,200)}\\
      Ibaraki & 62.6\,\% (751/1,200)\\
      Stanford-Titech1 & 49.1\,\% (589/1,200)\\
      AnonymY2 & 47.6\,\% (571/1,200)\\
      ATR & 45.8\,\% (549/1,200)\\
      Kyoto & 42.4\,\% (509/1,200)\\
      Stanford-Titech2 & 41.2\,\% (494/1,200)\\
      Baseline (Random) & 36.8\,\% \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

\begin{table*}[htbp]
  \footnotesize
  \begin{center}
    \caption{単語ごとの精度(コンテストの結果)}
    \label{tab:result2}
    \begin{tabular}[c]{|l@{}l@{ }|@{ }r@{ }|@{ }r@{ }|@{ }r@{ }|@{ }r@{ }|@{ }r@{ }|r@{ }r@{ }|r@{}r@{ }|r@{ }r@{ }|}
      \hline
      単語 & (読み) & \ 用例 & \ 学習文 & \ クラス & \ 学習文数
      & 学習 & 精度 & (手法 & 精度 & (手法1) & 精度 & (手法2) \\
      & & 数 & 数 & 数 & /クラス & \ モデル & & 1+2) & & & & \\ 
      \hline
      一般 & (ippan) & 33 & 760 & 16 & 47.5 & SVM 
      & 56.7\,\% & (17/30) & 66.7\,\% & (2/3) & 55.6\,\% & (15/27)\\
      一方 & (ippou) & 14 & 172 & 19 & 9.1 & DL 
      & 23.3\,\% & (7/30) & --- & & 23.3\,\% & (7/30) \\
      今 & (ima) & 15 & 433 & 15 & 28.9 & DL 
      & 63.3\,\% & (19/30) & --- & & 63.3\,\% & (19/30) \\
      意味 & (imi) & 22 & 419 & 18 & 23.3 & SVM 
      & 66.7\,\% & (20/30) & 100\,\% & (1/1) & 65.5\,\% & (19/29) \\
      核 & (kaku\_n) & 8 & 1,007 & 8 & 125.9 & SVM 
      & 80.0\,\% & (24/30) & 100\,\% & (3/3) & 77.8\,\% & (21/27) \\
      記録 & (kiroku) & 18 & 608 & 11 & 55.3 & SVM 
      & 80.0\,\% & (24/30) & 100\,\% & (1/1) & 79.3\,\% & (23/29) \\
      国内 & (kokunai) & 14 & 346 & 6 & 57.7 & SVM 
      & 83.3\,\% & (25/30) & 75.0\,\% & (3/4) & 84.6\,\% & (22/26) \\
      言葉 & (kotoba) & 35 & 925 & 28 & 33.0 & DL 
      & 80.0\,\% & (24/30) & 0\,\% & (0/1) & 82.8\,\% & (24/29) \\
      市民 & (shimin) & 23 & 187 & 8 & 23.4 & DL 
      & 50.0\,\% & (15/30) & 100\,\% & (5/5) & 40.0\,\% & (10/25) \\
      事業 & (jigyou) & 17 & 854 & 14 & 61.0 & SVM 
      & 63.3\,\% & (19/30) & 100\,\% & (7/7) & 52.2\,\% & (12/23) \\
      時代 & (jidai) & 39 & 621 & 10 & 62.1 & DL 
      & 83.3\,\% & (25/30) & 100\,\% & (4/4) & 80.8\,\% & (21/26) \\
      姿 & (sugata) & 28 & 139 & 19 & 7.3 & SVM 
      & 46.7\,\% & (14/30) & 80.0\,\% & (4/5) & 40.0\,\% & (10/25) \\
      近く & (chikaku) & 15 & 123 & 11 & 11.2 & SVM 
      & 73.3\,\% & (22/30) & --- & & 73.3\,\% & (22/30) \\
      中心 & (chushin) & 15 & 392 & 16 & 24.5 & SVM 
      & 56.7\,\% & (17/30) & --- & & 56.7\,\% & (17/30) \\
      花 & (hana) & 27 & 677 & 20 & 33.9 & SVM 
      & 83.3\,\% & (25/30) & 100\,\% & (2/2) & 82.1\,\% & (23/28) \\
      反対 & (hantai) & 26 & 480 & 17 & 28.2 & SVM 
      & 93.3\,\% & (28/30) & 71.4\,\% & (5/7) & 100\,\% & (23/23) \\
      場合 & (baai) & 23 & 1,167 & 16 & 72.9 & DL 
      & 86.7\,\% & (26/30) & --- & & 86.7\,\% & (26/30) \\
      前 & (mae) & 25 & 1,968 & 26 & 75.7 & DL 
      & 63.3\,\% & (19/30) & --- & & 63.3\,\% & (19/30) \\
      胸 & (mune) & 30 & 368 & 26 & 14.2 & DL 
      & 53.3\,\% & (16/30) & 100\,\% & (3/3) & 48.1\,\% & (13/27) \\
      問題 & (mondai) & 32 & 1,795 & 10 & 179.5 & SVM 
      & 100\,\% & (30/30) & 100\,\% & (2/2) & 100\,\% & (28/28) \\
      \hline
      全名詞 & & 459 & 13,441 & 304 & 44.2 & 
      & 69.3\,\% & ($\frac{416}{600}$) 
      & 87.5\,\% & ($\frac{42}{48}$) & 67.8\,\% & ($\frac{374}{552}$) \\
      \hline
      与える & (ataeru) & 36 & 808 & 34 & 23.8 & SVM 
      & 70.0\,\% & (21/30) & 100\,\% & (3/3) & 66.7\,\% & (18/27)\\
      言う & (iu) & 32 & 2,248 & 21 & 107.0 & DL 
      & 73.3\,\% & (22/30) & 50.0\,\% & (1/2) & 75.0\,\% & (21/28) \\
      受ける & (ukeru) & 22 & 5,143 & 25 & 205.7 & SB 
      & 20.0\,\% & (6/30) & 50.0\,\% & (1/2) & 17.9\,\% & (5/28) \\
      描く & (egaku) & 12 & 271 & 14 & 19.4 & SVM 
      & 76.7\,\% & (23/30) & 100\,\% & (1/1) & 75.9\,\% & (22/29) \\
      買う & (kau) & 31 & 1,117 & 19 & 58.8 & SVM 
      & 86.7\,\% & (26/30) & 100\,\% & (3/3) & 85.2\,\% & (23/27) \\
      書く & (kaku\_v) & 15 & 795 & 4 & 198.8 & SVM 
      & 76.7\,\% & (23/30) & 80.0\,\% & (4/5) & 76.0\,\% & (19/25) \\
      聞く & (kiku) & 25 & 536 & 14 & 38.3 & SVM 
      & 66.7\,\% & (20/30) & 100\,\% & (3/3) & 63.0\,\% & (17/27) \\
      超える & (koeru) & 14 & 109 & 10 & 10.9 & SVM 
      & 63.3\,\% & (19/30) & --- & & 63.3\,\% & (19/30) \\
      使う & (tsukau) & 19 & 1,139 & 14 & 81.4 & SVM 
      & 56.7\,\% & (17/30) & 100\,\% & (1/1) & 55.2\,\% & (16/29) \\
      作る & (tsukuru) & 19 & 834 & 17 & 49.1 & SB 
      & 10.0\,\% & (3/30) & 100\,\% & (2/2) & 3.6\,\% & (1/28) \\
      伝える & (tsutaeru) & 19 & 155 & 15 & 10.3 & DL 
      & 80.0\,\% & (24/30) & 100\,\% & (3/3) & 77.8\,\% & (21/27) \\
      出る & (deru) & 30 & 4,705 & 26 & 181.0 & SB 
      & 3.3\,\% & (1/30) & 100\,\% & (1/1) & 0\,\% & (0/29) \\
      乗る & (noru) & 23 & 712 & 17 & 41.9 & DL 
      & 53.3\,\% & (16/30) & 100\,\% & (8/8) & 36.4\,\% & (8/22) \\
      図る & (hakaru) & 17 & 3,184 & 17 & 187.3 & SB 
      & 2.7\,\% & (8/30) & 100\,\% & (8/8) & 0\,\% & (0/22) \\
      待つ & (matsu) & 23 & 618 & 15 & 41.2 & SVM 
      & 93.3\,\% & (28/30) & 100\,\% & (1/1) & 93.1\,\% & (27/29) \\
      守る & (mamoru) & 16 & 522 & 19 & 27.5 & SVM 
      & 46.7\,\% & (14/30) & 100\,\% & (3/3) & 40.7\,\% & (11/27) \\
      見せる & (miseru) & 20 & 285 & 12 & 23.8 & SVM 
      & 90.0\,\% & (27/30) & 100\,\% & (1/1) & 89.7\,\% & (26/29) \\
      認める & (mitomeru) & 10 & 929 & 13 & 71.5 & DL 
      & 66.7\,\% & (20/30) & 100\,\% & (1/1) & 65.5\,\% & (19/29) \\
      持つ & (motsu) & 59 & 1,835 & 23 & 79.8 & SB 
      & 46.7\,\% & (14/30) & 100\,\% & (3/3) & 40.7\,\% & (11/27) \\
      求める & (motomeru) & 10 & 481 & 22 & 21.9 & SVM 
      & 43.3\,\% & (13/30) & 100\,\% & (1/1) & 41.4\,\% & (12/29) \\
      \hline
      全動詞 & & 452 & 26,426 & 351 & 75.3 & 
      & 57.5\,\% & ($\frac{345}{600}$) & 94.2\,\% & ($\frac{49}{52}$) 
      & 54.0\,\% & ($\frac{296}{548}$) \\
      \hline
      合計 & & 911 & 39,867 & 655 & 60.9 & 
      & 63.4\,\% & ($\frac{761}{1,200}$) & 91.0\,\% & ($\frac{91}{100}$) 
      & 60.9\,\% & ($\frac{670}{1,100}$) \\
      \hline
    \end{tabular}
  \end{center}
\end{table*}

正解は各対象単語ごとにひとつあるいは複数与えられ，
各正解には，対象単語の翻訳に適切であるかどうかを考慮した複数段階による
評価が付与されている．
正解は以下の基準で◎，○，△の各段階に分けられた．
\begin{enumerate}
\item 正解がTMの用例の場合
  \begin{itemize}
  \item ◎ : 翻訳に利用できる用例の場合．日本語用例の品詞，時制，単複，
    微妙なニュアンス等は必ずしも一致しない．
  \item ○ : 評価単語のみに着目すれば妥当な訳語であるが，翻訳用例として
    使うことは望ましくない用例．
  \item △ : 評価単語のみに着目すれば妥当な訳語であるが，翻訳用例として
    直接は使えない用例．
  \end{itemize}
\item 正解が翻訳の場合
  \begin{itemize}
  \item ◎ : 翻訳に利用できる場合．品詞，時制，単複，
    微妙なニュアンス等は必ずしも一致しない．
  \item ○ : 評価単語のみに着目すれば妥当な訳語であるが，
    翻訳に使うことは望ましくない場合．
  \end{itemize}
\end{enumerate}
コンテストの結果は一番緩い評価基準で評価したものである．
一番緩い評価基準とは，正解をゆるくとる(上記の基準で，TMの◎，○，△，
翻訳の◎，○をすべて正解とする)場合，一番厳しい評価基準とは，
正解を厳しくとる(◎のみ)場合を意味する．
一番厳しい評価基準で我々のシステムの出力を評価した場合，
全体の精度が50.6\,\% (607/1,200)，
その内訳は，手法1の精度が82.0\,\% (82/100)，手法2が47.7\,\% (525/1,100)であった．

表~\ref{tab:result} から，一番緩い評価基準で全体の精度を比べると，
上位の二システムとは10\,\%程度以上の差があるが，
一番厳しい評価基準では，我々のシステムの精度は50.6\,\% (607/1,200)で，
AnonymY1システムの精度50.2\,\% (602/1,200)とほぼ同等であった．
また，一番緩い基準でも，名詞全体に対する精度は，
我々のシステムの精度は69.3\,\% (416/600)で，
AnonymY1システムの精度66.8\,\% (401/600)と同等以上の結果が得られている．
最も良かったAnonymXシステムの精度59.0\,\% (708/1,200)には遠く及ばなかったが，
後の\ref{sec:models_and_accuracy}節に示すように，
追加実験により我々の手法で62.4\,\% (749/1,200)の精度が得られ，
潜在的には66.0\,\% (792/1,200)の精度が得られる可能性があることが分かったため，
結果のみから判断すると，
我々のシステムはAnonymXシステムと同程度以上の性能であるとも考えられる．
手法そのものについては，AnonymX, AnonymY1については具体的な方法が
明かされていないため，現時点での比較はできない．

表~\ref{tab:result2} から，クラス当たりの学習文数の少ない名詞と，
クラス当たりの学習文数の非常に多い動詞の訳語選択精度が悪いといった傾向が
見られる．前者は学習データの不足が原因であると考えられる．
後者については，クラスの数が多く，日本語用例は似ているが異なるクラスに分類
されているという場合もあり，また学習データが特定のクラスに偏っている
ということもなかったため，ベースラインの精度そのものが低い難しい問題であった
と考えられる．実際，すべての入力に対し対象単語ごとに
常に学習データで最も学習文数の多いクラスを出力するシステムを作成して
実験したところ，これらの単語に対する精度は低いことが分かった．

\subsection{手法1と精度}
\label{sec:method1_and_acc}

手法1はTMを最も単純に利用した方法であり，
この手法による精度は高いことが望ましい．
実験(コンテスト)では手法1による精度は91.0\,\% (91/100)であった．

この手法により誤った例(正解と一致しなかった例)を表~\ref{tab:error1} にあげる．
誤ったのは，入力文と日本語用例との類似性だけから推定することが困難だったため
である．類似度はすべて1であり
\footnote{例えば，
入力文「お天気情報の大切さを一般の人に理解していただくことが，
僕の使命と思っています．」とTMの日本語用例「一般の人」のdiffをとると
用例の全ての文字列が入力文と一致し，一致した文字数は4となる．
日本語用例の文字数も4であるため，式(\ref{eq:sim1})より，類似度は1となる．
}，日本語用例そのものは類似していると思われるが，
英語用例はそれぞれひとつずつしか与えられておらず，
文脈からそれらの用例を翻訳として用いるのは不適切であると
判断されたものと思われる．
手法1はTMの日本語用例の文字列情報のみを用いる方法であるため，
このような場合，他の用例を適切に選択することはできない．

\begin{table*}[htbp]
  \footnotesize
  \begin{center}
    \caption{手法1で誤った例}
    \label{tab:error1}
    \begin{tabular}[c]{|p{4.5cm}|l|l|}
      \hline
      入力文(＜＞内は対象単語) & システムにより選択された用例 & 正解用例の \\
      & & 英語見出し語 \\
      \hline
      お天気情報の大切さを＜一般＞の人に理解していただくことが，
      僕の使命と思っています． 
      & 一般の人 : ordinary pepople & general \\
      \hline
      これは，「特」，「上」，「中」などに分けられる＜国内＞産米の分類が，
      「特」の場合，「一類米（最上級米）のブレンド率が八〇％以上」などと
      定められているのに準じた．
      & 国内産 : domestic & in this country\\
      \hline
      昨年暮れ，欧州から一時帰国したわが社の特派員が新聞コラムに
      「言葉がなく生気もない」と久しぶりに見た日本の印象をつづり，
      「言葉を＜失った＞のは街角にひしめく自動販売機のせい」と進行する
      失語社会を嘆いていた．
      & 言葉を失う : to lose one's ability to speak & language \\
      \hline
      休日で，子供に無残な＜姿＞を見せなくてすんだことがせめてもの救い．
      & 姿を見せる : to appear & look \\
      \hline
      当面，パリ大会，ハンガリー大会などの招待試合が予定されており，
      日本は国際試合への不参加という形で＜反対＞の立場を強くアピールする
      ことになる．
      & 反対の立場 : contrary position & opposition \\
      \hline
      これに対してフランスは核抑止力維持の立場から，現時点での核実験の
      無条件禁止には以前から＜反対＞の立場を表明し，特に中国が昨年十月に実験を
      行ったこともあって，ＮＰＴ延長と交渉期限をリンクさせることには強く反発．
      & 反対の立場 : contrary position & opposition \\
      \hline
      「米国にも言うべきことはっきり＜言う＞日本に」
      & はっきり言って : frankly speaking & say \\
      \hline
      教職員や学生ら約六百人から盛大な歓迎を＜受けた＞首相は，
      「本当に母校というものはありがたいものです」と大いに気を良くしていた．
      & 歓迎を受ける : to be welcomed & receive \\
      \hline
      私は自分の周りで起きたほのぼのとした出来事を見つけては，
      原稿用紙に＜書いて＞いろいろなところに送るのが大好きだ．
      & 紙に書く : to write on paper & write \\
      \hline
    \end{tabular}
  \end{center}
\end{table*}

次に，手法1が適用された100対象単語に対し手法2を適用したときの精度を調べた．
結果は49.3\,\% (34/69)であった．ただし，100語のうち31語は，TMの用例に含まれる
英語見出し語ではなく対訳辞書を索いて得られた英語見出し語を選択したため
評価していない．仮にこれらがすべて正解だったとしても精度は65\,\% (65/100)となる．
したがって，手法1では，適用された語に対してはかなり良い精度が得られることが
分かる．手法1で正しく手法2で訳語選択を誤ったものは30語であり，
それらの語を含む入力文には慣用的な表現が多く見られた．
そのうち，手法1によって適用された用例には次のようなものがあった．
以下で，＜＞内は見出し語を表わす．
\begin{itemize}
\item ＜胸＞を張る : to ＜look proud＞
\item 話に＜花＞が咲く : to engage in ＜animated＞ conversation
\item 一役＜買う＞ : to ＜offer＞ to help
\item 調子に＜乗る＞ : to be ＜carried away＞
\end{itemize}
上記のような慣用的な対訳用例を含む用例集合は，その集合に含まれる用例数が
少ないため学習データが不足し，手法2で適切に選択することは難しい．
このように予め学習データが少ないと分かったクラスつまり訳語/訳句候補は，
慣用表現である可能性が高いと考え，個別にTMに用例を追加するなどして
TMを充実させるのが効果的である可能性が高い．
この場合，TMに用例を追加するだけでなく，
表~\ref{tab:error1} にあげたような手法1による誤りもなくす必要があるため，
現状のTMを次の手順で変更する必要があると考えている．
\begin{enumerate}
\item 各日本語用例の翻訳として可能なものはすべて登録する．
\item 日本語用例が同一の用例が複数ありかつその用例を含む
  用例集合内の用例数が少ない場合は，
  日本語用例間に違いが出るまでそれぞれの用例の前後の文脈を伸ばす．
\end{enumerate}
このようにTMの用例を変更することにより，表~\ref{tab:error1} の誤りも
ほぼなくなると考えている．

\subsection{手法2と精度}
\label{sec:method2_and_acc}

手法2ではTMの用例だけでなく他の言語資源から抽出した用例も用いる．
もしTMの用例しか用いなければ，1クラスあたりの学習文数は平均1.4となる．
これでは機械学習をするにはデータが少な過ぎ，強力な学習モデルを用いても
高い精度は期待できない．
ちなみに，コンテストに参加したシステムのうち，
上位の4システム以外は，配布されたTM用例のみを用いていた．
最高のもので50\,\%程度の精度であり，他の言語資源を用いたことによる
効果は10\,\%以上と考えられる．我々の手法でもTM用例のみを用いた場合と
他の言語資源を用いた場合の結果を比較したところ，
他の言語資源を用いた場合の方が6\,\%から7\,\%程度良くなることが分かった．
他の言語資源を用いることの有効性については，詳しくは
\ref{sec:data_and_accuracy}節で述べる．

補強した学習データでは，
1クラスあたりの学習文数の平均は全体で60.9文(名詞44.2文，動詞75.3文)であった．
基本的に学習データが少ない語に対しては，さらに他の言語資源を利用してデータを
追加すればよいと考えられる．
しかし，学習文数が平均より多いにもかかわらず精度が平均より悪かったものは，
それぞれ名詞が3語(そのうちSVMが2語，DLが1語)，
動詞が5語(そのうちSVMが1語，SBが4語)であり，
この結果は，単純に学習データを増やしても精度が良くならない場合があることを
示している．1クラスあたりの学習データが多いにもかかわらず精度が良くなかった
原因としては，以下のことが考えられる．
\begin{enumerate}
\item SBモデルと素性集合の相性(4例)
    
  SBモデルによる精度はすべて悪かった．
  これは実験に用いた素性集合と，すべての素性を独立と仮定して扱うSBモデルの
  性質が合わなかったためであると考えられる．

\item 追加した学習データの質(4例)

  学習データの多くは他の言語資源から抽出したものである．
  コンテストでは，他の言語資源から対訳用例を抽出する際に，
  日英の見出し語が出現しているかどうかだけを手がかりにしていた．
  そのため，日英見出し語が対応関係にないものも抽出していた．
  例えば，haveやtake，lookなど一般に出現頻度が高く，日本語に訳したとき
  その訳語に曖昧性のある単語が英語見出し語である場合には，
  見出し語間に対応関係がない対訳用例も多く抽出してしまう．
  この単語対応を考慮していなかったことによる影響は，学習の際に顕著に現われる．
  学習モデルにおけるクラスは英語見出し語で表わされる．
  そのため，日英の見出し語間に対応がとられていないと，
  ひとつの用例に見出し語となり得る語が複数種類現われるとき，
  その用例の見出し語が特定できず曖昧になる．
  その結果，同じ用例が複数のクラスの正例として用いられることになり，
  この用例を用いて学習したモデルでは，正しくクラスを分類できなくなる．
  今回の実験で，SVMなどで学習が終了しなかったのは，
  このような例が多くあったことがひとつの原因であると考えている．
\end{enumerate}
以上のような問題を解消し，精度を改善するには，
次のような対策を講じる必要がある．
\begin{itemize}
\item モデル，素性の選択方法を工夫する．
\item 学習データを補強する際，
  他の言語資源から抽出した対訳用例における単語対応をとり，
  日英見出し語が対応関係にあるものだけを選択するようにする．
\end{itemize}
モデルの選択方法については，
当初クロスバリデーションによるモデル選択を採用する予定であったが，
コンテストの際には時間的な制約のため実現できなかった．
そこで，学習データでクロスバリデーションを行ない，平均精度が
最大となるモデルを最適なモデルとして選択するようにし再実験を行なった．
クラスである英語見出し語は，評価，比較が容易になるように
TMの用例のみから選択した．評価は次の二種類の評価方法で行なった．

\begin{description}
\item[評価方法1:] 見出し語による評価

  正解の用例から日英見出し語を取り出し，これを用例番号の代わりに正解として
  用いて評価する．
  コンテストの評価で，正解が翻訳のみからなると仮定した場合の評価方法
  に相当する．

  例えば，図~\ref{fig:tm_example2} において「sense id」で表される用例番号
  の代わりに「headword」で表される日本語見出し語と
  $<$ehead$>$$<$/ehead$>$で囲まれた英語見出し語のペアを正解として用いる．
\item[評価方法2:] 用例番号による評価

  システムの出力を見出し語とする用例集合からランダムに用例を選び，
  その用例番号の正否で評価する．
  コンテストの評価で，正解がTMの用例のみからなると仮定した場合の評価方法
  に相当する．

  例えば，システムの入力が図~\ref{fig:tm_example2} の「headword」で
  表される日本語見出しであり，出力が$<$ehead$>$$<$/ehead$>$で囲まれた
  英語見出し語の場合に，この見出し語の代わりに「sense id」で表される
  用例番号をシステムの出力とする．同じ見出し語を持つ用例が複数ある場合は
  ランダムに選ぶ．
\end{description}

学習データの数は21,650，クラスの数は平均で11.0(441/40)であった．
学習データを先頭から順番に10個置きに同じ集合に含まれるよう分割し，
各単語ごとに10分割のクロスバリデーションをして平均精度が最大となるモデルを
選択した結果，選択されたモデルの内訳は次の通りであった．

\begin{itemize}
\item ME : 21単語(名詞14，動詞7)
\item SVM : 12単語(名詞4，動詞8)
\item DL : 7単語(名詞2，動詞5)
\end{itemize}

結果は表~\ref{tab:exp:cross_valid} の通りであった．
手法1での類似度および分割数の閾値としては，
学習データに対する精度が最大になったときの値つまり1.0と0，
および，テストデータに対して最大の精度が得られたときの値
つまり0.8と1の二種類をあげた．
閾値が1.0と0のときの，単語ごとの精度と学習文数，クラス数との関係は
表~\ref{tab:result3} の通りである
\footnote{
  コンテストの時に比べて，主辞単語の定義を変更したり，
  追加用例を抽出した対訳辞書のバージョンがあがったりしたため，
  表~\ref{tab:result2} に比べて，クラス数や学習文数が増えている場合がある．
}．

\begin{table}[htbp]
  \begin{center}
    \caption{クロスバリデーションによりモデル選択を行なったときの精度}
    \label{tab:exp:cross_valid}
    \begin{tabular}[c]{|c|c|c|r|r|}
      \hline
      手法 & \multicolumn{2}{c|}{閾値} & \multicolumn{2}{c|}{精度}\\
      \cline{2-5}
      & 類似度 & 分割数 
      & \multicolumn{1}{c|}{評価方法1} & \multicolumn{1}{c|}{評価方法2} \\
      \hline
      2 & - & - & 65.2\,\% (782/1,200) & 61.1\,\% (733/1,200)\\
      1+2 & 1.0 & 0 & 65.8\,\% (789/1,200) & 61.8\,\% (741/1,200)\\
      1+2 & 0.8 & 1 & 65.9\,\% (791/1,200) & 62.0\,\% (744/1,200)\\
      \hline
    \end{tabular}
  \end{center}
\end{table}

\begin{table*}[htbp]
  \footnotesize
  \begin{center}
    \caption{単語ごとの精度(クロスバリデーションによるモデル選択時)}
    \label{tab:result3}
    \begin{tabular}[c]{|l@{}l|r|r|r|r|@{ }r@{ }r|@{ }r@{ }r|}
      \hline
      単語 & (読み) & 学習文 & クラス & 学習文数
      & 学習 & \multicolumn{2}{c|}{手法1+2} & \multicolumn{2}{c|}{手法2} \\
      \cline{7-10}
      & & 数 & 数 & /クラス 
      & モデル & 評価1 & 評価2 & 評価1 & 評価2 \\ 
      \hline
      一般 & (ippan) & 778 & 16 & 48.6 & ME
      & 15/30 & 12/30 & 16/30 & 13/30 \\
      一方 & (ippou) & 135 & 10 & 13.5 & SVM
      & 4/30 & 4/30 & 4/30 & 4/30 \\
      今 & (ima) & 413 & 11 & 37.5 & ME
      & 29/30 & 29/30 & 29/30 & 29/30 \\
      意味 & (imi) & 298 & 9 & 33.1 & ME 
      & 22/30 & 21/30 & 21/30 & 20/30 \\
      核 & (kaku\_n) & 742 & 4 & 185.5 & SVM 
      & 16/30 & 16/30 & 14/30 & 14/30 \\
      記録 & (kiroku) & 489 & 6 & 81.5 & DL
      & 29/30 & 24/30 & 29/30 & 24/30 \\
      国内 & (kokunai) & 255 & 5 & 51.0 & ME
      & 19/30 & 19/30 & 19/30 & 19/30 \\
      言葉 & (kotoba) & 675 & 19 & 35.5 & ME 
      & 30/30 & 30/30 & 30/30 & 30/30 \\
      市民 & (shimin) & 166 & 6 & 27.7 & ME
      & 25/30 & 21/30 & 25/30 & 21/30 \\
      事業 & (jigyou) & 581 & 5 & 116.2 & ME
      & 21/30 & 21/30 & 18/30 & 18/30 \\
      時代 & (jidai) & 613 & 12 & 51.1 & ME
      & 20/30 & 20/30 & 20/30 & 20/30 \\
      姿 & (sugata) & 137 & 20 & 6.9 & ME
      & 9/30 & 9/30 & 10/30 & 10/30 \\
      近く & (chikaku) & 105 & 8 & 13.1 & ME
      & 15/30 & 14/30 & 15/30 & 14/30 \\
      中心 & (chushin) & 326 & 9 & 36.2 & ME
      & 17/30 & 17/30 & 17/30 & 17/30 \\
      花 & (hana) & 543 & 15 & 36.2 & ME
      & 23/30 & 23/30 & 23/30 & 23/30 \\
      反対 & (hantai) & 457 & 11 & 41.5 & ME
      & 25/30 & 23/30 & 26/30 & 24/30 \\
      場合 & (baai) & 383 & 7 & 54.7 & DL 
      & 22/30 & 16/30 & 22/30 & 16/30 \\
      前 & (mae) & 824 & 15 & 54.9 & SVM
      & 10/30 & 10/30 & 10/30 & 10/30 \\
      胸 & (mune) & 269 & 12 & 22.4 & ME
      & 17/30 & 17/30 & 17/30 & 17/30 \\
      問題 & (mondai) & 1,848 & 9 & 205.3 & SVM 
      & 22/30 & 21/30 & 21/30 & 20/30 \\
      \hline
      全名詞 & & 10,037 & 209 & 48.0 & - 
      & 390/600 & 367/600 & 386/600 & 363/600 \\
      \hline
      与える & (ataeru) & 565 & 18 & 31.4 & DL
      & 23/30 & 23/30 & 23/30 & 23/30 \\
      言う & (iu) & 1,276 & 19 & 67.2 & DL 
      & 23/30 & 15/30 & 24/30 & 16/30 \\
      受ける & (ukeru) & 1,331 & 18 & 73.9 & DL
      & 11/30 & 11/30 & 12/30 & 12/30 \\
      描く & (egaku) & 189 & 6 & 31.5 & SVM 
      & 17/30 & 17/30 & 17/30 & 17/30 \\
      買う & (kau) & 798 & 12 & 66.5 & ME
      & 25/30 & 25/30 & 24/30 & 24/30 \\
      書く & (kaku\_v) & 796 & 2 & 398 & ME
      & 29/30 & 21/30 & 29/30 & 20/30 \\
      聞く & (kiku) & 453 & 9 & 50.3 & ME
      & 19/30 & 18/30 & 19/30 & 18/30 \\
      超える & (koeru) & 57 & 8 & 71.25 & ME
      & 24/30 & 24/30 & 24/30 & 24/30 \\
      使う & (tsukau) & 1,320 & 11 & 120.0 & DL
      & 28/30 & 26/30 & 27/30 & 25/30 \\
      作る & (tsukuru) & 702 & 14 & 50.1 & SVM
      & 20/30 & 20/30 & 20/30 & 20/30 \\
      伝える & (tsutaeru) & 143 & 13 & 14.2 & SVM
      & 8/30 & 8/30 & 7/30 & 7/30 \\
      出る & (deru) & 608 & 22 & 27.6 & SVM
      & 5/30 & 5/30 & 5/30 & 5/30 \\
      乗る & (noru) & 611 & 12 & 41.9 & ME
      & 15/30 & 15/30 & 15/30 & 15/30 \\
      図る & (hakaru) & 127 & 8 & 50.9 & ME
      & 28/30 & 28/30 & 28/30 & 28/30 \\
      待つ & (matsu) & 523 & 6 & 87.2 & ME
      & 29/30 & 23/30 & 29/30 & 23/30 \\
      守る & (mamoru) & 313 & 7 & 44.7 & SVM 
      & 15/30 & 15/30 & 13/30 & 13/30 \\
      見せる & (miseru) & 189 & 7 & 27.0 & SVM 
      & 28/30 & 28/30 & 28/30 & 28/30 \\
      認める & (mitomeru) & 114 & 4 & 28.5 & SVM
      & 11/30 & 11/30 & 11/30 & 11/30 \\
      持つ & (motsu) & 1,320 & 30 & 44.0 & DL
      & 19/30 & 19/30 & 19/30 & 19/30 \\
      求める & (motomeru) & 178 & 6 & 29.7 & SVM 
      & 22/30 & 22/30 & 22/30 & 22/30 \\
      \hline
      全動詞 & & 11,613 & 232 & 50.1 & - 
      & 399/600 & 374/600 & 396/600 & 370/600 \\
      \hline
      合計 & & 21,650 & 441 & 49.1 & - 
      & 789/1,200 & 741/1,200 & 782/1,200 & 733/1,200 \\
      \hline
    \end{tabular}
  \end{center}
\end{table*}

クラスである英語見出し語は，上述のようにTMの用例のみから選択しているため，
表~\ref{tab:result2} と表~\ref{tab:result3} を単純に比較することはできない．
しかし，今回の追加実験で用いたクラスはコンテストのときに用いたクラスに
包含されるため，コンテストの出力のうち追加実験で用いたクラスを出力したもの
のみを対象として評価した．ここで対象となった単語は861語であり，コンテストの
ときの精度は評価方法1で61.8\,\% (532/861)，評価方法2で58.0\,\% (500/861)であり，
追加実験での精度は評価方法1で68.4\,\% (589/861)，評価方法2で63.5\,\% (547/861)
であった．コンテストでモデル選択を行えていたら，5\,\%程度精度が良かった
可能性がある．

二つの評価基準により精度が4\,\%程度異なるのは，
コンテストで正解とされた用例における見出し語と同じものを含む用例が
必ずしもすべて正解に含まれているとは限らないためである．
つまり，評価方法1より評価方法2の方が厳しい基準となっているためである．
例えば，「わがままを言わず，全力で頑張りたい」という入力文で
対象単語が「言う」のとき，
\begin{itemize}
\item ＜言う＞までもない : to be needless to ＜say＞
\end{itemize}
という用例は正解に含まれていたが，
\begin{itemize}
\item ＜言い＞たいことを言う : to have one's ＜say＞
\end{itemize}
という用例は同じ見出し語「言う」と「say」を持つにも関わらず
正解には含まれていなかった．このような場合，評価方法1では「say」と回答
しても正しいと評価されるが，評価方法2では，さらに用例を正しく選択して回答
できないと正しいとは評価されない．
このような見出し語と正解用例とのずれが確認されたのは14単語についてであり，
残りの26単語については見出し語を含む用例はすべて正解に含まれていた．
ずれがあった単語の内訳は，表~\ref{tab:discrepancy} の通りである．
\begin{table}[htbp]
  \begin{center}
    \caption{見出し語と正解用例とのずれ}
    \label{tab:discrepancy}
    \begin{tabular}[c]{|ll|r|}
      \hline
      日本語見出し語 & (読み) & ずれがあったもの\\
      \hline
      乗る & (noru) & 1\\
      書く & (kaku\_v) & 17\\
      一般 & (ippan) & 13\\
      記録 & (kiroku) & 15\\
      問題 & (mondai) & 4\\
      守る & (mamoru) & 6\\
      近く & (chikaku) & 1\\
      反対 & (hantai) & 3\\
      今 & (ima) & 2\\
      市民 & (shimin) & 7\\
      使う & (tsukau) & 2\\
      意味 & (imi) & 1\\
      言う & (iu) & 19\\
      待つ & (matsu) & 20\\
      \hline
      合計 & & 111\\
      \hline
    \end{tabular}
  \end{center}
\end{table}
この表で，「ずれがあったもの」とは，テストの対象単語30出現のうち，
正解用例の見出し語と同じものを含む用例がひとつでも正解に含まれなかった
場合の数のことである．
このずれは，見出し語が同じでも文脈によって意味が違う場合があることを
示している．
対象単語の翻訳に使える用例を選択するというタスクでは，
訳語選択以上の意味的な曖昧性解消を要求していると言えるだろう．

\subsection{素性と精度}
\label{sec:feature_sets_and_accuracy}

この節では，各素性集合と精度との関係について述べる．

表~\ref{table:exp:feature} に，
実験に用いた素性集合の種類とそのときに得られた精度をあげる．
「機械翻訳モデル」の欄にはクロスバリデーションによって選択された
機械学習モデルの数を表わす．
手法1での類似度および分割数の閾値はそれぞれ，
学習データに対する精度が最大になったときの値つまり1.0，0とした．
括弧内の数字は，素性集合をすべて用いたときに得られた精度からの増減を表わす．
表~\ref{table:exp:feature} から素性集合1は精度向上に貢献していることが
分かるが，素性集合2と素性集合3は精度を下げる結果となっていたことが分かる．
これは，学習データの文数が平均49.1文(21,650/441)と少なく，
過学習に陥ったためと考えられる．

\begin{table}[htbp]
  \begin{center}
    \caption{各素性集合を削除したときの実験結果}
    \label{table:exp:feature}
    \begin{tabular}[c]{|l|c|l|l|c|c|c|c|}
      \hline
      \multicolumn{1}{|c|}{素性集合} & 手法 & \multicolumn{2}{c|}{精度}
      & \multicolumn{4}{c|}{機械学習モデル}\\
      \cline{3-8}
      & & \multicolumn{1}{c|}{評価方法1} & \multicolumn{1}{c|}{評価方法2} 
      & SVM & ME & DL & SB\\
      \hline
      すべて & 2 & 65.2\,\% & 61.1\,\% & 12 & 21 & 7 & 0\\
      すべて & 1+2 & 65.8\,\% & 61.8\,\% & 12 & 21 & 7 & 0\\
      1+2 & 2 
      & 66.8\,\% ($+$1.6) & 62.1\,\% ($+$1.0) & 20 & 15 & 5 & 0\\
      1+2 & 1+2
      & 67.4\,\% ($+$1.6) & 63.1\,\% ($+$1.3) & 20 & 15 & 5 & 0\\
      1+3 & 2 
      & 63.1\,\% ($-$2.1) & 58.5\,\% ($-$2.6) & 3 & 22 & 15 & 0\\
      1+3 & 1+2
      & 64.0\,\% ($-$1.8) & 59.7\,\% ($-$2.1) & 3 & 22 & 15 & 0\\
      2+3 & 2 
      & 62.8\,\% ($-$2.4) & 56.9\,\% ($-$4.2) & 0 & 26 & 14 & 0\\
      2+3 & 1+2
      & 64.1\,\% ($-$1.7) & 58.6\,\% ($-$3.2) & 0 & 26 & 14 & 0\\
      1 & 2 
      & 68.2\,\% ($+$3.0) & 62.9\,\% ($+$1.8) & 15 & 10 & 14 & 1\\
      1 & 1+2
      & 69.2\,\% ($+$3.4) & 64.3\,\% ($+$2.5) & 15 & 10 & 14 & 1\\
      2 & 2 
      & 65.4\,\% ($+$0.2) & 60.4\,\% ($-$0.7) & 0 & 35 & 3 & 2\\
      2 & 1+2
      & 65.9\,\% ($+$0.1) & 61.3\,\% ($-$0.5) & 0 & 35 & 3 & 2\\
      3 & 2 
      & 57.5\,\% ($-$7.7) & 52.5\,\% ($-$8.6) & 1 & 24 & 12 & 3\\
      3 & 1+2
      & 59.4\,\% ($-$6.4) & 54.9\,\% ($-$6.9) & 1 & 24 & 12 & 3\\
      \hline
    \end{tabular}\\
    \vspace*{1em}
    (手法1での閾値：類似度=1.0，分割数=0)
  \end{center}
\end{table}

\subsection{モデルと精度}
\label{sec:models_and_accuracy}

この節では，複数の機械学習モデルから最適なモデルを選択した場合と，
単独の機械学習モデルを用いた場合との違いについて述べる．

これまでの実験では，個々の単語に対し，複数の機械学習モデルから
クロスバリデーションによりモデルを選択していたが，すべて単一の機械学習
モデルを用いた場合との精度の違いが明らかではなかった．
そこで，手法2で各々の機械学習モデルをそれぞれ単独で用いた場合の実験を
行なった．素性としては，前節で最も良い精度が得られた素性集合1を用いた．
手法1における類似度と分割数の閾値は学習データで最適値となった1.0と0に
設定した．

一番緩い基準と厳しい基準で評価した結果を
表~\ref{tab:exp:each_model1} と表~\ref{tab:exp:each_model2} にあげる．
この表で，混合とは複数の機械学習モデルから最適なモデルを選択した場合を
意味する．混合(上限値)の行にあげた精度は，個々の単語ごとに，
複数の機械学習モデルからテストデータで最も良い精度が得られるモデルを
選択した場合の精度であり，複数のモデルを用いる場合の潜在的な上限値を
意味している．また，最頻とは常に学習データで最も学習文数の多いクラスを
出力するモデルを意味する．

\begin{table}[htbp]
  \begin{center}
    \caption{機械学習モデル単独での精度とモデル選択による上限値(一番緩い基準)}
    \label{tab:exp:each_model1}
    \begin{tabular}[c]{|c|c|r|r|}
      \hline
      モデル & 手法 & \multicolumn{2}{c|}{精度}\\
      \cline{2-4}
      & & \multicolumn{1}{c|}{評価方法1} & \multicolumn{1}{c|}{評価方法2} \\
      \hline
      SVM & 2   & 70.3\,\% (843/1,200) & 64.8\,\% (778/1,200)\\
      SVM & 1+2 & 71.1\,\% (853/1,200) & 66.0\,\% (792/1,200)\\
      ME  & 2   & 68.4\,\% (821/1,200) & 63.4\,\% (761/1,200)\\
      ME  & 1+2 & 69.0\,\% (828/1,200) & 64.2\,\% (771/1,200)\\
      SB  & 2   & 67.8\,\% (813/1,200) & 63.7\,\% (764/1,200)\\
      SB  & 1+2 & 68.6\,\% (823/1,200) & 64.8\,\% (778/1,200)\\
      DL  & 2   & 68.6\,\% (823/1,200) & 63.4\,\% (761/1,200)\\
      DL  & 1+2 & 69.7\,\% (836/1,200) & 64.8\,\% (778/1,200)\\
      混合 & 2   & 68.2\,\% (818/1,200) & 62.9\,\% (755/1,200) \\
      混合 & 1+2 & 69.2\,\% (830/1,200) & 64.3\,\% (771/1,200) \\
      最頻 & - & 64.0\,\% (768/1,200) & 59.0\,\% (708/1,200) \\
      \hline
      混合(上限値) & 1+2 & 74.8\,\% (898/1,200) & 70.2\,\% (842/1,200)\\
      \hline
    \end{tabular}
  \end{center}
  \begin{center}
    \caption{機械学習モデル単独での精度とモデル選択による上限値(一番厳しい基準)}
    \label{tab:exp:each_model2}
    \begin{tabular}[c]{|c|c|r|r|}
      \hline
      モデル & 手法 & \multicolumn{2}{c|}{精度}\\
      \cline{2-4}
      & & \multicolumn{1}{c|}{評価方法1} & \multicolumn{1}{c|}{評価方法2} \\
      \hline
      SVM & 2   & 61.6\,\% (739/1,200) & 56.0\,\% (672/1,200)\\
      SVM & 1+2 & {\bf 62.4\,\% (749/1,200)} & {\bf 57.3\,\% (687/1,200)}\\
      ME  & 2   & 59.8\,\% (718/1,200) & 54.8\,\% (657/1,200)\\
      ME  & 1+2 & 60.6\,\% (727/1,200) & 55.7\,\% (668/1,200)\\
      SB  & 2   & 60.0\,\% (720/1,200) & 55.8\,\% (670/1,200)\\
      SB  & 1+2 & 60.8\,\% (730/1,200) & 56.9\,\% (683/1,200)\\
      DL  & 2   & 59.4\,\% (713/1,200) & 54.1\,\% (649/1,200)\\
      DL  & 1+2 & 60.5\,\% (726/1,200) & 55.5\,\% (666/1,200)\\
      混合 & 2   & 59.6\,\% (715/1,200) & 54.2\,\% (650/1,200) \\
      混合 & 1+2 & 60.7\,\% (728/1,200) & 55.7\,\% (668/1,200) \\
      最頻 & - & 53.3\,\% (640/1,200) & 48.1\,\% (577/1,200) \\
      \hline
      混合(上限値) & 1+2 & 66.0\,\% (792/1,200) & 61.2\,\% (735/1,200) \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

これらの結果から，これまでの実験で用いてきたクロスバリデーションによる
モデル選択の方法は単独の学習モデル(SVM)を用いる方法に比べて劣ること，
しかし，潜在的には複数のモデルを組み合わせることにより，
より良い精度(5\,\%程度良い精度)が得られることが分かる．

\subsection{学習データと精度}
\label{sec:data_and_accuracy}

この節では，他の言語資源から対訳用例を自動抽出して用いた場合の効果について
述べる．

学習に，それぞれ，
TM用例のみを用いた場合，他の言語資源から自動抽出した対訳用例のみ
を用いた場合，すべて用いた場合の三種類の比較実験を行なった．
訳語選択モデルとしては，
これまでの実験で最も精度の良かった組み合わせのモデル，つまり，
手法1(類似度と分割数の閾値はそれぞれ1.0と0に設定)
とSVMの組み合わせに素性集合1を用いた場合のものを用いた．
結果を表~\ref{table:exp:data} にあげる．評価は一番緩い基準で行なった．

\begin{table}[htbp]
  \begin{center}
    \caption{学習データを変更したときの実験結果}
    \label{table:exp:data}
    \begin{tabular}[c]{|l|l|l|}
      \hline
      学習データ & \multicolumn{2}{c|}{精度} \\
      \cline{2-3}
      & \multicolumn{1}{c|}{評価方法1} & \multicolumn{1}{c|}{評価方法2} \\
      \hline
      TMのみ       & 64.0\,\% (768/1,200) & 57.4\,\% (689/1,200) \\
      追加用例のみ & 64.4\,\% (773/1,200) & 57.8\,\% (693/1,200) \\
      TMと追加用例 & 71.1\,\% (853/1,200) & 66.0\,\% (792/1,200) \\
      \hline
    \end{tabular}\\
    \vspace*{1em}
    (手法1での閾値：類似度=1.0，分割数=0)
  \end{center}
\end{table}

表~\ref{table:exp:data} より，
TM用例だけでなく，他の言語資源から自動抽出した対訳用例も用いた場合に，
より精度が良くなることが分かる．
他の言語資源から対訳用例を抽出する際には，
日英の見出し語が出現しているかどうかだけを手がかりにしていたため，
日英見出し語が対応関係にないものも抽出してしまっていたが，
現段階ではこの単語対応を考慮していなかったことによる悪影響よりも
自動抽出した用例が精度向上へ貢献する度合いの方が顕著に勝っていると
言えそうである．

今回用いたTMは新聞記事から抽出した語句を元に人手で作成されたものであり，
コンテストの対象である新聞記事と同じ，特化したドメインの知識と考えられる．
一方，自動抽出した用例は一般的な対訳辞書の用例であり，一般的なドメインの
知識であると考えれる．表~\ref{table:exp:data} の結果は，
一般的なドメインの知識と特化したドメインの知識が相補的に影響した
結果であるとも言えるだろう．

\section{関連研究}
\label{sec:related_works}

これまでに，
対訳コーパスを用いた統計的なあるいは機械学習モデルに基づく訳語選択の手法
が数多く提案されてきた(例えば，
\cite{Brown:93,Hussein:94,HTanaka:94,berger:cl96}など)
\footnote{
  テンスやアスペクト，モダリティの翻訳に
  機械学習モデルに基づく手法を用いた研究には
  文献\cite{Murata2001d}のものがある．
}．
我々も同様に機械学習モデルに基づく手法を用いている．
これまでに提案されてきた手法との主な違いは，
SVMなど複数の機械学習モデルを利用している点と，
それらの機械学習モデルと用例に基づく手法とを組み合わせて利用している点，
さらに，
これまでの方法がすべての単語に対し同じ機械学習モデルを用いているのに対して，
我々は単語ごと(原言語見出し語ごと)に異なるモデルを作成し，
その中から最適な機械学習モデルを選択している点にある．
実験では，クロスバリデーションによる選択は単独の学習モデル(SVM)より
劣ることが分かったが，潜在的には複数のモデルを組み合わせることにより
より良い精度(5\,\%程度良い精度)が得られることも示した．

用例に基づく手法として我々が用いたものはSato
\cite{Sato92} 
が提案した手法に類似している．
我々の手法との主な違いは，類似度を計算する際に課す制約である．
Satoの手法では特に制約は課していないが，我々の場合は，
入力文と用例とがいくつかの部分に分割されて一致する場合にその分割数を
制限する，対象単語と同じ見出し語を持つ用例に限定する，などの制約を課している．
実験により，前者の制約を課すことによって良い結果が得られることが分かった．
Satoの手法では，文字列の並びの順序が異なる場合でも一致したと見なす柔軟さが
ある．その柔軟性を我々の手法にも採り入れたい．

本論文で述べたTMあるいはそれと同様の対訳用例を訳語選択に用いた研究としては，
Baldwin
\cite{Baldwin:2001} 
や 
Sumita\cite{Sumita:2000} 
の研究がある．
Baldwin は原言語用例の情報を用いてTMから訳語選択に最も適した用例を
選択する方法を提案した．彼はbigramなどの文字列情報のみを用いたときが
最も精度良く類似した用例を選択できると報告している．
我々の方法でもbigramなどの文字列情報を素性として利用するようにすれば，
精度向上が期待できると考えている．
Sumita はTMの利用方法という点で我々と類似した方法を提案している．
彼の方法では，我々の手法と同様に，
TMの用例を目的言語見出し語ごとに用例集合としてまとめて利用している．
そして，入力文と用例集合をそれぞれ検索質問文，文書と考え，
情報検索でよく用いられるベクトル空間モデルを用いて
入力文と最も類似した用例集合を選択する．
この手法では学習は行なわれないが，我々の手法では学習により，
入力文と対象単語に関して最も類似した用例集合を選択する．
また，本論文では，対訳用例の訳語選択への利用方法に関する知見として，
今回用いたTMのように一見出し語あたり30個程度の例があれば，
それをもとに自動抽出した対訳用例と併せて学習に用いることで精度が向上する
ことを示した．

機械翻訳では，Marcu
\cite{Marcu:2001} 
が用例に基づく手法と統計的機械翻訳モデルを組み合わせて
一文全体を翻訳する手法を提案した．
統計的機械翻訳モデルを用いて入力文の最適な翻訳を探索する際に，
必ずしも最適解を探索するのではなく，
入力文と一致するTM用例があればそれを優先する，という制約を課すことにより
翻訳精度が向上したと報告している．
我々の手法では，用例に基づく手法と機械学習モデルを組み合わせて，
一文全体の翻訳ではなく，各単語の訳語選択を行なう．
また，Marcuは完全一致となる用例のみを用いているが，
我々はいくつかの部分に分かれて一致する用例や部分一致となる用例も用いている．
実験ではこのような用例も用いた場合に精度が向上したことから，
一文全体の翻訳の際にも部分一致となる用例を用いるとより良い結果が得られる
可能性が高いと考えている．今後，我々の手法が一文全体の翻訳の精度にどれだけ
貢献するかを調べたい．

\section{まとめ}
\label{sec:conclusion}

本論文では，機械翻訳における訳語選択の手法について述べた．
我々のシステムは，入力文と対象単語が与えられたとき，
対象単語に関して入力文と用例(あるいは用例集合)との類似度を求め，
類似度が最大となる用例(あるいは用例集合)を用いて対象単語の訳語選択を行なう．
類似度は，入力文，対象単語，用例に関する様々な情報を手がかりとして考慮し，
用例に基づく手法と機械学習モデルに基づく手法を組み合わせて求める．
学習には，TMの用例だけでなく，他の対訳辞書あるいは対訳コーパスから
抽出した用例を用い，学習の際には，
原言語と目的言語の間で互いに対応関係がない各単言語コーパスから抽出した
頻度情報なども考慮する．

コンテストでの結果および，追加実験の結果を分析して分かったことは
以下の通りである．

\begin{itemize}
\item 文字列の類似性に基づく方法(手法1)は
  慣用的な表現を含む文などに対して精度が良かった．
\item 対訳用例を自動的に収集して学習データに追加することにより，
  より良い精度が得られることが分かった．
\item 文字列の類似性に基づく方法(手法1)と機械学習モデルに基づく方法(手法2)
  を組み合わせたときに最も良い精度が得られた．
\end{itemize}

今後の課題としては，以下のことを考えている．
\begin{itemize}
\item 学習データの質の改善．

  他の言語資源から追加した対訳用例の英語見出し語が，
  日本語に訳したときその訳語に曖昧性のある場合には，
  データの質が精度に悪影響を及ぼす場合があった．
  今後，対訳用例における単語対応をとり，
  見出し語間に対応関係があるもののみ選択するようにし，
  学習データの質を改善したい．
  
\item 最適な機械学習モデルの選択方法の模索．

  本論文では，個々の単語に対して最適な機械学習モデルを選択するために，
  学習データにおいてクロスバリデーションを行ない，平均精度が最大となる
  モデルを最適なモデルとして採用したが，単独のモデル(SVM)に劣ることが分かった．
  今後，最適なモデルの選択を学習モデルにより決定するstacking法などを適用
  するなど，最適なモデルの選択方法を模索したい．

\item 新たな素性の導入と選択．

  見出し語とそのまわりに出現する単語の実データにおける分布を
  できるだけ反映させたモデルを作るために，
  単言語コーパスから抽出した単語の頻度情報を素性として利用した．
  しかし，過学習に陥り精度を下げる結果となった．
  今後，単言語コーパスに関する情報で何が訳語選択に貢献する有用な情報であるかを
  模索したい．
\end{itemize}

\begin{flushleft}
{\bf 謝辞}  
\end{flushleft}

本研究を進めるにあたって，データを利用させて頂いた毎日新聞社，
日経新聞社，産経新聞社，ニフティ，LDCの各社に感謝する．
また，貴重なコメントを下さった査読者，ならびに，本特集号編集委員長である
東京大学の黒橋禎夫先生に感謝の意を表したい．



\bibliographystyle{jnlpbbl}
\bibliography{6}


\begin{biography}
\biotitle{略歴}
\bioauthor{内元 清貴}{
1994年京都大学工学部卒業．
1996年同大学院修士課程修了．
同年郵政省通信総合研究所入所．現在，独立行政法人通信総合研究所研究員．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，ACL，各会員．}
\bioauthor{関根 聡}{
1987年東京工業大学応用物理学科卒．同年松下電器東京研究所入社．
1990-1992年UMIST，CCL，Visiting Researcher．1992年MSc．
1994年からNew York University，Computer Science Department，
Assistant Research Scientist．1998年PhD．
同年からAssistant Research Professor．
自然言語処理の研究に従事．
情報処理学会，人工知能学会，言語処理学会，ACL会員．}
\bioauthor{村田 真樹}{
1993年京都大学工学部卒業．
1995年同大学院修士課程修了．
1997年同大学院博士課程修了，博士（工学）．
同年，京都大学にて日本学術振興会リサーチ・アソシエイト．
1998年郵政省通信総合研究所入所．現在，独立行政法人通信総合研究所主任研究員．
自然言語処理，機械翻訳，情報検索の研究に従事．
言語処理学会，情報処理学会，人工知能学会，電子情報通信学会，ACL，各会員．}
\bioauthor{井佐原 均}{
1978年京都大学工学部電気工学第二学科卒業．
1980年同大学院修士課程修了．博士（工学）．
同年通商産業省電子技術総合研究所入所．
1995年郵政省通信総合研究所．
現在，独立行政法人通信総合研究所けいはんな情報通信融合研究センター
自然言語グループリーダー．
自然言語処理，機械翻訳の研究に従事．
言語処理学会，情報処理学会，人工知能学会，日本認知科学会，各会員．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}
