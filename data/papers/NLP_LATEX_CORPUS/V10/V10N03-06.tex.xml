<?xml version="1.0" ?>
<root>
  <title>用例に基づく手法と機械学習モデルの組み合せによる訳語選択</title>
  <author>内元清貴関根聡村田真樹井佐原均</author>
  <jabstract>本論文では，機械翻訳における訳語選択の手法について述べる．我々のシステムは，入力文と対象単語が与えられたとき，翻訳メモリと呼ばれる対訳用例集合と入力文との類似度を求め，類似度が最大となる用例集合を用いて対象単語の訳語選択を行なう．類似度は，用例に基づく手法と機械学習モデルを用いて計算される．類似度の計算には，文字列の類似性や入力文における対象単語周辺の単語，入力文中の内容語とその訳語候補の対訳コーパスおよび日英の単言語コーパスにおける出現頻度などを考慮する．入力文と対象単語が与えられると，まず用例に基づく手法を適用し，類似した用例が見つからなかった場合に機械学習モデルを適用する．機械学習モデルは複数用意し，クロスバリデーションなどにより単語毎に最適な学習モデルを選択する．本論文では，2001年の春に開催された単語の多義性解消のコンテスト第2回Senseval</jabstract>
  <jkeywords>訳語選択，用例に基づく手法，機械学習モデル，対訳コーパス，単言語コーパス</jkeywords>
  <section title=" Senseval">日本語翻訳タスクこのタスクでは，単語の多義は翻訳(訳語/訳句)として定義された．コンテストでは，予め日英のTMが訓練データとして配布された．具体的には，TMでは，日本語見出し語に対して，それを含む日本語表現とその英語翻訳のペア(以下これを用例と呼ぶ)の集合が与えられた．図~がそのTMのサンプルである．[htbp]figure*コンテストのテストでは，対象単語にマークのついたテスト文章が配布された．参加者には，対象単語に対して，その翻訳に利用できるTMの用例番号，または，翻訳そのものを提出することが求められた．翻訳の場合は，その語単独の翻訳でも，前後の適当な範囲の翻訳でも，文全体の翻訳でもよいものとされた．テストの各対象単語には正解が用意された．正解は必ずしもひとつではなく，複数の場合もある．評価は，システムの出力のうち正しく推定できたものの割合(精度)により行なわれた．システムの出力がTMの用例番号の場合は，その出力が正解のいずれかと一致するとき，正しく推定できたものと見なされた．システムの出力が翻訳の場合は，すべての可能な翻訳を用意することは難しいため，その出力が正しいかどうかは人間の判断に委ねられた．</section>
  <section title="はじめに">単語の多義性解消は自然言語処理の重要な基本技術のひとつとして認識されている．単語の多義性というのは，例えば，「買う」という単語について「本を買う」と「反感を買う」とでは意味が違うというように，同じ単語でも文脈によって意味の違いがあるという性質のことを言う．そして，その意味の違いのことを単語の多義と言う．単語の多義は細かく定義すればきりがない．したがって，多義をどこまで区別するべきかはタスクの目的に依存して決めることになる．機械翻訳の問題では，適切な翻訳(訳語/訳句)が選択できればよく，単語の多義はその翻訳の異なりとして定義できる．機械翻訳における単語の多義性解消の方法，つまり，訳語選択の方法は，これまでにも数多く提案されてきた．それらの方法を，利用している言語資源という観点から分類すると，対訳コーパスを用いるもの，対訳単語辞書と目的言語の単言語コーパスを用いるもの，対訳単語辞書と，原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いるもの，原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いるものに大別できる．我々は，多様な情報を用いれば用いるほど良い結果が得られると考え，対訳単語辞書，対訳コーパス，および，原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いる．対訳コーパスには大きくパラレルコーパスとコンパラブルコーパスの二種類があり，我々はそのうちパラレルコーパスを用いる．さらに，文対応をとる際の誤りを軽減するために，パラレルコーパスとして，対訳用例(句/文)集合(翻訳メモリ，トランスレーション・メモリー，以下TM)を用いる．我々のシステムは，入力文と対象単語が与えられると，その対象単語に関して入力文と対訳用例集合との類似度を求め，類似度が最大となる用例集合を用いて対象単語の訳語選択を行なう．類似度は，用例に基づく手法と機械学習モデルを用いて計算される．類似度の計算には，文字列の類似性，入力文における対象単語の前後の数単語，入力文中の内容語とその訳語候補のコーパスにおける出現頻度などを考慮する．このシステムで用いた訳語選択のためのモデルは次のような特徴を持つ．各対訳用例内の単語対応をとり，同じ対訳単語ペアを持つ対訳用例をまとめてひとつの用例集合とする．そして，そのペアの原言語(対象単語と同じ言語)の単語が同じである用例集合をまとめ，そのまとまりごとにモデルを作成する．以降で，各用例集合内で共通する対訳単語ペアを見出し語と呼ぶ．そして，そのペアの各単語をそれぞれ原言語見出し語，目的言語見出し語と呼ぶ(原言語が日本語，目的言語が英語の場合，それぞれ日本語見出し語，英語見出し語と呼ぶ)．対象単語に関して入力文と表層的にほぼ同じ用例が用例に基づく手法により見つかった場合にはその用例を優先的に翻訳に使う．見つからなかった場合には，機械学習モデルに基づく手法により対象単語に関して入力文と最も類似した用例集合を選択して翻訳に使う．言語資源としては，対訳単語辞書，対訳コーパス，および，原言語と目的言語の間で互いに対応関係がない各単言語コーパスを用いる．2001年の春，単語の多義性解消のコンテスト第2回Sensevalが開催された．このコンテストは1998年に，英語と二つのヨーロッパ言語(イタリア語とフランス語)を対象として始まったものである．2001年には新たに他のいくつかの言語に関するタスクが追加された．我々はそのうち日本語に関して追加された翻訳タスクに参加した．本論文では，そのコンテストでの結果をもとに，我々が本論文で提案する手法の有効性および精度向上にどのような情報が有効であったかについて述べる．</section>
  <section title="訳語選択モデル">入力文と対象単語が与えられたとき，対象単語の適切な訳語を選択するタスクを考える．そして，このタスクで，対象単語に関して入力文との類似度が最大となる用例あるいは用例集合を用いて対象単語の訳語を選択するモデルを考える．本論文ではこのモデルを訳語選択モデルと呼ぶことにする．以降では，原言語として日本語を，翻訳の目的言語として英語を仮定して説明する．入力文と用例との類似度は次の二つの方法により求める．文字列の類似性に基づく方法(手法1)類似度は，入力文と日本語用例との間で一致した文字列に基づいて計算する．機械学習モデルに基づく方法(手法2)類似度は，対象単語の各訳語候補に対して機械学習モデルにより求められる確率値あるいは確信度と定義する．入力文と対象単語が与えられたとき，まず手法1で対象単語に関して入力文との類似度が閾値以上となる用例があるかどうかを調べ，ある場合はその類似度が最大となる用例の番号あるいはその用例の英語見出し語を出力し，ない場合は，手法2で対象単語に関して入力文と最も類似した用例集合を選択し，その英語見出し語を出力する．以降で，各方法について詳細に述べる．</section>
  <subsection title="文字列の類似性に基づく方法(手法1)">対象単語に関して入力文との類似度が高い日本語用例があれば，TMを信頼しその用例の番号あるいはその英語見出し語を出力する．入力文と一致する割合を調べる際，日本語用例には文末処理(句末の場合も含む)を施しておく．文末処理としては，機能語，動詞や形容詞の活用部分，サ変動詞をすべて削除するということを行なった．例えば，図~の用例にこの文末処理を施すとそれぞれ，「母に遠慮」「母への遠慮」「献金を遠慮」となる．入力文との一致する割合は，動的計画法により入力文と日本語用例を文字単位で比較して差異を求め，一致した文字列の割合として求める．実験では，この差異をUNIXのdiffコマンドを用いて求めた．類似度は以下の式により求める．類似度&amp;=&amp;入力文とのdiffをとったときに一致した文字数文末処理を施した日本語用例の文字数eqnarrayこのとき，用例が複数の部分に分割されて一致する場合があり，類似度が大きくても多くの部分に分割されてしまう場合は類似用例としてふさわしくない場合が多い．そこで，分割数に閾値を設け，閾値より分割数が多い用例は選択対象外とする．類似度が最大となる用例が複数ある場合には，最長の日本語用例を持つ用例の番号を返す．ただし，一致した部分が日本語見出し語の長さより長い場合に限る．しかしながら，TMに全ての可能な用例を登録することは難しく，常に入力文と表層的にほぼ同じものがあることは期待できないため，類似度が最大となる用例が常に訳語選択に最適な用例であるとは限らない．そこで，類似度に閾値を設け，閾値以上の類似度を持つ用例がない場合は次節に述べる方法を用いる．</subsection>
  <subsection title="機械学習モデルに基づく方法(手法2)">入力文と表層的にほぼ同じ用例がない場合，より多様な情報を用いて類似度を求める必要があると考えられるが，そのために複雑な規則を作成するのは避けたいため，類似度の計算には機械学習モデルを用いることにした．機械学習モデルによって分類するクラスは対象単語の訳語/訳句候補とした．訳語選択モデルは，節でも述べたように，同じ日英対訳単語ペアを持つ対訳用例をまとめてひとつの用例集合とし，そのペアの日本語単語が同じである用例集合をまとめ，そのまとまりごとに作成する．したがって，各モデルでは，同じ見出し語を持つ用例は同じクラスとなり，入力文に対しすべて同じ類似度となる．そして，日英の見出し語つまり各用例集合内で共通する対訳単語ペアのうち，日本語見出し語は共通で，英語見出し語が訳語/訳句候補となるため，各用例集合の英語見出し語がモデルにより分類するクラスとなる．TMでは見出し語は予め人手で与える．例えば，図~の場合，日本語見出し語は「遠慮」であり，英語見出し語はそれぞれ，「feelconstrained」，「constraint」，「refrain」となる．これらを&lt;ehead&gt;&lt;/ehead&gt;のタグで明示すると図~のようになる．英語見出し語が動詞の場合はすべての語尾変化形を基本形で代表させる．さらに，TMの各日本語見出し語を対訳辞書で索き，TMになかった訳語/訳句候補が見つかれば，それらも新たなクラスとして追加する．[htbp]figure*学習には，TMの用例だけでなく，他の対訳辞書あるいは対訳コーパスから抽出した用例も用いる．抽出する用例は，TMの各用例集合と同じ日英見出し語を含む対訳用例とし，抽出した用例はTMの各用例集合に追加する．以降で，用例数および学習文数は，ともに各日本語見出し語に対しその語を含む用例の数を意味するものとし，TMに最初に含まれていた用例の総数を用例数，他の言語資源から抽出して追加した後の用例の総数を学習文数と呼んで区別する．また，クラス数とは各日本語見出し語に対するクラスの数つまり，訳語/訳句候補の種類の数を意味するものとする．機械学習モデルとしてはSVM(SupportVectorMachine)，ME(MaximumEntropy)，DL(DecisionList)，SB(SimpleBayes)を用いる．日本語見出し語ごとに，各モデルを用いて学習データでクロスバリデーションを行ない，平均精度が最も高いモデルをテストに用いる．各クラスの確率値あるいは確信度は基本的に，文脈の集合をB，クラスの集合をAとするとき，文脈b(B)でクラスa(A)となる事象(a,b)の確率分布p(a,b)として求められる．SVMではこのような確率分布は得られないが，便宜的に最適のクラスに対して確信度を1，その他のクラスに対して0とする．次に，各機械学習モデルの説明，各種パラメータ等の設定について述べる．</subsection>
  <subsubsection title="シンプルベイズ">このモデルでは，ベイズの定理に基づき，文脈bのときにクラスaが生起する確率を推定する．そして，確率値が最も大きいクラスを最適なクラスとする．文脈bのときにクラスaが生起する確率は次の式で与えられる．p(a|b)&amp;=&amp;p(a)p(b)p(b|a)&amp;&amp;p(a)p(b)_ip(f_i|a)eqnarrayここで文脈bは，予め設定しておいた素性f_j(F,1jk)の集合である．p(b)は，文脈bの生起確率で，今回の場合，クラスaには依存せず定数のため計算しない．p(a)とp(f_i|a)は，ともに学習データから推定される確率で，それぞれ，クラスaの出現の確率，クラスaのときに素性f_iを持つ確率を意味する．最尤推定により求めたp(f_i|a)の値は0になることが多く，式()の値が0になり本来求めるべきクラスが正しく求まらない場合が多い．このため，本論文では次の式によりスムージングを行なう．p(f_i|a)=freq(f_i,a)+*freq(a)freq(a)+*freq(a)eqnarrayここで，freq(f_i,a)とfreq(a)は，それぞれ，素性f_iを持ちかつクラスがaである事例の個数，クラスがaである事例の個数を意味する．は実験で定める定数であり，実験では0.0001に固定した．</subsubsection>
  <subsubsection title="決定リスト">このモデルでは，素性f_iとクラスaの組を規則として，予め定めた優先順序でリストに蓄えておき，リストで優先順位の高いところから，入力と素性が一致する規則を適用してクラスを求める．本論文では優先順序として次の式で表わされるものを用いる．p(a|f_i)eqnarrayこれは，ある文脈bでクラスaを出力する確率p(a|b)がもっとも高いクラスaを解とすることと等価であり，本論文では次の式を用いて最適なクラスを特定する．p(a|b)=p(a|f_max)eqnarrayここで，f_maxは次の式によって与えられる．f_max=argmax_f_jFmax_a_iAp(a_i|f_j)eqnarrayまた，p(a_i|f_j)は学習データで素性f_jを文脈とするクラスa_iの出現の割合である．</subsubsection>
  <subsubsection title="最大エントロピーモデル">このモデルでは，素性f_j(1jk)の集合をFとするとき，式()を制約とし，式()で表わされる目的関数つまりエントロピーを最大にするような確率分布p(a,b)を求め，その確率分布にしたがって求まる各クラスの確率のうち，最も大きい確率値を持つクラスを最適なクラスとする．_aA,bBp(a,b)g_j(a,b)=_aA,bBp(a,b)g_j(a,b)forf_j(1jk)eqnarrayH(p)&amp;=&amp;-_aA,bBp(a,b)log(p(a,b))eqnarrayただし，A,Bはそれぞれクラスと文脈の集合を意味し，g_j(a,b)は文脈bに素性f_jがあってかつクラスがaの場合1となりそれ以外で0となる二値関数である．また，p(a,b)は，既知データでの(a,b)の出現の割合を意味する．</subsubsection>
  <subsubsection title="サポートベクトルマシン">サポートベクトルマシンとは，空間を超平面で分割することにより2つのクラスからなるデータを分類する二値分類器のことである．2つのクラスを正例，負例とすると，学習データにおける正例と負例の間隔(マージン)を最大にする超平面を求めそれを用いて分類を行なう．通常は，学習データにおいてマージンの内部領域に少数の事例が含まれてもよいとする拡張(ソフトマージン)や，超平面の線形の部分を非線型とする拡張(カーネル関数の導入)などがなされたものが用いられる．これらの拡張によりクラスを判別することは，以下の識別関数の出力値が正か負かによってクラスを判別することと等価である．f(x)&amp;=&amp;sgn(^l_i=1_iy_iK(x_i,x)+b)b&amp;=&amp;-max_i,y_i=-1b_i+min_i,y_i=1b_i2b_i&amp;=&amp;^l_j=1_jy_jK(x_j,x_i)eqnarrayここでxは識別したい事例の文脈(素性の集合)を，x_iとy_i(i=1,...,l,y_i1,-1)は学習データの文脈とクラスを意味する．また，関数sgn(x)は，x0のときに1，x&lt;0のときに-1となる二値関数であり，各_iは式()と式()の制約のもと式()のL()を最大にするものである．L()&amp;=&amp;^l_i=1_i-12^l_i,j=1_i_jy_iy_jK(x_i,x_j)eqnarray0_iC,,(i=1,...,l)eqnarray^l_i=1_iy_i=0eqnarrayまた，関数Kはカーネル関数と呼ばれ様々なものが提案されているが，本論文では次の式で表わされる多項式カーネルを用いる．K(x,y)&amp;=(xy+1)^deqnarrayここで，C,dは実験的に設定される定数である．本論文ではC,dはそれぞれ1と2に固定した．サポートベクトルマシンは二値分類器であるため，クラスの数が2であるデータしか扱えないが，これにペアワイズ手法を組み合わせることにより，クラスの数が3以上のデータを扱えるようになる．ペアワイズ手法とは，N個のクラスを持つデータの場合，異なる二つのクラスのあらゆるペア(N(N-1)/2個)を作り，各ペアごとにどちらがよいかをサポートベクトルマシンなどの二値分類器で求め，最終的にN(N-1)/2個の二値分類器のクラスの多数決により，最適なクラスを求める方法である．実験では，サポートベクトルマシン(TinySVMを利用)とペアワイズ手法を組み合わせて用いた．</subsubsection>
  <subsubsection title="素性">上述のように文脈bは素性の集合で表わされる．実験に用いた素性は以下のものである．形態素情報(素性集合1)入力文における対象単語の前後三形態素ずつについての文字列，基本形，品詞(大分類，細分類)，活用型，活用形．最大一致となる用例に関する情報(素性集合2)入力文の文字列と連続して一致する部分が最大となる用例を調べ，その用例の英語見出し語および一致した長さをそれぞれ素性として用いる．内容語とその訳語候補の出現頻度(素性集合3)まず，各英語見出し語(各クラス)ごとに次の六種類の文集合を定義する．文集合1:該当する英語見出し語を含む用例において日本語用例を取り出した集合文集合2:該当する英語見出し語を含む用例において英語用例を取り出した集合文集合3:文集合1の類似文の集合．類似文は日本語の単言語コーパスから抽出する．文集合4:文集合2の類似文の集合．類似文は英語の単言語コーパスから抽出する．文集合5:文集合1と文集合3の和集合文集合6:文集合2と文集合4の和集合ある用例の類似文とは，その用例の見出し語とその単語のまわりの文脈の一部を含む文とする．入力文における各内容語とその訳語候補について，上記の各文集合における出現頻度を調べ，それぞれ素性として用いる．内容語は入力文を形態素解析したときに得られる単語のうち，その品詞が名詞，動詞，形容詞，副詞，連体詞であるものとする．ただし，対象単語は除く．内容語の訳語候補は内容語を対訳辞書で索いたときに候補としてあがる単語とする．この素性は文集合，英語見出し語，内容語の出現頻度の和，の組み合せによって表わされ，頻度の和がn回の場合，頻度1からnまでの素性値をもつ素性がすべて観測されたと仮定する．頻度は1以上のもののみ考慮する．例えば，入力文に見出し語以外の内容語がひとつあり，その内容語がクラス「buy」の文集合1に3回出現した場合には，「文集合1：buy：1」，「文集合1：buy：2」，「文集合1：buy：3」の素性が観測されたとする．この素性により，日英の各コーパスにおいて見出し語と共起する単語の頻度を訳語選択の手がかりとして考慮する．</subsubsection>
  <section title="実験と考察"/>
  <subsection title="実験の条件">入力，評価はSenseval-2日本語翻訳タスクのものに従った．TMは320語のもの(1見出し語に対する用例数は約20)が2001年3月中旬に配布された．この中から40語(名詞20語，動詞20語)がコンテストの対象単語として選択され，それぞれについて30語(30出現)ずつテストデータが用意された．対象単語ののべ数は1,200語であった．対訳単語辞書および対訳コーパスとしてはニフティで利用可能な英辞郎を用いた．ここから対訳用例を抽出する際，日英見出し語が対応関係にないものを抽出してしまった場合でも，抽出の際に検索語として用いた日英見出し語が正しい対応関係にあると仮定して学習に用いた．単言語コーパスとしては毎日新聞(1991年から2000年)，日経新聞(1995年から1999年)，産経新聞(1994年から1999年)，LDCデータ(1994年，1995年のデータでWallStreetJournalやAP通信，ニューヨークタイムズなど数年分の新聞記事が含まれる)を用いた．コンテストでは，手法1で類似度最大として選択された用例についてはその用例番号を，手法2で類似度最大として選択された用例集合についてはその英語見出し語を出力して提出した．以下にその際の条件について述べる．手法1における類似度の閾値は1.0，分割数の閾値は0とした．手法2の形態素解析にはJUMANを用いた．手法2における類似文としては，日本語用例に対しては，文末処理を施して得られる文字列を含む文を，英語用例に対しては，英語見出し語を含む文を抽出した．機械学習モデルについては，時間の制約があったため，単語によっては学習が終了しない場合があり，クロスバリデーションにより最適なモデルを選択することはできなかった．コンテストで最終的に選択したモデルの内訳は以下の通りであった．SVM:23単語(名詞12，動詞11)DL:12単語(名詞8，動詞4)SB:5単語(動詞5)</subsection>
  <subsection title="実験結果">コンテストの結果を表~にあげる．我々のシステムの精度は63.4,%であった．単語ごとの精度と用例数，学習文数，クラス数との関係は表~の通りである．[htbp]table*正解は各対象単語ごとにひとつあるいは複数与えられ，各正解には，対象単語の翻訳に適切であるかどうかを考慮した複数段階による評価が付与されている．正解は以下の基準で◎，○，△の各段階に分けられた．正解がTMの用例の場合◎:翻訳に利用できる用例の場合．日本語用例の品詞，時制，単複，微妙なニュアンス等は必ずしも一致しない．○:評価単語のみに着目すれば妥当な訳語であるが，翻訳用例として使うことは望ましくない用例．△:評価単語のみに着目すれば妥当な訳語であるが，翻訳用例として直接は使えない用例．正解が翻訳の場合◎:翻訳に利用できる場合．品詞，時制，単複，微妙なニュアンス等は必ずしも一致しない．○:評価単語のみに着目すれば妥当な訳語であるが，翻訳に使うことは望ましくない場合．コンテストの結果は一番緩い評価基準で評価したものである．一番緩い評価基準とは，正解をゆるくとる(上記の基準で，TMの◎，○，△，翻訳の◎，○をすべて正解とする)場合，一番厳しい評価基準とは，正解を厳しくとる(◎のみ)場合を意味する．一番厳しい評価基準で我々のシステムの出力を評価した場合，全体の精度が50.6,%(607/1,200)，その内訳は，手法1の精度が82.0,%(82/100)，手法2が47.7,%(525/1,100)であった．表~から，一番緩い評価基準で全体の精度を比べると，上位の二システムとは10,%程度以上の差があるが，一番厳しい評価基準では，我々のシステムの精度は50.6,%(607/1,200)で，AnonymY1システムの精度50.2,%(602/1,200)とほぼ同等であった．また，一番緩い基準でも，名詞全体に対する精度は，我々のシステムの精度は69.3,%(416/600)で，AnonymY1システムの精度66.8,%(401/600)と同等以上の結果が得られている．最も良かったAnonymXシステムの精度59.0,%(708/1,200)には遠く及ばなかったが，後の節に示すように，追加実験により我々の手法で62.4,%(749/1,200)の精度が得られ，潜在的には66.0,%(792/1,200)の精度が得られる可能性があることが分かったため，結果のみから判断すると，我々のシステムはAnonymXシステムと同程度以上の性能であるとも考えられる．手法そのものについては，AnonymX,AnonymY1については具体的な方法が明かされていないため，現時点での比較はできない．表~から，クラス当たりの学習文数の少ない名詞と，クラス当たりの学習文数の非常に多い動詞の訳語選択精度が悪いといった傾向が見られる．前者は学習データの不足が原因であると考えられる．後者については，クラスの数が多く，日本語用例は似ているが異なるクラスに分類されているという場合もあり，また学習データが特定のクラスに偏っているということもなかったため，ベースラインの精度そのものが低い難しい問題であったと考えられる．実際，すべての入力に対し対象単語ごとに常に学習データで最も学習文数の多いクラスを出力するシステムを作成して実験したところ，これらの単語に対する精度は低いことが分かった．</subsection>
  <subsection title="手法1と精度">手法1はTMを最も単純に利用した方法であり，この手法による精度は高いことが望ましい．実験(コンテスト)では手法1による精度は91.0,%(91/100)であった．この手法により誤った例(正解と一致しなかった例)を表~にあげる．誤ったのは，入力文と日本語用例との類似性だけから推定することが困難だったためである．類似度はすべて1であり，日本語用例そのものは類似していると思われるが，英語用例はそれぞれひとつずつしか与えられておらず，文脈からそれらの用例を翻訳として用いるのは不適切であると判断されたものと思われる．手法1はTMの日本語用例の文字列情報のみを用いる方法であるため，このような場合，他の用例を適切に選択することはできない．[htbp]table*次に，手法1が適用された100対象単語に対し手法2を適用したときの精度を調べた．結果は49.3,%(34/69)であった．ただし，100語のうち31語は，TMの用例に含まれる英語見出し語ではなく対訳辞書を索いて得られた英語見出し語を選択したため評価していない．仮にこれらがすべて正解だったとしても精度は65,%(65/100)となる．したがって，手法1では，適用された語に対してはかなり良い精度が得られることが分かる．手法1で正しく手法2で訳語選択を誤ったものは30語であり，それらの語を含む入力文には慣用的な表現が多く見られた．そのうち，手法1によって適用された用例には次のようなものがあった．以下で，＜＞内は見出し語を表わす．＜胸＞を張る:to＜lookproud＞話に＜花＞が咲く:toengagein＜animated＞conversation一役＜買う＞:to＜offer＞tohelp調子に＜乗る＞:tobe＜carriedaway＞上記のような慣用的な対訳用例を含む用例集合は，その集合に含まれる用例数が少ないため学習データが不足し，手法2で適切に選択することは難しい．このように予め学習データが少ないと分かったクラスつまり訳語/訳句候補は，慣用表現である可能性が高いと考え，個別にTMに用例を追加するなどしてTMを充実させるのが効果的である可能性が高い．この場合，TMに用例を追加するだけでなく，表~にあげたような手法1による誤りもなくす必要があるため，現状のTMを次の手順で変更する必要があると考えている．各日本語用例の翻訳として可能なものはすべて登録する．日本語用例が同一の用例が複数ありかつその用例を含む用例集合内の用例数が少ない場合は，日本語用例間に違いが出るまでそれぞれの用例の前後の文脈を伸ばす．このようにTMの用例を変更することにより，表~の誤りもほぼなくなると考えている．</subsection>
  <subsection title="手法2と精度">手法2ではTMの用例だけでなく他の言語資源から抽出した用例も用いる．もしTMの用例しか用いなければ，1クラスあたりの学習文数は平均1.4となる．これでは機械学習をするにはデータが少な過ぎ，強力な学習モデルを用いても高い精度は期待できない．ちなみに，コンテストに参加したシステムのうち，上位の4システム以外は，配布されたTM用例のみを用いていた．最高のもので50,%程度の精度であり，他の言語資源を用いたことによる効果は10,%以上と考えられる．我々の手法でもTM用例のみを用いた場合と他の言語資源を用いた場合の結果を比較したところ，他の言語資源を用いた場合の方が6,%から7,%程度良くなることが分かった．他の言語資源を用いることの有効性については，詳しくは節で述べる．補強した学習データでは，1クラスあたりの学習文数の平均は全体で60.9文(名詞44.2文，動詞75.3文)であった．基本的に学習データが少ない語に対しては，さらに他の言語資源を利用してデータを追加すればよいと考えられる．しかし，学習文数が平均より多いにもかかわらず精度が平均より悪かったものは，それぞれ名詞が3語(そのうちSVMが2語，DLが1語)，動詞が5語(そのうちSVMが1語，SBが4語)であり，この結果は，単純に学習データを増やしても精度が良くならない場合があることを示している．1クラスあたりの学習データが多いにもかかわらず精度が良くなかった原因としては，以下のことが考えられる．SBモデルと素性集合の相性(4例)SBモデルによる精度はすべて悪かった．これは実験に用いた素性集合と，すべての素性を独立と仮定して扱うSBモデルの性質が合わなかったためであると考えられる．追加した学習データの質(4例)学習データの多くは他の言語資源から抽出したものである．コンテストでは，他の言語資源から対訳用例を抽出する際に，日英の見出し語が出現しているかどうかだけを手がかりにしていた．そのため，日英見出し語が対応関係にないものも抽出していた．例えば，haveやtake，lookなど一般に出現頻度が高く，日本語に訳したときその訳語に曖昧性のある単語が英語見出し語である場合には，見出し語間に対応関係がない対訳用例も多く抽出してしまう．この単語対応を考慮していなかったことによる影響は，学習の際に顕著に現われる．学習モデルにおけるクラスは英語見出し語で表わされる．そのため，日英の見出し語間に対応がとられていないと，ひとつの用例に見出し語となり得る語が複数種類現われるとき，その用例の見出し語が特定できず曖昧になる．その結果，同じ用例が複数のクラスの正例として用いられることになり，この用例を用いて学習したモデルでは，正しくクラスを分類できなくなる．今回の実験で，SVMなどで学習が終了しなかったのは，このような例が多くあったことがひとつの原因であると考えている．以上のような問題を解消し，精度を改善するには，次のような対策を講じる必要がある．モデル，素性の選択方法を工夫する．学習データを補強する際，他の言語資源から抽出した対訳用例における単語対応をとり，日英見出し語が対応関係にあるものだけを選択するようにする．モデルの選択方法については，当初クロスバリデーションによるモデル選択を採用する予定であったが，コンテストの際には時間的な制約のため実現できなかった．そこで，学習データでクロスバリデーションを行ない，平均精度が最大となるモデルを最適なモデルとして選択するようにし再実験を行なった．クラスである英語見出し語は，評価，比較が容易になるようにTMの用例のみから選択した．評価は次の二種類の評価方法で行なった．学習データの数は21,650，クラスの数は平均で11.0(441/40)であった．学習データを先頭から順番に10個置きに同じ集合に含まれるよう分割し，各単語ごとに10分割のクロスバリデーションをして平均精度が最大となるモデルを選択した結果，選択されたモデルの内訳は次の通りであった．ME:21単語(名詞14，動詞7)SVM:12単語(名詞4，動詞8)DL:7単語(名詞2，動詞5)結果は表~の通りであった．手法1での類似度および分割数の閾値としては，学習データに対する精度が最大になったときの値つまり1.0と0，および，テストデータに対して最大の精度が得られたときの値つまり0.8と1の二種類をあげた．閾値が1.0と0のときの，単語ごとの精度と学習文数，クラス数との関係は表~の通りである．[htbp]table*クラスである英語見出し語は，上述のようにTMの用例のみから選択しているため，表~と表~を単純に比較することはできない．しかし，今回の追加実験で用いたクラスはコンテストのときに用いたクラスに包含されるため，コンテストの出力のうち追加実験で用いたクラスを出力したもののみを対象として評価した．ここで対象となった単語は861語であり，コンテストのときの精度は評価方法1で61.8,%(532/861)，評価方法2で58.0,%(500/861)であり，追加実験での精度は評価方法1で68.4,%(589/861)，評価方法2で63.5,%(547/861)であった．コンテストでモデル選択を行えていたら，5,%程度精度が良かった可能性がある．二つの評価基準により精度が4,%程度異なるのは，コンテストで正解とされた用例における見出し語と同じものを含む用例が必ずしもすべて正解に含まれているとは限らないためである．つまり，評価方法1より評価方法2の方が厳しい基準となっているためである．例えば，「わがままを言わず，全力で頑張りたい」という入力文で対象単語が「言う」のとき，＜言う＞までもない:tobeneedlessto＜say＞という用例は正解に含まれていたが，＜言い＞たいことを言う:tohaveone's＜say＞という用例は同じ見出し語「言う」と「say」を持つにも関わらず正解には含まれていなかった．このような場合，評価方法1では「say」と回答しても正しいと評価されるが，評価方法2では，さらに用例を正しく選択して回答できないと正しいとは評価されない．このような見出し語と正解用例とのずれが確認されたのは14単語についてであり，残りの26単語については見出し語を含む用例はすべて正解に含まれていた．ずれがあった単語の内訳は，表~の通りである．この表で，「ずれがあったもの」とは，テストの対象単語30出現のうち，正解用例の見出し語と同じものを含む用例がひとつでも正解に含まれなかった場合の数のことである．このずれは，見出し語が同じでも文脈によって意味が違う場合があることを示している．対象単語の翻訳に使える用例を選択するというタスクでは，訳語選択以上の意味的な曖昧性解消を要求していると言えるだろう．</subsection>
  <subsection title="素性と精度">この節では，各素性集合と精度との関係について述べる．表~に，実験に用いた素性集合の種類とそのときに得られた精度をあげる．「機械翻訳モデル」の欄にはクロスバリデーションによって選択された機械学習モデルの数を表わす．手法1での類似度および分割数の閾値はそれぞれ，学習データに対する精度が最大になったときの値つまり1.0，0とした．括弧内の数字は，素性集合をすべて用いたときに得られた精度からの増減を表わす．表~から素性集合1は精度向上に貢献していることが分かるが，素性集合2と素性集合3は精度を下げる結果となっていたことが分かる．これは，学習データの文数が平均49.1文(21,650/441)と少なく，過学習に陥ったためと考えられる．</subsection>
  <subsection title="モデルと精度">この節では，複数の機械学習モデルから最適なモデルを選択した場合と，単独の機械学習モデルを用いた場合との違いについて述べる．これまでの実験では，個々の単語に対し，複数の機械学習モデルからクロスバリデーションによりモデルを選択していたが，すべて単一の機械学習モデルを用いた場合との精度の違いが明らかではなかった．そこで，手法2で各々の機械学習モデルをそれぞれ単独で用いた場合の実験を行なった．素性としては，前節で最も良い精度が得られた素性集合1を用いた．手法1における類似度と分割数の閾値は学習データで最適値となった1.0と0に設定した．一番緩い基準と厳しい基準で評価した結果を表~と表~にあげる．この表で，混合とは複数の機械学習モデルから最適なモデルを選択した場合を意味する．混合(上限値)の行にあげた精度は，個々の単語ごとに，複数の機械学習モデルからテストデータで最も良い精度が得られるモデルを選択した場合の精度であり，複数のモデルを用いる場合の潜在的な上限値を意味している．また，最頻とは常に学習データで最も学習文数の多いクラスを出力するモデルを意味する．これらの結果から，これまでの実験で用いてきたクロスバリデーションによるモデル選択の方法は単独の学習モデル(SVM)を用いる方法に比べて劣ること，しかし，潜在的には複数のモデルを組み合わせることにより，より良い精度(5,%程度良い精度)が得られることが分かる．</subsection>
  <subsection title="学習データと精度">この節では，他の言語資源から対訳用例を自動抽出して用いた場合の効果について述べる．学習に，それぞれ，TM用例のみを用いた場合，他の言語資源から自動抽出した対訳用例のみを用いた場合，すべて用いた場合の三種類の比較実験を行なった．訳語選択モデルとしては，これまでの実験で最も精度の良かった組み合わせのモデル，つまり，手法1(類似度と分割数の閾値はそれぞれ1.0と0に設定)とSVMの組み合わせに素性集合1を用いた場合のものを用いた．結果を表~にあげる．評価は一番緩い基準で行なった．表~より，TM用例だけでなく，他の言語資源から自動抽出した対訳用例も用いた場合に，より精度が良くなることが分かる．他の言語資源から対訳用例を抽出する際には，日英の見出し語が出現しているかどうかだけを手がかりにしていたため，日英見出し語が対応関係にないものも抽出してしまっていたが，現段階ではこの単語対応を考慮していなかったことによる悪影響よりも自動抽出した用例が精度向上へ貢献する度合いの方が顕著に勝っていると言えそうである．今回用いたTMは新聞記事から抽出した語句を元に人手で作成されたものであり，コンテストの対象である新聞記事と同じ，特化したドメインの知識と考えられる．一方，自動抽出した用例は一般的な対訳辞書の用例であり，一般的なドメインの知識であると考えれる．表~の結果は，一般的なドメインの知識と特化したドメインの知識が相補的に影響した結果であるとも言えるだろう．</subsection>
  <section title="関連研究">これまでに，対訳コーパスを用いた統計的なあるいは機械学習モデルに基づく訳語選択の手法が数多く提案されてきた(例えば，など)．我々も同様に機械学習モデルに基づく手法を用いている．これまでに提案されてきた手法との主な違いは，SVMなど複数の機械学習モデルを利用している点と，それらの機械学習モデルと用例に基づく手法とを組み合わせて利用している点，さらに，これまでの方法がすべての単語に対し同じ機械学習モデルを用いているのに対して，我々は単語ごと(原言語見出し語ごと)に異なるモデルを作成し，その中から最適な機械学習モデルを選択している点にある．実験では，クロスバリデーションによる選択は単独の学習モデル(SVM)より劣ることが分かったが，潜在的には複数のモデルを組み合わせることによりより良い精度(5,%程度良い精度)が得られることも示した．用例に基づく手法として我々が用いたものはSatoが提案した手法に類似している．我々の手法との主な違いは，類似度を計算する際に課す制約である．Satoの手法では特に制約は課していないが，我々の場合は，入力文と用例とがいくつかの部分に分割されて一致する場合にその分割数を制限する，対象単語と同じ見出し語を持つ用例に限定する，などの制約を課している．実験により，前者の制約を課すことによって良い結果が得られることが分かった．Satoの手法では，文字列の並びの順序が異なる場合でも一致したと見なす柔軟さがある．その柔軟性を我々の手法にも採り入れたい．本論文で述べたTMあるいはそれと同様の対訳用例を訳語選択に用いた研究としては，BaldwinやSumitaの研究がある．Baldwinは原言語用例の情報を用いてTMから訳語選択に最も適した用例を選択する方法を提案した．彼はbigramなどの文字列情報のみを用いたときが最も精度良く類似した用例を選択できると報告している．我々の方法でもbigramなどの文字列情報を素性として利用するようにすれば，精度向上が期待できると考えている．SumitaはTMの利用方法という点で我々と類似した方法を提案している．彼の方法では，我々の手法と同様に，TMの用例を目的言語見出し語ごとに用例集合としてまとめて利用している．そして，入力文と用例集合をそれぞれ検索質問文，文書と考え，情報検索でよく用いられるベクトル空間モデルを用いて入力文と最も類似した用例集合を選択する．この手法では学習は行なわれないが，我々の手法では学習により，入力文と対象単語に関して最も類似した用例集合を選択する．また，本論文では，対訳用例の訳語選択への利用方法に関する知見として，今回用いたTMのように一見出し語あたり30個程度の例があれば，それをもとに自動抽出した対訳用例と併せて学習に用いることで精度が向上することを示した．機械翻訳では，Marcuが用例に基づく手法と統計的機械翻訳モデルを組み合わせて一文全体を翻訳する手法を提案した．統計的機械翻訳モデルを用いて入力文の最適な翻訳を探索する際に，必ずしも最適解を探索するのではなく，入力文と一致するTM用例があればそれを優先する，という制約を課すことにより翻訳精度が向上したと報告している．我々の手法では，用例に基づく手法と機械学習モデルを組み合わせて，一文全体の翻訳ではなく，各単語の訳語選択を行なう．また，Marcuは完全一致となる用例のみを用いているが，我々はいくつかの部分に分かれて一致する用例や部分一致となる用例も用いている．実験ではこのような用例も用いた場合に精度が向上したことから，一文全体の翻訳の際にも部分一致となる用例を用いるとより良い結果が得られる可能性が高いと考えている．今後，我々の手法が一文全体の翻訳の精度にどれだけ貢献するかを調べたい．</section>
  <section title="まとめ">本論文では，機械翻訳における訳語選択の手法について述べた．我々のシステムは，入力文と対象単語が与えられたとき，対象単語に関して入力文と用例(あるいは用例集合)との類似度を求め，類似度が最大となる用例(あるいは用例集合)を用いて対象単語の訳語選択を行なう．類似度は，入力文，対象単語，用例に関する様々な情報を手がかりとして考慮し，用例に基づく手法と機械学習モデルに基づく手法を組み合わせて求める．学習には，TMの用例だけでなく，他の対訳辞書あるいは対訳コーパスから抽出した用例を用い，学習の際には，原言語と目的言語の間で互いに対応関係がない各単言語コーパスから抽出した頻度情報なども考慮する．コンテストでの結果および，追加実験の結果を分析して分かったことは以下の通りである．文字列の類似性に基づく方法(手法1)は慣用的な表現を含む文などに対して精度が良かった．対訳用例を自動的に収集して学習データに追加することにより，より良い精度が得られることが分かった．文字列の類似性に基づく方法(手法1)と機械学習モデルに基づく方法(手法2)を組み合わせたときに最も良い精度が得られた．今後の課題としては，以下のことを考えている．学習データの質の改善．他の言語資源から追加した対訳用例の英語見出し語が，日本語に訳したときその訳語に曖昧性のある場合には，データの質が精度に悪影響を及ぼす場合があった．今後，対訳用例における単語対応をとり，見出し語間に対応関係があるもののみ選択するようにし，学習データの質を改善したい．最適な機械学習モデルの選択方法の模索．本論文では，個々の単語に対して最適な機械学習モデルを選択するために，学習データにおいてクロスバリデーションを行ない，平均精度が最大となるモデルを最適なモデルとして採用したが，単独のモデル(SVM)に劣ることが分かった．今後，最適なモデルの選択を学習モデルにより決定するstacking法などを適用するなど，最適なモデルの選択方法を模索したい．新たな素性の導入と選択．見出し語とそのまわりに出現する単語の実データにおける分布をできるだけ反映させたモデルを作るために，単言語コーパスから抽出した単語の頻度情報を素性として利用した．しかし，過学習に陥り精度を下げる結果となった．今後，単言語コーパスに関する情報で何が訳語選択に貢献する有用な情報であるかを模索したい．謝辞flushleft本研究を進めるにあたって，データを利用させて頂いた毎日新聞社，日経新聞社，産経新聞社，ニフティ，LDCの各社に感謝する．また，貴重なコメントを下さった査読者，ならびに，本特集号編集委員長である東京大学の黒橋禎夫先生に感謝の意を表したい．document</section>
</root>
