<?xml version="1.0" ?>
<root>
  <title>サポートベクタマシンを用いた対訳表現の抽出</title>
  <author>佐藤健吾斎藤博昭</author>
  <jabstract>本論文では，機械学習の一手法であるサポートベクタマシンを用いて文対応付き対訳コーパスから対訳表現を抽出する手法を提案する．サポートベクタマシンは従来からある学習モデルに比べて汎化能力が高く過学習しにくいためにデータスパースネスに対して頑健であり，カーネル関数を用いることによって素性の依存関係を自動的に学習することができるという特徴を持つ．本手法では対訳モデルの素性として，対訳辞書による素性，語数による素性，品詞による素性，構成語による素性，近傍に出現する語による素性を使用し，サポートベクタマシンに基づく対訳表現の対応度を用いて対訳表現を抽出する．既存の手法は対訳表現の対応度の計算に単語の共起関係を利用しているためにデータスパースネスに陥りやすく，低頻度の対訳表現の抽出は困難であるのに対して，本手法は，訓練コーパスによって対訳モデルをあらかじめ学習する必要があるが，一旦モデルを学習してしまえば低頻度の対訳表現でも抽出が可能であるという特徴を持つ．</jabstract>
  <jkeywords>対訳辞書，機械翻訳，サポートベクタマシン</jkeywords>
  <section title="はじめに">empty機械翻訳，言語横断的な検索や要約など複数の言語を同時に扱うシステムにおいて対訳辞書は必要不可欠であり，その品質がシステム全体の性能を左右する．これらに用いられる対訳辞書は現在，人手によって作成されることが多い．しかし，人手による作成には限界があり，品質を向上するためには膨大な労力が必要であること，辞書の記述の一貫性を保つことが困難であることが問題となる．このことからコーパスから自動的に対訳辞書を作成しようとする研究が近年盛んに行われている~．しかし，これらの研究の多くは対訳表現の対応度の計算に単語の共起関係を利用しているためにデータスパースネスに陥りやすく，そのため小規模なコーパスから対訳表現を抽出することは難しい．対訳コーパス自体があまり多くない現状では，小規模な対訳コーパスからでも対訳表現を抽出できることが望ましい．本論文では，サポートベクタマシン~を用いて文対応付き対訳コーパスから対訳表現を抽出する手法を提案する．サポートベクタマシンは訓練事例と分割境界の距離(マージン)を最大化する戦略に基づく手法であり，従来からある学習モデルに比べて汎化能力が高く過学習しにくいために，データスパースネスに対して頑健であるという特徴を持つ．さらにカーネル関数を用いることによって非線形な分割境界を学習したり，素性同士の依存関係を自動的に学習することが可能である．このため，自然言語処理の分野でもテキスト分類~，Chunk同定~，構文解析~などに応用されている．我々の手法は，訓練コーパスによって対訳モデルをあらかじめ学習する必要があるが，一旦モデルを学習してしまえば，訓練コーパスにおいて出現回数が少ない対訳表現あるいは訓練コーパスにおいて出現しなかった対訳表現でさえも抽出することができる．したがってある程度大規模な対訳コーパスから優れた対訳モデルを学習しておけば，サポートベクタマシンの高い汎化能力によって低頻度の対訳表現でも抽出が可能であるという特徴を持つ．本論文の構成は以下の通りである．~節ではサポートベクタマシンについて説明し，~節ではサポートベクタマシンを用いて対訳表現を抽出する手法を述べる．~節では我々が提案した手法の有効性を示すために行った実験の結果とそれに対する考察を述べる．~節において関連研究との比較を行う．最後に~節で本論文のまとめを述べる．</section>
  <section title="サポートベクタマシン">サポートベクタマシン(SupportVectorMachine,以下SVM)は，d~個の素性を持つ事例をd~次元ベクトルによって表し，R^dにおいて2~つのクラスに線形分離する二値分類器である．与えられた事例x=(x_1,x_2,,x_d)^tがクラスX_-1,X_+1のどちらに属するかを式~()によって判別する．ここでgは2~つのクラスを分離する超平面であり，wとbは学習によって決定する．訓練事例x_1,,x_nに対する教師信号y_1,,y_nを以下のように与える．[y_i=.]訓練事例が線形分離可能である場合には，式~()を満たすようなw,bは複数存在することから以下のような制約を与える．SVMでは，訓練事例と分割境界の間の距離(マージン)を最大化する戦略に基づきパラメータw,bを決める．詳しい導出は文献~に譲るが，最終的にマージンの最大化の問題は式~()の条件の下に||w||^2/2を最小化する問題に帰着する~．これを2~次計画法によって解くことで最適な分離平面gが得られる．事例xに対してg(x)の符号はクラスを表し，絶対値はクラス分けの確信度を表す．また，以下のようにシグモイド関数によってxがクラスX_+1に分類される確率を近似することができる~．非線形分離への拡張:線形分離が困難な事例に対しても，前処理として非線形な写像:R^dR^d'を用いてそれらをより高次元に写像することによって線形分離できる場合がある．写像先の空間R^d'において線形分離を行えば元の空間R^dにおいて非線形分離を行っているのと同じことになる．詳しい導出は省略するが，SVMでは学習，識別アルゴリズムにおいて事例間の内積しか使用していない点を生かし，各事例間の内積x_i^tx_jを式~()に置き換えることによって高次元への写像を実現する．Kはカーネル関数と呼ばれる．実際には自体の計算をする必要がないので，計算量の面でも非常に効率的である．よく使われるカーネル関数の例としては多項式型カーネル関数~()などが知られている．p~次の多項式型カーネル関数による非線形分離は，元の空間R^dにおいてはp~個の素性の依存関係を考慮していることに相当する．</section>
  <section title="SVM を用いた対訳表現の抽出">本論文で提案する手法は，対訳文となっている日本語文と英語文から，その中に含まれる句の対訳関係を抽出する．その手法は以下の2~つの手順から構成される．本手法の概略図を図~に示す．</section>
  <subsection title="使用する素性">SVMを対訳関係の抽出に用いるためには，対訳対候補から素性ベクトルを作成する必要がある．本論文で提案する手法では表~のような素性を用いて素性ベクトルを構成した．既存の辞書を使用する素性を2~種類用いる．素性~(1a)は，対訳対候補に含まれる語について辞書引きを行い，対訳となっている単語の組(対訳単語対)が対訳対候補に含まれていればそれを素性とする．対訳関係となっている表現には対訳単語対が多く含まれることに基づく素性である．辞書に含まれる対訳単語対を素性ベクトルの次元に割り当て，対訳対候補内に対訳単語対が現れた場合は対応する次元の値を1とし，そうでなければ0とする．素性~(1b)は，対訳対候補の近傍に出現した語について辞書引きを行い，辞書に含まれる対訳単語対を素性とする．「対訳関係にある表現は近傍に出現している語の出現文脈も(言語の違いこそあれ)似ている」という考え~に基づく素性である．本論文における実験では，同一文に現れる語を近傍とした．辞書に含まれる対訳単語対を素性ベクトルの次元に割り当て，対訳対候補の近傍に対訳単語対が現れた場合は対応する次元の値を1とし，そうでなければ0とする．対訳辞書という既存の知識を素性という形で有効に利用することによって精度の向上を期待することができる．素性~(2a)(2b)は，対訳関係となっている表現は両言語の句の構成語数に相関関係があるという考えに基づく．日英それぞれの句に含まれる語数を素性とした．素性~(3a)(3b)は，対訳関係となっている表現は内容語に関してはその構成比率について両言語間に相関関係があるという考えに基づく．日英それぞれについて句の語数に対する内容語の出現数の割合を素性とする．なお，日本語の内容語は名詞，動詞，形容詞，形容動詞，副詞とし，英語の内容語は名詞，動詞，形容詞，副詞とした．素性~(4a)(4b)は，日英両言語を構成する内容語に素性ベクトルの次元を割り当て，語が出現すれば対応する次元の値を1とし，そうでなければ0とする素性である．素性~(5a)(5b)は，対訳対候補の近傍に現れた内容語に素性ベクトルの次元を割り当て，語が出現すれば対応する次元の値を1とし，そうでなければ0とする素性である．対訳文中に既存の対訳辞書によって辞書引きできない語が多数含まれる場合がある．素性~(4a)(4b)(5a)(5b)はそのような場合に既存の対訳辞書を用いた素性~(1a)(1b)を補完する目的で導入した．カーネル関数によって素性~(4a)と(4b)の依存関係，素性~(5a)と(5b)の依存関係をモデルに組み込むことによって，既存の対訳辞書に現れない対訳単語対における素性~(1a)(1b)と同じ役割を期待することができる．</subsection>
  <subsection title="対訳モデルの学習">訓練コーパス中の各対訳文において対訳関係となっている表現とそうでない表現を人手によって作成する．対応する日英の両文を構文解析し，得られた両言語の句の組合わせについて，対訳表現となっているものを正事例とし，そうでないものを負事例とする．本論文における実験では，組合わせの対象とする句は名詞句と動詞句とした．また，巨大すぎる句構造は対訳表現としての実用的な価値が少ないと思われることから，句の部分構文木の高さが5以下のものを組合わせの対象とした．本論文における実験では，日本経済新聞社英文ビジネスレター文例大事典~を対訳コーパスとして用いた．英文ビジネスレター文例大事典の各対訳文は対訳対となる部分があらかじめマークアップされており，対訳表現として抽出すべき句の制約(部分構文木の高さが5以下の名詞句，動詞句)を満たす対訳対を正事例とした．負事例は，ApplePieParser~とKNP~によって構文解析した結果から対訳表現として抽出する句の制約を満たすもののうち，対訳表現になっていないものを選んだ．具体的には，各対訳文に1~対ずつある対訳対(p_j,p_e)(p_jは日本語句，p_eは英語句)に対して，日英各文を構文解析することによって得られた句p_j'(p_j)やp_e'(p_e)を用いた(p_j',p_e)や(p_j,p_e')を負事例とした~．このようにして得られた全ての事例から~節で述べた方法によって素性ベクトルを作成し，教師信号として正事例には+1，負事例には-1を与える．これを訓練データとして~節で述べたSVMによって対訳モデルの学習を行い，式~()における最適な分離平面gを得る．</subsection>
  <subsection title="対訳対の抽出">まず，抽出の対象となる対訳対の候補を作成する．対訳文になっている日英両言語の文を構文解析し，得られた日英両言語の句の組合わせを対訳対候補の集合とする．訓練データと条件を同じにするために，対象とする句は部分構文木の高さが5以下の名詞句と動詞句とした．生成した対訳対候補から~節で述べた方法によって素性ベクトルを作成する．それらと~節で述べた方法によって得た最適な分離平面gを用いて，その対訳対候補の「対訳対らしさ」を測る．対訳対候補(p_j,p_e)に対応する素性ベクトルをx_p_jp_eとした時，最適な分離平面gを用いて(p_j,p_e)の「対訳対らしさ」を以下の式によって表す．任意の(p_j,p_e)に対して0&lt;sim(p_j,p_e)&lt;1であり，sim(p_j,p_e)が大きいほど(p_j,p_e)が「対訳対らしい」ことを表す．一つの句が複数の句と対応することはないことから，以下のようなアルゴリズムによって対訳対の抽出を行う．thの値によって得られる対訳対の品質を調節することができる．thの値が1に近い時には抽出数が少なくなる代わりに確信度が高い対訳対だけを抽出し，逆にthの値が0に近い時には確信度が多少低いものも抽出することによって抽出数を優先する．上記の処理は1~文単位で行う．そのため~節によって対訳モデルを一旦学習してしまえば抽出対象となるコーパスは小規模なものでもよく，たとえ1~文からでもそこに含まれる対訳対を抽出することができる．</subsection>
  <section title="実験および考察"/>
  <subsection title="実験結果">~節において提案した手法の有効性を確認するために，日本経済新聞社英文ビジネスレター文例大事典~を対訳コーパスとして用いた実験を行った．コーパスに含まれる対訳文のうち，訓練コーパスとして4,000~文，テストコーパスとして1,000~文を用い，~節に従い対訳対候補を生成した．その結果，本論文における実験の対象となった対訳対候補の数は表~の通りとなった．また，対訳対候補に含まれる形態数の平均値とコーパス中における対訳対候補の出現頻度の平均値を表~に示す．得られた事例から~節に従って素性を生成する．素性~(1a)(1b)のために使用する対訳辞書としてEDICT~に含まれる対訳単語対のうち，訓練コーパス中に出現した2,879個を用いた．素性~(4a)(4b)(5a)(5b)のために使用する語として，訓練コーパス中に3回以上出現する語を用いた．その結果，用意した素性の個数は表~の通りとなった．対訳モデルの学習では，カーネル関数を用いない場合(linear)と2~次，3~次，4~次の多項式型カーネル関数(poly2,poly3,poly4)を用いた場合の実験を行った．訓練コーパスから得られた事例を用いて対訳モデルの学習を行い，テストコーパスから得られた事例から対訳対の抽出を行った．それぞれの対訳モデルにおいて抽出アルゴリズムの閾値thの値を0.1，0.5，0.7，0.9と変化させた時の適合率と再現率を図~に示す．各点の右に示した数字が閾値thである．もっとも良い抽出精度を示した2~次多項式型カーネル関数を用いた場合の適合率と再現率を表~に示す．また2~次多項式型カーネル関数を用い，抽出時の閾値th=0.5の時の対訳対の抽出例を表~[tbp]table*に示す．以上の結果から，本論文で提案した手法によって1,000~文という比較的小規模なコーパスから低頻度の対訳対でも高い精度で抽出できることが示された．</subsection>
  <subsection title="対訳モデルと抽出精度">SVMは使用するカーネル関数とそれに付随するパラメータに自由度があり，それらは実験的に決定する必要がある．そこで本論文で行った実験においてもカーネル関数を使わない場合(linear)と2~次，3~次，4~次の多項式型カーネル関数(poly2,poly3,poly4)を用いた場合の実験を行った．linearによる抽出精度は多項式型カーネル関数を使用した場合よりも低い．~節で述べた素性が，素性同士の依存関係がカーネル関数によって自動的に学習されることを期待しているためであると考えられる．多項式型カーネル関数を用いた場合には2~次(poly2)がもっとも良い抽出精度となった．本論文で行った実験における訓練事例の数や素性の構成では，2~次多項式型カーネル関数によって2~個の素性の依存関係を学習することが最適であることを示している．SVMは，より高次元の多項式型カーネル関数を用いることによってより多くの素性の依存関係を考慮した複雑なモデルを学習することが可能であるが，あまりに多くの素性の依存関係を学習してしまうと，その中には学習する必要のないものも含まれることになり，過学習によってモデルの性能を悪化させる結果になることが予想される．本論文における実験でも同様の現象が起こっていると考えられる．</subsection>
  <subsection title="訓練コーパスの大きさと抽出精度">訓練コーパスの文数が抽出精度に与える影響を調べるために，訓練コーパスの文数を200~文から4,000~文まで200~文ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図~(左)に示す．使用したカーネル関数は2~次多項式型カーネル関数であり，抽出時の閾値thは0.5とした．適合率，再現率ともに訓練コーパスの文数にほぼ比例して上昇しており，訓練コーパスの文数が精度に大きな影響を及ぼしていることがわかる．このため本手法は，対訳モデルの学習において比較的大規模なコーパスを用いる必要がある．しかし，抽出時には処理を1~文単位で行うので，一旦学習が完了してしまえば抽出対象となるコーパスは小規模なものでもよく，たとえ1~文からでもそこに含まれる対訳対を抽出することができる．</subsection>
  <subsection title="辞書の大きさと抽出精度">素性~(1a)(1b)で用いている既存の対訳辞書の大きさが抽出精度に与える影響を調べるために，使用する対訳単語対の数を0~個から2,800~個まで100~個ずつ増やしながら対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率を求める実験を行った結果を図~(右)に示す．使用したカーネル関数は2~次多項式型カーネル関数であり，抽出時の閾値thは0.5とした．適合率，再現率ともに使用する対訳単語対の数にほぼ比例して上昇しており，本手法において使用する対訳辞書は可能なかぎり多くの対訳単語対を含むものを用いた方が良いことがわかる．</subsection>
  <subsection title="素性と抽出精度">素性の重要度を調べるために，~節において述べた素性を1~種類ずつ削除して対訳モデルの学習を行い，テストコーパスからの抽出における適合率と再現率の増減を求める実験を行った結果を表~に示す．使用したカーネル関数は2~次多項式型カーネル関数であり，抽出時の閾値thは0.5とした．適合率と再現率における括弧内の値は素性1~個あたりの増減である．[tbp]table*素性1~個あたりの精度の増減では，語数による素性~(2a)(2b)と品詞による素性~(3a)(3b)を削除した時の下落が特に大きい．(2a)(2b)に属する素性は全ての事例に存在し，(3a)(3b)に属する素性も他の素性に比べるとはるかに多くの事例に存在する素性である．したがって，モデル構築におけるこれらの役割は大きく，ゆえに削除した時の精度の下落が大きくなると考えられる．その他では，対訳辞書による素性~(1a)(1b)を削除した時の下落が大きい．素性~(1a)は日英両言語の句の中で既存の対訳辞書によって辞書引きできるものがあるかどうかを表しており，この情報が句の対訳関係を推定する際には極めて重要であるという我々の直感と合致する．また素性~(1b)の仮定である「対訳関係にある表現は近傍に出現している語の出現文脈も(言語の違いこそあれ)似ている」という考えが対訳モデルの構築において効果が大きいことが示された．その他の素性を削除した時も抽出精度の下落を引き起こしており，対訳モデルの構成において有効であることが示された．</subsection>
  <subsection title="認識誤りと素性">認識誤りの原因を調べるために，テストコーパスにおいて正しく認識された事例と正しく認識されなかった事例における素性の出現個数(素性値が0以外となる要素の個数)の平均値を計算した(表~)．使用したカーネル関数は2~次多項式型カーネル関数であり，抽出時の閾値thは0.5とした．出力と記された行において+1と記されている列はシステムが対訳対であると認識した事例を表し，-1と記されている列は対訳対でないと認識した事例を表す．素性~(1b)の行に注目すると，対訳対でないと識別された負事例に対して，対訳対として識別されてしまった負事例における素性~(1b)の出現個数の平均値がかなり大きく，正事例の場合の値とあまり差のない値となっている．このことは，対訳対として識別されてしまった負事例の近傍に対訳単語対がよく現れていることを表している．本論文における実験では，同一文に現れる語を近傍とし，素性~(1b)は辞書中の対訳単語対が近傍に出現するか否かを表しているので，特に頻出する対訳単語対に関する素性~(1b)の出現個数は増えやすく，それが認識誤りを招いていると考えられる．したがって近傍の定義を「同一文内」ではなく，「日本語句・英語句からn~語以内」のように近傍の範囲を狭くしたり「日本語句・英語句と係り受け関係にある」のようにより関連性が強いものだけを素性にすることによってこのような誤りは減らすことができると思われる．しかし，表~からわかるように，近傍の範囲を狭くすることによって素性~(1b)が減りすぎると精度が下落するので，今回の実験では近傍を「同一文内」とした．</subsection>
  <section title="関連研究との比較">本手法と同様に対訳文の文対応が既に付いていることを前提にしている研究には文献~などがあげられる．はCompetitiveLinkingAlgorithmという単語対のリンク付け法と2つのパラメータに対する山登り法を組み合わせて単語対の対応度を求める手法を提案した．しかしMelamedの手法は1~単語対1~単語の対応を仮定しており，日本語と英語のように構造が大きく異なる言語に対して適用するのは困難である．はDice係数~を対訳対の出現頻度の対数によって重み付けする重み付きDice係数を提案し，これを対訳対の対応度として採用した．は北村らの手法を改良し，文節の依存関係が対訳表現の抽出において有効な手がかりであることを示した．北村らの手法と山本らの手法が対応度として採用している重み付きDice係数は対訳対の出現回数に依存しているので，出現回数が少ない対訳対に対する対応度はデータスパースネスのために信頼することができず，したがって小規模な対訳コーパスから対訳対を抽出することは難しい．それに対して本手法は対訳表現の抽出を統計的機械学習のアプローチで捉えており，対訳モデルの学習において対訳対の出現回数に依存しない素性を用いて対訳対を特徴づける．したがって，本手法は訓練コーパスによって対訳モデルをあらかじめ学習する必要がある反面，一旦モデルを学習してしまえば訓練コーパスにおいて出現回数が少ない対訳対あるいは出現しなかった対訳対でさえもデータスパースネスに陥ることなく抽出することができるという特徴がある．本手法と同様に対訳対の抽出を統計的機械学習の枠組みで捉えている研究として文献~があげられる．佐藤らは最大エントロピー法(MaximumEntropyMethod，以下ME~法)~を用いて文対応付き対訳コーパス上に対訳単語対の確率モデルを推定・抽出する手法を提案した．単語の共起情報と品詞情報を使用した素性約12,000~個を用い，推定確率0.1以上の単語対に対して行った抽出では適合率73.64,%，再現率21.79,%を実現した．この手法は，一旦モデルを学習してしまえば未知語を含むコーパスに対して学習し直す必要がないという点において本論文で提案した手法と共通点がある．における報告とは使用しているコーパス・素性や抽出対象が異なるので，本論文で行った実験において使用したコーパス・素性を用いてME~法によって抽出する実験を本手法との比較のために行った．対訳対候補(p_j,p_e)に対応する素性ベクトルx_p_jp_eが正事例である確率P(x_p_jp_eX_+1|x_p_jp_e)をME~法によって推定し，これを式~()の代わりに用いて対訳表現の抽出を行った．その結果，th=0.5において適合率69.2,%，再現率63.6,%となった．これはカーネル関数を用いない対訳モデル(linear)とほぼ同じ精度である．本論文で使用した素性は，素性同士の依存関係がカーネル関数によって自動的に学習されることを期待しているためであると考えられる．一般に素性同士には依存関係があるので，ME~法では素性同士の依存関係を表す素性を新たに作成する必要がある．その結果，素性の総数が非常に多くなってしまい，過学習を起こす危険があるため，ヒューリスティックによって有効な素性だけを選別したり，貪欲戦略に基づく素性選択アルゴリズム~を使用して素性の総数を減らす手法を用いることが多い．しかし，前者は選別の基準が難しく，後者は計算量が膨大になるという欠点がある．例えば本論文で用いた素性15,762~個を用いて2~つの素性の依存関係を表す素性を生成し，これらを用いてME~法によって確率モデルを推定しようとすると，素性の総数がおよそ250~万個となり，現実的な時間で計算することは困難である．一方，SVMでは多項式型カーネル関数を用いることによって計算量をほとんど増やすことなく素性同士の依存関係を自動的に学習することができる．一方，本手法と異なり，対訳文の文対応が付いていることを前提としない研究には文献~などがあげられる．これらの手法は「一方の言語で共起する単語の訳語は他方の言語でも共起する」ということを仮定している．は各言語に出現する語の共起確率行列の距離が小さくなるように確率翻訳行列を最適化することによって対訳関係を得る手法を提案した．は既存の辞書に含まれる単語との対訳対中に含まれる語の共起集合の共通部分の大きさによって対応度を計算している．本論文で提案した手法においても「一方の言語で共起する単語の訳語は他方の言語でも共起する」という仮定を素性~(1b)に用いている点においてこれらの手法と共通点がある．現状では文対応付き対訳コーパスはあまり多くないため，文対応を前提としないこれらの手法は適用できる範囲は広いが，文対応付き対訳コーパスを用いた手法よりも精度が劣る．一方，本手法の前提となっている文対応付き対訳コーパスは，原文に忠実に翻訳した対訳コーパスであれば，などで提案されている手法によって作成することができる．対応する文がなかったり，1つの文が複数の文に対応している場合には人手による後編集が必要になるが，その労力は全て人手による対応付けに比べて比較にならないほど少ないと考えられる．</section>
  <section title="おわりに">本論文では，SVMを用いて文対応付き対訳コーパスから対訳表現を抽出する手法を提案した．対訳モデルの素性として，対訳辞書による素性，語数による素性，品詞による素性，構成語による素性，近傍に出現する語による素性を使用し，SVMに基づく対訳表現の対応度を用いて対訳表現を抽出する．既存の手法は対訳表現の対応度の計算に単語の共起関係を利用しているためにデータスパースネスに陥りやすく，小規模なコーパスからの対訳表現の抽出は困難である．それに対して本手法は，訓練コーパスによって対訳モデルをあらかじめ学習する必要があるが，一旦モデルを学習してしまえば，訓練コーパスにおいて出現回数が少ない対訳表現あるいは訓練コーパスにおいて出現しなかった対訳表現でさえも抽出することができる．したがってある程度大規模な対訳コーパスから優れた対訳モデルを学習しておけば，サポートベクタマシンの高い汎化能力によって低頻度の対訳表現でも抽出が可能であるという特徴を持つ．本手法の有効性を示すために日英対訳コーパスを用いた対訳表現の抽出実験を行った．対訳モデルの学習に2~次多項式型カーネル関数を使用し，抽出時の閾値th=0.5とした時には，1,000文という比較的小規模なコーパスから適合率80.8,%，再現率77.6,%の精度で抽出できることを示した．また素性の重要度を調べる実験では，語数による素性，品詞による素性，対訳辞書による素性が精度向上に大きく貢献していることがわかった．しかし，対訳対候補の近傍に現れる語を対訳辞書によって辞書引きして得た素性において近傍の範囲を「同一文内」としていることが認識誤りを増やす原因となっている．近傍の範囲を「対訳対候補からn語以内」や「対訳対候補と係り受け関係にある」とすることで改善できると思われる．</section>
</root>
