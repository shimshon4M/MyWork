<?xml version="1.0" ?>
<root>
  <title>SENSEVAL2J辞書タスクでのCRLの取り組み---日本語単語の多義性解消における種々の機械学習手法と素性の比較---</title>
  <author>村田真樹内山将夫内元清貴馬青井佐原均</author>
  <jabstract>本稿では，2001年に行なわれたSENSEVAL2コンテストの日本語辞書タスクでのわれわれの取り組みについて述べる．われわれは機械学習手法を用いるアプローチを採用した．この研究では数多くの機械学習手法と素性を比較検討し用いている．コンテストには，我々は，サポートベクトルマシン法，シンプルベイズ法，またそれらの組み合わせのシステム二つの合計4システムを提出し，組合わせシステムが参加システム中もっとも高い精度(0.786)を得た．コンテストの後，シンプルベイズ法で用いていたパラメータを調節したところさらに高い精度を得た．現在もっとも性能の高いシステムは二つのシンプルベイズ法を組み合わせたシステムであり，その精度は0.793である．また，本稿では素性を変更した実験もいくつか追加で行ない，各素性の有効性，特徴を調査した．その調査結果では文字列素性のみを用いても比較的高い精度が得られるなどの興味深い知見が得られている．また，関連文献も紹介し，今後の多義解消の研究のための有益な情報を提供した．</jabstract>
  <jkeywords>多義解消，シンプルベイズ法，日本語</jkeywords>
  <section title="はじめに">われわれは2001年に行なわれたSENSEVAL2の日本語辞書タスクのコンテストに参加した．このコンテストでは，日本語多義性の解消の問題を扱っており，高い精度で日本語多義性の解消を実現するほどよいとされる．われわれは機械学習手法を用いるアプローチを採用した．機械学習手法としては多くのものを調査した方がよいと考え，予備調査として先行研究においてシンプルベイズ法，決定リスト法，サポートベクトルマシン法などの手法を比較検討した．その結果，シンプルベイズ法とサポートベクトルマシン法が比較的よい精度を出したのでその二つの機械学習手法を基本とすることにした．また，学習に用いる素性は，豊富なほどよいと考え，文字列素性，形態素素性，構文素性，共起素性，UDC素性(図書館などで用いられる国際十進分類を利用した素性)と，非常に多くの素性を利用した．コンテストには，シンプルベイズ法，サポートベクトルマシン法，またそれらの組み合わせのシステム二つの合計四つのシステムをコンテストに提出した．その結果，組合わせシステムが参加システム中もっとも高い精度(0.786)を得た．コンテストの後，シンプルベイズ法で用いていたパラメータを調節したところさらに高い精度を得た．また，解析に用いる情報(素性)を変更する追加実験も行ない，各素性の有効性，特徴を調査した．本稿では，これらのシステムの説明と結果を述べる．以降，節で多義解消の重要性を述べ，節で本コンテストの問題設定を述べる．節でわれわれが利用した機械学習手法について述べ，節でその機械学習手法で用いる素性について述べ，節でその機械学習手法と素性を用いた実験とその考察について述べる．節では関連文献について述べる．</section>
  <section title="多義性解消の重要性">本節では多義性解消の重要性を例を用いながら説明する．例えば，最近重要視されつつある質問応答の問題を考えてみる．ここで，質問応答の質問として以下のようなものがあったとしよう．ここで質問応答システムの知識源として，があったとする．この場合システムは「どのくらい」などの表現から数量表現が解とわかるのでこの知識源から「11頭」を解として正しく抽出することができる．しかし，質問が以下のようであったとしよう．この質問では先の質問の「トラ」が「虎」に変わっている．この場合，「トラ」と「虎」が同一であることを計算機に認識させなければならないが，これをするためには計算機に単語の意味に関する情報を与えておかなければならない．ここで例えばEDR辞書を利用すると，「虎」の同義語としては「トラ」「酒酔」「酒酔い」「酔客」「酔狂人」「酔人」が得られる．これは「虎」には「虎という動物」と「酒に酔った人」の二つの意味があり，この後ろの「酒に酔った人」の意味の場合の同義語が得られて「酒酔い」などの不要な同義語が得られるのである．この不要な同義語を使って解の抽出を試みる場合，例えばという文が知識中にある場合，誤って「５人」を解として取り出してしまう可能性がある．ここで多義性の解消をし，ここでの「虎」の意味は「虎という動物」と認識し同義語は「トラ」だけであるとしてから，解の抽出をした方が誤る可能性は減るのである．「虎」の場合はまだ意味が二つであったからよいが，高頻度に用いられる平易な語ほど語義の数が多く，この問題は深刻なものとなる．このことから，多義性の解消の重要性がわかる．ここでは質問応答の場合の例をあげたが各解析システムにおいて多義性の解消は同様に重要なものとなろう．例えば，照応解析においても，ある語Aが「人間」と「物」の二つの意味をもっていて，物しか指示しない「それ」という指示詞が出現した場合，語Ａの多義性を解消し，もし「人間」であるということがわかれば，この「それ」の指示先は語Aではありえないとわかり他の指示先の候補を探せばよいとわかる．また，機械翻訳でも訳し分けが必要な語は多義性を解消しなければ正しい翻訳をすることができない．このように多義性の解消は種々の場面で役に立つものである．</section>
  <section title="問題設定">本節ではSENSEVAL2の日本語辞書タスクの問題設定について説明する．SENSEVAL2の日本語辞書タスクでは，評価用のデータとしては100単語(このうち50単語が名詞で50単語が動詞)についてそれぞれ100事例が与えられ，合計10000事例が与えられた．学習用のデータとしては，RWCコーパスが与えられた．このコーパスは毎日新聞の1994年の3,000個の記事を用いたもので，コーパス中の主要な名詞，動詞，形容詞(総数：約15万個)に対して，岩波国語辞典に基づいて定義された語義がふられている．このタスクの目的は，この語義をその単語のまわりの情報などを用いて推定することである．また，精度の評価には，SENSEVAL2のホームページより取得できるscorer2という評価用プログラムによって算出される，mixed-grainedscoreという値が用いられた．</section>
  <section title="機械学習手法">一般に，単語多義性解消問題の場合，各単語にふられる語義は，単語ごとにかわるので，機械学習手法による実験は各単語ごとに逐次的に行なわれる．つまり，学習器は単語の異なり数の分だけ作成する．しかし本タスクでは，あらかじめ50個が名詞で，50個が動詞であるとわかっている．このため，システムは，単語ごとだけでなく，単語と品詞の組に対して個々に作成した．本コンテストの場合，50個の名詞と50個の動詞が対象であったので，合計100個の学習器を作ることになる．本稿では学習器のために用いる機械学習手法としては，以下の方法を利用した．シンプルベイズ法決定リスト法サポートベクトルマシン法本節ではこれらの個々の機械学習手法の説明と，これらの機械学習手法のいくつかを組み合わせる融合手法について説明する．</section>
  <subsection title="シンプルベイズ法">シンプルベイズ法は，ベイズの定理に基づいて各分類になる確率を推定し，その確率値が最も大きい分類を求める分類とする方法であり，多義性解消の研究における基本的な方法である．文脈bで分類aを出力する確率は以下の式で与えられる．p(a|b)&amp;=&amp;p(a)p(b)p(b|a)&amp;&amp;p(a)p(b)_ip(f_i|a)eqnarrayただし，ここで文脈bは，あらかじめ設定しておいた素性f_j(F,1jk)の集合である．p(b)は，文脈bの出現確率で，今回の場合分類aに非依存で定数のため，計算しない．p(a)とp(f_i|a)は，それぞれ学習データから推定された確率で，分類aの出現の確率，分類aのときに素性f_iを持つ確率を意味する．p(f_i|a)として最尤推定し求めた値を用いると，しばしば値がゼロになり，式()の値がゼロになり分類先を決めるのが難しい場合が多い．このため，スムージングがなされるが，本稿では以下のスムージングをしたものを用いる．p(f_i|a)=freq(f_i,a)+*freq(a)freq(a)+*freq(a)eqnarrayただし，freq(f_i,a)とfreq(a)は，それぞれ，素性f_iを持ちかつ分類がaである事例の個数，分類がaである事例の個数を意味する．は実験で定める定数である．本稿では，としては0.01と0.0001を用いた．</subsection>
  <subsection title="決定リスト法">これは，素性f_iと分類先aの組を規則とし，それらをあらかじめ定めた優先順序でリストに蓄えておき，リストで優先順位の高いところから，入力と素性が一致する規則を利用して分類先を求める方法である．本稿では優先順序としては以下のものを用いる(a|f_i)の値が等しい場合は，出現頻度の多い規則，すなわち，素性f_jで分類aである事例の多い規則を優先するようにしている．^,(a|f_i)の式の上でベイズ推定に基づくスムージングをした式を用いることで，従来の尤度比を用いる方法よりも高い精度を得たという報告がある．本稿ではこのあたりはそれほど注意深く検討していない．種々のスムージングをすることで今よりもよい精度を得る可能性はある．．p(a|f_i)eqnarrayこの方法は，以下の式で与えられる，ある文脈bでの分類aを出力する確率p(a|b)がもっとも高い分類aを解とする方法と等価であり，本稿では実際にはこの方法を用いて分類先を特定する．p(a|b)=p(a|f_max)eqnarrayただし，f_maxは以下の式によって与えられる．f_max=argmax_f_jFmax_a_iAp(a_i|f_j)eqnarrayまた，p(a_i|f_j)は学習データで素性f_jを文脈に持つ場合の分類a_iの出現の割合である．</subsection>
  <subsection title="サポートベクトルマシン法">サポートベクトルマシン法は，空間を超平面で分割することにより2つの分類からなるデータを分類する手法である．このとき，2つの分類が正例と負例からなるものとすると，学習データにおける正例と負例の間隔(マージン)が大きいもの(図参照)ほどオープンデータで誤った分類をする可能性が低いと考えられ，このマージンを最大にする超平面を求めそれを用いて分類を行なう．基本的には上記のとおりであるが，通常，学習データにおいてマージンの内部領域に少数の事例が含まれてもよいとする手法の拡張や，超平面の線形の部分を非線型にする拡張(カーネル関数の導入)がなされたものが用いられる．この拡張された方法は，以下の識別関数を用いて分類することと等価であり，その識別関数の出力値が正か負かによって二つの分類を判別することができる．f(x)&amp;=&amp;sgn(^l_i=1_iy_iK(x_i,x)+b)b&amp;=&amp;-max_i,y_i=-1b_i+min_i,y_i=1b_i2b_i&amp;=&amp;^l_j=1_jy_jK(x_j,x_i)eqnarrayただし，xは識別したい事例の文脈(素性の集合)を，x_iとy_i(i=1,...,l,y_i1,-1)は学習データの文脈と分類先を意味し，関数sgnは，sgn(x),=&amp;1&amp;(x0)&amp;-1&amp;(otherwise)eqnarrayであり，また，各_iは式()と式()の制約のもと式()のL()を最大にする場合のものである．L()&amp;=&amp;^l_i=1_i-12^l_i,j=1_i_jy_iy_jK(x_i,x_j)eqnarray0_iC,,(i=1,...,l)eqnarray^l_i=1_iy_i=0eqnarrayまた，関数Kはカーネル関数と呼ばれ，様々なものが用いられるが本稿では以下の多項式のものを用いる．K(x,y)&amp;=(xy+1)^deqnarrayC,dは実験的に設定される定数である．本稿ではすべての実験を通してC,dはそれぞれ1と2に固定した．ここで，_i&gt;0となるx_iは，サポートベクトルと呼ばれ，通常，式()の和をとっている部分はこの事例のみを用いて計算される．つまり，実際の解析には学習データのうちサポートベクトルと呼ばれる事例のみしか用いられない．サポートベクトルマシン法は分類の数が2個のデータを扱うもので，通常これにペアワイズ手法を組み合わせて用いることで，分類の数が3個以上のデータを扱うことになる．ペアワイズ手法とは，N個の分類を持つデータの場合，異なる二つの分類先のあらゆるペア(N(N-1)/2個)を作り，各ペアごとにどちらがよいかを2値分類器(ここではサポートベクトルマシン法)で求め，最終的にN(N-1)/2個の2値分類器の分類先の多数決により，分類先を求める方法である．本稿のサポートベクトルマシン法は，上記のようにサポートベクトルマシン法とペアワイズ手法を組み合わせることによって実現される．</subsection>
  <subsection title="融合手法">本節では，いくつかの機械学習を組み合わせて用いる融合手法について説明する．われわれの融合手法では，それぞれの単語ごとに用いる機械学習手法を変更する．(厳密には，本稿の場合は単語と名詞の組に対して学習器を作成しているので，この融合手法はそれぞれの単語と名詞の組ごとに機械学習手法を変更することになる．)各単語ごとに用いられる機械学習手法は，融合する機械学習手法のうち学習データでの10分割のクロスバリデーションの精度がもっともよかったものとする．われわれは融合手法としては以下の五つの手法を試した．融合手法1シンプルベイズ(=0.01)とサポートベクトルマシンの組み合わせ融合手法2二種類のシンプルベイズ(=0.01)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせただし，ここでいう二種類は節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．融合手法3シンプルベイズ(=0.0001)とサポートベクトルマシンの組み合わせ融合手法4二種類のシンプルベイズ(=0.0001)と二種類のサポートベクトルマシンの合計四種類のシステムの組み合わせただし，ここでいう二種類は節で後述する素性(解析に用いる情報)をすべて用いた場合と，KNP構文素性のみを削除した場合の二つの場合を意味する．融合手法5=0.01のシンプルベイズと=0.0001のシンプルベイズの組み合わせ</subsection>
  <section title="素性(解析に用いる情報)">前節で種々の機械学習の説明を述べたが，それぞれの手法ともに素性(解析に用いる情報)を定義しなければ，その手法を用いることができない．本節ではその素性の説明を行なう．節の問題設定で述べたように，本稿の問題設定では，日本語文の入力を与えられたときに，その入力中の語義タグがふられていた各形態素に対して，その語義の分類を推定して出力することになっている．このため，解析に用いる情報，すなわち，素性は入力される日本語文から取り出すことになる．本稿では素性としては以下のものを定義する．文字列素性解析する形態素自身の文字列解析する形態素の直前の1〜3gramの文字列解析する形態素の直後の1〜3gramの文字列RWC形態素素性解析する形態素自身のRWCコーパスの品詞情報，品詞細分類情報，品詞細細分類情報解析する形態素の直前の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞細細分類情報解析する形態素の直後の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞細細分類情報JUMAN形態素素性コーパスをJUMANで形態素解析し，その結果を素性として利用する．解析する形態素自身のJUMANの解析結果の品詞情報，品詞細分類情報，品詞活用形情報解析する形態素の直前の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報解析する形態素の直後の形態素の単語自身，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報構文素性コーパスをKNPで構文解析し，その結果を素性として利用する．解析する形態素を含む文節自身，また，その文節が体言かいなか，付属語の品詞，品詞細分類，活用情報解析する形態素を含む文節の係り先の文節の自立語，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報解析する形態素を含む文節の係り元の文節の自立語，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁，品詞情報，品詞細分類情報，品詞活用形情報．ただし，すべての場合において，付属語の情報を併用する．同一文内共起素性コーパスをJUMANで形態素解析し，その解析結果の形態素列を素性として利用する．同一文中の各形態素，また，その単語の分類語彙表の5桁，その単語の分類語彙表の3桁．UDC素性RWCコーパスには，各記事ごとに図書館などで書籍の分類に用いられる，国際十進分類(UDC)がふられている．この情報は各記事がどういう分野のものかを示している．解析対象とする形態素を含む記事のUDCコードの最初の1桁，2桁，3桁．</section>
  <section title="実験">本節ではまず節で，コンテストに提出したシステム，また，コンテストの後に改良したシステムについて記述し，その後節で，素性を変更した実験について記述する．</section>
  <subsection title="コンテストの実験結果(一部コンテスト後のシステムも含む)">われわれはSENEVAL2のコンテストに四つのシステム(CRL1からCRL4)，すなわち，サポートベクトルマシン，シンプルベイズ(=0.01)，融合手法1，融合手法2を提出した．また，コンテストの後，=0.0001を用いるシンプルベイズと決定リスト法，融合手法3,4,5を用いて実験を行なった．これらの結果を表に示す．「ベースライン」は学習データで最も頻度の大きかった分類を常に正解として選ぶ手法を意味する．「コンテストの最高システム」はコンテストに参加した団体によって提出されたすべてのシステムにおいてもっとも高いシステムを意味し，実際にはそれは融合手法2であった．表の値は，節でも述べたscorer2から算出されるmixed-grainedscoreの値である．値の分子が整数でないのは複数の語義が正解となる場合も考慮し部分点も与えるためである．また，scorer2のプログラムでは適合率(精度)と再現率を出力するが，われわれのシステムではすべての事例に対して解を出すため適合率(精度)と再現率の値は常に一致する．このため，表ではそれらを精度として統一して記述している．[t]table*表の結果より以下のことがわかる．すべてのシステムがベースラインよりも高い精度を出した．このことから，それぞれの手法ともにそれなりにまともな解析をしていることがわかる．提出した4システム(CRL1からCRL4)の中では，CRL4の融合手法2が最も高い精度(0.786)をえた．また，コンテストの後，=0.0001を用いるシンプルベイズを用いたところ，さらに高い精度(0.790)をえた．(この=0.0001の設定は脚注でのべたように学習データのみを用いて定めた値なので恣意的ではない．)この結果から，この問題ではシンプルベイズ法が有効であることがわかる．最近の機械学習手法を用いた種々の研究ではたいていの場合サポートベクトルマシン法がよいようだが，日本語多義解消ではそうではないことがあることがわかる．しかし，シンプルベイズとサポートベクトルマシンの精度差はそれほど大きいものではない．融合手法としてはシンプルベイズ法でのパラメータ調整が適切でない場合つまり，=0.01のとき，サポートベクトルマシンが0.783でシンプルベイズが0.778でそれらの融合が0.786であったので，精度向上を実現できる場合があることがわかる．しかし，シンプルベイズ法でのパラメータ調整を適切にした場合つまり，=0.0001のとき，サポートベクトルマシンが0.783でシンプルベイズが0.790でそれらの融合が0.787であったので，精度向上を実現できていない．このことから，システムの融合がいつでも効果があるわけではなく効果がないことがあることもわかる．融合手法としては，=0.01のシンプルベイズと=0.0001のシンプルベイズを融合する手法も用いたが，この精度は0.793となり精度向上を実現した．これは単語ごとに最適なが異なることを示唆する．本稿のシンプルベイズ法では単純なスムージング法を採用しているが，本稿のスムージング法があまりよくないために単語ごとに最適なパラメータがかわっている可能性もある．今後は他のもう少し高度なスムージング法も試してみる必要があると思われる．ところで，融合手法としては同じシンプルベイズでもパラメータをかえたものを組み合わせることで精度向上ができる場合があることがわかった．本研究では，融合手法としては節で述べたように5つのものを用いている．ここで，実際に実験対象である100単語のうち，どのくらいの割合で融合される個々の機械学習手法が用いられていたかを示しておきたい．この用いられた機械学習手法の内訳を表に示す．ただし，融合手法において用いる学習手法は，学習データでの10分割のクロスバリデーションの精度がもっともよかったものとしているが，この精度が同点であった場合は，その同点であった学習手法のうち表に示した順序で最初に出現した手法を用いている．表からわかるように精度の高い手法ほど，融合手法において多く利用されていることがわかる．例えば，「サポートベクトルマシン」の精度は0.783で，「シンプルベイズ(=0.01)」の精度は0.778で，「サポートベクトルマシン」の方が精度が高いが，実際に表(a)では，「サポートベクトルマシン」の方が多く用いられている．[t]table*[t]table*[t]table*</subsection>
  <subsection title="素性を変更した実験">次に解析に用いる情報，すなわち，素性を変更した場合の実験を行なった．この実験では融合手法は用いず，シンプルベイズ(=0.0001)，サポートベクトルマシン，決定リストで行なった．この結果を表から表までに示す．表は課題の100単語すべてでの結果であり，表と表は名詞50単語，動詞50単語に対する結果である．各表とも，まず全素性を用いる方法の精度を示し，次に各素性を省いた場合のもの，最後に各素性のみを用いた場合のものを示している．各手法で最も大きいときの精度を太字にしている．また，表で``------''としている部分については，システムおよび素性の設定の都合でシステムが問題を解けなかった単語が一部あったため精度が算出できなかったものを示す．全課題での実験において精度がもっとも高かったのは，全素性を用いるシンプルベイズ法であった．シンプルベイズ法では，名詞50単語，動詞50単語でも，全素性を用いる方法が安定して最も高い精度を獲得した．サポートベクトルマシン法では，名詞ではUDC素性を用いない方法が最もよく，動詞では文字列素性のみを用いる方法がもっともよかった．決定リスト法では名詞ではRWC形態素素性のみを用いる方法がもっともよく，動詞では文字列素性のみを用いる方法がもっともよかった．名詞50単語の精度では，UDC素性を用いないサポートベクトルマシンがもっとも精度がよい．このことから，常にシンプルベイズ法がよいわけではなく，他の方法の方がよい場合があることがわかる．表の文字列素性のみを用いる場合の各手法の精度を見て欲しい．このときは，サポートベクトルマシン法がもっとも精度がよく0.777であった．また，決定リスト法では0.773であった．これらの数字は最高精度に比較してもそれほど悪くなく，単なる文字列の素性だけでも高い精度を獲得できることを示している．また，特に動詞の場合は，サポートベクトルマシン，決定リスト法ともに文字列素性のみを用いた場合がもっとも精度が高い．これらの結果から現状で日本語多義解消を行なう場合，簡便性を考えると以下の二通りのアプローチがあると思われる．手法としては簡便なシンプルベイズを用いるが，素性としてはさまざまなものを用意して高い精度を目指す．手法としては，サポートベクトルマシンや決定リストなどの強力な機械学習手法を用いるが，文字列素性などの少数の有用な素性のみを用いるもの．このアプローチでは前者に比べて素性が簡便であってもよい．</subsection>
  <section title="関連文献">本節では関連文献について説明する．英語単語の多義語の曖昧性解消に機械学習手法を用いた研究は極めて多数存在するが，日本語単語の多義語の曖昧性解消に機械学習手法を用いた研究は，SENSEVAL2以前はほとんどなかった．例えば，新納の研究では語の多義の解消ではなく，同音異義語の判別を扱っていた．その意味で，日本語多義解消の問題で「シンプルベイズ法」「決定リスト法」「サポートベクトルマシン法」の三つの機械学習手法，さらには，素性を変化させた場合の実験結果を示している本稿は，今後の日本語単語の多義語の曖昧性解消の問題を考えるための資料として非常に役に立つものと思われる．次にいくつかの関連研究を紹介したい．まず，SENSEVAL2で英語を含む数多くの言語で優秀な成績をとっていたYarowskyらのシステムについて説明する．Yarowskyらのシステムは，シンプルベイス法と決定リストの組み合わせであり，決定リストで求まる確信度が高いところでは決定リストの手法の解を用い，それ以外の場合は種々の手法の多数決の結果を解とする手法である．確信度を用い決定リストで確実に求まるところだけを別個に扱っているところが興味深い．次に，SENSEVAL2の日本語辞書タスクに参加していた八木らのシステムについて説明する．八木らのシステムは決定リスト法を機械学習手法として用いており，学習用のデータとして，RWCコーパス以外に岩波国語辞典の例文のデータを用いていることを特徴としている．RWCコーパスでの語義の定義は岩波国語辞典を用いているため，岩波国語辞典の例文のデータも語義解析のための学習データとして利用できるのである．八木らの研究ではこの例文データも利用した場合の方が利用しない場合よりも精度が高かったとしている．この結果は，われわれの研究でもこのデータを追加で用いることで精度を向上できる可能性を示唆するものであり，興味深い．次に，高村らの素性空間を再構成する手法について説明する．この研究は英語を対象に行なわれており，機械学習手法としてはサポートベクトルマシン法を利用している．この手法は学習に用いる素性を構成し直すところに特徴がある．普通に抽出した素性だけでなく，その素性の分布に対して独立成分分析や主成分分析を行ない，元々の素性よりも一段抽象化したような素性を新たに作り出し，これも素性として追加で用いる方法である．この素性を再構成する方法を含めた複数のシステムの多数決を用いる方法で，単純なサポートベクトルマシン法の性能を上回ったとしている．独立成分分析などにより素性の情報を抽象化することでデータスパースネス対策などに役立っていると思われ，興味深い．最後に，中野らのAdaBoostを用いた手法を説明する．この研究ではSENSEVAL2日本語タスクのデータを対象としており，AdaBoostを機械学習手法として利用している．AdaBoostは正しく分類された事例の重みを下げ，誤って分類された事例の重みを上げて，再学習をする手法である．中野らの報告では，AdaBoostを利用することで決定リスト法，シンプルベイズ法よりも高い精度を得たと報告している．ただし，その最高精度は79.1,%であり，われわれの最高精度の79.3,%より若干低い．しかし，この結果はわれわれのシステムの素性の情報が豊かであるためである可能性があり，われわれのシステムの素性の情報でAdaBoostを利用するとさらによい精度を得ることができる可能性がある．しかし，中野らはわれわれのシステムでは用いていない日本語語彙体系の辞書の情報を用いており，中野らの方が素性の情報が少ないとは言い切れないので，われわれのシステムの素性の情報でAdaBoostを利用するとさらによい精度を得ることができるかどうかはわからない．また，われわれのシステムの素性の情報の方が豊富であっても，われわれのシステムの素性でAdaBoostが本当によい精度を出せるかどうかはわからない．次に，多義性の研究に直接は関係はないが，複数の機械学習の方法を組み合わせるのに，スタッキングを用いる手法について説明したい．スタッキングを用いる手法とは，もともとの素性の他に，複数の機械学習の結果を素性として追加し，その追加された素性を用いて機械学習を行なう方法である．従来は複数の機械学習の方法の融合には多数決が多く用いられていたが，スタッキングの方法ではどの機械学習の方法がよいかを学習することになっておりたいていの場合で多数決の方法よりも精度が高くなると思われる．このスタッキングを利用する研究としては，形態素解析のものや固有名詞表現抽出のものなどがある．本稿でのシステムの融合では，各単語でもっとも精度の高い手法を利用していた．このわれわれの融合手法は各単語ごとに用いる手法を最尤推定で求めるものになっていて少々は融合に学習を用いていることにはなっている．しかし，手法の組み合わせにおいても強力な学習手法を用いた方が精度はよいと思われるので，われわれの手法でもスタッキングを利用することを考えた方がよい．以上，種々の有力な関連研究を紹介した．それぞれの手法ともに特徴的な要素を持っており，節の最後に述べた考察と含めてそれらを総合的に考察し，それぞれの手法の良い面を組み合わせることで，さらによりよい多義解消を行なえると思われる．</section>
  <section title="おわりに">本稿では，2001年に行なわれたSENSEVAL2コンテストの日本語辞書タスクでのわれわれの取り組みについて述べた．我々は，サポートベクトルマシン法，シンプルベイズ法，またそれらの組み合わせのシステム二つの合計4システムを提出し，組合わせシステムが参加システム中もっとも高い精度(0.786)を得た．コンテストの後，シンプルベイズ法で用いていたパラメータを調節したところさらに高い精度を得た．現在もっとも性能の高いシステムは二つのシンプルベイズ法を組み合わせたシステムであり，その精度は0.793である．また，本稿では素性を変更した実験もいくつか追加で行ない，各素性の有効性，特徴を調査した．その調査結果では文字列素性のみを用いても比較的高い精度が得られるなどの興味深い知見が得られている．また，関連文献も紹介し，今後の多義解消の研究のための有益な情報を提供した．2の運営，および，本特集号に尽力してくださいました，東大黒橋助教授と北陸先端大白井助教授をはじめとする方々に感謝いたします．document</section>
</root>
