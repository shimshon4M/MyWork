<?xml version="1.0" ?>
<root>
  <title>サポートベクトルマシンを用いた中国語解析実験</title>
  <author>吉田辰巳大竹清敬山本和英</author>
  <jabstract>現在入手可能な解析器と言語資源を用いて中国語解析を行った場合にどの程度の精度が得られるかを報告する．解析器としては，サポートベクトルマシン(SupportVectorMachine)を用いたYamChaを使用し，中国語構文木コーパスとしては，最も一般的なPennChineseTreebankを使用した．この両者を組み合わせて，形態素解析と基本句同定解析(basephrasechunking)の2種類の解析実験を行った．形態素解析実験の際には，一般公開されている統計的モデルに基づく形態素解析器MOZとの比較実験も行った．この結果，YamChaによる形態素解析精度は約88%でMOZよりも4%以上高いが，実用的には計算時間に問題があることが分かった．また基本句同定解析精度は約93%であった．</jabstract>
  <jkeywords>中国語解析，サポートベクトルマシン，同定解析，YamCha，MOZ</jkeywords>
  <subsubsection title="">*入手方法LinguisticDataConsortium(LDC)より出版されている．そのため，入手方法は通常のLDCのコーパスを入手する方法と同じである．本報告で使用したLDC2000T48は2000年のメンバーに配布可能である．メンバー以外であっても，US100にて入手することができる．関連URIを以下に示す．</subsubsection>
  <section title="はじめに">自然言語処理を進める上で，形態素解析器をはじめとする言語解析器は，コーパスなどの言語資源と同様に最も重要な道具である．近年では，この重要性は研究者間でほぼ認識されており，英語や日本語に対する形態素解析器と構文解析器はいずれも複数のものが作成，そして公開または市販され，我々研究者はその恩恵に預かっている．ところが，中国語に関しては以上の状況は同じではない．我々の知る限り，日本国内はもちろん，中国においても誰もが手軽に使える中国語解析器が研究者の間で広範に知られている，という状況にはなく，まだ十分に解析器が整備されているとは言えない．この背景の一つは，中国語解析の困難性であると考える．中国語は英語のように概ね単語ごとに分かち書きされてはおらず，単語分割が必要である．また，文字種が単語分割のための大きな情報を持つ日本語とは異なり，ほぼ単一文字種(漢字)である．さらに，複数品詞を持つ語が多いため品詞付与も容易ではない．たとえば，中国語の介詞(前置詞)のほとんどは動詞からの転成であるため日本語や英語にはほとんど存在しない内容語と機能語との間で品詞付与の曖昧性が生じる．たとえば``.25ex=1.1zw[0109990]Chinese_Chars/dao.eps=1.1zw[0109990]Chinese_Chars/bei.eps=1.1zw[0109990]Chinese_Chars/jing.eps=1.1zw[0109990]Chinese_Chars/le.eps''（北京に着いた）の``.25ex=1.1zw[0109990]Chinese_Chars/dao.eps''は動詞（到着する）であるが``.25ex=1.1zw[0109990]Chinese_Chars/dao.eps.25ex=1.1zw[0109990]Chinese_Chars/bei.eps=1.1zw[0109990]Chinese_Chars/jing.eps=1.1zw[0109990]Chinese_Chars/qu.eps''（北京に行く）の``.25ex=1.1zw[0109990]Chinese_Chars/dao.eps''は介詞（に）であり，すなわち``.25ex=1.1zw[0109990]Chinese_Chars/dao.eps=1.1zw[0109990]Chinese_Chars/bei.eps=1.1zw[0109990]Chinese_Chars/jing.eps''だけでは``.25ex=1.1zw[0109990]Chinese_Chars/dao.eps''の品詞は決定できない．また日本語における「−する」(動詞)「−い」(形容詞)などの明確な文法標識を持たないため，内容語間の曖昧性も比較的多い．たとえば中国語の``.25ex=1.1zw[0109990]Chinese_Chars/dan.eps=1.1zw[0109990]Chinese_Chars/xin.eps''は日本語の「心配(名詞)/心配する(動詞)/心配だ(形容詞)」のすべてに相当する．我々は現在，中日翻訳，並びに中国語換言処理の研究を行っている．これらの処理は中国語が入力であるため，表層処理を行わない限り中国語解析器が必要である．このため我々は，現在入手可能な解析器や言語資源を組み合わせて中国語解析を行うことを試みた．ここで，中国語構文木コーパスとしては，現在一般的なPennChineseTreebank(以下，CTBとする)を使用した．一方，解析器としてはサポートベクトルマシン(SupportVectorMachine，以下，SVM)に基づくYamChaを使用した．SVMならびにYamChaについては節でその概要を述べる．本報告では，形態素解析と基本句同定解析(basephrasechunking)の2種類を行った．節で形態素解析について，節で基本句同定解析について述べる．それぞれの解析で，学習文テストと未知文テストの2種類の解析精度を測定し，考察を行った．形態素解析実験では，連接コスト最小法に基づく形態素解析器MOZを使用して，解析精度の比較を行った．さらに，日本語と比較してどの程度中国語の形態素解析が難しいのかを調べるために京都大学テキストコーパスを用いて実験した．また，品詞タグ付けに限定すれば，CTBよりも大きなコーパスが入手可能であることから，CTBの約11倍の大きさを持つ人民日報タグ付きコーパスを用いての形態素解析実験も行った．本報告の主な目的は，上記の解析器と言語資源を用いて中国語解析器を構築した場合，どの程度の解析精度が得られるのかを報告することにある．すなわち，この解析器にどのような問題がありどのような改善が可能かを提案するという提供者の視点ではなく，使用者の視点，すなわち中国語処理に携わる研究者にとってこの解析器がどの程度有用であり，使用の際にはどのような点に注意が必要か，などを報告することに主眼がある．いずれも容易に得られるツールと言語資源を組み合わせた場合にどのような精度が得られるかを測定，報告することは誰にでもできる作業である．しかし，研究者が研究の必要性のためできるだけ高精度の解析器を求める状況にある場合，本報告のような報告によって解析の期待精度を予め知った上で同一の解析器を構築できる．あるいは，研究上より高精度の解析器が必要な場合は最初から別の選択肢を考えることもできる．このように，我々は中国語処理を行う研究者への有益性を考え，我々で測定した解析精度を技術資料として報告することにした．</section>
  <section title="中国語解析のための言語資源と解析環境">本節では，我々の実験で使用した言語資源と解析環境の概略を述べる．</section>
  <subsection title="中国語構文木コーパス">我々は，入手可能な中国語言語資源として，現在最も一般に知られていると考えられるPennChineseTreebank(CTB)を使用した．CTBは，米国ペンシルバニア大学(UniversityofPennsylvania)のChineseTreebankProjectにより作成された構文木コーパスである．このコーパスの概要ならびに入手方法を付録に示す．以下に述べる実験では，このプロジェクトの最終版であるLDC2000T48を用いた．また，CTBで定義されている中国語品詞数は33，句情報の数は17である．この一覧を巻末の付録に示す．</subsection>
  <subsection title="SVMによる同定解析">SVMは，d次元の特徴ベクトル(パターン)xを定められた二つのクラス(A,B)のいずれかに識別する2値クラスの線形識別器である．また，SVMでは，カーネルトリックと呼ばれる計算技術によって非線形識別器を実現できる．従来の手法と比べて多くの面で優位性を示し，文字認識や画像認識など，様々な分野で応用されている．識別器は，識別関数fx)の形によって与えられ，fが正ならクラスA,fが負ならクラスBに識別される．fx)=0を満たxの集合を識別面と呼ぶ．SVMの大きな特徴の一つは，マージン最大化である．マージンとは，識別面と特徴ベクトル間の最小距離であり，マージンが大きいほうが，汎化能力が高く，テストパターンを精度良く識別できる．一般に，学習パターンを識別する超平面は複数存在する．SVMでは，上に述べた理由から超平面と学習パターンとの最小距離を最大にする超平面を求め，これを識別面とする．決定した超平面からの最小距離に対応する特徴ベクトルをサポートベクトルと呼ぶ．またサポートベクトル以外の特徴ベクトルは最終的に得られる識別関数に一切影響を及ぼさない．したがって，出現頻度などの統計量を用いる識別器(たとえば決定木など)とは性質が異なる．SVMを用いることの短所は，(1)2値クラス識別器であるため多クラスを考慮に入れた識別関数の最適化ができない(2)計算量が大きい(3)問題に適したカーネルトリック(カーネル関数)の明確な選択方法は知られていない，などである．自然言語処理における同定解析(chunking)とは，与えられた言語的な要素列(文字列，単語列など)をより上位概念の言語的要素(単語，句，文など)にまとめあげるために，各要素に情報を付与する一連の処理を指す．たとえば，単語の分かち書きや形態素解析，文節まとめあげ，テキストセグメンテーション，文書分類などはすべて同定解析とみなすことができる．工藤は，SVMに基づく汎用的な同定解析器としてYamCha(YetAnotherMultipurposeCHunkAnnotator)taku-ku/software/yamcha/を公開している．YamChaは同定解析を各要素に対する情報付与と見なすため，一般的な解析器として用いることが可能である．SVMは2値識別器であるため，情報付与(tagging)のような多値クラスの識別問題を扱うためには，何らかの拡張を行う必要がある．これに対してYamChaでは，pairwiseclassification（一対比較分類）と呼ばれる手法を採用している．これは，Kクラスの識別問題を解くために，各クラス2つの組み合わせを識別するK(K-1)/2種類の識別器を作成し，最終的にそれらの多数決でクラスを決定する手法である．SVMを用いた自然言語解析の例として英文の基本句同定実験や，日本語の係り受け解析実験があり，従来手法と比較して高い解析結果を示している．また，平と春野は，SVMを用いた文書分類について，高い分類精度を得るためには品詞によるフィルタリングをした後，全単語を入力として用いればよいことを示している．</subsection>
  <section title="YamCha による形態素解析">SVMを用いた中国語の解析器として，我々はYamChaを用いた．この節ではYamChaによる中国語の形態素解析について述べる．形態素解析を文字のならびを形態素へまとめあげる同定解析と見なす．したがって，各文字がチャンク(chunk)を構成する1要素に相当する．チャンクとは，同定解析における同定単位を指し，ここでは形態素に相当する．SVMの学習のためにCTBを正解データとして用いる．</section>
  <subsection title="YamChaの準備">YamChaで扱うデータ形式は，複数のトークンと複数のカラムから構成される．各行は入力のトークンに対応する．形態素解析を行う場合は，1トークンが1文字に対応する．各カラムにはトークンに付与された属性が記述される．また，各カラムはタブまたはスペースによって区切られている必要がある．YamChaによって推定(学習)すべき属性は最後のカラムに与える．ここでは，形態素解析を行うので，第1カラムには，形態素の要素である1文字を記述し，第2カラムには，YamChaで推定する情報を記述する．この情報には，形態素の区切り位置を示す情報と，形態素に付与する品詞情報の両方が含まれる．また，文と文の境界は，EOSと記述した行，もしくは空行を付与することで同定する．トークンがチャンクに含まれるか否かの状態を示すためにIOB2モデルを用いた．これは，あるトークンがチャンクの先頭ならばBタグを付与し，チャンクに含まれる先頭以外のトークンならばIタグを付与し，チャンクに含まれない場合にはOタグを付与するモデルである．一方，本実験ではすべてのトークンが何らかのチャンクに含まれるためOタグは用いられない．付与する品詞タグセットはCTBのタグセットと同一である．また，CTBにおいて品詞が``-NONE-''の形態素は構文構造上形式的に配置され，実体を持たないため対象外とする．最終的にトークンに付与されるタグはB/Iタグと品詞タグを``--''で結んだものとなる．CTBからYamChaで中国語形態素解析を行うための書式へ変換する概要を図に示す．以上の処理で得られた学習データをYamChaに与え，SVMのモデルを作成する．その際に，素性として使用したデータはYamChaの標準設定に従った．すなわち，推定するトークンと，その前方，および後方2トークンの計5トークンにおける文字データと前方2トークンの推定タグを素性として学習した．解析方向は前方からである．これは，使用する素性を変化させた場合の精度を検討した予備実験の結果において，YamChaの標準設定が最も高い精度であったためである．これらの関係を図に示す．また，YamChaで学習を行うために用いたSVMの実装は同じく工藤が公開しているTinySVM0.08taku-ku/software/TinySVM/である．</subsection>
  <subsection title="形態素解析器 MOZ">本報告では，YamChaと同程度の時間的コストで実現できる中国語形態素解析器としてMOZをとりあげ，両者の比較を行う．本節では，MOZに関する概略を述べる．MOZで形態素解析を行うためには，形態素辞書と接続表が必要となる．MOZはコスト最小法に基づく解析器であるので，形態素辞書と接続表にはそれぞれコストを与えなければならない．ここでは，CTBから得られる情報(品詞2つ組の頻度や形態素の頻度など)から形態素辞書と接続表，ならびにそれらのコストを求める．すなわち，形態素辞書は形態素とその出現確率から，品詞接続表は品詞bi-gramによって与える．MOZでは，品詞接続表にtri-gram以上のデータを用いることができるが，データ過疎性(datasparseness)による精度低下を避けるために本実験では品詞bi-gramのみを用いた．形態素をw_i，品詞をPOS_i，xの頻度をC(x)と表記すると品詞がPOS_iである形態素w_iの出現確率を式()で与える．ここで，C(w_i,POS_i)は形態素w_i，かつその品詞がPOS_iである頻度を示している．また，品詞接続表の確率は式()で与える．ここでC(POS_i,POS_j)は品詞POS_iのあとに品詞POS_jが出現した頻度である．システムで扱う最高コストを128として，コスト化係数を求める．コスト化係数は式()により与えられる．ここで最小確率は，すべてのp(w_i|POS_i)およびp(POS_j|POS_i)における最小値である．形態素辞書ならびに接続表のコストはそれぞれの確率から式()により与えられる．以上述べた方法により形態素辞書ならびに接続表のコストを計算する．</subsection>
  <subsection title="学習文テスト">まず，CTB全体を学習データ(4181文)とし，この中から無作為に抽出した1割の文（418文）を解析する学習文テスト(closedtest)を行った．具体的には，YamChaとMOZをそれぞれ用いて，418文からなるテストデータを解析し，その結果をCTBの正解と比較し，評価した．その結果から，再現率(recall)と適合率(precision)を算出した．再現率と適合率はそれぞれ式()および式()とした．再現率と適合率からF値(F-measure)も求めた．F値は再現率Rと適合率Pの調和平均であり，式()によって与えられる．ただし，本実験では正解形態素数を求める場合に形態素分割のみ正解の場合と，分割ならびに品詞の両方の2段階の条件を設けて評価した．この結果を表に示す．また，品詞誤りの上位10件を表に示す．ここで，出現率とは誤りの総数に対する各誤りの割合を示す．</subsection>
  <subsection title="未知文テスト">次に，CTB全体を母集団とする10分割交差検定(crossvalidation)による未知文テスト(opentest)を行った．まず，CTB全体(4181文)を無作為に10等分し，1割をテストデータ，残りの9割を学習データとする．この方法で10組の学習データとテストデータを作成した．YamChaとMOZそれぞれに対して，10組の学習データとテストデータを用いて学習ならびにテストを行い，平均値を求めた．実験結果を表に示す．また，品詞誤りの上位10件の内訳を表に示す．表中のnullは未知語のために付与されたタグを示している．未知文テストにおいてYamChaが1学習データを学習するために要した処理時間と1テストデータを解析するために要した処理時間などを表に示す．測定時は，CPU:PentiumIII600MHz，メモリ:256MB，OS:Linuxの計算機を用いた．ただし，YamChaで解析を行うためには，アーキテクチャ非依存のテキスト形式のモデルファイル(学習結果を格納するファイル)をアーキテクチャ依存のバイナリ形式にコンパイルする必要がある．その際にテキスト形式のモデルをメモリ上に展開するため大量のメモリを必要とする．この実験では，約650MBのメモリを必要としたため，コンパイル作業だけは，CPU:PentiumIII733MHz，メモリ:960MBの計算機を使用した．このコンパイルに要した時間は約5分であった．本実験のあと，コンパイルに必要なメモリ量を抑える目的からプログラムを修正した．その結果，速度を少々犠牲にするが，80MB程度のメモリで，上記のモデルファイルをコンパイル可能となった．処理時間は，CPU:PentiumIII600MHz，メモリ:256MBの計算機で約7分であった．このYamCha0.1に対するプログラムの差分はWWWページkohtake/にて公開している．一方，MOZが学習データ(約3700文)から形態素辞書と接続表のコストを求めるために必要とした時間は約3秒であり，1テストデータ(約400文)を解析するために必要とした時間は約1秒であった．</subsection>
  <subsection title="未知語の性質">次に，テストデータに含まれる形態素のうち，学習データに含まれていないものを未知語と定義し，その性質を調べた．未知文テストにおける平均未知語率などを求めた．結果を表に示す.未知語率とはテストデータの単語数に占める未知語数の割合を指し，平均未知語率とはテストセット全体での未知語率の平均を示している．未知語に対する解析器の性質をより詳しく調べるため，以下の実験を行った．まず，CTBから40記事を無作為に選択する．そのうち30記事を学習データ，残り10記事をテストデータとする．次にテストデータから順に1記事ずつ学習データに加えていき，計11個の学習データを作成する．それぞれの学習データに基づく解析器で同一のテストデータ10記事を解析した．以上の実験概要を図に示す．テストデータに含まれる単語数は1111，のべ語数は2954である．11のテストセットにおける学習データの単語，未知語数ならびに未知語率を表に示す．各テストセットにおける未知語率(異なり)と解析精度の関係を図に示す．図では，解析精度をF値で示す．なお，未知語率(のべ)と精度の関係を図示していないが，図とほぼ同一の図となるため省略する．次に，未知語がある場合の解析結果を調査した．テストセットt_iにおける未知語の集合をUK(t_i)，wUK(t_i)のうち形態素分割に成功した形態素の集合をUSeg(t_i)とする．さらに，wUSeg(t_i)のうち品詞も正しく解析された形態素の集合をUSP(t_i)とする．これらの集計結果を表に示す．また，MOZでは入力に未知語が含まれる場合，解析不能で停止することはないが，最終的に未知語と判断された文字列を1文字ずつ，nullという品詞を与えて出力する．したがって，MOZでの解析で|USP(t_i)|を示していないのは，MOZでは未知語がnullと解析されるため，USP(t_i)は空集合となるためである．一方，MOZでの解析においてUSeg(t_i)が得られるのは，正解が1文字の形態素である場合に形態素分割が成功したと見なすからである．</subsection>
  <subsection title="言語依存性とコーパスの大きさ">これまで，CTBをコーパスとして，中国語の形態素解析について2つの解析器，YamChaとMOZを比較してきた．しかしその未知文テストの結果は，表に示す通り，これまでに報告されている日本語の形態素解析器の精度より低い．ここでは，その原因が，中国語の言語としての解析の難しさにあるのか，コーパスの量にあるのかを検討する．</subsection>
  <subsubsection title="日本語形態素解析におけるYamCha">CTBで用いられているのは，新華社通信の新聞記事である．そこで，SVMに基づく形態素解析器の日本語に対する精度を検証するために我々は，京都大学テキストコーパス第3.0版（以下，京大コーパスと呼ぶ）を用いて実験を行った．このコーパスの詳細については付録を参照されたい．CTBの大きさが約10万語であるところから，我々は，京大コーパスのうち1月1,3,4,5日の記事，4117文，102310単語を用いることにした．CTB全体では，4181文，99720単語である．我々が選択した京大コーパスの一部についてCTBに対する実験と同様に，10分割交差検定を実施した．この検定における平均未知語率などを表に示す．京大コーパスを用いた実験における品詞は，JUMANが定義する品詞のうち品詞細分類までを含めたものとした．この結果，タグセットの大きさは，41となり，CTBの33より大きい．YamChaの学習に用いたデータの例を以下に示す．*5mm*5mm実験結果を表に示す．参考までに我々が選択した京大コーパスの一部をJUMANで形態素解析した結果もあわせて示す．日本語を対象とした実験でも，同程度の大きさのコーパスでは，同程度の精度となった．</subsubsection>
  <subsubsection title="コーパスの大きさと解析精度">CTBは既に述べた通り4181文，99720単語からなるコーパスだが，大きいとは言えない．そのため，10分割交差検定を行っても，テストセットにおける未知語率が非常に大きくなり，精度が低くなる．品詞タグ付けされたコーパスがあれば，それを形態素解析器のために利用することが可能である．CTBのように構文木を備えている必要はない．品詞タグ付けされた中国語のコーパスはいくつかあるが，我々は，CTBよりも大きく，そして同じ新聞記事という点から人民日報タグ付きコーパスを使用した．人民日報タグ付きコーパスに関しては，付録にその概要等を示す．ただし，我々は人民日報半年分であるコーパス全てではなく，無償公開している1ヶ月分のデータを用いた．人民日報タグ付きコーパス1ヶ月分(以下，PKUと呼ぶ)は，44011文，1121447単語からなるコーパスである．定義されているタグセットの大きさは39である．しかしながら，実際のPKUにはここに定義されていないタグが7種類(Bg:8,Mg:7,Rg:10,Yg:1,na:1,nx:459,vvn:1，コロンの後の数値は頻度を示す)出現する．ここで，nxは，定義されているタグxに該当することがわかったので，nx以外の6種類のタグを含む文を除いた．その結果，PKUは，43913文，1118794単語からなるコーパスとなった．PKUはCTBの約11倍の大きさを持つ．まず，同程度のコーパスの大きさでの精度を検証した．PKUをランダムに文単位で11等分し，そのうちの1つ(約10万語)を用いて10分割交差検定を行った．結果を表に示す．以下，このPKUの10万語のコーパスをPKU10万語と表記する．PKU10万語を用いての未知文テストとCTBでの未知文テストでの精度の違いは，両者のコーパスの違いに起因する．両者はともに約10万語のコーパスであるが，表から，PKUの方が未知語が多く，なおかつ1文あたりの平均形態素数がCTBより約1単語多いことがわかる（CTBでの1文平均形態素数=41.10/1.72=23.90，PKU10万語での1文平均形態素数=40.71/1.64=24.82）．さらに，PKUは，CTBと比較してタグセットが大きく，タグ一種類あたりの学習データが少なくなることからタグの推定がより難しくなっている．したがって，PKU10万語での結果は，同じ10万語のCTBと比較して精度が大きく低下したと考える．MOZが再現率の面でYamChaを上回るのは，辞書を用いる利点が活かされていると考える．YamChaは1文字単位でタグの推定を行う．タグの推定に用いるのは推定対象文字とその前後2文字，さらに直前に推定した2つのタグの計7つの素性である．したがって，学習量が不十分な状態では，ある形態素が学習，テストコーパスの両方に含まれている場合でも，テストデータにおける当該形態素とその周辺文字列の組合せを素性として学習している可能性は低いためSVMが誤る可能性が大きくなる．一方，MOZでは，一度辞書に登録された形態素は，形態素分割および品詞の曖昧性が生じない限り正しく再現される．さらに学習コーパスが大きくない場合では，これらの曖昧性が発生する頻度は低いと予想する．したがってMOZが再現率の面で，YamChaを上回ったと考える．次に，PKU全てを学習コーパスとし，学習文テストを行った．テストデータとしてPKUから無作為に抽出した3993文，101218単語を解析した．なお，学習に用いるコーパスが大きくなることから，より大きな分解能が必要になると考え，MOZのコスト化係数を128から1024へと変更した．実験結果を表に示す．この結果から，学習コーパスが100万語を越えても，YamChaは変わらず高い性能を示していることがわかる．学習に用いるコーパスの大きさが非常に大きくなった場合の2つの解析器のふるまいを検討するために，11等分したデータを用いて11分割交差検定を行った．結果を表に示す．</subsubsection>
  <subsection title="形態素解析結果に関する考察">以上得られた形態素解析に関する実験結果について考察する．まず，YamChaとCTBを使用した場合の未知文に対する形態素解析(分割と品詞付与)精度(F値)は87.9%であった．同条件でMOZが83.3%であることを考えると，言語資源としてCTBしか得られない条件下ではYamChaを使用したほうが高精度な解析器を実現できる．次に，解析時間についてはYamChaが極端に遅い．学習時間も同様である．よって解析時に実時間性を問われる状況においてはMOZを使用すべきである．YamChaでは，既に述べたように，一対比較分類に基づき品詞付与を行うため，品詞数が大きくなると，その2乗に比例するSVMが必要となる．そのため，品詞数の増加とともに，学習，解析時間が増大する．品詞付与誤りの傾向では，1節で述べたように中国語において本質的に解析の難しいと予想される箇所で両解析器共に誤っており，解析器としての誤りのくせはあまり見受けられない．未知語に対する頑健性については，YamChaのほうが優れる．実験では，YamChaは未知語の約4割を正しく解析しており，頑健性を確かめられた．この割合は，未知語率が変化しても，大きく変化することはなく，実験した範囲の未知語率(51.5%から6.4%)で，40%から45%程度であった．このことから，未知語率が大きくなったからといってそれに影響されて極端に精度が低下することはないと予想する．一方，MOZは，未知語に対して1文字ずつにnullという品詞を付与して出力するのみであるため，何らかの拡張を行わない限り品詞の推定を行えない．したがって，再現率に対して適合率が低くなる傾向がある．また，YamChaにはこのような傾向はなく，適合率が再現率を若干上回る傾向を示す．これらのことから，入力文中に多くの未知語の存在が予想される場合，あるいは学習データの語彙傾向と異なる入力文を解析する場合はYamChaを用いたほうがよい．ただし，一般的な状況としてコーパスとは別個に単語集合を入手できる場合がある．この場合にはMOZを使うべきだろう．YamChaでは単語集合があってもこの情報を学習に反映させることができず，コーパス中の出現単語のみが学習対象であるためである．言語資源をより活用しているのはYamChaであるが，辞書を用いないことから語彙的整備ができない．また人間の内省による知見を反映させにくい．したがって，既に大量のタグ付きコーパスが存在する状況では，MOZのような，接続コストを統計的言語モデルに基づいて推定する手法が頑健で，整備しやすい解析器となる．逆に，タグ付きコーパスが充分に整備されていない言語の解析器を必要とする場合，あるいは，新たに定義した品詞に対する解析器が，その品詞で解析されたコーパスが充分に存在しない状況で必要となる場合にはYamChaが有効である．また，中国語に固有の解析の難しさが考えられるが，日本語を対象とした実験の結果から，同程度のコーパスならびにそのタグセットの大きさの場合では顕著な違いは見られなかった（表）．しかしながら，京大コーパスの平均未知語率が，CTBのそれと比較して大きく（表），さらに，京大コーパスのタグセット(41)がCTBのそれ(33)より大きい．これは，日本語解析の実験条件が中国語解析の条件に比べ，厳しいことを示す．それにもかかわらず，実験結果は同程度の精度を示した．これらのことから中国語解析が，日本語解析に比べて難しいと判断する．さらに，表は，京大コーパスの解析結果とCTBの解析結果において単語分割のみと分割と品詞付与との間の逆転現象があることを示している．これは，中国語解析の困難な点は，品詞付与にあるという我々の予見を裏付ける結果と考える．一方で，より大きなコーパスを用いることにより，高精度な解析器が実現可能であることが，表からわかる．また，表に示した学習文テストの結果から，学習コーパスをさらに大きくするとYamChaはさらに精度を向上させる可能性がある．それに対し，MOZは，PKU（100万語以上の大きさを持つコーパス）を用いての学習文テスト結果において分割と品詞付与のF値が約95%（表）だったことから，現状の枠組のままでは，F値で95%程度がその性能の限界だと考える．これをさらに向上させるためには，接続表へのtri-gram規則の適用ならびにその補完などが可能である．しかし，浅原らは，中国語の場合には，tri-gramの規則自体があまり有効ではなく，品詞体系の詳細化が精度の向上に寄与することを実験結果から予測している．</subsection>
  <section title="YamChaによる基本句同定解析">本節では，YamChaを用いた基本句同定解析(basephrasechunking)実験について述べる．基本句同定解析とは，形態素解析結果すなわち品詞付与された単語列を入力として，最も下位の構造を同定し，その構造に対して構文的情報を付与する処理である．ここで，最も下位の構造を基本句，基本句に対する構文的情報を句情報と本報告では呼ぶことにする．このように，基本句同定解析は一段階の構文解析と考えることができる．したがって，構文解析は同定解析を繰り返すことで実現できる．工藤らは，SVMに基づく同定解析の段階適用が，日本語の係り受け解析に有効であることを示している．</section>
  <subsection title="学習データ">同定解析の学習データは，形態素解析と同様にCTBを用いた．CTBが表現する構文木では，葉が形態素に相当する．基本句同定解析では，葉に最も近い位置に付与されている構造が基本句であり，形態素が基本句を構成する要素に該当する．すなわち，形態素情報を入力として基本句の区切り位置と句情報を推定する．</subsection>
  <section title="まとめ">本報告では，SVMに基づく言語解析器を用いて，PennChineseTreebankを言語資源とした時にどの程度の中国語解析精度が得られるかを報告した．以下にその結果をまとめる．SVMに基づく解析器（YamCha）による形態素解析精度は単語単位で約88%であり，コスト最小法に基づく解析器（MOZ）よりも4%以上高い．未知語の約4割を正しく解析でき，未知語に対する頑健性は高い．ただし計算量に問題があり，解析時間，学習時間共に非常に長い．大量のタグ付きコーパスが入手できる場合は，YamCha，MOZのいずれを用いても，さらに高精度の解析器（110万語のコーパスの場合，F値でそれぞれ約92%，89%）を実現できる．そのような場合には，解析，学習にかかる時間を考慮すると，MOZを用いるべきである．なお，中国語形態素解析は日本語のそれと比較して顕著な困難さは見られなかった．基本句同定解析(basephrasechunking)の精度は約93%．約3200文の学習に約2時間，357文の解析に約3分を要する．*8mm</section>
  <section title="CTB のタグセット">*-1emCTBにおける全品詞の説明と，全ての句情報の説明をCTBのタグ付与指針から転記する．*-1em</section>
  <section title="本報告で用いた言語情報資源">以下に，本報告で用いた言語情報資源についてまとめる．</section>
  <subsection title="Penn Chinese Treebank">米国ペンシルバニア大学(UniversityofPennsylvania)のChineseTreebankProjectにより作成された構文木コーパスである．このプロジェクトは1998年夏に始まり，最終版(LDC2000T48)を2000年12月に，また同一内容で誤りを修正したPennChineseTreebankVersion2.0(LDC2001T11)を2001年に公開した．新華社通信(.25ex=5.5zw[01048290]Chinese_Chars/xinhua_news.eps,XinhuaNewsAgency)の1994年から1998年の325記事から構成される，約10万語の大きさのコーパスである．CTBは.25ex=5.5zw[01048290]Chinese_Chars/xinhua_news.epsの325記事に対して，単語分割，品詞付与，構文情報付与されたコーパスである．コーパス作成作業は，(1)作業者1名が全情報を付与する(2)別の作業者1名が点検する，という方法で行った．文字コードにはGBコードを使用し，データの書式はEnglishPennTreebankとほぼ同一である．</subsection>
  <subsection title="人民日報タグ付きコーパス">富士通研究開発中心有限公司(.25ex=14.3zw[010124790]Chinese_Chars/fujitu.eps)と，北京大学(.25ex=4.4zw[01038690]Chinese_Chars/beijingdaxue.eps)および人民日報社(.25ex=5.5zw[01048290]Chinese_Chars/renminribao.eps)が協力し作成した，中国で最も権威を持ち影響力のある中国全国紙のタグ付きコーパスである．.25ex=4.4zw[01038390]Chinese_Chars/renminribao_4char.epsの1998年の新聞記事半年分，約1,300万文字＝約730万単語からなる．.25ex=5.5zw[01048290]Chinese_Chars/renminribao.eps=6.6zw[01058190]Chinese_Chars/xinwenxinxi_center.epsから，大学や研究所などでの研究利用に限定して，人民元2,000元（約3万円，実費）にて有償公開している．また，この内1ヶ月分を無償公開している．</subsection>
  <subsection title="京都大学テキストコーパス">京都大学テキストコーパスは，毎日新聞1995年1月1日から17日までの全記事，約2万文，1月から12月までの社説記事，約2万文，計約4万文に対して，京都大学の形態素解析システム(JUMAN)，構文解析システム(KNP)で自動解析を行い，その結果を人手で修正したコーパスである．ただし，コーパスとして含んでいるのは形態素・構文の付加情報のみであり，毎日新聞の記事そのものは含まれていない．そのためコーパス本来の形式とするためには別途毎日新聞CD-ROMが必要である．毎日新聞CD-ROMを用意し，京都大学テキストコーパスの配布パッケージに含まれるプログラムを使用して完全なコーパスの形式へ変換する．</subsection>
</root>
