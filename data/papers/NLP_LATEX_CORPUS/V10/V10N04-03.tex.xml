<?xml version="1.0" ?>
<root>
  <title/>
  <author/>
  <jkeywords/>
  <section title="Introduction">Mostcontinuousspeechrecognitionsystemsrequirephonetictranscriptionsofwordsintheirrecognitionlexica.Forcommercialspeechrecognitionproducts,whoseusersmayneedtocreatenewrecognitionlexicafornewapplicationsorpurposes,itwouldbedesirableifphoneticsymbolsareautomaticallyprovidedwheneveranewlexiconiscreatedsincenoteveryuserisgoodatworkingwiththesesymbols.Acommonpracticeistoshipwiththeproductsanextensivebackgroundlexiconandphoneticsymbolsfortherecognitionlexiconarelookedupfromthebackgroundlexicon.Suchlook-upschemesalmostalwayssufferfromcoverageproblemswhendealingwithsuchproductiveandinflectionallanguagesasJapanese.Moreover,sincetheusermayhaveadifferentideaaboutwhatconstitutesanorthographicwordinJapanesethanthemaker(s)ofthebackgroundlexicon,look-upproceduresmayfailtoyieldanyresult.Finally,sinceitiswellknownthateachkanjicharacterusuallyhasmorethanonecommonpronunciationandthecorrectpronunciationcanonlybedeterminedbyexaminingtheexpressioninwhichthecharacterisused,look-upschemesaretoosimpletodisambiguate.Normallyamorphologicalanalyzerisemployedinconjunctionwithalook-upproceduretoovercometheseshortcomings.Despiteitseffectiveness,itrequiresdeeperlinguisticknowledgeaboutthelanguage.Inthispaper,weproposeastatisticalapproachtoautomaticallyconvertingJapaneseorthographicwordsintophoneticsymbolsrepresentingtheirpronunciations,whichwerefertoastheSAMPA-J.Thisapproachdoesnotrelyonanymorphologicalanalysisbutisbasedonalanguagemodel.Itismodifiedfromthetwo-stepapproachwedescribedin,wheretheorthographicwordwasfirstconvertedintoitskanareadingandthenthekanareadingwasmappedtothephoneticsymbols.Wealsopresentinthispaperresultsfromourextensiveevaluationstoshowefficacyofourapproach.IntheEnglish-writtenliterature,istheonlypaperwehaveseensofarthataddressesasimilarproblem.Itishopedthat,bypublishingthispaperinaJapan-basedjournal,wecandrawmorefeedbackfromtheJapaneseresearchcommunity,makingusbetterawareofwhathasbeenachievedinthistopicbyJapaneseresearchers.Weorganizethispaperasfollows.Inthenextsection,weformulatethephonetictranscriptionprobleminmathematicaltermstoderiveourapproachanddescribehowtotrainthelanguagemodelthatisrequiredbyourmethod.Wereportresultsfromourevaluationsandcompareperformancetothepublic-domaintoolKAKASIinSection~.Finally,weconcludewithSection~.</section>
  <section title="Mathematical Formulation"/>
  <subsection title="A Maximum a Posteriori Setup">Phonetictranscriptionoforthographicwordscanbeposedasamaximumaposterioriproblemasfollows.Givenanorthographicwordconsistingofncharactersk_1,,k_n,thetranscriptionsystemoutputstheSAMPA-Jsequences_1^,,s_n^whichisthesolutiontothefollowingequations_1^,,s_n^=_s_1,,s_nPr(S_1=s_1,,S_n=s_n|K_1=k_1,,K_n=k_n),displaymathwheres_iisastringofSAMPA-Jsymbolsrepresentingthepronunciationoftheithcharacterk_i.UsingBayesruleanddroppingthetermindependentofs_1,,s_n,wecanrewritetheaboveequationass_1^,,s_n^&amp;=&amp;_s_1,,s_nPr(K_1=k_1,,K_n=k_n,S_1=s_1,,S_n=s_n)Pr(K_1=k_1,,K_n=k_n)&amp;=&amp;_s_1,,s_nPr(K_1=k_1,,K_n=k_n,S_1=s_1,,S_n=s_n).eqnarray*Withsomeabuseofnotation,wewritePr(K_1=k_1,,K_n=k_n,S_1=s_1,,S_n=s_n)&amp;=&amp;Pr((K_1,S_1)=(k_1,s_1),,(K_n,S_n)=(k_n,s_n))&amp;=:&amp;p((k_1,s_1),,(k_n,s_n)).eqnarrayThus,thetranscriptionsystemshoulddecideinfavoroftheSAMPA-Jsequences_1^,,s_n^satisfyingWeshallcallthepair(k_i,s_i)analignment/inthefollowing,sincethecharacterk_iisalignedwithitspronunciations_i.Notethatthetermp((k_1,s_1),,(k_n,s_n))asdefinedinlm_definitioncanbethoughtofasalanguagemodelfora``language''whosealphabetconsistsofthealignments(k_i,s_i).Inthispaper,weconsiderN-grammodels,N=2,3,toestimatethisprobability:p((k_1,s_1),,(k_n,s_n))&amp;&amp;.eqnarray*Thatis,weassumethatthepronunciationofacharacteronlydependsonthepreviousonetotwocharactersandtheirpronunciations.Webelievethatthisassumptionisquiteclosetothereality.Now,supposethatthelanguagemodelisavailable.Wecansolvemax_problemasfollows:Startingwiththefirstcharacterintheinputword,allhypothesizedpronunciations_ifortheithcharacterk_iarelookedupinadictionaryandthenlabeledtogetherwithk_ionthearcsleadingfromnodeitonodei+1.Thisprocedureisrepeatedforthe(i+1)thcharacteruntiltheendoftheinputwordisreached.Next,allhypothesesonthearcsareevaluatedwiththelanguagemodel.Then,adynamicprogrammingalgorithmselectstheoptimalSAMPA-Jsequenceinsenseofmax_problemastheoutput.Inthenextsub-section,wedescribehowwetrainthislanguagemodel.</subsection>
  <subsection title="Training the Language Model">Thelanguagemodelp((k_1,r_1),,(k_n,r_n))canbetrainedwithstandardN-grammodelingtechniquesonthetrainingdataderivedfromJapanesedictionariesbyaligningeachkanjicharacterinadictionarywordwithitscorrespondingpronunciationinSAMPA-J.Sincedictionariesnormallyonlyprovidekanareading(s)ofaword,wepreparethetrainingdatainthefollowingthreesteps.Supposethedictionarywordtobealignedconsistsofnorthographiccharactersk_1,,k_nandthekanareadinggivenbythedictionaryhasmkanacharactersh_1,,h_m.Firstweapplyacomputertoolwedevelopedtoconsistentlyassociateeachk_iwiththereadingr_i=(h_i_1,,h_i_l)suchthat(r_1,,r_n)=(h_1,,h_m).Ifthetoolfailstoproperlyaligntheorthographiccharacterswiththekanareadings,weresorttomanualwork.Finally,thereadingr_iismappedintothecorrespondingSAMPA-Jstrings_iwithakana-to-SAMPAconversiontoolthatwealsodeveloped.Onoccasionweencounteredwordswhosereadingswereonlylegalwhenkeptasawholeandcouldnotbefurtherdivided.SomeexamplesofsuchwordsareshowninFigure~.Therefore,werelaxedthedefinitionoflanguagemodelinlm_definitionandallowedthealphabetofthelanguagetoalsocontainclusteredalignments(_i^i+j,_i^i+j)=(k_ik_i+j,s_is_i+j).Thatis,p((k_1,s_1),,(_i^i+j,_i^i+j),,(k_n,s_n))&amp;=&amp;Pr((K_1,S_1)=(k_1,s_1),,(_i^i+j,_i^i+j)=(_i^i+j,_i^i+j),,&amp;&amp;(K_n,S_n)=(k_n,s_n)).eqnarray*Consequently,intheoptimizationprocesstosolvemax_problem,therearepossiblyalsoarcsleadingfromnodeitonodei+j.</subsection>
  <section title="Evaluations"/>
  <subsection title="Set-up">Inourevaluations,weused288,197wordsplustheirkanareadingsthatwehadcollectedfromvarioussourcesasourtrainingdata.TheywerefirstprocessedasdescribedinSection~andthenusedtotrainbothbigramandtrigrambacking-offlanguagemodels.WedevelopedthetestsetsfromtheIPAdictionariesprovidedintheChaSenmorphologicalanalysispackagesincetheyweredividedaccordingtolexicalcategoriesandsowecouldevaluatecategory-specificperformance.Topreparethetestsets,weexcludedallwordsthathadbeenobservedinourtrainingdata,thatconsistofonlyasinglecharacter,andthatcontainRomanletters,Arabicdigits,orsymbols.Onlythosedictionarieswithmorethan100wordsleftafterexclusionwereusedasthetestsets.TheirkanareadingswerethenmappedtoSAMPA-Jwithourkana-to-SAMPAconversiontoolandusedasthereference.Table~presentssomeinformationontheresultingtwelvetestsets,whosenamesarekeptconsistentwiththoseintheChaSenpackage.Notethatnounsarefurtherdividedintoseveralsub-categories.Thepublic-domaintoolKAKASIwaschosentocompareperformance.SincethemainfunctionofKAKASIiskanji-to-kanaconversion,itsoutputwasconvertedintoSAMPA-Jbythesamekana-to-SAMPAconversiontoolweappliedtotheIPAdictionaries.Inveryfewcases,thekanaoutputbyKAKASIerroneouslycontainedkanjicharacters.Thesekanjicharactersweresimplydeletedbeforeweappliedthekana-to-SAMPAtool.</subsection>
  <subsection title="Results and Discussion">Foreachtestset,wemeasuredtheworderrorrate(WER),whichistheratioofthenumberofincorrectlytranscribedwordstothetotalnumberofwordsinthetestset,andtheSAMPA-Jphonemeerrorrate(PER),whichistheratioofthesumofdeleted,inserted,andsubstitutedphonemestothetotalnumberofphonemes.Theworderrorrateisanindicationhowofteninputwordsareincorrectlytranscribedwhilethephonemeerrorrateisameasureoftheeffortthattheuserwouldhavetospendoncorrecting.Table~summarizestheerrorratesyieldedbyourstatisticalmethodincorporatingthebigrammodelandthetrigrammodel,respectively,andtheerrorratesbyKAKASI.TheresultsinTable~showthatthetrigramlanguagemodelresultedinlowererrorratesthanthebigramlanguagemodelinallbutonetestset(Noun.verbal).However,theperformancegapbetweenthetwomodelsisquitesmall,whichmaybebecausetrigramsobservedintrainingaresparse,thusforcingmanybacking-offstooccur.Wealsoseethatourmethod(usingeithermodels)yieldedsuperiorperformancetoKAKASIonallbuttwosets(AdverbandVerb).Sincetheevaluationswereconductedinanopen-settestingscenario,theresultsimplythatthemethodweproposedhasbettercapabilityofgeneralization.Overall,errorratesontestsetscorrespondingtonouns(Noun)arehigherthanthoseonothertestsets.Thisisnotentirelyunexpectedsincenon-nounwordsusuallycontainfewerkanjicharacters,whicharedirectlyrelatedtopronunciationvariability,thandonouns.Inaddition,pronunciationsofkanjicharactersinadjectives,adverbs,andverbsaredominatedbytheirkunyomiandthusaremoreorlessfixed.Ontheotherhand,pronunciationsofnounscanvaryamongthemultiplicityofonyomiorbemixturesofkunandonyomiandconsequentlyaremuchlesspredictable.Amongthetestsetsinvariousnouncategories,errorratesarehigheronpropernames,withtheexceptionoforganizationnames(Noun.org).Thisisbecauseorganizationnamesarenormallyformedfromgenericnounsbycompoundingwhilemanyotherpropernameshaveuniquepronunciations.Inouropinion,thereisprobablynogoodsolutionforthisproblem.Duetothesheernumberofwordsinvolvedandlimitedresourcesavailable,wewereunabletoperformathorougherroranalysis.Nonetheless,wefoundthatmanyincorrecttranscriptionscontainingonlyasinglephonemeerrorwerecausedbythephenomenonofsequentialvoicing,orrendaku.Ifthebigraminvolvingrendakuisnotobservedintraining,then,forthesecondcharacter,thelanguagemodelwillfavorthemostfrequentpronunciation,usuallywithoutvoicing.Thisisalimitationofourapproach.Itisprobablyeasiertohandlerendakuwithrules.</subsection>
  <section title="Conclusions">WehavepresentedastatisticalapproachtoautomaticallytranscribingJapaneseorthographicwordsintophoneticsymbols.ItincorporatesanN-gramlanguagemodel,whichcanbetrainedonprocessedJapanesedictionaries.Wehaveshownthattheperformancegapbetweenabigrammodelandatrigrammodelwasrathersmallandthatourapproachhadsuperiorperformancethanthepublic-domainKAKASIonallbuttwotestsets.Itisworthnotingthattoprocessdictionariesintotrainingdatadoesnotrequirespecializedskillsorknowledge.Therefore,ourmethodcanbeeasilyextended.Anotheradvantageisthatlanguagemodelingandhypothesissearchingcanre-usethecorrespondingroutinesfromtheintendedspeechrecognitionsystem,thussavingconsiderabledevelopmenteffort.document</section>
</root>
