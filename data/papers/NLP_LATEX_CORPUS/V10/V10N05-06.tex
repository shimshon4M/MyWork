\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}


\makeatletter
\def\slashbr{}
{\catcode '57=\active
 \gdef\@slashbr#1{}}
\makeatother



\setcounter{page}{93}
\setcounter{巻数}{10}
\setcounter{号数}{5}
\setcounter{年}{2003}
\setcounter{月}{10}
\受付{2003}{2}{1}
\再受付{2003}{5}{2}
\採録{2003}{5}{7}



\title{異なるコーパスにおける重要文抽出の結果と素性の分析}

\author{野畑 周\affiref{CRL} \and 関根 聡\affiref{NYU} \and 井佐原 均\affiref{CRL}}

\headtitle{異なるコーパスにおける重要文抽出の結果と素性の分析}

\headauthor{野畑，関根，井佐原}

\affilabel{CRL}{独立行政法人通信総合研究所けいはんな情報通信融合研究センター自然言語グループ}
{Computational Linguistic Group, Keihanna Human Info-Communication Research Center, Communications Research Laboratory}

\affilabel{NYU}{ニューヨーク大学コンピュータサイエンス学科}{Computer Science Department, New York University}

\jabstract{
本論文では，三種類の異なるコーパスに対する我々の自動要約システムの評価と，
その要約データの分析結果について述べる．我々は重要文抽出に基いた要約シス
テムを作成し，そのシステムを用いて日本語・英語双方の新聞記事を対象にした
要約評価ワークショップに参加し，良好な評価結果を得た．また日本語の講演録
を対象として重要文抽出データを人手によって作成し，そのデータに対して要約
システムの実験・評価を行った．さらにシステムの評価結果に加えて，重要文抽
出に用いられる主な素性の振舞い・素性の組合せによる重要文の分布の違いなど
を各々の要約データにおいて分析した結果を示した．
}

\jkeywords{自動要約，重要文抽出，固有表現}

\etitle{Analysis of Evaluation Results and Features of \\ Sentence Extraction on Different Corpora}

\eauthor{Chikashi Nobata\affiref{CRL} \and Satoshi Sekine\affiref{NYU} \and
Hitoshi Isahara\affiref{CRL}}

\eabstract{
In this paper, we report evaluation results of our summarization system
and analysis of summarization data in three different types of corpora.
We have created our summarization system based on sentence extraction,
and applied the system to summarization for Japanese and English
newspaper articles and made excellent results.  We have also created
sentence extraction data from Japanese lecture speeches and evaluated
our system to them.  Besides evaluation results of our system, we showed
analysis of relationships between key sentences and features used in
sentence extraction, and distributions of key sentences with a
combination of features among these three different types of corpora.
}

\ekeywords{Automatic summarization, Sentence extraction, Named entity}


\begin{document}
\maketitle
\thispagestyle{empty}
\section{はじめに}

我々はこれまで，多様なテキストを要約することのできる頑健な自動要約システムの開発をめざして，重要文抽出を基にした要約システムを作成・拡張してきた．
その過程で，作成したシステムを用いて日本語・英語双方において新聞記事などの書き言葉を対象にした要約評価ワークショップに参加し，良好な評価結果を得た\cite{nobata:tsc2001,sekine:duc2001}．
また，日本語の講演録を対象として重要文抽出データを人手によって作成し，そのデータに対して要約システムの実験・評価を行った\cite{nobata:orc2002}．

日本語と英語など異なる言語や，書き言葉と話し言葉など異なる性質をもつテキストを要約するためには，どのような点が共通化できてどのような点を個別に対応する必要があるのかを，実際に要約データにあたって要約手法を適用し，その結果を検討する必要がある．
本論文の目的は，これまで行ってきた日本語と英語，また書き言葉と話し言葉のデータそれぞれについて，共通の素性を用いた重要文抽出の結果について示すことと，それらのデータ間での各素性の分布がどのように共通しているか，異なるかを示すことである．

我々のシステムは，重要文抽出をベースにして自動要約を行っている．
これは，文章全体を1〜2割程度縮める要約ではなく文章を大きく縮めて要約するためには，重要文抽出もしくはそれに類する手法を用いることが必要であると考えたためである．
重要文抽出は自動要約に用いられる主要な手法の一つである\cite{mani:aats,okumura:nlp1999-07}．
文章から重要文を抽出するためには，各文がどの程度重要であるかを示す素性を用意する必要がある．
文の位置情報，たとえば文章の先頭にあるものほど重要だとみなす手法は，単純ではあるが現在でも自動要約の主要な手法である．
他にも記事中の単語の頻度などの統計的な情報や，文書構造を示す表現などの手がかりなどが用いられている．
これらの素性を統合的に用いる手法も研究されており，例えば
\cite{edmundson:acm1969}は人手で重み付けの値を与えることによって，\cite{watanabe:coling1996}は回帰分析，\cite{kupiec:sigir1995-s}や\cite{aone:colingacl1998}はベイズの規則，また\cite{nomoto:ipsj1997}，\cite{lin:cikm1999}らは決定木学習を用いて複数の情報を統合している．
本論文では，これらの論文で示されているように素性を統合的に用いた要約システムの評価結果を示すだけでなく，
自動要約に用いられる主な素性の振舞い・素性の組合せによる重要文の分布の違いなどを，性質の異なる3種類の要約データにおいて
比較・分析した点に特徴がある．

以下では，\ref{section:data}章において各要約データについて説明し，
\ref{section:system}章において重要文抽出システムの概要を述べ，
\ref{section:evaluation}章において各要約データにシステムを適用した結果の評価を示す．
さらに，\ref{section:analysis}章においてシステムが用いた素性の各データにおける分布について考察する．

\section{要約データ}
\label{section:data}

本研究で用いた要約データは，日本語新聞記事・英語新聞記事・日本語講演録の3種類のテキストデータを対象として作成されたものである．
日本語新聞記事の要約データ，英語新聞記事の要約データは，ともに評価コンテストのために作成された公式のデータである．
この2種類のデータを対象とすることで，異なる言語に対して用いることのできる要約システムを構築することを意図している．
日本語講演録の要約データは，講演音声についての大規模なコーパスを構築するプロジェクトの中で作成された，
学会講演の書き起しデータに対して作成されたものである．
このようなデータを対象とすることによって，書き言葉と話し言葉それぞれに対応できる要約システムを構築することを意図している．
以下，本研究で用いた3種類の要約データそれぞれについて説明する．

\subsection{日本語新聞記事の要約データ}
\label{section:data_tsc}

TSC (Text Summarization Challenge)は，自動要約の研究の発展を目的として2001年に開始された自動要約の評価プロジェクトであり，国立情報学研究所によって主催されている評価ワークショップNTCIRのタスクの一つである\cite{TSC1}．
TSCは，複数の要約課題を提示して参加者を募り，参加者が作成した個々の自動要約システムを同一のデータに基づいて評価を行い，また自動要約の評価基準自体についての議論，さらに研究者間で共有できる要約データの作成・公開を行ってきている．
第1回にあたるTSC2001では，日本語の新聞記事を対象として，A1: 重要文抽出型要約，A2: 人間の自由作成要約と比較可能な要約，B: IRタスク用要約の3種類の課題が提示された．
本論文ではこのうち課題A1で用いられた重要文データを実験に用いた．
予備試験，本試験データはそれぞれ30記事あり，ともに社説15記事と報道記事15記事で構成されている．
この課題では，予備試験，本試験ともに3種類の要約率(10\,\%, 30\,\%, 50\,\%)に応じて重要文抽出を行うことが課された．

本論文では，TSCで用いられた要約データを「TSCデータ」と呼ぶ．
TSCデータは課題で用いられた新聞記事と，要約率ごとに作成されたそれらの記事の要約とから成る．
TSCデータは日本語書き言葉要約データの例として\ref{section:evaluation}章に示す評価結果，\ref{section:analysis}章に示す分析で用いられる．

\subsection{英語新聞記事の要約データ}
\label{section:data_duc}

Document Understanding Conference(DUC)は，米国DARPAの支援の下にNational Institute of Standards and Technology(NIST)によって実施されている，自動要約の評価プロジェクトである\cite{DUC:2001}．
DUCは日本におけるTSCと同様に，同一のデータに基づく複数の要約システムの評価，要約データの作成・公開を行うことで自動要約の研究の発展を図って行われているプロジェクトであり，2000年に最初のワークショップが行われた後，2001年から本格的に要約課題の提示，自動要約システムの評価が開始され，その結果に対する議論を経て課題内容や評価基準の改良が施されてきている．

DUC2001では，英語新聞記事を対象として単一文書の要約・複数文書の要約の2種類の課題が出された．
対象とするデータは両課題において共通であり，トレーニングデータとして30記事セット，テストデータとして新たに30記事セットが主催者から配布された．
各記事セットには約10記事ずつ含まれており，それらの記事はAP通信やFinancial Times, Los Angels Times, Wall Streat Jounal などの新聞から取られている．
各記事セットは，例えば「最高裁判事に任命されたトーマス氏についての記事」「ピナツボ火山の噴火についての記事」などの主題ごとに集められた記事から成っている．

DUCでは，要約率ではなく語数によって作成する要約の長さが制限された．
単一文書の要約では，各記事を100語以内に要約して出力することが課された．
複数文書の要約では，各記事セットごとに50語，100語，200語，400語の4種類の要約が課された．

DUC2001で用いられたデータのうち，本論文で示す実験では単一文書要約課題のデータを用いた．
ただし主催者側から与えられた正解データは，文抽出(extract)データではなく人間が作成した要約(abstract)データであったので，我々はこのabstractデータをもとに記事セット中の対応する文を抜き出し，重要文抽出の正解データを作成した．

本論文では，DUCで用いられた要約データを「DUCデータ」と呼ぶ．
DUCデータは英語書き言葉要約データの例として\ref{section:evaluation}章に示す評価結果，\ref{section:analysis}章に示す分析で用いられる．

\subsection{日本語話し言葉の要約データ}
\label{section:data_csj}

話し言葉の要約データとして本研究の実験に用いたコーパスは，国立国語研究所，東京工業大学，通信総合研究所の3団体が共同で構築作業をすすめているCSJコーパス(Corpus of Spontaneous Japanese)\cite{furui:asj2000}から得たものである．
CSJコーパスは，学会講演などのモノローグを中心に収集・構築されているコーパスである．
本論文では，このCSJコーパスのうち，1999年日本音響学会秋季研究発表会(AS99)の講演から35講演，2000年言語処理学会年次大会(NL00)の講演から25講演の計60講演を取り出して用いた．
重要文抽出の実験では，60講演のうち50講演(AS99から30講演，NL00から20講演)をトレーニングデータとし，10講演(AS99から5講演，NL00から5講演) をテストデータとして用いた．

重要文抽出を適用するには文境界が与えられている必要があるが，講演の書き起しデータは話し言葉の特性上，書き言葉のようには文の境界が予め与えられていない．
このため，三人の被験者(論文の著者は含まない)が全60講演について文境界の検出と重要文抽出のデータ作成をともに行った．
文境界においては，さらに各被験者の結果を言語学の専門家が統合して単一の文境界データを作成した．
文境界データにおける各講演の平均文数は68.7文であった．一方重要文抽出においては，各被験者における重要文の判断の揺れが大きく，正解データを統一することは困難であったので，\ref{section:evaluation}章で示す評価結果では被験者の抽出結果を個々に正解とみなして評価している．
なお，重要文抽出の要約率は10\,\%に設定した．

本来のCSJコーパスはここで用いたものよりも大規模なコーパスであるが，本論文ではCSJコーパスを用いて作成された要約データを「CSJデータ」と呼ぶ．
CSJデータは，日本語話し言葉要約データの例として\ref{section:evaluation}章に示す評価結果，\ref{section:analysis}章に示す分析で用いられる．

\section{重要文抽出手法の概要}
\label{section:system}

自動要約では，文章中で重要な文を選択するために有効と思われる素性を考案し，それを用いた評価尺度を関数の形で表現し，その評価値の高い文を抽出するという重要文抽出の手法が主に用いられており，本システムでもこの手法を採用している．
本章ではこの重要文抽出で用いた評価尺度について説明し，次にしきい値・重み付けなどその他の部分について説明する．

TSC，CSJ，DUC各データに特化した部分については，個々に特化した項目を明記する．
それ以外で特に対象データについて限定していない記述は，各データに対して共通して用いられた部分である．

\subsection{評価尺度}

本システムでは，個々の素性についてそれを基にした評価尺度を与える関数を予め定義している．
それぞれの情報に対しては，複数の関数を用意しているものがある．
それらの関数の選択も，各評価尺度に対する重みと同様，トレーニングデータを用いて行なう．

使用した評価尺度は，文の位置情報・文の長さ・単語のtf*idf値・記事の見出し，そして言語的パタンである．
各関数の出力したスコアに重みを掛け合せたものの和が，各文の重要度となる．

\subsubsection{文の位置}

本システムでは，文の位置情報に基づく関数を3種類用意した．
重要文を抽出する際には，この三つのうちの一つが用いられる．

1つ目の関数は，出力すべき文が\(N\)文であると指定されたときに，記事の先頭から\(N\)文目までにスコア1をつけ，それ以外は0とするものである：
\begin{eqnarray*}
\mbox{P1. }
 Score_{\mbox{pst}}(S_i) (1 \le i \le n) & = & 1 \quad (i < N \quad のとき) \\[-1mm]
                            & = & 0 \quad (\mbox{それ以外})
\end{eqnarray*}
ここで\(n\)は記事中の文の数を示す．
この関数は，最初の\(N\)文を要約結果とする単純な重要文選択の方法が
好成績を納めてきているという事実に基いたものである．

2つ目の関数は文の位置の逆数を与えるものである．つまり\(i\)番目の文に対するスコアは，
\begin{eqnarray*}
\mbox{P2. }
 Score_{\mbox{pst}}(S_i) & = & \frac{1}{i}
\end{eqnarray*}
となる．
この2つ目の関数は先頭に近い程重要であるという点では1つ目の関数と同じであるが，他の評価尺度と組み合わせた際に両者の差が出てくることを意図して定義されたものである．

3つ目の関数は，2つ目の関数に手を加え，先頭からの文の位置と末尾からの文の位置を共に用いるものである．
つまり，全文数が\(n\)である記事において，\(i\)番目の文に対するスコアは以下のようになる．
\begin{eqnarray*}
\mbox{P3. }
 Score_{\mbox{pst}}(S_i) & = & \max(\frac{1}{i}, \frac{1}{n - i + 1})
\end{eqnarray*}
この関数は，先頭か末尾に近い文ほど重要であるという仮定を表現したものである．

\subsubsection{文の長さ}

各文の長さに基づく評価尺度については，以下の3種類の関数を用意した．
1つ目の関数は，文の長さをそのままスコアとして与えるものである：
\begin{eqnarray*}
\mbox{L1. }
 Score_{\mbox{len}}(S_i) & = & L_i
\end{eqnarray*}
これは，「長い文ほど重要である」という仮定を表現したものである．

2つ目の関数は，長さ\(L_i\)が一定の値\(C\)より短い文にはペナルティとして負の値を与えるものである： 
\begin{eqnarray*}
\mbox{L2. }
 Score_{\mbox{len}}(S_i) & = & 0 \quad (L_i \ge C \quad のとき) \\[-1mm]
            & = & L_i - C \quad (\mbox{それ以外}) \nonumber
\end{eqnarray*}
このペナルティは，極端に短い文は重要文として選択されることが非常に稀であるという観測事実に基いている．

3つ目の関数は，1つ目と2つ目の関数を組み合わせたもので，各文の長さをスコアとして与えるが，一定値\(C\)より短ければペナルティとして負の値を与えるものである：
\begin{eqnarray*}
\mbox{L3. }
 Score_{\mbox{len}}(S_i) & = & L_i \quad (L_i \ge C \quad のとき) \\[-1mm]
            & = & L_i - C \quad (\mbox{それ以外}) \nonumber
\end{eqnarray*}
この関数は先に挙げた両者の関数の長所を組み合わせることを意図している．

TSCデータ・CSJデータにおける評価の際には，文の長さを文字数で表し，トレーニングデータを用いた実験の結果から一定値\(C\)を20(文字)とした．
DUCデータにおける評価の際には，文の長さを単語数で表し，同様にトレーニングデータを用いた実験の結果から一定値\(C\)を10(単語)とした．

\subsubsection{tf*idf値}
\label{section:system_tfidf}

この評価尺度は，各文中の単語についてtf*idf値を計算し文のスコア付けを行うものである．
tf*idf値は，各記事中の単語\(w\)の頻度{\it tf}\((w)\)と，その単語がある記事群の中で現れた記事の数，すなわち記事頻度{\it df}\((w)\)とを組み合わせて計算される値で，記事中のある単語がどの程度その記事特有の単語であるかを示す．
記事数{\it DN}個の記事群が与えられたとき，最も単純なtf*idf値の計算式は以下のようになる：
\begin{eqnarray*}
\mbox{T1.  } \mbox{tf*idf}(w) & = & \mbox{\it tf(w)}  \log \frac{\mbox{\it DN}}{\mbox{\it df(w)}} \\
\end{eqnarray*}
右辺第二項は特にinverse document frequency (idf)と呼ばれる値である．
tf*idf値は，与えられた検索要求に関連する記事をデータベースから検索する情報検索の分野において，記事の特徴を示すための指標として用いられるものであり，検索の精度を向上させるためにいくつか異なるtf*idf値の計算手法が提案されている．
その一つは以下のようなものである：
\begin{eqnarray*}
\mbox{T2.  } \mbox{tf*idf}(w) & = & \frac{\mbox{{\it tf(w)}}-1}{\mbox{\it tf(w)}}  \log \frac{\mbox{\it DN}}{\mbox{\it df(w)}} \\
\end{eqnarray*}
また，特に情報検索の分野において効果を挙げている\cite{2poisson}の定義に基づく式は以下のものである：
\begin{eqnarray*}
\mbox{T3.  } \mbox{tf*idf}(w) & = & \frac{\mbox{\it tf}(w)}{1+\mbox{\it tf(w)}}  \log \frac{\mbox{\it DN}}{\mbox{\it df(w)}}
\end{eqnarray*}

tf*idf値を重要文抽出に用いる意図は，「その記事に特有な単語をより多く含む文は，その記事においてより重要である」という仮定を表現することである．
各文のスコアは，文中の各単語に対するtf*idf値の和によって与えられる：
\begin{eqnarray*}
\mbox{\it Score}_{\mbox{tf*idf}}(S_i) & = & \sum_{w \in S_i} \mbox{tf*idf}(w)
\end{eqnarray*}
なお\ref{section:analysis}章で示す結果では，tf*idf値を用いた文のスコアから文の長さによる影響を避けるため，以下の式のようにtf*idf値の和を文の長さ\(\vert S_i \vert\)で割って正規化した値を文のスコアとしている：
\begin{eqnarray*}
\mbox{\it Score}_{\mbox{tf*idf}}(S_i) & = & \frac{1}{\vert S_i \vert}\sum_{w \in S_i} \mbox{tf*idf}(w)
\end{eqnarray*}

TSCデータ，CSJデータに対しては単語の切り分けにJUMAN ver.3.61\cite{juman361}を用い，tf*idf値を与える単語を時相名詞や副詞的名詞を除いた名詞に限定した．
記事頻度を求めるための記事群には，1994年と1995年の毎日新聞の記事を用いた．
DUCデータに対しては，品詞による単語の選別は行わず，ストップワードのリストを作成し，そのリストに含まれない単語についてtf*idf値を求めた．
記事頻度を求めるための記事群としては，1994年と1995年のWall Street Journalの記事を用いた．

TSCデータ, CSJデータにおいては，各単語のtf*idf値を求める際に関数T3を用いた．
DUCデータにおいては，T1〜T3の3つの関数のうち一つをトレーニングデータを用いて選択するようにした結果，T1が選択された．

\subsubsection{見出し}

この評価尺度は，対象記事の見出しに含まれる単語に対するtf*idf値を用いて文のスコア付けを行うものである．
これは「見出しと類似している文は重要である」という仮定に基いている．
類似度を求める際に対象とする単語は，前節のtf*idf値を用いた関数と同様に，日本語であるTSCデータ, CSJデータでは時相名詞や副詞的名詞を除いた名詞，英語であるDUCデータではストップワードのリストに含まれない単語である．
文(\(S_i\))中の対象単語について，その名詞が見出し(\(H\))に含まれていれば，そのtf*idf値を文のスコアに加算する．
文のスコアを与える式を以下に示す：
\begin{eqnarray*}
\mbox{H1.  } 
\mbox{\it Score}_{\mbox{hl}}(S_i)  = 
\frac{\displaystyle{\sum_{w \in H \cap S_i}} \mbox{tf*idf}(w)}
{\displaystyle{\sum_{w \in H}} \mbox{tf*idf}(w)}
\end{eqnarray*}
CSJデータにおいては，講演録そのものには見出しは存在しないが，それに対応する予稿から見出しを取り出して用いた．

TSCデータ，DUCデータについては，さらに名詞の代わりに固有表現(Named Entity: NE)を用いて見出しとの類似度を計算する関数も定義した．
TSCデータに対する日本語の固有表現抽出には，最大エントロピー法を用いたシステムを使用した\cite{uchimoto:acl2000}．
抽出する日本語固有表現の定義はIREXワークショップ\cite{IREX}で用いられたものに拠っている．
DUCデータに対する英語の固有表現抽出には，パターンベースの固有表現抽出システムを用いた．
このシステムは，拡張された固有表現の定義150クラスを抽出の対象とするものである\cite{sekine:lrec2002}．
固有表現を用いる際には，簡便性のため，tf*idf値ではなく頻度のみを用いた．
すなわち，各記事中の固有表現\(e\)に対する頻度\(\mbox {\it tf}(e)\)を用いれば，関数の式は以下のように示される： 
\begin{eqnarray*}
\mbox{TF}(e) & = & \frac{\mbox{\it tf}(e)}{1+\mbox{\it tf}(e)} \\[1mm]
\mbox{H2.  } 
\mbox{\it Score}_{\mbox{hl\_{\sc ne}}}(S_i)  & = &
\frac{\displaystyle{\sum_{e \in H \cap S_i}} \mbox{TF}(e)}
{\displaystyle{\sum_{e \in H}} \mbox{TF}(e)}
\end{eqnarray*}

\subsubsection{言語的パタン}

DUCデータに対しては，言語的パタンの獲得方法とそれを用いた評価尺度を導入した．
ここで用いているパタンの獲得手法は，日本語情報抽出において提案された手法に基づいている\cite{sudo:hlt2001}．
この手法は，例えば地震の発生を報道する記事には「○月×日ｘ時ｙ分ごろ，△□で地震があった」といった表現がよく現われるように，「分野(domain)を特定したときに，記事によく現れる表現はその分野において重要だ」という仮定に基づいてパタンを自動的に獲得するものである．

DUC2001においては，約10記事ずつを1セットとして30記事セットのデータが配布されたので，この各記事セットを情報抽出における一つの分野とみなし，各セットごとにパタンの自動獲得を行った．
パタンの獲得方法は以下の過程に従って行われる：
\begin{enumerate}
 \item 文の解析： \\
	   与えられた記事セット中の記事全文について品詞・固有表現のタグづけ，係り受け解析を行う．
 \item 部分木の抽出： \\
	   係り受け木中の部分木を全て取り出す．
 \item 固有表現による抽象化： \\ 
	   部分木中に固有表現があった場合には，その固有表現を対応するクラス
	   に置き換えたものと，元の表現のままの二通りの部分木をパタンとして
	   用意する．複数の固有表現がある場合は，各置換操作の組み合わせだけ部
	   分木を生成する．
 \item 部分木のスコア付け： \\ 
	   木全体の頻度と，部分木中の各単語の記事頻度から部分木のスコアを求める．
	   このスコアの定義は，その記事セットに特有な部分
	   木を取り出すという意図に基づいており，スコアが高い部分木ほど重要
	   なパタンであると仮定することになる．
\end{enumerate}

パタンは重要文抽出を行う前に取り出され，スコアとともにシステムに格納される．
実際に重要文抽出を行うときには，システムは各文\(S_i\)について品詞・固有表現のタグづけや係り受け解析を行って係り受け木を作成し，次いで格納されたパタンとの比較を行う．
パタン\(P_j\)のスコアと文\(S_i\)の評価尺度をそれぞれ式に表わすと以下のようになる：
\begin{eqnarray*}
\mbox{\it a\_idf}_j & = & \displaystyle{\frac{1}{\vert P_j \vert}\sum_{w \in P_j} \log \frac{\mbox{\it DN}}{\mbox{\it df(w)}}} \\
\mbox{\it PatScore}(S_i) & = & \displaystyle{\sum_{j} F_{P_{j}} \mbox{\it a\_idf}_j} \mbox{ (} P_j \mbox{ が } S_i \mbox{の一部に一致) }  \\
                         & = & 0 \mbox{ (それ以外) } \\
\mbox{\it Score}_{\mbox{pat}}(S_i) & = & \log (\mbox{\it PatScore}(S_i)+1)
\end{eqnarray*}
ここで，\(F_{P_{j}}\) はパタン\(P_{j}\)の記事セット中の頻度，\(\vert P_j \vert\) は \(P_{j}\)中の単語数を示す．
{\it DN}は予め与えられた記事群中の記事数，{\it df}\((w)\)はその記事群の中で単語\(w\)が現れる記事の数である．
すなわち，\(a\_idf\)は，パタン\(P_{j}\)中の単語の平均idf値であり，これとパタンの頻度\(F_{P_{j}}\)を用いて\ref{section:system_tfidf}節で述べたtf*idf値のような値を各パタンに与えることが，パタンのスコアを表す式の意図するところである．
あるパタン\(P_j\)が文\(S_i\)の係り受け木の一部と一致した場合には，そのパタンのスコアが文の評価尺度として加算される．
さらに各文について一致した全パタンのスコアを加算し，その値の対数をとったものを最終的な文の評価尺度\(\mbox{\it Score}_{\mbox{pat}}\)としている．

\subsection{重み付け}

本システムでは，各評価尺度の値({\it Score}\(_j()\))に重み(\(\alpha_j\))を掛け合わせたものの総和をとり，各文(\(S_i\))のスコアを与える：
\begin{eqnarray}
\label{eq:weight}
 \mbox{TotalScore}(S_i) = \sum_{j} \alpha_j \mbox{\it Score}_j(S_i)
\end{eqnarray}
この重み付けの最適値は，トレーニングデータを用いて求めた．
具体的には，予め設定した値域内で，重みの値を変化させながらトレーニングデータに対する実験・評価を繰り返し，最も良い値を与える重みづけの値を求めた．
複数の関数が定義されている評価尺度においては，その関数の選択も重み付けとともに行なわれた．

TSCデータ, DUCデータにおいては，それぞれ予備試験のデータをトレーニングデータとして用いた．
TSCデータにおいては，30の新聞記事を更に社説15記事とそれ以外の報道記事15記事とに分けてそれぞれについて最適な重み付けを求めた
\footnotemark．
\footnotetext{ 要約の対象となる各記事には，{\tt{}<SECTION>}社説
{\tt{}</SECTION>} のようにセクションが明示されており，社説とその他の記事
とを分類することは容易に行うことができた．}
CSJデータでは，60講演のうち，テストデータとして残した10講演を除く50講演をトレーニングデータとして用いた．
\ref{section:evaluation}章に示す実験結果では，各情報においてどの関数が選ばれたか，重みの程度がどの
くらいだったかを報告する．

\subsection{しきい値}

本システムでは，重要文抽出を行う際に記事中の全文にスコア付けを行い，その結果を元にスコアの良い順に各文を順位付けする．
これらの文のうち何文まで出力するかを決定するのに，本システムでは文数・文字数(単語数)・スコアの3種類のしきい値を用いることができる．
どのしきい値を用いても，出力される文の順番は元の記事のまま保たれる．

文の数\(N\)がしきい値として与えられたならば，システムは順位付けされた文の上位\(N\)文までを重要文として抽出する．
文字数または単語数が与えられたときには，システムはこれを文数のしきい値に変換する．
スコアがしきい値として与えられたならば，システムはそのしきい値より大きい値をもつ文のみを出力する．

TSCデータ，CSJデータについては，文の数\(N\)をしきい値として用いた．
DUCデータについては，DUC2001において100語前後の要約を出力することが課題に指定されていたので，単語数をしきい値として用いた．

\section{各タスクの評価結果}
\label{section:evaluation}

本章では，前章で述べた重要文抽出システムをTSC，DUC，CSJの3種類のデータそれぞれに適用した結果を示す．

\subsection{TSCデータでの評価結果}

TSC2001の重要文抽出課題においては，人手で作成された重要文抽出の正解データとシステムの出力した重要文抽出結果との間で，どのくらい抽出された重要文が一致するかの度合に基づいた評価が行われた．
評価の指標としては，再現率・精度・F値の3種類\footnotemark{}が用いられた．
\footnotetext{
再現率・精度・F値の定義は以下のように与えられる：
\begin{quote}
再現率(REC) = COR / GLD \\
精度(PRE) = COR / SYS \\
F値 = 2 * REC * PRE / (REC + PRE)
\end{quote}
ここで，COR はシステムが出力した文のうち正解である文の数，
GLD は正解データに含まれる重要文の数，
SYS はシステムが出力した全文数を示す．
各記事についてこれらの値を計算したあと，全記事の平均をとったものが
最終的な評価値となった．
}

表\ref{table:result_tsc}は，本システムの重要文抽出での評価結果を，二種類のベースラインシステムの結果とともに示したものである．
ベースラインシステムのうち，Lead-basedは常に記事の先頭から指定された文数まで出力するものであり，TF-basedは各文ごとに記事中の語(名詞，動詞，形容詞，未定義語)のTF値の和を計算し，そのスコアの高い順に文を選択する手法である．
このとき選択された文の順序は，元記事の順序のものを保つ．

表内の数値はF値を示す．
また，表内の本システムの評価値に添えた括弧内の数字は，参加した10システム中の本システムの順位である．
本システムは，平均・各要約率の各評価においてベースラインシステムの結果を上回る成果を得た．また，参加システム中でも，全体で2位の評価であった．
社説と報道記事とでは，文の位置情報を用いる評価尺度において，異なる関数が選択されており，この選択が重要文抽出の評価向上に意味があったと考えられる．
このことをより明確に示すために，文の位置情報のみを用いたときの，記事の種類別に見た評価結果を表\ref{table:result_tsc_location}に示す．
P1とP2は，文の位置情報を単独で用いたときには同じ値を返すので，ここでは一つにまとめた．
表\ref{table:result_tsc_location}に示されるように，P1, P2は社説以外の報道記事でP3より高い結果を示し，P3は社説においてP1, P2より高い結果を示した．
すなわち，社説においては記事の前の方と後の方の両方に重要文として選択されたものが多く，社説以外では前の方だけに重要文として選択されたものが多いということを示している．
本システムにおける文の位置を用いた評価尺度では，用いる関数を対象記事の種類に応じて適切に使い分けることで，どれか一つの関数に固定した場合の評価結果を上回ることができている．

\begin{table}[t]
\caption{TSCデータにおける重要文抽出の評価結果}
\begin{center}\label{table:result_tsc}
\begin{tabular}{l|lll|l} \hline
要約率 & 10\,\% & 30\,\% & 50\,\% & 平均 \\ \hline
本システム~(順位)  & 0.363 (1) & 0.435 (5) & 0.589 (2) & 0.463 (2) \\
ベースライン1:~Lead-based & 0.284 & 0.432 & 0.586 & 0.434 \\ 
ベースライン2:~TF-based   & 0.276 & 0.367 & 0.530 & 0.391 \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[t]
\caption{TSCデータの記事の種類別に見た文の位置情報の評価結果}
\begin{center}\label{table:result_tsc_location}
\begin{tabular}{c|ccc|c} \hline
\multicolumn{5}{l}{P1, P2} \\ \hline
要約率 & 10\,\%   & 30\,\%  & 50\,\%  & 平均  \\ \hline
社説   & 0.158  & 0.256 & 0.474 & 0.293 \\
その他 & 0.394  & 0.478 & 0.586 & 0.486 \\
全体   & 0.276  & 0.367 & 0.530 & 0.391 \\ \hline
\multicolumn{5}{l}{P3} \\ \hline
社説   & 0.323  & 0.360 & 0.557 & 0.413 \\
その他 & 0.356  & 0.436 & 0.544 & 0.445 \\
全体   & 0.339  & 0.398 & 0.550 & 0.429 \\ \hline
\multicolumn{5}{l}{本システムでの文の位置を用いた評価尺度} \\ \hline
全体   & 0.359  & 0.419 & 0.572 & 0.450 \\ \hline
\end{tabular}
\end{center}
\end{table}

各評価尺度がどの程度結果に寄与しているかをみるために，表\ref{table:optimal_weight_tsc}に各評価尺度の標準偏差とそれに対する重みを掛け合わせたものを示した．
標準偏差が大きいほど各文に対する評価尺度の変化の度合が大きくなり，また各評価尺度の値には与えられた重みが掛け合わされて用いられるので，表に示した値によって各評価尺度が最終的な文のスコアにどの程度大きな影響を及ぼすかが分かる．
表中の値は，各評価尺度の寄与する度合を正規化したものを示している．
すなわち，各評価尺度についての値を要素とするベクトルについて，そのノルムが1になるように値を変換している．
表\ref{table:optimal_weight_tsc}から，文の位置に基づく評価尺度はどの区分においても寄与している評価尺度であり，特に社説においてその値が大きいことが分かる．
それ以外の評価尺度は，対象とする記事の分野や要約率によってその寄与する度合が大きく変化している．
しかし，\ref{section:analysis}章で示す分析からは，文の位置を除く評価尺度間の相関が有意に存在することから，文の位置とそれ以外の評価尺度のどれかを使うということがより重要であって，文の位置以外のどの評価尺度を使うかによる差は，それほど重要でなかったと考えられる．


\begin{table}[t]\small
\caption{TSCデータにおける各評価尺度の重み×標準偏差，及び選択された関数の種類}
\label{table:optimal_weight_tsc}
\begin{center}
\begin{tabular}{l|l|lr|lr|lr} \hline
         &              & \multicolumn{6}{|c}{要約率} \\ \cline{3-8}
対象記事 & 評価尺度     &  \multicolumn{2}{|c|}{10\,\%} & \multicolumn{2}{|c|}{30\,\%} & \multicolumn{2}{|c}{50\,\%} \\ \hline
社説     & 文の位置     & P3 & 0.811 & P3  & 0.533 & P3  & 0.788  \\
         & 文長         & L2 & 0.000 & L2  & 0.000 & L2  & 0.000  \\
         & tf*idf       & T3 & 0.306 & T3  & 0.503 & T3  & 0.298  \\
         & 見出し(単語) &    & 0.311 &     & 0.681 &     & 0.504  \\
         & 見出し(NE)   &    & 0.389 &     & 0.000 &     & 0.189  \\[2mm] \hline
報道     & 文の位置     & P1 & 0.501 & P1  & 0.464 & P1  & 0.278 \\
         & 文長         & L2 & 0.000 & L2  & 0.870 & L2  & 0.957 \\
         & tf*idf       & T3 & 0.365 & T3  & 0.146 & T3  & 0.080 \\
         & 見出し(単語) &    & 0.578 &     & 0.058 &     & 0.000 \\
         & 見出し(NE)   &    & 0.531 &     & 0.053 &     & 0.029 \\ \hline
\end{tabular} 
\end{center}
\end{table}

\subsection{DUCデータでの評価結果}

表\ref{table:optimal_weight_duc}に，DUCデータにおける各評価尺度の標準偏差とそれに対する重みを掛け合わせたものを示す．
TSCデータにおける値と同様に，これらの値は各評価尺度についての値を要素とするベクトルについて，そのノルムが1になるように値を変換している．

結果から，最も文のスコアに対する影響が大きい評価尺度は文の位置であり，次いでtf*idf値であった．見出しや言語的パタンに基づく評価尺度は，それらに比較して結果に寄与する割合が小さかった．

\begin{table}[t]
\caption{DUCデータにおける各評価尺度の重み×標準偏差}
\label{table:optimal_weight_duc}
\begin{center}
\begin{tabular}{l|l|r} \hline
評価尺度 & 関数 & 重み×S.D. \\ \hline
文の位置 & P1   & 0.943 \\
文の長さ & L2   & 0.027 \\
tf*idf   & T1   & 0.327 \\
見出し   & H2   & 0.061 \\
パタン   & -    & 0.007 \\ \hline
\end{tabular}
\end{center}
\end{table}

DUC2001における要約結果の評価は主観評価によって行なわれた．
すなわち，システムによって生成された要約と人間が作成した要約とを被験者が比較してその質を判定した．
主観評価は，Grammaticality(文法性)，Cohesion(結束性)，Organization/coherence(一貫性)の3つの基準について行われ，10人の被験者が各基準について5段階(4が最も高く，0が最も低い)の評価を与えた．
各被験者の評価結果の平均を表\ref{table:eval_result}に示す．
全システムの結果は，参加した11システムとベースラインの結果の平均値である．
ベースラインの要約は，各記事について先頭から100語ずつ出力したものである．

本システムの結果は，どの評価基準においてもベースライン，全システムの平均を上回っている．
また，システム全体での順位も，文法性では5位であったが，それ以外の評価では1位であり，全体でも1位であった．

\begin{table}[t]
\caption{DUCデータでの評価結果(主観評価：被験者の評価の平均)}
\label{table:eval_result}
\begin{center}
\begin{tabular}{l|lll|l} \hline
評価基準          & 文法性    & 結束性    & 一貫性    & 全体      \\ \hline
本システム~(順位) & 3.711~(5) & 3.054~(1) & 3.215~(1) & 9.980~(1) \\       
ベースライン      & 3.236     & 2.926     & 3.081     & 9.243     \\       
全参加者の平均    & 3.580     & 2.676     & 2.870     & 9.126     \\ \hline
\end{tabular}
\end{center}
\end{table}


\subsection{CSJデータでの評価結果}

CSJデータにおける各評価尺度の標準偏差とそれに対する重みを掛け合わせたものを，表\ref{table:optimal_weight_csj}に示す．
TSCデータにおける値と同様，これらの値は各評価尺度についての値を要素とするベクトルについて，そのノルムが1になるように値を変換している．
結果から，最も文のスコアに対する影響が大きい評価尺度は文の長さであり，次いで文の位置，tf*idf値であった．

CSJデータに対する要約の評価結果を表\ref{table:performance_csj}に示す．
ここでは，文境界をパタンに基いたシステムによって自動的に検出した場合と，正しい文境界を予め与えた場合の双方について重要文抽出結果の評価を行った．
また，\ref{section:data_csj}節で述べたように，3人の被験者がそれぞれ作成した重要文抽出の結果は判断の揺れが大きく，それらを統合して正解データを作成することは困難であったので，この表では，各被験者(それぞれA,B,Cとする)の重要文抽出結果を個々に正解とみなしてシステムの出力を評価した値と，それらの平均値とをともに示した．

文境界を自動的に検出した場合の評価結果の平均は30\,\%を超えない．
一方，正しい文境界を予め与えた場合の重要文抽出結果はF値で36.8\,\%という評価を得た．
CSJデータについてはコンテストによる結果は存在しないため，同一データによる他のシステムとの評価結果の比較は行っていないが，
TSC，CSJ両データに対する重要文抽出の結果を比較すると，10\,\%という小さい要約率においては文境界が正しく検出できれば，話し言葉に対する重要文抽出は新聞記事に対する重要文抽出に匹敵しうることを示しているといえる．

\begin{table}[t]
\caption{CSJデータにおける各評価尺度の重み×標準偏差}
\label{table:optimal_weight_csj}
\begin{center}
\begin{tabular}{l|l|r} \hline 
評価尺度     &  関数 & 重み×S.D. \\ \hline
文の位置     &  P3   & 0.248  \\ 
文の長さ     &  L2   & 0.948  \\ 
tf*idf       &  T3   & 0.198  \\
見出し(単語) &  -    & 0.028  \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[t]
\caption{CSJデータでの評価結果}
\label{table:performance_csj}
\begin{center}
\begin{tabular}{l|llll} \hline
文境界＼被験者 & A   &   B  &     C &  平均 \\ \hline
自動           & 0.352 & 0.297 & 0.250 & 0.300 \\
正解           & 0.411 & 0.359 & 0.334 & 0.368 \\ \hline
\end{tabular} 
\end{center}
\end{table}

\section{要約データの分析}
\label{section:analysis}

\ref{section:evaluation}章では，複数の素性を用いた重要文抽出システムが，TSC，DUC，CSJの各データについて良好な結果を得たことを示した．
しかしながら，評価結果だけでは，各データにおいて有効な素性に違いはあるのか，複数の素性を組み合わせて用いたことにどのような効果があったのかという点についてはっきり示されていない．
そこで本章では，まず各素性についてその値の変化に対応する重要文の分布を図示し，どのような素性の用い方が効果的であるかを調べた．
次に，有効な素性の組み合わせを調べるため，二つの素性間の相関と素性の組み合わせによる重要文の数・割合の分布を示した．

\subsection{素性に対応する重要文の分布}

本節では，重み付けの値を得たトレーニングデータにおいて重要と判断された文と素性との関連を調べ，素性を用いた評価尺度のうちどのようなものが有効であるかを考察する．
具体的には，文の位置・文の長さ・tf*idf値・見出しの4種類の素性について，その評価尺度の値に対応する記事全体の文数・重要文の文数を調べた．
文の位置・tf*idf値・見出しについてのグラフでは，各素性ごとにそれに基づく評価尺度の値の昇順に文を順位付けしてその順位を5\,\%または10\,\%ごとに区分し，各区分ごとに重要文の占める割合を示した．
一方，文の長さについてのグラフでは，傾向をより見やすくするために，文の長さの値そのものに対して記事中の文数とそれに含まれる重要文の数とを示した．
TSCデータにおいては，さらに記事の種類を社説と報道記事に分け，個々の要約率における正解要約(10\,\%, 30\,\%, 50\,\%)に含まれる重要文の割合をグラフによって示した．
なおCSJデータについては，重要文の数・割合として3人の被験者による抽出結果の平均値を用いている．

データ全体の文数・重要文の数を示すため，表\ref{table:training_num_of_sent}に各トレーニングデータの記事数と文数・重要文の数・要約率を掲げる．
DUCデータにおいては，要約の制限は要約率ではなく語数(100語)であったため，全データにおける重要文の割合を要約率として示した．

\begin{table}[t]
\caption{各トレーニングデータの記事数と文数}
\label{table:training_num_of_sent}
\begin{center}
\begin{tabular}{l|rrl} \hline
データの種類    & 記事数 & 文数  & 重要文の数(要約率) \\ \hline
TSCデータ：報道 & 15     & 257   & 34(10\,\%),86(30\,\%),118(50\,\%) \\       
TSCデータ：社説 & 15     & 459   & 51(10\,\%),143(30\,\%),225(50\,\%) \\
DUCデータ       & 299    & 13988 & 3299(23.5\,\%) \\       
CSJデータ       & 50     & 3428  & 333.3(10\,\%: 被験者間の平均) \\ \hline
\end{tabular}
\end{center}
\end{table}
\clearpage

\subsubsection{文の位置}

\begin{figure*}[t]
\begin{center}
\begin{tabular}{ll}
\epsfile{file=tsc_ratio_position_report_train.eps,width=.47\columnwidth} &
\epsfile{file=tsc_ratio_position_editorial_train.eps,width=.47\columnwidth} \\
\epsfile{file=duc_ratio_position_train.eps,width=.47\columnwidth} &
\epsfile{file=csj_ratio_position_train.eps,width=.47\columnwidth}
\end{tabular}
\end{center}
\caption{各データにおける文の位置と重要文との関係}
\label{figure:position_train}
\end{figure*}

各データ中の文の位置と重要文との関係を図\ref{figure:position_train}に示す．
グラフ中の横軸は各記事中の文の位置であり，先頭を0，末尾を1として正規化した値を表している．

TSC報道記事データ(Report)では，先頭に近いところに一番大きなピークがあり，「先頭の方ほど重要な文が多い」という仮定は当たっているようである．
一方，社説データ(Editorial)では，先頭に重要な文がある割合は報道記事に比べて小さいが， 末尾からの文の位置と文数の関係を見ると，末尾に近いところにも大きなピークがある．
社説においては，先頭だけでなく末尾の部分にも被験者に選択された文が多かったということになる．

DUCデータにおいては，末尾よりも先頭からの文の位置と重要文数の関係が比較的強く，DUCデータにおける文の位置と重要文との関係はTSC報道記事データに近い．
一方CSJデータにおいては，先頭よりも末尾の方に被験者に選択された文がより多く，CSJデータにおける文の位置と重要文との関係はTSC社説データに近いことがグラフから分かる．
CSJデータは学会講演から取られたものであるので，最後に発表をまとめる表現が重要文とされることが多いことがその要因として考えられる．
\clearpage

\subsubsection{文の長さ}

\begin{figure*}[t]
\begin{center}
\begin{tabular}{ll}

\epsfile{file=tsc_total_length_report_train.eps,width=.47\columnwidth} &
\epsfile{file=tsc_total_length_editorial_train.eps,width=.47\columnwidth} \\
\epsfile{file=duc_total_length_train.eps,width=.47\columnwidth} &
\epsfile{file=csj_total_length_train.eps,width=.47\columnwidth}
\end{tabular}
\end{center}
\caption{各データにおける文の長さと文の数・重要文の数との関係}
\label{figure:length_train}
\end{figure*}

文の長さと文の数・重要文の数との関係を図\ref{figure:length_train}に示す．
TSCデータ, CSJデータでは文の長さを文字数で，DUCデータでは文の長さを単語数で示している．
どのデータにおいても，短い文に対しては記事全体の文数に比べて重要文の文の割合が小さい．
一定の長さ以下の文にペナルティを与える関数は重要でない文を除く上で有効であったといえる．
また非常に長い文は，その数は少ないが重要文である割合が高く，一定の長さ以上の文を重要文とみなすような関数を用いることも考えられる．
\clearpage

\subsubsection{tf*idf値}

\begin{figure*}[t]
\begin{center}
\begin{tabular}{ll}

\epsfile{file=tsc_ratio_tfidf1_report_train.eps,width=.47\columnwidth} &
\epsfile{file=tsc_ratio_tfidf1_editorial_train.eps,width=.47\columnwidth} \\
\epsfile{file=duc_ratio_tfidf1_train.eps,width=.47\columnwidth} &
\epsfile{file=csj_ratio_tfidf1_train.eps,width=.47\columnwidth}


\end{tabular}
\end{center}
\caption{各データにおけるtf*idf値を用いた評価尺度と重要文との関係}
\label{figure:tfidf_train}
\end{figure*}

tf*idf値を用いた評価尺度と重要文との関係を図\ref{figure:tfidf_train}に示す．
ここでは各単語ごとのtf*idf値の計算には式T1を用い，また文の長さによる影響を避けるため，各文ごとにtf*idf値の和を文長によって正規化している．
横軸に示している値は，tf*idf値を用いた評価尺度の値そのものではなく，評価尺度の値によって各文を順序付けした相対順位である．

TSC報道記事データでは，tf*idf値が大きくなるにつれて，特に30\,\%，50\,\%の要約率において正解要約に含まれる文の割合が大きくなる．
tf*idf値の高い文は重要であると見なすことは報道記事において効果があったと考えられる．

DUCデータ，CSJデータにおいては，tf*idf値が大きくなるに従って緩やかに重要文である割合が増しているが，際立った特徴は見られなかった．
TSCデータにおいても10\,\%におけるグラフは，報道記事データ・社説データの双方においてほぼ同様の傾向を示しており，CSJデータの要約率は10\,\%であり，DUCデータにおける要約率の平均は23.5\,\%であることを考慮すると，要約率が小さい場合には，tf*idf値はどのデータにおいてもとくに目立った特徴は示していないといえる．

\subsubsection{見出し}

\begin{figure*}[t]
\begin{center}
\begin{tabular}{ll}

\epsfile{file=tsc_ratio_hl_noun_report_train.eps,width=.47\columnwidth} &
\epsfile{file=tsc_ratio_hl_noun_editorial_train.eps,width=.47\columnwidth} \\
\epsfile{file=duc_ratio_hl_noun_train.eps,width=.47\columnwidth} &
\epsfile{file=csj_ratio_hl_noun_train.eps,width=.47\columnwidth}
\end{tabular}
\end{center}
\caption{各データにおける見出しを用いた評価尺度(単語単位)と重要文との関係}
\label{figure:hl_noun_train}
\end{figure*}

\begin{figure*}[t]
\begin{center}
\begin{tabular}{ll}

\epsfile{file=tsc_ratio_hl_ne_report_train.eps,width=.47\columnwidth} &
\epsfile{file=tsc_ratio_hl_ne_editorial_train.eps,width=.47\columnwidth} \\
\epsfile{file=duc_ratio_hl_ne_train.eps,width=.47\columnwidth} & \\


\end{tabular}
\end{center}
\caption{各データにおける見出しを用いた評価尺度(固有表現単位)と重要文との関係}
\label{figure:hl_ne_train}
\end{figure*}

見出しを用いた評価尺度と重要文との関係を図\ref{figure:hl_noun_train}, 図\ref{figure:hl_ne_train}に示す．
図\ref{figure:hl_noun_train}は単語を単位とした見出しと文との類似度に基づくグラフ，図\ref{figure:hl_ne_train}は固有表現を単位とした見出しと文との類似度に基づくグラフである．
CSJデータに対しては固有表現を単位とした評価尺度を適用していないので，図\ref{figure:hl_ne_train}のグラフはTSCデータとDUCデータのもののみ掲げてある．
横軸に示している値は，tf*idf値におけるグラフと同様に，見出しを用いた評価尺度の値によって各文を順序付けした相対順位である．

tf*idf値を用いた評価尺度とTSC報道記事データとの関連と同様に，TSC社説データにおいて見出しを用いた評価尺度による順位が大きくなるにつれて，特に30\,\%，50\,\%の要約率において正解要約に含まれる文の割合が大きくなる．
見出しを用いた評価尺度の値が高い文を重要であると見なすことは，社説において効果があったと考えられる．

DUCデータ，CSJデータにおいては，tf*idf値に比べると評価尺度による順位が90\,\%以上のときの重要文の増加の割合がより大きい．
見出しを用いた評価尺度の値が大きい文は，数としては少ないが重要文である割合が高いことが分かる．

固有表現を単位とした評価尺度においては，グラフ全体の傾きは単語を単位とした評価尺度よりも小さく，重要文の割合と評価尺度の値との関連はあまり見られないが，評価尺度による順位が90\,\%以上のときには，単語を単位とした評価尺度と同様に重要文の割合が増加している．

\subsection{素性間の関係}

\begin{table}[t]\small
\caption{各データにおける素性間の順位相関係数}
\label{rank_cc_results}
\begin{center}
\begin{tabular}{l|rrrrr} \hline \hline
\multicolumn{6}{c}{TSC報道記事データ} \\ \hline
             & 文の位置 & 文の長さ & tf*idf値 & 見出し(単語) & 見出し(NE) \\ \hline
文の位置     & --       & 0.019    & $-$0.095   & $-$0.139       & $-$0.137     \\       
文の長さ     & 0.019    & --       & 0.546    & 0.338        & 0.272      \\       
tf*idf値     & $-$0.095   & 0.546    & --       & 0.696        & 0.312      \\       
見出し(単語) & $-$0.139   & 0.338    & 0.696    & --           & 0.399      \\       
見出し(NE)   & $-$0.137   & 0.272    & 0.312    & 0.399        & --         \\ \hline \hline
\multicolumn{6}{c}{TSC社説データ} \\ \hline
             & 文の位置 & 文の長さ & tf*idf値 & 見出し(単語) & 見出し(NE) \\ \hline
文の位置     & --       & $-$0.047   & $-$0.099   & 0.046        & 0.023      \\       
文の長さ     & $-$0.047   & --       & 0.532    & 0.289        & 0.209      \\       
tf*idf値     & $-$0.099   & 0.532    & --       & 0.658        & 0.371      \\       
見出し(単語) & 0.046    & 0.289    & 0.658    & --           & 0.517      \\       
見出し(NE)   & 0.023    & 0.209    & 0.371    & 0.517        & --         \\ \hline \hline
\multicolumn{6}{c}{DUCデータ} \\ \hline
             & 文の位置 & 文の長さ & tf*idf値 & 見出し(単語) & 見出し(NE) \\ \hline
文の位置     & --       & $-$0.130   & $-$0.108   & $-$0.134       & $-$0.062     \\       
文の長さ     & $-$0.130   & --       & 0.471    & 0.293        & 0.186      \\       
tf*idf値     & $-$0.108   & 0.471    & --       & 0.526        & 0.269      \\       
見出し(単語) & $-$0.134   & 0.293    & 0.526    & --           & 0.493      \\       
見出し(NE)   & $-$0.062   & 0.186    & 0.269    & 0.493        & --         \\ \hline \hline
\multicolumn{6}{c}{CSJデータ} \\ \hline
             & 文の位置 & 文の長さ & tf*idf値 & 見出し(単語) & --         \\ \hline
文の位置     & --       & $-$0.092   & $-$0.069   & $-$0.106       & --         \\       
文の長さ     & $-$0.092   & --       & 0.460    & 0.224        & --         \\       
tf*idf値     & $-$0.069   & 0.460    & --       & 0.533        & --         \\       
見出し(単語) & $-$0.106   & 0.224    & 0.533    & --           & --         \\ \hline
\end{tabular}
\end{center}
\end{table}

複数の素性を用いて重要文抽出を行うには，素性間の独立性が高いことと，素性を組み合わせたときに重要文が多い値域を絞り込めることが重要である．
本節では，まず素性間の独立性を調べるために，各素性による文のスコアの順序に基づく順位相関係数を求め，素性間の独立性を調べた結果を示す．
次に，独立性が比較的高い素性同士のいくつかの組み合わせについて，その組み合わせによる重要文の数・割合の分布を示した．


\subsubsection{素性間の相関}

各要約データにおける文の位置・文の長さ・tf*idf値・見出しの4種類の素性について，その評価尺度の値に基づく順位相関係数(Spearman)を求めた．
各素性の組ごとの順位相関係数の値を表\ref{rank_cc_results}に示す．
結果からは，どのデータにおいても
\begin{itemize}
 \item 文の位置は他のどの素性とも相関が低く，比較的独立であること
 \item 文の長さとtf*idf値との相関が高いこと\footnotemark
 \item TF*idf値と見出し(単語)との相関が高いこと
\end{itemize}
が分かる．
\footnotetext{ここでは，前節と同様に各単語ごとのtf*idf値の計算には式T1を用い，また文の長さによる影響を避けるため，各文のスコアは，tf*idf値の和を文の長さで割って正規化している．
従って「文の長さ」と「tf*idf値」との相関が高いことは自明な結果ではない．}
これら4種類の素性は重要文抽出に用いられる典型的な素性であり，\ref{section:evaluation}章ではこれらの素性を組合せて重要文抽出を行い日本語・英語双方のコンテストにおいて良好な結果を得たことを示したが，順位相関係数の値からはこれらの素性は必ずしも相互に独立ではないことが分かった．

\subsubsection{素性の組み合わせ}

前節の結果から，4種類の素性は互いに独立であるとはいえないが，文の位置と他の素性との組み合わせはどのデータにおいても他の組み合わせと比較して独立性が高いことが分かった．
本節では，これらの素性の組み合わせにおいて重要文の分布とどのように関連しているかを調べる．
TSCデータについては，素性の組み合わせについて示すにはデータ中の文数が少ないため，ここではDUCデータとCSJデータについて調べた結果のみを示している．

前節の結果独立性の高かった文の位置と他の素性の組み合わせについて，重要文の分布がどう変化するかを示す．
表\ref{table:diagram_pst_len}，\ref{table:diagram_pst_tfidf}，\ref{table:diagram_pst_hlnoun}は，二つの素性の組み合わせによって重要文の数・割合がどう変化するかを示したものである．
これらの表では各素性ごとにその評価尺度の値の昇順に文を順位付けし，その順位を10\,\%ごとに区分して各区分ごとに重要文の数と割合を文字によって段階分けして示した．
各区分中の文字は，重要文が各区分に均一に分布している場合に比べて，どのくらい偏りがあるかを示すものである．
左側の文字は重要文の数の偏りを示すもので，具体的には，データ中の全重要文の数を\(T\)としたときに各区分中の重要文の数\(T_{i,j}\)が重要文の各区分に対する平均値\(M (= \frac{T}{100})\)からどのくらい離れているかを，以下のような範囲ごとに示している．
ここで\(S\)は各区分に対する重要文数の標準偏差である．
\begin{quote}
\begin{tabular}{ll}
A: & \(T_{i,j} \ge M + 2S\) \\
B: & \(M + S \le T_{i,j} < M + 2S \) \\
C: & \(M - S \le T_{i,j} < M + S \) \\
D: & \(M - 2S \le T_{i,j} < M - S \) \\
E: & \(T_{i,j} < M - 2S \) \\
O: & \(T_{i,j} = 0 \) \\
{\tt -}: & その区分に対応する文が存在しない
\end{tabular}
\end{quote}

同様に，各区分の右側の文字は，重要文の全文数に対する割合が均一に分布している場合と比較して，どのくらい偏りがあるかを示すものである．
全文数\(N\)に占める重要文の割合を\(m (= \frac{T}{N})\)としたときに，各区分中の重要文の割合\(t_{i,j}\)が以下の範囲にあることを示している．
ここで\(s\)は各区分に対する重要文の割合の標準偏差である．
\begin{quote}
\begin{tabular}{ll}
a: & \(t_{i,j} \ge m + 2s\) \\
b: & \(m + s \le t_{i,j} < m + 2s \) \\
c: & \(m - s \le t_{i,j} < m + s \) \\
d: & \(m - 2s \le t_{i,j} < m - s \) \\
e: & \(t_{i,j} < m - 2s \) \\
o: & \(t_{i,j} = 0 \) \\
{\tt -}: & その区分に対応する文が存在しない
\end{tabular}
\end{quote}
すなわち，重要文が素性に関係なく均一に分布している状態ならば，全ての区分がCcとなる．
重要文の数が多くてもその割合が小さければ，単にその区分に含まれる文の数が多いだけで，重要文の抽出に有効な区分ではない．
逆に重要文の割合が大きくてもその数が小さければ，その区分は重要文抽出の性能向上に有効ではあるが，寄与する度合は小さい．

\begin{table}[tb]\small
\caption{文の位置と文長を組み合わせたときの重要文の分布}
\label{table:diagram_pst_len}
\begin{center}
\begin{tabular}{c|cccccccccc} \hline \hline
\multicolumn{11}{c}{DUCデータ} \\ \hline
 & \multicolumn{10}{c}{文の長さ} \\ \cline{2-11}
文の位置 & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 1.0 \\ \hline
0.1                    & Cc  & Cc  & Cc  & Cb  & Bb  & Ba  & Ba  & Aa  & Aa  & Aa  \\       
0.2                    & Cd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cb  & Bb  & Bb  & Aa  \\       
0.3                    & Dd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Bc  & Cc  & Cb  \\       
0.4                    & Cd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cb  & Cc  \\       
0.5                    & Cd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.6                    & Dd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.7                    & Dd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.8                    & Cd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.9                    & Dd  & Dd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
1.0                    & Dd  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
\hline \hline 
\multicolumn{11}{c}{CSJデータ} \\ \hline
 & \multicolumn{10}{c}{文の長さ} \\ \cline{2-11}
文の位置 & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 1.0 \\ \hline
0.1                    & Cc  & Cc  & Cc  & Ab  & Bc  & Cc  & Cc  & Cc  & Bc  & Ab  \\       
0.2                    & Cc  & Cc  & Cc  & Cc  & Cc  & Bc  & Cc  & Cc  & Cc  & Cc  \\       
0.3                    & Oo  & Oo  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.4                    & Cc  & Cc  & Cc  & Oo  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.5                    & Oo  & Oo  & Oo  & Cc  & Oo  & Cc  & Oo  & Cc  & Cc  & Cc  \\       
0.6                    & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.7                    & Cc  & Oo  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.8                    & Oo  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
0.9                    & Cc  & Cc  & Cc  & Cc  & Bb  & Cc  & Cc  & Cc  & Cc  & Cc  \\       
1.0                    & Cc  & Cc  & Aa  & Aa  & Aa  & Ba  & Aa  & Aa  & Aa  & Aa  \\       
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[tb]\small
\caption{文の位置とtf*idf値を組み合わせたときの重要文の分布}
\label{table:diagram_pst_tfidf}
\begin{center}
\begin{tabular}{c|cccccccccc} \hline \hline
\multicolumn{11}{c}{DUCデータ} \\ \hline
 & \multicolumn{10}{c}{tf*idf値} \\ \cline{2-11}
文の位置 & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 1.0 \\ \hline
0.1                    & Cc & Cc & Cc & Cb & Ba & Ba & Aa & Aa & Aa & Aa \\
0.2                    & Cd & Cc & Cc & Cc & Cc & Cc & Bb & Bb & Bb & Bb \\
0.3                    & Cd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.4                    & Dd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.5                    & Dd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.6                    & Dd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.7                    & Dd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.8                    & Cd & Dd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.9                    & Dd & Dd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
1.0                    & Dd & Dd & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
\hline \hline 
\multicolumn{11}{c}{CSJデータ} \\ \hline
 & \multicolumn{10}{c}{tf*idf値} \\ \cline{2-11}
文の位置 & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 1.0 \\ \hline
0.1                    & Cc & Cc & Cc & Cc & Bc & Cc & Ab & Bb & Bb & Bb \\
0.2                    & Oo & Oo & Cc & Cc & Cc & Cc & Cc & Bb & Bc & Cc \\
0.3                    & Oo & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.4                    & Cc & Cc & Cc & Cc & Oo & Cc & Cc & Cc & Cc & Cc \\
0.5                    & Oo & Cc & Oo & Oo & Cc & Oo & Cc & Cc & Cc & Cc \\
0.6                    & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.7                    & Oo & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc \\
0.8                    & Oo & Cc & Cc & Oo & Oo & Cc & Cc & Cc & Cc & Cc \\
0.9                    & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Cc & Bb \\
1.0                    & Cc & Cc & Ba & Bb & Bb & Aa & Aa & Bb & Aa & Aa \\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[tb]\small
\caption{文の位置と見出しを組み合わせたときの重要文の分布}
\label{table:diagram_pst_hlnoun}
\begin{center}
\begin{tabular}{c|cccccccccc} \hline \hline
\multicolumn{11}{c}{DUCデータ} \\ \hline
 & \multicolumn{10}{c}{見出し} \\ \cline{2-11}
文の位置 & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 1.0 \\ \hline
0.1                    & Ab & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Ca & Ba & Ba & Aa \\
0.2                    & Ac & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cb & Cc & Ca & Ca \\
0.3                    & Ac & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cb & Cb \\
0.4                    & Ac & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cc & Cb \\
0.5                    & Ac & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cc & Cc \\
0.6                    & Bc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cc & Cc \\
0.7                    & Bc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cc & Cc \\
0.8                    & Ac & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cd & Cc & Cc & Cc \\
0.9                    & Bd & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cd & Cc & Cc & Cc \\
1.0                    & Bd & {\tt --} & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cd & Cc & Cc & Cc \\
\hline \hline 
\multicolumn{11}{c}{CSJデータ} \\ \hline
 & \multicolumn{10}{c}{見出し} \\ \cline{2-11}
文の位置 & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 & 0.6 & 0.7 & 0.8 & 0.9 & 1.0 \\ \hline
0.1                    & Bc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Bb & Cc & Aa \\
0.2                    & Bc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cb & Cc & Cc & Bb \\
0.3                    & Cc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cc & Cc & Cc \\
0.4                    & Cc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Oo & Cc & Cc & Cc & Cc \\
0.5                    & Cc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Oo & Cc & Oo & Cc & Cc \\
0.6                    & Cc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cc & Cc & Cc \\
0.7                    & Cc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Oo & Cc & Cc & Cc & Cc \\
0.8                    & Cc & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Cc & Cc & Cc & Cc & Cc \\
0.9                    & Ac & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Ca & Cc & Cc & Cc & Cb \\
1.0                    & Ab & {\tt --} & {\tt --} & {\tt --} & {\tt --} & Ca & Aa & Ba & Ba & Ba \\
\hline
\end{tabular}
\end{center}
\end{table}

まず，表\ref{table:diagram_pst_len}に示した文の位置と文長の組み合わせについて調べてみると，DUCデータでは文の位置が先頭から20\,\%以内で，かつ文長による順位が50\,\%以降の場合(文の位置 \(\le\) 0.2，文長 \(\ge\) 0.5)において重要文の数，割合とも大きいことが分かる．
一方CSJデータでは文の位置が末尾から10\,\%以内で，かつ文長による順位が30\,\%以降の場合(文の位置 = 1.0，文長 \(\ge\) 0.3)に重要文の数，割合とも大きい．

次に，文の位置とtf*idf値の組み合わせについての結果を表\ref{table:diagram_pst_tfidf}に示す．
CSJデータにおいて文の位置が先頭から20\,\%以内のところに重要文の割合が大きい区分が若干増えたこと以外は，
文長との組み合わせとほぼ同様の結果になっている．
これらの結果から，文の位置と組み合わせて文長またはtf*idf値を用いた際には，
ともにそのスコアが低い文を除くことで文の位置による重要文抽出の精度をより向上させていることが分かる．

最後に，文の位置と見出しの組み合わせについての結果を表\ref{table:diagram_pst_hlnoun}に示す．
見出しを用いた評価尺度の場合，ほぼ半数の文が見出しと共通する語を持たないため，スコアが0になる．
このため，対応する文が存在しない区分が中間に現われている．
見出しを用いた評価尺度においては，そのスコアが0であるような文においても重要文の数が多く，文長またはtf*idf値のような効果は得られていない．
しかし，DUCデータにおいて文の位置が先頭から20\,\%以内で見出しによる順位が70\,\%以降の場合(文の位置 \(\le\) 0.2，見出し \(\ge\) 0.7)，重要文の割合は大きくなっている．
また，CSJデータにおいては，文の位置が末尾から10\,\%以内(文の位置 = 1.0)の場合に加えて，文の位置 = 0.1，見出し = 1.0の区分においても重要文の数，割合が大きくなっている．
従って，文の位置と組み合わせて見出しの情報を用いた場合には，文長やtf*idf値とは逆に，そのスコアが高い文を優先することで文の位置単独の場合よりも重要文抽出の精度が向上するといえる．

これらの実験結果をまとめると「重要文抽出に用いた素性を組み合わせたときに，その値の増減に応じて連続的に重要文の数・割合が増えるのではなく，組み合わせによってできる一定の境界があって，その内外で重要文の数・割合が大きく異なることがある」ということになる．
つまり，重要文抽出を行う際には，式\ref{eq:weight}のように素性を用いた評価尺度を線型に組み合わせる方法ではなく，ここで発見された特徴を生かすような非線型の評価尺度を導入することで，同じ素性を用いても精度向上の可能性があるということである．
また，DUCデータとCSJデータの双方において素性の組み合わせによる非線型な重要文の数・割合の変化がみられたことは，英語新聞記事と日本語講演録という異なる種類のデータにおいても，非線型な素性の組み合わせが重要文抽出に有効であることを示唆しているといえる．
日本語新聞記事においても，\cite{hirao:phdthesis}はSVMを用いた重要文抽出を行う際に連続値を持つ素性を一定の値域に区切って二値素性に変換して用いているが，
その分析において報告されている有効な二値素性の組み合わせからも，同様に非線型な素性の組み合わせが有効であることが推測される．


\section{おわりに}

本論文では，重要文抽出に基いた要約システムの評価結果を日本語新聞記事，英語新聞記事，日本語話し言葉コーパスの3種類のデータそれぞれについて示した．
本システムは，日本語新聞記事の要約評価ワークショップTSC(2001)，英語新聞記事の要約評価ワークショップDUC(2001)の各々において，単一文書の要約課題において良好な成績をおさめた．
また要約率が10\,\%程度と小さいときには，文境界が正しく検出できれば，講演録などの話し言葉に対する重要文抽出は新聞記事に対する重要文抽出に匹敵しうることを示した．

要約データの分析においては，トレーニングデータにおいて各素性に基づく評価尺度の値と重要文の分布を示し，各素性の重要文抽出における有効性を3種類のデータ間で比較した．
また，素性間の順位相関係数を求め，用いたどのデータにおいても，文の位置とその他の素性との相関に比べて文の位置以外の素性間の相関が高く，重要文抽出に用いられるこれらの代表的な素性が必ずしも相互に独立ではないことを示した．
さらに，比較的独立性の高い文の位置とそれ以外の素性との組み合わせについて重要文の分布を調べ，文の位置と組み合わせて文長またはtf*idf値を用いた際には，ともにそのスコアが低い文を除くことで文の位置による重要文抽出の精度が向上し，文の位置と組み合わせて見出しの情報を用いた場合には，逆にそのスコアが高い文を優先することで文の位置単独の場合よりも重要文抽出の精度が向上していることを示した．

今後の課題としては，今回の実験で用いた素性と独立性の高い新たな素性を導入し，それによって重要文抽出の精度を上げることを考えている．
本論文では，異なる言語・種類のコーパス間での比較を主眼としたため素性については重要文抽出において代表的な素性のみを対象としたが，例えば構文情報や，\cite{hirao:phdthesis}が用いたような機能語・モダリティを示す表現など，新たな素性についてもその独立性や組み合わせによる有効性を調べ，重要文抽出に有用で特定のコーパスに依存しないような素性を見出していきたい．

\begin{acknowledgment}
本研究を進めるにあたっては，通信総合研究所の自然言語グループのメンバーとの討論が参考になりました．
特に内元清貴氏には有益な助言をいただき感謝します．
\end{acknowledgment}

\bibliographystyle{jnlpbbl}

\begin{thebibliography}{}

\bibitem[\protect\BCAY{Aone, Okurowski \BBA\ Gorlinsky}{Aone
  et~al.}{1998}]{aone:colingacl1998}
Aone, C., Okurowski, M.~E., \BBA\ Gorlinsky, J. \BBOP 1998\BBCP.
\newblock \BBOQ {Trainable, Scalable Summarization Using Robust NLP and Machine
  Learning}\BBCQ\
\newblock In {\Bem Proc. of the 17th International Conference on Computational
  Linguistics and 36th Annual Meeting of the Association for Computational
  Linguistics}, pp.~62--66.

\bibitem[\protect\BCAY{DUC}{DUC}{2001}]{DUC:2001}
DUC \BBOP 2001\BBCP.
\newblock \BBOQ Document Understanding Conference \BBCQ
\newblock \slashbr{http://duc.nist.gov/}.

\bibitem[\protect\BCAY{Edmundson}{Edmundson}{1969}]{edmundson:acm1969}
Edmundson, H. \BBOP 1969\BBCP.
\newblock \BBOQ New methods in automatic abstracting\BBCQ\
\newblock {\Bem Journal of ACM}, {\Bbf 16}  (2), pp.~264--285.

\bibitem[\protect\BCAY{古井，前川，井佐原}{古井\Jetal
  }{2000}]{furui:asj2000}
古井貞煕，前川喜久雄，井佐原均 \BBOP 2000\BBCP.
\newblock \JBOQ
  科学技術振興調整費開放的融合研究推進制度—大規模コーパスに基づく「話し言葉工
学」の構築—\JBCQ\
\newblock \Jem{日本音響学会誌}, {\Bbf 56}  (11), pp.~752--755.

\bibitem[\protect\BCAY{Hirao}{Hirao}{2002}]{hirao:phdthesis}
Hirao, T. \BBOP 2002\BBCP.
\newblock {\Bem {A Study on Generic and User-Focused Automatic Summarization}}.
\newblock Ph.D.\ thesis, Nara Institute of Science and Technology.

\bibitem[\protect\BCAY{IREX}{IREX}{1999}]{IREX}
IREX \BBOP 1999\BBCP.
\newblock \BBOQ Information Retrieval and Extraction Exercise\BBCQ \\
\newblock \slashbr{ http://cs.nyu.edu/cs/projects/proteus/irex}.

\bibitem[\protect\BCAY{Kupiec, Pedersen \BBA\ Chen}{Kupiec
  et~al.}{1995}]{kupiec:sigir1995-s}
Kupiec, J., Pedersen, J., \BBA\ Chen, F. \BBOP 1995\BBCP.
\newblock \BBOQ {A Trainable Document Summarizaer}\BBCQ\
\newblock In {\Bem Proc. of SIGIR'95}, pp.~68--73.

\bibitem[\protect\BCAY{黒橋，長尾}{黒橋，長尾}{1999}]{juman361}
黒橋禎夫，長尾真 \BBOP 1999\BBCP.
\newblock \Jem{日本語形態素解析システム{JUMAN} version 3.61}.
\newblock 京都大学.

\bibitem[\protect\BCAY{Lin}{Lin}{1999}]{lin:cikm1999}
Lin, C.-Y. \BBOP 1999\BBCP.
\newblock \BBOQ Training a Selection Function for Extraction\BBCQ\
\newblock In {\Bem Proc. of the CIKM'99}.

\bibitem[\protect\BCAY{Mani \BBA\ Maybury}{Mani \BBA\ Maybury}{1999}]{mani:aats}
Mani, I. \BBA\ Maybury, M. \BBOP 1999\BBCP.
\newblock {\Bem {Advances in Automatic Text Summarization}}.
\newblock The MIT Press, Cambridge, MA.

\bibitem[\protect\BCAY{Nobata, Sekine, Murata, Uchimoto, Utiyama
  \BBA\ Isahara}{Nobata et~al.}{2001}]{nobata:tsc2001}
Nobata, C., Sekine, S., Murata, M., Uchimoto, K., Utiyama, M., \BBA\ Isahara, H. \BBOP 2001\BBCP.
\newblock \BBOQ Sentence Extraction System Assembling Multiple Evidence\BBCQ\
\newblock In {\Bem Proceedings of the Second NTCIR Workshop}, pp.~319--324.

\bibitem[\protect\BCAY{野畑，関根，内元，井佐原}{野畑\Jetal
  }{2002}]{nobata:orc2002}
野畑周，関根聡，内元清貴，井佐原均 \BBOP 2002\BBCP.
\newblock \JBOQ 話し言葉コーパスにおける文の切り分けと重要文抽出\JBCQ\
\newblock \Jem{第2回 話し言葉の科学と工学ワークショップ}, pp.~93--100.

\bibitem[\protect\BCAY{野本，松本}{野本，松本}{1997}]{nomoto:ipsj1997}
野本忠司，松本祐治 \BBOP 1997\BBCP.
\newblock \JBOQ 人間の重要文判定に基づいた自動要約の試み\JBCQ\
\newblock In {\Bem IPSJ-NL 120-11}, pp.~71--76.


\bibitem[\protect\BCAY{奥村，難波}{奥村，難波}{1999}]{okumura:nlp1999-07}
奥村学，難波英嗣 \BBOP 1999\BBCP.
\newblock \JBOQ テキスト自動要約に関する研究動向(巻頭言に代えて)\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 6}  (6), pp.~1--26.

\bibitem[\protect\BCAY{Robertson \BBA\ Walker}{Robertson \BBA\
  Walker}{1994}]{2poisson}
Robertson, S.~E. \BBA\ Walker, S. \BBOP 1994\BBCP.
\newblock \BBOQ Some Simple Effective Approximations to the 2-Poisson Model for
  Probabilistic Weighted Retreival\BBCQ\
\newblock In {\Bem Proc. of the Seventeenth Annual International ACM SIGIR
  Conference on Research and Development in Information Retrieval}.

\bibitem[\protect\BCAY{Sekine \BBA\ Nobata}{Sekine \BBA\
  Nobata}{2001}]{sekine:duc2001}
Sekine, S. \BBA\ Nobata, C. \BBOP 2001\BBCP.
\newblock \BBOQ {Sentence Extraction with Information Extraction
  Technique}\BBCQ\
\newblock In {\Bem Online Proceedings of the Document Understanding Conference:
  http://www.itl.nist.gov/iaui/894.02/projects/duc/duc2001/agenda\_duc2001.htm
l}\ New Orleans, LA.

\bibitem[\protect\BCAY{Sekine, Sudo \BBA\ Nobata}{Sekine
  et~al.}{2002}]{sekine:lrec2002}
Sekine, S., Sudo, K., \BBA\ Nobata, C. \BBOP 2002\BBCP.
\newblock \BBOQ {Extended Named Entity Hierarchy}\BBCQ\
\newblock In {\Bem Proceedings of the LREC-2002 Conference}, pp.~1818--1824.

\bibitem[\protect\BCAY{Sudo, Sekine \BBA\ Grishman}{Sudo
  et~al.}{2001}]{sudo:hlt2001}
Sudo, K., Sekine, S., \BBA\ Grishman, R. \BBOP 2001\BBCP.
\newblock \BBOQ Automatic Pattern Acquisition for Japanese Information
  Extraction\BBCQ\
\newblock In {\Bem Proc. of Human Language Technology Conference}\ San Diego,
  California, USA.

\bibitem[\protect\BCAY{TSC}{TSC}{2001}]{TSC1}
TSC \BBOP 2001\BBCP.
\newblock \BBOQ {Proceedings of the Second NTCIR Workshop on Research in
  Chinese \& Japanese Text Retrieval and Text Summarization (NTCIR2)}\BBCQ.
\newblock National Institute of Informatics.

\bibitem[\protect\BCAY{Uchimoto, Ma, Murata, Ozaku \BBA\
  Isahara}{Uchimoto et~al.}{2000}]{uchimoto:acl2000}
Uchimoto, K., Ma, Q., Murata, M., Ozaku, H., \BBA\ Isahara, H.
  \BBOP 2000\BBCP.
\newblock \BBOQ {Named Entity Extraction Based on A Maximum Entropy Model and
  Transformation Rules}\BBCQ\
\newblock In {\Bem Proc. of the 38th Annual Meeting of Association for
  Computational Linguistics (ACL2000)}, pp.~326--335.

\bibitem[\protect\BCAY{Watanabe}{Watanabe}{1996}]{watanabe:coling1996}
Watanabe, H. \BBOP 1996\BBCP.
\newblock \BBOQ {A Method for Abstracting Newspaper Articles by Using Surface
  Clues}\BBCQ\
\newblock In {\Bem Proc. of the 16th International Conference on Computational
  Linguistics}, pp.~974--979.


\end{thebibliography}
\begin{biography}
\biotitle{略歴}
\bioauthor{野畑 周}{
1995年東京大学理学部情報科学科卒業．
2000年東京大学大学院理学系研究科博士課程修了．博士（理学）．
同年郵政省通信総合研究所非常勤研究職員．
現在，独立行政法人通信総合研究所けいはんな情報通信融合研究センター自然言語グループ専攻研究員．
言語処理学会，情報処理学会，ACL各会員．}
\bioauthor{関根 聡}{
Assistant Research Professor, New York University．
1987年東京工業大学応用物理学科卒業．同年松下電器東京研究所に入社．
1990年〜1992年UMIST客員研究員．1992年UMIST計算言語学科修士．
1994年からNYU, Computer Science Department, Assitant Research Scientist．
1998年Ph.D.．同年から現職．自然言語処理の研究に従事．
コーパスベース，パーザー，分野依存性，情報抽出，情報検索等に興味を持つ．
言語処理学会，人工知能学会，ACL各会員．}
\bioauthor{井佐原 均}{
1978年京都大学工学部電気工学第二学科卒業．
1980年同大学院修士課程修了．博士（工学）．
1980年通商産業省電子技術総合研究所入所．
1995年郵政省通信総合研究所．
現在，独立行政法人通信総合研究所けいはんな情報通信融合研究センター自然言語グループリーダー．
言語処理学会，情報処理学会，人工知能学会，日本認知科学会，各会員．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}
\end{biography}

\end{document}
