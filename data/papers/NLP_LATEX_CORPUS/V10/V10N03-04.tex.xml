<?xml version="1.0" ?>
<root>
  <title>EMアルゴリズムを用いた教師なし学習の日本語翻訳タスクへの適用</title>
  <author>新納浩幸</author>
  <jabstract>本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法を，SENSEVAL2の日本語翻訳タスクで出題された名詞の語義の曖昧性解消問題に適用する．この手法は，ラベルなしデータをラベルを欠損値とする観測データ，その観測データを発生させるモデルをNaiveBayesモデル，このモデルの未知パラメータをラベル(c)のもとで素性(f)が起る条件付き確率(p(f|c))に設定して，EMアルゴリズムを用いる．結果として，モデルの識別精度が向上する．ここでは識別のための素性として，対象単語の前後数単語の原型や表記という簡易なものに設定した．実験では，ラベル付き訓練データのみから学習したNaiveBayesの正解率が58.2,%，同データから学習した決定リストの正解率が58.9,%（Ibarakiの公式成績）であったのに対し，ラベル付き訓練データの他にラベルなし訓練データを用いた本手法では，61.8,%の正解率を得た．また訓練データの一部の不具合を修正することで，NaiveBayesの正解率を62.3,%に改善できた．更に本手法によりそれを68.2,%に向上させることができた．</jabstract>
  <jkeywords>EMアルゴリズム，教師なし学習，多義語の曖昧性解消，翻訳タスク，SENSEVAL2</jkeywords>
  <section title="はじめに">本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法を，SENSEVAL2の日本語翻訳タスクで出題された名詞の語義の曖昧性解消問題に適用する．その結果，通常の教師付き学習で得られる分類規則の精度を向上させ得ることを示す．自然言語処理では個々の問題を分類問題として定式化し，帰納学習の手法を利用して，その問題を解決するというアプローチが大きな成功をおさめている．しかしこのアプローチには帰納学習で必要とされる訓練データを用意しなければならないという大きな問題がある．この問題に対して，近年，少量のラベル付き訓練データから得られる分類器の精度を，大量のラベルなし訓練データによって高めてゆく教師なし学習が散見される．代表的な手法として，Co-trainingと，EMアルゴリズムを利用した手法がある．Co-trainingは2つの独立した属性AとBを設定し，一方の属性Aから構築される分類器を利用して，ラベルなしデータにラベル（クラス）を付与する．その中から信頼性のあるラベルが付与されたデータをラベル付き訓練データに加える．このようにして追加されたラベル付き訓練データは，もう一方の属性Bから見るとランダムなサンプルにラベル付けされたデータとして振る舞うので，属性Bから構築される分類器の精度が高まる．これをお互いに作用し合うことで，分類器の精度が高められる．一方，EMアルゴリズムは，部分的に欠損値のある不完全な観測データ(x_1,x_2,,x_N)から，そのデータを発生する確率モデル(P_(x))を推定する手法である．(P_(x))は未知パラメータ()を含み，(P_(x))の推定は，()の推定に帰着される．分類問題の教師なし学習では，ラベル付き訓練データが完全な観測データ，ラベルなし訓練データがラベルを欠損値とした不完全な観測データとなる．EMアルゴリズムは，現時点での()を使って，モデル(P_(c|x_i))のもとでの(P_(x_i,c))の期待値を取る（E-step）．次に，この期待値を最大にするような()を求める（M-Step）．()を新たな()として先のE-stepとM-stepを繰り返す．ここで(c)は欠損値となるラベルである．EMアルゴリズムはパラメータ()とモデル(P_(x))を適切に設定することで，隠れマルコフモデルや文脈自由文法のパラメータ推定，あるいは名詞と動詞間の関係クラスの教師なし学習などに利用できる．そして，Nigamらは文書分類を題材にモデル(P_(x))をNaiveBayesのモデル，()をラベル(c)のもとで素性(f)が起る条件付き確率(p(f|c))に設定することで，教師なし学習を試みている．NigamらのEMアルゴリズムを利用した手法やCo-trainingは，どちらも本来は文書分類に対して考案されており，多義語の曖昧性解消に利用できるかどうかは明らかではない．多義語の曖昧性解消は自然言語処理の中心的な課題であり，これらの手法が適用できることが望ましい．ここではSENSEVAL2の日本語翻訳タスクで出題された名詞を題材に，EMアルゴリズムを利用した教師なし学習の手法が名詞の語義の曖昧性解消に適用可能であることを示す．翻訳タスクの出題形式はある単語(w)がマークされた（日本語）文書である．翻訳タスクでは予め，単語(w)に関するTranslationMemory（以下TMと略す）と呼ばれる日英の対訳例文の集合が解答者に配られている．そして翻訳タスクの解答形式は，出題された文書内において注目する単語(w)を英訳する際に利用できるTMの例文番号である．つまり，翻訳タスクは単語(w)の訳を語義と考えた多義語の曖昧性解消問題となっている．また同時に，翻訳タスクはTMの例文番号をクラスと考えた場合の分類問題として扱える．ここで注意すべきは，翻訳タスクは訓練データを作るのが困難な点である．TMは1つの単語に対して平均して21.6例文がある．今仮にある単語(w)の例文として(id_1)から(id_20)までの20例文がTMに記載されていたとする．新たに訓練データを作成する場合，単語(w)を含む新たな文を持ってきて，(id_1)から(id_20)のどれか1つのラベルを与える必要がある．〇か×かの二者択一は比較的容易であるが，20個のラベルの中から最も適切な1つを選ぶのは非常に負荷のかかる作業である．このように，翻訳タスクは訓練データを新たに作るのが困難であるために，教師なし学習を適用する格好のタスクになっている．実験ではSENSEVAL2の日本語翻訳タスクで出題された全名詞20単語を用いて，本手法の評価を行う．各単語に対して，平均70事例（TMの例文も含む）からなるラベル付き訓練データと，新聞記事1年分から取り出した平均3,354事例からなるラベルなし訓練データを作成し，本手法を適用した．ラベル付き訓練データだけから学習できた決定リストの正解率は58.9,%(コンテストでのIbarakiの成績)であり，NaiveBayesによる分類器の正解率は58.2,%であった．そして本手法を用いてNaiveBayesによる分類器の精度を高めた結果61.8,%まで改善された．また一部，訓練データの不具合を修正することで，NaiveBayesによる分類器の正解率を62.3,%，決定リストでの正解率を63.2,%に向上できた．更に，本手法を用いてNaiveBayesによる分類器の正解率（62.3,%）を68.2,%まで高めることができた．</section>
  <section title="Naive Bayes による多義語の曖昧性解消">まず，用語の混乱を避けるため，本論文で用いる「属性」と「素性」の区別をしておく．本論文では，例えば，「対象単語の直前の単語」といった識別のための観点を「属性」と呼び，属性に具体的な値が与えられたものを「素性」と呼んでいる．例えば「対象単語の直前の単語」といった属性を|e1|などで表し，対象単語の直前の単語が，例えば，「日本」であった場合に，|'e1=日本'|と表されたものを素性と呼ぶ．ある事例(x)が素性のベクトルとして，以下のように表現されたとする．[x=(f_1,f_2,,f_n)](x)の分類先のクラスの集合を(C=c_1,c_2,,c_m)と置く．分類問題は(P(c|x))の分布を推定することで解決できる．実際に，(x)のクラス(c_x)は以下の式で求まる．[c_x=arg_cCP(c|x)]ベイズの定理を用いると，[P(c|x)=P(c)P(x|c)P(x)]なので，結局，以下が成立する．[c_x=arg_cCP(c)P(x|c)]ここで，(P(c))は比較的簡単に推定できる．問題は，(P(x|c))の推定だが，これは現実的には難しい．NaiveBayesのモデルは，この推定に以下の仮定を導入する．(P(f_i|c))の推定は比較的容易であるために，結果として(P(x|c))が推定できる．NaiveBayesを使った分類がうまくゆくかどうかは，の仮定をできるだけ満たすような素性を選択することである．文書分類であれば，各素性を各単語の生起に設定することで，NaiveBayesが有効であることが知られている．多義語の曖昧性解消でもの仮定をできるだけ満たすような素性を選択すればNaiveBayesが利用できる．本論文では以下の4つの属性を利用することにした．e1:直前の単語，e2:直後の単語，e3:前方の内容語（2つまで）e4:後方の内容語（2つまで）verbatim例えば，「胸」の語義は『体の一部としての胸』という語義と『心の中』という語義がある．そして，「その無力感は今も原告たちの胸に染み付いている」という文中の「胸」の語義は『心の中』なので，この事例のクラスは『心の中』となる．また，この文は以下のように形態素解析される．各行が分割された単語であり，第1列が表記，第2列が原型，第3列が品詞を表す．そのその連体詞無力無力名詞-形容動詞語幹感感名詞-接尾-一般はは助詞-係助詞今今名詞-副詞可能もも助詞-係助詞原告原告名詞-一般たちたち名詞-接尾-一般のの助詞-連体化胸胸名詞-一般にに助詞-格助詞-一般染み付い染み付く動詞-自立てて助詞-接続助詞いるいる動詞-非自立verbatimこの結果から以下の4つの素性が抽出できる．e1=の，e2=に，e3=原告,たち，e4=染み付く，いるverbatim属性|e3|と|e4|の値は集合になるが，学習の際に以下のように分割して，素性として表す．e3=原告,e3=たち,e4=染み付く,e4=いるverbatim</section>
  <section title="EM アルゴリズムによる教師なし学習">分類問題の解決にNaiveBayesが使えれば，Nigamらが提案した教師なし学習が利用できる．そこではEMアルゴリズムを用いることで，ラベルなし訓練データを用いて，ラベル付き訓練データから学習された分類器の精度を向上させる．ここではポイントとなる式とアルゴリズムだけを示す．基本となるのは，あるクラス(c_j)のもとで，素性(f_i)が発生する確率(P(f_i|c_j))を求めることである．これは以下の式で求まる．この式は頻度0の部分を考慮したスムージングを行っている．式の(D)はラベル付けされた訓練データとラベル付けされていない訓練データを合わせた訓練データ全体を示す．(D)の各要素を(d_k)で表す．(F)は素性全体の集合である．(F)の各要素を(f_m)で表す．また，(N(f_i,d_k))は，訓練事例(d_k)に含まれる素性(f_i)の個数を表す．ここでの設定では，(N(f_i,d_k))は0か1の値であり，ほとんどの場合0である．(P(c_j|d_k))は訓練データがクラス(c_j)を持つ確率である．ラベル付けされた訓練データに対しては，0か1の値をとる．ラベル付けされていない訓練データに対しては，最初は0であるが，EMアルゴリズムの繰り返しによって，徐々に適切な値に更新されてゆく．式を利用して，以下の分類器が作成できる．ここで，(C)はクラスの集合である．(K_d_i)は訓練事例(d_i)に含まれる素性の集合を示す．(P(c_j))はクラス(c_j)の発生確率であり，以下の式で計算する．[P(c_j)=1+_k=1^|D|P(c_j|d_k)|C|+|D|]EMアルゴリズムはを利用して，ラベル付けされていない事例(d_i)に対して，(P(c_j|d_i))を求める(E-step)．次にを利用して，(P(f_i|c_j))を求める(M-step)．このE-stepとM-stepを交互に繰り返して，(P(f_i|c_j))と(P(c_j|d_i))を収束するまで更新してゆく．最終的には収束した(P(f_i|c_j))を使って，から分類が行える．</section>
  <section title="実験">SENSEVAL2の日本語翻訳タスクで課題として出題された全名詞20単語に対して本手法を適用する．翻訳タスクのコンテストでは，手作業で訓練データを作成し，それを用いて学習するというオーソドックスな戦略を用いたシステムはIbarakiだけであった．ここではそこで用意された訓練データを借用し，Ibarakiの結果と比較することで本手法を評価する．Ibarakiでは，TMの他に毎日新聞'95年度版から該当単語を含む文を適当な数だけ取りだし，ラベルを付けることで訓練データを増やしている．名詞に対しては各単語に対して約50事例を追加している．結果として，各単語に対して平均70事例がラベル付き訓練データとして用意された．そのラベル付き訓練データから決定リストを作成し，課題の曖昧性解消問題を解いている．名詞20単語に対するIbarakiの翻訳タスクに対する公式成績をに示す．Ibarakiで利用した訓練データを借用し，それを本手法のラベル付き訓練データとした．次に，毎日新聞'96年度版から該当単語を含む文を取りだし，それをラベルなし訓練データとした．に，名詞20単語の各単語に対するラベル付き訓練データLの数，ラベルなし訓練データUの数，ラベル付き訓練データから学習できた決定リスト（DLと略す）による正解率（Ibarakiの結果），ラベル付き訓練データのみから学習できたNaiveBayes（NBと略す）による正解率，NBをEMアルゴリズムにより改善させた分類器（NB＋EMと略す）の正解率を示す．から分るようにラベル付き訓練データLのみから学習できたDLもNBもほぼ同等の正解率（58.9,%と58.2,%）である．一方，NB+EMの正解率は61.8,%であり，本手法の効果が確認できる．特に教師なし学習が効果的に行えたkokunaiとkirokuの2単語について，その学習のグラフをとに示す．このグラフの横軸はEMアルゴリズムの繰り返しの回数，縦軸はテスト文に対する正解率を示す．ラベルなし訓練データを用いることで全体の正解率は向上したが，個々の単語をみると，本手法を利用することで精度が大きく下がる単語が存在する．具体的にはに示す2単語である．調査したところ，これは最初に用意しているラベル付き訓練データ中の誤りが原因であった．Ibarakiで用意されたラベル付き訓練データは，一部の単語で必要以上に語義を細かく分けている．上記の2単語はその例であり，特にimaではUNASSIGNABLEのラベル（適切な例文がないことを意味するラベル）を付けている事例が67事例中20事例も存在する．実際はUNASSIGNABLEのラベルを与えた事例にはdefaultの語義（この場合，『重要性』の意味で使われている例文番号）を与えるべきであった．muneでも慣用的な表現が多く細かく語義を分けすぎている．正解を見れば，『体の一部としての胸』と『心の中』の2つに分類できればよいだけである．これらを考慮して，この2単語に関しては，ラベル付き訓練データを修正した．具体的には，imaに対してはUNASSIGNABLEをdefaultの語義に変更し，muneでは語義を2値に変更した．修正して得られた訓練データに対して，本手法をもう一度試した．またこれらの2単語に対しては，修正したラベル付き訓練データを利用したIbarakiによる決定リストDLの正解率も調べた．修正して得られた結果をに示す．結果的にラベル付き訓練データLのみから学習できたNBの正解率62.3,%を本手法により68.2,%まで高めることができた．</section>
  <section title="考察">ここでは本手法を名詞のみに適用した．同じ処理によって，動詞に対しても適用することができるが，ここではその実験を行わなかった．教師なし学習を利用するには，本質的に，識別のための冗長性のある情報が必要である．名詞の場合，その名詞を修飾する語句（左文脈）は，その名詞の語義を特定できる可能性が高いし，その名詞を格にもつ動詞（右文脈）もその名詞の語義を特定できる可能性が高いので，一方の文脈から名詞の語義が識別できれば，もう一方の文脈は識別のための冗長性のある情報となる．このため，設定した属性は教師なし学習に適していると考えられる．一方，動詞の語義を識別するのは，格要素になる名詞，つまり左文脈が重要であり，右文脈は語義の識別の助けになることは少ない．連体修飾の用法にしても，左右が逆になるだけである．つまり，どちらかの文脈を利用して語義を識別した場合に，もう一方の文脈は識別に寄与する情報にならない．このため，動詞に対しては，本手法を利用する効果は低いと考えた．ただし「効果がない」ということでもないことを注意しておく．本手法はラベル付き訓練データのみから得られた分類器の精度を必ずしも向上するとは言えず，逆に精度を落す危険性もある．そのために，本手法を利用する効果があまり期待できない場合には，危険性を犯してまで本手法を試みる必要はないと判断した．動詞に対して実際にどの程度の精度向上，あるいは精度低下があるのか，あるいは動詞に対してはどのような属性を設定するのが良いのかを調べることは今後の課題である．先ほども述べたが，本手法により必ずしも精度が向上するとは限らない．実際に，実験ではの5単語に関して，わずかではあるが精度が低下している．精度低下の原因を一般的に論じるのは難しい．この実験の場合，偶然的な要素が強かった．NBによる分類器では正解したが，NB+EMによる分類器では誤るようなテスト文を調査すると，NBによる分類器で正解したのは，たまたまdefaultの規則が適用できて，正解になったというように，偶然的な要素が強い．EMによる学習が進むと，defaultから少しずれてくるために，誤ってしまう．精度低下の原因に関しては，ラベル付き訓練データ，ラベルなし訓練データおよびテストデータの関係を詳しく調査する必要がある．本手法による更なる精度向上をはかるための最も有効な手段は，最初のラベル付き訓練データを見直すことである．今回利用したラベル付き訓練データは，コンテストの正解が提示される以前に作成されたものであり，出題者が想定した語義と微妙に違う部分がある．概して，出題者が想定した語義は荒く，Ibarakiで用意された語義は細かい．語義が細かいと，結果として訓練データが小さいものになり，学習から得られる規則の精度が悪く，無用な部分で識別が誤る．imaやmuneでもラベル付きの訓練データを見直すことで精度が改善された．またラベルなし訓練データの量の問題が指摘されるかも知れない．ラベルなし訓練データは多ければ多いほど精度が向上すると言われている．今回，精度低下のあったippan，shimin,jidaiの3単語に関して，ラベルなし訓練データの量を約4倍に増やして実験を行った．このデータは別年度の毎日新聞記事から取り出した．結果をに示す．精度は悪くなることはなかったが，ほとんど変化は生じなかった．おそらく今回実験で利用した程度のラベルなし訓練データの量でも，このタスクでは十分であったと考えられる．またもう一つの代表的な教師なし学習の手法であるCo-trainingとの比較について述べておく．Co-trainingは独立な2つの属性させ設定できれば，ベースとなる学習手法を問わないために，応用範囲が広い．また完全に独立な2つの属性が設定できた場合，Co-trainingはEMアルゴリズムを利用した手法よりも優れていることが報告されている．しかしCo-trainingには独立な2つの属性という条件の他に，属性の一貫性という条件も必要になる．この条件のために，実際はCo-trainingを多値の分類問題に適用することは難しい．一方，本手法はNaiveBayesの学習を基本とするという制限はあるが，分類問題が多値であっても，原理的に問題はない．そのために，より頑健性の高い現実的な手法と言える．また多義語の曖昧性解消問題に教師なし学習を利用したYarowskyの研究との比較についても述べておく．Yarowskyの教師なし学習も，実はCo-trainingの特殊ケースと見なせる．2つの独立した属性として，1つは前後の文脈，もう1つは「同じ文書内で使われている曖昧な単語の語義は1つに固定される」というヒューリスティクスである．このヒューリスティクスが翻訳タスクで設定している語義の細かさに対して，どれほど成立しているかは未知である．またこの手法では，必要とされるラベルなし訓練データは文書，しかも対象単語が複数含まれているような文書となる．これはいかにラベルなしと言えども収集は容易ではない．このため比較対象の実験も困難である．一方，本手法はその対象単語を含む文が訓練データとなるので，収集は容易であり，より現実的な手法と言える．今後の課題としては2つある．1つは名詞以外の単語への適用である．教師なし学習が機能するような属性をどのように設定するかが課題である．2つ目は教師なし学習による精度低下の原因の調査，およびその回避策の検討である．これによってより頑健な教師なし学習が可能となる．</section>
  <section title="おわりに">本論文では，Nigamらによって提案されたEMアルゴリズムを利用した教師なし学習の手法を，SENSEVAL2の日本語翻訳タスクで出題された名詞に適用した．識別のための属性としては，対象単語の前後数単語の原型や表記という簡易なものを利用した．ラベル付き訓練データだけから学習できた決定リストの正解率は58.9,%(コンテストでのIbarakiの成績)であり，NaiveBayesによる分類器の正解率は58.2,%であった．そして本手法を用いてNaiveBayesによる分類器の正解率を61.8,%まで改善できた．また一部，訓練データの不具合を修正することで，NaiveBayesによる分類器の正解率62.3,%（決定リストでの正解率は63.2,%）を，本手法により68.2,%まで高めることができた．問題点としては名詞のみの適用である点と，精度が低下するケースも存在する点である．これら問題の解決が今後の課題であり，より頑健性の高い教師なし学習手法の構築を目指す．document</section>
</root>
