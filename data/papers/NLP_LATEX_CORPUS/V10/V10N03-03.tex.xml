<?xml version="1.0" ?>
<root>
  <title>文脈素性のベクタ空間モデルを用いた日英翻訳選択---SENSEVAL</title>
  <author>熊野正柏岡秀紀田中英輝</author>
  <jabstract>Senseval</jabstract>
  <jkeywords>翻訳選択，多義解消，ベクタ空間モデル，Senseval</jkeywords>
  <section title="	 ENSEVAL-2 日本語翻訳タスクの特徴とシステム設計方針">Senseval-2日本語翻訳タスクは，対訳用例に基づく翻訳アプリケーションにおいて，ある対象語を含んだ表現の翻訳として適切な対訳用例を選択する問題を，語義曖昧性解消の問題と見なした課題である．コンテスト参加者は，あらかじめ配布される対訳用例集「翻訳メモリ」に基づいて翻訳を選択するシステムを構築する．そして，後に評価データが配布されると，システムを用いてデータ中の指定された対象語の翻訳を翻訳メモリ中の用例から選択する．本章では，配布された翻訳メモリと評価データの概要を説明し，タスクの特徴とそれに適したシステムの設計について考察する．</section>
  <section title="はじめに">単語の意味を判別し，多義曖昧性を解消する技術（語義曖昧性解消;WordSenseDisambiguation）は，機械翻訳や情報検索，意味・構文解析など，自然言語処理のあらゆる分野において必要である．これは一般に，テキストに現れた単語の語義が辞書などであらかじめ与えられた複数の語義のいずれに該当するかを判定する分類問題である．ただし，曖昧性解消をどのような応用に利用するかに依存して，どのような語義分類を与えるのが適切であるかは異なる．そして，分類の粒度や語義定義の与え方に応じて，最適な分類手法は異なってくることが予想される．それゆえ，具体的な応用に沿った語義曖昧性解消課題を設定して解決手法を研究することは有用である．2001年に開催された語義曖昧性解消国際コンテストSenseval-2では，このような考え方に基づき，日本語翻訳タスクが実施された．本タスクは，日本語単語（対象語）320語に対して，1語あたり約20の日英対訳用例を収集した翻訳メモリを語義分類の定義と見なし，新たな日本語表現に含まれる対象語の語義を翻訳メモリ中の適切な用例を選択することで分類する課題である．各対象語の語義分類は，翻訳メモリとして収集された日英の表現対であるが，語義を決定している重要な要因が日本語表現に現れる周辺文脈であるとみなすことにより単言語の語義曖昧性解消課題と捉えることができる．この種の問題は，一般に，正解タグを付与した訓練データを用い，各分類に属する表現例の対象語周辺文脈の性質を機械学習によって獲得することで解決できる．正解タグを付与した訓練データの作成のために，さまざまな全自動/半自動の訓練データ構築手法が提案されてきた．しかし，本タスクには，以下のような問題点がある．翻訳メモリ中には，各語義分類ごとに1つしか正解例が与えられない．また，正解タグを付与した訓練データも（タスクの配布物としては）与えられない．翻訳メモリ中の表現は，（人間の感覚で）最低限語義を分別できる程度の，たかだか数語の文脈しか持たない．語義分類間の違いがしばしば非常に微妙である．本タスクでは，上記の問題点のため，正解例を機械的に拡張するための手がかりは乏しく，これを精度よく行うことは難しい．このため，我々は，入力表現を直接的に翻訳メモリの各日本語表現と比較して表現間の類似度を計算し，用例を選択する手法を採用した．我々は，情報抽出や文書分類の分野でよく用いられるベクタ空間モデル（VectorSpaceModel）による文書間比較の手法に着目し，Sch&quot;utzeによる，目的語の近傍に出現する単語の情報をベクタ（共起ベクタ）に表現して共起ベクタ間の余弦値を類似度の尺度とする手法を用いた．ベクタ空間モデルでは，通常，ベクタの各次元に文書中の単語の出現（真偽値）や出現頻度を配置する．しかし本タスクへの適用を考えた場合，翻訳メモリの日本語表現中に対象語と共に出現する単語は非常に少ないため，単純に表層的な単語出現情報を用いるだけでは表現の特徴（表現間の差異）をつかみきれない．またデータスパースネスの影響も深刻である．そこで我々は，単語の代わりに対象語周辺の各種素性（文脈素性）の出現を各次元に配置したベクタ（文脈素性ベクタ）を用いることとした．各文脈素性は，対象語周辺文脈を特徴づける要素を表すもので，表現中に出現する内容語の対象語との構文的/位置的関係（構文解析の結果から獲得）	例:対象語にガ格でかかる，対象語より前にある，	任意の位置，形態的/意味的属性（形態素解析の結果とシソーラスから獲得）	例:標準形=*-.25zw「子供」，	品詞=*-.25zw「名詞」，	シソーラス上の意味コード=*-.25zw「名0pt86」，	を任意に組み合わせたものである．これは，対象語周辺の単語の出現をさまざまな抽象化のレベルで捉えることを意味する．これにより，文脈素性ベクタは，表現間の微妙な違いを表現すると同時に，適応範囲の広い文脈特徴量となることが期待できる．本稿では，まず~章でSenseval-2日本語翻訳タスクの特徴について述べるとともに，本タスクを解決するシステムの設計方針について述べる．次に~章で文脈素性ベクタを用いた翻訳選択の手法を説明する．そして~章でSenseval-2参加システムの諸元と，コンテスト参加結果を紹介する．~章では，~章で各種文脈素性の翻訳選択性能への寄与について調査した結果を報告し，考察を行う．最後に~章でまとめと今後の課題について述べる．</section>
  <subsection title="翻訳メモリ">語義分類の定義として与えられる翻訳メモリは，毎日新聞9年分の記事から収集された用例を元に作成されたもので，各対象語に対して，図~のような形式で与えられる．各語義分類（|&lt;sense&gt;|）を定義する用例は，1対の対象語を含む日本語表現（|&lt;jexpression&gt;|）とその表現全体の対訳である英語表現（|&lt;eexpression&gt;|），それに用例作成時に対訳作成者によって付与された補足情報（|&lt;transmemo&gt;|）などからなっている．配布された翻訳メモリは320対象語に対して合計6,920用例（1対象語平均21.6用例）であった．用例中の日本語表現は，図~の例のように，一般に短く，人間が見て最低限語義を分別できる程度の文脈しか与えられていない（日本語表現の平均単語数は4.5語）．また分類間の日本語表現の違いは微妙なものも多く，図~の用例|14-19|〜|14-21|のように，全く同じ日本語表現が複数の異なる翻訳に分類されていることもある．このように分類間の日本語表現の違いが微妙な場合に，補足情報が分類を行う上で決定的な情報を持っているものもある（図~の用例|14-20|，|14-21|が一例）．</subsection>
  <subsection title="評価データ">評価データは，毎日新聞1994年の記事の中から選ばれたものである．翻訳メモリに存在する対象語から動詞・名詞20語ずつが選ばれ，この対象語を持つ記事が各対象語につき30記事ずつ選ばれた．評価記事は図~のように，記事全体が形態素解析されており，対象語に印（|&lt;head&gt;|）がつけられている．対象語は記事本文中に設定されていることが多いが，記事先頭にある見出しに設定されていることもある．</subsection>
  <subsection title="タスクの特徴とシステム設計方針">語義曖昧性解消問題の解法には，決定木学習や決定リスト学習のような，正解例からの学習に基づく手法がしばしば用いられる．しかし本タスクのように，どの分類に対しても正解例が1例しか与えられていないような問題を解くには適していない．半自動的に正解例を拡張しようという試みも，本タスクの翻訳メモリのように，対象語あたりの語義数が非常に多く，かつそれぞれの違いが微妙で文脈情報も少ない場合には精度よく行うことは難しい．このため，我々は，入力表現を直接的に翻訳メモリの各日本語表現と比較して表現間の類似度を計算し，用例を選択する手法が適切であると考えた．類似度に基づく手法は，類似度をどのように定めるかが重要である．表現間の類似度の尺度には，従来から数多くの提案がされてきた．田中らは，表現中の内容語の一致数と，一致した内容語間の距離（文字数）に基づいて，類似度を定義している．また黒橋らは，表現中の各文節の類似度を字面や品詞，シソーラスの意味コードの一致度などを用いて求め，動的計画法を用いて表現間の類似文節列を発見している．これらは表現間の類似度を直接計算する手法であるが，本タスクで必要な，ある対象語を中心とした類似性を測定する手法とはやや異なる．一方Sch&quot;utzeは，ベクタ空間モデルを用いて単語の語義曖昧性解消を行っている．コーパスから目的語の近傍に出現する単語の情報を単語ベクタとして収集し，それらを語義ごとに足し合わせることで，語義を表す文脈ベクタを作成している．そして，入力表現を表す単語ベクタと各語義の文脈ベクタとの間の余弦値を求めることにより，入力表現がどの語義に一番近いかを求めている．またFujiiは，日本語の動詞の語義曖昧性を解消するためにある語義に属する用例表現集合と入力表現を比較する際，動詞の格スロットに入る名詞の類似度を求めている．この類似度は，シソーラスの意味コードの一致度，またはベクタ空間モデルによって計算する．これらの手法は，ある対象語を中心とした類似性を測定しているが，数多くの正解例の存在を前提にしており，そのままでは本タスクに適用できない．そこで我々は，Sch&quot;utzeの手法の文脈ベクタに相当する文脈素性ベクタを，ただ1つの正解例から構築することを目指した．文脈ベクタは，単語ベクタを足し合わせることで周辺語の意味的な性質を表現していたが，文脈素性ベクタではシソーラスを用い，直接的に周辺語の意味属性を表現する．また，周辺語の出現を，目的語との関係（係り受け関係など）と併せて表現することで，格スロットの類似性の観点を取り入れる．</subsection>
  <section title="文脈素性ベクタを用いた翻訳選択">本章では，対象語周辺の文脈を多角的に表現するための文脈素性の考え方を説明する．そして，これを用いてベクタ空間モデルによって表現間の類似度を計算し，翻訳選択を行う手法について述べる．</section>
  <subsection title="文脈素性">対象語から見て構文的/位置的関係rにある単語（群）が持つ形態的/意味的属性t=v（属性種別がtでその値がv）を指して，文脈素性r:t=vと呼ぶ．一例として，翻訳選択の対象語（対象語）が「間」であるような表現e_1:を考える．図~のように，この表現には，対象語「間」の周辺に内容語「夫婦」「子供」「産まれる」が存在している．これら周辺語は，対象語との間に図中a)に示すような構文的/位置的関係にある．また各単語は，それぞれ図中b)に示すような形態的/意味的属性を持つ．この表現e_1は，対象語の周囲に図~のような文脈素性を持っている．</subsection>
  <subsection title="文脈素性ベクタの作成">文脈素性ベクタは，以下の手順で作成する．翻訳メモリ中の日本語表現と入力表現の各々を行成分に，各文脈素性を列成分に持つ行列（文脈素性共起行列）を作成する（~節）．文脈素性のうちシソーラス上の意味コードを属性に持つものに対応する要素（意味属性要素）を，それぞれ上位概念まで拡張する（~節）．各要素に対して文脈素性種別に応じた重みづけをする（~節）．行列の各行ベクタを文脈素性ベクタと見なす．以下では，図~の表現e_1を例にとり，上記の各手順を説明する．</subsection>
  <subsubsection title="文脈素性共起行列の作成">文脈素性共起行列Aは，翻訳メモリ中の日本語表現と入力表現の各々を行成分に，各日本語表現が持つすべての文脈素性を列成分に持つ行列である．行列の要素a_e,は，表現e中，対象語の周辺に文脈素性r:t=vが出現しているか（真偽値）を表している．例えば，図~の表現e_1に対応する行列の行成分は，表~に示される表現の行のようになる．周辺語の多くは対象語に対して複数の構文的/位置的関係に解釈できるので，ある1つの周辺語中に現れる形態的/意味的属性は，一般に複数の文脈素性要素となって行成分中に出現することに注意されたい．</subsubsection>
  <subsubsection title="意味属性要素の拡張">前節で作成した行列の各行ベクタをそのまま文脈素性ベクタと見なし，ベクタ間の角度の余弦値を計算して表現間の類似度を求めることができる．しかし，それはデータスパースネスの克服という点で十分でない．なぜならこのままでは，シソーラス上の意味コードを属性に持つ文脈素性の出現の一致を，単純な真偽で測ることになってしまうからである．階層構造を持つシソーラス上の2つの意味コードに対しては，単純な意味コードの一致による真偽値ではなく，一致している階層の深さを考慮した一致度を決めることができる．我々が用いる日本語語彙体系のように階層構造を持つシソーラスの場合，その概念から最上位概念までの上位概念を共有している度合を意味コードの一致度と見なすことができる．我々は，形態的/意味的属性として意味コードを持つ文脈素性に対応する行列要素（意味属性要素）の出現の各々について，その上位概念である意味コードの文脈素性も出現していると見なす拡張を行うことにした．具体的には，以下の通りである．これは，意味コードを含む部分的な文脈素性ベクタが以下の性質を保持することを期待している．2つの意味コードが概念階層を共有している度合は，ベクタの意味属性成分どうしの余弦値に一致する．拡張後の全ての意味属性要素a_e,,a_e,,,a_e,からなる部分ベクタの大きさ[(a_e,)^2+(a_e,)^2++(a_e,)^2]を拡張前の意味属性要素a_e,と等しくすることで，概念階層の深さにかかわらず余弦値計算への寄与を一定に保つ．一例として，表~の文脈素性に対応する要素を拡張してみる．概念「名0pt74」と「名0pt86」は，日本語語彙体系上に図~のように位置している．従って，2つの要素は表~のように拡張される．このとき，同じ構造的／位置的関係に複数の意味コードが与えられた文脈素性が存在することがあり，これらの展開の結果，上位の意味コードを含む文脈素性に対してそれぞれ異なった値を配置しようとする要素があるが，その場合は大きい方の値を採用する．</subsubsection>
  <subsubsection title="文脈素性要素の重みづけ">2つの文脈素性ベクタを比較して類似度を測る際に，文脈素性の出現の一致が類似性に寄与する度合は，文脈素性によって異なると考えられる．例えば，表~で表現e_1の文脈素性として出現しているもののうち，の一致はより類似性への寄与が大きいであろうし，さらにの一致はより類似性への寄与が大きいであろう．すなわち，文脈素性種別r:tが類似性への寄与の度合を決定しているのではないかと考えられる．ベクタ空間モデルを用いた文書間比較においては，一般に索引語が文書の内容に寄与する度合（重要度）で索引語の重みづけを行う．我々は，同様の枠組で文脈素性ベクタの各文脈素性要素の出現に重みづけをすることにした．先の考察結果を実現するために，各要素に対して以下のように重みづけを行うことにする．この重みづけの結果，文脈素性ベクタ中，ある文脈素性種別r:tに属する要素からなる部分ベクタの大きさはw()に正規化される．これは直感的には，2つの文脈素性ベクタの類似度を計算するとき，ある文脈素性種別r:tに属する要素成分の類似度が全体の類似度に寄与する度合が次の式のようになる．つまり文脈素性種別ごとの寄与度の比がwの比になることを意味する．Senseval-2日本語翻訳タスクへの参加システムではこの解釈に基づき，文脈素性種別ごとのwを，その種別の意味づけを考慮したうえで直感的に決定した．</subsubsection>
  <subsection title="表現間の類似度の計算">ある対象語を含む日本語入力表現に対して，その語の適切な翻訳を選択するためには，入力表現の文脈素性ベクタを，その対象語に対応する翻訳メモリ中の全ての選択肢中の日本語表現の文脈素性ベクタと比較する．そして，入力表現のベクタとのなす角が最も小さい（余弦値が最も大きい）選択肢を採用する．文脈素性ベクタ間の比較を行うためには，当然両方のベクタは一意に決まっている必要がある．しかし，対象語周辺語は一般に多義であり，シソーラス上の意味コードには複数の候補がある．対象語の曖昧性解消にあたって，全ての周辺語の曖昧性を解消しておく必要があるというのは，手法として適切でない．そこで我々は，文脈素性ベクタ間の比較に先立って周辺語の曖昧性の解消は行わないことにした．代わりに，曖昧性を持つ周辺語の全ての候補の組み合わせについて文脈素性ベクタを計算し，その全てを「文脈素性ベクタ候補」として持つことにする．そして，文脈素性ベクタ間の類似度の計算の際には，お互いの全ての候補の組み合わせについて類似度を求め，値が最も大きな組み合わせを採用する．これによって，周辺語の多義性解消を対象語の翻訳選択と同時に行うことができる．</subsection>
  <subsection title="システムの諸元"/>
  <subsubsection title="文脈を考慮する範囲">翻訳メモリ中の表現が非常に短いのに対し，評価データはそれぞれ新聞記事1記事分と非常に長い．できるだけ長さをそろえるために，評価データの方は対象語を含む1文のみを用いることにした．</subsubsection>
  <subsubsection title="文脈素性・種別ごとの重み">対象語周辺の文脈素性を形成するものとして採用した，構文的/位置的関係と形態的/意味的属性の一覧を表~に示す．[t]-2参加システムが採用した文脈素性要素と，種別ごとの重みtable*また，~節で説明した，文脈素性種別r:tごとに与える重みは，表~のw_r(r)とw_t(t)を用いて[w()=w_r(r)w_t(t)]と与えることにした．これは，表中全てのr:tの組み合わせについて人手で直感的に値を定めるのは困難なためである．</subsubsection>
  <subsubsection title="形態素・構文解析結果の誤りの扱い">形態素・構文解析結果の誤りは，次のように扱った．翻訳メモリ中の各表現の文脈素性ベクタを作成する際には，誤りを人手で修正した．評価セットの各表現の文脈素性ベクタを作成する際には，修正は行わなかった．footnote-2footnote1-2参加システムでは，実験時間の削減の必要もあり，これらを利用しなかった．footnote1</subsubsection>
  <subsubsection title="翻訳メモリ中の補足情報の扱い">配布された翻訳メモリには，日英表現対のいくつかに，作成者が加えた日本語による補足情報，例えば補足的な表現例やコメントなど，が含まれていた（~節参照）．これらは以下のように扱う．対象語が含まれているならば，日英表現対の日本語表現と同等に扱う．すなわち，日英表現対の日本語表現と補足情報の両方に対して文脈素性ベクタを作成し，それらの全てを，~節で述べた文脈素性ベクタ候補と扱う．対象語が含まれないならば，それらに含まれる全ての内容語を，対応する日本語用例で対象語の「任意の周辺文脈」に属しているものと見なし，該当する文脈素性要素に組み入れる．各補足情報の上記とへの分類，およびの場合の対象語へのマーキングは，全て人手で行った．</subsubsection>
  <subsubsection title="シソーラスの検索">「日本語語彙体系」は，一般名詞，固有名詞，用言の3つの体系からなる．そして，収録されている各単語には標準形と読みの情報がある．「日本語語彙体系」から各単語の意味コードを取得するときには，以下の手順に従った．翻訳メモリ中の各表現の文脈素性ベクタを作成するときには，表現の形態素解析結果は人手で修正済である（~節）ので，修正済の形態素解析結果と完全に一致する単語のみを（複数あれば全てを候補に）採用する．すなわち，形態素解析結果の品詞情報を基に体系（一般名詞/固有名詞/用言）を選択し，その中で標準表記と読みが一致するものを選ぶ．一方，評価セットの場合は形態素解析結果の修正は行わないため，読みや品詞分類が誤っている場合がある．そのため，体系の選択を行うときには一般名詞と固有名詞の区別は行わず，標準表記が一致する語を全て選択する．翻訳メモリ中には，例えば「〜（人）に手をあげる」のように，単語が特定されず，その概念を表す語が添えられている用例がある．この語には，その概念語に対する一般名詞を検索し，その意味コードを当てる．数詞には全て意味コード「名0pt2585（数量）」を割り当てる．体系中に存在しない単語には，該当する体系の最上位の意味コードを1つ割り当てる．上記~〜~で一般名詞の意味コードを割り当てた場合，「日本語語彙体系」の「一般名詞と固有名詞の意味属性対応表」に相当する項目があれば，得られる固有名詞の意味コードも併せて候補にする．固有名詞から一般名詞への拡張も同様に行う．</subsubsection>
  <subsection title="参加システムの翻訳選択精度">我々の参加システムが評価データに対して行った翻訳選択実験の，正解データ（goldstandard）に対する精度・再現率は，ともに45.8,%であった（goldstandard作成者間の一致度は86.0,%，baseline（無作為に1つを選択）の精度は36.8,%）．ただ，参加システムにはベクタの正規化などに重大な不具合があった．この点を修正し，参加システムと同じ文脈素性種別の重みを用いて再度実験を行った．その精度・再現率はともに49.3,%（名詞:50.0,%，動詞:48.5,%）であった．</subsection>
  <section title="文脈素性種別と翻訳選択性能との関係">本システムの開発にあたって，各種の文脈素性が表現の類似性を異なる観点から表現し，それぞれ類似性への寄与の度合が異なるという前提があった．従って，システムの翻訳選択性能は，文脈素性種別ごとの重みづけに本質的に依存すると言える．Senseval-2参加システムではこの重みを直感的に定めたが，より適切な重みを正解データから獲得することで性能の向上が期待できる．本章では，最適な重みの正解データからの学習の前段階として，文脈素性が種別ごとに翻訳選択性能にどのように寄与しているかを調査した．</section>
  <subsection title="実験">各文脈素性種別r:tについて，それぞれ重みw()のみを1，残りを全て0にした重み集合を用いて翻訳選択実験を行い，性能を比較した．実験時間の節約のため，対象語との構文的/位置的関係が任意の周辺位置にある対象語より前にある対象語より後にあるである文脈素性要素については，対象語から内容語5~語分より遠くにあるものを対象から外した-2参加システムと同じ文脈素性種別の重みを用いて評価実験を行った結果の精度/再現率は，52.1,%/51.3,%（名詞:54.4,%/53.6,%，動詞:49.7,%/49.0,%）であった．．実験の結果得られた，各文脈素性種別ごとの精度/再現率を図~に示す．また，得られた精度/再現率の総合的な指標として，各々のF-尺度:[F=(+1)PRP+R]を=1として計算したものの上位を表~に示す．</subsection>
  <subsection title="分析">前節の実験結果を分析し，以下の考察を行った．また，前節表~で決めた文脈素性分類ごとの重みを全て与えて翻訳選択実験を行ったときの性能は，F-尺度で0.517であり，表~で最大のF-尺度を持つものより大きい．このことから，提案の枠組による各種文脈情報の統合は効果があったと言える．</subsection>
  <section title="まとめ">本稿では，ベクタ空間モデルを用いた翻訳選択手法を提案し，本手法を用いたシステムでSenseval-2日本語翻訳タスクに参加した結果を報告した．ある対象語を含む対訳用例の中から最適な翻訳を選択する問題を，対象語周辺の詳細な文脈情報を表す文脈素性ベクタの類似した用例を選択することで解決する．本手法を用いたSenseval-2日本語翻訳タスク参加システムは，不具合修正後の精度が49.3,%であった．本手法で利用した各種文脈素性が翻訳選択性能に寄与する度合を調査したところ，シソーラスの意味情報が大きく貢献していることが分かった．また構文的制約の緩い素性の方が全般に頑強であった．今後の課題として，以下の2点を挙げる．表現間の類似度を計算するとき，周辺語の意味がシソーラス上で一般に複数の語義を持つために，語義曖昧性の数だけ「文脈素性ベクタ候補」を作成し，総当たりで類似度を求めている（~節）．このため，周辺語の数が増えるにしたがって計算時間が指数関数的に増大する．何らかの枝刈りを検討したい．正解データに基づく，最適な文脈素性種別ごとの重みの学習方法を検討したい．</section>
</root>
