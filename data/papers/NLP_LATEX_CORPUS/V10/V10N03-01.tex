




\documentstyle[epsf,fancybox,array,jnlpbbl]{jnlp_j_b5}


\def\MARU#1{}
\newcommand{\clA}{}
\newcommand{\clB}{}
\newcommand{\clC}{}
\newcommand{\head}[1]{}
\newcommand{\sensesymbol}[2]{}
\newcommand{\tume}[1]{}
\newlength{\sensedescwidth}
\newenvironment{senseexam}[1]{}{}


\setcounter{page}{3}
\setcounter{巻数}{10}
\setcounter{号数}{3}
\setcounter{年}{2003}
\setcounter{月}{4}
\受付{2002}{4}{30}
\再受付{2002}{7}{28}
\採録{2002}{9}{9}



\title{SENSEVAL-2 日本語辞書タスク}
\author{白井 清昭\affiref{jaist}}

\headauthor{白井}
\headtitle{SENSEVAL-2 日本語辞書タスク}

\affilabel{jaist}{北陸先端科学技術大学院大学情報科学研究科}
{School of Information Science,
Japan Advanced Institute of \\Science and Technology
}

\jabstract{
SENSEVALは語義曖昧性解消を対象としたコンテストである．
本論文では，第2回SENSEVAL (SENSEVAL-2) における
日本語辞書タスクの概要について報告する．
日本語辞書タスクでは，
語の意味の区別(曖昧性)を岩波国語辞典によって定義した．
参加者には，岩波国語辞典，訓練データ，評価データの3つが配布された．
訓練データは，3,000個の新聞記事中の単語に
正しい語義を付与したコーパスである．
一方評価データは，参加者のシステムが語義を選択するべき
単語を含んだ新聞記事である．
評価単語の種類は，名詞50，動詞50，合わせて100個である．
また各評価単語毎に100ずつ語義を選択するとしたため，
評価単語の総数は10,000である．
正解データは，評価対象となる10,000個の単語について，
二名の作業者が独立に正しい語義を付与して作成した．
この際，二者の語義が一致した割合は0.863であり，
Cohenの$\kappa$ は0.657であった．
また，二者の語義が一致しなかった場合には，第三者が正しい語義を選んだ．
日本語辞書タスクには，3団体7システムが参加した．
ベースラインシステムのスコア(正解率)が0.726であるのに対し，
一番成績の良かった参加者のシステムのスコアは0.786であった．
}

\jkeywords{語義曖昧性解消，国語辞典，コーパスの注釈付け}

\etitle{SENSEVAL-2 Japanese Dictionary Task}
\eauthor{Kiyoaki Shirai\affiref{jaist}}

\eabstract{
SENSEVAL is an evaluation exercise for word sense disambiguation
programs.
This paper describes a Japanese dictionary task
in the second SENSEVAL (SENSEVAL-2).
This task defined word senses
according to a Japanese dictionary, Iwanami Kokugo Jiten.
Three data were distributed to the participants:
the Iwanami Kokugo Jiten, the training data and the evaluation data.
The training data was an word sense tagged corpus
made up of 3,000 newspaper articles,
while the evaluation data was newspaper articles
containing words of which participants' systems should determine
correct word senses.
The number of target words was 100, 50 nouns and 50 verbs.
One hundred instances of each target word were provided,
making for a total of 10,000 instances.
For constructing a gold standard data,
two annotators chose correct word senses for 10,000 instances
separately.
The inter-tagger agreement of two annotators was 0.863,
while Cohen's $\kappa$ was 0.657.
When word senses selected by two annotators didn't agree,
the third annotator chose the correct sense between them.
7 systems of 3 organizations participated
in a Japanese dictionary task.
The best score achieved by participants' systems was 0.786,
while the score of the baseline system was 0.726.
}

\ekeywords{Word Sense Disambiguation, Japanese Dictionary, Corpus Annotation}




\begin{document}
\maketitle
\thispagestyle{empty}

\section{はじめに}
\label{sec:intro}

語義曖昧性解消(Word Sense Disambiguation，以下WSD)は
機械翻訳，情報検索など，
自然言語処理の多くの場面で必要となる基礎技術である\cite{ide:98:a}．
SENSEVALはWSDのコンテストであり，
WSDの共通の評価データを作成し，
その上で様々なシステム・手法を比較することによって
WSDの研究・技術を向上させることを目的としている．
SENSEVALは過去2回行われている．
第1回のSENSEVAL~\cite{kilgarriff:00:a}は1998年夏に，
第2回のSENSEVAL-2~\cite{senseval2:00:a}は2001年春に行われた．
SENSEVAL-2では，9言語を対象に37研究グループが参加した．
日本語を対象としたタスクとしては，
辞書タスクと翻訳タスクの2つが行われた．
辞書タスクでは語の意味の区別(曖昧性)を国語辞典によって定義し，
翻訳タスクではこれを訳語選択によって定義した．
本論文は，SENSEVAL-2の日本語辞書タスクについて，
タスクの概要，データ，コンテストの結果について報告する．

まず，日本語辞書タスクの概要について述べる．
SENSEVAL-2 では，
タスクをlexical sample taskとall words taskに
大別している．
lexical sample taskは特定(数十〜数百)の単語だけをWSDの対象とし，
all words taskでは評価テキスト中のすべての単語を対象とする．
日本語辞書タスクはlexical sample taskである．
以下，本論文では，評価の対象として選ばれた単語を評価単語と呼び，
評価単語の評価データ中での実際の出現を評価インスタンス，
または単にインスタンスと呼ぶ．
辞書タスクでは，
単語の語義を岩波国語辞典~\cite{nisio:94:a} の
語義立てによって定義した．
参加者は，テキスト中の評価インスタンスに対して，
該当する語義を岩波国語辞典の語釈の中から選択し，
その語釈に対応したID(以下，語義ID)を提出する．
評価テキストは毎日新聞の1994年の新聞記事を用いた．
語義を決定する評価単語の数は100と設定した．
また，評価単語のそれぞれについて100インスタンスずつ
語義を決めるとした．
すなわち，評価インスタンスの総数は10,000である．
本タスクには3団体，7システムが参加した．

本論文の構成は以下の通りである．
\ref{sec:data} 節では，辞書タスクで用いたデータの概要を述べる．
\ref{sec:gold standard} 節では，正解データの作成手順について述べる．
また，正解データを作成する際，
1つの評価インスタンスに対して二人の作業者が
独立に正しい語義を選択したが，
そのときの語義の一致率などについても報告する．
\ref{sec:contest} 節では，
参加者のシステムの概要やスコアなどについて述べ，
コンテストの結果に関する簡単な考察を行う．
最後に\ref{sec:conclusion} 節では，本論文のまとめを行う．


\section{データ}
\label{sec:data}

本節では，辞書タスクで用いられた3つのデータ，
岩波国語辞典，訓練データ，評価データについて述べる．

\subsection{岩波国語辞典}
\label{sec:iwanami}

\ref{sec:intro} 節で述べたように，
辞書タスクでは，岩波国語辞典によって語義を定義する．
岩波国語辞典の見出しの数は60,321，語義の総数は85,870であり，
一見出し当たりの平均語義数は1.42である．
岩波国語辞典の語釈文の例を図~\ref{fig:dic-MURI} に示す．
また，岩波国語辞典では，語義は階層構造を持つ．
例えば，図~\ref{fig:dic-MURI} では，
「理を欠くこと」という語義が\MARU{ア},\MARU{イ}の
語義の上位にある．
階層構造の最大の深さは3である．

辞書タスクでは，語義の定義として，
形態素解析された岩波国語辞典の語釈文と，
それに対応する語義IDが参加者に配布された．
なお，語釈文の形態素解析結果は人手修正されている．

\begin{figure}[btp]

  \begin{center}
  \noindent
   \Ovalbox{  
    \begin{tabular}{@{\hspace*{5mm}}l@{}p{0.7\textwidth}@{\hspace*{5mm}}}
      \\[-4mm]
      \multicolumn{2}{l}{むり【無理】}\\[1mm]
      \multicolumn{2}{l}{((名・ダナ))理を欠くこと。}\\
      \hspace*{1.5zw}\MARU{ア} &
      道理に反すること。「—が通れば道理が引っ込む」「君が怒るのは—もない（＝もっともだ）」。理由が立たないこと。「—な願い」\\
      \hspace*{1.5zw}\MARU{イ} &
      行いにくいのに、押してすること。「—をして出掛ける」「仕事の—で病気になる」\\[1mm]
    \end{tabular}
     }
  \end{center}
  
  \caption{岩波国語辞典の「無理」の語釈文}
  \label{fig:dic-MURI}
  \bigskip
\end{figure}

\subsection{訓練データ}
\label{sec:train data}

訓練データは，毎日新聞の1994年の3,000記事を解析したコーパスである．
このコーパスに付与されている情報を以下にまとめる．

\begin{itemize}
\item 形態素情報(分かち書き，品詞，読み，基本形)

  コーパスに含まれる形態素数は880,000である．
  これらは人手修正されている．

\item UDCコード

  各記事には，テキストの分類カテゴリを表わす指標として，
  国際十進分類法(Universal Decimal Classification, UDC)による
  コード番号~\cite{infosta:94:a}が人手によって付与されている．

\item 語義情報

  各単語には，その単語の意味に該当する語義IDが付与されている．
  但し，語義IDはコーパスの全ての単語ではなく，
  以下の条件を満たす単語のみに付与されている．
  \begin{itemize}
  \item 名詞，動詞，形容詞のいずれかである
  \item 岩波国語辞典に見出しがある
  \item 多義である
  \end{itemize}
  語義が付与されている形態素の総数は148,558である．
  語義IDは全て人手によって付与された．
  また，1つの単語に語義IDを付与した人は1人である．
  複数の人が同じ単語に語義IDを付与し，
  それらを照合するといった作業は行われていない．
\end{itemize}

\subsection{評価データ}
\label{sec:eval data}

評価データは，
評価インスタンスとその正解となる語義IDを含むテキストである．
評価テキストとして毎日新聞の1994年の記事を用いた．
これらは訓練データの記事とは異なる．
評価データに付与されている情報は以下の通りである．

\begin{itemize}
\item 形態素情報(分かち書き，品詞)

  これらは自動解析されたものである．
  訓練データとは異なり，人手による修正はされていない．
  したがって，
  訓練データで学習したWSDシステムを評価データに適用した際，
  訓練データと評価データにおける分かち書きや品詞付けの違いによって
  誤りが生じる可能性がある．
  本来は評価データの形態素情報も人手修正するべきであったが，
  今回は準備期間が短かったために断念した．

\item UDCコード

  訓練データにおけるUDCコードと同じ．

\item 語義情報(正解データ)

  評価インスタンスには正解となる語義IDが付与されている．
  また，訓練データとは異なり，
  1つのインスタンスに対して最低2人の人が語義IDを付与している
  (詳細は\ref{sec:gold standard} 節を参照)．
  もちろん，
  この情報はコンテストの際には参加者に配布されない．
\end{itemize}

\subsection{付加情報}

本節で述べた岩波国語辞典，訓練データ，評価データの
付加情報のほとんどは，RWCPによって作成され，
1997年から既に公開されているデータである．
訓練データの語義情報については\cite{sirai:01:b}，
それ以外の情報については\cite{hasida:98:a}を参照していただきたい．
これに対し，評価データの語義情報，
すなわち正解となる語義IDのデータは，
今回のコンテストのために新たに作成した．
\ref{sec:gold standard} 節では，
正解データの作成過程ならびにその概要について述べる．

\section{正解データの作成}
\label{sec:gold standard}

正解データの作成は以下のように行った．
まず評価単語を100語選定した．
次に，各評価単語毎に100，合計10,000の評価インスタンスを選定した．
さらに，各評価インスタンスに対し，のべ二人の作業者が語義IDを付与した．
本節では，正解データ作成の過程，
ならびに二者の語義IDの一致度などについて報告する．

\subsection{評価単語，評価インスタンスの選定}
\label{sec:dic-target-word-selection}

評価単語を選定する際には，以下の点を考慮した．
\begin{itemize}
\item
  評価単語の品詞は名詞または動詞とした．
\item 
  訓練データにおける出現頻度が50以上の単語を評価単語とした．
\item 
  訓練データにおける語義の頻度分布のエントロピー
  $E(w)$を考慮した．
  $E(w)$の定義を式~(\ref{eq:dic-entropy})に示す．
  \begin{equation}
    \label{eq:dic-entropy}
    E(w) = - \sum_i p(s_i|w) \log p(s_i|w)
  \end{equation}
  式(\ref{eq:dic-entropy})において，
  $P(s_i|w)$ は単語$w$ の語義が$s_i$ となる確率を表わす．
  $E(w)$ の値が大きい単語は，語義の頻度分布が一様であり，
  語義を決定することが比較的難しい単語であると考えられる．
  一方，$E(w)$ の値が小さい単語は，
  1つの語義が集中して現われる傾向が強く，
  語義の決定も比較的易しいと考えられる．

  評価単語の選定の際には，$E(w)$ をWSDの難易度の目安とした．
  具体的には，以下の3つの難易度クラスを設定し，
  それぞれのクラスから評価単語をまんべんなく選ぶようにした．
  \begin{enumerate}
  \item 高難易度の単語クラス\clA ($E(w) \ge 1$)
  \item 中難易度の単語クラス\clB ($0.5 \le E(w) < 1$)
  \item 低難易度の単語クラス\clC ($E(w) < 0.5$)
  \end{enumerate}
\end{itemize}

品詞別，難易度クラス別の評価単語数の内訳を
表~\ref{tab:target words} に示す．
また，評価単語の一覧を付録\ref{sec:target word list} に示す．
表~\ref{tab:target words} において，
「語義数」は評価単語の岩波国語辞典における語義の数の平均を，
「$E(w)$」は評価単語毎に求めた
訓練データにおけるエントロピーの平均を表わす．


\begin{table}[tbp]
{\normalsize
  \begin{center}
    \caption{評価単語数の内訳}
    \label{tab:target words}

    \smallskip

    \begin{tabular}[t]{|c|l|ccc||c|} \hline
      \multicolumn{2}{|c|}{}  &
      \makebox[12mm]{\clA} &
      \makebox[12mm]{\clB} &
      \makebox[12mm]{\clC} &
      \makebox[12mm]{計} \\ \hline
     	   & 単語数  &{\bf 10}&{\bf 20}&{\bf 20}&{\bf 50} \\
      名詞 & 語義数  &   9.1 &   3.7 &   3.3 &   4.6 \\
           & $E(w)$  &  1.19 & 0.723 & 0.248 & 0.627 \\ \hline
           & 単語数  &{\bf 10}&{\bf 20}&{\bf 20}&{\bf 50} \\
      動詞 & 語義数  &    18 &   6.7 &   5.2 &   8.3 \\
           & $E(w)$  &  1.77 & 0.728 & 0.244 & 0.743 \\ \hline\hline
           & 単語数  &{\bf 20}&{\bf 40}&{\bf 40}&{\bf 100} \\
      計   & 語義数  &    14 &   5.2 &   4.2 &   6.4 \\
           & $E(w)$  &  1.48 & 0.725 & 0.246 & 0.685 \\ \hline
    \end{tabular}
  \end{center}
}
\end{table}


次に，評価テキストである1994年の毎日新聞の記事中から
評価インスタンスを選択した．
これらの記事には，RWCPによって，
形態素情報とUDCコードが付加情報として与えられている．
各評価単語毎に，日付の古い記事から順に100語を選択し，
それらを評価インタンスとした．
ただし，訓練データの記事やUDCコードが付与されていない記事は
対象外とした．
評価単語は100語であるので，評価インタンスの総数は10,000である．
また，評価インスタンスが選ばれた記事の総数は2,130となった．

\subsection{語義IDの付与}
\label{sec:dic-annotating}

10,000語の評価インスタンスに対して，
その単語の意味に該当する語義IDを人手で付与した．
語義IDを付与した作業者は6名で，
言語学や辞書編纂の知識をある程度持っている人達である．
また，本タスクの訓練データはRWCPが作成したコーパスを利用しているが，
今回の作業者の中には訓練データへ語義IDを付与した人も含まれる．
その手順を以下にまとめる．
\begin{enumerate}
\item 
  二人の作業者が独立に語義IDを付与する．
  その際の大まかな指針は以下の通りである．
  \begin{itemize}
  \item
    1つの語義IDを選択する．複数の語義IDは選択しない．
  \item 
    どの階層の語義IDを選んでもよい．
  \item 
    岩波国語辞典の語釈の中に該当するものがなければ，
    UNASSIGNABLE(該当無し)とする．
    ただし，なるべくUNASSIGNABLEとすることは避け，
    岩波国語辞典の語釈の中から語義IDを選択する．
  \end{itemize}

\item 
  二者が選んだ語義IDが一致していれば，それを正解の語義IDとする．

\item 
  二者が選んだ語義IDが一致していなければ，
  第三者がその中から正しいと思われるものを選択する．
  ただし，第三者が，
  二者が選んだ語義ID以外の語義IDが正しいと判断した場合には，
  三者が選んだ3つの語義IDの全てを正解とする．
\end{enumerate}

語義IDを選択する際，どの階層の語義IDを選んでもよいとしたが，
階層構造の末端以外の語義IDが選択されたインスタンスの数は94であり，
階層の上の語義IDはあまり選ばれなかった．
また，二者の語義IDが一致せず，
第三者も違う語義IDを選んだインスタンスの数は28であり，
その全体に対する割合は0.3\,\%と非常に少なかった．

表~\ref{tab:dic-agreeement} は，
作業者二人が最初に選んだ語義IDの一致率を示したものである．
評価インスタンス全体における一致率は86.3\,\%であった．
名詞と動詞とで一致率を比較すると，それほど差が見られないことがわかる．
また，名詞，動詞ともに，難易度の高いクラスの単語ほど一致率が低くなるが，
その傾向は名詞よりも動詞の方が強いことがわかる．

一方，表~\ref{tab:kappa} は評価単語毎に計算した
Cohenの$\kappa$~\cite{bakeman:97:a} の平均を示したものである．
$\kappa$ とは二系列のデータがどの程度一致しているかを測るために
よく用いられる統計的尺度であり，式(\ref{eq:kappa})で与えられる．



\begin{eqnarray}
  \label{eq:kappa}
  \kappa & = & \frac{P_o - P_e}{1 - P_e} \\[2mm]
  \label{eq:p_o}
  P_o    & = & \frac{\sum_i x_{ii}}{n} \\[2mm]
  \label{eq:p_e}
  P_e    & = & \frac{\sum_{i=1}^k x_{+i} x_{i+}}{n^2}
\end{eqnarray}

\noindent
式(\ref{eq:p_o})と(\ref{eq:p_e})において，
$n$ はインスタンスの総数を，
$x_{ij}$ は作業者Aが語義$i$，作業者Bが語義$j$ を与えたインスタンスの数を，
$x_{i+}, x_{+i}$ はそれぞれ作業者A,Bが語義$i$ を与えた
インスタンスの数を表わす．
$P_o$ は二人の作業者が同じ語義を付与した実際の確率であり，
$P_e$ は二人の作業者の語義付与が独立であるときに
同じ語義を付与する期待値である．
$\kappa$ は両者の比から計算され，その値が大きいほど，
二者の語義付与が一致していることを示す．
その最大値は1である．

評価単語100語の$\kappa$の平均は0.657であり，
決して大きいとは言えない．
このことは，岩波国語辞典の語釈の中から正しい語義を選択する作業は
人間でも難しく，
付与される語義が人によって揺れやすいことを示唆している．
また，表~\ref{tab:kappa} を見ると，
表~\ref{tab:dic-agreeement} の一致率とは異なり，
名詞で難易度クラスが\clB のときの
$\kappa$ の値が不自然に低いことがわかる．
これは，一致率と$\kappa$ が
作業者間の語義の一致度に関して
必ずしも同じ傾向を示すわけではないためと考えられる．
例えば，100個の評価インスタンスに対して，
作業者Aが語義~$\!{}_1$を100回付与し，
作業者Bが語義~$\!{}_1$を99，語義~$\!{}_2$を1回付与したとする．
このとき，一致率は0.99と高いのに対し，$\kappa$ は0となる．
直観的には，$\kappa$ の値はもっと大きいと考えられるが，
これは統計的に信頼できる$\kappa$ を求めるのに
十分な量のサンプルがなかったためかもしれない．
今回の作業では，1つの評価単語のインスタンスの数は100なので，
$\kappa$ を求める際のサンプル数$n$も100である．

\begin{table}[tbp]
{\normalsize
  \begin{center}
    \caption{作業者の語義IDの一致率}
    \label{tab:dic-agreeement}
    \medskip
    \begin{tabular}{|c|ccc|c|} \hline
           & \clA  & \clB  & \clC  & 計 \\\hline
      名詞 & 0.809 & 0.786 & 0.957 & 0.859 \\
      動詞 & 0.699 & 0.896 & 0.922 & 0.867 \\\hline
      計   & 0.754 & 0.841 & 0.939 & 0.863 \\\hline
    \end{tabular}

    \bigskip

    \caption{$\kappa$の平均}
    \label{tab:kappa}
    \medskip
    \begin{tabular}{|c|ccc|c|} \hline
           & \clA  & \clB  & \clC  & 計 \\\hline
      名詞 & 0.713 & 0.526 & 0.655 & 0.616 \\
      動詞 & 0.605 & 0.723 & 0.722 & 0.698 \\\hline
      計   & 0.659 & 0.627 & 0.687 & 0.657 \\\hline
    \end{tabular}
  \end{center}
}
\end{table}

\section{コンテスト}
\label{sec:contest}

\subsection{参加団体}
\label{sec:participants}

辞書タスクには3団体7システムが参加した．
参加団体とそのシステムの特徴は以下の通りである．
いずれのシステムも訓練データを利用した教師あり学習を行っている．

\begin{itemize}
\item 通信総研(CRL)

  以下の4つのシステムによって回答を提出した．
  システム名とその概要は以下の通りである~\cite{murata:01:a}．

  \begin{itemize}
  \item CRL1\\
    分類器としてサポートベクトルマシンを使用したシステム．
    学習に用いる素性としては，
    対象語及びその周辺にある単語の表記，品詞，構文情報，
    意味クラスやUDCコードなどを用いている．
  \item CRL2\\
    分類器としてシンプルベイズを使用したシステム．
    学習に用いる素性はCRL1と同じ．
  \item CRL3\\
    シンプルベイズとサポートベクトルマシンの混合モデル．
    個々の対象単語毎に，
    それぞれの分類器の精度を
    学習データを用いたクロスバリデーションによって評価し，
    精度の高い分類器を選択している．
  \item CRL4\\
    CRL3と同じような混合モデル．
    CRL1と同じ素性を用いたシンプルベイズとサポートベクトルマシン，
    CRL1の素性のうち構文素性を使わない
    シンプルベイズとサポートベクトルマシンの4つの分類器を使用している．
  \end{itemize}

\item 奈良先端科学技術大学院大学(NAIST)

  以下の1つのシステムによって回答を提出した．
  その概要は以下の通りである~\cite{takamura:01:a}．

  \begin{itemize}
  \item NAIST\\
    分類器としてサポートベクトルマシンを用いている．
    学習に用いる素性は，
    対象語及びその周辺にある単語の表記や品詞の情報などである．
    さらに，独立成分分析(Independent Component Analysis, ICA)や
    主成分分析(Principle  Component Analysis, PCA)といった
    手法を用いて，素性空間の再構築を行っている．
    また，複数の素性空間によって学習された分類器を混合している
    \footnote{
      SENSEVAL-2の参加システムは
      文献~\cite{takamura:01:a}のシステムと厳密に同じではない．
      両者の違いは，複数の分類器を混合する際に，
      前者ではクロスバリデーションによって
      最も良いと思われる分類器を選択しているのに対し，
      後者では重み付き多数決によって複数の分類器を混合している．
      }．
  \end{itemize}

\item 東京工業大学(TITECH)

  以下の2つのシステムによって回答を提出した．
  システム名とその概要は以下の通りである~\cite{yagi:01:a}．

  \begin{itemize}
  \item TITECH1\\
    分類器として決定リストを用いている．
    学習に用いる素性は，
    対象語及びその周辺にある単語の表記，品詞やUDCコードである．
    また，訓練データの他に，
    岩波国語辞典の語釈文中の例文からも
    決定リストの規則を学習している．
  \item TITECH2\\
    TITECH1とほぼ同じであるが，
    評価データに付与された形態素情報の誤りを
    自動修正することを試みている．
  \end{itemize}
\end{itemize}

\subsection{評価基準}
\label{sec:scoring}

SENSEVAL-2では，全ての言語のタスクにおける共通の評価基準として，
以下に述べる3つの評価基準がある．
辞書タスクでも，この評価基準に従ってシステムの評価を行った．

\begin{itemize}
\item fine-grained scoring

  正解の語義IDとシステムの語義IDが完全に一致していれば正解とする．

\item coarse-grained scoring

  正解の語義IDとシステムの語義IDが，
  語義の階層構造の一番上の層で一致していれば正解とする．

\item mixed-grained scoring

  正解の語義IDとシステムの語義IDが完全に一致していなくても，
  語義の階層構造に従って部分的にスコアを与える方式で，
  fine-grainedとcoarse-grainedの中間にあたる．

  語義の階層構造において，
  正解の語義IDがシステムが出力する語義IDの親であるなら
  正解とみなす(図~\ref{fig:mixed-grained} (a))．
  逆に，システムの語義IDが正解の語義IDの親であるなら，
  \begin{equation}
    \label{eq:mixed-grained}
    \frac{1}{システムの語義\rm{ID}の子の数}
  \end{equation}
  といった部分的なスコアを与える(図~\ref{fig:mixed-grained} (b))．
\end{itemize}

\noindent
参加者は，1つの評価インスタンスに対して複数の語義IDを返してもよい．
また，インスタンスの意味がその語義IDである確率をつけて返してもよい．
確率をつけずに複数の語義IDを回答した場合には，
全ての語義IDの確率が等しいとして取り扱われる．
複数の語義IDが提出されたときには，
各語義IDの確率に従ってスコアの重み付き平均をとる．
また，正解の語義IDが複数ある場合は，
正解の語義ID毎にスコアを計算し，その和を全体のスコアとする．

\begin{figure}[tbp]
  \begin{center}
    \epsfile{file=scoring.eps,scale=0.72}
    \caption{評価基準(mixed-grained scoring)}
    \label{fig:mixed-grained}
  \end{center}
\end{figure}

\subsection{評価結果と考察}
\label{sec:results}

\begin{figure}[tbp]
  \begin{center}
    \epsfile{file=res2.eps,scale=0.45}
    \caption{辞書タスクの結果}
    \label{fig:res}
  \end{center}
\end{figure}

本項では，コンテストの結果とそれに関する考察について述べる．
まず，システムの評価結果を図~\ref{fig:res} に示す．
図~\ref{fig:res} において，
``Baseline''は訓練データにおける最頻出語義を選択したときのスコアを，
``Agree''は2人の作業者の語義IDが一致した割合を示している．
参加システムの中で一番スコアが良かったのはCRL4である．
しかし，どのシステムもベースラインを上回り，
お互いのスコアの差も3\,\%程度で，
それほど大きな差は見られなかった．

3つの評価基準によるスコアのうち，
coarse-grained scoreはBaselineも含めてほとんど差はない．
また，mixed-grainedとfine-grainedでは，
システム間の差に見られる傾向はほとんど同じである．
そのため，以後の考察はfine-grained scoreについてのみ行う．

\subsubsection{品詞別に見た評価結果}
\label{sec:results-pos}


\begin{figure}[tbp]
  \begin{center}
   
    \epsfile{file=res-pos-fine.eps,scale=0.4}
    \caption{品詞別スコア(fine-grained)}
    \label{fig:res-pos}
  \end{center}
\end{figure}

図\ref{fig:res-pos} は，
品詞別に見た各システムのスコア(fine-grained)を示したグラフである．
ベースラインを比べると，動詞の方が名詞よりも平均エントロピーが
大きい(表~\ref{tab:target words})にも関わらず，約3\,\%ほどスコアが高い．
これは，特にエントロピーの高い評価単語が動詞にいくつかあり，
それらが動詞の平均エントロピーを大きくしているためと考えられる．

参加者のシステムを比べると，
名詞のスコアは比較的差が小さいが，動詞のスコアは差が大きい．
特に通信総研のシステムは動詞に対するスコアが高く，
このことが全体の評価においても
他のシステムよりもスコアが高い要因となっている．
この原因を明らかにするために，
CRL1が正解しNAISTとTITECH2が不正解であった
動詞のインスタンス(139事例)を抜き出し，
どのような動詞に対してCRLのシステムが正しく語義を決めることが
できるのかについて調査した．
通信総研の4つのシステムの中からCRL1を選択したのは，
CRL1が学習アルゴリズムとしてサポートベクトルマシンを
採用したシステムであり，
同じくサポートベクトルマシンを用いたNAISTと比較するためである．
また，東工大の2つのシステムの中からTITECH1を選択したのは，
TITECH1の方がTITECH2に比べて若干スコアが高いためである．

\begin{figure}[tbp]
  \begin{center}
    (a)
    \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-7mm}
\begin{tabular}[t]{|p{7mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
      \multicolumn{2}{|l|}{「えがく」の語義(抜粋)} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{絵や図をかく。「弧を—いて飛ぶ」} &
      20 & & & ○ \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{様子を写し出す。表現する。
        描写する。「情景を—」「勝利を胸に—」} &
      & 20 & 20 & \\
      \hline\hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{そのわきで、歴代王たちの肖像を\head{描い}た
          百メートルにも及ぶ美しい壁画が風雨にさらされている。}}
      \\ \hline
      \end{tabular}
    }

    \bigskip

    (b)
    \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-7mm}
\begin{tabular}[t]{|p{7mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
      \multicolumn{2}{|l|}{「とう」の語義(抜粋)} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0pt}{[一]} &
      \tume{【問う】((五他))} &
      & & & \\
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{わからない事、はっきりしない事を、知らせ（教え）て
        くれるように求める。問題として出す。
        「年齢を—わず（＝問題とせず。それで差別しないで）出願できる」
        } &
      14 & & & ○ \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{物事の原因、責任の所在、罪を犯した事実などを取り立てて、
        明らかにするためにただす。「事故の原因を—」「責任を—」
        } &
      & 14 & 14 & \\
      \sensesymbol{0pt}{[二]} &
      \tume{【訪う】((五他))
        他人の家や特定の場所を訪問する。おとずれる。たずねる。
        「恩師を—」「名所旧跡を—」} &
      & & & \\
      \hline\hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{交換できる本は汚れのひどくないもので、
          引き取り価格は一律定価の一〇％。
          分野は\head{問わ}ず漫画も可。}}
      \\ \hline
    
    \end{tabular}
    }

    \medskip

    \begin{minipage}{0.75\textwidth}
      \small
      C,N,Tの欄は
      それぞれ通信総研,奈良先端大,東工大のシステムが
      該当する語義を出力した頻度を表わす．
      語釈文の下は，対象インスタンスと
      それが現われる新聞記事の例である．
      対象インスタンスは\head{~~}でマークされている．
    \end{minipage}

  \caption{ CRL1が正解する動詞の例}
  \label{fig:verb c+ n- t-}
    
  \end{center}
\end{figure}

調査の結果，「描く」「問う」などの動詞について，
CRL1は他のシステムよりも正解率が高いことがわかった．
これらの動詞の岩波国語辞典の語釈文と，
各システムが出力した語義の頻度を図~\ref{fig:verb c+ n- t-} に示す．
しかし，これらの例を見ただけでは，
CRL1がNAISTやTITECH1に比べて動詞のスコアが高い原因はわからない．
原因のひとつとして考えられるのは，
CRL1がNAISTやTITECH1と比べて，
より多くの素性を用いていることである(\ref{sec:participants}項参照)．
但し，この推察を裏付けるためには，
各システムが個々のインスタンスに対して
語義を決める際に手がかりとした素性を明らかにする必要がある．
例えば，図~\ref{fig:verb c+ n- t-} に示したインスタンスに対して，
CRL1がNAISTやTITECH2が考慮していない構文素性などの素性を
特に手がかりとしていることが明らかになれば，
それらの素性が動詞の語義曖昧性解消に有効であると結論できる．
但し，著者は，
各システムが語義を決定する際に一番有力な手がかりとした
素性に関する情報を持っていないため，
上記の考察を具体的に検証することはできなかった．
しかし，このように複数のWSDシステムの出力を詳細に比較することは，
WSDに有効な素性を明らかにし，
今後のWSDシステムの精度向上につながる可能性がある．


\subsubsection{難易度別に見た評価結果}
\label{sec:results-dif}

\begin{figure}[tbp]
  \begin{center}
   
    \epsfile{file=res-dif-fine.eps,scale=0.4}
    \caption{難易度別スコア(fine-grained)}
    \label{fig:res-dif}
  \end{center}
\end{figure}

図~\ref{fig:res-dif} は，
難易度別に見た各システムのスコア(fine-grained)を示したグラフである．
クラス\clC の単語については，
ベースラインや作業者の一致率も含めて，
各システムのスコアにほとんど差がない．
これは，クラス\clC の単語の語義を決定するタスクが
比較的容易であったためと考えられる．
これに対し，難易度の高い\clA や\clB の単語では，
システム間の相違は全体での評価(図~\ref{fig:res})とほぼ同じである．

\subsubsection{参加システムの比較}
\label{sec:comparing systems}

\begin{table}[tbp]
{\normalsize
  \begin{center}
    \caption{個々のインスタンスに対する参加システムの比較}
    \label{tab:comparing systems}

    \medskip

    \begin{tabular}{|c||c|ccc|ccc|c|} \hline
      & \multicolumn{1}{c|}{(a)} & \multicolumn{3}{c|}{(b)} &
        \multicolumn{3}{c|}{(c)} & \multicolumn{1}{c|}{(d)} \\ \hline
      CRL4    & ○ & ○ & × & × & × & ○ & ○ & × \\[-1mm]
      NAIST   & ○ & × & ○ & × & ○ & × & ○ & × \\[-1mm]
      TITECH1 & ○ & × & × & ○ & ○ & ○ & × & × \\ \hline
      & 6558 & ~345 & ~283 & ~280 & ~308 & ~501 & ~383 & 1342 \\\hline
    \end{tabular}
  \end{center}
}
\end{table}

表~\ref{tab:comparing systems} は，
10,000語の対象インスタンスを(a)3つの参加者の全てのシステムが正解，
(b)1システムだけが正解，(c)1システムだけが不正解，
(d)全てのシステムが不正解，の4つに分類し，
その内訳を調べたものである．
通信総研と東工大のシステムとしては一番スコアの良いCRL4と
TITECH1を選択し，比較の対象とした．
また，NAISTは複数の語義を確率付きで回答するシステムであったが，
出力された複数の語義の中に正解が含まれていれば
そのインスタンスに対して正解したとみなすと，
NAISTのシステムのパフォーマンスが過大に評価され，
システムの公平な比較ができない．
そこで，確率の一番大きい語義のみを出力したとみなして
他のシステムと比較することにした．
ちなみに，確率の一番大きい語義のみを出力したときの
NAISTのfine-grainedスコアは0.753である．

表~\ref{tab:comparing systems} (b),(c)から，
参加者のシステムの回答が完全に一致していない事例の数は
2,100であることがわかる．
これらの事例から，それぞれのWSDシステムの特徴を考察することができる．
例えば，表~\ref{tab:comparing systems} (c)の事例は，
他のシステムは正しい語義を出力したのに対し，
あるシステムだけが正しい語義を出力できなかったことを表わす．
付録\ref{sec:example:only one system failure}に
具体的な事例をいくつか紹介する．
これらの事例を調べれば，
現在のWSDシステムがうまく語義を決定することができない
要因を探ることができる．
但し，\ref{sec:results-pos}の考察で述べたように，
各システムが個々のインスタンスに対して語義を決定する際に
一番有力な手がかりとした素性に関する情報が必要である．

また，自然言語処理における様々なタスクにおいて，
votingと呼ばれる技術に関する研究が近年盛んに行われている．
votingとは，複数のシステムの結果を混合することにより
パフォーマンスを向上させる技術で，WSDに応用した研究もいくつか
報告されている~\cite{pedersen:00:a,agirre:00:a,takamura:01:a}．
表~\ref{tab:comparing systems} から，
3つのシステムのいずれかに正解が含まれるインスタンスの割合は
0.865であることがわかる．
これは，3つのシステムの出力を組み合わせたときに得られる
スコアの上限であり，
単独のシステムよりも8\,\%程度精度が向上することを意味する．
したがって，日本語のWSDにおいても，
votingは精度を向上させる技術として有望であろう．

\subsubsection{未知の語義}
\label{sec:unknown-word-sense}

\begin{table}[tbp]
{\normalsize
  \begin{center}
    \caption{未知の語義に対するスコア(fine-grained)}
    \label{tab:unknown-word-sense}

    \medskip

    \begin{tabular}{|ccccccc|} \hline
      \makebox[14mm]{CRL1}    & \makebox[14mm]{CRL2} &
      \makebox[14mm]{CRL3}    & \makebox[14mm]{CRL4} &
      \makebox[14mm]{NAIST}   &
      \makebox[14mm]{TITECH1} & \makebox[14mm]{TITECH2}     \\\hline
      0 & 0 & 0 & 0 & 0.01 & 0.648 & 0.657 \\\hline
    \end{tabular}
  \end{center}
}
\end{table}

未知の語義とは，ここでは訓練データに1回も現われない語義を指す．
今回のコンテストでは，
未知の語義を正解とするインスタンスの数は108であった．
未知の語義に対する各システムのスコアを
表~\ref{tab:unknown-word-sense} に示す．
各システムは訓練データを用いた機械学習を行っているため，
未知の語義に対するスコアは全体のスコアに比べて著しく劣る．
また，参加者のシステムを比較すると，
東工大のシステムのスコアが特に高いことがわかる．
東工大システムのみが正解した例を図~\ref{fig:unk-ws-system} に示す．

\begin{figure}[tbp]
  \begin{center}
    
  \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-9mm}
\begin{tabular}[t]{|p{9mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
      \multicolumn{2}{|l|}{「め」の語義(抜粋)} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0pt}{[一]} &
      \tume{((名))} &
      & & & \\
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{生物の、物を見る働きをする器官。また、その様子・働き。} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ア}} &
      \tume{眼球・視神経から成る器官。} &
      32 & 49 & & \\
      \sensesymbol{1.5zw}{\MARU{イ}} &
      \tume{目\MARU{1}\MARU{ア}の様子。目つき。} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ウ}} &
      \tume{見ること。見えること。また、視力。更に、注意（力）。
        } &
      37 & 20 & & \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{目\MARU{1}\MARU{ア}に見える姿・様子。} &
      & & & \\
      \sensesymbol{0.75zw}{\MARU{3}} &
      \tume{ある物事に出会うこと。経験。体験。また、局面。} &
      & & & \\
      \sensesymbol{0.75zw}{\MARU{4}} &
      \tume{形が目\MARU{1}\MARU{ア}に似ているもの。「台風の—」} &
      & & & \\
      \multicolumn{2}{|c|}{$\vdots$} & & & & \\
      \sensesymbol{0pt}{[二]} &
      \tume{((接尾))} &
      & & & \\
      \sensesymbol{1zw}{\MARU{1}} &
      \tume{順序を表す時に添える語。「三番—の問題」} &
      & & 69 & ☆ \\
      \multicolumn{2}{|c|}{$\vdots$} & & & & \\
      \hline\hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{２年連続１３回\head{目}の優勝を狙う早大を中心に、
          山梨学院大、中大が追う展開になりそうだ。}}
      \\ \hline
    
	\end{tabular}

    \medskip

    C=CRL4,~~~N=NAIST,~~~T=TITECH1
  \end{center}

  \caption{未知の語義に対するシステムの出力例}
  \label{fig:unk-ws-system}
\end{figure}

図~\ref{fig:unk-ws-system} に示したように，
[二]\MARU{1}が正解となるインスタンスに対して，
TITECH1は正解と同じ語義を出力するのに対し，
CRL4,NAISTは訓練データの頻出語義である
[一]\MARU{1}\MARU{ア}や[一]\MARU{1}\MARU{ウ}を
出力することがわかった．
東工大のシステムが訓練データにない語義を正確に返すのは，
語釈文中の例文からも決定リストの規則を学習しているためである．
東工大システムの開発者に，
「目」の語義を[二]\MARU{1}に決めた
決定リストの規則を問い合わせたところ，
式(\ref{eq:decision rule for ME})の規則であることがわかった．
\newpage
\begin{equation}
  \label{eq:decision rule for ME}
  \begin{array}[c]{p{0.8\textwidth}}
    \setlength{\baselineskip}{0.8\normalbaselineskip}
    対象インスタンスの1つ前の単語の品詞が``名詞 接尾 助数詞''かつ
    2つ前の単語の品詞が``名詞 数''なら，語義を[二]\MARU{1}にせよ．
  \end{array}
\end{equation}
式(\ref{eq:decision rule for ME})の規則は，
訓練データの例文ではなく，
語義[二]\MARU{1}の語釈文中の例文「三番—の問題」から
学習されたものである．
このように，WSDシステムを構築する際に複数の知識源を利用すること
--- 東工大システムの場合は訓練データ(語義タグ付きコーパス)と
辞書の語釈文 --- は，
WSDの精度向上に有効な手段であると考えられる．

なお，訓練データ中に[二]\MARU{1}の語義が現われなかった理由は
以下の通りである．
訓練データにおいては，図~\ref{fig:unk-ws-system} のような
「目」の品詞は``名詞 接尾''になっている．
訓練データに語義を付与する際に，接尾語は対象外としたため，
これらの単語には語義が付与されていない．
ところが，評価データにおいては，
RWCの品詞体系の大分類が``名詞''または``動詞''の単語を
対象インスタンスとしたため，
品詞が``名詞 接尾''の単語も語義を決める対象となっている．
このため，学習データに含まれない，接尾語としての意味
[二]\MARU{1}を正解とするインスタンスが評価データに頻出した．
このような状況は明らかにタスクの設定として不適切である．
これは主催者側の過失であり，反省点としたい．

\subsubsection{作業者の一致率とシステムのスコア}
\label{sec:agreement-and-score}

図~\ref{fig:annotator-system} は，
作業者が付与した語義の一致率を横軸，
参加者の7システムの平均スコアを縦軸とし，
100個の評価単語の結果をプロットしたグラフである．
この図から，作業者の一致率とシステムの平均スコアには
正の相関関係があることが読みとれる．
しかし，評価単語の中には，作業者の一致率が高いのにも関わらず，
システムの平均スコアが低い単語がある．
具体的には「開発」「核」「精神」「乗る」「生まれる」「かかる」
などである．
これらの一部の単語の語義と，参加システムが出力した語義の頻度を
付録~\ref{sec:example:agr+sys-}に示す．

このような単語は，人間にとっては正しい語義を選択するのは易しいが，
現状のWSDシステムではうまく語義を決めることができない単語である．
したがって，特にこれらの単語について，
システムが語義の選択を誤る原因を考察すれば，
システムの性能を向上させることができると期待される．

\begin{figure}[tbp]
  \begin{center}
  
    \epsfile{file=plot-all.eps,scale=0.4}
    \caption{作業者の語義の一致率とシステムの平均スコア(fine-grained)}
    \label{fig:annotator-system}
  \end{center}
\end{figure}

\section{おわりに}
\label{sec:conclusion}

本論文では，SENSEVAL-2の日本語辞書タスクの概要について報告した．
辞書タスクは，タスク設定自体はオーソドックスなものであるが，
日本語を対象とした語義曖昧性解消に関するコンテストとしては
始めての試みである．
本タスクで用いられた正解データや参加者のシステムの結果は，
SENSEVAL-2のウェブサイト\footnote{
  {\tt http://www.senseval.org/}}
で公開されている．
これらのデータが今後の語義曖昧性解消の研究に貢献することを願う．

\bigskip
\acknowledgment

辞書タスクでは，
評価テキストとして毎日新聞の新聞記事を利用させていただきました．
新聞記事の利用に御協力いただきました毎日新聞社に感謝いたします．
また，辞書タスクの運営に数々の助言をいただいた
東京工業大学の徳永健伸助教授，東京大学の黒橋禎夫助教授，
ならびに正解データを作成して下さった作業者の皆様に深く感謝いたします．
査読者の方には，コンテストの結果の考察に関して
示唆に富む数多くの御意見をいただきました．厚く御礼申し上げます．


\bibliographystyle{jnlpbbl}
\bibliography{paper}

\appendix
\section{評価単語}
\label{sec:target word list}

辞書タスクの評価単語の一覧を以下に示す．
また，日本語タスクには辞書タスクと翻訳タスクの2つがあるが，
両タスクの評価単語は同じものを使用した．
ただし，翻訳タスクの評価単語の数は40である．
下表で*のついた単語は，翻訳タスクの評価単語でもある．

\begin{center}
  \begin{tabular}{|m{2zw}|m{10zw}|m{10zw}|m{10zw}|}\hline
    & \multicolumn{1}{c|}{\clA} &
      \multicolumn{1}{c|}{\clB} &
      \multicolumn{1}{c|}{\clC} \\ \hline
    名詞 &
    間, 頭, 一般*, 意味*, 姿*, 近く*, 手, 胸*, 目, もの &
    一方*, 今*, 開発, 関係, 気持ち, 記録*, 国内*, 言葉*, 子供, 午後, 
    市場, 市民*, 時間, 事業*, 時代*, 情報, 地方, 同日, 場合*, 前* &
    疑い, 男, 核*, 技術, 現在, 交渉, 社会, 少年, 自分, 精神,
    対象, 代表, 中心*, 程度, 電話, 花*, 反対*, 民間, 娘, 問題*
    \\ \hline
    動詞 &
    与える*, 受ける*, かかる, 聞く*, 進む, 出す, 出る*, 取る, 入る, 持つ* &
    言う*, 訴える, 生まれる, 描く*, 書く*, 決まる, 来る, 超える*, 使う*, 作る*,
    伝える*, 出来る, 問う, 残す, 乗る*, 開く, 待つ*, まとめる, 守る*, 見る &
    思う, 買う*, 変わる, 考える, 決める, 加える, 知る, 進める, 違う, 狙う,
    図る*, 話す, 含む, 見せる*, 認める*, 迎える, 求める*, 読む, よる, 分かる
    \\ \hline
  \end{tabular}
\end{center}

\section{1つのシステムだけが不正解となる事例}
\label{sec:example:only one system failure}

CRL4, NAIST, TITECH1のうち，
1つのシステムだけが不正解となった事例を紹介する．

\begin{itemize}
\item CRL4のみが不正解となる事例
\end{itemize}
\hspace{7.4mm}
  \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-7mm}
\begin{tabular}[t]{|p{7mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
    
      \hline
      \multicolumn{2}{|l|}{「じょうほう」の語義} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{ある物事の事情についての知らせ。「海外—」「—を流す」} &
      & 19 & 19 & ☆ \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{それを通して何らかの知識が得られるようなもの。
        ▽ｉｎｆｏｒｍａｔｉｏｎの訳語。
        「データ」が表現の形の面を言うのに対し、
        内容面を言うことが多い。} &
      19 & & & \\
      \hline\hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{「お天気\head{情報} の大切さを一般の人に
          理解していただくことが、僕の使命と思っています。...}}
      \\ \hline
 
 	\end{tabular}
    }

    \medskip
    
\begin{itemize}
\item NAISTのみが不正解となる事例
\end{itemize}
\hspace{7.4mm}
  \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-7mm}
\begin{tabular}[t]{|p{7mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
     
      \multicolumn{2}{|l|}{「こども」の語義(抜粋)} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{幼い子。児童。} &
      22 & & 22 & ☆ \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{自分のもうけた子。むすこ、むすめ。子。} &
      & 22 & & \\
      \hline\hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{\head{子供}のころ、牛肉のすきやきは
          月に一度ありつけるかどうかのごちそうだった。}}
      \\ \hline
    
    \end{tabular}
    }

    \medskip
  \newpage

\begin{itemize}
\item TITECH1のみが不正解となる事例
\end{itemize}
\hspace{7.4mm}
  \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-9mm}
\begin{tabular}[t]{|p{9mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
     
      \multicolumn{2}{|l|}{「むね」の語義(抜粋)} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{動物の、（体の前面で）首と腹との間の部分。「—を張る」} &
      12 & 12 & & ☆ \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{胸\MARU{1}の内側に収まっている（と考える）もの。} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ア}} &
      \tume{肺。「—をわずらう」} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{イ}} &
      \tume{胃。「—が焼ける」} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ウ}} &
      \tume{心臓。「—がどきどきする」} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{エ}} &
      \tume{心。「—に迫る」「—に秘める」} &
      & & 12 & \\
      \hline\hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{同乗の兵庫県西宮市鷲林寺南町、無職、大園輝樹さん
          （２１）が\head{胸}などを強く打って間もなく死亡。}}
      \\ \hline
    
    \end{tabular}
    }

\vspace*{1cm}
\section{一致率が高くシステムのスコアが低い単語の例}
\label{sec:example:agr+sys-}

2人の作業者の一致率が高いのにも関わらず，
7つの参加システムの平均スコア(fine-grained)が
低い単語の例を以下に示す．
以下の表は，作業者の語義付けが一致したインスタンスに対する
参加システムの出力語義の頻度分布である．
CはCRL4，NはNAIST，TはTITECH1を表わす．

\begin{itemize}
\item 「開発」(一致率 0.93，参加システムの平均スコア 0.493)

  2人の作業者がともに正解を\MARU{1}\MARU{ア}とした場合．
\end{itemize}
\hspace{7.4mm}
  \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-9mm}
\begin{tabular}[t]{|p{9mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
      
      \multicolumn{2}{|l|}{「かいはつ」の語義(抜粋)} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{開きおこすこと。} &
      4 & & & \\
      \sensesymbol{1.5zw}{\MARU{ア}} &
      \tume{（天然資源などを）人間生活に役立たせること。「電源—」} &
      7 & 2 & 5 & ☆ \\
      \sensesymbol{1.5zw}{\MARU{イ}} &
      \tume{現実化すること。実用化すること。「新製品の—」「研究—」} &
      35 & 44 & 41 & \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{教育で、問答などを使って自発的にわからせる方法。} &
      & & & \\ \hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{「試掘で百本のうち三本も当たれば十分」とされる
          石油\head{開発}が、
          なぜ今になって盛り上がってきたのか——。}}
      \\ \hline
    
    \end{tabular}
    }

    \medskip
\newpage
\begin{itemize}
\item 「核」(一致率0.97，参加システムのスコアの平均0.721)

  2人の作業者がともに正解を\MARU{1}とした場合．
\end{itemize}
\hspace{7.4mm}
  \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-9mm}
\begin{tabular}[t]{|p{9mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
      
      \multicolumn{2}{|l|}{「かく」の語義} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{物事の中心（となるもの）。かなめ。「核になる」} &
       1 & & & ☆ \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{物の中心の部分。「地核・痔核（じかく）」} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ア}} &
      \tume{細胞核。「核膜・核分裂」} &
      21 & 22 & 22 & \\
      \sensesymbol{1.5zw}{\MARU{イ}} &
      \tume{原子核。また、核兵器。「核の持込み」} &
      & & & \\
      \sensesymbol{0.75zw}{\MARU{3}} &
      \tume{草や木の芽ばえるたね。内果皮の硬化したもの。「核果」} &
      & & & \\ \hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{とはいえ、このままボスニア情勢を座視していれば、
          国連を\head{核}とした地域紛争の管理システムの信頼性が
          決定的打撃を受けかねない。}}
      \\ \hline
    
    \end{tabular}
    }

  \medskip



\begin{itemize}
\item 「乗る」(一致率0.91，参加システムのスコアの平均0.567)

  2人の作業者がともに正解を\MARU{3}\MARU{ア}とした場合．
\end{itemize}
\hspace{7.4mm}
  \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-9mm}
\begin{tabular}[t]{|p{9mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
      \multicolumn{2}{|l|}{「のる」の語義(抜粋)} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{運送用の物の上や内部に移る。「馬に—」} &
      19 & 11 & 20 & \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{（持ち上げられて）物の上に移る。} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ア}} &
      \tume{物に上がる。「台の上に—」} &
      & 5 & & \\
      \sensesymbol{1.5zw}{\MARU{イ}} &
      \tume{上に置かれる。載「机に—っている本」} &
      & & & \\
      \sensesymbol{0.75zw}{\MARU{3}} &
      \tume{動き・調子によく合う。} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ア}} &
      \tume{勢いがついて物事が進む状態にある。「仕事に気が—らない」
        } &
      2 & 4 & 1 & ☆ \\
      \sensesymbol{1.5zw}{\MARU{イ}} &
      \tume{他のものの調子にうまく合う。「リズムに—って踊る」} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{ウ}} &
      \tume{十分によくつく。「あぶらの—った肉」} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{エ}} &
      \tume{物事をする仲間・相手になる。「相談に—」} &
      & & & \\
      \sensesymbol{1.5zw}{\MARU{オ}} &
      \tume{他からのたくらみにまんまと引き込まれる。「計略に—」} &
      & 1 & & \\
      \sensesymbol{0.75zw}{\MARU{4}} &
      \tume{伝える手段に託せられる。「電波に—って広まる」。
        特に、新聞・雑誌・書物に記される。「社会面に—った記事」} &
      & & & \\
      \hline \hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{株式会社にして資金を集めブームに\head{乗っ}て事業拡大し、
            資産を公開して大企業になり
            結局だれのものだかわからなくなってしまう。}}
      \\ \hline
    
    \end{tabular}
    }

    
\newpage
\begin{itemize}
\item 「生まれる」(一致率1，参加システムのスコアの平均0.719)

  2人の作業者がともに正解を\MARU{2}とした場合．
\end{itemize}
\hspace{7.4mm}
  \raisebox{2mm}{
    
    \setlength{\sensedescwidth}{100mm}
 \addtolength{\sensedescwidth}{-7mm}
\begin{tabular}[t]{|p{7mm}@{$\;$}p{\sensedescwidth}|
                    c@{\hspace*{1.8mm}}c@{\hspace*{1.8mm}}c|c|}\hline
      \multicolumn{2}{|l|}{「うまれる」の語義} &
      C & N & T & \multicolumn{1}{@{}c@{}|}{正解} \\ \hline
      \sensesymbol{0.75zw}{\MARU{1}} &
      \tume{母体から子や卵が、その時期が来て、出る。
        また、卵からかえる。出生する。誕生する。} &
      11 & 22 & 20 & \\
      \sensesymbol{0.75zw}{\MARU{2}} &
      \tume{今までなかったものが出来上がる。} &
      33 & 22 & 24 & ☆ \\
      \hline \hline
      \multicolumn{6}{|p{128mm}|}{
        \tume{料理は産物で支配され、結果、その国、
          その土地の伝統的料理が\head{生まれ}、育ちました。}}
      \\ \hline
    
    \end{tabular}
    }

\medskip

\begin{biography}
\biotitle{略歴}
\bioauthor{白井 清昭}{
  1993年東京工業大学工学部情報工学科卒業．
  1998年同大学院情報理工学研究科博士後期課程修了．
  同年同大学院情報理工学研究科計算工学専攻助手．
  2001年北陸先端科学技術大学院大学情報科学研究科助教授，現在に至る．
  博士 (工学)．
  統計的自然言語処理に関する研究に従事．
  情報処理学会，人工知能学会会員．
}
\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}

