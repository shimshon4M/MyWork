<?xml version="1.0" ?>
<root>
  <title>機械学習による複数文書からの重要文抽出</title>
  <author>平尾努賀沢秀人磯崎秀樹前田英作松本裕治</author>
  <jabstract>近年，インターネットや大容量の磁気デバイスの普及によって，大量の電子化文書が氾濫している．こうした状況を背景として，文書要約技術に対する期待が高まってきている．特に，ある話題に関連する一連の文書集合をまとめて要約することが可能となれば，人間の負担を大きく軽減することができる．そこで本稿では，特定の話題に直接関連する文書集合を対象とし，機械学習手法を用いることによって重要文を抽出する手法を提案する．重要文抽出の手法としては近年，自然言語処理研究の分野でも注目されている機械学習手法の1種であるSupportVectorMachineを用いた手法を提案する．毎日新聞99年1年分より選んだ12話題の文書集合を用意し，それぞれの話題から総文数の10,%，30,%，50,%の要約率に応じて人手により重要文を抽出した正解データセットを異なる被験者により3種作成した．このデータセットを用いて評価実験を行った結果，提案手法の重要文抽出精度は，Lead手法，TFIDF手法よりも高いことがわかった．また，従来より複数文書要約に有効とされる冗長性の削減が，文を単位とした場合には，必ずしも有効でないこともわかった．</jabstract>
  <jkeywords>複数文書要約，重要文抽出，機械学習，SupportVectorMachines</jkeywords>
  <subsubsection title="">*文の位置特定の話題に関する文書集合をEとし，Eに含まれる任意の文書をD_i，D_iに含まれる任意の文をS_j，任意のパラグラフをP_kとする．ここで，文S_jの位置を表す素性として，D_iにおけるS_jの位置(S_j)とP_kにおけるS_jの位置(S_j)を以下の式で定義する．(S_j)&amp;=&amp;1-_i(S_j)/M(D_i)(S_j)&amp;=&amp;1-_k(S_j)/M(P_k)eqnarrayここで，M(D_i)はD_iの文字数，_i(S_j)は，文書の先頭からS_jまでの文字数である．M(P_k)はP_kの文字数，_k(S_j)はそのパラグラフの先頭からS_jまでの文字数を表す．</subsubsection>
  <section title="はじめに">大量の電子化文書が氾濫する情報の洪水という状況に我々は直面している．こうした状況を背景として，情報の取捨選択を効率的に行うための様々な手法が研究されている．近年，それらの研究の一つとして文書要約技術が注目を集めている．特にある話題に関連する複数の文書をまとめて要約する複数文書要約といわれる技術が関心を集めており，検索技術などと組み合わせることにより効率的に情報を得ることが期待できる．DocumentUnderstandingConference(DUC)や，TextSummarizationChallenge(TSC)といった評価型ワークショップにおいても複数文書要約タスクが設定されており，その注目度は高い．複数文書要約も含め自動要約では，文書中から重要な情報を持つ文を抽出する重要文抽出技術用いて，その出力をそのまま要約とする手法や，その出力から不要な表現の削除や置換，あるいは，新たな表現の挿入を行い，より自然な要約にする手法がある．いずれの場合にも，重要文抽出は中心的な役割を担っている．そこで本稿では，複数文書を対象とした重要文抽出に着目する．複数文書からの重要文抽出も，単一文書からの重要文抽出と同様に，ある手がかりに基いて文の重要度を決定し，重要度の高い文から順に，要約率で指定された文数までを重要文として抽出する．この際，複数の手がかりを扱うことが効果的であるが，手がかりの数が多くなると，人手によって適切な重みを見つけることが難しいという問題がある．本稿では，汎化能力が高いとされる機械学習手法の一種であるSupportVectorMachineを用いて，複数の手がかりを効率的に扱い，特定の話題に関連する複数文書から重要文を抽出する手法を提案する．評価用のテストセットとして12話題に関する文書集合を用意し，文書集合の総文数に対して10,%，30,%，50,%の要約率で重要文抽出による要約の正解データを作成した．人間による重要文の選択の揺れを考慮するため，1話題に対し3名が独立に正解データを作成した．このデータセットを用いた評価実験の結果，提案手法は，Lead手法，TFIDF手法よりも性能が高いことがわかった．さらに，文を単位とした冗長性の削減は，情報源が一つである場合の複数文書からの重要文抽出には，必ずしも有効でないことを確認した．以下，2章では本稿における重要文抽出の対象となる複数文書の性質について説明し，3章ではSupportVectorMachineを用いた複数文書からの重要文抽出手法を説明する．4章では評価実験の結果を示し，考察を行う．5章ではMaximumMarginalRelevance(MMR)を用いて抽出された文集合から冗長性を削減することの効果について議論する．</section>
  <section title="対象とする複数文書">複数文書要約において，これまでに処理対象とされている文書集合は以下の2種に大別できる．情報検索結果である文書集合ある特定の話題(トピック)に関する文書集合(1)の分類を対象とした複数文書要約の研究としては，などがある．(1)では，ユーザが入力した検索要求(すなわち，単語群)を含む全ての文書が該当する．このため，要約の対象となる文書の数が多い．また，検索結果には，様々な出来事を扱った文書が多く含まれるだけでなく，ユーザが必要としない文書も多く含まれる可能性も高い．こうした多様で大量の文書集合に対して，理想的な要約を作成することは困難であるという問題がある．一方，(2)の分類を対象とした複数文書要約の研究としては，などがある．TSC，DUCで扱われている複数文書もこの範疇に入る．また，こうした文書集合を抽出するための研究はTopicDetectionandTracking(TDT)などで盛んに行われている．(2)の分類に属する文書集合は，特定の話題(出来事)に関連する文書集合であるので，一つのまとまったストーリが形成されていると考えられる．こうした文書集合は，意味的に良くまとまっているという特徴を持っているので，要約対象とする文書集合としても適している．本稿では，理想的な要約を作成することが比較的，容易であると考えられる分類(2)に属する文書集合から重要文を抽出する手法を提案する．特に，McKeownの分類や野畑らの分類によるSingle-Eventに属する文書集合を処理の対象とする．</section>
  <section title="Support Vector Machine に基づく複数文書からの重要文抽出手法"/>
  <subsection title="SVM による文のランキング">SVMは，Vapnikによって提案された2値分類のための教師あり学習アルゴリズムである．近年，様々な自然言語処理のタスクに適用され，その有効性が報告されている．SVMは既に自然言語処理の分野でもよく知られているので，本稿では詳しい説明を省略する．解説記事などを参照されたい．SVMでは，学習データをx_i(1in)としたときに，テストデータxを判別する判別関数f(x)=sgn(g(x))が以下の式で与えられる．w_i，bは定数である．ここで，w_i0となるベクトルはサポートベクトルと呼ばれ，学習データ中の正例，負例を代表する．結局，判別関数はサポートベクトルのみで記述される．K(x_i,x)はカーネル関数と呼ばれる．様々なカーネル関数が提案されているが，本稿では多項式カーネル(式2)を用いる．重要文抽出は，要約率で指定された重要文の数をNumとした時に，重要度の高い上位Num件の文を重要文とみなし，それ以外を非重要文と見なす2値分類問題と考えることができる．しかし，重要文抽出では，指定された要約率に応じた数だけ文を抽出する必要がある．判別関数f(x)を用いて重要文であるかどうかの判断を行った場合には，重要文と判定された文の数が要約率で指定された文の数をみたすとは限らず，問題となる．そこで本稿では，入力となる複数文書集合に含まれる全ての文に対してg(x)の値を用いてランキングを行い，指定された要約率をみたすように文を抽出する．</subsection>
  <subsection title="素性">複数文書からの重要文抽出は，話題に関する文書集合を連結して1文書とみなせば，従来の単一文書からの重要文抽出と同等である．しかし，文書集合中の任意の文が，それが属する文書において重要かどうかという観点だけでなく，文書集合全体において重要かどうかという観点も扱う必要がある．よって本稿では，1文書のみで決定することのできる素性(単一文書用素性)と文書集合が与えられたときに決定することのできる素性(複数文書用素性)の2種の素性を用いる．以下に詳細を述べる．また，素性ベクトルx_jの各要素は0か1の2値となるようにx_jを定義した．2値とならない素性は，[0,1]の値に正規化し，その後，正規化した値が[0,1]を10分割した区間[0.0,0.1),[0.1,0.2),,[0.9,1.0]のどこに属するかを表す10次元の2値ベクトルに変換した．たとえば，文S_jのある素性F(S_j)が0.75であれば，これがベクトル0000000100に変換され，素性ベクトルx_jの要素の内の10個となる．こうして，最終的に，各文の素性ベクトルx_jの次元は583となる．</subsection>
  <subsubsection title="単一文書用素性">従来より，単一文書からの重要文抽出において，多くの文の素性が過去の研究により報告されている．本稿ではこうした素性を参考にするだけでなく，文に出現する固有表現と係り受け構造を考慮したTFIDFを文の素性として導入した．</subsubsection>
  <subsubsection title="複数文書用の素性">任意の文S_jに対し，複数の文書が与えられた場合に定義できる素性として，以下の3種の素性を定義した．</subsubsection>
  <section title="評価実験"/>
  <subsection title="コーパス">まず，評価実験のために毎日新聞99年から12個の話題に関連する文書集合を記者経験のある人物1名が作成した．話題に関連する文書は，基本的に各話題の開始記事か続報記事であり，コラムなどは含まれない．表にデータの詳細を示す．次に，それぞれの文書集合の総文数に対して10,%，30,%，50,%の要約率を設定し，重要文抽出による要約の評価用データを人手によって作成した．重要文抽出データの作成には，新聞記事の編集などに深くかかわったことのある6名があたり，1つの話題に対して異なる3名によるデータを作成した．それぞれをセットA，セットB，セットCとよぶ．まず，被験者が抽出した重要文間の一致率，つまり，表の重要文数に対する被験者間で共通な重要文の割合を調べた．次に，被験者間の重要文の一致をKappa統計値(K値)で調べた．詳細を表に示す．K値の解釈については，表となる．表より，被験者間で一致する重要文の割合は，要約率が高くなるにつれ大きくなる．これは，要約率が高くなるにつれ，被験者が抽出する文の数も多くなるので当然と言える．2つのセットの組み合わせでは，BとCの一致の割合が高い．これに比べ，AとCでは一致の割合は低い．しかし，K値でみた場合には，低い要約率の方が被験者間の一致に対する信頼性は高いという結果となった．表より，信頼性が高いとは言えないが，10,%の要約率では適度(MODERATE)な一致であると言える．30,%，50,%の要約率では信頼性は低くなる傾向にある．過去の重要文抽出の研究例である野本らのデータでは，報道記事の10,%要約率におけるK値は0.34であった．よって，単一文書，複数文書という違いはあるが，低い要約率におけるデータの信頼性は本稿のデータがやや高い．</subsection>
  <subsection title="実験結果と考察">提案手法の有効性を検証するために，先に説明したデータセットを用いて評価実験を行った．Lead手法，TFIDF手法を比較手法として提案手法の性能評価を行った．Lead手法は文書の先頭から順に与えられた要約率をみたすまで文を抽出する手法である．ここで，複数文書要約におけるLead手法をどう定義するかが問題となる．本稿では，それぞれの話題に含まれる全ての文に対して3章で説明したPosdを計算し，その値の大きい文から順に与えられた要約率をみたすまでを重要文として採用した．TFIDF手法としては，話題に関する文書集合に特徴的な単語のみに着目した手法である_Eを用いた．Lead手法と同様に値の大きい文から順に要約率をみたすまでを重要文として抽出した．この手法を以下TFIDFと略記する．提案手法では，2次の多項式カーネルを用い，コストパラメータはC=0.001に設定した．g(x)の値が大きい文から順に要約率をみたすまでを重要文として抽出した．以下，この手法をSVMと略記する．プログラムにはTinySVMtaku-ku/software/TinySVMを利用した．なお，評価指標はTSCの重要文抽出タスクに従った．つまり，文書集合に対して要約率によって抽出すべき文の数を設定し，各手法がその数だけ抽出した重要文に含まれる正解重要文の数の割合(Precision)で評価を行う．いま，システムが抽出した重要文の数をa，システムが抽出した重要文のうち正解の数をbとすると，=b/a100となる．[tb]table*</subsection>
  <subsubsection title="各手法の性能比較">表~にそれぞれの手法の各要約率における重要文の抽出精度を示す．なお，SVMはA〜Cの各セットに対して，学習用の11話題とテスト用の1話題に分けて評価を行い，これを12回繰り返した結果の平均値である．表~より，どのセットと要約率の組み合わせにおいてもSVMの抽出精度が高い．10,%の要約率では，SVMに続いてLead手法，TFIDFの順となり，30,%，50,%の要約率では，TFIDF，Lead手法の順となる．特に，SVMはデータの信頼性が高い10,%の要約率において，他の2手法との抽出精度の差が大きい．利用したデータや素性が異なるため，正確な比較とは言えないが，Lead手法とSVMの差は単一文書(TSCの報道記事)の場合と比較して大きくなっている．また，被験者間で一致した重要文に対して各手法が抽出した重要文の占める割合を調べた．表〜表にその結果を示す．なお，SVM(A)，SVM(B)，SVM(C)はそれぞれA，B，Cによる正解を学習に用いた結果を表す．各表より，どの正解セットの組み合わせに対しても，被験者間で共通な重要文に対する各手法の抽出した重要文の占める割合はSVMが高い．特に，10,%，30,%の要約率で他の2手法との差も大きい．また，セットA，Cを学習に用いた場合が，セットBを用いた場合よりもやや高い割合であることがわかる．今回のデータセットの中でK値の高い組み合わせ，BCの要約率10,%，ABCの要約率10,%においてもSVMは高い割合で被験者間で共通な重要文を抽出しており，他の手法との差も大きい．以上より，提案手法はLead手法，TFIDFと比較して成績が良いことがわかった．さらに，被験者間で一致する重要文についても，提案手法は他の手法よりも高い割合で抽出できていることがわかった．</subsubsection>
  <subsubsection title="有効な素性に関する考察">[tb]table*[tb]table*本稿で用いた各素性の有効性についての考察を行う．2次の多項式カーネルを用いた場合，テストデータをx=(x[1],,x[J]])とすると，g(x)は，式(1)の内積を展開して計算すると以下の式となる．更に，xが2値ベクトルであることを利用すると以下のように書き直すことができる．ただし，[W_0=b+_i=1^nw_i,~~~W_1[k]=3_i=1^nw_ix_i[k],~~~W_2[h,k]=2_i=1^nw_ix_i[h]x_i[k]]である．ここで，W_1[k]は，単独の素性kに対する重み，W_2[h,k]は素性の組hkに対する重みである．この時，判別関数g()はk，hkという素性に関するスコア関数と考えることができる．よって，W_1[k]，W_2[h,k]の絶対値の大きい素性k，hkはスコアに与える影響が大きい素性であり，重要文の判定に影響を与える．セットA〜Cの全てのデータを用いて学習した結果から，絶対値の大きい上位10個の素性を表，表に示す．表は，文が重要文となるために必要な素性の一部を示しており，表に示す素性を含む文は重要文となる場合が多い．要約率10,%では，文が文書の先頭付近に出現することを表す素性に加え，以下の素性の組み合わせに高い重みが与えられていることがわかる．TFIDF値(バリエーションを含む)が高いことを表す素性記事のタイトルとの類似度が高いことを表す素性固有表現(DATE，LOCATION，PERSON)が出現することを表す素性文末表現が叙述や過去であることを表す素性これは，文書集合を構成する記事の多くが報道記事であるため，文書の先頭付近に話題に関する重要事項が客観的に記述されており，それを人間が重要文として抽出する傾向があるからである．特に，実験に用いた文書集合はある話題(出来事)に関する文書であるので，その時系列情報を表す固有表現(DATE)や場所の情報を表す固有表現(LOCATION)が重要であることがわかる．また，特定の人物に関する話題も多いので人物名の固有表現(PERSON)も重要である．要約率30,%でも要約率10,%の場合とほぼ同等の傾向であるが，セットAに関してはタイトルとの類似度が高いことを表す素性の重要度が増している．また，全てのセットに共通して文書のジャンルを表す素性が重要な素性として新たに加わっている．要約率50,%では，要約率10,%，30,%の場合と異なり，特定の助詞が出現することを表す素性が単独で高い重みを獲得している．「は」や「が」は大胆な省略がしばしば行われる新聞記事において，新たな情報を導入する際に用いられることが多いからであると考える．一方，表は，重要文らしさのスコアを下げる素性の一部を表している．上位を占めているものをみると，文書の先頭付近に出現しながら重要でない文に特徴的な素性に高い重みがついていることがわかる．文書の先頭付近に出現する文でも全てが重要文となるわけではないことを示している．文書の位置以外の実数値(スコア)を取る素性はその値が小さい場合には，重要文とならない傾向が強い．以上より，各セットにより，わずかに違いはあるが，重要文であるために必要な素性は，文の位置が文書の先頭付近であること，固有表現が出現すること，TFIDFのスコアが高いこと等の組み合わせであることがわかった．更に実数値をとる素性はその値が低い場合には重要文とならない場合が多いこともわかった．また，本稿で新たに導入した複数文書用の素性である_Eや_Cに対しても高い重みが与えられており有効性がわかった．</subsubsection>
  <subsubsection title="複数文書用の素性の有効性">本稿で用いた複数文書用素性の有効性についての詳しい考察を行う．評価実験に用いた素性から3.2.2節で説明した複数文書用素性を取り除いた後に学習と評価を行った．SVMの抽出精度を表，図〜図に示す．なお，図中の1は，2は_E，3は_C，4はに対応する．表，図〜図より，全体の傾向としては，複数文書用の素性を取り除くことによって抽出精度が低下している．特に10,%，30,%の要約率ではその傾向が強い．ただし，複数文書用の全ての素性を取り除くよりも2つか3つの素性の組み合わせを取り除いた場合に最も抽出精度が低下している．特にセットCはどの要約率においても，TFIDFのバリエーションを組み合わせて素性を取り除いたときに抽出精度の低下が大きい．これに対し，セットA，セットBでは，セットC程大きな抽出精度の低下はみられないが，文書のジャンルと組み合わせて素性を取り除いたときに抽出精度の低下が大きい．また，セットCの要約率10,%では最も低い抽出精度の時には，Lead手法よりもわずかに低い成績であったが，それ以外の場合では，最も低い抽出精度であってもLead手法より高い成績であった．一方，セットBの10,%要約率，セットAの50,%要約率ではある組み合わせの素性を取り除くことによって，約2,%の抽出精度の向上がみられた．複数文書用の全ての素性を取り除いた場合には，10,%，30,%の要約率では表よりもやや抽出精度が低下し，50,%の要約率ではほぼ同等の抽出精度である．一般的には，取り除く素性の数を増やすことによって抽出精度が低下することが予測されるが，実験結果では逆に抽出精度がわずかながら向上するなど揺れがみられた．これは，データ(話題数)の規模が小さく分散が大きいことと実験に用いた素性間に従属関係があることが原因であると考える．例えば，Postは，Posdとの関連が強く，_E，_Cといった素性は単一文書のTFIDFとの関連が強い．このように従属関係にある素性がある場合には，一方の素性を取り除いても他方が残っている場合には抽出精度が低下しないことも考えられる．以上より，複数文書用の素性を組み合わせて取り除くことで抽出精度の低下が起ること，複数文書用の全ての素性を取り除くことでわずかであるが抽出精度の低下が起ることがわかった．この結果より，本稿での評価実験において，複数文書用の素性を用いることは効果は小さいが有効であることがわかった．複数文書用の素性の効果が小さかった原因としては，対象とした文書集合に含まれる文書がすべて単一の話題を主題としている文書であったということが考えられる．たとえば，「奈良で最古の貨幣出土」という話題を考えた場合，対象文書集合に含まれる全文書は「奈良で最古の貨幣出土」という話題を主題としており，各文書における重要文がそのまま文書集合全体での重要文になる可能性が高い．このように単一文書での重要文が複数文書での重要文になることが多い場合では，複数の文書であることを考慮することの効果が小さいと考える．</subsubsection>
  <section title="冗長性削減の有効性">一般的に，複数文書からの重要文を抽出した場合，抽出された文間で内容が重複する可能性があるということが言われている．重要文として抽出された文集合からこのような冗長性を削減する方法として，Carbonellらは，MaximumMarginalRelevance(MMR)という指標を用いて，ある観点でランキングされた文に別の観点を導入し，再ランキングする手法を提案している．本稿でもMMRを使った場合にSVMの重要文の抽出精度がどのように変化するかを調べる．MMRを用いた文の再ランキングアルゴリズムを図に示す．Rは文集集合に含まれる文の集合を表し，Aは出力となる文集合を表す．s(x)は，シグモイド関数s(x)=1/(1+(-x))を表し，=1とした．s(g(S_i))は，式(1)の値を0〜1に正規化した値となる．(S_i,S_j)は，文S_iとS_jの単語の重複度をcosinemeasureで表した指標である．3.2.1節のタイトルとの類似度と同様に計算する．ここでのMMRはSVMの判別関数の値から既に選択した文との重複度をペナルティとして引いたものである．はそれぞれの項の重みを決めるパラメータである．MMRを用いることで，冗長性の低い(重複の少ない)文集合を得られることが期待できる．図にを1〜0.8まで0.05刻で変化させた場合のSVMの抽出精度を示す．図より，どのセットに対しても10,%，30,%の要約率ではSVMの抽出精度は低下するだけであり，MMRが有効でないことがわかる．これは，10,%，30,%の要約率では，SVMによる抽出結果に文単位での冗長性が無いことを示している．複数の文書からの重要文抽出では冗長性を削減することが有効であるといわれていたが，今回の実験では10,%，30,%の低い要約率では有効でないという結果となった．この傾向はSVMだけでなく，Lead手法，TFIDFでも同様であった．このような結果の原因として，重要文の抽出もととなる文集合に文を単位とした冗長性が少ないため，抽出された文にも結果として冗長性が少なかったということが考えられる．特に，評価実験の対象とした文集合が全て単一の情報源(毎日新聞)から得られたものであることの影響が大きい．このような文を単位とした冗長性が少ないデータに対してMMRが及ぼす悪影響の原因について考える．(S_i,S_j)は2文間に共通する単語に依存する．ここで，ある文集合において全く冗長性が無い(文の意味的な内容に重複がない)ことをどの2文間にも共通する単語が無いことと捉える．この場合，(S_i,S_j)は常に0となり，ランキングに対するMMRの悪影響は無い．しかし，実際には，文の意味としては異なるが，共通する単語は存在するような文の組は多数存在する．よって，(S_i,S_j)が0とならず，再ランキングに悪影響を及ぼす．ただし，複数の情報源から得た文集合であれば，類似度の高い2文はほぼ同一の意味を持つ傾向が強いと予想されるので，MMRによる再ランキングは有効に働くと考える．一方，50,%の要約率ではわずかではあるが，抽出精度の向上が見られた．特に，SVM(C)では1.5,%程度，抽出精度が向上している．以下にSVM(C)においてMMRが有効に働いた例を示す．上の文が正解文として残った文で下の文が上の文に対して類似していることで削除(下位にランク)された文である．16、チェルノブイリ原子力発電所を2000年までに閉鎖するというウクライナが行った新たな約束を歓迎する。また、声明には、ウクライナのチェルノブイリ原子力発電所を来年までに閉鎖することを改めて確認、金融犯罪への取り組み強化も盛り込んだ。このように2文間に共通する単語が多く，意味的にも類似した文の組がある場合には，MMRは有効である．先にも述べたが，今回の実験に用いたデータにはこうした例は少ない．よって，多数の文を抽出する50,%の要約率でしか効果が確認できなかったと考える．ただし，文を単位とした冗長性は少ないが，語句単位での冗長性は数多く見られた．一例を以下に示す．このように語句を単位とした冗長性は多く存在するので，単一の情報源を対象とした場合には，文を単位とした冗長性ではなく，語句を単位とした冗長性を削減する手法を考える必要がある．</section>
  <section title="まとめ">本稿では，機械学習手法の1種であるSupportVectorMachineを用いた複数文書からの重要文抽出手法について述べた．評価実験の結果，提案手法がLead手法，TFIDF手法よりも重要文の抽出精度が高いことを実証し，有効性を示した．また，わずかではあるが，複数の文書を考慮した素性を用いることで重要文の抽出精度が向上することがわかった．さらに，単一の情報源から得た複数の文書を対象とした場合，低い要約率では文を単位とした冗長性の削減法(MMR)が有効でないことがわかった．今後の課題としては，複数の情報源から得た複数文書を対象とした場合のMMRの効果の確認，文を単位とした冗長性だけでなく，語句を対象とした冗長性削減手法の研究がある．</section>
</root>
