<?xml version="1.0" ?>
<root>
  <title>日英新聞の記事および文を対応付けるための高信頼性尺度</title>
  <author>内山将夫井佐原均</author>
  <jabstract>大規模な日英対訳コーパスを作ることを目的として，1989年から2001年までの読売新聞とTheDailyYomiuriとから日英記事対応と文対応とを得た．そのときの方法は，まず，内容が対応する日本語記事と英語記事とを言語横断検索により得て，次に，その対応付けられた日英記事中にある日本語文と英語文とをDPマッチングにより対応付けるというものである．しかし，それにより対応付けられた記事対応や文対応には，間違った対応(ノイズ)が多く含まれる．そのため，我々は，本稿において，そのようなノイズを避けて，正しい対応のみを得るための信頼性の高い尺度を提案し，その信頼性の評価をした．実験の結果，我々の提案した尺度を用いることにより，良質な記事対応や文対応が得られることがわかった．また，その数は，良質な記事対応は約4万7千であり，文対応は，1対1対応が約15万，1対1対応以外が約3万8千であった．これらは，現時点で一般に利用できる日英2言語コーパスとしては最大のものである．</jabstract>
  <jkeywords>日英対訳コーパス，記事アライメント，文アライメント</jkeywords>
  <section title="">*付録節の実験より，比較的良質と推定される文対応は，1対1対応が約15万あり，1対1対応以外が約3万8千あることがわかった．更に，そこから，日英それぞれの文末が句点やピリオドなどで終了しているものについて，1対1対応の上位15万対と1対1対応以外の上位3万対とを一般に公開していることを節で述べた．本付録では，この公開されている部分の文対応のサンプルと，公開されてはいないが，公開されている部分と公開されていない部分との境界付近にあるサンプルとを示す．公開されている部分のサンプルを示すことにより，どのような文対応が比較的良質とされているかの目安がつき，境界付近にあるサンプルを示すことにより，公開されている部分の文対応の最低品質の目安がつく．なお，節で例示している日英対応を含む記事対応から得られる文対応は，1対1対応についても1対1対応以外についても，公開されている部分には入っていない．このことは，を利用して文対応をソートすることにより，節で示したような直訳とはいえないような文対応は，下位に位置付けられることを例証している．</section>
  <section title="はじめに">日英対訳コーパスは，機械翻訳などの自然言語処理において必要であるばかりでなく，英語学や比較言語学，あるいは，英語教育や日本語教育などにとっても非常に有用な言語資源である．しかしながら，これまで，一般に利用可能で，かつ，大規模な日英対訳コーパスは存在していなかった．そのような背景の中で，我々は，比較的大規模な日本語新聞記事集合およびそれと内容的に一部対応している英語新聞記事集合とから，大規模な日英対訳コーパスを作ることを試みた．そのための方法は，まず，内容が対応する日本語記事と英語記事とを得て，次に，その対応付けられた日英記事中にある日本語文と英語文とを対応付けるというものである．ここで，我々が対象とする日本語記事と英語記事においては，英語記事の内容が日本語記事の内容に対応している場合には，その英語記事は，日本語記事を元にして書かれている場合が多いのであるが，その場合であっても，日本語記事を直訳しているわけではなく，意訳が含まれていることが多く，更に，日本語記事の内容の一部が英語記事においては欠落していたり，日本語記事にない内容が英語記事に書かれている場合もある．また，記事対応付けを得るための日本語記事集合と英語記事集合についても，英語記事集合の大きさは日本語記事集合の大きさの6,%未満であるので，日本語記事の中で，対応する英語記事があるものは極く少数である．そのため，記事対応付けおよび文対応付けにあたっては，非常にノイズが多い状況のなかから，適切な対応付けのみを抽出しなくてはならないので，対応の良さを判断するための尺度は信頼性の高いものでなくてはならない．本稿では，そのような信頼性の高い尺度を，記事対応付けと文対応付けの双方について提案し，その信頼性の程度を評価する．また，作成した対応付けデータを試験的に公開したときの状況についても述べ，そのようなデータが潜在的に有用な分野について考察する．以下では，まず，対応付けに用いた日英新聞記事について概要を述べ，次に，記事対応付けの方法と文対応付けの方法を述べたあとで，それぞれの対応付けの精度を評価する．最後に考察と結論を述べる．また，付録には，実際に得られた文対応の例を示す．</section>
  <section title="対応付けに用いた日英新聞記事">対応付けの元データは，日本語記事は「読売新聞」，英語記事は「TheDailyYomiuri」であり，それぞれ「読売新聞記事データ」における1989年9月から2001年12月までの記事を利用した．この期間における年間の記事数は，日本語記事は10万から35万程度であり，英語記事は4千から1万3千程度である．また，総記事数は，日本語記事は約200万であり，英語記事は約11万である．このように，英語記事の方が少ないので，対応付けにおいては，各英語記事に対応する日本語記事を求めることにした．記事のメタ情報として，TheDailyYomiuriには，1996年7月中旬から，「本紙翻訳=Y/N」という情報が各記事に付いている．これは，その英語記事を書くにあたって，読売新聞の記事を元にしたかどうかという意味であるので，1996年7月中旬からは，「本紙翻訳=Y」である英語記事についてのみ，対応する日本語記事を求めることにした．このときの英語記事の数は35318である．一方，1996年7月中旬以前には，そのような情報はないので，全ての英語記事について対応する日本語記事を求めることにした．このときの英語記事の数は59086である．なお，以下では，1996年7月中旬以前の記事集合を「1989-1996」と書き，1996年7月中旬以降の記事集合を「1996-2001」と書くことにする．1989-1996については，全英語記事を利用するため，1996-2001と違って，そもそも，各英語記事について対応する日本語記事がない場合がある．そのため，どのくらいの英語記事に，対応する日本語記事があるかを推測するために，「本紙翻訳=Y」の割合を，1997年から2001年の記事について調べたところ，67.9,%であった．対応を求めるにあたって，各英語記事に対応する日本語記事は，互いに近い日付であると考えられる．そのため，各英語記事について，その日付の前後2日の範囲の日本語記事の中から対応する記事を見付けることにした．このとき，1日分の英語記事について，日本語記事は5日分があるが，このときの平均記事数は，1989-1996については，英語記事が24，日本語記事が1532，1996-2001については，英語記事が18，日本語記事が2885である．このように，非常に曖昧性があり，かつ，対応記事も場合によっては存在しないという，ノイズの多い状況のなかから対応記事を見つける必要があるので，信頼性の高い記事対応(評価)尺度が必要である．また，文対応についていえば，たとえ記事同士が対応していたとしても，その対応は，直訳関係にあるものは少なく，どちらかというと，日本語記事を材料として英語記事を書いたというような状況である．たとえば，以下の例では，英語と日本語とで，e1，e3，e4とj1，j2，j3，j4とによる3対4に複雑に絡みあう対応があり，その間にe2とj5による対応がある．このような文対応は，人間の観察者(たとえば，日英記事のスタイルを比較研究しているような人)にとっては価値があるが，文対応の結果を自然言語処理，たとえば，機械翻訳に利用しようとしている場合には，今のところは，有用性は限定されている．そのため，なるべく直訳同士にあるような文対応を抽出したいのであるが，このような状況から直訳に近い文対応を抽出するためには，信頼性の高い文対応(評価)尺度が必要である．</section>
  <section title="対応付けの方針">これまで，節で，日英対訳コーパスが必要とされてていることを述べ，また，節において，対応付けの元となる日英新聞記事に付いて述べた．本節では，これらの節に基づいて，本稿における，記事対応付けおよび文対応付けの方針について述べる．それは以下の2点である．まず，日英記事対応付けと文対応付けとは，本稿における目的ではあるが，そのような対応付けをすること自体の目的は，その対応付けの結果を利用して，機械翻訳なり英語教育なりに役立てることである．そのため，対応付けについては，もし，既存の言語資源および手法を利用することにより，ある程度の量と精度の対応付けが得られるなら，あえて新しい言語資源や手法を開発することなく，既存の言語資源や手法を有効に利用する．しかし，対象とするコーパスには，多くのノイズがあるため，既存の言語資源や手法をそのまま利用した場合に得られる対応付けには，間違った対応付けも多く含まれる．そのため，その対応付けのなかから，良さそうな対応付けのみを抽出するための信頼性の高い尺度を考える．こうした場合には，対象とするコーパスに潜在的に存在する対応付けのうちで，既存の言語資源や手法により抽出されなかったものは利用できない，そのため，対応付けの再現率は低い可能性がある．しかし，良さそうな対応付けとして抽出されたものの精度は高いことが期待できる．つまり，上記の方針は，再現率よりも精度を重視するということである．以下，この方針に基づき，節と節では，既存の言語資源や手法に基づいて記事対応と文対応とを取る方法について述べ，節では，得られた対応付けの中から良さそうな対応付けを得る尺度について述べる．</section>
  <section title="記事対応付けの方法">記事対応付けは，言語横断検索の枠組で行なう．つまり，英語記事を質問とし，それに関連する記事を日本語記事データベースから検索することにより，与えられた英語記事と対応する日本語記事を見付ける．このとき，一般に，質問である英語記事を日本語に変換するか，あるいは，データベースである日本語記事を英語に変換する必要がある．本研究では，データベースである日本語記事を英語(の単語集合)に変換した．そうした主な理由は，手元にある言語資源が日英方向の変換に便利だったからである．</section>
  <subsection title="日本語記事の英単語集合への変換">我々は，辞書引きに基づいて日本語記事を英単語集合に変換することにした．利用した日英辞書は，EDR日英対訳辞書，EDICT(一般的な日英対訳辞書)，ENAMDICT(固有名詞の日英対訳辞書)であるjwb/edict.html．これらの辞書の見出し語に対して，IPADIC(version2.4.4)の品詞体系を付与し，茶筌(version2.2.8)の追加辞書として利用した．追加したエントリ数は，EDR日英対訳辞書が約18万，EDICTが約6万，ENAMDICTが約22万である．こうすることにより，茶筌の解析結果から容易に日英対訳辞書のエントリがアクセスできるようになる．たとえば，「あおぎ見た月」は，追加辞書なしの状態ではと形態素解析される(形態素情報の一部を省略)が，追加辞書ありの状態ではのように解析され，特に工夫をせずとも，複合語である「あおぎ見る」の訳語として「lookup」「faceupwards」「lookupto」「respcet」「admire」などが得られる．また，この方法によると，「くすの木台に行く」を形態素解析した場合のように，辞書にない単語に起因する解析誤りである「くす/の/木/台/に/行く」のようなものも「くすの木台/に/行く」として解析でき，かつ，「くすの木台」の訳語として「Kusunokidai」も容易に得られる．このように，IPADICを増強することにより，解析誤りを避けながら，容易に日英辞書の辞書引きができると共に，複合語や固有名詞の翻訳という言語横断検索において重要な作業も同時にできるため，この方法は有用である．このようにして日本語の各単語(もしくは複合語)において，その品詞が内容語(主に名詞)に相当するものから英訳語を得て，そこから簡単なヒューリスティクスにより主辞を抽出し当該日本語単語の変換結果としたが，このとき，各単語についてその全ての訳語の主辞全てを変換結果として採用するとすると，訳語の主辞のなかには当該文脈の訳として適当でないものもあるため，検索結果に悪影響を与えると考えられる．そのため，なるべく，訳語として適当なものだけを変換結果として利用したい．そうするためには，訳語の曖昧性を解消すれば良いのだが，それを正確にするのは困難である．そのため，ここでは，ヒューリスティクスとして，まず，訳語の主辞の中から，より多くの訳語に含まれているようなものを優先し，次に，同順位のものについては，その訳語の主辞に対応する日本語単語を含む日本語記事の年と同年の英語記事において，その訳語の主辞を含む英語記事数(documentfrequency,df)が多いような訳語の主辞を優先することにした．そして，このヒューリスティクスにより優先付けられた上位2個のみを変換結果として利用した．なお，dfが0であるような訳語の主辞は，最初から，候補に含めない．</subsection>
  <subsection title="英語記事からの日本語記事の検索">一旦，日本語記事が英単語集合に変換されてしまえば，あとは，通常の情報検索と同様にして，質問として与えられた英語記事に最も類似するような日本語記事(の英単語集合への変換結果)を検索することができる．そして，その日本語記事をもって対応記事とする．このときの英語記事と日本語記事の類似度としては，を利用した．は，情報検索に有用な尺度として知られており，TREC(TextREtrievalConference)やNTCIRntcadm/index-en.html(NII-NACSISTestCollectionforIRSystems)でも，その有効性は実証されている．ここで，質問である英語記事Qと日本語記事の変換結果Dとの類似度(D,Q)は以下である．(D,Q)=_TQw^(1)(k_1+1)tf/K+tf/(k_3+1)qtf/k_3+qtf/displaymath以上をまとめると，記事対応付けにおいては，日本語記事を英単語集合に変換し，その変換結果に対して，英語記事を質問として情報検索をし，その結果のによる類似度が1位の日本語記事を，英語記事の対応記事とする．この対応付けられた日英記事中にある日本語文と英語文との対応付けは，次節で述べる方法で行なう．</subsection>
  <section title="文対応付けの方法">日英記事における文間の対応はDPマッチングで求めた．DPマッチングで文対応を得るアルゴリズムの簡潔な記述にはを参照せよ．ここでは，日本語文(集合)から得られた内容語集合Jと英語文(集合)から得られた内容語集合Eとの類似度，(J,E)についてのみ述べる．(J,E)=(JE)+1|J|+|E|-2(JE)+2displaymathである．ただし，(x)を文Xにおけるxの頻度とすると|X|=_xX(x)である．また，(JE)は，J中の単語とE中の単語との1対1対応を，日英および英日対訳辞書に基づき求めた場合の集合をJE=(j,e)|jJ,eEとすると，(JE)=_(j,e)JE((j),(e))である．JとEとJEとは，以下のようにして求めた．まず，辞書引きにあたって，日本語文については，茶筌により形態素解析をした結果から，内容語および複合語を抽出した．これがJである．また，英語文については，Brill'sTaggerにより品詞付けをし，基本形をWordNetwn/のライブラリを利用して求め，その結果から，内容語と複合語を抽出した．これがEである．次に，JEについては，ある(j,e)の組(jJeE)について，もし，jの訳語にeがあるか，eの訳語にjがある場合には，(j,e)には対応の可能性があるとし，そのような全ての対応の可能性のなかから，訳語の曖昧性の低いほうから1対1に対応付けていった．すなわち，(j,e)の曖昧性として，jの訳語の数を採用し，それの小さいものから対応付けをしていくのだが，既に，(j,e)のどちらかでもが選ばれている対応はスキップする，という方法を採用した．なお，このときの訳語の対応付けに用いた対訳辞書は，EDR日英対訳辞書とEDR英日対訳辞書を統合して生成した日英および英日対訳辞書である．これらの辞書において，日英方向のエントリ数は約32万，英日方向のエントリ数は約37万である．以上のように定義された類似度を用いて，文対応を付けたが，このとき，文対応付けに用いたプログラムでは，DPマッチングにおける文間の対応としては，1対nもしくはn対1，ただし，1n6しか許していない．この条件下で，文対応プログラムの精度を，人手により文対応が付けられている，白書データに適用することにより求めた．白書データには，18対の日英ファイルがあるが，そのうち，訳抜け(0対nもしくはn対0の文対応)の数が3以下の12ファイルを対象とした．これらのファイル対について，日本語文の平均数は413，英語文の平均数は495である．このとき，再現率の平均は0.982，適合率の平均は0.986である．これより，このプログラムの精度は十分に高いと言える．なお，再現率=プログラムの得た文対の中で正しい対の数正しい対の総数displaymath適合率=プログラムの得た文対の中で正しい対の数プログラムが推定した対の総数displaymathただし，1対nの文対応からは，n個の対が得られる．たとえば，文J_1と文E_1,E_2,E_3が対応しているとすると，得られる対は(J_1,E_1),(J_1,E_2),(J_1,E_3)の3個である．我々は，辞書のみに基づいて文対応付けをした．それに対して，は，辞書情報に統計情報を組合せることにより，文対応の精度が向上すると述べている．しかし，我々のプログラムの精度は既に十分に高いので，統計情報は利用しなかった．</section>
  <section title="記事対応尺度と文対応尺度">節と節とにおいて，記事対応の類似度と文対応の類似度とを導入した．しかしながら，これらの類似度のみを利用して記事対応や文対応を付けた場合には，節や節で実験で示すように，十分に精度の高い記事対応や文対応を得ることはできない．そのため，本節では，記事対応と文対応の双方について，新たな尺度を定義する．本研究の主要な貢献は，以下で述べる二つの尺度ととを提案し，その性能を実験により詳細に検討すると同時に，大規模な日英対応付けコーパスを構築し，それを一般に利用可能にした点である．まず，記事対応についてであるが，我々は，節において，日本語記事Jと英語記事Eの類似度として(J,E)を導入した．この類似度は，単語集合間の類似度であるので，文の順序などは考慮できない．そのため，文の順序を考慮できる記事対応尺度として，(J,E)を定義する．これは，JとEとの文対応を(J_1,E_1),...,(J_m,E_m)としたとき，以下の式である．(J,E)=_k=1^m(J_k,E_k)mdisplaymathが高い値となるのは，個々の文対応の類似度が高い場合であるので，そのような場合には，記事としての対応も良いと考えた．次に文対応の良さの尺度について述べる．節で述べたように，我々の文対応付けプログラムの精度は，白書データのように日本語文と英語文とが原文と訳文という関係にあるようなものを対応付ける限りにおいては，高精度である．しかし，節で述べたように，日本語記事と英語記事との関係は，一般には，原文と訳文という関係ではない．そのため，節の方法で文対応付けをした場合には，適切な対応と共に不適切な対応も多く得られる．そのようにノイズの多い状況から，適切な対応のみを抽出するためには，文対応の尺度として，文類似度だけでなく，記事対応の尺度も利用すれば良いと考えた．そのため，日本語記事Jと英語記事Eとの記事対応における，文J_kとE_kとの文対応尺度として，(J_k,E_k)=(J,E)(J_k,E_k)displaymathを定義した．この尺度は，同一記事対応内で文対応を比べる場合には文類似度と同じ順位を与えるが，異なる記事間での文対応の比較では，文類似度だけでなく，記事対応の尺度値も高いような文対応を優先する．</section>
  <section title="記事対応付けの精度"/>
  <subsection title="無作為抽出による精度評価">記事対応付けは，各英語記事との類似度が高い日本語記事を検索することによりなされる．このとき，類似度1位の日本語記事についての記事対応付けの精度を1996-2001と1989-1996とについて表に示す．表において，「評価値」とは，記事対応の良さの人手による判定の評価値であり，その基準は，Aは「記事全体の記述の5〜6割程度以上について意味の対応がとれる」，Bは「2〜3割程度以上5〜6割程度以下について意味の対応がとれる」，Dは「全然違う」，Cは「A,B,D以外」である．「割合」とは，1996-2001と1989-1996のそれぞれから，100記事対応ずつを一様無作為抽出したときに，その評価値であった記事対応の割合である．「下限」「上限」とは，割合の95,%信頼区間の下限と上限である．節で述べたように，1996-2001については，「本紙翻訳=Y」なる英語記事のみを対象したが，1989-1996については，全英語記事を対象とした．そのため，1989-1996の精度は，1996-2001よりも低い．また，1996-2001の精度が1989-1996の精度よりも高いといっても，それでも，評価値Aが約60,%，AもしくはBが約70,%であるので，による記事対応付けの結果をそのまま利用した場合には，ノイズとなる記事対応が多すぎる．我々の観察によれば，評価値がAもしくはBの記事対応は，そこから日英言語表現間の対応が抽出できそうという意味において，有用な記事対応である．このような記事対応のみを抽出するには，による記事対応付けの結果をそのまま全て利用するのではなく，対応の良さにより対応付けの結果をソートし，その上位のみを抽出すれば良い．</subsection>
  <subsection title="ソートした場合の記事対応の精度">記事対応の良さの指標として，とのどちらが適当かを比較した．表と同じデータに対して，それぞれの値の降順により記事対応をソートし，評価値がAもしくはBの場合を正解とし，各順位までにおける正解の個数とその割合とを調べた．それを表に示す．表から，我々は，の方がよりも，記事対応の良さとして適切な尺度であると判断した．の精度の方がの精度よりも高い理由は，節で述べたように，が，と違って，個々の文対応の良さまでも考慮した尺度であるからと考える．</subsection>
  <subsection title="評価値とAVSIM">人手により判定された評価値A,B,C,Dととの対応の程度を調べることを目的とし，表と同じデータに対して，各評価値となった記事対応について，の統計量を求めた．それらを，1996-2001については表に，1989-1996については表に示す．これらの表において，「数」とは，その評価値であった記事対応の数である．また，「平均」とは，そのような記事対応のの平均値であり，「下限」および「上限」は，平均値の95,%信頼区間の下限と上限である．「閾値」は，その評価値であるような記事対応と，次の評価値であるような記事対応とを分けるときに，どので区切れば良いかを示す．たとえば，表では，A判定とB判定とはの値が0.168により分かれる．この閾値は，線形判別分析により求めた値である．また，「有意差」の欄にある「**」と「*」は，それぞれ，その評価値と次の評価値とで平均値に差があるかを，Welch検定により片側検定したときに，その差が，1,%と5,%水準で有意であることを示す．二つの表において，1989-1996のBとCとの区分を除いては，全ての評価値において，各評価値と次の評価値とでは，平均値に有意な差があることがわかる．このことから，は，各評価値を十分に明確に区切ることができると言える．なお，1989-1996では，BとCが分かれていないことについて，その理由を調べた．そうすると，実際，1989-1996では，Cだといっても，記述の重複が，1996-2001のCと比べて，多いものが多かった．定性的には，1996-2001のCは，「Dではない(全然違うわけではない)」という意味でCであり，1989-1996のCは，「Bかもしれない」という意味でCであった．次に，1996-2001と1989-1996とで，同じ評価値を与えられた記事対応のの平均値に統計的に有意な差があるかを調べた．つまり，たとえば，表では，評価値Aの平均値は0.193であり，表では，0.175であるが，この二つの平均値の差が統計的に有意かどうかを両側検定によるWelch検定により調べたところ，有意水準5,%においては，A,B,C,Dいずれの評価値においても有意差はみられなかった．そのため，1996-2001と1989-1996とで，同じ評価値の記事対応は，同じ程度のであると判断した．そのため，は，異なる記事集合を利用した場合であっても，安定して，記事対応の良さを示す指標であると考える．最後に，表と表にある閾値に基づいて，1989-1996と1996-2001とについて，A,B,C,Dであるような記事数を推定した結果を表に示す．表より，評価値がAもしくはBと推定される記事対応は，全体では，46738(=31495+15243)だけある．我々は，約4万7千という記事対応は，訳語抽出などの自然言語処理への応用や，英語教育などへの応用にとって，十分有効に利用できる量であると考える．以上より，は，人手による評価値A,B,C,Dに良く対応した尺度であり，かつ，異なる記事集合においても同一評価値については安定した数値をとる尺度であることがわかった．また，に基づいて記事対応を抽出することにより，約4万7千の良質な記事対応が抽出できることが期待できることがわかった．</subsection>
  <section title="記事対応付けの精度向上の可能性">節で述べたように，は，記事対応の良さを示す信頼性の高い尺度である．そのため，の代り(もしくは重みつき和などによる組み合わせで)，最初からを利用して記事対応を求めれば，節で述べた全体的な精度も向上すると考えられる．しかし，我々は，現時点では，による類似度1位の記事対応についてのみしか，を求めていない．その理由は，10位以内などの比較的少しの記事をみただけでは記事対応精度に顕著な向上がないからであり，かつ，現時点での文対応プログラムの実行速度が遅いからである．今の文対応プログラムでは，一記事あたりの対応を取るために，数秒は掛る．そのため，一位同士の対応についてを得るだけでも，9万4千記事程度なので，数日間は掛かる．したがって，たとえば，100位以内をみるだけでも，数100日間掛かることになる．これは非現実的である．しかし，今後，もっと高速の文対応プログラムを作り，それを利用することにより，より高精度な記事対応が得られるものと考えている．また，今は，各英語記事について，その記事の日付の前後2日の範囲しか調べていないが，記事によっては，5日前のものが翻訳されているものがあった．このようなものまでカバーするためには，もっと広い範囲から対応候補記事を集める必要がある．この2点は，システム全体を効率化しスケールアップすることにより達成可能なので，将来的には実現したい．</section>
  <section title="文対応付けの精度">節で述べたように，たとえ，日英記事間に内容上の対応があったとしても，文間対応があるとは限らないので，対応付けられた記事から得られる文対応はノイズが多いものとなる．そのため，による類似度1位の記事対応全てから得られる文対応全てをにより降順にソートし，その上位のみを利用することにより対応の良いものを抽出することにした．このような文対応の数は，1989-1996と1996-2001を合せた全体で，約130万だけある．なお，ここでの文とは，日本語文については，簡単なプログラムにより，句点などで日本語記事を分割した結果であり，英語文については，MXTERMINATORに対して前処理と後処理を適用して英語記事を分割した結果である．文対応のなかでは，1対1対応が最も重要である．また，文対応といっても，新聞記事には，中見出しなどの，必ずしも文でないものもある．そのため，1対1対応のなかで，文末が句点やピリオドなどで終っているもののみを取り出し，これを特に「1:1」と呼び，その他の対応を「1:n」と呼ぶことにする．1:1の数は，約64万ある．1:nの数は，約66万ある．1:1の精度を求めるために，により降順にソートされた上位30万対応について，3万対応ごとに100ずつを一様無作為抽出した．この各対応について，x/oの2値評価をした．ここで，xは「意味が全然違う」であり，oは「意味が全然違うことはない」である．その結果のx/oの数を表に示す．表から分かるように，順位が下っていくにつれて，xの数が指数的に増加している．このことは，が，効率良く，適切な1:1を上位に順位付けていることを示している．表から，15万対までは十分に信頼できる対応であると言える．なお，15万対までのoの累積の割合は0.982である．次に，1:nの精度を求めるために，により降順にソートされた上位について，表の「1-90000」「90001-180000」「180001-270000」の各範囲について，それらの1:1のの範囲に収まるような1:nの精度を求めた．精度を求めるときには，1:1のときと同様に，各範囲から100対を一様無作為抽出し，x/oの2値評価をした．その結果を表に示す．表より，「1-90000」の範囲の38090個の1:nについては，精度の良い対応であると言える．以上述べたように，により文対応をソートすることにより，1:1と1:nの双方について，上位には，十分に精度の高い文対応が得られる．次に，について，との比較のため，その精度を述べる．比較にあたっては，の降順でソートした上位における精度を調べ，その精度により比較する．まず，1:1についてであるが，の降順により1:1をソートした場合の上位15万対から100対を一様無作為抽出してo/xの判定をした結果は，o数=93・x数=7であった．これを，表に示される，における上位15万対における無作為抽出500対でのo数=491・x数=9と比べると，比率の差の検定を片側検定ですると，有意水準1,%(実際には0.16,%)での方が有意にoの比率が高い．次に，1:nについてであるが，1:1のときと同様に，1:nをの降順にソートし，上位38090対から100対を一様無作為抽出してo/xの判定をした結果は，o数=89・x数=11であった．これを，表に示されるにおける上位38090対における無作為抽出100対でのo数=98・x数=2と比べると，比率の差の検定を片側検定ですると，有意水準1,%(実際には0.49,%)での方が有意にoの比率が高い．これらより，1:1と1:nの双方について，の方が，有用な尺度であると言える．の精度の方がの精度よりも高い理由は，節で述べたように，が，と違って，記事対応の良さまでも考慮した尺度であるからと考える．</section>
  <section title="関連研究">自動的に記事対応を得ることを目的とする研究はいくつかある．そのうち，は，言語横断検索に機械翻訳を利用した場合と辞書引きを利用した場合とを比較しており，再現率が高いとき(多くの記事対応を得たいとき)には，辞書引きの方が有利だとしている．我々も，表のデータの1996-2001についてのみ，シャープ株式会社の機械翻訳支援システムを利用して精度評価をしてみたが，その結果は，統計的に有意ではないが，辞書引きの結果の精度の方が高かったただし，このときには，英語記事を日本語に翻訳し，その翻訳結果を質問として日本語記事からなるデータベースを検索した．これは，本稿でこれまで説明してきた方法である，日本語記事を英語単語集合に変換する方法の逆であるので，厳密な比較ではない．．これらのことから，辞書引きの方が記事対応を得るには適しているのではないかと考えられる．また，は，日経産業新聞について，英語記事と日本語記事との対応付けをしていて，その精度は，97,%と非常に高精度である．しかし，彼らは，同じ方法を，NHKの報道記事の対応付けに対しても適用しているが，その場合の精度は69.8,%であり，彼らの方法が，全ての場合で高精度であるわけではないということも示している．そのため，彼らの方法を読売新聞の記事対応付けに利用した場合にも同様に高い精度が得られるかは明かではない．これらの従来の記事対応を得る研究と我々の研究との主要な違いは次の2点である．まず，記事対応の評価尺度について，我々は，DPマッチングによる文対応付けの結果を利用した信頼性の高い尺度を提案した．それに対して従来の研究はbag-of-wordsに基づいた尺度を利用している．なお，情報検索において，質問文と文書との類似度を求める際にDPマッチングを利用する方法がにより提案されているが，彼らの研究対象と我々の研究対象とは異なるし，かつ，DPマッチングの方法や，評価尺度の定義も異なる．次に，我々は，記事対応の結果から文対応までを，実際に，大規模に得た．は，記事対応の結果から文対応を得ることを構想してはいるが，実際に文対応を得ているわけではない．加えて，我々は，対応付けの結果が一般に研究および教育目的に利用できるようにしているが，これは日英対応付けコーパスとしては初めての試みである．</section>
  <section title="データ公開">我々は，本稿で述べた日英新聞記事対応付けの結果を数値情報としてエンコーディングすることにより，読売新聞とTheDailyYomiuriの記事データを持っている場合には，対応付けの結果が復元できるデータを作った．また，節で述べた文対応について，日英それぞれの文末が句点やピリオドなどで終了しているものについて，1:1の上位15万対と1:nの上位3万対とを，読売新聞社からの許可を得て，生の文として，上記数値データに追加したデータを試験的に公開した．公開した期間は2002年10月23日から2002年11月22日の1ヶ月間であり，公開の情報は，言語処理学会のメイリングリストを通じて流した．その結果，31の機関からデータ入手の申し込みを受けた．それら機関の内訳は，国内が28，国外が3であった．また，企業からの申し込みは4件あり，そのほかの27件は中学・高校・大学もしくは研究機関であった．また，自然言語処理関係の研究機関から15件，その他の機関からは16件であった．それら16件は，言語学関係が13件，中学・高校が2件，また，民間企業で翻訳業務をしている企業からの申し込みが1件あった．これらの内訳から，このような日英対応付けデータが，自然言語処理の研究機関だけでなく，言語学や中学・高校の英語教育などに関わる人にとっても関心の高いものであることがわかる．</section>
  <section title="今後の課題">本稿で述べた対応付けは，節で述べた方針に基づいている．すなわち，既存の言語資源や手法を用いて対応付けをして，その結果から，なるべく対応の良さそうなもののみを抽出するというものである．その結果，節や節で述べたように，上位にソートされた記事対応や文対応については，十分に精度の高い対応が得られた．しかし，ソートの適用対象は，節や節の方法で求められた記事対応や文対応であるので，どんなに精度良くソートしたとしても，最初に求められた記事対応や文対応に含まれているよりも多くの正解対応を得ることはできない．たとえば，記事対応では，により検索された記事対応しか対象としていないため，の検索精度により，抽出できる記事対応の精度は制限される．この記事対応付けについては，節で，を用いることにより，精度が向上すると考えられると述べた．これと同様に，文対応においても，新聞記事に適した文対応付けアルゴリズムを用いることにより，抽出できる，正解である文対応の数が増えるものと考える．そのようなアルゴリズムを考案し，より多くの正解対応を求めることが今後の課題である．</section>
  <section title="おわりに">ノイズの多い日英新聞記事集合から，内容が対応した記事対応と文対応を得るための信頼性の高い尺度を提案した．それら尺度を用いることにより，1989年から2001年までの読売新聞とTheDailyYomiuriとから記事対応と文対応を得た．それらのなかで，比較的良質と推定されるものが，記事対応は約4万7千あり，文対応は，1対1対応が約15万あり，1対1対応以外が約3万8千ある．これらは，現時点で一般に利用できる日英2言語コーパスとしては最大のものである．我々は，今後，この日英対応付けコーパスを，より良質にしていくとともに，このコーパスを実際の応用に利用することを考えている．</section>
</root>
