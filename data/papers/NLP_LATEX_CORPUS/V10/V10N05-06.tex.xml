<?xml version="1.0" ?>
<root>
  <title>異なるコーパスにおける重要文抽出の結果と素性の分析</title>
  <author>野畑周関根聡井佐原均</author>
  <jabstract>本論文では，三種類の異なるコーパスに対する我々の自動要約システムの評価と，その要約データの分析結果について述べる．我々は重要文抽出に基いた要約システムを作成し，そのシステムを用いて日本語・英語双方の新聞記事を対象にした要約評価ワークショップに参加し，良好な評価結果を得た．また日本語の講演録を対象として重要文抽出データを人手によって作成し，そのデータに対して要約システムの実験・評価を行った．さらにシステムの評価結果に加えて，重要文抽出に用いられる主な素性の振舞い・素性の組合せによる重要文の分布の違いなどを各々の要約データにおいて分析した結果を示した．</jabstract>
  <jkeywords>自動要約，重要文抽出，固有表現</jkeywords>
  <section title="はじめに">我々はこれまで，多様なテキストを要約することのできる頑健な自動要約システムの開発をめざして，重要文抽出を基にした要約システムを作成・拡張してきた．その過程で，作成したシステムを用いて日本語・英語双方において新聞記事などの書き言葉を対象にした要約評価ワークショップに参加し，良好な評価結果を得た．また，日本語の講演録を対象として重要文抽出データを人手によって作成し，そのデータに対して要約システムの実験・評価を行った．日本語と英語など異なる言語や，書き言葉と話し言葉など異なる性質をもつテキストを要約するためには，どのような点が共通化できてどのような点を個別に対応する必要があるのかを，実際に要約データにあたって要約手法を適用し，その結果を検討する必要がある．本論文の目的は，これまで行ってきた日本語と英語，また書き言葉と話し言葉のデータそれぞれについて，共通の素性を用いた重要文抽出の結果について示すことと，それらのデータ間での各素性の分布がどのように共通しているか，異なるかを示すことである．我々のシステムは，重要文抽出をベースにして自動要約を行っている．これは，文章全体を1〜2割程度縮める要約ではなく文章を大きく縮めて要約するためには，重要文抽出もしくはそれに類する手法を用いることが必要であると考えたためである．重要文抽出は自動要約に用いられる主要な手法の一つである．文章から重要文を抽出するためには，各文がどの程度重要であるかを示す素性を用意する必要がある．文の位置情報，たとえば文章の先頭にあるものほど重要だとみなす手法は，単純ではあるが現在でも自動要約の主要な手法である．他にも記事中の単語の頻度などの統計的な情報や，文書構造を示す表現などの手がかりなどが用いられている．これらの素性を統合的に用いる手法も研究されており，例えばは人手で重み付けの値を与えることによって，は回帰分析，やはベイズの規則，また，らは決定木学習を用いて複数の情報を統合している．本論文では，これらの論文で示されているように素性を統合的に用いた要約システムの評価結果を示すだけでなく，自動要約に用いられる主な素性の振舞い・素性の組合せによる重要文の分布の違いなどを，性質の異なる3種類の要約データにおいて比較・分析した点に特徴がある．以下では，章において各要約データについて説明し，章において重要文抽出システムの概要を述べ，章において各要約データにシステムを適用した結果の評価を示す．さらに，章においてシステムが用いた素性の各データにおける分布について考察する．</section>
  <section title="要約データ">本研究で用いた要約データは，日本語新聞記事・英語新聞記事・日本語講演録の3種類のテキストデータを対象として作成されたものである．日本語新聞記事の要約データ，英語新聞記事の要約データは，ともに評価コンテストのために作成された公式のデータである．この2種類のデータを対象とすることで，異なる言語に対して用いることのできる要約システムを構築することを意図している．日本語講演録の要約データは，講演音声についての大規模なコーパスを構築するプロジェクトの中で作成された，学会講演の書き起しデータに対して作成されたものである．このようなデータを対象とすることによって，書き言葉と話し言葉それぞれに対応できる要約システムを構築することを意図している．以下，本研究で用いた3種類の要約データそれぞれについて説明する．</section>
  <subsection title="日本語新聞記事の要約データ">TSC(TextSummarizationChallenge)は，自動要約の研究の発展を目的として2001年に開始された自動要約の評価プロジェクトであり，国立情報学研究所によって主催されている評価ワークショップNTCIRのタスクの一つである．TSCは，複数の要約課題を提示して参加者を募り，参加者が作成した個々の自動要約システムを同一のデータに基づいて評価を行い，また自動要約の評価基準自体についての議論，さらに研究者間で共有できる要約データの作成・公開を行ってきている．第1回にあたるTSC2001では，日本語の新聞記事を対象として，A1:重要文抽出型要約，A2:人間の自由作成要約と比較可能な要約，B:IRタスク用要約の3種類の課題が提示された．本論文ではこのうち課題A1で用いられた重要文データを実験に用いた．予備試験，本試験データはそれぞれ30記事あり，ともに社説15記事と報道記事15記事で構成されている．この課題では，予備試験，本試験ともに3種類の要約率(10,%,30,%,50,%)に応じて重要文抽出を行うことが課された．本論文では，TSCで用いられた要約データを「TSCデータ」と呼ぶ．TSCデータは課題で用いられた新聞記事と，要約率ごとに作成されたそれらの記事の要約とから成る．TSCデータは日本語書き言葉要約データの例として章に示す評価結果，章に示す分析で用いられる．</subsection>
  <subsection title="英語新聞記事の要約データ">DocumentUnderstandingConference(DUC)は，米国DARPAの支援の下にNationalInstituteofStandardsandTechnology(NIST)によって実施されている，自動要約の評価プロジェクトである．DUCは日本におけるTSCと同様に，同一のデータに基づく複数の要約システムの評価，要約データの作成・公開を行うことで自動要約の研究の発展を図って行われているプロジェクトであり，2000年に最初のワークショップが行われた後，2001年から本格的に要約課題の提示，自動要約システムの評価が開始され，その結果に対する議論を経て課題内容や評価基準の改良が施されてきている．DUC2001では，英語新聞記事を対象として単一文書の要約・複数文書の要約の2種類の課題が出された．対象とするデータは両課題において共通であり，トレーニングデータとして30記事セット，テストデータとして新たに30記事セットが主催者から配布された．各記事セットには約10記事ずつ含まれており，それらの記事はAP通信やFinancialTimes,LosAngelsTimes,WallStreatJounalなどの新聞から取られている．各記事セットは，例えば「最高裁判事に任命されたトーマス氏についての記事」「ピナツボ火山の噴火についての記事」などの主題ごとに集められた記事から成っている．DUCでは，要約率ではなく語数によって作成する要約の長さが制限された．単一文書の要約では，各記事を100語以内に要約して出力することが課された．複数文書の要約では，各記事セットごとに50語，100語，200語，400語の4種類の要約が課された．DUC2001で用いられたデータのうち，本論文で示す実験では単一文書要約課題のデータを用いた．ただし主催者側から与えられた正解データは，文抽出(extract)データではなく人間が作成した要約(abstract)データであったので，我々はこのabstractデータをもとに記事セット中の対応する文を抜き出し，重要文抽出の正解データを作成した．本論文では，DUCで用いられた要約データを「DUCデータ」と呼ぶ．DUCデータは英語書き言葉要約データの例として章に示す評価結果，章に示す分析で用いられる．</subsection>
  <subsection title="日本語話し言葉の要約データ">話し言葉の要約データとして本研究の実験に用いたコーパスは，国立国語研究所，東京工業大学，通信総合研究所の3団体が共同で構築作業をすすめているCSJコーパス(CorpusofSpontaneousJapanese)から得たものである．CSJコーパスは，学会講演などのモノローグを中心に収集・構築されているコーパスである．本論文では，このCSJコーパスのうち，1999年日本音響学会秋季研究発表会(AS99)の講演から35講演，2000年言語処理学会年次大会(NL00)の講演から25講演の計60講演を取り出して用いた．重要文抽出の実験では，60講演のうち50講演(AS99から30講演，NL00から20講演)をトレーニングデータとし，10講演(AS99から5講演，NL00から5講演)をテストデータとして用いた．重要文抽出を適用するには文境界が与えられている必要があるが，講演の書き起しデータは話し言葉の特性上，書き言葉のようには文の境界が予め与えられていない．このため，三人の被験者(論文の著者は含まない)が全60講演について文境界の検出と重要文抽出のデータ作成をともに行った．文境界においては，さらに各被験者の結果を言語学の専門家が統合して単一の文境界データを作成した．文境界データにおける各講演の平均文数は68.7文であった．一方重要文抽出においては，各被験者における重要文の判断の揺れが大きく，正解データを統一することは困難であったので，章で示す評価結果では被験者の抽出結果を個々に正解とみなして評価している．なお，重要文抽出の要約率は10,%に設定した．本来のCSJコーパスはここで用いたものよりも大規模なコーパスであるが，本論文ではCSJコーパスを用いて作成された要約データを「CSJデータ」と呼ぶ．CSJデータは，日本語話し言葉要約データの例として章に示す評価結果，章に示す分析で用いられる．</subsection>
  <section title="重要文抽出手法の概要">自動要約では，文章中で重要な文を選択するために有効と思われる素性を考案し，それを用いた評価尺度を関数の形で表現し，その評価値の高い文を抽出するという重要文抽出の手法が主に用いられており，本システムでもこの手法を採用している．本章ではこの重要文抽出で用いた評価尺度について説明し，次にしきい値・重み付けなどその他の部分について説明する．TSC，CSJ，DUC各データに特化した部分については，個々に特化した項目を明記する．それ以外で特に対象データについて限定していない記述は，各データに対して共通して用いられた部分である．</section>
  <subsection title="評価尺度">本システムでは，個々の素性についてそれを基にした評価尺度を与える関数を予め定義している．それぞれの情報に対しては，複数の関数を用意しているものがある．それらの関数の選択も，各評価尺度に対する重みと同様，トレーニングデータを用いて行なう．使用した評価尺度は，文の位置情報・文の長さ・単語のtf*idf値・記事の見出し，そして言語的パタンである．各関数の出力したスコアに重みを掛け合せたものの和が，各文の重要度となる．</subsection>
  <subsubsection title="文の位置">本システムでは，文の位置情報に基づく関数を3種類用意した．重要文を抽出する際には，この三つのうちの一つが用いられる．1つ目の関数は，出力すべき文が(N)文であると指定されたときに，記事の先頭から(N)文目までにスコア1をつけ，それ以外は0とするものである：Score_(S_i)(1in)&amp;=&amp;1(i&lt;Nのとき)[-1mm]&amp;=&amp;0()eqnarray*ここで(n)は記事中の文の数を示す．この関数は，最初の(N)文を要約結果とする単純な重要文選択の方法が好成績を納めてきているという事実に基いたものである．2つ目の関数は文の位置の逆数を与えるものである．つまり(i)番目の文に対するスコアは，Score_(S_i)&amp;=&amp;1ieqnarray*となる．この2つ目の関数は先頭に近い程重要であるという点では1つ目の関数と同じであるが，他の評価尺度と組み合わせた際に両者の差が出てくることを意図して定義されたものである．3つ目の関数は，2つ目の関数に手を加え，先頭からの文の位置と末尾からの文の位置を共に用いるものである．つまり，全文数が(n)である記事において，(i)番目の文に対するスコアは以下のようになる．Score_(S_i)&amp;=&amp;(1i,1n-i+1)eqnarray*この関数は，先頭か末尾に近い文ほど重要であるという仮定を表現したものである．</subsubsection>
  <subsubsection title="文の長さ">各文の長さに基づく評価尺度については，以下の3種類の関数を用意した．1つ目の関数は，文の長さをそのままスコアとして与えるものである：Score_(S_i)&amp;=&amp;L_ieqnarray*これは，「長い文ほど重要である」という仮定を表現したものである．2つ目の関数は，長さ(L_i)が一定の値(C)より短い文にはペナルティとして負の値を与えるものである：Score_(S_i)&amp;=&amp;0(L_iCのとき)[-1mm]&amp;=&amp;L_i-C()eqnarray*このペナルティは，極端に短い文は重要文として選択されることが非常に稀であるという観測事実に基いている．3つ目の関数は，1つ目と2つ目の関数を組み合わせたもので，各文の長さをスコアとして与えるが，一定値(C)より短ければペナルティとして負の値を与えるものである：Score_(S_i)&amp;=&amp;L_i(L_iCのとき)[-1mm]&amp;=&amp;L_i-C()eqnarray*この関数は先に挙げた両者の関数の長所を組み合わせることを意図している．TSCデータ・CSJデータにおける評価の際には，文の長さを文字数で表し，トレーニングデータを用いた実験の結果から一定値(C)を20(文字)とした．DUCデータにおける評価の際には，文の長さを単語数で表し，同様にトレーニングデータを用いた実験の結果から一定値(C)を10(単語)とした．</subsubsection>
  <subsubsection title="tf*idf値">この評価尺度は，各文中の単語についてtf*idf値を計算し文のスコア付けを行うものである．tf*idf値は，各記事中の単語(w)の頻度tf((w))と，その単語がある記事群の中で現れた記事の数，すなわち記事頻度df((w))とを組み合わせて計算される値で，記事中のある単語がどの程度その記事特有の単語であるかを示す．記事数DN個の記事群が与えられたとき，最も単純なtf*idf値の計算式は以下のようになる：(w)&amp;=&amp;eqnarray*右辺第二項は特にinversedocumentfrequency(idf)と呼ばれる値である．tf*idf値は，与えられた検索要求に関連する記事をデータベースから検索する情報検索の分野において，記事の特徴を示すための指標として用いられるものであり，検索の精度を向上させるためにいくつか異なるtf*idf値の計算手法が提案されている．その一つは以下のようなものである：(w)&amp;=&amp;-1eqnarray*また，特に情報検索の分野において効果を挙げているの定義に基づく式は以下のものである：(w)&amp;=&amp;(w)1+eqnarray*tf*idf値を重要文抽出に用いる意図は，「その記事に特有な単語をより多く含む文は，その記事においてより重要である」という仮定を表現することである．各文のスコアは，文中の各単語に対するtf*idf値の和によって与えられる：_(S_i)&amp;=&amp;_wS_i(w)eqnarray*なお章で示す結果では，tf*idf値を用いた文のスコアから文の長さによる影響を避けるため，以下の式のようにtf*idf値の和を文の長さ(S_i)で割って正規化した値を文のスコアとしている：_(S_i)&amp;=&amp;1S_i_wS_i(w)eqnarray*TSCデータ，CSJデータに対しては単語の切り分けにJUMANver.3.61を用い，tf*idf値を与える単語を時相名詞や副詞的名詞を除いた名詞に限定した．記事頻度を求めるための記事群には，1994年と1995年の毎日新聞の記事を用いた．DUCデータに対しては，品詞による単語の選別は行わず，ストップワードのリストを作成し，そのリストに含まれない単語についてtf*idf値を求めた．記事頻度を求めるための記事群としては，1994年と1995年のWallStreetJournalの記事を用いた．TSCデータ,CSJデータにおいては，各単語のtf*idf値を求める際に関数T3を用いた．DUCデータにおいては，T1〜T3の3つの関数のうち一つをトレーニングデータを用いて選択するようにした結果，T1が選択された．</subsubsection>
  <subsubsection title="見出し">この評価尺度は，対象記事の見出しに含まれる単語に対するtf*idf値を用いて文のスコア付けを行うものである．これは「見出しと類似している文は重要である」という仮定に基いている．類似度を求める際に対象とする単語は，前節のtf*idf値を用いた関数と同様に，日本語であるTSCデータ,CSJデータでは時相名詞や副詞的名詞を除いた名詞，英語であるDUCデータではストップワードのリストに含まれない単語である．文((S_i))中の対象単語について，その名詞が見出し((H))に含まれていれば，そのtf*idf値を文のスコアに加算する．文のスコアを与える式を以下に示す：_(S_i)=_wHS_i(w)_wH(w)eqnarray*CSJデータにおいては，講演録そのものには見出しは存在しないが，それに対応する予稿から見出しを取り出して用いた．TSCデータ，DUCデータについては，さらに名詞の代わりに固有表現(NamedEntity:NE)を用いて見出しとの類似度を計算する関数も定義した．TSCデータに対する日本語の固有表現抽出には，最大エントロピー法を用いたシステムを使用した．抽出する日本語固有表現の定義はIREXワークショップで用いられたものに拠っている．DUCデータに対する英語の固有表現抽出には，パターンベースの固有表現抽出システムを用いた．このシステムは，拡張された固有表現の定義150クラスを抽出の対象とするものである．固有表現を用いる際には，簡便性のため，tf*idf値ではなく頻度のみを用いた．すなわち，各記事中の固有表現(e)に対する頻度(tf(e))を用いれば，関数の式は以下のように示される：(e)&amp;=&amp;(e)1+(e)[1mm]_(S_i)&amp;=&amp;_eHS_i(e)_eH(e)eqnarray*</subsubsection>
  <subsubsection title="言語的パタン">DUCデータに対しては，言語的パタンの獲得方法とそれを用いた評価尺度を導入した．ここで用いているパタンの獲得手法は，日本語情報抽出において提案された手法に基づいている．この手法は，例えば地震の発生を報道する記事には「○月×日ｘ時ｙ分ごろ，△□で地震があった」といった表現がよく現われるように，「分野(domain)を特定したときに，記事によく現れる表現はその分野において重要だ」という仮定に基づいてパタンを自動的に獲得するものである．DUC2001においては，約10記事ずつを1セットとして30記事セットのデータが配布されたので，この各記事セットを情報抽出における一つの分野とみなし，各セットごとにパタンの自動獲得を行った．パタンの獲得方法は以下の過程に従って行われる：文の解析：	与えられた記事セット中の記事全文について品詞・固有表現のタグづけ，係り受け解析を行う．部分木の抽出：	係り受け木中の部分木を全て取り出す．固有表現による抽象化：	部分木中に固有表現があった場合には，その固有表現を対応するクラス	に置き換えたものと，元の表現のままの二通りの部分木をパタンとして	用意する．複数の固有表現がある場合は，各置換操作の組み合わせだけ部	分木を生成する．部分木のスコア付け：	木全体の頻度と，部分木中の各単語の記事頻度から部分木のスコアを求める．	このスコアの定義は，その記事セットに特有な部分	木を取り出すという意図に基づいており，スコアが高い部分木ほど重要	なパタンであると仮定することになる．パタンは重要文抽出を行う前に取り出され，スコアとともにシステムに格納される．実際に重要文抽出を行うときには，システムは各文(S_i)について品詞・固有表現のタグづけや係り受け解析を行って係り受け木を作成し，次いで格納されたパタンとの比較を行う．パタン(P_j)のスコアと文(S_i)の評価尺度をそれぞれ式に表わすと以下のようになる：_j&amp;=&amp;1P_j_wP_j(S_i)&amp;=&amp;_jF_P_j_jP_jS_i&amp;=&amp;0_(S_i)&amp;=&amp;((S_i)+1)eqnarray*ここで，(F_P_j)はパタン(P_j)の記事セット中の頻度，(P_j)は(P_j)中の単語数を示す．DNは予め与えられた記事群中の記事数，df((w))はその記事群の中で単語(w)が現れる記事の数である．すなわち，(a_idf)は，パタン(P_j)中の単語の平均idf値であり，これとパタンの頻度(F_P_j)を用いて節で述べたtf*idf値のような値を各パタンに与えることが，パタンのスコアを表す式の意図するところである．あるパタン(P_j)が文(S_i)の係り受け木の一部と一致した場合には，そのパタンのスコアが文の評価尺度として加算される．さらに各文について一致した全パタンのスコアを加算し，その値の対数をとったものを最終的な文の評価尺度(_)としている．</subsubsection>
  <subsection title="重み付け">本システムでは，各評価尺度の値(Score(_j()))に重み((_j))を掛け合わせたものの総和をとり，各文((S_i))のスコアを与える：(S_i)=_j_j_j(S_i)eqnarrayこの重み付けの最適値は，トレーニングデータを用いて求めた．具体的には，予め設定した値域内で，重みの値を変化させながらトレーニングデータに対する実験・評価を繰り返し，最も良い値を与える重みづけの値を求めた．複数の関数が定義されている評価尺度においては，その関数の選択も重み付けとともに行なわれた．TSCデータ,DUCデータにおいては，それぞれ予備試験のデータをトレーニングデータとして用いた．TSCデータにおいては，30の新聞記事を更に社説15記事とそれ以外の報道記事15記事とに分けてそれぞれについて最適な重み付けを求めた．&lt;SECTION&gt;社説&lt;/SECTION&gt;のようにセクションが明示されており，社説とその他の記事とを分類することは容易に行うことができた．CSJデータでは，60講演のうち，テストデータとして残した10講演を除く50講演をトレーニングデータとして用いた．章に示す実験結果では，各情報においてどの関数が選ばれたか，重みの程度がどのくらいだったかを報告する．</subsection>
  <subsection title="しきい値">本システムでは，重要文抽出を行う際に記事中の全文にスコア付けを行い，その結果を元にスコアの良い順に各文を順位付けする．これらの文のうち何文まで出力するかを決定するのに，本システムでは文数・文字数(単語数)・スコアの3種類のしきい値を用いることができる．どのしきい値を用いても，出力される文の順番は元の記事のまま保たれる．文の数(N)がしきい値として与えられたならば，システムは順位付けされた文の上位(N)文までを重要文として抽出する．文字数または単語数が与えられたときには，システムはこれを文数のしきい値に変換する．スコアがしきい値として与えられたならば，システムはそのしきい値より大きい値をもつ文のみを出力する．TSCデータ，CSJデータについては，文の数(N)をしきい値として用いた．DUCデータについては，DUC2001において100語前後の要約を出力することが課題に指定されていたので，単語数をしきい値として用いた．</subsection>
  <section title="各タスクの評価結果">本章では，前章で述べた重要文抽出システムをTSC，DUC，CSJの3種類のデータそれぞれに適用した結果を示す．</section>
  <subsection title="TSCデータでの評価結果">TSC2001の重要文抽出課題においては，人手で作成された重要文抽出の正解データとシステムの出力した重要文抽出結果との間で，どのくらい抽出された重要文が一致するかの度合に基づいた評価が行われた．評価の指標としては，再現率・精度・F値の3種類が用いられた．表は，本システムの重要文抽出での評価結果を，二種類のベースラインシステムの結果とともに示したものである．ベースラインシステムのうち，Lead-basedは常に記事の先頭から指定された文数まで出力するものであり，TF-basedは各文ごとに記事中の語(名詞，動詞，形容詞，未定義語)のTF値の和を計算し，そのスコアの高い順に文を選択する手法である．このとき選択された文の順序は，元記事の順序のものを保つ．表内の数値はF値を示す．また，表内の本システムの評価値に添えた括弧内の数字は，参加した10システム中の本システムの順位である．本システムは，平均・各要約率の各評価においてベースラインシステムの結果を上回る成果を得た．また，参加システム中でも，全体で2位の評価であった．社説と報道記事とでは，文の位置情報を用いる評価尺度において，異なる関数が選択されており，この選択が重要文抽出の評価向上に意味があったと考えられる．このことをより明確に示すために，文の位置情報のみを用いたときの，記事の種類別に見た評価結果を表に示す．P1とP2は，文の位置情報を単独で用いたときには同じ値を返すので，ここでは一つにまとめた．表に示されるように，P1,P2は社説以外の報道記事でP3より高い結果を示し，P3は社説においてP1,P2より高い結果を示した．すなわち，社説においては記事の前の方と後の方の両方に重要文として選択されたものが多く，社説以外では前の方だけに重要文として選択されたものが多いということを示している．本システムにおける文の位置を用いた評価尺度では，用いる関数を対象記事の種類に応じて適切に使い分けることで，どれか一つの関数に固定した場合の評価結果を上回ることができている．各評価尺度がどの程度結果に寄与しているかをみるために，表に各評価尺度の標準偏差とそれに対する重みを掛け合わせたものを示した．標準偏差が大きいほど各文に対する評価尺度の変化の度合が大きくなり，また各評価尺度の値には与えられた重みが掛け合わされて用いられるので，表に示した値によって各評価尺度が最終的な文のスコアにどの程度大きな影響を及ぼすかが分かる．表中の値は，各評価尺度の寄与する度合を正規化したものを示している．すなわち，各評価尺度についての値を要素とするベクトルについて，そのノルムが1になるように値を変換している．表から，文の位置に基づく評価尺度はどの区分においても寄与している評価尺度であり，特に社説においてその値が大きいことが分かる．それ以外の評価尺度は，対象とする記事の分野や要約率によってその寄与する度合が大きく変化している．しかし，章で示す分析からは，文の位置を除く評価尺度間の相関が有意に存在することから，文の位置とそれ以外の評価尺度のどれかを使うということがより重要であって，文の位置以外のどの評価尺度を使うかによる差は，それほど重要でなかったと考えられる．</subsection>
  <subsection title="DUCデータでの評価結果">表に，DUCデータにおける各評価尺度の標準偏差とそれに対する重みを掛け合わせたものを示す．TSCデータにおける値と同様に，これらの値は各評価尺度についての値を要素とするベクトルについて，そのノルムが1になるように値を変換している．結果から，最も文のスコアに対する影響が大きい評価尺度は文の位置であり，次いでtf*idf値であった．見出しや言語的パタンに基づく評価尺度は，それらに比較して結果に寄与する割合が小さかった．DUC2001における要約結果の評価は主観評価によって行なわれた．すなわち，システムによって生成された要約と人間が作成した要約とを被験者が比較してその質を判定した．主観評価は，Grammaticality(文法性)，Cohesion(結束性)，Organization/coherence(一貫性)の3つの基準について行われ，10人の被験者が各基準について5段階(4が最も高く，0が最も低い)の評価を与えた．各被験者の評価結果の平均を表に示す．全システムの結果は，参加した11システムとベースラインの結果の平均値である．ベースラインの要約は，各記事について先頭から100語ずつ出力したものである．本システムの結果は，どの評価基準においてもベースライン，全システムの平均を上回っている．また，システム全体での順位も，文法性では5位であったが，それ以外の評価では1位であり，全体でも1位であった．</subsection>
  <subsection title="CSJデータでの評価結果">CSJデータにおける各評価尺度の標準偏差とそれに対する重みを掛け合わせたものを，表に示す．TSCデータにおける値と同様，これらの値は各評価尺度についての値を要素とするベクトルについて，そのノルムが1になるように値を変換している．結果から，最も文のスコアに対する影響が大きい評価尺度は文の長さであり，次いで文の位置，tf*idf値であった．CSJデータに対する要約の評価結果を表に示す．ここでは，文境界をパタンに基いたシステムによって自動的に検出した場合と，正しい文境界を予め与えた場合の双方について重要文抽出結果の評価を行った．また，節で述べたように，3人の被験者がそれぞれ作成した重要文抽出の結果は判断の揺れが大きく，それらを統合して正解データを作成することは困難であったので，この表では，各被験者(それぞれA,B,Cとする)の重要文抽出結果を個々に正解とみなしてシステムの出力を評価した値と，それらの平均値とをともに示した．文境界を自動的に検出した場合の評価結果の平均は30,%を超えない．一方，正しい文境界を予め与えた場合の重要文抽出結果はF値で36.8,%という評価を得た．CSJデータについてはコンテストによる結果は存在しないため，同一データによる他のシステムとの評価結果の比較は行っていないが，TSC，CSJ両データに対する重要文抽出の結果を比較すると，10,%という小さい要約率においては文境界が正しく検出できれば，話し言葉に対する重要文抽出は新聞記事に対する重要文抽出に匹敵しうることを示しているといえる．</subsection>
  <section title="要約データの分析">章では，複数の素性を用いた重要文抽出システムが，TSC，DUC，CSJの各データについて良好な結果を得たことを示した．しかしながら，評価結果だけでは，各データにおいて有効な素性に違いはあるのか，複数の素性を組み合わせて用いたことにどのような効果があったのかという点についてはっきり示されていない．そこで本章では，まず各素性についてその値の変化に対応する重要文の分布を図示し，どのような素性の用い方が効果的であるかを調べた．次に，有効な素性の組み合わせを調べるため，二つの素性間の相関と素性の組み合わせによる重要文の数・割合の分布を示した．</section>
  <subsection title="素性に対応する重要文の分布">本節では，重み付けの値を得たトレーニングデータにおいて重要と判断された文と素性との関連を調べ，素性を用いた評価尺度のうちどのようなものが有効であるかを考察する．具体的には，文の位置・文の長さ・tf*idf値・見出しの4種類の素性について，その評価尺度の値に対応する記事全体の文数・重要文の文数を調べた．文の位置・tf*idf値・見出しについてのグラフでは，各素性ごとにそれに基づく評価尺度の値の昇順に文を順位付けしてその順位を5,%または10,%ごとに区分し，各区分ごとに重要文の占める割合を示した．一方，文の長さについてのグラフでは，傾向をより見やすくするために，文の長さの値そのものに対して記事中の文数とそれに含まれる重要文の数とを示した．TSCデータにおいては，さらに記事の種類を社説と報道記事に分け，個々の要約率における正解要約(10,%,30,%,50,%)に含まれる重要文の割合をグラフによって示した．なおCSJデータについては，重要文の数・割合として3人の被験者による抽出結果の平均値を用いている．データ全体の文数・重要文の数を示すため，表に各トレーニングデータの記事数と文数・重要文の数・要約率を掲げる．DUCデータにおいては，要約の制限は要約率ではなく語数(100語)であったため，全データにおける重要文の割合を要約率として示した．</subsection>
  <subsection title="素性間の関係">複数の素性を用いて重要文抽出を行うには，素性間の独立性が高いことと，素性を組み合わせたときに重要文が多い値域を絞り込めることが重要である．本節では，まず素性間の独立性を調べるために，各素性による文のスコアの順序に基づく順位相関係数を求め，素性間の独立性を調べた結果を示す．次に，独立性が比較的高い素性同士のいくつかの組み合わせについて，その組み合わせによる重要文の数・割合の分布を示した．</subsection>
  <subsubsection title="素性間の相関">各要約データにおける文の位置・文の長さ・tf*idf値・見出しの4種類の素性について，その評価尺度の値に基づく順位相関係数(Spearman)を求めた．各素性の組ごとの順位相関係数の値を表に示す．結果からは，どのデータにおいても文の位置は他のどの素性とも相関が低く，比較的独立であること文の長さとtf*idf値との相関が高いことTF*idf値と見出し(単語)との相関が高いことが分かる．これら4種類の素性は重要文抽出に用いられる典型的な素性であり，章ではこれらの素性を組合せて重要文抽出を行い日本語・英語双方のコンテストにおいて良好な結果を得たことを示したが，順位相関係数の値からはこれらの素性は必ずしも相互に独立ではないことが分かった．</subsubsection>
  <subsubsection title="素性の組み合わせ">前節の結果から，4種類の素性は互いに独立であるとはいえないが，文の位置と他の素性との組み合わせはどのデータにおいても他の組み合わせと比較して独立性が高いことが分かった．本節では，これらの素性の組み合わせにおいて重要文の分布とどのように関連しているかを調べる．TSCデータについては，素性の組み合わせについて示すにはデータ中の文数が少ないため，ここではDUCデータとCSJデータについて調べた結果のみを示している．前節の結果独立性の高かった文の位置と他の素性の組み合わせについて，重要文の分布がどう変化するかを示す．表，，は，二つの素性の組み合わせによって重要文の数・割合がどう変化するかを示したものである．これらの表では各素性ごとにその評価尺度の値の昇順に文を順位付けし，その順位を10,%ごとに区分して各区分ごとに重要文の数と割合を文字によって段階分けして示した．各区分中の文字は，重要文が各区分に均一に分布している場合に比べて，どのくらい偏りがあるかを示すものである．左側の文字は重要文の数の偏りを示すもので，具体的には，データ中の全重要文の数を(T)としたときに各区分中の重要文の数(T_i,j)が重要文の各区分に対する平均値(M(=T100))からどのくらい離れているかを，以下のような範囲ごとに示している．ここで(S)は各区分に対する重要文数の標準偏差である．同様に，各区分の右側の文字は，重要文の全文数に対する割合が均一に分布している場合と比較して，どのくらい偏りがあるかを示すものである．全文数(N)に占める重要文の割合を(m(=TN))としたときに，各区分中の重要文の割合(t_i,j)が以下の範囲にあることを示している．ここで(s)は各区分に対する重要文の割合の標準偏差である．すなわち，重要文が素性に関係なく均一に分布している状態ならば，全ての区分がCcとなる．重要文の数が多くてもその割合が小さければ，単にその区分に含まれる文の数が多いだけで，重要文の抽出に有効な区分ではない．逆に重要文の割合が大きくてもその数が小さければ，その区分は重要文抽出の性能向上に有効ではあるが，寄与する度合は小さい．まず，表に示した文の位置と文長の組み合わせについて調べてみると，DUCデータでは文の位置が先頭から20,%以内で，かつ文長による順位が50,%以降の場合(文の位置()0.2，文長()0.5)において重要文の数，割合とも大きいことが分かる．一方CSJデータでは文の位置が末尾から10,%以内で，かつ文長による順位が30,%以降の場合(文の位置=1.0，文長()0.3)に重要文の数，割合とも大きい．次に，文の位置とtf*idf値の組み合わせについての結果を表に示す．CSJデータにおいて文の位置が先頭から20,%以内のところに重要文の割合が大きい区分が若干増えたこと以外は，文長との組み合わせとほぼ同様の結果になっている．これらの結果から，文の位置と組み合わせて文長またはtf*idf値を用いた際には，ともにそのスコアが低い文を除くことで文の位置による重要文抽出の精度をより向上させていることが分かる．最後に，文の位置と見出しの組み合わせについての結果を表に示す．見出しを用いた評価尺度の場合，ほぼ半数の文が見出しと共通する語を持たないため，スコアが0になる．このため，対応する文が存在しない区分が中間に現われている．見出しを用いた評価尺度においては，そのスコアが0であるような文においても重要文の数が多く，文長またはtf*idf値のような効果は得られていない．しかし，DUCデータにおいて文の位置が先頭から20,%以内で見出しによる順位が70,%以降の場合(文の位置()0.2，見出し()0.7)，重要文の割合は大きくなっている．また，CSJデータにおいては，文の位置が末尾から10,%以内(文の位置=1.0)の場合に加えて，文の位置=0.1，見出し=1.0の区分においても重要文の数，割合が大きくなっている．従って，文の位置と組み合わせて見出しの情報を用いた場合には，文長やtf*idf値とは逆に，そのスコアが高い文を優先することで文の位置単独の場合よりも重要文抽出の精度が向上するといえる．これらの実験結果をまとめると「重要文抽出に用いた素性を組み合わせたときに，その値の増減に応じて連続的に重要文の数・割合が増えるのではなく，組み合わせによってできる一定の境界があって，その内外で重要文の数・割合が大きく異なることがある」ということになる．つまり，重要文抽出を行う際には，式のように素性を用いた評価尺度を線型に組み合わせる方法ではなく，ここで発見された特徴を生かすような非線型の評価尺度を導入することで，同じ素性を用いても精度向上の可能性があるということである．また，DUCデータとCSJデータの双方において素性の組み合わせによる非線型な重要文の数・割合の変化がみられたことは，英語新聞記事と日本語講演録という異なる種類のデータにおいても，非線型な素性の組み合わせが重要文抽出に有効であることを示唆しているといえる．日本語新聞記事においても，はSVMを用いた重要文抽出を行う際に連続値を持つ素性を一定の値域に区切って二値素性に変換して用いているが，その分析において報告されている有効な二値素性の組み合わせからも，同様に非線型な素性の組み合わせが有効であることが推測される．</subsubsection>
  <section title="おわりに">本論文では，重要文抽出に基いた要約システムの評価結果を日本語新聞記事，英語新聞記事，日本語話し言葉コーパスの3種類のデータそれぞれについて示した．本システムは，日本語新聞記事の要約評価ワークショップTSC(2001)，英語新聞記事の要約評価ワークショップDUC(2001)の各々において，単一文書の要約課題において良好な成績をおさめた．また要約率が10,%程度と小さいときには，文境界が正しく検出できれば，講演録などの話し言葉に対する重要文抽出は新聞記事に対する重要文抽出に匹敵しうることを示した．要約データの分析においては，トレーニングデータにおいて各素性に基づく評価尺度の値と重要文の分布を示し，各素性の重要文抽出における有効性を3種類のデータ間で比較した．また，素性間の順位相関係数を求め，用いたどのデータにおいても，文の位置とその他の素性との相関に比べて文の位置以外の素性間の相関が高く，重要文抽出に用いられるこれらの代表的な素性が必ずしも相互に独立ではないことを示した．さらに，比較的独立性の高い文の位置とそれ以外の素性との組み合わせについて重要文の分布を調べ，文の位置と組み合わせて文長またはtf*idf値を用いた際には，ともにそのスコアが低い文を除くことで文の位置による重要文抽出の精度が向上し，文の位置と組み合わせて見出しの情報を用いた場合には，逆にそのスコアが高い文を優先することで文の位置単独の場合よりも重要文抽出の精度が向上していることを示した．今後の課題としては，今回の実験で用いた素性と独立性の高い新たな素性を導入し，それによって重要文抽出の精度を上げることを考えている．本論文では，異なる言語・種類のコーパス間での比較を主眼としたため素性については重要文抽出において代表的な素性のみを対象としたが，例えば構文情報や，が用いたような機能語・モダリティを示す表現など，新たな素性についてもその独立性や組み合わせによる有効性を調べ，重要文抽出に有用で特定のコーパスに依存しないような素性を見出していきたい．本研究を進めるにあたっては，通信総合研究所の自然言語グループのメンバーとの討論が参考になりました．特に内元清貴氏には有益な助言をいただき感謝します．acknowledgmentdocument</section>
</root>
