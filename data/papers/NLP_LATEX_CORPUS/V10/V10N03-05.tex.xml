<?xml version="1.0" ?>
<root>
  <title>日本語翻訳タスクへの帰納論理プログラミングの適用</title>
  <author>新納浩幸阿部修也</author>
  <jabstract>本論文では，SENSEVAL2の日本語翻訳タスクに対して帰納論理プログラミング（InductiveLogicProgramming,ILP）を適用する．翻訳タスクは分類問題として定式化できるため，帰納学習の手法を利用して解決できる．しかし翻訳タスクは新たに訓練データを作るのが困難という特異なタスクになっており，単純に確率統計的な帰納学習手法を適用することはできない．TranslationMemoryの例文だけ，つまり少ない訓練データのみを用いて，どのように分類規則を学習すれば良いかが，翻訳タスク解決の1つの鍵である．このために本論文ではILPを用いる．ILPは確率統計的な帰納学習手法にはない特徴を有する．それは背景知識を容易に利用可能である点である．背景知識とは訓練データには明示されない問題固有の知識である．この背景知識によって訓練データが少ない場合の学習が可能となる．ここではILPの実装システムとしてProgol，背景知識として分類語彙表を利用することで，翻訳タスクに対して正解率54.0,%を達成した．この値は，付加的な訓練データを用いないSENSEVAL2参加の他システムと比較して優れている．</jabstract>
  <jkeywords>翻訳タスク，帰納論理プログラミング，Progol，分類語彙表，背景知識</jkeywords>
  <section title="はじめに">本論文では，SENSEVAL2の日本語翻訳タスクに対して帰納論理プログラミング（InductiveLogicPrograming，以下ILPと略す）を適用する．背景知識として分類語彙表を利用することで，正解率54.0,%を達成した．この値は，訓練データを新たに作成しない翻訳タスク参加の他システムと比較して優れている．SENSEVAL2の日本語翻訳タスクは，TranslationMemory（以下TMと略す）と呼ばれる日英対訳対が与えられ，テスト文中の該当単語を英訳する際に利用できるTMの例文番号を返すタスクである．これは英訳を語義と考えた場合の多義語の曖昧性解消問題となっており，分類問題の一種である．このため従来から活発に研究されている帰納学習手法を用いて解決可能である．おそらく大規模かつ高品質な訓練データを用いたシステムが，コンテストで優秀な成績を納めるはずである．しかし翻訳タスクでは大規模かつ高品質な訓練データを用意するコストが高い．TMは1つの単語に対して平均して21.6例文がある．今仮にある単語Aの例文として(id_1)から(id_20)までの20例文がTMに記載されているとする．新たに訓練データを作成する場合，単語Aを含む新たな文を持ってきて，(id_1)から(id_20)のどれか1つのラベルをその事例に与える必要がある．〇か×かの二者択一は比較的容易であるが，20個のラベルの中から最も適切な1つを選ぶのは非常に負荷のかかる作業である．この理由のために，実際のコンテストにおいて，大規模かつ高品質な訓練データを用意する方法をとったシステムは1つ（Ibaraki）だけであった．ここでは訓練データを新たに作成せずに，日本語翻訳タスクを解決することを目標とする．訓練データを新たに作成しないとしても，TMの例文は訓練データとして扱える．ただしTMの例文を訓練データと見た場合，その量は少量と言わざるをえない．つまり問題は，少量の訓練データからどのようにして精度の高い分類規則を獲得するかである．そのための戦略としてILPを用いる．少量の訓練データからどのようして分類規則を学習したらよいかは，機械学習における1つの重要な課題である．その解決方法として背景知識の利用が提案されている．背景知識とは，訓練データには明示されない問題固有の知識であり，広く捉えれば，人間の持つ常識的知識と考えて良い．一種の知識データベースである．問題はその背景知識を，どのように学習手法に取り入れてゆくかである．その解決のために提案されているのがILPである．ILPは訓練データを述語論理の形式で表し，そこから分類規則に相当する規則（述語論理の形式では節に対応）を導出する．知識データベースは述語論理の形式によって自然に表現できるので，背景知識の利用の観点からはILPを用いた学習戦略が優れている．更にILPの背景知識では，複雑なグラフ構造を持ったものも表現できるので，近年，CMUの機械学習チームはWebページの文書分類にILPを利用している．更にいくつかの自然言語処理への応用も知られている．本論文では，ILPの処理系としてMuggletonによるProgolを利用する．Progolによって多義語の曖昧性解消を行う．そして背景知識としては分類語彙表を利用する．以下2章で多義語の曖昧性解消をILPで行う方法を示す．3章では分類語彙表をどのように背景知識として組み込むかを説明し，4章で実験，5章で考察を述べ，最後にまとめる．</section>
  <section title="ILP による多義語の曖昧性解消">ILPによる分類問題の解決については，書籍に詳しく解説されている．ここでは関連する事柄についてのポイントのみを述べる．自然言語処理の個々の問題の多くは分類問題として以下のように定式化できる．まず分類先のクラスの集合(C=c_1,c_2,,c_m)を設定し，次に事例(x)を(n)個の要素からなる素性ベクトル((f_1,f_1,,f_n))で表す．各素性は事例を識別するための観点に対応する．(k)番目の素性を(attr_k)と名前をつけておく．訓練事例は事例(x)とそのクラス(c_x)の対の情報((x,c_x))であり，これを多数集めたものが訓練データとなる．確率統計的な帰納学習手法（決定木，決定リスト，ME法など）は訓練データを入力として，分類器(F)を構築する．分類器(F)への入力は事例であり，出力はクラスである．分類問題を解決するとは，この分類器(F)を作成することである．ILPでは訓練事例((x,c_x))を以下の節で表現する．[t]50mm|class(|x,c_x)).|attr_1(|x,f_1)).|attr_2(|x,f_2))....|attr_n(|x,f_n)).minipageこれらの節が訓練データとなる．ILPではここからあるクラスにのみ共通して見られ，他のクラスには見られないある種のパターンの発見を行う．これは本質的に帰納推論の処理である．その結果，例えば，以下のような節をILPは出力する．[t]50mm|class(X,c):-attr_5(X,h).|minipageこれは事例|X|の5番目の素性が|h|であれば，事例|X|のクラスが|c|であることを示している．また左辺が|class(Y,c)|である節が他になくしかも，事例|X|の5番目の素性が|h|でなければ，事例|X|のクラスは|c|でないことも示している．ここまでは特に確率統計的な手法と大きな違いはない．確率統計的手法にはないILPの大きな特徴は，訓練データ中に任意の述語や節を記述できる点である．この与えられた訓練事例の集合以外から追加される述語や節を背景知識と呼ぶ．つまり問題固有の知識や，人間の常識といったものを背景知識として訓練データ内に簡単に追加できることがILPの大きな特徴となっている．特に，述語論理の節の表現力は高く，ILPは表形式（素性ベクトル）では表現できない複雑な構造を持つ訓練事例も表現できる．以下，ILPによって多義語の曖昧性解消を行う．利用する素性は以下の4種類を用いた．対象単語の直前の単語e1対象単語の直後の単語e2e1から前方3単語e3e2から後方3単語e4verbatim例を示す．対象とする多義語を「与える」として「彼では力不足という印象を与えるかもしれない。」という文は，以下のように形態素解析される．第1列が表記，第2列が原型，第3列が品詞を表す．彼彼普通名詞でで格助詞はは副助詞力力普通名詞不足不足サ変名詞とと格助詞いういう動詞印象印象普通名詞をを格助詞与える与える動詞かもかも接続助詞しれしれる動詞ないない形容詞性述語接。。句点verbatimここから以下の素性が得られる．e1='を'e2='かも'e3='と'，'いう'，'印象'e4='しれ'，'ない'verbatim例えば，この例文のIDが|sen25|であり，この文の「与える」の語義IDが|ataeru2|だとすれば，この例文に対するデータは，以下の節で表現される．class(sen25,ataeru2).e1(sen25,'を').e2(sen25,'かも').e3(sen25,'と').e3(sen25,'いう').e3(sen25,'印象').e4(sen25,'しれ').e4(sen25,'ない').verbatim</section>
  <section title="分類語彙表の利用">前節の設定で，訓練事例を節に変換すれば，ILPにより分類規則が節の形で得られる．ここで得られる規則を，背景知識を利用することで更に高めることも可能である．本論文では，背景知識として分類語彙表を利用する．分類語彙表は木構造をもったシソーラスである．ただし木のリーフノードにのみ単語が配置されている．つまり木のあるノード以下に位置するリーフノードの単語群はそのノードの階層において同一の意味クラスに属すると考えて良い．当然階層が上がるほど，同じ意味クラスの単語は増加することになる．例えばにおいて一番下の階層で考えると，「課題」「宿題」「問題」は同じ意味をもつグループとなり，「語意」「題意」「意義」は別の意味のグループとなる．1つ上の階層で考えると，これらの単語はすべて同じ意味をもつ単語と見なせる．本論では一番下の階層でみた場合のグループの単語を同じ意味をもつ単語とした．図に示した規則は，素性（|e1|，|e2|，|e3|，|e4|の単語）と，分類語彙表に含まれる単語と，その単語と同じ意味を持つ単語を結び付ける．つまり，ILPは同じ意味の単語を同じ単語として扱うようになる．述語|b|は，分類語彙表の単語とその意味の番号の組を表す．述語|e1〜e4|は，文の素性を表す．述語|e1_w〜e4_w|は，単語の代わりに語義を用いることによって述語|e1〜e4|を拡張したものであり，|e1〜e4|の代りに素性として用いられる．</section>
  <section title="実験">本論文ではILPの実装システムとしてMuggletonによるProgolを利用した．Progolへの入力形式は，Prolog形式の述語や節であり，本論文で説明に用いた形式で行える．ILPの実装システムは他にも存在するが，Progolが最もよく利用される代表的なシステムである．まず，TMの形態素解析結果から素性（|e1|，|e2|，|e3|，|e4|）を抽出する．また例文番号を分類先のクラスとする．例文番号，クラス，素性の情報を節に変換し，Progolの入力ファイルを作成する．入力ファイルをProgolに読み込ませて，規則を生成した．テストは翻訳タスクのコンテストで用いられた全40単語（各単語30問，計1,200問）が対象である．それらに対して，Progolにより得られた規則を使い，多義語の曖昧性解消のテストを行った（実験1）．次に，TMの例文の他に背景知識として分類語彙表を用いて，Progolにより規則を生成した．得られた規則を使い，40単語に対してテストを行った（実験2）．実験1と実験2の結果をに示す．のTMの列は実験1の結果を示し，TM+背景知識の列は実験2の結果を示している．平均の正解率はTMのみは48.7,%であり，TM+背景知識では54.0,%であった．分類語彙表を背景知識として用いた効果が確認できる．またこの54.0,%という値は，付加的な訓練データを用いない翻訳タスクの他のシステムの正解率と比較しても，優秀な値と言える．次に確率統計的な手法の1つである決定リストと比較してみる．論文では翻訳タスクの正解から語義（例文番号）をグループ化して，TMの例文番号をグループ化することで，正解率が向上することを述べている．そのため翻訳タスクに対する学習手法を比較する場合，TMの例文のグループ化を揃える必要がある．そこで，ここでは論文と同じ手法を用いて，正解データから例文をクラスタリングし，同一の訓練データを用いることにした．確率統計的な学習手法としては，決定リストを用いた（実験3）．実験の結果をに示す．平均の正解率は決定リストでは54.8,%であったが，本手法では60.5,%の結果を得た．つまりTMだけを用いた学習システムとしては，決定リストよりもILPの方が優れていた．ただし，いくつかの単語については，実験3でのILPの正解率が，実験1でのILPの正解率や，実験3での決定リストの正解率よりも，極端に低くなっている．例えば，mokuteki，jidai，ukeru，baai，egaku，imaなどである．これらの正解率が極端に下がっている理由は，学習結果として生成された節の順序の問題である．これは，default規則にあたるものを適切に設定できなかったことを意味している．これについては次節の考察に記述する．</section>
  <section title="考察">背景知識を用いても必ずしも正解率が高くなるとは限らないことは容易に予想がつく．実際に，実験1，2でも精度が下がる単語がいくつか存在する．また，実験3と同様の課題についてさらに分類語彙表を背景知識として用いた実験も行ったが，この場合の平均の正解率も60.5,%から58.9,%に低下した．分類語彙表を用いることで，単語を語義に一般化すれば，ある部分では効果があるが，別の部分では過度の一般化になるので，その影響が現れると精度は下がる．過度の一般化への対処は今後の課題である．また節を規則として見た場合，節の適用順序が重要になる．これは入力事例と訓練事例に矛盾がないことを仮定する論理を基盤とする推論では問題にならない．しかし現実の問題では訓練データに矛盾する入力も有り得る．例えば，以下のケースを考えてみる．class(X,c1):-attr_1(X,a).class(X,c2):-attr_2(X,b).verbatim節Aは事例の1番目の素性の値がaなら分類クラスがc1であることを示し，節Bは事例の2番目の素性の値がbなら分類クラスがc2であることを示している．この2つの規則が学習されたということは，訓練データ内には，1番目の素性の値がaでしかも2番目の素性の値がbの事例が存在しなかったことを意味する．また同時にそのような事例が存在しないことも仮定したことになる．ところが，現実にはそのような事例が入力されることもある．この場合，上記の規則では，クラスはc1と識別される．一方，上記の規則の順序を変更し，以下の形にすれば，クラスはc2と識別される．class(X,c2):-attr_2(X,b).class(X,c1):-attr_1(X,a).verbatim節の出現順序はProgolでは考慮されていないようである．訓練データに対応する述語や節の与える順序が，生成される節の順序に影響する．本実験ではこの点は何も対策をたてずに，学習された節をそのまま適用した．しかしこのような節の順序はdefault規則が何に対応するかという問題にもなっており，正解率に大きく影響する．実験3で正解率が大きく下がる単語は，みなこの問題がからんでいた．この対策も今後の課題である．また上記の問題とも関連するがILPでは頻度の情報がなくなってしまう．例えば，上記の節Bに合致した訓練事例の数が10,000で，節Aに合致した訓練事例の数が1のとき，普通に考えれば合致する事例数の多い節Bを優先させるのが正しいであろう．しかしILPでは，頻度の情報が節Bと節Aに反映されず，結果として同じ重みを与えている形になる．この問題は，確率と論理を結び付ける研究と関連しており，いまだ決定版は出ていない状況である．少量の訓練データしかない場合，識別精度を高めるには，訓練データ以外の情報，つまり背景知識をいかに取り込むかが重要である．今回の実験では背景知識として分類語彙表を用いたが，単語を語義で一般化することは通常の確率統計的な手法でも実現可能であり，この点ではILPを用いた利点は少ない．ただし翻訳タスクでは背景知識の利用という観点以外からも，ILPを用いた方が適切であると思われる．なぜならここで扱っている少量のデータは統計学でいうサンプルではないからである．例えば，仮に語義c1の例文1からe1=aとe2=bいう素性語義c2の例文2からe1=cとe2=dいう素性語義c1の例文3からe1=aとe2=eいう素性verbatimが得られたとする．確率統計的な手法では，以下の5つの確率が高くなる．確率対応する例文------------------------------P(c1|e1=a)例文1，例文3P(c1|e2=b)例文1P(c1|e2=e)例文3P(c2|e1=c)例文2P(c2|e2=d)例文2verbatimそして特に#P(c1|e1=a)#の確率が高くなる．同じクラスc1の例文1と3に素性|e1=a|が発生しているからである．ただし，このような確率の算出が妥当なのは，例文1，2，3がサンプル，つまり等確率で現れる事例という仮定がある．TMの例文はサンプルではありえない．例えば，ある単語は90,%以上の割合で，語義c1の意味用法で利用されるとしても，TMのその単語の例文の90,%以上が語義c1の例文であることはない．つまり，TMの例文数から素性に重みをつけるのは意味がない．そのためTMから得られる素性は，同じ重みで評価するのが妥当であろう．今回ILPが決定リストよりも優れた結果を出せた要因がそこにあると思われる．またILPの背景知識として，今回は分類語彙表を用いたが，任意の節が組み込めることは大きな魅力である．特に，Webページは解析の観点によっては，複雑な構造をもつことになり，そのような複雑なデータ構造からの学習にはILPが利用できるため，今後応用範囲が広がる研究分野だと思われる．</section>
  <section title="おわりに">本論文では，SENSEVAL2の日本語翻訳タスクに対してILPを適用した．ILPは背景知識を容易に学習に組み込めるという確率統計的な手法にはない長所がある．翻訳タスクは少量の訓練データしか利用できない分類問題と見なせるため，翻訳タスクはILPの格好の応用となっている．ここではILPの実装システムとしてProgol，背景知識として分類語彙表を利用することで，正解率54.0,%を達成した．この値は，訓練データを新たに作成しない翻訳タスクの他システムと比較して優れている．また語義のクラスを同一にした訓練データを用いて，確率統計的手法の1つである決定リストと比較したところ，決定リストの正解率54.8,%に対して，ILPでは60.5,%となり，決定リストよりも良い結果が得られた．分類語彙表を利用した場合の過度の一般化をどう押さえるか，出力される規則の優先順序をどのように制御するかが今後の課題である．document</section>
</root>
