<?xml version="1.0" ?>
<root>
  <title>決定木学習による日本語対話文の格要素省略補完</title>
  <author>山本和英隅田英一郎</author>
  <jkeywords>格要素省略、決定木、機械学習、対話処理</jkeywords>
  <jabstract>機械翻訳では目的言語で必須格となる格の人称と数を補う必要がある。本論文では、省略補完知識の決定木による表現、及び帰納的に機械学習することによって日本語対話文の格要素省略を補完する手法を提案する。本研究では形態素分割され、品詞、省略情報が付与された任意のコーパスとシソーラスのみを用いて行なう。決定木学習には、内容語の意味属性、機能語の出現、言語外情報の3種類の属性を使用する。未学習文に対してテストを行なった結果、ガ、ヲ、ニの三つの格で照応的な省略の補完を十分な精度で行なうことができた。またガ格とニ格に対しては人称と数の補完にも有効であることを確認した。ガ格に関して、処理の有効性を学習量、話題依存性、使用属性との関係の三点から実験し、以下の知見が得られた。(1)当該問題に対する決定木学習量は全体として10^410^5事例で十分である。この時の補完精度の上限は80%85%と予想される。(2)対話の話題が既知もしくは予測可能な時は、その話題のみのコーパスによる学習が最善である。話題が未知の場合は、可能な限り広範な話題に対して学習するのが最も効果的である。(3)学習量増加に伴い、決定木には機能語などの話題に依存しない属性が多く採用される。</jabstract>
  <subsection title="">*謝辞本研究を進めるにあたって、省略に関する正解データを提供していただいたATR音声翻訳通信研究所の荒川直哉氏、及びプログラミング、実験を担当していただいた同研究所の西村仁志氏に感謝する。</subsection>
  <section title="はじめに">日本語対話文における格要素の省略補完について述べる。主語や目的語などの表示が義務的でない日本語の言語処理においては、これら省略される格要素を補う処理が重要である。格要素の省略は日本語に特有の現象ではなく、例えば韓国語、中国語などにも認められる。これら省略のある言語から英語やドイツ語など必須格を持つ言語への翻訳処理を行なう際には、補完処理(省略内容の推定処理)は重要な処理となる。また情報検索など、自然言語処理に関係する他の問題においても、省略補完処理は必要となる。省略された内容は、言語内、つまり省略位置以前のテキスト中に存在する場合と言語外に存在する場合に大きく分かれる。本論文では前者を文脈省略(endophoricellipsis)、後者を外界省略(exophoricellipsis)と呼ぶ。日本語の文脈省略補完に関しては従来から様々な研究がなされてきている。センタリング理論(centeringtheory)と呼ばれる一連の手法はこの一つである(最近の論文としては、例えば、、などを参照)。この理論では、`center'(談話のある時点において最も顕著な談話要素)という概念を導入することによって照応や省略の解決を行なう。または、日本語において発話から語用論的制約を抽出し、制約充足プロセスに基づいて文脈の下で解釈することによる文脈省略の補完手法を提案している。一方、外界省略も含めた補完手法に対しては、ヒューリスティックスなどによる経験的な解決手法を中心にいくつか提案されている。このうち日本語を対象にしたものとしては、村田ら、江原ら、Nakaiwaetal.の研究などがある。は補完に関係する表層的な言語現象をヒューリスティックスで得点を付与し、それらの合計によって最尤の省略内容を補完している。この手法は多くの言語情報を利用した省略補完手法であるが、対話文に対しては十分な考慮がされておらず(節を参照)、また得点の調整には困難を伴うことが予想される。または複文を単文に分割した際に生じる省略主語を補完するという問題に対して、経験的に8項目の特徴パラメータを設定して、確率モデルによる手法を提案している。一般の省略に対して有効であるか現時点では不明であり、少なくとも本研究の対象とは問題が異なるために確率モデルや特徴パラメータを再検討する必要がある。では用言意味属性と語用論的、意味論的制約を用いて外界省略の解消を行なっている。必要とする知識量が膨大であり、保守コストや他言語への適用を考えた場合に課題が残る。本論文の目的は、(1)対話における省略という現象の分析、問題設定(2)決定木と決定木学習による問題解決手法の提案(3)提案手法の特性の議論、の三点である。後述するように、対話においては外界省略の割合が高いが、このような状況下で我々はすべての省略を同一の枠組みで補完することは現実的でないと考える。また対話においてどのような問題設定が適当かはこれまで十分に議論されていない。そこでまず、対話における現象を分析し本論文における問題設定を節において行なう。次に、節で提案手法の説明を行なう。本論文では、省略補完知識の決定木(decisiontree)による表現、及び省略情報の正解付きコーパスから言語現象と補完すべき省略の関係を帰納的に機械学習し、これによって日本語対話文の格省略を補完する手法を提案する。本研究は機械学習手法の提案が目的ではないので一般的に知られている機械学習手法を利用し、どのような情報をどのように使用し、いかに機械学習させるべきかを提案する。論文の後半では、提案手法の特性を議論する。節においては、提案手法の有効性を議論するために行なった実験について述べる。節では決定木を観察することによって使用属性などに対する議論を行なう。両節での議論によって、提案手法がどのような特徴を持ち、またどのような限界があるのかを明確にする。最後に本論文の結論を節で述べる。近年多くのテキストやシソーラスが機械可読化されてきており、多くの場合これらの言語資源は入手が可能となっている。本研究では、他の話題への適用性を考慮して、形態素分割されて品詞と省略情報が付与されたコーパス、及びシソーラスのみを用いて行なう手法を試みる。提案手法は、特定のコーパス、品詞体系、シソーラスをいずれも仮定しないため、大量の知識を作成、保守する必要性がなく、手作業による補完規則やパラメータの調整を行なう必要もない。また本手法では、構文解析も仮定しないため、構文解析の手法や精度とは独立である。本論文は、日本語対話文を英語やドイツ語に翻訳する際に必要となる処理を想定しており、省略内容の人称と数を補完するという問題設定を行なっている。また、省略の検出処理は他の処理部によって格要素の省略が正しく検出されると仮定する。なお、本論文は以前報告した文献及び文献の内容を基本にして議論、検討を行ない、新たにまとめたものである。</section>
  <section title="日本語における格要素の省略現象">本節では格要素の省略という現象の考察を行なう。対話と文章、格による相違という二つの視点から格要素がどのように省略されるのかを議論することによって、本研究で解くべき問題の設定を明確にする。</section>
  <subsection title="対話と格要素省略">前述したように、格要素の省略には文脈省略と外界省略の二種類あるでは、補完要素が省略された格要素を持つ文中にある場合(文内照応)とその文以前にある場合(文間照応)とに分けている。。この二種類の省略の出現割合はテキストの種類によって、つまりそのテキストが対話(音声言語)か文章(新聞や小説などの文字言語)かによって大きく異なることが想像できる。この関係を表にしたものを表に示す。本研究の対象となる対話について考えると、文章とは省略の様子が大きく異なることがわかる。文章は多くの場合、それ自体で完結していることが必要であり、読者を明確に特定できない場合が多いため読者との共有知識を明確に定義できず、それ故省略もそれほど多く起こらない。また省略された場合の補完内容は、その文章内にある場合が多いと考えられる。これに対し対話(特に二者対話などの少数聴者に対する対話)では、相手に情報を伝えることが目的であり、双方向でコミュニケーションをとりながら進行するため共有知識も次第に増え、その結果省略も多用される。また、コミュニケーションをとる必要上、対話参加者に関する省略、つまり外界省略が比較的多いと考えられる。以上のような理由により、省略の補完処理についてもどのようなテキストを対象にするかによってどの省略を中心に取り扱うかが自ずと決まる。</subsection>
  <subsection title="表層格による格要素省略の差異">省略された格要素が外界省略か文脈省略かは格によっても大きく傾向が異なる。以下では、日本語の主たる表層格要素であるガ格、ヲ格、ニ格について考える。ガ格は、動作や状態の主体または対象を表す場合に使用される。これらを観察すると、動作の主体または対象が省略される場合と、状態の主体または対象が省略される場合で、省略及び補完に必要な情報の傾向が大きく異なることが予想される。以下の[]は動作を表す文であり、[]は状態を表す文である。前者のガ格は人である場合が多いが後者ではガ格が人になる割合はそれほど多くない。早く電車に乗ってください。とても冷たいですね。example以上の検討より、本論文では省略された文の述部によってガ格を二つに分離し、別個のものとして取り扱った。すなわち、一つは述部が動詞の場合、もう一つは述部が形容詞、形容動詞、あるいは「名詞＋判定詞(だ/です)」の場合である。以下では、前者をガ格(動)、後者をガ格(形)と表記する。なお、ガ格分離の妥当性は後で考察する。ヲ格は、動作や感情を向ける対象や移動の場所、起点を示す。このため、動作や感情の対象が対話参加者となる可能性のある一部の動詞(「紹介する」など)を除いて、多くの場合が照応的な省略、文脈省略となることが予想される。ニ格は、動作を向ける相手(「彼に見せる」)、移動の着点(「京都に着く」)などいろいろな用法がある。ニ格となる名詞には様々な種類が考えられるが、大別すると、人、場所、抽象物(時間を含む)、具体物に分けられるが、多くは人であると予想される。以上の考察の妥当性を確認するために、対話コーパス(節を参照)499対話(18385文、省略総数15397)における省略された格の補完内容を実際に調査した。その結果を表に示す。これより、ガ格(動)とガ格(形)ではその省略の傾向が異なること、ヲ格はほとんどが文脈省略であること、ニ格の89.1%が外界省略であることなどがわかる。</subsection>
  <subsection title="対話文の問題設定と補完戦略">本研究の目的は、日本語から必須格を持つ目的言語への機械翻訳において、省略されている必須格要素の人称と数を補完することである。しかし前述したように、文章と対話によって省略の傾向が異なり、これらすべてを対象にして統一的な処理を行なうことは適当ではないと考える。そこで、対話において比較的重要な外界省略を主たる対象にして、本論文では以下のように問題を設定した。外界省略の人称と数の補完文脈省略の認知これまで、照応的な省略に対しての研究はいくつか行なわれている。これらの研究は以上の問題設定とは相補的になる。すなわち、本論文の手法によって文脈省略と認知することができれば、省略内容の補完処理はこれらの従来研究、例えばセンタリング理論によって解くことが可能となり、対話におけるすべての格要素省略の問題を解くことができる。</subsection>
  <subsection title="コーパスと話題">本研究で使用したコーパスは、チケット予約、観光案内などにおける二者の対話を収録したATR旅行会話コーパス(以下、「コーパス」と呼ぶ)である。おおよそ1対話は20文から40文で構成され、平均は26文である。コーパスは全部で618対話からなるが、本研究ではそのうち499対話を調査、決定木学習及び実験に使用した。コーパスは、ホテルにおける旅行客とフロントの対話を中心に、広範な範囲の対話を収録している。本論文ではこれを大きく表に示す4つの話題に分類した。この分類は節での話題依存性での議論の際に使用する。</subsection>
  <section title="決定木を用いた省略補完">本節では、省略の補完に必要な二つの側面、多要素性と相互依存性について検討を行なった後、提案する手法について述べる。</section>
  <subsection title="多要素性">日本語における格要素の省略内容の補完には、非常に多種多様な要素が関係していることは、以前から知られている。従来文献においても、例えばDohsakaは、待遇関係、視点関係、制御関係、情報のなわばりに関する語用論的制約によって補完を試みている。また、工藤らは、謙譲、丁寧、可能、完了などの意味を持つ機能語と、動詞の語彙的な特性による省略補完手法を提案している。省略補完に必要な情報の例を、以下に示す。待遇表現対話において尊敬語や謙譲語などが使用された場合には、誰の動作か述べる必要がなくなり、ガ格が省略される。すなわち、ガ格の補完にはこれら敬語は重要な情報を果たす。そちらに参ります。(ガ格は一人称)example平叙/疑問/命令以下の例では、疑問文かどうかでガ格が異なる。わかりました。(ガ格は一人称)わかりましたか。(ガ格は二人称)example動詞の持つ意味例えば、以下の発話がホテルのフロントと客との対話と仮定すると、どちらの発話かに関係なく、当該動詞のガ格の内容が決まる。キャンセル待ちを調べて(ガ格はフロント)JRに乗って(ガ格は客)example前文以前の情報(文脈情報)対話におけるこれまでの話の流れ。言語外情報その文が、どこで、誰が誰に対して発話されたか、など。例えば、[]で、ガ格の人称を決定するには、話者がフロントと客のどちらか、という情報が必要となる。このように、対話文において省略を補完するためには多くの情報が必要と考えられる。さらに用言の持つ意味は省略の補完にとって重要な情報であると思われるが、その重要性は個々の用言によって異なると考えられる。このように非常に多くの要素が考えられるが、このうち個々の補完事例に本当に必要な要素のみを選択することが可能な補完手法が必要とされる。人手による補完規則作成によるアプローチは、このような言語現象に対して個々に考察を行なう必要があり、一般的には困難が伴う。</subsection>
  <subsection title="相互依存性">例として、以下の発話において「忘れる」のガ格を補完することを考える。部屋/に/カメラ/を/忘れ/てき/てしまっ/た/ような/んです/が。exampleこの例では、動詞「忘れる」の持つ意味属性や「てくる」「てしまう」「た」「ようだ」「んです」「が」といった文末表現など、多くの要素が省略補完に関係する可能性があり、このうちどの要素がどの程度省略補完に影響しているかを明確に記述することは難しい。また、影響の範囲は文末表現間のみ、あるいは用言と文末表現の組み合わせに限らず、例えば以下のように接頭辞と文末表現の組み合わせで考慮すべき例もあり、その関係は多種、複雑である。近鉄にお乗りになってください。exampleこのように、格要素の省略補完に必要な情報は独立ではなく、相互に影響しながら省略が可能になることに注意しなければならない。つまり、[]で言えば、「お」と「になる」の出現に対して、個別に補完内容の補完をすることはできない。あるいは、ホテルのフロントにおける受付と客の対話で、一般的に「宿泊する」の動作主は客もしくは「一般的な人」であるが、ある特殊な文脈によってはそれ以外の可能性も考えられ、一概に「宿泊する」という動詞のみでは決定できない。格要素の補完では、多種多様な言語現象からどの2要素(あるいはそれ以上)に対して、同時に考慮する必要があるのかを検討する必要がある。</subsection>
  <subsection title="補完情報の付与">決定木学習による学習、並びにテストを行なうことを目的に、対話コーパスに補完内容の情報を付与した。今回付与したタグの種類を表に示す。本論文では、表に示すように6種類のタグを設定した。タグの付与に関して、これらの補完内容は日本語のみを考慮して付与した。財布を盗まれた。Mywalletisstolen.MeinGeldbeutelistgestohlenworden.example例えば以上の例文において、[]におけるガ格は「私」であるが、その英語訳である[]の主格は`mywallet'、ドイツ語訳である[]の主格は`meinGeldbeutel'である。このように翻訳先の言語によって人称が変わる場合があるが、英語などへの翻訳時に人称がどうなるかという観点では付与しなかった。つまり上記の例では用言「盗む」に対して&lt;1sg&gt;(＝一人称単数)のタグを付与した。これは、一般に訳し方は一通りでないこと、翻訳の目的言語が英語のみではないこと、などの理由による。右へ曲がると交番です。example日本語においては、[]などのように、特定されない人称を省略要素とする文、つまり一般的な「人」を念頭において発話していると考えられる文がしばしば見受けられる。このような場合、例えば英語への翻訳の場合には人称代名詞`you'を、ドイツ語への翻訳の場合には不定代名詞`man'を主格にすることが多い。しかし、それぞれ二人称、三人称の省略などとは異なる現象であること、想定する翻訳目的言語が英語、ドイツ語などと複数であることを理由に、一人称や二人称とは別のタグ&lt;g&gt;を設定した。以下便宜上、このタグを「一般(人称)」と呼ぶ。以上は外界省略として扱える。省略位置以前の要素に照応先がある場合、つまり文脈照応の場合は、一括して&lt;a&gt;のタグを付与した。本論文では、対話文に頻出する外界省略の補完に主眼を置き、文脈省略に関しては当該省略が文脈省略であることの認知のみを行ない、具体的な先行詞の補完は別処理で行なうと仮定した。</subsection>
  <subsection title="決定木と決定木学習">多岐にわたる情報を統一的に、かつ自動的で一意に省略を補完する手法として、本研究では決定木を用いる。決定木は、根付き有向木で表現される知識表現構造であり、以下の利点を持つ。木という単純な構造の組み合わせによって多要素が複雑に関係した概念が表現できる透明性が高いため、要素間の影響が明確に記述され、手作業による変更が十分に可能である処理が高速で、多くの場合処理時間は実用上無視できる程短い決定木の各分岐節点はある属性に対応してその属性値によって枝分かれしていき、それぞれの葉で意志決定が行なわれる。決定木は分岐節点における分岐数によって大きく二分木と多分木とに分かれるが、本論文では前者を使用した。これによって、属性値は`Y'または`N'の二値になる。決定木の例を付録のに示す。コーパスからの帰納的学習により決定木の作成を行なう。本研究ではID3のアルゴリズムと同様、エントロピー規準による貪欲法(greedyalgorithm)によって決定木学習を行なった。また、枝刈り(pruning)は行なっていない。</subsection>
  <subsection title="使用属性">省略された格要素を補完するためには、種々の情報を考慮して行なわなければならない。本研究では計367の属性を使用した。その内訳を表に示す。表に示すように、属性は内容語、機能語、言語外情報に大きく分類できる。以下ではそれぞれについて説明する。すべての属性は(照合方法,照合位置,属性値)の三つ組によって表現される。照合方法は、+:speaker+(話者の照合)、+:regexp+(正規形による形態素の照合)、+:semcode+(意味属性の照合)の3種類である。照合位置は、補完の対象となる用言の位置を基準として以下に示す5種類を設定した。例えば、照合位置として補完対象用言に関しては+:here+、格助詞に対しては+:before+、接頭辞に対しては+:latest+を与える。話者の照合+:speaker+の対象は常に省略された文であり、位置情報は一意に決まるため不要であるが、他の属性との整合性をとるため便宜上+:here+を与える。照合対象が複数の形態素となる+:before+と+:after+に関しては、照合範囲にある形態素のいずれかが属性の条件を満たすかどうかによって照合を行なった。具体的な属性の例と、その意味を以下に示す。(:speaker:here情報提供者)文の話者が情報提供者である。(:regexp:after(&quot;たい&quot;&quot;助動詞&quot;))用言の後に助動詞「たい」を含む。(:semcode:here30)用言の意味属性が30である。(:semcode:before81)用言の前に意味属性81の内容語を含む。用言の直前の語が接頭辞の「お/ご/御」である。3複文や重文などの、文が複数の単文からなる場合には、近似的に単文に分割した。分割手法は、接続助詞を分割位置にしてその前後を分割した。</subsection>
  <section title="実験">本節では、学習された決定木による省略補完の有効性を検証する。まず、ガ格(動)に対して検証を行ない、続いてガ格(形)、ヲ格、ニ格に対しての有効性を議論する。さらに、学習量、決定木学習の話題依存性、使用属性による相違の三点から検討を行なう。本論文では、性能評価尺度としてF値(F-measure)を用いる。F値は、再現率(recall)と適合率(precision)を一つの尺度として表現するために使用される尺度で、Rを再現率、Pを適合率としたとき、以下の式で定義する。33ここで、パラメータは適合率の再現率に対する相対的な重要性である。本論文ではこのパラメータを=1とした。</section>
  <subsection title="基本条件による実験">まず、以下の条件により実験を行なった。実験対象はガ格(動)の省略属性集合は表に示した367属性学習文はコーパスから100対話を無作為に抽出した集合テスト文は学習文と同一の話題の100対話表に、以上の条件による結果を示す。単位はF値である。表の「学習文」の欄は、学習文とテスト文を同一にして行なったテスト(closedtest)の結果である。3種類の話題H_1、H、Tの中から各100対話を無作為に選択して実験を行なった。「未知文」の欄は、未学習文に対するテスト(opentest)を意味する。学習文テストTで用意した100対話と同一の集合をテスト文にして、それに含まれない100対話をコーパスより無作為に抽出した集合で決定木学習を行なった。また同表には比較対象として、補完内容を無作為に選択した場合の精度を(比較A)に、補完内容をすべて最多事例の人称(&lt;1sg&gt;)に一意に決定した場合の精度を(比較B)に示した。また表の最下段に、未知文テストにおける学習文およびテスト文の人称別省略事例数を示した。また、未知文テストを行なうためにコーパス100対話から作成した決定木の一部を付録のに示す。決定木の再現性、弁別性を確認することを目的に行なった学習文テストでは、決定木の枝刈りを行なっていないため、話題の広さに関係なくほぼ100%の再現性を示した。未知文に対するテストでは、(比較A)、(比較B)のいずれよりも高い値を示し、本手法の有効性が確認された。なお、表はF値のみであるが、再現率と適合率は共にF値とほぼ同一の値となっている。人称別では、ほぼ学習事例の多い順に精度が良くなっていることがわかる。&lt;1sg&gt;、&lt;2sg&gt;、&lt;a&gt;に関しては比較的良好な性能を得ることができたが、&lt;1pl&gt;、&lt;2pl&gt;、&lt;g&gt;については低い精度しか得ることができなかった。これは学習事例数の不足が一つの原因と考えられる。誤りの主な傾向を以下に分類する。複文の単文分割に関係する誤り照合範囲の誤り単複の弁別性に関係する誤り文脈省略に関係する誤りタグ付与のゆれこれらのうち、単文分割に関係する誤りと照合範囲の誤りが最も多かった。前述したように、本研究では接続助詞によって擬似的に単文分割しているが、例えば以下の例文のような場合には、「行けば」だけに対して補完処理を行なってしまい、提案手法が有効に機能しない(例文の下線は補完対象用言、`/'は形態素区切り、`//'は設定した文区切りを示す)。どう/やっ/て//行け/ば//いい/か/分から/ない/ん/です。exampleまた単文であっても、以下の文で「予約」の補完を行なう場合のように、補完対象の用言(「予約」)の補完に、これとは関係のない付属語(「いたす」「ます」)によって判断してしまい、その結果失敗する。現在/ご/予約/の/フライト日/と/便名/を/お/願い/いたし/ます。example以上は本手法の問題点であるが、文分割と属性照合を共に厳密にすればよいので、今後十分に対処可能な課題である。一方、単複の誤りと文脈省略に関係する誤りは本質的に難しい問題であり、現在用意した属性のみによるこれ以上の精度向上は難しいと考えられる。より一層の精度向上には別の情報が必要である。</subsection>
  <subsection title="他手法との比較">日本語格要素の省略補完を行なう手法はこれまでにもいくつか提案されている。ここでは、このうちのいくつかの手法と定性的な比較を行なう。補完の手がかりとなる現象を人手で得点化したでは対話文章中の省略のための規則も作成し、物語文を対象にした実験の結果、学習文(204文)で86%、未知文(184文)で76%の省略が補完できたと報告している。同論文と本論文との差異を以下に示す。AoneandBennettは文献において、本論文と同様に機械学習による省略補完処理を行なっている。ここでは、照応の先行詞補完の一部として省略補完処理を行ない、合弁事業に関するテキストにおいて先行詞が組織名である省略の補完実験を行なった結果、最高で再現率が40.8%、適合率が73.0%の補完精度が得られたと報告している。同論文では先行詞の種類が所与(組織)で組織名を推定することが目的であり、先行詞の種類(人称)補完を目的とする本論文とは問題の性質が異なる。また対話文を対象にした補完処理ではないために文脈省略の補完のみを考慮していることから、本論文と直接比較することはできない。日本語対話文を対象に省略補完を行なっている研究として、文献がある。工藤らの実験は本論文と同一のコーパスに対しても行なっており、補完規則作成に使用した文に対する省略補完精度として93.2%の補完精度が得られたと述べている。また文献は日英機械翻訳システム評価用例文の175事例に対して実験を行ない、情報抽出に使用した文に対してテストを行ない、100%の精度を得たと報告している。これら両論文はどちらも未知文に対しての報告がない。これらを比べた時、本論文には以下の優位性があると考える。</subsection>
  <subsection title="表層格との関係">ここでは、日本語の主たる表層格であるガ格、ヲ格、ニ格に対する補完精度の比較を行なうことによって、格との関係を考察する。本来ならば、補完に必要な属性は格によって異なると考えるのが自然である。しかし本論文では、手法の有効性を議論し、格による差異を明確化することを目的とするため、網羅的に属性を用意し、すべての格で学習時に同一の属性集合を用意した。学習時に用意した属性集合は、これまでと同様、表の367属性である。実験は、それぞれの格について300対話を学習対話とし、それらに含まれない100対話をテスト対話として未知文テストを行なった。その結果を表に示す。なお、表でガ格(動)として示した値は、表の`400(対話)'の項と同一の実験である。表からわかるように、ガ格(動)とガ格(形)との比較では全体としての補完精度に大きな差異はないが、個別の人称に対する精度では両者に明確な差異が現れている。表には現れていないが、ガ格(形)の補完人称に比較的多くの&lt;a&gt;が含まれているため、&lt;1sg&gt;あるいは&lt;2sg&gt;に対する学習が十分に行なわれず、比較的低い精度になったと推察される。一方ヲ格については、90%以上の省略が照応的(&lt;a&gt;)であり、外界省略がほとんどないことから非常に高い数字となった。本手法によってヲ格の文脈省略の認知は高精度で可能であるので、認知された文脈省略に対し従来から知られている照応解決の諸手法を導入することによって解決できるものと考えられる。ニ格に関しては十分な性能が得られた。このように高い性能が得られた背景には、二者対話を対象にしたテキストであること、話題が旅行対話に限定されているために使用される述語がある程度限定されることなどが考えられる。ニ格の多くは間接目的語で外界省略が多かったため、少数候補からの択一問題に有効な本手法が有利に機能したものと考えられる。</subsection>
  <subsection title="学習量との関係">学習量との関係を見るために以下の実験を行なった。学習量として、25、50、100、200、400対話の5種類の集合を作成した。ここで、これらの集合は包含関係となるように作成した。テスト集合はこれらのいずれにも含まれない100対話(ガ格(動)の省略数:1685)を用意した。また、学習属性は表のものを使用した。主な人称に対する実験の結果をF値で表に示す。なお、表の「100(対話)」の欄は表の「未知文」の欄と同一である。表によれば、ほぼすべての人称に関して学習量の増加と共に性能が単調に向上している。また、表には示されていないが、再現率、適合率共に単調増加の傾向を示している。ただし、その増加の割合は徐々に鈍化し、&lt;1sg&gt;に関しては400対話で精度がわずかに減少していることがわかる。補完内容と学習量の差をグラフにしたものを片対数グラフで図に示す。グラフが示すように、比較的学習事例数の少なかった&lt;2pl&gt;や&lt;g&gt;が、学習量増加に伴い大きく精度が向上していることがわかる。その様子から、&lt;1pl&gt;を含めたこれらの人称に関しては学習量の増加によって一層の精度向上が予想される。一方、その他の人称並びに全体的な精度に関しては、全体として400対話(6806事例)でほぼ横ばいになっていることから、10^410^5事例の学習量で十分であると言える。またグラフより、人称に関わらずほぼ一定の精度を示していることから、この時の補完精度(本手法による補完精度の上限)は80%85%となると予想する。</subsection>
  <subsection title="話題依存性">ここでは、実験の結果と共に、決定木学習の話題依存性を議論する。学習用のテキストとして、四つの話題H_1、H_2、R、Tに属する対話を50対話無作為に抽出し、これによって決定木学習を行なった。テスト用の対話は前節と同一の未学習100対話を使用し、未知文テストを行なった。このとき、属性は表の367属性を使用した。表に、テスト対話(＝コーパス全体)の話題別構成比、並びに話題依存性を示す。表の縦は学習対話の話題、横はテスト対話の話題を示し、値はF値で表現した。表に示すように、学習対話とテスト対話が一致している時に、H_2を除いて最も良好な性能となった。またH_2においてもかなり高い性能を示した。この傾向は話題に関係なく言えることから、あらかじめテスト対話の話題がある程度限定される、もしくは予測できる問題に対しては、できるだけ同一の話題のみによって学習することが望ましく、その際にテスト対話以外の話題を含めて学習しないことが重要であると考えられる。学習文の話題別性能では、話題Rが最も高い性能を示した。この理由は、話題Rが何か特殊な情報を持っているためではなく、話題Rの構成比が最も高かったためである。また表によると、広範な話題で学習を行なった場合(T/)に、全体としても平均以上の補完精度を示した。学習文とテスト文の話題が同一の場合を除くと、T/はすべての話題に対して良好な性能を示していることが観察される。このことから、テスト文の話題が未知の場合は、広範な話題に対して学習を行なうことが最も有効であることが示唆される。ただし表の最下段に示すように、全く未知の話題(H_R)に対しては若干精度が低下する。たとえ少量の学習であっても、未学習よりはかなり優位であることがわかる。</subsection>
  <subsection title="属性との関係">本節では、格要素の省略補完の問題解決にどの程度使用属性が関係するかを議論する。これまでに述べてきた諸実験は、比較のため、すべて同一の属性集合を使用して行なってきた。ここではこの使用属性を変化させることによって補完精度がどうなるかを観察する。ここでは、以下に示す4種類の属性集合を用意した。これらはいずれも表に示した属性の部分集合である。言語情報のみ(366属性)機能語のみ(166属性)内容語のみ(200属性)用言情報のみ(100属性)実験は100対話の学習、未学習100対話のテストにより行なった。この対話集合はどちらも、表の未知文テスト、あるいは表の`100'の実験と同一である。実験結果を表に示す。比較対象として、全属性に実験の結果を表の「全属性」欄に示す。表より、言語情報のみを使用した学習では、言語外情報を加えた場合とほとんど同程度の精度が得られた。これは、言語外情報(特に実験で用意した話者情報)がそれほど省略補完に重要でないことを示す。この結果は我々の予想に反するが、おそらく旅行対話という限られた分野での実験であったため、用言の情報が話者情報を包含するような関係になったことが理由として考えられる。つまり用言によって話者が推測できたため、話者情報の必要性が低下した可能性がある。これらを確認するには、両者が対等な関係にある状況での対話、例えば自由対話に対して省略補完実験を行なうことが必要であろう。機能語のみで決定木学習を行なった場合、全体で8%程度の精度低下が観察された。この結果は、話題に依存しない機能語のみで決定木学習した場合に、その精度に限界があることを示している。また、機能語のみの結果は文脈省略(&lt;a&gt;)認知に対して大きな精度低下が見られることから、内容語は比較的照応関係の維持に寄与していることが予想される。内容語のみの場合はさらに低い精度となった。日本語対話文においては、内容語よりも一部の機能語の存在によって省略が可能となる場合が多いということをこの結果は示している。さらに用言情報のみを使用した場合は最も悪い精度を示したが、これは対話文の省略補完が書き言葉のそれと異なる大きな特徴の一つと考えられる。すなわち、用言情報などの内容語は対話文での省略補完においては相対的に重要性は低いが、文脈省略の先行詞補完など、照応処理に関しては逆に重要性が増すと予想する。</subsection>
  <section title="議論">決定木はある問題に対しては非常に便利な知識表現手段であるが、可読性もその特徴の一つである。本節では、これまでに述べた諸実験において作成された決定木を観察することによって、属性の充足性、個々の属性の重要性などを議論する。</section>
  <subsection title="決定木の形状">学習数と決定木の節数との関係を両対数グラフにしたものを図に示す。また各決定木の最深節と最大幅を表に示す。この図より、学習量を変化させて作成したガ格(動)の決定木において、学習量と節数はほぼ対数的に線形であることがわかる。本研究では決定木学習に際し枝刈りを行なっていないため、このような関係になったものと推察される。ガ格(形)に関してはほぼガ格(動)と同様の節数となった。ニ格に関しては、ガ格(動)よりはいくぶん小さな木となっていることがグラフよりわかる。またヲ格はほとんどが&lt;a&gt;であるため、ほとんど事例分割の必要性がなく、最も小さな木となった。</subsection>
  <subsection title="事例被覆率">補完内容の決定に対する各属性の重要性を見る一つの尺度として、「事例被覆率」を定義する。ある属性の事例被覆率は、その属性が決定木の意志決定に使用されている事例数の、全事例数に対する割合である。例えば決定木の根で使用されている属性の事例被覆率は、すべての事例がこの属性を(最初に)検査することから、100%となる。この尺度から、各属性の意志決定に対する寄与度が数値化できる。まず、学習量との関係を議論した節での実験における主な属性の事例被覆率を表に示す。表の上部に示した通り、事例被覆率が100%である属性(＝最上部で検査される属性)は「+:here43+」つまり対象となる用言の意味コードが43(意向)であるかどうか、であった。この属性や「+:here41+」(思考)には共に「思う/考える/願う」などの語が含まれており、話者の意図や希望を表現している。これらの動詞は旅行対話に限らず広く使用されるため、この両属性はその他の内容語とは異なる一種の機能語のような役割を果たしていると考えられる。ただ、この両属性のように学習量に関係なく事例被覆率の高い属性はむしろ少数で、同一の格、同一の話題であっても学習量の増加と共に多くの属性の事例被覆率が変化していることが観察できる。表によると、学習量が少ない時は+:before+、つまり対象となる用言以前にどのような内容語が存在したかに関して多くの注意が注がれ、学習量の増加に伴って機能語、特に尊敬を示す「てくださる」「召し上がる」などの語の存在によって人称を判断するようになることがわかる。次に、格要素別の事例被覆率を表に示す。ここでも、ガ格(動)とガ格(形)の明確な差異が見受けられる。ガ格(形)の決定木は他の各要素の内容、例えば「で」などの格の存在とその格要素に関する属性が多いのに対して、一方ガ格(動)は述語と一部の重要な機能語に関する属性が多い。またニ格補完に作成した決定木は、一部の相違はあるもののガ格(動)と類似の傾向を示した。なお事例被覆率による結果では、話者の役割は我々が事前に予想したほどの重要性を持っていないとの結果となった。これは、用言と話者役割の情報を共に使用することによって補完内容が特定される場合を想定していたが、このような例があまり多数存在しなかったため、もしくは旅行対話における二者対話という制約が強く働き、話者を知る必要がないため、などの理由が考えられる。</subsection>
  <section title="結論">日本語対話文の格要素省略に対して、決定木による補完処理の表現および機械学習によって補完知識を獲得する手法を提案した。補完に必要な知識として、内容語の意味属性、機能語の存在、話者知識の三種類を使用した。本論文で提案した手法は入力として品詞付き形態素列のみを使用しており、構文解析を必要としない。本手法により獲得した決定木で未学習文に対してテストを行なった結果、ガ格とニ格に対しては十分な精度で省略された人称を補完することを確認した。ヲ格に関しては、その補完内容が照応的であるという認知を行なうのに有効であることを確認し、本手法の有効性を確認することができた。また提案手法に関して、処理の有効性を学習量、話題依存性、使用属性との関係の3点から議論した。本研究で得られた主な知見を以下にまとめる。ガ格(動)やニ格は、尊敬を示す機能語などを重要視する。ガ格(形)は他の格要素の情報によって補完を試みる傾向がある。当該問題に対する学習量は全体として10^410^5事例で十分である。この時の補完精度の上限は80%85%と予想される。対話の話題が既知もしくは予測可能な時は、その話題のみによる学習が最高の性能を示す。話題が未知の場合は、可能な限り広範な話題に対して学習するのが最も効果的である。学習量増加に伴い、決定木は話題に依存しない機能語などの属性を採用する。本論文では日本語対話文における格要素の補完処理に限定して述べてきたが、提案手法の有効性はこれだけにとどまらない。例えば韓国語は日本語などと同様に格要素の省略が観察される。韓国語などにおける省略補完処理も本手法の応用によって可能になると考えられる。本論文で述べた手法を今後、多言語話し言葉翻訳システムTDMTの日英翻訳/日独翻訳部に組み込み、本処理が翻訳結果に与える有効性について検討を行なう。*-10mm10</section>
  <section title="決定木の例">本提案手法で作成される決定木の例を図に示す。この決定木は、節の表における「未知文」の欄の実験(補完対象:ガ格(動)、使用属性数:367、話題:T、学習対話数:100、省略数:1710)により実際に作成されたものの一部である。例えば(1)に示す葉には128事例が学習で集まり、最多要素(＝補完人称)が&lt;1sg&gt;であったことを示す。また、この意志決定が行なわれるまでに、+:here43+(意向)--&gt;[Y]+:here78+(社交)--&gt;[N]+:after+か(終助詞)--&gt;[N]+:after+できる--&gt;[N]+:here40+(感覚)--&gt;[Y]という五つの属性に対して検査されてきていることを示す。ここで、属性の条件を満たすときは[Y]、満たさない時は[N]と表記している。形態素に関する属性にはすべて品詞情報も付与してあるが、以下に示す例では省略した。ただし、多品詞語に対しては品詞名も表記した。また便宜のため、内容語の意味属性に対してはそのラベル名も記した。</section>
  <section title="決定木学習に使用した発話の例">節の例において、主な終端節点での発話の例を示す。以下では、`/'は形態素区切りを、下線は補完対象となる用言を示す。また、すべての形態素は正規形で表記する。</section>
  <subsection title="節点(1):一人称単数 128事例">ケーブルカー/が/おもしろい/と/思う/ます/ね/。予約/の/必要/は/ない/か/と/思う/ます/。バス/の/中/で/ご/ゆっくり/お/休む/いただける/と/思う/ます/が/。一/泊/する/たい/と/思う/ている/ます/。その際/に/はっきり/する/た/お/答え/が/できる/か/と/思う/ます/が/。ええ/そう/だ/と/思う/ます/。二/時間/で/終わる/と/思う/ます/。それでしたら/当ホテル/の/桔梗の間/が/ちょうど/大きい/さ/よろしい/か/と/思う/ます/。わたくし/ども/の/要望/する/会場/使用料/の/限度/を/分かる/ていただける/た/と/思う/ます/。使いで/は/より/よい/なる/と/思う/ます/けれども/。</subsection>
  <subsection title="節点(2):文脈省略 120事例">はい/分かる/ます/た/。分かる/ます/た/。はい/分かる/ます/た/鈴木/様/。わかる/ます/た/。分かる/ます/た/どうも/ありがとう/。なるほど/分かる/ます/た/。そう/です/か/分かる/ます/た/。分かる/ます/た/では/お/願う/いたす/ます/。わかる/ます/た/お/調べる/いたす/ます/。だいたい/分かる/ます/た/。</subsection>
  <subsection title="節点(3):二人称単数 58事例">少々/そのまま/で/お/待つ/くださる/ます/。少々/お/待つ/くださる/。少々/お/待つ/くださる/ます/。はい/少々/お/待つ/くださる/ます/。しばらく/お/待つ/くださる/ます/。それで/こちら/の/番号/が/ちょっと/待つ/てどうも/ありがとう/ちょっと/待つ/てくださる/。もう/少々/そのまま/で/お/待つ/いただける/ます/か/。お/部屋/の/ほう/で/少々/お/待つ/くださる/ます/。もう/少々/お/待つ/いただける/ます/でしょう/か/。document</subsection>
</root>
