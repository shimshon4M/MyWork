



\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{73}
\setcounter{巻数}{6}
\setcounter{号数}{7}
\setcounter{年}{1999}
\setcounter{月}{10}
\受付{1999}{3}{24}
\再受付{1999}{4}{30}
\採録{1999}{5}{10}

\setcounter{secnumdepth}{2}
\setlength{\parindent}{\jspaceskip}

\title{局所的要約知識の自動獲得手法}
\author{加藤 直人\affiref{NHK} \and 浦谷 則好\affiref{ATR}}

\headauthor{加藤, 浦谷}
\headtitle{局所的要約知識の自動獲得手法}

\affilabel{NHK}{日本放送協会放送技術研究所}
{NHK Science and Technical Research Laboratoies}
\affilabel{ATR}{ATR 音声翻訳通信研究所}
{ATR Interpreting Telecommunications Research Laboratories}

\jabstract{
日本語ニュースを局所的要約する際に必要となる要約知識を，コーパスから自動獲得する手法について述べる．局所的要約とは注目個所の近傍の情報（局所的情報）を用いて行なう要約をいう．局所的情報には注目個所そのものやその前後の単語列などがある．本手法では要約知識として置換規則と置換条件を用い，これらを原文−要約文コーパスから自動獲得する．はじめに原文中の単語と要約文中の単語のすべての組み合わせに対して単語間の距離を計算し，ＤＰマッチングによって最適な単語対応を求める．その結果より，置換規則は単語対応上で不一致となる単語列として獲得する．一方，置換条件は置換規則の前後ｎグラムの単語列として獲得する．原文と要約文にそれぞれＮＨＫニュース原稿とＮＨＫ文字放送の原稿を使って実際に要約知識を自動獲得し，得られた要約知識を評価する実験を行った．その結果，妥当な要約知識が獲得できることを確認した．}

\jkeywords{自動要約，コーパス，自動獲得，言語知識，日本語ニュース，ｎグラム}

\etitle{A new approach to acquiring linguistic \\knowledge for locally summarizing \\Japanese news sentences}
\eauthor{Naoto Katoh \affiref{NHK} \and Noriyoshi Uratani\affiref{ATR}}

\eabstract{This paper proposes a new approach to acquiring linguistic knowledge for local context-based summarization. Our summarization method can transform characters, words, and Bunsetsu-phrases to the shorter ones by using linguistic information on some words to be summarized and some words located before and after the summarized words. Our linguistic knowledge for summarization, which is composed of transformation rules and transformation conditions, is automatically acquired from Japanese news corpus. In our corpus, original articles and the human-summarized ones are collected from NHK news text and NHK teletext respectively. The proposed method analyzes original news sentences and the summarized ones by Japanese morphological analyzer, and aligns original words with the summarized words by DP matching based on distances between both of the words. Transformation rules are acquired as the result of the difference. Transformation conditions are extracted as n-gram words located near a transformation rule. We acquired linguistic knowledge from NHK news corpus and obtained a high accuracy rate as a result of a series of experiments to evaluate the linguistic knowledge.}

\ekeywords{automatic summarization, corpus, automatic acquisition, linguistic knowledge, Japanese news, n-gram}

\begin{document}
\maketitle


\section{はじめに} \label{sec:sec1}
インターネットの普及も手伝って，最近は電子化されたテキスト情報を簡単にかつ大量に手にいれることが可能となってきている．このような状況の中で，必要な情報だけを得るための技術として文章要約は重要であり，計算機によって要約を自動的に行なうこと，すなわち自動要約が望まれる．

自動要約を実現するためには本来，人間が文章を要約するのと同様に，原文を理解する過程が当然必要となる．しかし，計算機が言語理解を行うことは現在のところ非常に困難である．実際，広範囲の対象に対して言語理解を扱っている自然言語処理システムはなく，ドメインを絞ったトイシステムにとどまっている．一方では言語理解に踏み込まずともある程度実現されている自然言語処理技術もある．例えば，かな漢字変換や機械翻訳は，人間が適切に介在することにより広く利用されている．

自動要約の技術でも言語理解を導入せずに，表層情報に基づいたさまざまな手法が提案されている．これらの手法による要約は用いる情報の範囲により大きく２つに分けることができる．本論文では文章全体にわたる広範な情報を主に用いて行なう要約を{\gt 大域的要約}，注目個所の近傍の情報を用いて行なう要約を{\gt 局所的要約}と呼ぶ．

我々は字幕作成への適用も視野に入れ，現在，局所的要約に重点を置き研究している．局所的要約を実現するには，後述する要約知識が必須であり，これをどのようにして獲得するかがシステムを構築する際のポイントとなる．本論文ではこのような要約知識（置換規則と置換条件）を，コーパス（原文−要約文コーパス）から自動的に獲得する手法について述べる．本手法では，はじめに原文中の単語と要約文中の単語のすべての組み合わせに対して単語間の距離を計算し，ＤＰマッチングによって最適な単語対応を求める．その結果から置換規則は単語対応上で不一致となる単語列として得られる．一方，置換条件は置換規則の前後ｎグラムの単語列として得られる．ＮＨＫニュースを使って局所的要約知識の自動獲得実験を行い，その有効性を検証する実験を行ったのでその結果についても述べる．

以下，~\ref{sec:sec2}~章では自動要約に関して{ \gt 大域的要約}と{ \gt 局所的要約}について説明をする．~\ref{sec:sec3}~章では要約知識を自動獲得する際にベースとなる，原文−要約文コーパスの特徴について述べる．~\ref{sec:sec4}~章では要約知識を構成する置換規則と置換条件について説明し，これらを自動獲得する手法について述べる．~\ref{sec:sec5}~章では原文−要約文コーパスから実際に要約知識を自動獲得した実験結果について述べ，獲得された要約知識の評価結果についても述べる．~\ref{sec:sec6}~章ではまとめと今後の課題について述べる.\newpage

\section{大域的要約と局所的要約}
\label{sec:sec2}
本論文では，文章全体にわたる広範な情報（大域的情報）を用い
て行なう要約を{\gt 大域的要約}と呼ぶ．大域的情報とは文章中に含
まれる単語の出現頻度や，文章中での文の位置などである．例えば，
これらの情報を使って重要文を抽出し連結することで要約を行う手
法が提案されている~\cite{Luhn58,Edmundson69,Watanabe95,Kupiec95,Zechner96}~．
このような要約手法は，実現
の容易さから，市販の自然言語処理システム（ワードプロセッサ，
機械翻訳システム）の一機能として組み込まれていることもある．
しかし，要約文章は重要文を単に連結したものであるため，文章全
体の概要を知るという用途には利用できるものの，文章としての自
然さに欠ける．

一方，注目個所の近傍の情報（局所的情報）を用いて行なう要約
を{\gt 局所的要約}と呼ぶ．局所的情報とは注目個所そのものや，そ
の前後の単語列などである．例えば，ある単語列に注目してそれを
より短い単語列に言い換えることにより要約を行なう手法が提案さ
れている~\cite{Yamamoto95,Wakao97,Yamazaki98}~
．これらの手法には，どの単語列をどのように
言い換えるか（置換規則），また，どのような場合に言い換えるか
（置換条件）という要約知識が必須となる．要約対象を拡大したり
要約精度をあげるためには，このような要約知識を増やしたり精練
したりしなければならない．しかし，従来はこうした知識を人手で
作成していたため大規模なシステムはない．

文章を自動要約するには大域的要約と局所的要約の両方を用いる
ことが望まれるが，本論文では局所的要約だけに焦点をあてる．こ
れは，我々が自動要約の当面の応用としてニュースの字幕原稿の自
動作成を考えているからである．ニュースの字幕原稿とはアナウン
サーが話す元原稿を要約して画面に表示したものである．字幕は，
すべての情報を与えるという観点からはむしろ元原稿を要約しない
で作成するほうが望ましいが，字幕の表示速度や読み易さという観
点からはやはり元原稿を要約して作成する必要がある．この元原稿
の要約に従来の大域的要約手法を適用すると文全体を省略してしま
うので，大きな情報の欠落を伴うという問題が生じる．また，元原
稿の文は局所的情報で要約できる場合が多いので，ニュースの字幕
原稿作成には局所的要約のほうが適している．

以下，単に「要約」と書いた場合には局所的要約を指すものとす
る．

\section{原文−要約文コーパス}
\label{sec:sec3}
本論文で提案する要約知識自動獲得手法では，原文と要約文から
なる電子化されたコーパスが大量に必要となる．この章では我々が
使用している原文−要約文コーパスについて説明する．

我々は原文にＮＨＫニュース原稿，要約文にＮＨＫ文字放送の原
稿
\footnote{
我々が局所的要約の当面の適用として考えているのはニュース字幕作成であ
るので，要約文としてニュース字幕の原稿を使えることがもちろん望ましい．
しかし，現行では字幕が付与されているニュースはほとんどない．そこで本手
法では大量にある文字放送の原稿を要約文に使った．
}
を使っている．ＮＨＫニュース原稿とは，主にＮＨＫ総合ＴＶ
（ＧＴＶ）のニュース（例えば，「７時のニュース」）でアナウン
サーが読む原稿の元になるものであり，電子的に保存されている．
アナウンサーが読んで伝えることを目的として書かれているため，
新聞記事と比較すると冗長な表現も少なくない．一方ＮＨＫ文字放
送の原稿とは，ＧＴＶの電波に多重され放送されている文字放送
（テレビジョン文字多重放送）の番組の原稿である．文字放送は専
用のデコーダーで受信することができ，わずかの例外を除いては市
販の受信ソフトにより文字コードとして計算機に取り込むことが可
能である．ＧＴＶの文字放送は数百の番組があるが，本論文で用い
ている番組はテレモケイザイニュース，テレモコクサイニュース，
テレモサンギョウ，ＮＨＫニュース，ＮＨＫフルサトネットワーク
の５つの番組である．文字放送の原稿の記事数は番組や日によって
異なるが，１番組当たり４〜８記事であり，一日に数回ニュース内
容が更新される．また，１記事は１画面の中に収まるように作成さ
れている．ＮＨＫニュース原稿とＮＨＫ文字放送の原稿の一例を図
１に示す．

\begin{figure}
  \vspace*{-1cm}
\begin{center}
\epsfile{file=77.eps,scale=1.0}
\vspace*{-4mm}
\vspace{-3mm}
  \caption{原文と要約文の例}
\end{center}
\end{figure}

はじめに，ＮＨＫニュース原稿とＮＨＫ文字放送の原稿の１記事
全体を定量的に比較する．比較は9,243記事に対して，文の数，文字
数の平均を計算して行った．結果を表１に示す．文の数では，ニュー
ス原稿は１記事当たり５〜６文であるのに対して，文字放送の原稿
はほとんどの場合が２文である．文字数でみると，文字放送の原稿
の１文は短く，ニュース原稿が約２０％に縮約されている．

\begin{table}
 \begin{center}
  \caption{ＮＨＫニュース原稿と文字放送の原稿の特徴}
  \begin{tabular}{c|c|c|c} \hline \hline
   平均 & ニュース原稿 & 文字放送の原稿 & 要約率 \\ \hline
   平均文数 & 5.4 & 2.2 & 40.7\% \\
   平均文字数 & 495.5 & 107.2 & 21.6\% \\ \hline
  \end{tabular}
 \end{center}
\end{table}

図１の例で，ニュース原稿と文字放送の原稿を各文ごとに具体的
に比較する．文字放送の原稿の第１文とニュース原稿の第１文は共
通に存在する単語列が多い．また，異なっている部分は局所的要約
が行なわれている．すなわち，次のようにニュース原稿の単語列が
文字放送の原稿中では短い単語列に置換されている．（ここで，矢
印の左辺が原文中の単語列，右辺が要約文中の単語列である．また，
記号φは空を表す．）

　「ごみの焼却場などから出る」（連体節）→「φ」

　「有害物質のダイオキシン」→「有害物質ダイオキシン」

　「摂取基準を引き下げること」→「摂取基準引き下げ」

　「受けて」→「受け」

　「国内の基準」→「国内基準」

　「なりました」→「なった」

\vspace{-3mm}
文字放送の原稿の第２文はニュース原稿の第２，３文から要約さ
れている．文字放送の原稿の第２文は「１０ピコグラム」というキー
ワードを中心にして要約が生成されている．すなわち，前半はニュー
ス原稿第２文の「１０ピコグラム」辺りの節までを要約し，後半は
第３文の「１０ピコグラム」からの節を要約し，これらを繋げるこ
とにより要約が行なわれている．つまり，第２文の要約は「１０ピ
コグラム」という共通単語列を考慮して要約しており，節を対象に
した大域的要約である．

ニュース原稿の第４，５，６文は文字放送の原稿中では省略され
ている．すなわち，これらは文を対象にした大域的要約が行なわれ
たものである．

\section{コーパスからの要約知識の自動獲得}
\label{sec:sec4}
\subsection{要約知識}
\label{sec:sec4-1}
我々の要約知識は置換規則と置換条件からなる．

置換規則とは原文の単語列を短い単語列に置き変えよというものである．例えば，次の規則は連体格助詞「の」という単語を省略するという置換規則である．\vspace{8mm}\\
\hspace*{5mm}【置換規則の例】\\
\hspace*{10mm}「の／体助」→「φ」\\
\hspace*{10mm}（ここで「の」は表層文字列，「体助」は品詞が“連体格助詞”　であることを表す．）\vspace{8mm}\\
一方，置換条件とは置換規則が適用できるか否かを判定する条件である．置換規則の適用はその前後の単語列で決まる．例えば，次は上述の置換規則の例に対する置換条件の一部である．\vspace{8mm}\\
\hspace*{5mm}【置換条件の例】\\
\hspace*{10mm}「日本 の 経済」のときは置換規則適用可\\
\hspace*{10mm}「日本 の 銀行」のときは置換規則適用不可 \vspace{8mm}\\
この置換条件の例では，「日本の経済」中の「の／体助」は省略可能であるが，「日本の銀行」中の「の／体助」は省略できないということを表している．この例のように，置換規則は必ず適用できるわけではなく，適用してはいけない場合もある．実際には後述するように，適用できる程度を[0.0, 1.0]の実数値で表現している．

以下では，置換規則と置換条件をコーパスから自動的に獲得する手法について具体的に説明する．
\subsection{置換規則}
\label{sec:sec4-2}
置換規則は，原文と要約文の差分として自動的に獲得する．

本手法でははじめに原文−要約文コーパスのそれぞれの文を形態
素解析し，単語単位に分割する．形態素解析
\footnote{
形態素解析の誤りが置換規則の自動獲得に影響を及ばすことが考えられるが，
後述するように実際には出現頻度の高いものを使っているので影響は少ない．
}
は我々独自のシステムを使っている．

次に，形態素解析で得られた原文中の単語と要約文中の単語の最
適な単語対応を求める．これは，原文中の単語 $w_i$（表層文字列を$c^o_i$ ，
品詞を $p^o_i$ と表す）と要約文中の単語 $x_j$（表層文字列 $c^s_j$，品詞 $p^s_j$ ）
のすべての組み合わせに対して単語間の距離を計算し，その距離に
基づいて単語間のＤＰマッチングを取ることによって実現している．
この中で単語間の距離をどのように定義するかが重要となる．

単語間の距離は，対応する単語の有無や単語の類似性により式(1)
のように３つの場合に分けて定義した．\vspace{8mm}\\
【単語間の距離】
$$ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
distword(w_i, x_j)
  = distword(c^O_i/p^O_i, c^S_j/p^S_j)
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{lr}
           \lambda _1{distchar(c^O_i, c^S_j)+\lambda _2distpos(p^O_i, p^S_j)}
             & \mbox{ \ \ \ \ \ \ \ \ \ \ \ (1a)} \\
             \mbox{ \ \ \ $if \ \ w_i \neq φ \wedge x_j \neq φ \wedge ContWord(p^O_i)=ContWord(p^S_j)$}
               & \mbox{} \\
           2.0
             & \mbox{ \ \ \ \ \ \ \ \ \ \ \ (1b)} \\
             \mbox{ \ \ \ $if \ \ w_i \neq φ \wedge x_j \neq φ \wedge ContWord(p^O_i) \neq ContWord(p^S_j)$ }
               & \mbox{} \\
           1.5
             & \mbox{ \ \ \ \ \ \ \ \ \ \ \ (1c)} \\
             \mbox{ \ \ \ $if \ \ w_i = φ \vee x_j = φ$}
               & \mbox{} \\
          \end{array}
  \right. \]
\vspace{8mm}\\
ここで，φは空を表す記号であり，$w_i = φ$ は対応する単語が省略
されたことを表す．また，内容語判定関数 $ContWord$ は単語 $w_i$ が内
容語であるかないかをその品詞（ $p_i$ ）から判定する関数であり，式
(2)で定義する．
\vspace{8mm}\\
【内容語判定関数】
$$ \ \ \ \ \ \ \ \ \ \ \ \ ContWord(p) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{llr}
        1 & \mbox{ $if \ \ p=$ 内容語である品詞 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
          & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2a)} \\
        0 & \mbox{ $otherwise$ }
          & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (2b)}
          \end{array}
  \right. \]
\vspace{8mm}\\
　式(1a)は２つの単語が共に内容語であるか，共にそうではない場
合であり，式(3)，式(4)を用いて計算される．単語間の距離は，シ
ソーラス上の距離と品詞間の距離を重み付け（ $\lambda _1 + \lambda _2 =1$ ）して計算される．シソーラス上の距離は表層文字列が完全一致する場合に
は 0.0（式(3a)）をとる．一致しない場合には，それぞれの単語が内
容語であれば，意味的な距離をシソーラスを使って計算する．実際
には角川類語新辞典~\cite{Oono97}~の分類番号の一致する桁に基づき，
式(3b)〜(3d)で計算している．
\vspace{8mm}\\
【シソーラス上の距離】
$$ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ distchar(c^O_i, c^S_j) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{llr}
        0.0 & \mbox{ $if \ \ c^O_i=c^S_j$ \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3a)} \\
        0.1 & \mbox{ $if$ 上位３桁のみが一致 \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3b)} \\
        0.4 & \mbox{ $if$ 上位２桁のみが一致 \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3c)} \\
        0.8 & \mbox{ $if$ 上位１桁のみが一致 \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3d)} \\
        1.0 & \mbox{ $otherwise$ \ \ \ \ \ \ \ \ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (3e)}
          \end{array}
  \right. \]
\vspace{8mm}\\
式(1a)の第２項である品詞間の距離は，式(4)のように３つの場合に
分けて定義している．
\vspace{8mm}\\
【品詞間の距離】
$$ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ distpos(p^O_i, p^S_j) 
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4) $$
\[ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \left\{ \begin{array}{llr}
        0.0 & \mbox{ $if \ \ p^O_i=p^S_j$ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4a)} \\
        0.2 & \mbox{ $if \ \ p^O_i$ と $p^S_j$ は人手で指定したもの }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4b)} \\
        1.0 & \mbox{ $otherwise$ }
            & \mbox{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (4c)}
          \end{array}
  \right. \]
\vspace{8mm}\\
ここで式(4b)は，「名詞とサ変名詞」のように，完全一致しないが
類似している品詞同士であり，人手で指定した．しかし，現在のと
ころその数はあまり多くない
\footnote{
人手で指定している品詞の組み合わせは現在のところ約40個である．品詞間
の距離は，理想的にはすべての品詞（我々の形態素解析システムでは約230個
ある）の組み合わせに対して，細かく人手で定義することが望ましい．
}
．式(1a)は，定義式からわかるように[0.0, 1.0]の値を取る．

さて，式(1b)は内容語である単語と内容語でない単語が対応する
場合であり，このような対応は不適切である場合が多いので他の場
合よりも大きい値にした．式(1c)は対応する単語が省略されている
場合であり，式(1b)と式(1a)の最大値（ $= 1.0$ ）の間の値とした．

以上のように定義した単語間の距離に基づいて単語間のＤＰマッ
チングをとると，図２のように，前の単語列が一致し（単語数 $q1$ 個），
一部が不一致となり（ $p$ 個），その後にまた単語\mbox{列が一致する}（ $q2$ 
個）という部分が求められる．この不一致となる単語列が置換規則
となる．さらに，一致する部分が長く，不一致の部分が短いほうが
置換規則としての信頼性が高いと考えられる．そこで置換規則自動
獲得の信頼度として式(5)を定義すると，この値の大きいほうが知識
として有効である．実際にはあるしきい値（ $f_0$ ）を決め，式(5)の値
がしきい値より大きいものを収集した．
\vspace{8mm}\\

\vspace{-3mm}
【置換規則自動獲得の信頼度】
$$ f(w_i w_{i+1} \ldots w_{i+p-1}, x_i x_{i+1} \ldots x_{i+p-1}) =\frac{q1+q2}{p} \eqno{(5)} $$
\begin{figure}
\begin{center}
\epsfile{file=81.eps,scale=1.0}
\vspace{-5mm}
  \caption{単語対応の差分による置換規則と置換条件の自動獲得}
\end{center}
\end{figure}

\vspace{-7mm}
さらに置換規則としての信頼度を高めるために，収集され
た置換規則の頻度統計をとり，頻度が高い置換規則を最終的に有効
な置換規則とした．

\vspace{-2mm}
\subsection{置換条件}
\label{sec:sec4-3}
\vspace{-1mm}
置換条件には置換規則の前後の単語ｎグラムが使われている．置
換条件は置換規則と同時に収集されるが，原文の単語列が置換され
る場合 $w_i w_{i+1} \ldots w_{i+p-1} → x_i x_{i+1} \ldots x_{i+p-1}$（正例と呼ぶ）とともに，原文の
単語列がそのまま保存される場合 $w_i w_{i+1} \ldots w_{i+p-1} → w_i w_{i+1} \ldots w_{i+p-1}$（負例
と呼ぶ）も収集している．負例を自動獲得する場合にも式(5)による
信頼度を使っている．

\begin{figure}
\begin{flushleft}
 \ \ \ \ \ \ \ \ \ \ \ \ {\gt 置換規則：} $w_i w_{i+1} \ldots w_{i+p-1} → x_i x_{i+1} \ldots x_{i+p-1}$ \\
 \ \ \ \ \ \ \ \ \ \ \ \ {\gt 置換条件：}
\nolinebreak
\end{flushleft}
\begin{center}
 \ \ \ \ \ \ \ \ \ \ \ {\gt 置換前条件 } \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ {\gt 置換後条件 } \ \ \ \ \ \ \\
 \ \ \ 正例 \ \ \ $w^1_{i-r1} \ldots w^1_{i-2} w^1_{i-1} \ \ \ \ w^1_{i+p} w^1_{i+p+1} \ldots w^1_{i+p+r2-1}$ \\
 \ \ \ 負例 \ \ \ $w^2_{i-r1} \ldots w^2_{i-2} w^2_{i-1} \ \ \ \ w^2_{i+p} w^2_{i+p+1} \ldots w^2_{i+p+r2-1}$ \\
 \ \ \ \ \ \ \ \ \ \ : \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ : \\
 \ \ \ 正例 \ \ \ $w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1} \ \ \ \ w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1}$ \\
 \ \ \ \ \ \ \ \ \ \ : \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ : \\
\end{center}
\caption{置換規則と置換条件}
\end{figure}

置換規則の前のｎグラムを置換前条件，後のｎグラムを置換後条
件と呼び，それぞれのｎの値を $r1$ ， $r2$ とおく．すると，要約知識は
図３のように表すことができる．この図で $k$ は $k$ 番目にある置換条
件を表すのに用いている．このような置換条件を参照して，ある置
換規則 $w_i w_{i+1} \ldots w_{i+p-1} → x_i x_{i+1} \ldots x_{i+p-1}$ が適用できるかどうかの程度は，
式(6)で定義された置換条件上の距離として計算される．置換条件上
の距離の計算ではまず，それぞれの $k$ に対して，原文の単語列の前 
 $r1$ グラム（ $w_{i-r1} \ldots w_{i-2} w_{i-1}$ ）と $k$ 番目の置換前条件（ $w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1}$ ）
との距離（式(6b)），原文の単語列の後 $r2$ グラム（ $w_{i+p} w_{i+p+1} \ldots 
w_{i+p+r2-1}$ ）と $k$ 番目の置換後条件（ $w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1}$ ）との距離（式
(6c)）を求める．次にそれらを重み付けた和（式(6a)）を計算し，さ
らにすべての $k$ に対する最小値を求め，この最小値を置換条件上の
距離とする．定義から明らかなように，式(6)は[0.0, 1.0] の値をとる．
\vspace{8mm}\\
【置換条件上の距離】
$$  \min_{k}( g(w_i w_{i+1} \ldots w_{i+p-1}, x_i x_{i+1} \ldots x_{i+p-1}, k) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \eqno{(6)} $$

 \ \ \ \ \ \ \ \ \ \ \ 
$g(w_i w_{i+1} \ldots w_{i+p-1}, x_i x_{i+1} \ldots x_{i+p-1}, k)$
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (6a)

 \ \ \ \ \ \ \ \
$= \mu _1g^-(w_{i-r1} \ldots w_{i-2} w_{i-1} , w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1} )$

 \ \ \ \ \ \ \ \
$+ \mu _2g^+(w_{i+p} w_{i+p+1} \ldots w_{i+p+r2-1} , w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1} )$

 \ \ \ \ \ \ \ \
$(\mu _1+\mu _2=1)$

\[ g^-(w_{i-r1} \ldots w_{i-2} w_{i-1} , w^k_{i-r1} \ldots w^k_{i-2} w^k_{i-1})
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\[ =\frac{ \sum_{j=1}^{r1} \bigl\{ weight_1(j) \times distword(w_{i-j} , w^k_{i-j}) \bigr\}}
{ \sum_{j=1}^{r1} weight_1(j) }
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\begin{flushright}(6b)\end{flushright}

\[ g^+(w_{i+p} w_{i+p+1} \ldots w_{i+p+r2-1} , w^k_{i+p} w^k_{i+p+1} \ldots w^k_{i+p+r2-1} ) 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\[ =\frac{ \sum_{j=1}^{r2} \bigl\{ weight_2(j) \times distword(w_{i+p+j-1} , w^k_{i+p+j-1}) \bigr\}}
{ \sum_{j=1}^{r2} weight_2(j) } 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \]
\begin{flushright}(6c)\end{flushright}

 \ \ \ \ \ \ \ \ \ \ \ \
$weight_1(j) = { \alpha _1 }^{j-1}$
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
(6d)

 \ \ \ \ \ \ \ \ \ \ \ \
$weight_2(j) = { \alpha _2 }^{j-1}$
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
(6e)

（$\alpha _1$, $\alpha _2$ は定数，$0.0 \le \alpha _1 \le 1.0$, \ \ $0.0 \le \alpha _2 \le 1.0$）
\vspace{10mm}\\
ただし，$g^-$ ， $g^+$ はそれぞれ，原文と収集された置換前条件，置換後
条件間の距離を計算する関数であり，置換規則となる単語列から離
れるほど，その影響が少なくなるように $weight(j)$ で重み付けしてい
る．さらに，置換前条件と置換後条件は $\mu $ で重み付けしている．

式(6)で最小値を与える置換条件が正例に関するものであるならば，
置換規則が適用され局所的に要約される．しかし，置換規則の適用
を式(6)で単純に判定してしまうと，負例，すなわち置換規則を適用
しない方を解とする場合が多くなってしまう．これは，置換条件の
正例が置換しなければならないというものではなく，置換してもよ
いという程度の意味しか持たないからである．そこで後述する要約
知識の評価実験では，あるしきい値（ $g_0$ ）を決め，式(6)で求められ
た最小値を与える解が負例であっても正例での最小値がしきい値以
下であるならば，正例を解とした．

\section{実験}
\label{sec:sec5}
\subsection{要約知識獲得実験}
\label{sec:sec5-1}
ＮＨＫニュース原稿とＮＨＫ文字放送の原稿から構成される，原
文−要約文コーパスの9,243記事を使って要約知識を自動獲得する実
験を行った．単語間のＤＰマッチングを行う際には，あらかじめ文
対応をつけておくということはせずに，原文，要約文それぞれに含
まれる単語のすべての組み合わせを使った．

要約知識のうち，まず置換規則の自動獲得実験を行った．この際，
次のパラメータ値をあらかじめ決めておかなければならない．

\begin{flushleft}
　　　{\gt パラメータ１：} シソーラス上の距離と品詞間距離の重みづけ $\lambda _1$ 
式(1a)） \\
　　　{\gt パラメータ２：} 置換規則自動獲得の信頼度 $f$（式(5)）の
しきい値 $f_0$ 
\end{flushleft}

今回の実験では，パラメータ１に関しては，品詞間距離の計算に
おいて人手で指定している品詞対があまり多くないので，表層表現
を重視するように次の値にした．

\begin{flushleft}
　　　{\gt パラメータ１：} $\lambda _1 =0.7$（ $\lambda _2 = 0.3$ ）
\end{flushleft}

またパラメータ２に関しては，置換規則となる単語列は１単語以上
は必要であり，その前後は少なくとも一方のうち１単語は一致して
ほしいと考え，$p = 1$， $q1 = 1$， $q2 = 0$（または， $q1 = 0$ ， $q2 = 1$）
から計算される次の値にした．

\begin{flushleft}
　　　{\gt パラメータ２：} $f_0 = 1.0$
\end{flushleft}

自動獲得された置換規則に対してさらに頻度統計をとった．上位
40位を表２に示す．表２の中で，「や／並助 → ・／つなぎ」や
「の／体助 → ・／つなぎ」等は字数が同じであり，字数を減らす
という要約本来の意味では置換規則とはいえない．しかし，要約文
としての読みやすさという点では有効であると考えられるので，参
考のために含めた．もちろん後処理でこれらを置換規則から取り除
くことは容易である．

\begin{table}
 \begin{center}
  \caption{自動獲得された置換規則}
  \begin{tabular}{|r|l|l|} \hline \hline
   獲得個数 & 原文中の単語列 & 要約文中の単語列 \\ \hline
   8967 & 、／読点 & 　φ\\
   5331 & の／体助 & 　φ\\
   3491 & まし／助丁寧 & 　φ\\
   1643 & を／格助を & 　φ\\
   579 & で／助断定 & 　φ\\
   529 & に／格助に & 　φ\\
   525 & が／格助が & 　φ\\
   484 & 総理／名 大臣／名 & 首相／名\\
   450 & 」／閉かぎ & 　φ\\
   426 & な／助断定 & 　φ\\ \hline
   387 & て／接助 & 　φ\\
   360 & する／さ連体 & の／体助\\
   340 & し／さ連用 & 　φ\\
   328 & や／並助 & ・／つなぎ\\
   324 & など／副助 & 　φ\\
   312 & い／形五わ う／自尾 & の／体助\\
   306 & てい／助完了 ます／助丁寧 & ている／助完了\\
   305 & は／係助は & 　φ\\
   266 & て／接助 、／読点 & 　φ\\
   247 & です／助断定 & 　φ\\ \hline
   246 & 「／開かぎ & 　φ\\
   238 & し／さ連用 まし／助丁寧 た／助過去 & 　φ\\
   228 & アメリカ／地 & 米／名\\
   225 & を／格助を & の／体助\\
   221 & てい／助完了 & 　φ\\
   201 & 委員／名 会／尾 & 委／尾\\
   195 & なり／形五ら まし／助丁寧 & なっ／形五ら\\
   186 & ・／つなぎ & ＝／つなぎ\\
   185 & だ／助断定 & 　φ\\
   181 & り／自尾 まし／助丁寧 & っ／自尾\\ \hline
   180 & もの／形名 です／助断定 & 　φ\\
   169 & 余り／別尾 & 余／別尾\\
   167 & 大蔵／人姓 大臣／名 & 蔵相／名\\
   166 & の／体助 & ・／つなぎ\\
   166 & と／格助と & ・／つなぎ\\
   161 & について／格助他 & 　φ\\
   159 & が／格助が & の／体助\\
   156 & する／さ連体 & 　φ\\
   150 & 行な／他五わ & 行／他五わ\\
   144 & 外務／名 大臣／名 & 外相／名\\ \hline
  \end{tabular}
 \end{center}
\end{table}

表２をみると，妥当な置換規則が得られているのがわかる．実際，
上位100位までを人手で確認したところ，すべて妥当な置換規則が
得られていた．

具体的にみると，上位には「の／体助 → φ」や「を／格助 → φ」
のように，分野に関係なく行なわれる要約である助詞や助動詞の省
略が多いのがわかる．また，我々の原文−要約文コーパスを使った
ことによる特徴であるが，置換規則「まし／助丁寧 → φ」（実際に
は「しました → した」）や「てい／助完了 ます／助丁寧 → てい
る／助完了」のように，アナウンサーが話すことを目的としたニュー
ス原稿を，書き言葉である文字放送の原稿に要約するための置換規
則が得られている．言い換えでは内容語の場合が多く，表２では
「総理／名 大臣／名 → 首相／名」（総理大臣 → 首相），「委員
／名 会／尾 → 委／尾」（委員会 → 委）という置換規則が得られ
ている．内容語が内容語に置換されている場合を抽出すると表３の
ようになった．ただし，表３では品詞は省略している．表には現れ
ていないが，節の言い換えの例として，「日本を訪問している → 
訪日中の」という置換規則も得られている．

\begin{table}
 \begin{center}
  \caption{自動獲得された置換規則（内容語）}
  \begin{tabular}{|r|l|l|} \hline \hline
   獲得個数 & 原文中の単語列 & 要約文中の単語列 \\ \hline
   484 & 総理大臣 & 首相 \\
   228 & アメリカ & 米 \\
   201 & 委員会 & 委 \\
   167 & 大蔵大臣 & 蔵相 \\
   144 & 外務大臣 & 外相 \\
   89 & 地方裁判所 & 地裁 \\
   87 & 大臣 & 相 \\
   70 & 経済企画 & 経企 \\
   68 & 衆議院 & 衆院 \\
   65 & さきがけ & さ \\
   54 & アメリカのクリントン & クリントン米 \\
   45 & ヶ月 & か月 \\
   34 & 参議院 & 参院 \\
   31 & 警察本部 & 警 \\
   29 & 自由民主 & 自民 \\ \hline
  \end{tabular}
 \end{center}
\end{table}

次に得られた置換規則に対して，置換条件を正例，負例ともに自
動獲得した．この際，前後のｎグラムの値はコーパスを見て置換条
件として有効であると思われる長さより少し長めに，$r_1 = r_2 = 6$
とした．実際にはこれほどの長さは必要ないものと思われるが，重
みの値（式(6)の $\alpha _1$ ， $\alpha _2$ ）を小さく取ることにより長さが短い場合
も近似的に実現することが可能である．置換規則「の／体助→φ」
に対する置換条件の例の一部を表４に示す．

\begin{table}
\begin{center}
\epsfile{file=86.eps,scale=1.0}
\vspace*{-3mm}
  
\end{center}
\end{table}

\subsection{要約知識評価実験}
\label{sec:5-2}
~\ref{sec:sec5-1}~で自動獲得された置換規則とその置換条件を使って要約知
識の評価実験を行った．実験は正例と負例をあわせた全データ（表
５参照）から50個をパラメータ決定実験用に，他の100個を評価実
験用にランダムにそれぞれ抽出し，残り（例えば，置換規則「の／
体助 → φ」では $(5,331+13,498) - (50+100) = 18,679個$ を置換条件
用のデータとした．

\setcounter{table}{4}
\begin{table}
\begin{center}
\vspace{-3mm}
  \caption{実験に使った置換規則における置換条件の数}
\epsfile{file=87.eps,scale=1.0}
  
\end{center}
\end{table}
評価は，置換条件上の距離（式(6)）から正例か負例か（すなわち，
要約するか否か）を判断し，実際の正例・負例と一致したときを正
解とした．しかし，~\ref{sec:sec4-3}~の最後で述べたように，自動的に得られ
ている負例には，本来は正例にもなりうる場合と，正例にはなりえ
ない場合（真の負例と呼ぶ）がある．そこで評価実験に際して，パ
ラメータ決定実験用データ，評価実験用データともに負例に対し正
例になりうるか否かを人手で判断し，正例になりうるものは元の正
例に加えた．

要約知識はなるべく適用されたほうがいいものの，誤って適用さ
れてはいけないので，評価は式(7)の値で行った．

$$ \ \ \ \ \ \ \ \ \ \ f‐measure = \frac{2.0 \times P \times R }{ P + R } \ \ (=F) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (7)$$

\begin{eqnarray*}
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
precision = \frac{正例，負例が正しく判定された個数}{評価実験用データ数（=100）} \ \ (=P)
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (7a)
\end{eqnarray*}
\begin{eqnarray*}
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
recall = \frac{正しく正例と判定された個数}{評価実験用データ数のうち正例の数} \ \ (=R)
 \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (7b)
\end{eqnarray*}
\\
式(7a)は，正例，負例の判断をして実験用データと一致した割合を
表している．式(7b)は実験用データの正例の中で正確に正例として
判断された割合であり，すなわち，要約が行なわれた場合にどのく
らいが正解かを表している．これら２つの値から $f‐measure$ を計算
し評価した．

今回評価に用いた置換規則は，表２の中からある程度のデータ量
をもつ助詞，助動詞の要約に関するものである，「の／体助 → φ」，
「を／格助を → φ」，「で／助断定 → φ」，「に／格助に → φ」，
「が／格助が → φ」，「な／助断定 → φ」，「する／さ連体 → 
の／体助」，「て／接助 → φ」，「し／さ連用 → φ」の９種類で
ある ．

パラメータ決定実験では次の値を評価実験に先だって決めなけれ
ばならない．

\begin{flushleft}
　　　{\gt パラメータ３：} 置換前条件と置換後条件との重み $\mu _1$（式(6a)）

　　　{\gt パラメータ４：} 置換前条件内の単語列に対する重み $\alpha _1$（式(6d)）

　　　{\gt パラメータ５：} 置換後条件内の単語列に対する重み $\alpha _2$（式(6e)）

　　　{\gt パラメータ６：} 置換条件上の距離のしきい値  $g_0$ 
\\
この中で置換条件上の距離のしきい値 $g_0$ は置換規則の種類によらず
経験的に次の値にした．

　　　{\gt パラメータ６：} $g_0 = 0.4$
\end{flushleft}

その他のパラメータに関しては置換規則ごとにさまざまなパラメー
タを使って実験し，最も $f‐measure$ の大きい場合を選択した．それ
ぞれの置換規則におけるパラメータを表６に示す．表６中の $\mu _1$ をみ
ると，置換規則によってパラメータの値がかなり異なることがわか
る．置換規則「を／体助を → φ」では置換前知識に重み付けられ
ているのに対し，置換規則「の／体助 → φ」では置換後知識のほ
うが重みが大きい．

\begin{table}
  
  
  
\begin{center}
\epsfile{file=89.eps,scale=1.0}
\end{center}
\end{table}

次にこれらのパラメータ値を使って要約知識の評価実験をした．
実験結果を表７に示す．ここで比較のために，すべてを正例と判断
した場合の $f‐measure$ の値（ $F'$ ）も記した．\mbox{この場}合，$R=100$ とな
るので $F'$ は，

$$ f‐measure のbaseline 値 = \frac{2.0 \times (100-真の負例の割合) \times 100 }{ (100-真の負例の割合) + 100 } \ \ (=F') \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (8)$$

\begin{flushleft}
と計算される．
\end{flushleft}

表７を見ると，置換規則「を／体助を → φ」の場合は $f‐measure$ 
の値が $baseline$ 値とほとんど変わらない．しかし，置換規則によっ
て精度のばらつきがあるものの，概ね良好な結果が得られている．

\subsection{置換規則「の／体助→φ」の誤り例}
\label{sec:sec5-3}
今回の実験で $f‐measure$ が一番低かった置換規則「の／体助→φ」
の誤りを分析した．\mbox{多く}の誤りは距離計算がうまくなされていない
ことによるものであった．これを改善するには，単純には学習デー
タを増やしたり，またシソーラスをニュース用にきめ細かく作成す
ることにより，さらに精度よく置換条件上の距離を計算する必要が
ある．

しかし，さらに細かい言語情報を必要とする誤りの例もあった．
以下に例をあげる．
\newpage
\begin{flushleft}
【誤り例１】

　　　原文　「『白鳥の王女のアリア』」

　　　要約文「『白鳥の王女アリア』」
\end{flushleft}

\begin{flushleft}
例１では「『白鳥の王女のアリア』」は固有名詞なので要約して
はならないのであるが，「の」を省略してしまった．正確に要約す
るためには「『白鳥の王女のアリア』」が固有名詞であるという情
報が必要である．
\end{flushleft}

\begin{flushleft}
【誤り例２】

　　　原文　「アメリカ軍嘉手納基地周辺の住民」

　　　要約文「アメリカ軍嘉手納基地周辺住民」 \\
\end{flushleft}

\begin{flushleft}
例２では，正例に「周辺の住民 → 周辺住民」という例があった
ために「の」が省略されてしまったが，要約文では非常に長い名詞
連続となってしまうので読みにくくなってしまう．この場合にはあ
る長さ以上の名詞連続を作成するときには省略をしてはいけないと
いう情報が必要となろう．
\end{flushleft}

\begin{flushleft}
【誤り例３】

　　　原文　「アジアの株式市場と為替市場」

　　　要約文「アジア株式市場と為替市場」 \\
\end{flushleft}

\begin{flushleft}
例３では正例に「アジアの株式市場 → アジア株式市場」という
例があったために「の」が省略されてしまった．原文では「アジア」
が「株式市場」とともに「為替市場」にも係っているので，省略す
ることはできない．このような場合には前後の単語列の構文情報も
考慮する必要があろう．
\end{flushleft}

今後はこのような言語情報も加えて要約の改善をしていく予定で
ある．

\section{おわりに}
\label{sec:sec6}
原文−要約文コーパスより局所的要約知識を自動獲得する手法に
ついて述べた．また，ＮＨＫニュース原稿とＮＨＫ文字放送の原稿
から構成されるコーパスを使って，局所的要約知識を自動獲得する
実験を行った．さらに要約知識の評価実験を行い，良好な結果を得
た．

今後の研究の方向は２つある．

１つは局所的要約に関するものである．今回は評価実験の第一歩
として特定の局所的要約知識にのみ着目したが，今後は自動獲得さ
れた要約知識すべてを使って文全体の局所的要約を試みたい．その
際には，適用する要約知識間で競合が起こることが予想される．そ
こで，与えられた要約率の中で要約知識の最適な組み合わせを求め
ることが必要となる．我々は信頼度の評価関数を最小化することに
より，要約知識の最適な組み合わせを求めるアルゴリズムを研究し
ている~\cite{Katoh98}~．このアルゴリズムによって得られた要約結果を
人間が読んでどれぐらい違和感がないかも評価する必要があろう．

もう１つの方向は，大域的要約に関するものである．これには要
約には現れなかった元のニュースの文（例えば，図１の第４，５，
６文）や節（図１の第２，３文中の節）を，文や節の削除手法の研
究の評価用データとして使っている．現在，従来の評価関数（例え
ば，tf法やtf*idf法）を使ってどのくらいの精度で削除できるかを実
験中である．

これらの詳細については稿を改めて報告したい．




\bibliographystyle{jnlpbbl}
\bibliography{v06n7_04}
\newpage
\begin{biography}
\biotitle{略歴}
\bioauthor{加藤 直人}{
1986年早稲田大学理工学部電気工学科卒業．
1988年同大学院修士課程修了．同年日本放送協会(NHK)に入局，
同放送技術研究所に勤務．1994年より３年間ATR音声翻訳通信研究所に出向．
1997年NHK放送技術研究所に復帰．機械翻訳，対話処理，
音声言語処理，自動要約の研究に従事．情報処理学会，電子情報通信学会各会員．}
\bioauthor{浦谷 則好}{
1975年東京大学大学院修士課程（電気工学）修了．同年日本放送協会(NHK)に入局．
1979年同放送技術研究所に勤務．1991年より３年間ATR自動翻訳電話研究所に出向．
1994年NHK放送技術研究所に復帰．1999年6月より音声翻訳通信研究所に再び出向．
現在，第４研究室主幹研究員．情報検索，自然言語処理の研究に従事．
工学博士．情報処理学会，電子情報通信学会，映像情報メディア学会各会員．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}


