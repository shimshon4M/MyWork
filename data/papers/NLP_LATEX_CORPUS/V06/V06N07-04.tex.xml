<?xml version="1.0" ?>
<root>
  <title>局所的要約知識の自動獲得手法</title>
  <author>加藤直人浦谷則好</author>
  <jabstract>日本語ニュースを局所的要約する際に必要となる要約知識を，コーパスから自動獲得する手法について述べる．局所的要約とは注目個所の近傍の情報（局所的情報）を用いて行なう要約をいう．局所的情報には注目個所そのものやその前後の単語列などがある．本手法では要約知識として置換規則と置換条件を用い，これらを原文−要約文コーパスから自動獲得する．はじめに原文中の単語と要約文中の単語のすべての組み合わせに対して単語間の距離を計算し，ＤＰマッチングによって最適な単語対応を求める．その結果より，置換規則は単語対応上で不一致となる単語列として獲得する．一方，置換条件は置換規則の前後ｎグラムの単語列として獲得する．原文と要約文にそれぞれＮＨＫニュース原稿とＮＨＫ文字放送の原稿を使って実際に要約知識を自動獲得し，得られた要約知識を評価する実験を行った．その結果，妥当な要約知識が獲得できることを確認した．</jabstract>
  <jkeywords>自動要約，コーパス，自動獲得，言語知識，日本語ニュース，ｎグラム</jkeywords>
  <section title="はじめに">インターネットの普及も手伝って，最近は電子化されたテキスト情報を簡単にかつ大量に手にいれることが可能となってきている．このような状況の中で，必要な情報だけを得るための技術として文章要約は重要であり，計算機によって要約を自動的に行なうこと，すなわち自動要約が望まれる．自動要約を実現するためには本来，人間が文章を要約するのと同様に，原文を理解する過程が当然必要となる．しかし，計算機が言語理解を行うことは現在のところ非常に困難である．実際，広範囲の対象に対して言語理解を扱っている自然言語処理システムはなく，ドメインを絞ったトイシステムにとどまっている．一方では言語理解に踏み込まずともある程度実現されている自然言語処理技術もある．例えば，かな漢字変換や機械翻訳は，人間が適切に介在することにより広く利用されている．自動要約の技術でも言語理解を導入せずに，表層情報に基づいたさまざまな手法が提案されている．これらの手法による要約は用いる情報の範囲により大きく２つに分けることができる．本論文では文章全体にわたる広範な情報を主に用いて行なう要約を大域的要約，注目個所の近傍の情報を用いて行なう要約を局所的要約と呼ぶ．我々は字幕作成への適用も視野に入れ，現在，局所的要約に重点を置き研究している．局所的要約を実現するには，後述する要約知識が必須であり，これをどのようにして獲得するかがシステムを構築する際のポイントとなる．本論文ではこのような要約知識（置換規則と置換条件）を，コーパス（原文−要約文コーパス）から自動的に獲得する手法について述べる．本手法では，はじめに原文中の単語と要約文中の単語のすべての組み合わせに対して単語間の距離を計算し，ＤＰマッチングによって最適な単語対応を求める．その結果から置換規則は単語対応上で不一致となる単語列として得られる．一方，置換条件は置換規則の前後ｎグラムの単語列として得られる．ＮＨＫニュースを使って局所的要約知識の自動獲得実験を行い，その有効性を検証する実験を行ったのでその結果についても述べる．以下，~~章では自動要約に関して大域的要約と局所的要約について説明をする．~~章では要約知識を自動獲得する際にベースとなる，原文−要約文コーパスの特徴について述べる．~~章では要約知識を構成する置換規則と置換条件について説明し，これらを自動獲得する手法について述べる．~~章では原文−要約文コーパスから実際に要約知識を自動獲得した実験結果について述べ，獲得された要約知識の評価結果についても述べる．~~章ではまとめと今後の課題について述べる.</section>
  <section title="大域的要約と局所的要約">本論文では，文章全体にわたる広範な情報（大域的情報）を用いて行なう要約を大域的要約と呼ぶ．大域的情報とは文章中に含まれる単語の出現頻度や，文章中での文の位置などである．例えば，これらの情報を使って重要文を抽出し連結することで要約を行う手法が提案されている~~．このような要約手法は，実現の容易さから，市販の自然言語処理システム（ワードプロセッサ，機械翻訳システム）の一機能として組み込まれていることもある．しかし，要約文章は重要文を単に連結したものであるため，文章全体の概要を知るという用途には利用できるものの，文章としての自然さに欠ける．一方，注目個所の近傍の情報（局所的情報）を用いて行なう要約を局所的要約と呼ぶ．局所的情報とは注目個所そのものや，その前後の単語列などである．例えば，ある単語列に注目してそれをより短い単語列に言い換えることにより要約を行なう手法が提案されている~~．これらの手法には，どの単語列をどのように言い換えるか（置換規則），また，どのような場合に言い換えるか（置換条件）という要約知識が必須となる．要約対象を拡大したり要約精度をあげるためには，このような要約知識を増やしたり精練したりしなければならない．しかし，従来はこうした知識を人手で作成していたため大規模なシステムはない．文章を自動要約するには大域的要約と局所的要約の両方を用いることが望まれるが，本論文では局所的要約だけに焦点をあてる．これは，我々が自動要約の当面の応用としてニュースの字幕原稿の自動作成を考えているからである．ニュースの字幕原稿とはアナウンサーが話す元原稿を要約して画面に表示したものである．字幕は，すべての情報を与えるという観点からはむしろ元原稿を要約しないで作成するほうが望ましいが，字幕の表示速度や読み易さという観点からはやはり元原稿を要約して作成する必要がある．この元原稿の要約に従来の大域的要約手法を適用すると文全体を省略してしまうので，大きな情報の欠落を伴うという問題が生じる．また，元原稿の文は局所的情報で要約できる場合が多いので，ニュースの字幕原稿作成には局所的要約のほうが適している．以下，単に「要約」と書いた場合には局所的要約を指すものとする．</section>
  <section title="原文−要約文コーパス">本論文で提案する要約知識自動獲得手法では，原文と要約文からなる電子化されたコーパスが大量に必要となる．この章では我々が使用している原文−要約文コーパスについて説明する．我々は原文にＮＨＫニュース原稿，要約文にＮＨＫ文字放送の原稿を使っている．ＮＨＫニュース原稿とは，主にＮＨＫ総合ＴＶ（ＧＴＶ）のニュース（例えば，「７時のニュース」）でアナウンサーが読む原稿の元になるものであり，電子的に保存されている．アナウンサーが読んで伝えることを目的として書かれているため，新聞記事と比較すると冗長な表現も少なくない．一方ＮＨＫ文字放送の原稿とは，ＧＴＶの電波に多重され放送されている文字放送（テレビジョン文字多重放送）の番組の原稿である．文字放送は専用のデコーダーで受信することができ，わずかの例外を除いては市販の受信ソフトにより文字コードとして計算機に取り込むことが可能である．ＧＴＶの文字放送は数百の番組があるが，本論文で用いている番組はテレモケイザイニュース，テレモコクサイニュース，テレモサンギョウ，ＮＨＫニュース，ＮＨＫフルサトネットワークの５つの番組である．文字放送の原稿の記事数は番組や日によって異なるが，１番組当たり４〜８記事であり，一日に数回ニュース内容が更新される．また，１記事は１画面の中に収まるように作成されている．ＮＨＫニュース原稿とＮＨＫ文字放送の原稿の一例を図１に示す．はじめに，ＮＨＫニュース原稿とＮＨＫ文字放送の原稿の１記事全体を定量的に比較する．比較は9,243記事に対して，文の数，文字数の平均を計算して行った．結果を表１に示す．文の数では，ニュース原稿は１記事当たり５〜６文であるのに対して，文字放送の原稿はほとんどの場合が２文である．文字数でみると，文字放送の原稿の１文は短く，ニュース原稿が約２０％に縮約されている．図１の例で，ニュース原稿と文字放送の原稿を各文ごとに具体的に比較する．文字放送の原稿の第１文とニュース原稿の第１文は共通に存在する単語列が多い．また，異なっている部分は局所的要約が行なわれている．すなわち，次のようにニュース原稿の単語列が文字放送の原稿中では短い単語列に置換されている．（ここで，矢印の左辺が原文中の単語列，右辺が要約文中の単語列である．また，記号φは空を表す．）「ごみの焼却場などから出る」（連体節）→「φ」「有害物質のダイオキシン」→「有害物質ダイオキシン」「摂取基準を引き下げること」→「摂取基準引き下げ」「受けて」→「受け」「国内の基準」→「国内基準」「なりました」→「なった」文字放送の原稿の第２文はニュース原稿の第２，３文から要約されている．文字放送の原稿の第２文は「１０ピコグラム」というキーワードを中心にして要約が生成されている．すなわち，前半はニュース原稿第２文の「１０ピコグラム」辺りの節までを要約し，後半は第３文の「１０ピコグラム」からの節を要約し，これらを繋げることにより要約が行なわれている．つまり，第２文の要約は「１０ピコグラム」という共通単語列を考慮して要約しており，節を対象にした大域的要約である．ニュース原稿の第４，５，６文は文字放送の原稿中では省略されている．すなわち，これらは文を対象にした大域的要約が行なわれたものである．</section>
  <section title="コーパスからの要約知識の自動獲得"/>
  <subsection title="要約知識">我々の要約知識は置換規則と置換条件からなる．置換規則とは原文の単語列を短い単語列に置き変えよというものである．例えば，次の規則は連体格助詞「の」という単語を省略するという置換規則である．*5mm【置換規則の例】*10mm「の／体助」→「φ」*10mm（ここで「の」は表層文字列，「体助」は品詞が“連体格助詞”であることを表す．）一方，置換条件とは置換規則が適用できるか否かを判定する条件である．置換規則の適用はその前後の単語列で決まる．例えば，次は上述の置換規則の例に対する置換条件の一部である．*5mm【置換条件の例】*10mm「日本の経済」のときは置換規則適用可*10mm「日本の銀行」のときは置換規則適用不可この置換条件の例では，「日本の経済」中の「の／体助」は省略可能であるが，「日本の銀行」中の「の／体助」は省略できないということを表している．この例のように，置換規則は必ず適用できるわけではなく，適用してはいけない場合もある．実際には後述するように，適用できる程度を[0.0,1.0]の実数値で表現している．以下では，置換規則と置換条件をコーパスから自動的に獲得する手法について具体的に説明する．</subsection>
  <subsection title="置換規則">置換規則は，原文と要約文の差分として自動的に獲得する．本手法でははじめに原文−要約文コーパスのそれぞれの文を形態素解析し，単語単位に分割する．形態素解析は我々独自のシステムを使っている．次に，形態素解析で得られた原文中の単語と要約文中の単語の最適な単語対応を求める．これは，原文中の単語w_i（表層文字列をc^o_i，品詞をp^o_iと表す）と要約文中の単語x_j（表層文字列c^s_j，品詞p^s_j）のすべての組み合わせに対して単語間の距離を計算し，その距離に基づいて単語間のＤＰマッチングを取ることによって実現している．この中で単語間の距離をどのように定義するかが重要となる．単語間の距離は，対応する単語の有無や単語の類似性により式(1)のように３つの場合に分けて定義した．【単語間の距離】distword(w_i,x_j)=distword(c^O_i/p^O_i,c^S_j/p^S_j)(1)[=.]ここで，φは空を表す記号であり，w_i=φは対応する単語が省略されたことを表す．また，内容語判定関数ContWordは単語w_iが内容語であるかないかをその品詞（p_i）から判定する関数であり，式(2)で定義する．【内容語判定関数】ContWord(p)(2)[=.]式(1a)は２つの単語が共に内容語であるか，共にそうではない場合であり，式(3)，式(4)を用いて計算される．単語間の距離は，シソーラス上の距離と品詞間の距離を重み付け（_1+_2=1）して計算される．シソーラス上の距離は表層文字列が完全一致する場合には0.0（式(3a)）をとる．一致しない場合には，それぞれの単語が内容語であれば，意味的な距離をシソーラスを使って計算する．実際には角川類語新辞典~~の分類番号の一致する桁に基づき，式(3b)〜(3d)で計算している．【シソーラス上の距離】distchar(c^O_i,c^S_j)(3)[=.]式(1a)の第２項である品詞間の距離は，式(4)のように３つの場合に分けて定義している．【品詞間の距離】distpos(p^O_i,p^S_j)(4)[=.]ここで式(4b)は，「名詞とサ変名詞」のように，完全一致しないが類似している品詞同士であり，人手で指定した．しかし，現在のところその数はあまり多くない．式(1a)は，定義式からわかるように[0.0,1.0]の値を取る．さて，式(1b)は内容語である単語と内容語でない単語が対応する場合であり，このような対応は不適切である場合が多いので他の場合よりも大きい値にした．式(1c)は対応する単語が省略されている場合であり，式(1b)と式(1a)の最大値（=1.0）の間の値とした．以上のように定義した単語間の距離に基づいて単語間のＤＰマッチングをとると，図２のように，前の単語列が一致し（単語数q1個），一部が不一致となり（p個），その後にまた単語（q2個）という部分が求められる．この不一致となる単語列が置換規則となる．さらに，一致する部分が長く，不一致の部分が短いほうが置換規則としての信頼性が高いと考えられる．そこで置換規則自動獲得の信頼度として式(5)を定義すると，この値の大きいほうが知識として有効である．実際にはあるしきい値（f_0）を決め，式(5)の値がしきい値より大きいものを収集した．【置換規則自動獲得の信頼度】f(w_iw_i+1w_i+p-1,x_ix_i+1x_i+p-1)=q1+q2p(5)さらに置換規則としての信頼度を高めるために，収集された置換規則の頻度統計をとり，頻度が高い置換規則を最終的に有効な置換規則とした．</subsection>
  <subsection title="置換条件">置換条件には置換規則の前後の単語ｎグラムが使われている．置換条件は置換規則と同時に収集されるが，原文の単語列が置換される場合w_iw_i+1w_i+p-1→x_ix_i+1x_i+p-1（正例と呼ぶ）とともに，原文の単語列がそのまま保存される場合w_iw_i+1w_i+p-1→w_iw_i+1w_i+p-1（負例と呼ぶ）も収集している．負例を自動獲得する場合にも式(5)による信頼度を使っている．置換規則の前のｎグラムを置換前条件，後のｎグラムを置換後条件と呼び，それぞれのｎの値をr1，r2とおく．すると，要約知識は図３のように表すことができる．この図でkはk番目にある置換条件を表すのに用いている．このような置換条件を参照して，ある置換規則w_iw_i+1w_i+p-1→x_ix_i+1x_i+p-1が適用できるかどうかの程度は，式(6)で定義された置換条件上の距離として計算される．置換条件上の距離の計算ではまず，それぞれのkに対して，原文の単語列の前r1グラム（w_i-r1w_i-2w_i-1）とk番目の置換前条件（w^k_i-r1w^k_i-2w^k_i-1）との距離（式(6b)），原文の単語列の後r2グラム（w_i+pw_i+p+1w_i+p+r2-1）とk番目の置換後条件（w^k_i+pw^k_i+p+1w^k_i+p+r2-1）との距離（式(6c)）を求める．次にそれらを重み付けた和（式(6a)）を計算し，さらにすべてのkに対する最小値を求め，この最小値を置換条件上の距離とする．定義から明らかなように，式(6)は[0.0,1.0]の値をとる．【置換条件上の距離】_k(g(w_iw_i+1w_i+p-1,x_ix_i+1x_i+p-1,k)(6)g(w_iw_i+1w_i+p-1,x_ix_i+1x_i+p-1,k)(6a)=_1g^-(w_i-r1w_i-2w_i-1,w^k_i-r1w^k_i-2w^k_i-1)+_2g^+(w_i+pw_i+p+1w_i+p+r2-1,w^k_i+pw^k_i+p+1w^k_i+p+r2-1)(_1+_2=1)[g^-(w_i-r1w_i-2w_i-1,w^k_i-r1w^k_i-2w^k_i-1)][=_j=1^r1weight_1(j)distword(w_i-j,w^k_i-j)_j=1^r1weight_1(j)](6b)flushright[g^+(w_i+pw_i+p+1w_i+p+r2-1,w^k_i+pw^k_i+p+1w^k_i+p+r2-1)][=_j=1^r2weight_2(j)distword(w_i+p+j-1,w^k_i+p+j-1)_j=1^r2weight_2(j)](6c)flushrightweight_1(j)=_1^j-1(6d)weight_2(j)=_2^j-1(6e)（_1,_2は定数，0.0_11.0,0.0_21.0）ただし，g^-，g^+はそれぞれ，原文と収集された置換前条件，置換後条件間の距離を計算する関数であり，置換規則となる単語列から離れるほど，その影響が少なくなるようにweight(j)で重み付けしている．さらに，置換前条件と置換後条件はで重み付けしている．式(6)で最小値を与える置換条件が正例に関するものであるならば，置換規則が適用され局所的に要約される．しかし，置換規則の適用を式(6)で単純に判定してしまうと，負例，すなわち置換規則を適用しない方を解とする場合が多くなってしまう．これは，置換条件の正例が置換しなければならないというものではなく，置換してもよいという程度の意味しか持たないからである．そこで後述する要約知識の評価実験では，あるしきい値（g_0）を決め，式(6)で求められた最小値を与える解が負例であっても正例での最小値がしきい値以下であるならば，正例を解とした．</subsection>
  <section title="実験"/>
  <subsection title="要約知識獲得実験">ＮＨＫニュース原稿とＮＨＫ文字放送の原稿から構成される，原文−要約文コーパスの9,243記事を使って要約知識を自動獲得する実験を行った．単語間のＤＰマッチングを行う際には，あらかじめ文対応をつけておくということはせずに，原文，要約文それぞれに含まれる単語のすべての組み合わせを使った．要約知識のうち，まず置換規則の自動獲得実験を行った．この際，次のパラメータ値をあらかじめ決めておかなければならない．パラメータ１：シソーラス上の距離と品詞間距離の重みづけ_1式(1a)）パラメータ２：置換規則自動獲得の信頼度f（式(5)）のしきい値f_0flushleft今回の実験では，パラメータ１に関しては，品詞間距離の計算において人手で指定している品詞対があまり多くないので，表層表現を重視するように次の値にした．パラメータ１：_1=0.7（_2=0.3）flushleftまたパラメータ２に関しては，置換規則となる単語列は１単語以上は必要であり，その前後は少なくとも一方のうち１単語は一致してほしいと考え，p=1，q1=1，q2=0（または，q1=0，q2=1）から計算される次の値にした．パラメータ２：f_0=1.0flushleft自動獲得された置換規則に対してさらに頻度統計をとった．上位40位を表２に示す．表２の中で，「や／並助→・／つなぎ」や「の／体助→・／つなぎ」等は字数が同じであり，字数を減らすという要約本来の意味では置換規則とはいえない．しかし，要約文としての読みやすさという点では有効であると考えられるので，参考のために含めた．もちろん後処理でこれらを置換規則から取り除くことは容易である．表２をみると，妥当な置換規則が得られているのがわかる．実際，上位100位までを人手で確認したところ，すべて妥当な置換規則が得られていた．具体的にみると，上位には「の／体助→φ」や「を／格助→φ」のように，分野に関係なく行なわれる要約である助詞や助動詞の省略が多いのがわかる．また，我々の原文−要約文コーパスを使ったことによる特徴であるが，置換規則「まし／助丁寧→φ」（実際には「しました→した」）や「てい／助完了ます／助丁寧→ている／助完了」のように，アナウンサーが話すことを目的としたニュース原稿を，書き言葉である文字放送の原稿に要約するための置換規則が得られている．言い換えでは内容語の場合が多く，表２では「総理／名大臣／名→首相／名」（総理大臣→首相），「委員／名会／尾→委／尾」（委員会→委）という置換規則が得られている．内容語が内容語に置換されている場合を抽出すると表３のようになった．ただし，表３では品詞は省略している．表には現れていないが，節の言い換えの例として，「日本を訪問している→訪日中の」という置換規則も得られている．次に得られた置換規則に対して，置換条件を正例，負例ともに自動獲得した．この際，前後のｎグラムの値はコーパスを見て置換条件として有効であると思われる長さより少し長めに，r_1=r_2=6とした．実際にはこれほどの長さは必要ないものと思われるが，重みの値（式(6)の_1，_2）を小さく取ることにより長さが短い場合も近似的に実現することが可能である．置換規則「の／体助→φ」に対する置換条件の例の一部を表４に示す．</subsection>
  <subsection title="要約知識評価実験">~~で自動獲得された置換規則とその置換条件を使って要約知識の評価実験を行った．実験は正例と負例をあわせた全データ（表５参照）から50個をパラメータ決定実験用に，他の100個を評価実験用にランダムにそれぞれ抽出し，残り（例えば，置換規則「の／体助→φ」では(5,331+13,498)-(50+100)=18,679個を置換条件用のデータとした．4評価は，置換条件上の距離（式(6)）から正例か負例か（すなわち，要約するか否か）を判断し，実際の正例・負例と一致したときを正解とした．しかし，~~の最後で述べたように，自動的に得られている負例には，本来は正例にもなりうる場合と，正例にはなりえない場合（真の負例と呼ぶ）がある．そこで評価実験に際して，パラメータ決定実験用データ，評価実験用データともに負例に対し正例になりうるか否かを人手で判断し，正例になりうるものは元の正例に加えた．要約知識はなるべく適用されたほうがいいものの，誤って適用されてはいけないので，評価は式(7)の値で行った．f‐measure=2.0PRP+R(=F)(7)precision=正例，負例が正しく判定された個数評価実験用データ数（=100）(=P)(7a)eqnarray*recall=正しく正例と判定された個数評価実験用データ数のうち正例の数(=R)(7b)eqnarray*式(7a)は，正例，負例の判断をして実験用データと一致した割合を表している．式(7b)は実験用データの正例の中で正確に正例として判断された割合であり，すなわち，要約が行なわれた場合にどのくらいが正解かを表している．これら２つの値からf‐measureを計算し評価した．今回評価に用いた置換規則は，表２の中からある程度のデータ量をもつ助詞，助動詞の要約に関するものである，「の／体助→φ」，「を／格助を→φ」，「で／助断定→φ」，「に／格助に→φ」，「が／格助が→φ」，「な／助断定→φ」，「する／さ連体→の／体助」，「て／接助→φ」，「し／さ連用→φ」の９種類である．パラメータ決定実験では次の値を評価実験に先だって決めなければならない．パラメータ３：置換前条件と置換後条件との重み_1（式(6a)）パラメータ４：置換前条件内の単語列に対する重み_1（式(6d)）パラメータ５：置換後条件内の単語列に対する重み_2（式(6e)）パラメータ６：置換条件上の距離のしきい値g_0この中で置換条件上の距離のしきい値g_0は置換規則の種類によらず経験的に次の値にした．パラメータ６：g_0=0.4flushleftその他のパラメータに関しては置換規則ごとにさまざまなパラメータを使って実験し，最もf‐measureの大きい場合を選択した．それぞれの置換規則におけるパラメータを表６に示す．表６中の_1をみると，置換規則によってパラメータの値がかなり異なることがわかる．置換規則「を／体助を→φ」では置換前知識に重み付けられているのに対し，置換規則「の／体助→φ」では置換後知識のほうが重みが大きい．次にこれらのパラメータ値を使って要約知識の評価実験をした．実験結果を表７に示す．ここで比較のために，すべてを正例と判断した場合のf‐measureの値（F'）も記した．合，R=100となるのでF'は，f‐measureのbaseline値=2.0(100-真の負例の割合)100(100-真の負例の割合)+100(=F')(8)と計算される．flushleft表７を見ると，置換規則「を／体助を→φ」の場合はf‐measureの値がbaseline値とほとんど変わらない．しかし，置換規則によって精度のばらつきがあるものの，概ね良好な結果が得られている．</subsection>
  <subsection title="置換規則「の／体助→φ」の誤り例">今回の実験でf‐measureが一番低かった置換規則「の／体助→φ」の誤りを分析した．の誤りは距離計算がうまくなされていないことによるものであった．これを改善するには，単純には学習データを増やしたり，またシソーラスをニュース用にきめ細かく作成することにより，さらに精度よく置換条件上の距離を計算する必要がある．しかし，さらに細かい言語情報を必要とする誤りの例もあった．以下に例をあげる．【誤り例１】原文「『白鳥の王女のアリア』」要約文「『白鳥の王女アリア』」flushleft例１では「『白鳥の王女のアリア』」は固有名詞なので要約してはならないのであるが，「の」を省略してしまった．正確に要約するためには「『白鳥の王女のアリア』」が固有名詞であるという情報が必要である．flushleft【誤り例２】原文「アメリカ軍嘉手納基地周辺の住民」要約文「アメリカ軍嘉手納基地周辺住民」flushleft例２では，正例に「周辺の住民→周辺住民」という例があったために「の」が省略されてしまったが，要約文では非常に長い名詞連続となってしまうので読みにくくなってしまう．この場合にはある長さ以上の名詞連続を作成するときには省略をしてはいけないという情報が必要となろう．flushleft【誤り例３】原文「アジアの株式市場と為替市場」要約文「アジア株式市場と為替市場」flushleft例３では正例に「アジアの株式市場→アジア株式市場」という例があったために「の」が省略されてしまった．原文では「アジア」が「株式市場」とともに「為替市場」にも係っているので，省略することはできない．このような場合には前後の単語列の構文情報も考慮する必要があろう．flushleft今後はこのような言語情報も加えて要約の改善をしていく予定である．</subsection>
  <section title="おわりに">原文−要約文コーパスより局所的要約知識を自動獲得する手法について述べた．また，ＮＨＫニュース原稿とＮＨＫ文字放送の原稿から構成されるコーパスを使って，局所的要約知識を自動獲得する実験を行った．さらに要約知識の評価実験を行い，良好な結果を得た．今後の研究の方向は２つある．１つは局所的要約に関するものである．今回は評価実験の第一歩として特定の局所的要約知識にのみ着目したが，今後は自動獲得された要約知識すべてを使って文全体の局所的要約を試みたい．その際には，適用する要約知識間で競合が起こることが予想される．そこで，与えられた要約率の中で要約知識の最適な組み合わせを求めることが必要となる．我々は信頼度の評価関数を最小化することにより，要約知識の最適な組み合わせを求めるアルゴリズムを研究している~~．このアルゴリズムによって得られた要約結果を人間が読んでどれぐらい違和感がないかも評価する必要があろう．もう１つの方向は，大域的要約に関するものである．これには要約には現れなかった元のニュースの文（例えば，図１の第４，５，６文）や節（図１の第２，３文中の節）を，文や節の削除手法の研究の評価用データとして使っている．現在，従来の評価関数（例えば，tf法やtf*idf法）を使ってどのくらいの精度で削除できるかを実験中である．これらの詳細については稿を改めて報告したい．document</section>
</root>
