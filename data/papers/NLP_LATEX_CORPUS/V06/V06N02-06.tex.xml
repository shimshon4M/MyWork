<?xml version="1.0" ?>
<root>
  <title>音声認識用言語モデルのためのタスク適応化と定型表現の利用</title>
  <author>中川聖一赤松裕隆西崎博光</author>
  <jabstract>本研究では大規模コーパスが利用可能な新聞の読み上げ音声の認識のための精度の良い言語モデルの構築を実験的に検討した．N-gram言語モデルの改善を目指し，以下．まずN-gram言語モデルはタスクに依存するので，タスクに関する大量のデータベースを用いて構築される必要があることに注目し，共通の大量データベースによる言語モデルをもとに，同一ジャンルの過去の記事を用いるタスク．次に，新聞記事は話題が経時的に変化するので，数日間〜数週間の直前の記事内容で言語モデルの適応化を行に新聞テキストには，使用頻度の高い(特殊)表現や，固定的な言い回しな，定型表現と呼ぶ)が多いことに注目し，複数形態素から成る定型表現を抽出し，，討し，有用性を示す．</jabstract>
  <jkeywords>音声認識，言語モデル，N-gram，タスク適応化，定型表現</jkeywords>
  <subsubsection title="">*Step.1定型表現抽出RWCの毎日新聞形態素解析結果に対して，定型表現抽出プログラムを実行し，連結数2または3の定型表現を抽出する．</subsubsection>
  <section title="はじめに">近年の著しい計算機速度の向上，及び，音声処理技術/自然言語処理技術の向上により，音声ディクテーションシステムやパソコンで動作する連続音声認識のフリーソフトウェアの公開など，音声認識技術が実用的なアプリケーションとして社会に受け入れられる可能性がでてきた．我が国では，大量のテキストデータベースや音声データベースの未整備のため欧米と比べてディクテーションシステムの研究は遅れていたが，最近になって新聞テキストデータやその読み上げ文のデータが整備され,ようやく研究基盤が整った状況である．このような背景を踏まえ，本研究では大規模コーパスが利用可能な新聞の読み上げ音声の精度の良い言語モデルの構築を実験的に検討した．音声認識のためのN-gram言語モデルでは，N=34で十分であると考えられる．しかし，N=3ではパラメータの数が多くなり，音声認識時の負荷が大きい．そこで，大語彙連続音声認識では，第1パス目はN=2のbigramモデルで複数候補の認識結果を出力し，N=3のtrigramで後処理を行なう方法が一般的である．ばかりでなく，第1パス目のbigram言語モデルの改善を目指し，以下の3つの点に注目した．まずタスクについて注目する．言語モデルをN-gram記述するのとは異なり)，大量の学習データが必要となる．最近では各種データベースが幅広く構築され，言語モデルの作成に新聞記事などの大規模なデータベースを利用した研究が行なわれている．しかしN-gramはタスクに依存するのでタスクに関する大量のデータベースを用いて構築される必要がある．例えば，観光案内対話タスクを想定し，既存の大量の言語データに特定タスクの言語データを少量混合することによって，N-gram言語モデルの性能の改善が行なわれている．また，複数のトピックに関する言語モデルの線形補間で適応化する方法が試みられている．本研究ではタスクへの適応化のために，同一ジャンルの過去の記事を用いる方法とその有効性を示す．次に言語モデルの経時変化について注目する．例えば新聞記事などでは話題が経時的に変化し，新しい固有名詞が短期的に集中的に出現する場合が多い．以前の研究では、みられ，その有効性が示されてはいるが，本論文では直前の数万〜数十万語に拡大する．つまり，直前の数日間〜数週間の記事内容で言語モデルを適応化する方法を検討し，その有効性を示す．最後に認識単位に注目する．音声認識において，付属語においてその影響は大きいと考えられ，小林らは，付属語列を新たな認識単位とした場．関連率の高い複合名詞などを新しい認識単位とし，ルの性能に与える影響を検討している．なお，連続する単語クラスを連結して一つの単語クラスとする方法や句を一つの単位とする方法は以前から試みられているが，いずれも適用されたデータベースの規模が小さい．同じような効果を狙った方法として，N-gramのNを可変にする方法も試みられている．なお，定型表現の抽出に関する研究は，テキスト処理分野では多くが試みられている(例えば，新納,井佐原1995;北,小倉,森本,矢野1995)．新聞テキストには，使用頻度の高い(特殊)表現や，固定的な言い回しなどの表現(以下，定型表現と呼ぶ)が非常に多いと思われる．定型表現は，音声認識用の言語モデルや音声認識結果の誤り訂正のための後処理に適用できる．そこでまず，定型表現を抽出した．次に，これらの(複数形態素から成る)定型表現を1形態素として捉えた上で，N-gram言語モデルを構築する方法を検討する．評価実験の結果，長さ2および3以下である定型表現を1形態素化してbigram,trigram言語モデルを作成することで，bigramに関しては，エントロピーが小さくなり，言語モデルとして有効であることを示す．なお，これらの手法に関しては様々な方法が提案されているが，大規模のテキストデータを用いて，タスクの適応化と定型表現の導入の有効性を統一的に評価した研究は報告されていない．*-3mm</section>
  <section title="言語モデルの評価基準">*-1mm</section>
  <subsection title="エントロピーとパープレキシティ">言語モデルの評価基準として，エントロピーとパープレキシティを用いる．エントロピーとパープレキシティは共に，対象とする文集合の複雑さを定量的に示す指標で，その文集合が複雑なほど，それぞれの値は大きくなる．単語列を生成する情報源をモデル化したものを言語モデルと呼ぶ．いま(単語列)W_i=w_1w_L_iの出現確率をP(W_i)とすれば，文集合W_1,W_2,,W_Nのエントロピーは次式で求められる．*-3mmテキスト文の連接をW=W_1W_2W_N=w_1w_2w_Tとすれば，テストセットのエントロピーは*-3mmで示される．トライグラムを用いた場合，P(W)は*-3mmP(W)&amp;=&amp;P(W_1)P(W_2)P(W_N)&amp;=&amp;P(w_1|*#)P(w_2|#w_1)&amp;&amp;P(w_3|w_1w_2)P(w_T|w_T-2w_T-1)eqnarrayとなる(注:#は文頭を，*は文末を示す．以降の評価実験では句読点を含む)．この時，一単語当たりのエントロピーはまた，言語の複雑さ・パープレキシティはと定義される．パープレキシティは，情報理論的にある単語から後続可能な単語の種類数を表している．この値が大きくなるほど，単語を特定するのが難しくなり，言語として複雑であるといえる．また逆に，この値が小さくなるほど，音声認識での後続予測単語を特定するのがやさしくなるので，認識率が上がる傾向にある．日本語の単語の定義は定かでなく，また形態素の定義も異なる．そこで，本論文では文字単位のエントロピー(パープレキシティ)の指標も用いる．*-1mm</subsection>
  <subsection title="補正パープレキシティ">本研究で使用したCMUSLMtoolkitでは語彙に含まれないものは全て一つの未知語のカテゴリにまとめられ，語彙に含まれる形態素と等価に未知語のカテゴリは扱われる．そのため語彙サイズのセットが小さい程(カバー率が小さい程)，パープレキシティは小さくなるということになり好ましくない．そこで評価テキスト中に出現した未知語の種類mと，未知語の出現回数n_uを用いてパープレキシティを補正する．補正パープレキシティは*-3mmで与えられる．これは，複数の未知語はそれぞれ等確率に生じると仮定して，補正したものである．勿論，これは評価テキストの大きさに依存する(テキストが大きくなると未知語の種類が増える)ので，簡易的な補正である．より厳密には未知語に対しては出現頻度を考慮するか，未知語の生成モデルを用いる必要がある．なお，一般には，未知語部分はスキップしてパープレキシティを算出する方法がよく使われている．*-1mm</subsection>
  <section title="言語モデルの適応化">*-1mm</section>
  <subsection title="面種別での学習と評価">*-1mmタスク依存の言語モデルを構築する場合，ターゲットとするタスクに関するデータのみを用いて学習する方がよいと考えられる．学習と評価用のコーパスとして毎日新聞の1991年1994年の記事を用いた．形態素解析にはRWCPが提供している毎日新聞形態素解析データを，電総研で作成された括弧除去ツールで加工し，使用している．学習には1991年月までの記事を用い，評価には1994年12月の記事を用いた．毎類されているが，「社説」，「科学」，「読書」などの面種にはデータが少な過ぎるので，面種別の結果は省いた．登録した形態素数は5000,20000の2通りで，bigram,trigramの学習と評価にCMUSLMtoolkitを使用した．表に用いたコーパスの諸量をまとめた(学1994年1月〜11月の場合の結果は，文献を参照されたい)．これらのデータを用いて作成したbigramとtrigramの評価結果を表,に示す．で，5000形態素に関する結果は省略した．これらの表では，実験結果をエントロピーではなくパープレキシティで表示している．これは音声認識実験を行なうことを踏まえ，情報理論的にある単語から後続可能な単語の種類数を示すパープキシティという指標の方が直観的にわかりやすいためである．またカバー率とは，unigramのヒット率のことである．これらの結果より以下の事がわかる．bigramとtrigramを比較すると，bigramより，レーニングデータとテストデータのどちらのパープレキシティも小さくなる．テストデータとトレーニングデータを比較すると，形態素数5000のbigramでは，テストデータとトレーニングデータとの間にパープレキシティの差はほとんど見られなかった．しかし，それ以外の言語モデル(bigram形態素数20000,trigram形態素数5000,trigram形態素数20000)では，テストデータとトレーニングデータとの間にパープレキシティの差が大きい．これは補正パープレキシティでも同様である．特に形態素数20000のtrigramで差が大きい．これは，9000万形態素では，トレーニングデータ量が不足していることを示している．全面種で学習した場合と面種別で学習した場合の比較をすると，面種別に語彙を設定する方がカバー率は向上する．また，テストデータのパープレキシティに関しては，形態素数20000のbigramでは全面種で学習するより面種別で学習する方がパープレキシティが小さくなる．trigramでは面種別で学習するより全面種で学習する方がパープレキシティが小さくなる．これは，面種別ではトレーニングデータが不足することによると考えられる．なお，テストデータの補正パープレキシティに関しては，形態素数20000のtrigramでは面種別で学習するより全面種で学習する方が補正パープレキシティが小さくなる．bigramでは全面種で学習するより面種別で学習する方が補正パープレキシティが小さくなる．また，スポーツ面に関しては全面種で学習するより，面種別(すなわち，スポーツ面)で学習する方がパープレキシティが小さくなる傾向が見られる．これは，スポーツ面は他の面種と異なった文が多いことによる．表には示さなかったが，形態素数5000のbigramに関しては，全面種での学習では4年分の新聞記事で十分な学習が出来ている．一方，面種別での学習ではトレーニングデータとテストデータのパープレキシティの間に差があるのでトレーニングデータの不足が見られる．しかしトレーニングデータの不足が見られるものの，全面種で学習した言語モデルより面種別で学習した言語モデルの方がテストデータのパープレキシティが小さい．つまり，全面種で学習した言語モデルより面種別で学習した言語モデルを使用する方がよいことになる．形態素数5000のtrigramに関しては，面種別学習による効果はパープレキシティでは見られないが，補正パープレキシティでは効果が見られる．形態素数20000のtrigramに関しては，トレーニングデータとテストデータの(補正)パープレキシティの比較によって，面種別での学習のみならず全面種での学習でもトレーニングデータ量の不足が起きていることが分かる．全面種で学習した言語モデルと面種別で学習した言語モデルをテストデータの(補正)パープレキシティで比較すると，形態素数5000のbigramでの比較とは逆に，面種別で学習した言語モデルより全面種で学習した言語モデルの方が，(補正)パープレキシティが小さく，面種別で学習した言語モデルを使用するより，全面種で学習した言語モデルを使用する方がよいという結論が得られた．以上から，形態素数5000のbigramを言語モデルに使用する場合は，面種別で学習した言語モデルを用いればよいことがわかった．しかし，最近の大語彙音声認識に用いられる形態素数は20000以上で，また第2パスに言語モデルとしてtrigramを使用するのが主流となりつつある．形態素数20000のtrigramだと，本研究で用いたトレーニングデータ量程度では，面種別で学習した言語モデルを使用するより，全面種で学習した言語モデルを使用する方がよい．そこで，タスク(新聞では，面種)依存のより精度のよい言語モデルを構築するために全面種の記事で構築した言語モデルを，ターゲットとするタスク(面種)に適応化する手法をとる必要がある．*-4mm*-5mm</subsection>
  <subsection title="適応化法">新聞記事では数日間に渡って関連のある記事が載っていることがある．そこで記事の評価時に，過去の数日間の記事で言語モデルを適応化しておけば，適応前より精度のよい言語モデルが出来ると考えられる．ここで，N-gram言語モデルの適応化にはMAP推定(最大事後確率推定)を用いる．適応化サンプルを与えた後の推定値は次式で与えられ，推定前の条件確率と現在与えたサンプルとの間で，サンプル数で重み付けされた線形補間の形になっている．今回の実験では標準言語モデルと適応化サンプルによる言語モデルの２つを構築しておき，バックオフを行なってスムージングした２つの条件確率を用いてMAP推定を行なっている．この過程のブロック図を図に示す．標準言語モデルでは，プルで出現頻度の高い形態素20000に限定した．適応化サンプルでは語彙を限定せず，全ての形態素を語彙リストに登録した．そのため，２つのモデルの語彙リストは独立している．実験手順としては，1形態素数20000の標準言語モデル(trigram)を構築し，2デルを事前モデルとして，面種別の適応化サンプルでターゲットタスクの言語モデルをMAP推定し，3テストデータのパープレキシティを求める．本実験では，を種々変えてパープレキシティが最小となる場合を求めた．</subsection>
  <subsection title="実験結果">実験結果を表,に示す．最適なの値は5日間の適応化データに対してはほとんどの面種で0.01，14日間の適応化データに対しては0.020.04であり，ほぼデータ量に比例した．これらの表より適応化前より適応化後の方がパープレキシティが小さくなること5日より14日間の適応化サンプルの方がパープレキシティが小さくなる	こと6カ月前の数日間より直前の数日間の記事での適応化の方がパープレキ	ることが分かる．通常，直前の数百単語をキャッシュとして用いて適応化する方法が効果があると言われているが，これよりも大量の直前データを用いる方が効果があるということである．特に，スポーツ面において，直前の記事による適応化の効果が大きい．これは，他の面種記事よりも特定の話題が短期間継続するためと考えられる．国際面とスポーツ面で適応化サンプルの期間を5,14日,1,2,3,6カ月にして求めたパープレキシティと補正パープレキシティを図に示す．ど，パープレキシティが小さくなること，日数が多くなるにつれてパープレキシティが飽和していくことが分かる．また，直前の適応化データと6カ月前の適応化データを比べると，後者の場合の方がやや最適なの値が大きくなった．これは直前の適応化データの方が6カ月前の適応化データよりも有用であることを示している．</subsection>
  <subsection title="固有名詞の適応化">前述したように，新聞記事では数日間に渡って関連のある記事が載っていることが多い．音声認識では特に固有名詞の扱いが重要となってくるので，固有名詞の登録法について検討した．固有名詞はトピックに依存するものが多いので，数日間に渡って局所的に出現する傾向があると考えられる．そこで数日間〜数週間中に出現した固有名詞を基本語彙に追加することにより，評価文の固有名詞をどの程度カバーすることが出来るかを調べた．実験手順を以下に示す．実験は，追加登録する形態素を5000に限定した場合と出現したすべてを登録する場合を行なった．実験結果を表,に示す．合の数を示している．この結果より次のことが言える．６ヶ月前の記事より直前の記事に出現する固有名詞を追加する方がカバー率が高い．これより，新しく出現した固有名詞の多くは直前の数日間に渡って出現していることが分かる．追加する固有名詞の数を制限しない場合は，適応化サンプルが多いほどカバー率が高くなるのは当然だが，固有名詞の数を制限した場合でも，10日間より30日間の適応化サンプルを用いた方が，カバー率は少し高くなる．テストデータ全体でのカバー率を見て分かるように，固有名詞を追加することによるカバー率の上昇は高々2%程度である．このことは，基本語彙に登録されなかった単語(未知語)において，固有名詞の占める割合が低いことを示している(5000語彙に対しては約20%，20000語彙に対しては約25%)．なお，固有名詞に限定せずに，出現頻度の多い形態素を登録した場合の結果を表に示す．，登録する単語を固有名詞かし，このような新しい登録単語のbigram,trigramの算出は困難なので固有名詞に限定した方が扱いやすいと思われる．また表より，カバー率を98%にするためには直前に出現した形態素を中心とした55000形態素程度が必要なことがわかる．但し，面種別で学習すれば，20000〜30000形態素でも十分である(表~2,3参照)．*-1mm*-13mm</subsection>
  <section title="定型表現">新聞テキスト文には，定型表現が多いことに着目し，これらの高頻出定型表現を1形態素として捉えた上で，言語モデルを構築すれば，より精度の良いモデルが出来ると考られる．今回の実験では，定型表現を抽出するアルゴリズムとして，池原らの提案した方法を用いる．エントロピー基準で連語を抽出する方法も考えられるが，今回は簡略化のため出現頻度に着目した．どのような基準で連語を抽出し，言語モデルを構築するかは興味ある課題であるが，手法による実質的な差は少ないと思われる．この方法では，最長一致の文字列抽出(ある文字列が抽出されたとき，その文字列に含まれる部分文字列は統計量を求める際にはこの部分文字列を定型表現とはカウントしない)を条件とし，任意の長さ以上，任意の使用頻度以上の表現を，もれなく自動的に抽出する．文献では文字列単位で抽出していたが，これを抽出するように変更した．抽出例を表~に示す．*-5mm</section>
  <subsection title="標準言語モデル">標準言語モデルは，表~に示した全面種の学習用データから作成した表~のモデルを用いる．まず，RWCの毎日新聞形態素解析結果を用いて，出現頻度が上位20000番目までの形態素を語彙として辞書に登録した．言語モデルの構築には，CMUSLMToolkitVer.1を用いた．バックオフ・スムージングにはGood-Turing推定を用いた．</subsection>
  <subsection title="定型表現を用いた言語モデル">定型表現を用いた言語モデル構築のための手順を以下に示す．</subsection>
  <subsection title="評価実験">評価を行なう時，注意しなければならないことは，いずれの比較対象に対しても同じ定義の1形態素あたりのパープレキシティを求めないといけないということである．ティを求める式はbigramの場合で，であるが，これは1連結形態素(定型表現として形態素を連結したもの)あたりのパープレキシティを求めている．形態素を連結する前の従来の1形態素あたりのパープレキシティを求めるには，を用いなければならない．ここでM:定型表現を1つの形態素としたときの連結形態素と従来の形態素の総数N:定型表現を使わなかったときの従来の形態素の総数また，定型表現は述語表現に多く現れるため，それらの形態素は比較的短いものが多い．そのため形態素単位のパープレキシティでは全体に及ぼす影響が大きいと考えられる．そこで同時に文字単位のパープレキシティも求めた．標準言語モデルと，前節に述べた方法で定型表現を用いた言語モデルを構築し，その評価を行なった．トレーニングデータには，標準言語モデル作成の場合と同じ，表~の学習用データを用いている．テストデータには，標準言語モデル，定型表現を用いた言語モデルともに表~の評価用データを使用した．実験結果を表~と図~に示す．まず，bigramモデルでは，トレーニングデータに関しては約半分，テストデータに関しては約3割，パープレキシティが減少しているのがわかる．しかし，trigramモデルではトレーニングデータでは効果があったが，テストデータに対しては大きな効果が得られなかった．これは，語彙サイズを一定にしたため，定型表現を登録したためにもとの語彙から省かれた単語が未知語となったのが原因であると考えられる．実際，定型表現を用いた場合，定型表現を用いなかった場合と比べて，未知語の種類数が約8000個増加している．次に，標準言語モデルを作成した時の語彙サイズ20000の辞書に，2および3連結の定型表現をそれぞれ高出現頻度順で上位2000個,5000個分を追加した場合の辞書で言語モデルを構築した．その評価結果を表~,に示す．ここで表~,の``定型表現の連結なし''はを22000個および25000個用いた時の結果である．この言語モデルの作成方法の場合でも，パープレキシティの改善が見られた．bigramでは定型表現を用いることにより，補正パープレキシティも大幅に減少している．また，定型表現5000個追加のものの方が，ものと比べて，語彙サイズが大きいのにも関わらず，パープレキシティが減少している．これより，出来るだけ多くの定型表現を辞書に登録すれば良いということが言える．以上より，trigramではトレーニングデータに対しては大きな効果があったが，テストデータに対しては効果がなかった．これはトレーニングデータの不足によるものと考えられる．一方，bigramでは大きな効果があった．同じパラメータ数(bigram)でもいモデルが構築できたことは，これを大語彙連続音声認識の第1パスに使用すると認識率の向上に繋がると考えられる．[htbp]figure*</subsection>
  <section title="まとめ">本研究では，毎日新聞記事データベースを用いた過去の記事による言語モデルのタスクへの適応化と抽出した定型表現を用い，N-gram言語モデルを構築する方法を検討した．まず言語モデルのタスクへの適応化については，実験の結果，6カ月前の数日間の記事より直前の数日間の記事で適応化した方がパープレキシティが小さくなった．このことは言語モデルがジャンルだけでなく時間にも依存するものであることを示すものである．ただ，適応化サンプルの量を多くするほどパープレキシティが小さくなる傾向があり，N-gramベースでの言語モデルを少量サンプルで適応化させることは限界があると考えられる．次に定型表現を抽出し，これを用いたN-gram言語モデルを構築した．定型表現を用いた言作成することで，bigramモデルに関しては，テストデータに対し約3割程度キシティを低く押えるとこができ，言語モデルの有効性を示すことができた．しかし，trigramではトレーニングデータの量が不十分だったため，トレーニングデータでは効果があったがテストデータに対しては効果が得られなかった．トレーニングデータの量をもっと増やし，本方法の有効性を調べる必要がある．また，本研究では言語モデルの有効性をパープレキシティで評価したが，実際の音声認識で確認する必要がある．なお，NHKのニュース原稿に対する経時変化の適応化や定型表現の導入による言語モデルに関しては文献を参照されたい．document</section>
</root>
