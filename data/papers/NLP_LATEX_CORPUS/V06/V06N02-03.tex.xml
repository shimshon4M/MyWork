<?xml version="1.0" ?>
<root>
  <title>品詞および可変長形態素列の複合Ｎ─ｇｒａｍを用いた日本語形態素解析</title>
  <author>政瀧浩和匂坂芳典</author>
  <jabstract>本論文では，日本語連続音声認識用のN-gram言語モデルの学習に用いる形態素データを，テキストデータから自動的に生成することを目的として，品詞および可変長形態素列の複合N-gramを用い，日本語テキストデータを自動的に形態素解析する手法を提案する．複合N-gramは，品詞，形態素，形態素列を単位としたN-gramで，少ないデータ量から高い予測精度を持つ言語モデルである．また，品詞から未知語が出現する確率を定式化することにより，未知語の形態素解析を行えるようにモデルの改良を行った．形態素解析実験の結果，複合N-gramの形態素同定率は最高99.17%で，従来のルールベースによる方法よりも正確に形態素の同定が行えることが判明し，提案手法の有効性を確認した．また，読みまで含めた評価を行った場合でも，最高98.68%の正解率が得られた．未知語を含む文の形態素解析では，全ての語いが辞書に登録されている場合と比較して0.8%程度の低下に抑えることができた．</jabstract>
  <jkeywords>連続音声認識,形態素解析，N-gram,複合N-gram，未知語</jkeywords>
  <section title="はじめに">近年，連続音声認識において，N-gram言語モデルによる言語制約を用いた手法が幅広く用いられている．N-gramは，大規模なテキストデータを統計的に解析し，直前のN-1個の単語から次の単語への遷移を確率的に与える非常に単純な言語モデルである．しかし，その構築・実装の容易さ，統計的音響モデルとの相性の良さ，認識率向上や計算時間の短縮の効果が大きい等の理由から，連続音声認識にはでは盛んに用いられている．N-gramは当初，英語の連続音声認識に対して適用され，その有効性が示された．英語の文章は，単語がスペースで区切られており，テキストデータから単語を単位としたN-gramが容易に構築できる．しかし，日本語の文章は文字が連続しており単語の境界が明らかではなく，テキストデータのみでは単語N-gramを構築することはできない．このため，我々は日本語の連続音声認識の認識単位として形態素を用いているが，その有効性について２章で明らかにしている．形態素を単位としたN-gramを構築する場合，テキストデータに形態素を付与する，いわゆる形態素解析を行う必要がある．しかし，N-gramを構築するのに必要な，大量のテキストデータを全て人手で形態素解析を行うには多大な労力と時間が必要であり，また，かなりの経験がある人が作業を行わなければ，付与された形態素の揺れも大きくなると考えられる．従って，大量のデータをより正確に形態素解析を行うためには，自動的に形態素解析する手法が望ましい．自動形態素解析は，従来人手で作成したルールにより解析を行う方法が主流であったが，ルールの作成の作業は相当の知識・経験が必要であり，また，話し言葉等のより自然な文を全てカバーできかつ矛盾のないルールを作成するのは困難であると考えられる．これに対し，本論文ではN-gram統計に基づく形態素解析手法を考える．N-gramを構築するためには，事前に形態素体系の構築や定義を行う必要はあるが，従来の形態素解析で必要であった形態素間の接続ルールの作成・重みの変更等の作業に代わり，ある程度の量の形態素データを収集するという比較的単純な作業で構築できる利点がある．また，より自然な発話文に対しても，データさえ収集できれば容易に適用可能である．３章では，N-gramを用いた形態素解析の原理を説明する．統計的モデルにより形態素解析を行うためには，通常は統計モデルの学習用として形態素解析済みの言語コーパスが整備されていることが前提となる．このため，山本らは辞書と接続コストのみを用いて文コーパスから形態素ネットワークを生成し，生成された形態素ネットワークから隠れマルコフモデルを学習し形態素解析を行うことにより，形態素解析された言語コーパスが存在しない場合でも形態素解析が可能な手法を提案している．しかしこの方法では，形態素解析にかかるコストは非常に小さいという長所はあるが，形態素解析の結果はモデル化能力の低いとされる品詞Bigramと大きくは変わらず，形態素解析の正解率の適合率が93.5%程度と報告されており，正しい形態素データを学習しない方法には精度に限度があると考えられる．形態素解析の精度は連続音声認識の精度にも大きく影響すると考えられるため，我々は高い精度でかつできるだけコストを抑えた形態素解析の手法を考える．このため，本論文では，形態素解析のためのN-gram言語モデルとして，より少ない量の形態素解析された言語コーパスから精度の高い予測精度の言語モデルを得るため，品詞と可変長形態素列の複合N-gramを用いることを提案する．複合N-gramは，基本的には品詞を単位としたN-gramであるが，言語モデルとしての精度を高めるため，特定の形態素は品詞クラスから分離させ独立して扱い，さらに特定の形態素列を結合させて新たな単位として扱うモデルである．このため，品詞という単位では表現できない形態素独自の特徴を表現でき，かつ長い範囲の形態素間の連接関係を効率良く表現することができるモデルである．４章では，品詞と可変長形態素列の複合N-gramについて解説する．通常連続音声認識では，辞書に登録されている語いを対象とした認識が行われている．しかし形態素解析では，大量のテキストデータをまとめて処理するため，辞書に登録されていない未知語が含まれている場合も多く存在する．このため，形態素解析においては，未知語を含む文に対しても正確に処理が行えることが重要であると考える．本論文では，品詞から未知語が出現確率する確率を考えることにより，未知語の形態素解析も行えるよう，５章で定式化を行った．本論文で使用した複合N-gramは，品詞を基本単位としたN-gramであるため，このような未知語処理が容易である．第６章では，形態素解析実験により，形態素N-gramや品詞N-gramに対する複合N-gramの有効性を示し，最後の７章で本論文の結論を述べる．</section>
  <section title="日本語連続音声認識のための形態素解析">英語等の言語では，単語を認識単位とした連続音声認識システムが構成されている．しかし，日本語の文は連続した文字列から構成されているため，単語の定義が明らかでなく，適切な認識単位が定かではない．連続音声認識の適切な単位として，以下の条件を満たすが重要であると考えられる．認識単位から読みの対応が明確であること日本語の場合，漢字の読みや，助詞の「は」「へ」など，その文字だけでは読みが決定できない場合が多い．できる限りヴァリエーションの少ない読みが決定できる認識単位を選択することが，連続音声認識の探索空間の削減のために有効である．ポーズ（無音区間）の挿入位置が限定できること連続音声といっても，発声文にはポーズが挿入される．連続音声認識では，認識単位間にはポーズの挿入が可能であるとして認識を行うため，連続音声認識の探索空間の削減および認識率の向上のためには，認識単位をできるだけ長くしてポーズが挿入される個所を少なくし，かつ認識単位中にはポーズは挿入されないように決定するのが好ましい．言語理解システムとの整合性が良いこと音声認識のアプリケーションとして，機械翻訳等の言語理解と結合した音声理解システムが考えられる．言語理解には形態素解析・構文解析等の処理が必要である．このため，認識誤りにより認識結果の解析が不能に陥ることが少ない単位が望まれる．以上の条件をよく満たす単位として，形態素が挙げられる．しかし，形態素を単位としてN-gramを構築する場合，テキストデータから形態素を切り出す必要があり，この作業をすべて手作業で行うにはかなりのコストが必要となり，N-gram構築上の大きな問題となる．このため，形態素切り出し作業を省くことを目的として，文字あるいは文字列を単位とした手法が提案されているが，上記３条件には適合せず，連続音声認識にとって好ましい単位とは言えない．従って，テキストデータから大量の形態素データを得るためには，自動で形態素解析を行う必要があると考えられる．また，音声認識の対象となる文は基本的に話し言葉であり，文章の読み上げなどの場合を除いては，通常の発話において書き言葉を喋ることはまずありえない．このため，連続音声認識用の言語モデル構築のためには，話し言葉のテキストデータに対して形態素解析が可能でなければならない．現在形態素解析の手法としては，形態素間の接続ルールや重み付けを人手で作成するルールベースの手法が広く用いられているが，接続ルールは通常書き言葉を対象に作成されており，音声認識で必要な話し言葉に対して，十分な性能が得られない可能性がある．このため，本論文では，統計的な言語モデルを用いた形態素解析の手法を採用した．統計的モデルは，データから自動的に構築できるため，接続ルールや重み付けを手作業で行うことと比較して，話し言葉に対しても適用が容易であると考えられる．また，統計的言語モデルは，連続音声認識の言語モデルとしても盛んに使用されているため，形態素解析にも統計的モデルを用いることにより，認識用言語モデルに適した形態素解析結果が得られると考えられる．</section>
  <section title="N-gram言語モデルによる形態素解析">日本語の形態素解析は，文の文字列Lから，それに対応する形態素列W_Lを獲得することである．統計的手法では，Lに対して最も高い確率を与える形態素列W_L形態素解析を実現する．これは，以下の式で与えられる．ベイズ則により本式は下式のように変形される．本式において，P(L)は右式の最大値を与えるためには無関係な量である．従って，式は下式と等価となる．右辺の確率P(L|W)は形態素から文字列を与える確率であるが，これは，形態素の表記と文字列が一致する場合は必ず1であり，一致しない場合は0である．また，確率P(W)は，形態素列Wの生成確率である．従って，統計的手法による形態素解析は，与えられた文字列と一致する全ての形態素列の中から，生成確率が最も高くなる形態素列を探索することによって実現できる．形態素列Wをw_1,w_2,w_mとすると，その生成確率P(W)は次のように表される．本式において，w_x^yはx番目yから番目までの形態素列を表す．難であるから，各形態素は，直前のN-1形態素から確率的に予測できると近似する．これが，形態素N-gramである．N-gramを用いると，上式の形態素列Wの遷移確率は次のように近似される．N-gramは，Nが大きくなるほど，パラメータ数が飛躍的に増大するため，通常は直前の形態素から次の形態素を予測するBigram(2-gram)，および直前の2形態素から次の形態素を予測するTrigram(3-gram)程度がよく使用される．</section>
  <subsection title="品詞と可変長形態素列の複合N-gram">本論文では，形態素解析のための言語モデルとして，品詞と可変長形態素列の複合N-gramを使用することを提案する．品詞と可変長形態素列の複合N-gramは，品詞N-gramを基本としたN-gramであるが，品詞全体の性質とは異なった性質を呈する特殊な形態素はその品詞から分離させ独立して扱う．さらに，結合させることにより，言語モデルの精度を向上させる特定の形態素列は結合させた単位として扱う．従って，品詞と可変長形態素列の複合N-gramは，前節で示した品詞N-gramと可変長形態素列N-gramとのそれぞれの長所を生かしながら，それぞれの短所を補い合うことにより，少ないパラメータで高い予測精度が得ることを可能とした言語モデルである．N=2の場合，すなわちBigramを例にして，形態素N-gram，品詞N-gram，可変長形態素列N-gram，複合N-gramとの比較を図に示す．複合N-gramは，品詞クラス，形態素，形態素列を同時に扱うため複雑なモデルとなるが，本論文では，表現を簡単にするため，複合N-gramを次の３種類のクラス間のN-gramとして表現する．_FIG_FIGこのクラス分類を用いると，複合N-gramによる文の生成確率は，下式のクラスN-gramの形で与えることができる．但し，(ws_t)は文章を上記のクラス分類を用いた場合の，t番目の形態素列（単独の形態素も含める）を意味する．また，mは文章の形態素列の個数を表し，mmである．例として，次の文章（５形態素）を考える．「橋本」は出現頻度が高くないため．固有名詞クラスとして扱う方が適切であると考えられる．「わたくし」および「と」は日本語の文章で頻繁に出現する形態素であるため．品詞クラスより分離して単独で扱う．また，「言い-ます」は日本語で頻繁に用いられるフレーズであるため．結合させて一単位として扱う方が効果的であると考えられる．従って，この文章の生成確率は，次の式で与えられる．&amp;P(w_1^m)&amp;=P(わたくし|わたくし)P(わたくし)&amp;&amp;P(橋本|固有名詞)P(固有名詞|わたくし)&amp;&amp;P(と|と)P(と|固有名詞)&amp;&amp;P(言います|[言います])P([言います]|と)eqnarray*但し，([])はそれぞれ，クラスA)B)C)に属していることを表す．B)およびC)のクラスは，形態素（列）とクラスの出現頻度は等しいため((P(w_t)=P(c_t)))，上式は次のように変形することができ，複合N-gramと等価であることがわかる．&amp;P(w_1^m)&amp;=P(わたくし)&amp;&amp;P(橋本|固有名詞)P(固有名詞|わたくし)&amp;&amp;P(と|固有名詞)&amp;&amp;P(言います|と)eqnarray*</subsection>
  <subsection title="品詞N-gram・可変長形態素列N-gram">形態素N-gramのパラメータ数，すなわち形態素遷移の組合せはV^N（Vは語い）であり，Nを大きくするとパラメータ数が格段に多くなるため，それぞれの値の推定が困難になる．例えば，語いが10,000語の時，Trigramのパラメータ数は10,000^3=10^12(=1兆)となり，それぞれのパラメータを推定するためには，数兆語からなるテキストデータが必要となるが，これほどの大規模のデータを収集することは事実上不可能に近い．実際には，平滑化の手法を用いてデータ上に出現しない形態素遷移に対しても，確率を与えることができるが，その結果，実際には有り得ない形態素の遷移に対しても比較的高い確率を与える可能性がある．この問題を解決するため，品詞を単位としたN-gramが使用される場合がある．これは，形態素の代りに品詞間の遷移を考えることによりパラメータ数を削減し，推定量の信頼性を高めるものである．m形態素からなる文の生成確率は一般に下式で表される．（c_tはw_tの属する品詞を，c_x^yはx番目からy番目の形態素列に対応する品詞列を表す）上式で，P(c_t|c_t-N+1^t-1)は直前のN-1形態素列に対応する品詞列から次の形態素の属する品詞への遷移確率を表し，P(w_t|c_t)は，次品詞から次形態素が出現する確率を表す．品詞数を100とした時，Trigramの全ての品詞間の遷移の組は100^3=10^6(=100万)であるから，形態素N-gramに比べてパラメータ数は極めて少なく，比較的信頼できる遷移確率が求めることができる．しかし，品詞単位でのモデルでは，それぞれの形態素特有の接続関係を表現することができないため，言語モデルとしての性能は劣ると考えられる．また，N-gramの単位を結合させ部分的に長くする手法も提案されている．日本語の場合は特定の形態素列を結合させてN-gramの単位として扱い，固定長のN-gramと比較して，局所的にNを大きくさせる効果があり，パラメータ数の増大を抑えながら，より長い範囲の形態素間の関係を表現するものである．m形態素からなる文の生成確率は一般に下式で表される．但し，ws_tは文章のt番目の形態素列（単独の形態素も含める）を意味する．また，mは形態素列に分割した際の形態素列の個数を表し，mmである．可変長形態素列N-gramは，長い範囲の形態素間の連接関係を表現するのには有効であるが，パラメータ数が同じNの形態素N-gramより多くなり，少量の学習データから，信頼性の高いパラメータ推定を行うのは困難である．</subsection>
  <subsection title="複合N-gramの生成方法">より少ないパラメータで次形態素予測精度の高い効率的な複合N-gramを得るためには，初期クラスから独立させる形態素，および結合させる形態素列を適切に選択する必要がある．本論文では，品詞クラスを初期クラスとし，初期クラスからの形態素独立によるクラス分離，および形態素列結合によるクラス分離の２種類のクラス分離を逐次的に行うことによって，複合N-gramのためのクラス分類を決定する方法を提案する．形態素独立，および形態素列結合候補の決定は，式により求められるエントロピーを最小にさせる候補を１つのみ選択する．&amp;H&amp;(c_i)=-_iP(c_i)&amp;&amp;_kP(ws_k|c_j)P(c_j|c_i)_2P(ws_k|c_j)P(c_j|c_i)&amp;&amp;where~ws_kc_jeqnarrayエントロピーはあいまいさを表す尺度であり，また，エントロピーをHとしたときパープレキシティは2^Hで与えられる．すなわち，エントロピーが小さいことはあいまいさが小さく，また，次形態素予測の分岐も少なく，言語モデルの精度が高いことを意味する．従って，クラス分離を行う際に，常にエントロピーを最小にする候補を選択する本手法は，より少ないパラメータで精度の高い複合N-gramを生成するために適した手法であると考えられる．なお，本手法において，エントロピーの減少は常に正になることが保証されており，クラス分離によって，学習データに関してエントロピーは単調に減少する．</subsection>
  <section title="未知語を含んだ文の形態素解析">本論文では，未知語の形態素解析を行うために，品詞クラスc_に対して，同一品詞の未知語のためのクラスc_を導入する．クラスc_は，任意の文字を１次を出力するクラスであり，同一未知語クラスc_が連続した場合は，それらをまとめて一つの未知語とみなす．図に，いう未知語を含んだ文の品詞Bigramを使用した形態素解析の処理例を示す．以下に，c_に関する確率の導出を行う．_FIG_FIGTuring推定によると，データ上にr回出現する形態素は，次式のr^*回と推定される．ただし，n_rはデータ上にr回出現した形態素の種類数を表す．品詞からの出現確率P(w|c_)は，となる．これを，クラスc_に属する全ての形態素について計算し，1から引いた残りが品詞c_から未知語出現する確率P(c_)である．品詞c_の未知語の文字lの出現する確率P(l|c_)は，本来文字毎に与えられるべきであるが，固有名詞等では，学習データにも出現しない文字が出現する可能性もあり文字毎に正確な確率を与えるのは困難であるため，全ての文字が等しい確率で出現するとし，未知語出現確率P(c_)から均等に割り当てる．ただし，Vは文字の種類数とする．また，P(c_|c_)は，未知語が連続する確率である．本モデルにより生成される未知語の長さは二項分布に従うため，実際の未知語の長さも二項分布に従うという仮定を設けると，その品詞に属する語wの文字列len(w)よりP(c_|c_)は下式により求められる．</section>
  <section title="評価実験"/>
  <subsection title="各種N-gramモデルの形態素解析性能評価">自然発話旅行会話データベースを用いて形態素解析の評価実験を行った．本データベースには，間投詞や感動詞のほか，ら抜き表現，助詞落ち等の自然発話特有の言語現象が頻出する．また，本データベースは旅行会話という限定された内容の言語データであるが，実際のアプリケーションを想定した連続音声認識システムとしては，情報案内システム・予約システム等用途を限定し音声認識の精度を向上させている例が多く，このような内容の限定されたデータで評価を行うことは適切であると考えられる．データベースは，1,334対話，44,091文，559,711形態素から成り，語いは7,724語である．このうち，約４分の１(334対話,11,321文，137,691形態素)を評価用データとし，残り(1,000対話，32,770文，402,020形態素)を言語モデル学習に使用した．形態素解析精度の比較対象として，複合N-gramと形態素N-gram，および品詞N-gramを構築した．複合N-gramは，活用形，および活用型を含めた234品詞を初期状態とし，最大2,000クラスまで分離を行い，500分離おきにデータを採取した．また，形態素N-gram，品詞N-gram，複合N-gramともに，形態素および品詞クラスの遷移確率をback-offSmoothingにより学習データに出現しない形態素および品詞クラス遷移に対して0でない確率を与えた．また，本節の実験では，辞書には学習データ，評価データに出現する全ての形態素が登録されており，未知語は存在しない．ただし，学習データに出現しない形態素に対する遷移確率は，全てのモデルにおいて1/(100*語数)という確率を与えた．これは，他に候補が無い場合はこの形態素を割り当てるために，０でない小さい値を与えることを目的としている．形態素の正解率の評価には，音声認識で広く用いられている単語正解率(Accuracy)にならい形態素Accuracyを用いた．形態素Accuracy(%)は下式で表される．ただし，W:正解の形態素数，S:置換誤り形態素数，D:削除誤り形態素数，I:挿入誤り形態素数を表す．通常，形態素解析では，形態素の分割が正しく，かつ付与された品詞が正しければ，正解とみなされれる．この場合の形態素Accuracy(%)を表に示す．また，形態素解析結果を音声認識に用いることを考えると，同一品詞の形態素でも読みが異なるものは，別単位として扱うことが好ましい．形態素に読みまで考慮した場合のた場合の形態素Accuracy(%)を表に示す．ただし，読みの推定は，表記が同一の形態素でも読みが異なるものは別の形態素として扱い，異なる単位としてN-gramを構築し形態素解析を行うことにより実現している．表中で下線を付した値が，その次数の複合N-gramの最高の形態素正解率を示す．表およびより，いずれの評価の場合も，複合N-gramの最も高い形態素正解率は，同次数の形態素N-gramおよび品詞N-gramよりも高い正解率を得ることができ，複合N-gramの他のモデルに対する優位性が実験的に示された．形態素正解率最高の値を与える分離クラス数は，品詞のみの評価の場合は分離クラス数500，読みも含めた評価の場合は分離クラス1000であり，それ以上増やしても逆に形態素正解率は低下する傾向にある．これは，クラス数が増加すると共に，パラメータ数も増加するため，各パラメータの確率推定が正しく行われないことに起因すると考えられる．このため，適切なクラス数を決定する必要があるが，これは，ニューラルネットワークの学習回数の決定等で用いられるCrossValidationの手法を用いることにより，適切なクラス数を実験的に求めることができる．以下に手順を示す．学習データの一部を仮想的なテストデータとするクラス数を徐々に増加させながらN-gramを学習する仮想的なテストデータに対し形態素解析を行い，形態素解析の性能が頭打ちになる所をクラス数とする３種類のモデルを比較すると，品詞N-gramは読みを含めた評価の場合に他のモデルと比較して形態素正解率が著しく低下している．これは，ある形態素の読みはその前後の形態素の読みに影響されると考えられるが，品詞という枠組みでは，前後の読みの関係が表現できないためと考えられる．形態素N-gramと複合N-gramでは，読みまで含めた形態素を単位として扱うことができるため，このような大きな低下は見られない．また，複合N-gramと形態素N-gramとの正解率の差は大きくはないが，５章で示した未知語処理の容易さとを考えると，複合N-gramが有利である．また，山本らの手法では，タグなしコーパスから形態素ネットワークを生成する際に，ノイズを調整するための信頼性係数なるパラメータを変化させると，隠れマルコフモデルと品詞BigramおよびTrigramの形態素解析の精度は同等であると報告されている．しかし本実験の結果では，品詞Bigram，品詞Trigram，形態素Bigram，形態素Trigramの順に精度が向上しており，正解形態素列を学習させることにより，モデル化能力が形態素解析の正解率に反映されていると考えられる．また，複合N-gramは，複合Bigramでさえ隠れマルコフモデルよりもモデル化能力が高いとされる品詞Trigramよりも形態素の精度が高くなっている．従って，山本らの手法と比較し，正解形態素列を与えること，および複合N-gramを使用することにより，精度の高い形態素解析が可能であることが示せた．</subsection>
  <subsection title="学習データ量と形態素解析率との関係">前節の実験で，約40万語のデータより構築した複合N-gramモデルは，読みまで考慮した形態素解析率が98%以上の，高い解析率が得られることが分かった．しかし，40万語の形態素データを集めることはそれほど容易ではなく，連続音声認識に使用するN-gramを学習するための，大量の形態素データを容易に集めるという本研究の目的と矛盾する．従って，データ量が少ない時にどの程度の形態素解析率が得られるかは，本論文の趣旨において重要なことである．これを調査するため，前節の実験で用いたデータを量を1/2,1/4から最小1/64とした時の形態素正解率を調べた．言語モデルには，複合Bigramの分離クラス数500と1000を用い，形態素正解率は読みも含めた場合の形態素Accuracyで評価した．実験結果をに示す．表より，データ量が減少するに比例して，形態素正解率は低下することが分かる．しかし，データ量が全体の1/64の場合は，形態素数がわずか6,306であるが，このような非常に少ない量の学習データから構築したモデルでも，94%程度の比較的高い正解率が得られる．94%の形態素正解率は自動で形態素解析を行うには高い精度とは言えないが，自動形態素解析の結果を見て，人手で誤り個所を修正するような，半自動の形態素解析としては，使用に耐える性能であると考える．全学習データを使用した場合は，複合Bigramの分離クラス数1000の場合が分離クラス数500の場合よりも正解率が高いが，データ量が減少するにつれて，正解率は逆転している．これは，パラメータ数の多い分離クラス1000のモデルでは，データ量が少ない場合では，正確なパラメータ値を推定することが困難になることが原因であると考えられる．以上より，大量の形態素データを得るためには，まず，数千形態素程度のデータを人手で作成し，クラス数の少ない複合N-gramを構築して半自動の形態素解析を行い，数十万形態素程度のデータが集まった段階で，クラス数の大きい複合N-gramを構築し，その後は自動で形態素解析を行う，というのが効果的な手段であると考えられる．以下に，この作業に必要なコストについて検討した．まず，最初のN-gram学習用の形態素データを作成する必要があるが，これは，１形態素のデータ作成に１分あれば十分であるとして，6,000形態素のデータ作成にかかる時間は，１分×6,000＝6000分＝100時間である．これを基にして作成した複合N-gramで95%程度の正解率が得られるため，形態素解析したデータの修正には，1形態素あたりでは形態素データ作成時の1/20の3秒程度で可能であると考えられる．40万形態素のデータを作成するためには，40万×3秒＝120万秒＝2万分＝約333時間となる．一日８時間労働としても，２ヶ月程度で正解率98%以上の形態素解析システムの構築が可能であることになる．また，修正を行うだけなら比較的単純な作業であり，多数の人間で平行して行うことができるため，さらにシステム構築の期間を短縮することが可能である．なお，以上の議論では文章データ収集のためのコストを無視している．しかし，英語・日本語に限らず音声認識システムを構築するためには文章データを収集することは必須の作業であり，この部分のコストに関してし議論するのは無意味である．このため形態素解析の作業量のみを議論した．</subsection>
  <subsection title="ルールベースの形態素解析との比較">形態素解析システムJUMAN(Version3.5)との比較により，従来のルールベースの形態素解析に対する有効性を示す．ただし，我々の形態素解析とJUMANとでは，用いている形態素の体系や辞書に登録されている形態素の語数等が異なるため，できるだけ公平になるよう次のような方法で比較を行った．辞書サイズの均等化辞書サイズが，本論文の実験では約7千語であるのに対しJUMANでは約58万語あり，さらに，本論文の実験では評価データの全ての形態素が登録されている等，条件はJUMANが圧倒的に不利である．このため，名詞，動詞，形容詞等の自立語の語彙を我々のシステムと同一にした．ただし，「えー」「あのー」等の語は我々のシステムでは間投詞としているが，JUMANには間投詞という品詞は存在しないため感動詞とした．評価方法我々のシステムとJUMANとでは形態素の体系が異なり，評価データに対してJUMANの形態素体系の正解は存在しない．このため，提案方法よびJUMAN共に，形態素解析結果を目視して正誤の判定を行った．ただし，形態素の切り分けや品詞の判断は専門家でも困難な部分もあるため，明らかに誤りであると判断できる個所のみを誤りと判断している．また，評価データ約1万文を，目視により全て検査するのは時間を要するため，最初の200文のみを評価の対象とした．6.1節の実験で，最も正解率の高かった複合Trigram（クラス数1000）とJUMANに関し，形態素数と形態素解析の品詞付与および読み付与正解率とで比較した結果を表に示す．表より，形態素数はほぼ同じであり，両システムの形態素体系はは同程度の長さであることがわかる．形態素解析の精度に関しては，品詞付与で約4%，読み付与で約5%と本論文の提案手法の方が優れている．JUMANの誤り個所を調べると，大部分は感動詞と，数字の読みに関する誤りである．以下に代表例を示す．「たぶんえー大丈夫だと思います」→「たぶん(副詞)え(動詞)ー(記号)大丈夫だ(形容詞)と(助詞)思い(動詞)ます(接尾辞)」「九月十一日ご一泊」→「きゅうつきじゅういちにちごいちはく」これらの誤りの大部分は，接続ルールや重みを変更することで対応できると考えられる．しかし，そのためには，相当数のルールの追加・変更が必要になると考えられる．このような，修正を行うためには，試験的に形態素解析を行って形態素解析の誤り個所を見つけ，誤りの個所が修正でき，かつ正解個所の解析結果は変化しないように接続ルールや重みを変更する必要があると予想される．この作業を行うためにはルールの作成において相応の経験・知識を持つ人が，相当な時間をかける必要があると考えられる．これに対してN-gramでは，前節の実験でデータ量が増えるに比例して形態素解析率は向上していることから，形態素解析の誤り部分を修正するだけで形態素解析精度が向上でき，日本語において多少の文法的知識を持つ人なら容易に作業が可能であり，ルールベースの方法より精度の改善が容易であると考えられる．</subsection>
  <subsection title="未知語を含む文の形態素解析結果">次に，未知語を含む文の形態素解析実験を行った．学習・評価には，6.1節の実験と同一データを使用した．ただし，辞書には学習データに出現した形態素しか登録しておらず，評価データのみにしか出現しない形態素が未知語となる．このような未知語は632語存在し，評価データ中の137,691形態素中の859形態素(約0.6%)を占める．ただし，形態素N-gramは，この処理は行えないため，品詞N-gramと複合N-gramのみで比較実験を行った．ただし，処理時間の都合上，両モデル共にBigramのみを用いた．形態素解析の評価は，品詞付与の形態素Accuracy(%)のみで評価した．これは，現在の我々の形態素解析システムでは，未知語に対し読みを付与する機能がないためである．未知語に読みを付与するためには漢字毎の読みの情報があることが最低条件となるが，現在そのようなデータを持ちあわせていないことがその理由である．また，未知語，特に固有名詞の読みは人間でも間違う場合が多く，これを自動で行うのは技術的にも困難であると考えられる．表に結果を示す．未知語処理を行った場合でも，複合Bigramが品詞Bigramよりも高い正解率を得た．辞書に全語いが登録されている6.1節の実験では正解率が99.13%であったから，0.8%程度低下はしているものの，98%以上の比較的高い正解率が得られた．また，未知語の形態素解析誤りを分析したところ，「防音」が「防」と「音」のように，１形態素が複数の形態素に分割された例が多数見られた．これは，「音」という形態素が辞書に登録されているため「防」という文字のみが未知語として解析された結果生じた現象である．「防」も「音」も両方普通名詞であるから，これらの語を結合させることにより，誤りを低減することが可能であると考えられる．</subsection>
  <section title="むすび">本論文では，連続音声認識用のN-gram言語モデルを構築するのに必要な形態素データを大量に収集することを目的として，品詞と可変長形態素列の複合N-gramを用い，テキストデータから自動で形態素解析を行う方法を提案した．形態素解析実験の結果，最高99.17%の精度であり，読みまで考慮した結果でも最高98.68%の精度を得ることができた．これは，従来のルールベースの手法よりも高い精度であり，提案手法の有効性が示された．また，実験により，６千語程度の少ない学習データから学習したモデルでも94%程度の精度が得られることを確認した．さらに，品詞から未知語の出現確率を考えることにより未知語を含む文の形態素解析が行えるよう改良を行い，実験の結果，未知語が登録されている場合と比較して形態素解析精度の低下は0.8%程度であることを確認した．今後の課題としては，形態素解析に最適な複合N-gramの分離クラス数を自動決定することが重要と考える．また，未知語に関しては，同一品詞の未知語と既知語とを結合させ，新たな未知語と考えること等により形態素解析率を向上させ，さらに，音声認識に直接活用できるよう，未知語に対して読みを自動的に付与する手法の開発も行いたい．document</section>
</root>
