<?xml version="1.0" ?>
<root>
  <title>文字クラスモデルによる日本語単語分割</title>
  <author>小田裕樹森信介北研二</author>
  <jabstract>日本語処理において，単語の同定，すなわち文の単語分割は，最も基本的かつ重要な処理である．本論文では，日本語文字のクラス分類により得られた文字クラスモデルを用いる新しい単語分割手法を提案する．文字クラスモデルでは，推定すべきパラメータ数が文字モデルより少ないという大きな利点があり，文字モデルより頑健な推定を可能とする．したがって，文字クラスモデルを単語分割へ適用した場合，文字モデルよりもさらに頑健な未知語モデルとして機能することが期待できる．文字クラスタリングの基準はモデルの推定に用いるコーパスとは別に用意したコーパスのエントロピーであり，探索方法は貧欲アルゴリズムに基づいている．このため，局所的にではあるが最適な文字のクラス分類がクラスの数をあらかじめ決めることなく得られる．ATR対話データベースを用いて評価実験を行った結果，文字クラスモデルを用いた提案手法の単語分割精度は文字モデルによる精度より高く，特に，文字クラスを予測単位とする可変長n-gramクラスモデルではオープンテストにおいて再現率96.38%，適合率96.23%の高精度を達成した．</jabstract>
  <jkeywords>単語分割，未知語モデル，文字n-gramモデル，可変長n-gramモデル，文字クラスモデル，文字クラスタリング</jkeywords>
  <subsection title="文字 n-gram クラスモデル">n-gramモデルに，クラスという概念を導入したモデルをn-gramクラスモデル(n-gramclassmodel)と呼ぶ．ここで，クラスとはn-gramモデルの予測単位とする文字(あるいは単語)の集合を何らかの基準でクラスタリング(クラス分類)したものを指す．本節では，特に日本語漢字が表意文字であり，一文字が何らかの意味を担っていることから，類似した文字を自動的にグループ化することを考える．文字クラス数は文字数に比べると少ないものとなるので，文字n-gramモデルよりも文字n-gramクラスモデルの方が推定すべきパラメータ数が少ないという利点がある．また，文字クラスモデルは，文字クラスを用いた一種のスムージングであり，頑健なモデルを構築することが期待できる．このため，文字n-gramクラスモデルは，文字n-gramモデルよりも必要な学習データ量が少なく，たとえ小さな学習データからでも，より信頼性のある確率値を推定することが容易となる．文字n-gramクラスモデルでは，次の文字を直接予測するのではなく，先行する文字クラス列から次の文字クラスを予測した上で次の文字を予測する．ここで，文字が一つのクラスにしか属さないとすると，文字の生起確率は次の式で表すことができる．クラスC_iは，文字c_iの属する文字クラスである．また，確率P(c_i|C_i)は次式により最尤推定できる．ここで，N(c_i)は学習データ中で文字c_iが出現した回数であり，N(C_i)はクラスC_iの文字が出現した回数である．さらに，本論文では，未知文字を考慮するために，未知文字のクラスを考える．未知文字クラスには，学習データ中に出現しない未知文字と，頻度の小さい文字を含めることとする(未知文字の実例の収集)．未知文字cが未知文字クラスCから生起する確率P(c|C)は次式により計算することができる．ここで，Aは対象言語の文字集合であり，A_kは既知文字集合である．</subsection>
  <section title="はじめに">日本語や中国語等においては，単語間に空白を入れる習慣がないため，これらの言語の計算機処理では，まず文を単語列に分割する処理が必要となる．単語分割は日本語処理における最も基本的かつ重要な技術であり，精度・速度ともに高い水準の性能が要求される．単語分割と品詞付けから成る日本語形態素解析法の多くは，単語辞書の登録語との照合を行い，複数の形態素解析候補がある場合はヒューリスティクス(heuristics)を用いて候補間の順位付けを行うというものである．しかし，実際に，辞書中にすべての単語を網羅するのは不可能であるため，未知語(辞書未登録語)という重大な問題が生ずる．また，ヒューリスティクスでは扱うことのできない例外的な言語現象の存在や，例外現象に対処するための規則の複雑化が問題となる．その結果，一部の規則修正が全体に与える影響を人間が把握することが困難になり，規則の保守・管理に大きな労力を必要とすることとなる．一方，英語の品詞付けでは，タグ付きコーパスを用いた確率的手法が確立されている．言語表現の出現頻度に基づく確率的言語モデルを用いる方法には，対象領域のテキストからモデルのパラメータを学習する方法が存在するという大きな利点があり，タグ付きコーパスが整備されている領域では，実験的に最も高い精度が報告されている．英語の正書法は単語間で分かち書きするため，これらの手法は，単語モデル(word-basedmodel)を用いている．英語の品詞付けは，日本語の単語分割と技術的に似ているため，英語の品詞付け手法の多くは日本語の単語分割にも適用可能となる．しかし，単語モデルを日本語に適用するためには，いくつかの問題がある．日本語では，未知語の存在が単語の同定に影響を与える上，分割が曖昧で，異なる長さの多くの分割候補があり，それらの候補を比較する必要がある．このため，単語モデルを用いるためには，分割候補の確率を正規化する必要が生じる．以上の点から，我々は文字モデル(character-basedmodel)に基づく単語分割法を提案した．文字モデルは，未知語モデルとしても機能するために，学習データに含まれていない単語に対しても対応が可能である．本論文では，より頑健な単語分割モデルを構築するために，日本語文字のクラスタリング(グループ化)を行うことを考える．日本語漢字は表意文字であり，一文字が何らかの意味を担っている．したがって，何らかの基準によりいくつかのグループ(クラス)に分類することが可能である．文献で示されている文字モデルの利点に加え，文字クラスモデルでは，文字モデルよりもさらにモデルのパラメータ数を少なくすることができるという大きな利点がある．したがって，より頑健なモデルである文字クラスモデルを単語分割へ適用した場合，未知語に対する頑健性がさらに向上すると考えられる．文字とクラスの対応関係を得るためのクラスタリング処理には，クロス・バリデーション法(cross-validation)の適用により求められる平均クロス・エントロピーを言語モデルの評価基準としたクラスタリング法を用いる．平均クロス・エントロピーを評価基準として求められた単語bigramクラスモデルは，単語bigramモデルよりも予測力という点において優れていることが実験的に示されている．本論文では，この方法を日本語文字のクラスタリングに適用し，文字クラスモデルを構築する．以下，本論文では，文字クラスモデルに基づく新しい単語分割手法を提案する．まず，基本となる文字モデルに基づく単語分割モデルについて簡単に説明する．さらに，類似した文字を自動的にグループ化するクラス分類法について説明し，文字クラスモデルに基づいた単語分割モデルを提案する．ADD(ATRDialogueDatabase)コーパスを用いた評価実験において，文字モデルを用いた場合と，文字クラスモデルを用いた場合の単語分割精度を比較し，提案した手法の評価を行う．</section>
  <section title="文字モデルに基づく単語分割法">本節では，文字モデルに基づく単語分割法について説明する．まず，言語モデルとして，文字n-gramモデルを用いることを考える．文字n-gramモデルでは，言語の文字生起は，(n-1)重マルコフモデルで近似される．長さlの文字列c_1^l=c_1c_2c_lにおいて，直前の(n-1)文字のみが次の文字の生起確率に影響する．実際によく用いられるモデルは，n=2あるいはn=3のモデルであり，これらはbigramモデル，trigramモデルと呼ばれている．以下では，n=3の文字trigramモデルを用いることで，単語分割モデルの定式化を行う．単語分割モデルの学習データとしては，単語境界位置の付与されたデータを用いる．図に学習データの例を示す．記号dは単語境界(単語間のスペース)を表す特殊記号であり，sと/sはそれぞれ文頭と文末を表す特殊記号である．単語境界位置の付与された学習データから文字trigramモデルの確率値を推定し，これを用いて単語分割を行う．与えられた「ベタ書き」文を単語列に分割するためには，入力文中の各文字位置に対し，その文字の前で単語分割が起こるか否かを求めればよい．このために，それぞれの文字位置に対し，2つの状態1と0を仮定する．状態1はその文字の前が単語境界となることを表す状態であり，状態0は単語境界とならないことを表す状態である．文字位置i(2)の状態の推定は次式で与えられる．なお，P_j(c_1^i)は文字列c_1^i=c_1c_2c_iを生成して状態jに到達する確率を表す．P_0(c_1^i)=(P_0(c_1^i-1)A_i,~	P_1(c_1^i-1)B_i)	P_1(c_1^i)=(P_0(c_1^i-1)C_i,~	P_1(c_1^i-1)D_i)	[3pt]&amp;&amp;A_i=p(c_i|c_i-2c_i-1)&amp;&amp;B_i=p(c_i|dc_i-1)&amp;&amp;C_i=p(d|c_i-2c_i-1)p(c_i|c_i-1d)&amp;&amp;D_i=p(d|dc_i-1)p(c_i|c_i-1d)eqnarrayまた，文字位置i=1の場合は，次式で求めることができる．P_0(c_1)&amp;=&amp;p(c_1|s)_1(c_1)&amp;=&amp;0eqnarrayここで，学習データ中の文字位置1の前には単語境界記号がないため，式()を定義する．入力文s=c_1^mに対する最適な単語分割は，各文字位置に対する状態1と0の最適な状態遷移系列として与えられる．単語分割モデルの計算のため，実際の入力文には，文頭記号と文末記号を各々0番目とm+1番目の文字として加えて処理を行う．学習データ中の文末記号/sの前には単語境界dがないので，最適な状態遷移系列はとなるような状態遷移系列である．これを求めるためには，動的計画法の一種であるビタビ・アルゴリズム(Viterbialgorithm)を用いることができる(図参照)．求められた最尤状態遷移系列において，状態1である文字位置の前で単語分割を行う．図において単語境界を点線で示す．文字trigramモデルを言語モデルとして用いた場合，以上の単語分割モデルにより，入力文に対して最適な単語分割を求めることができる．また，同様の考えに基づいて可変長n-gramモデル(variable-lengthn-grammodel)を用いた単語分割を行うことも可能である．その場合は，解探索における単語分割候補の指数的増加を避けるために，各文字位置において確率の高い候補のみを後続する文字位置での探索に用いるようにする．もし文字trigramモデルによる単語分割モデルと同様に，文字位置iの直前が単語境界である(状態1)か否(状態0)かの2つの仮定に対する各々の最尤解のみに関して解探索を行うならば，その探索空間は，図に示す探索空間と同じとなる．</section>
  <section title="日本語文字のクラスタリング"/>
  <subsection title="文字クラスタリング法">クラス分類法には様々なものが提案されている．優れた文字クラスモデルを獲得するためには，モデルの予測力を向上させる(すなわちクロス・エントロピーの値を小さくする)文字とクラスの対応関係を発見する必要がある．しかし，クラスタリングに関する多くの先行研究では，確率値の推定に用いる学習データのエントロピーの値を評価基準とすることでクラスタリングの優劣を判定している．学習データのエントロピーを小さく(学習データを高い精度で予測)することを目的とするのであれば，モデルのパラメータ数は多いほど良いこととなる．したがって，学習データのエントロピーを評価基準としてクラスタリングの解探索を行う限り，どのような文字の組合せに対しても複数の文字を同一視することで必ず情報の損失が生じるため，文字モデルよりもエントロピーの値が小さい文字クラスモデルは解空間に存在しないこととなる．以上のように，学習データのエントロピーは，クラスタリングの評価基準としては不適切なものであり，得られた文字クラスモデルが文字モデルより優れた言語モデルであることが期待できないという重大な問題が生じる．実際，文献の手法では，停止基準として人間が決定する閾値(クラス数)を導入し，閾値までパラメータ数を減少させた場合における最も良い(情報の損失の少ない)解を求めているが，得られたモデルの予測力は低下していることが報告されている．そもそも言語モデルの評価は確率の推定に用いない未知の評価データに対する予測力によって決められる．したがって，理想的には，対象言語の未知のデータに対してクロス・エントロピーを小さくするように文字をグループ化することが望ましい．以上の点から，文献では，学習データ内の一部を未知の評価データとして扱い，その評価データのクロス・エントロピーが小さくなるようにクラス分類を行うアルゴリズムを提案している．このクラス分類法には，停止基準を評価基準から導き出せるという利点があり，人間の判断に委ねられる停止基準(閾値)を必要としない(詳細に関しては後述する)．実際に，得られた単語bigramクラスモデルは単語bigramモデルよりも優れた性能を示すことが実験的に報告されている．そこで，本論文では日本語文字のクラスタリングに文献の手法を適用することを考える．</subsection>
  <subsubsection title="クラスタリングの評価基準">クラスタリングの評価基準として用いる平均クロス・エントロピーについて説明する．ここで，言語モデルの性能尺度であるクロス・エントロピーHは以下の式で定義される．ここで，Mは言語モデル，s_iは評価データT中のi番目の文である．|s_i|は文s_iを構成する文字の数とする．このとき，文区切りを考慮するために，s_iは文末記号までを含むと仮定する．学習データ内に未知の評価用データを用意して，その評価データによりクラス分類の性能を評価する．これを実現するために，削除補間(deletedinterpolation)のようにクロス・バリデーション法(cross-validation)あるいは交差検定法と呼ばれる技術を用いる．クロス・バリデーション法とは，データの役割を交替しながら繰り返し学習および評価を行う方法のことを指す．学習データLをm個の部分データL_1,L_2,,L_mに分割する．各部分データ(i=1,2,,m)に対し，ステップ3,4を行う．学習データからL_iを削除し，残りのm-1個のデータから確率値を推定する．削除されたデータL_iで，式()によりクロス・エントロピーの値を計算する．以上のようにして，m個のクロス・エントロピーの値を得ることができるので，それらの値の平均値H(平均クロス・エントロピー)を全体の評価関数とする．ここで，M_iはステップ3でL_iを削除した残りのデータから推定されたモデルである．平均クロス・エントロピーHは確率推定に用いないデータにおけるクロス・エントロピーの平均値であるため，文字とクラスの対応関係を変更していくつかの文字を同一視するようにした場合，同一視しなかった場合に比べてHの値が増加することもあれば減少することもあるという振舞をみせる．したがって，クラスタリングの解探索はHが減少する場合のみクラスの変更を施せば良いという極めて自然なものとなる．以上のHの値を最小とする文字とクラスの対応関係を求めることが，本論文の文字クラスタリングの最終目的となり，クラスの併合過程においてどのような併合もHを減少させることができない状態に到達することがアルゴリズムの停止条件となる．</subsubsection>
  <subsubsection title="クラスタリング・アルゴリズム">文字クラスモデルを構築するためには，文字クラスタリングにより文字とクラスの対応関係を求めることが必要となる．文字とクラスの対応関係としては，ある文字が一定の確率で複数のクラスに属するという確率的な関係も考えられるが，解空間が広大になるので，本論文では，文字は一つのクラスのにみ属することを仮定する．以下では，文字とクラスの対応関係を返すクラス関数fを用いて説明する．たとえば，文字c_1の属するクラスとして，f(c_1)=c_1,c_2,c_3を返す．このとき，文字c_2,c_3に対するクラス関数fも，各々の文字が属するクラスとして同じく文字集合c_1,c_2,c_3を返すこととなる．ここで，クラスタリング対象文字の集合をA_kとすると，A_k中のすべての文字のクラス関数fの和集合はA_kとなり，A_kと未知文字クラスの和集合が対象言語の文字集合Aとなる．さらに，文字のクラス分類に対する解探索を行うために，文字とクラスの対応関係の変更を表す関数moveを定義する．移動関数moveは，文字とクラスの関係fに対して，文字cをクラスCに移動した結果得られる文字とクラスの関係を返す．文字は唯一のクラスに属するとしているので，move(f,c,C)は，現在，文字cが属するクラスf(c)から，集合の要素cを取り除き，クラスCに要素cを加えることを意味する．文字クラス分類の最適解を求めるためには，あらゆる可能な文字とクラスの対応関係を調べる必要がある．クラス分けの総数は有限であるので，理論的には総当たり戦略により最適なクラスを見つけることはできる．しかし，総当たり法は非現実的であるため，準最適なアルゴリズムを用いることとなる．文献のアルゴリズムを以下に示す．文字クラスの学習アルゴリズム文字集合A_k中の文字を頻度の降順にソートし，c_1,c_2,,c_nとするforeachi(1,2,,n)*2ex=C_i:=c_i&gt;f(c_i):=C_iforeachi(2,3,,n)+C:=argmin_CC_1,C_2,...,C_i-1H(move(f,c_i,C))if(H(move(f,c_i,C))&lt;H(f))thenf:=move(f,c_i,C)-tabbing上記アルゴリズムはボトムアップ型の探索を行っており，初期状態において，各文字を各々一つのクラスとみなしている．後は，頻度の高い文字の順に他のクラスへの文字の移動を仮定して，平均クロス・エントロピーの値を再計算している．このとき，平均クロス・エントロピーが減少する文字とクラスの新しい対応関係が発見できれば，クラス関数fを変更する．頻度の高い文字から処理を行う理由は，頻繁に出現する文字ほどクロス・エントロピーに与える影響が大きいと考えられるので，早い段階での移動が後の移動によって影響されにくく，収束がより速くなると考えられるからである．クラスタリングの処理の例を図に示す．</subsubsection>
  <section title="文字クラスモデルに基づく単語分割法">文字クラスモデルを言語モデルとして，単語分割を行う．ここで，節の文字クラスタリング法では，文字と文字クラスの関係が一意に定まることを考えると，一文を構成する文字列c_1^mがそのまま文字クラス列C_1^mに変換できることが分かる．単語分割モデルでは，入力文の各文字間において単語境界の有無を仮定して文の生成確率を計算・比較する．ここで，式()および式()から分かるように，確率p(c_i|C_i)は単語境界の有無には影響を受けない値である．さらに，一文を構成する文字は不変であるので，_i=1^mp(c_i|C_i)はどのような分割候補の確率を求める場合でも一定の値の項となる(式()参照)．したがって，文字trigramクラスモデルによる単語分割モデルでは，以下のようにクラス連鎖の確率のみを用いて簡単に計算することができる．P_0(c_1^i)=(P_0(c_1^i-1)A_i,~	P_1(c_1^i-1)B_i)	P_1(c_1^i)=(P_0(c_1^i-1)C_i,~	P_1(c_1^i-1)D_i)	[3pt]&amp;&amp;A_i=p(C_i|C_i-2C_i-1)&amp;&amp;B_i=p(C_i|dC_i-1)&amp;&amp;C_i=p(d|C_i-2C_i-1)p(C_i|C_i-1d)&amp;&amp;D_i=p(d|dC_i-1)p(C_i|C_i-1d)eqnarrayまた，文字位置i=1の場合は，次式で求めることができる．P_0(c_1)&amp;=&amp;p(C_1|s)	_1(c_1)&amp;=&amp;0	eqnarray上記の単語分割モデルをみれば分かるように，文字クラスモデルを用いた場合は，文字クラスの連鎖により単語境界を予測するという問題に置き換わる．文字trigramクラスモデルを用いた場合も，P_0(c_1^m+1)となる状態遷移系列をビタビ・アルゴリズムを用いて求めることで，入力文に対する最適な単語分割を得ることができる(図参照)．また，可変長n-gramクラスモデルを用いる場合でも，同様に，クラス連鎖における単語境界の出現の有無により確率比較を行い，解探索を行うこととなる．</section>
  <section title="評価実験">以上で提案した手法を評価するために，ATR対話データベースを用いた評価実験を行った．それぞれのデータの文数，単語数，文字数を表に示す．</section>
  <subsection title="文字クラスモデルのクロス・エントロピー評価">前節の単語分割モデルで用いる文字クラスモデルを作成する．したがって，文字trigramクラスモデルや可変長n-gramクラスモデルの予測力を改善するような文字クラスを求める必要がある．しかし，文字クラスタリング・アルゴリズムの評価基準である平均クロス・エントロピーの計算を考えると，高次のモデルでは，必要な記憶容量と計算時間が大きな問題となる．そこで，本実験では，クロス・エントロピーの計算は，低次のbigram確率によって計算した．bigramモデルであれば，高速なクラスタリング処理が可能である．もし日本語における文字分類の最適解に近い解を得ることができれば，得られたクラス関数fはどのような次数のモデルに対してもある程度有効であると考えられる．また，本論文では，日本語文字が明らかに字種によって分類できることから，クラスタリング処理において，字種により規制を設けることを考えた．たとえば，漢字は漢字同士でグループ化するというように考えることで，文字とクラスの対応関係の変更を考える場合に必要な計算量を少なくすることができる．これにより，漢字の場合はmove関数の移動先クラスとして漢字のクラスのみを考えることとなり，ひらがなの場合はひらがなのクラスのみとなる．以上の条件により，文字クラスタリングを行うために，学習データを9個のデータL_1,L_2,,L_9に分割した．ここで，1個のデータにしか出現しない文字は未知文字とし，字種ごとに未知文字クラスを用意した．これは，クロス・バリデーション法による平均クロス・エントロピーの計算(9回の評価)において未知文字であった文字をそのまま学習データ全体における未知文字の実例の収集に用いることを意味する．したがって，クラスタリングの対象となる文字は，2個以上のデータに出現する文字となる．また，単語分割に用いる言語モデルを獲得することを念頭におくため，単語間に単語境界記号を挿入した分かち書きデータを用いた．単語境界記号自体はクラスタリングの対象ではないが，その存在により，クロス・エントロピー評価では単語境界(単語間のスペース)まで考慮するようになる．本実験において，評価データ中の未知文字(クラスタリング対象文字以外)は字種ごとに異なる特別な記号に置き換えてクロス・エントロピーの計算を行った．未知文字の扱いは文字モデルと文字クラスモデルで共通であるので，未知文字の確率はモデルの比較においては問題とならない．重要なことは，クラスタリング対象文字のグループ化によって，モデルの予測力がどのように変化するかである．以上の点から，モデルの状態は，既知文字すべて(もしくは文字クラスすべて)，未知文字クラス(字種ごと)，単語境界，文区切りの各々に対応することとなる．実験により得られた，文字bigramモデルと文字bigramクラスモデルのクロス・エントロピーを表に示す．本実験において，文字クラスモデルのクロス・エントロピーは文字モデルのものよりも小さく，より予測力の高い言語モデルの獲得に成功している．また，表に，クラスタリング対象文字数とそれらをクラスタリングした後の文字クラス数を示す．学習データ中には，1357種類の文字が含まれていたが，約200種類の低頻度文字が未知文字として取り扱われた．実験の結果，クラス当たりの平均要素(文字)数は1.36文字であり，最大のクラスの所属文字数は12文字であった．文字クラスタリング実験により得られたクラス関数fが返す文字集合(文字クラス)を，図にいくつか示す．必ずしもすべての文字クラスが言語直観から納得がいくものではないが，いくつかのノイズと思われる文字を除けば，(特に出現位置の類似という点で)ある程度良い解が得られていることが分かる．不自然な印象を受ける文字のグループが存在するのは，あくまでbigramクラスモデルの改善における準最適解を求めているからであると考えられる．本実験では，各文字クラスに属する文字数は少なく，文字クラスタリングによって，それほど極端にパラメータ数が減少するということにはならなかった．この原因は，今回用いたコーパスの規模が小さく，学習データに含まれる文字の種類が少なかったためであると考えられる．より多くの文字種をクラスタリングの対象とすれば，モデルのパラメータ数の減少度はさらに大きくなるであろう．</subsection>
  <subsection title="単語分割精度の比較評価">文字クラスタリング実験により得られたクラス関数fを用いることで，文字trigramクラスモデルや可変長n-gramクラスモデルを構築することができる．ここで，文字クラスタリングでは字種別にグループ化を行ったので，単語分割に用いる文字クラスモデルを作成するときに，クラス関数fを用いる字種を限定してみることについても試みることとした．もしあまり有効でない文字のグループ化が行われている字種があれば，それらの文字はクラス関数fを用いず，文字を予測単位として処理すれば，より性能の良いモデルが得られる可能性がある．また，本論文で提案した文字クラスモデルに基づく単語分割モデルは非常に簡単な構造となっており，いかにクラス連鎖により単語境界の生起を把握するかが単語分割精度の鍵となる．ここで，字種変化によるヒューリスティクスを考慮した場合，カタカナ，数字，英字はその字種同士の文字間では分かち書きされる可能性がほとんどないと考えられる．単語分割を行う場合，これらの文字は単にカタカナか数字か英字であるという情報のみでモデル化したほうが良い結果が得られる可能性がある．そこで，それらの字種に関しては字種全体を一つのクラスとみなして同一視することについても検討することとした．以上の点から，文字クラスモデルと文字モデルの比較において，表の5つのモデルを考え，単語分割実験を行った．表中には，字種ごとに何を予測単位としてモデル化を行うかを示している．モデル1は文字モデルであり，モデル2は文字クラスタリングの結果に何も手を加えずに，すべての文字でクラス関数fを用いた文字クラスモデルである．モデル3,4,5は字種クラス(字種全体を一つのクラスとする)を予測単位とすることを試みたモデルであり，それらの中のモデル4とモデル5では文字クラスタリングの結果得られるクラス関数fを用いる文字を限定している．表に，文字trigramモデルと文字trigramクラスモデルに基づく単語分割モデルによる単語分割精度を示す．単語分割の性能は，再現率(recall)と適合率(precision)により評価する．ここで，Stdをコーパス中の単語数，Sysを本手法で分割された単語数，Mを照合した単語数とすると，再現率はM/Std，適合率はM/Sysで表される．本実験では，バックオフ・スムージング付きのtrigram確率値を計算した．表のモデル1とモデル2は文字trigramモデルと文字trigramクラスモデルの精度であるが，オープンテストにおいて文字クラスモデルの精度が上回る結果となっている．また，モデル1とモデル3およびモデル2とモデル4のオープンテストの結果を比較することで，カタカナ，数字，英字を各々一つのクラスとしたほうが未知語を含むデータに対して，精度が向上していることが分かる．したがって，字種単位でのグループ化の有効な字種の存在が確認できた．全体として，オープンテストでは，漢字に関して文字クラスを用いたモデル5の場合が最も高精度であった．本実験結果より，文字クラスタリングの動機であった漢字のクラスタリングには特に良い解が得られていることが分かる．また，可変長n-gramモデルと可変長n-gramクラスモデルの比較に関する単語分割実験も行ったが，trigram同様，クラスモデルの方が高精度であった．本実験において，可変長n-gramクラスモデルによる探索空間はtrigramによる場合と同じものとした．文献において，trigramモデルによる探索空間と同じ場合に最も高い精度を達成している可変長n-gramモデルを用いた場合の結果を表に示す．実験結果から，可変長n-gramクラスモデルはtrigramクラスモデルよりもさらに高い単語分割精度を達成できることが分かる．学習データと評価データの組を変更して，可変長n-gramクラスモデルによる単語分割の再評価を行ったところ，オープンテストで96%〜98%以上のかなりの高精度を達成することを確認した．パラメータ数の少ない文字クラスモデルでは，本論文で用いたような比較的小規模の学習データからでも信頼のおける確率値を得ることが容易となり，有効な未知語モデルとして機能できることが結論できる．</subsection>
  <section title="おわりに">本論文では，日本語のような単語間で分かち書きをしない言語のための新しい単語分割モデルを提案した．入力文に対して最適な単語分割を見つけるために，本手法は文字クラスモデルを言語モデルとして用いる．ADDコーパスを用いた評価実験で，クロス・エントロピー評価によるクロス・バリデーション法を適用した文字クラスタリングを行い，モデルのパラメータ数を減少させた上で，優れた予測力を持つ頑健な文字クラスモデルを獲得できることを示した．また，提案した単語分割モデルにおいて，文字モデルを用いた場合と，文字クラスモデルを用いた場合の単語分割精度の比較を行い，文字クラスモデルによる単語分割モデルの方が未知語を含むデータに対する解析力が優れていることを示した．今後は，文字クラスモデルの有効性をさらに確認するために，高次のクラスモデルの性能を直接改善するようなクラスタリング実験を行うことを考えている．また，より多くの文字種を含む大規模コーパスでの文字クラスモデルのクロス・エントロピーおよびパラメータ数の減少度を計測し，その有効性を確認することを予定している．document</section>
</root>
