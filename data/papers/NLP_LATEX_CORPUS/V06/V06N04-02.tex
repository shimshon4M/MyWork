



\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{23}
\setcounter{巻数}{6}
\setcounter{号数}{4}
\setcounter{年}{1999}
\setcounter{月}{7}
\受付{1997}{10}{2}
\再受付{1998}{1}{27}
\採録{1998}{12}{24}

\setcounter{secnumdepth}{2}

\title{音声対話システムのための対話の認知プロセスモデル}
\author{荒木 雅弘 \affiref{media} \and 堂下 修司 \affiref{kuis}}

\headauthor{荒木, 堂下}
\headtitle{音声対話システムのための対話の認知プロセスモデル}

\affilabel{media}{京都大学 総合情報メディアセンター}
{Center for Information and Multimedia Studies, Kyoto University}
\affilabel{kuis}{京都大学大学院 情報学研究科 知能情報学専攻}
{Dept. of Intelligence Science and Technology,
Graduate School of Informatics, Kyoto University}

\jabstract{本稿では，音声を用いて人間と機械が対話をする際の対話過程を，
認知プロセスとしてとらえたモデルを提案する．対話システムをインタラクティ
ブに動作させるためには，発話理解から応答生成までを段階的に管理する発話
理解・生成機構と，発話列をセグメント化し，焦点および意図と関連付けて構
造的にとらえる対話管理機構とが必要である．さらに，入力に音声を用いた音
声対話システムでは，音声の誤認識によるエラーを扱う機構を組み込む必要が
ある．本稿で提案するモデルは，発話理解・生成機構における各段階での処理
を具体化し，それらと対話管理機構とのやりとりを規定することによる統合的
な認知プロセスモデルとなっている．それらの処理の中に，音声の誤認識によっ
て生じ得るエラーを具体的に記述し，その対処法を網羅的に記述している．こ
のモデルを実装することによって，ある程度のエラーにも対処できる協調的な
音声対話システムの実現が期待できる．}

\jkeywords{音声対話，対話モデル，認知プロセス，プラン認識}

\etitle{Cognitive Process Modeling of Dialogue\\
for Spoken Dialogue Systems}
\eauthor{Masahiro Araki \affiref{media} \and Shuji Doshita \affiref{kuis}} 

\eabstract{ In this paper, we propose a cognitive process model of
spoken dialogue. In order to make an interactive dialogue system, we
need two management processes: one is an understanding process which
manages the subprocess of utterance understanding through response
generation; the other is a dialogue management process which
aggregates the utterances to the discourse segment and manages focus
and intentions of dialogue. Furthermore, in applying the model to
spoken dialogue systems, we have to deal with misunderstandings caused
by speech recognition errors. Our model specifies the cognitive
process of whole dialogue understanding process and stipulates the
interaction between understanding process and dialogue management
process. We also specify the recovering method from communication
errors into this cognitive process.  Therefore, our model is suitable
for implementing cooperative spoken dialogue systems.  }

\ekeywords{Spoken Dialogue, Dialogue Modeling, Cognitive Process, Plan 
Recognition}

\begin{document}
\maketitle


\section{まえがき}

本稿では，音声を用いて人間と機械が対話をする際の対話過程を，認知プロセ
スとしてとらえたモデルを提案する．対話システムをインタラクティブに動作
させるためには，発話理解から応答生成までを段階的に管理する{\dg 発話理
解・生成機構}と，発話列をセグメント化し，焦点および意図と関連付けて構
造的にとらえる{\dg 対話管理機構}とが必要である．さらに，入力に音声を用
いた音声対話システムでは，音声の誤認識によるエラーを扱う機構を組み込む
必要がある．これらの機構は従来，比較的独立して研究されてきた．

発話理解から応答生成までを通してモデル化したものに関しては，大きく分類
して並列マルチエージェント(およびそれに付随する分散データベース)による
モデル\cite{peckham91}と，逐次的なモジュールの結合によるモデル
\cite{jonsson91}, \cite{airenti93}とが提案されている．並列マルチエージェ
ントモデルは様々なレベルの制約を同時に発話理解・生成に用いているという
人間の認知プロセスのモデル化になっているが，制御の難しさ・確実な動作保
証の難しさから，対話システムの実現には逐次的なモジュール結合方式がよく
用いられている．

逐次的なモジュール結合方式において，音声対話システムに不可欠な発話の柔
軟な解釈や次発話の予測を行うためには，個々のモジュールが常に参照できる
情報を集中的に管理する対話管理機構が必要になる．対話管理機構に関して，
Groszらは言語構造・意図構造・注意状態の3要素に分割してモデル化を行って
いる\cite{grosz86}．

言語構造をとらえる方法としては，スタックによるモデル化\cite{grosz86},
\cite{allen96}, \cite{jonsson91}\footnote{\cite{jonsson91}ではやりとり
(働き掛け＋応答)単位を対話木によって管理しているが，この対話木は働き掛
け＋応答の2分木の中にあらたなやりとりが挿入できるという形式なので，本
質的にはスタックと同機能であると考えられる．}とAND-OR木によるモデル化
\cite{young89}, \cite{smith94}, \cite{smith95}がある．スタックによるモ
デル化は実現しやすく，注意状態との関係が明確であるという利点を持つ．し
かし，入れ子構造をなさないような副対話が生じた場合にその管理が難しい．
また，ユーザから主導権を取る発話(典型的にはユーザの誤った知識・方略を
協調的に修正する発話)を生成した場合には，いくつかのスタック要素のポッ
プを伴うことが多く，ユーザが主導権を改めて取ろうとしたときに必要な情報
がスタックから消えているという状況が生じる．また，原則としてスタックか
らポップした情報にはアクセスできないので，音声の誤認識による誤解を(し
ばらく対話が進んだ後で)修正する必要のある音声対話システムに用いるには
適していない．一方，AND-OR木によるモデル化は，基本的にタスクの問題構造
の記述であり，Groszらの言語構造と意図構造とを混同してしまっているので，
タスクの問題構造に従わない対話(例えば詳細化対話やシステムの能力に関す
るメタ的な質問など)は特別に扱わなければならないという欠点を持つ．これ
らのことを考え合わせると，音声対話に適した対話管理は，焦点とする範囲を
適当に絞りながらも過去の対話履歴にアクセスする可能性を残した方法を用い
て，言語構造と意図構造を区別して管理する必要があるといえる．
\cite{airenti93}では言語構造と意図構造とを区別してモデル化し，これらを
会話ゲームと行動ゲームと呼んでいる．しかし，それぞれのゲームがどのよう
に表現されるかについては部分的にしか示されておらず，音声対話システムを
構成するには不十分であるといえる．

さらに，音声対話システムに適用する対話モデルには，音声の誤認識によるエ
ラーに対処する機能が不可欠である．従来研究の多くは発話単位でのロバスト
な解析を実現することに目標が置かれ\cite{kawa95}，いくつかの例外を除い
ては，対話システムに入力される発話または意味表現はユーザの意図したもの
であることが前提になっていた．しかし，ある単語が同一カテゴリーの単語と
置き換わった場合や選択格に関する情報が欠落していた場合などは，ロバスト
な解析では対処できないので，対話レベルでの対処が必要となる．

以上の議論より，我々は音声対話システムのための対話モデルとして，逐次的
なモジュール結合による発話理解・生成機構，言語構造と意図構造とを区別し
た対話管理機構，それら相互の密接な情報のやりとりによる頑健な処理の実現
が必要であると考えた．

本稿で提案するモデルは，(1)\cite{airenti93}で提案された伝達行為理解の
プロセスモデルを音声対話システムに適用可能なレベルまで具体化し，(2)そ
れらと言語構造を表現した会話空間，意図構造を表現した問題解決空間とのや
りとりを規定し，(3)個々のプロセスで同定可能な誤りへの対処法を網羅的に
記述したものである．このモデルを実装することによって，ある程度のエラー
にも対処できる協調的な音声対話システムの実現が期待できる．以後本稿では，
我々のモデルに関して発話理解・生成機構，会話レベルの管理機構，問題解決
レベルの管理機構について順に説明し，最後に動作例を示す．

\section{対話処理の認知プロセスモデル}

本章ではまず，我々のモデルのベースとなっているAirentiらの伝達行為理解
のモデルについて概観した後，我々のモデルで拡張を行った点を中心に各段階
での処理について説明する．

\subsection{Airentiらの伝達行為理解のモデル}

対話における認知プロセスのモデル化では，相手の発話を聞いてから自分の発
話を生成するまでに，どのようなプロセスによって，どのような信念の変化が
起こっているのかをとらえる必要がある．Airentiらは，この認知プロセスを
会話ゲームと行動ゲームという2つのゲームによってモデル化し，主に伝達行
為を理解するという側面においての分析を行っている\cite{airenti93}．

会話ゲームは(1)意味理解，(2)意図理解，(3)伝達効果，(4)意図生成，(5)応
答生成の5段階に分れており，各段階の処理における目標とするタスクの集合
および処理の流れを決めるメタルールからなっている．図\ref{airenti}に
Airentiらの提案した会話ゲームを示す．ここで用いる述語の定義を付録
\ref{appendixA}に示す．これらのプロセスは標準的な処理では(1)から(5)ま
でが順に行われ，いずれかの段階でタスクが達成できなかった場合は，即座に
応答生成に行く．

\begin{figure}[htbp]
\small
\begin{enumerate}
\item {\dg 意味理解}

\noindent
{\bf if} $\mbox{SH}_{yx}\mbox{DO}_x \mbox{express(y, s)}
\lor \mbox{SH}_{yx}\mbox{DO}_{xy} G(x,y)$
{\bf then goto} 意図理解;
{\bf else goto} 応答生成

\item {\dg 意図理解}

\noindent
{\bf if} $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
\mbox{DO}_{xy} G(y,x)$
{\bf then goto} 心的状態の更新;
{\bf else goto} 応答生成

\item {\dg 心的状態の更新}

\noindent
{\bf if} $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_{xy} G(y,x)$
{\bf then} $\mbox{INT}_y \mbox{DO}_{yx} G(y,x)$;\\
{\bf if}   $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_y e$
{\bf then}   $\mbox{INT}_y \mbox{DO}_y e$;\\
{\bf if}   $\mbox{SH}_{yx}\mbox{CINT}_{xy} p$
{\bf then}   $\mbox{BEL}_y p$;\\
{\bf goto}   意図生成

\item {\dg 意図生成}

\noindent
{\bf if} $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_{xy} G(y,x)$
{\bf then}  $\mbox{CINT}_{yx} \mbox{INT}_y 
\mbox{DO}_{yx} G(y,x)$;\\
{\bf if}  $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_y e$
{\bf then}  $\mbox{CINT}_{yx} \mbox{INT}_y e \lor
\mbox{CINT}_{yx} \lnot \mbox{INT}_y e$;\\
{\bf if}  $\mbox{SH}_{yx}\mbox{CINT}_{xy} p$
{\bf then}  $\mbox{CINT}_{yx} \mbox{BEL}_y p
\lor \mbox{CINT}_{yx} \lnot \mbox{BEL}_y p$;\\
{\bf goto} 応答生成

\item {\dg 応答生成}

\noindent
{\it not specified}

\end{enumerate}
\caption{Airentiらの会話ゲーム (\cite{airenti93}より抜粋したものを整理)}
\label{airenti}
\end{figure}

会話ゲームは，基本的に理解から生成に至るまでの1ターンを説明するために
用いられたもので，対話全体を管理できるほどには具体化されていない．また，
会話ゲームを対話全体が扱える程度に拡張しようとすると，明確化対話の挿入
や応答の省略などの現象を会話ゲームの規則として記述せねばならず，規則の
組合わせが手に負えないほどの量になってしまうことが予測される．

一方，行動ゲームは妥当性条件と参加者の行為の集合からなるとされている
(図\ref{airenti2})．しかし，どのような知識表現を用いるか，どのような推
論ができるのかが明確にされていないため，意味理解段階において，ある表層
発話がその行動ゲームの手となるかどうかの判定に用いられたり，意図理解段
階において，ある行為がその行動ゲームの手となるかどうかの判定に用いられ
たりしており，あやふやな位置付けになっている．

\begin{figure}[htbp]
\begin{center}
\begin{minipage}{10cm}
\begin{verbatim}
[KITCHEN]
validity condition: at home, after meal
- x does the dishes
- y makes something useful.
\end{verbatim}
\end{minipage}
\end{center}
\caption{Airentiらの行動ゲームの例 (\cite{airenti93}より抜粋)}
\label{airenti2}
\end{figure}

\subsection{認知プロセスモデルの概要}

我々は，対話における言語構造に関して，会話ゲーム中の局所的な制約として
記述するのではなく，行動ゲームと同様に認知プロセス中から参照されるもの
として，言語構造を表現した空間を設定する．行動ゲームに対応するものを
{\bf 問題解決空間}，言語構造を表現したものを{\bf 会話空間}と定義する．
このことによって，各プロセスの処理は比較的単純でありながら，対話の局所
的な単位であるやりとりにおけるフェーズの把握や対話全体における問題解決
過程の把握ができるモデルとなる．我々の認知プロセスモデルの概要を図
\ref{model}に示す．

\begin{figure}[htbp]
\vspace{-5mm}
\begin{center}
\epsfile{file=fig1.eps,scale=0.8}
\end{center}
\caption{対話処理の5段階モデル}
\label{model}
\end{figure}

さらに我々はこのモデルの各段階において，音声の誤認識への対処が行えるよ
うに拡張を行った．認知プロセスに誤認識への対処法を組み込むアプローチは，
発話理解や問題解決構造に組み込む方法に比べて，発話スタイルやタスクへの
依存度が少ないので，より一般性のある方法であるといえる．

以後，我々のモデルにおける各段階での処理について，主にAirentiらのモデ
ルをどのように拡張したかという視点から説明する．

\subsection{意味理解}

Airentiらのモデルにおける意味理解段階の処理は，ゴールとして
$\mbox{SH}_{yx}\mbox{DO}_x \mbox{express(y, s)}$または
$\mbox{SH}_{yx}\mbox{DO}_{xy} G(x,y)$を得ることとしている．後
者は，発話が直接に行動ゲームの手となるような場合(行動ゲームgreetingに
おける``Have a nice day.''のような発話)であり，システムとの対話におい
ては例外的であると思われるので，ここでは前者の拡張について議論する．

Airentiらは表層発語内行為(assertive, interrogative, directive)から話者
の意味したもの(述語express中の命題)を導き出す規則を明示しているが，自
然な音声対話においては述語の省略や代用表現(「〜お願いします」など)がよ
く用いられるので，表層的な情報だけでは話者の意味したものが特定できない
場合が多い．そこで，対話の局所的な情報を何らかの形式で保持しておき，そ
れを参照しながら意味表現を生成する処理が必要になる．

我々のモデルでは，表層発語内行為と発語内行為との対応規則を用いるのでは
なく，ロバストパーサの出力として仮定している「全体として整合した部分的
な意味表現」を，局所的な対話文脈に位置付けるという方法で意味理解を行っ
ている．ここで部分的な意味表現とは，キーワード・句・文のそれぞれのレベ
ルで解析できた範囲でロバストパーサが出力する意味表現であり，例えば述語
部分の解析に失敗した場合には，句に相当する意味表現が複数出力されること
を仮定している．それが全体として整合しているとは，複数出力された意味表
現を組み合わせてひとつの発話の意味表現を構成し得ることを指しており，一
文一格の原理を満たさない場合や，従属関係になりえない述語レベルの意味表
現が複数ある場合などは全体として整合していないことになり，ロバストパー
サの段階で解析失敗となる．

この意味表現を対話文脈に位置付けるという方法は発話には文脈独立な意味表
現が存在するという表層発語内行為仮説(literal meaning hypothesis)
\cite{allen95}に基づいたものであり，処理は以下の2段階に分割される．

\begin{enumerate}
\item 入力発話から，全体として整合した部分的な意味表現を抽出する．これ
は表層情報のみから決まるもので，理想的には表層発語内行為と命題内容を導
き出す．
\item その部分意味情報から発語内行為への対話文脈に応じたマッピングを
行う．
\end{enumerate}

ここで，(1)の段階が達成されない場合(すなわちロバストパーサによって何も
意味表現が生成されない場合)は，応答生成段階に制御を移し，再入力を促す
発話を生成する．(1)の処理をいかに頑健に行うかということはロバストパー
サの問題であり本稿では扱わないが，この時点でいかなる誤りも存在しないと
仮定するわけではない．すなわち，表層発語内行為や命題内容を構成する要素
の中に音声の誤認識による誤りが含まれている場合でも，これ以降の処理で検
出・修復を行う．

例えば(1)の段階の処理としては，個人スケジュール管理タスクにおける「2時
から会議を登録して下さい．」というユーザ$x$からシステム$y$への発話に対
して，その命題内容\\ register([[start\_time, 2], [obj, meeting]])を抽
出し，表層発語内行為を組み合わせて，
\begin{quote}
$\mbox{DO}_x \mbox{lit-illoc(y, register([[start\_time,
2], [obj,meeting]]), directive)}$
\end{quote}
という命題が共有信念として得られる．

これに続く(2)の処理として，この共有信念からユーザの発語内行為を認識す
ることを目的とする．発語内行為の認識の前提として，意味理解段階ではまず
発語内行為の分類を考える．発語内行為は大きく働き掛けと応答に分類できる
\footnote {自然な対話では，応答に対する了解・相手の発話を促す相槌・伝
達そのものの調整などの行為があるが，本稿におけるモデルでは音声対話シス
テムを対象としているので，働き掛けと応答のみを扱う．}ので，ここでは命
題内容と表層発語内行為を基にして得られた共有信念から，以下のどちらに分
類できる行為であるかを認識し，その表明された内容を共有信念とすることを
意味理解段階の目標とする．

\begin{enumerate}
\item[(a)] ユーザ$x$がシステム$y$に行為$e$をしてほしい($\mbox{INT}_x
\mbox{DO}_y e $)と表明した(働き掛け)
\item[(b)] ユーザ$x$が信念$p$を持っている($\mbox{BEL}_x p$)という
ことを表明した(応答)
\end{enumerate}

しかし，表層発語内行為には働き掛け／応答の双方の機能と対応するものがあ
り，また，音声対話によく出現する述語の省略・代用表現によって，この機能
を決定するためには対話の局所的な知識が必要となる．我々のモデルでは
\ref{conv}章で述べる会話空間に対して，ここで得られた要素を局所的対話文
脈に位置づけるという処理を行うことによって，これらの問題を扱っている．
さらに会話空間では入力発語内行為および命題が，現在維持している対話履歴
と整合しているかどうかを判定し，整合していなければ誤認識とみなして応答
生成段階に処理を移し，問い返しの応答を生成する．

以上の意味理解段階の処理をまとめると図\ref{step1}に示すようになる．

\begin{figure}[htbp]
\begin{quote}
\noindent
{\dg 意味理解}

\noindent
{\bf if} $\mbox{SH}_{yx}\mbox{DO}_x \mbox{express(y, INT}_x
\mbox{DO}_y e)
\lor \mbox{SH}_{yx}\mbox{DO}_x \mbox{express(y, BEL}_x p)$\\
{\bf then goto} 意図理解;\\
{\bf else goto} 応答生成
\end{quote}

\caption{意味理解段階の処理}
\label{step1}
\end{figure}

\vspace{-3mm}
\subsection{意図理解}

対話において発語内行為を成功させるには，話者の意図と，その意図を伝えよ
うとする意図(伝達意図)とが聴者に理解されることが必要であり，さらにそれ
らが相互に信念として持たれている必要がある\cite{allen95}．すなわち，対
話において聴者が話者の意図を理解する(あるいは話者の発語内行為が成功す
る)とは，「話者の意図と，その意図を伝達しようとする意図とを話者と聴者
の共有信念とすること」である．では，ここでは話者の持つ意図はどの程度具
体化されているべきであろうか．

対話システムが知的な振る舞いをするためには，対話がタスク構造に従って構
造化されており，かつ各副対話が適切にその機能を明らかにされている必要が
ある\cite{grosz86}．すなわち話者の意図として話者が持つプランが聴者に理
解されている状況が望ましい．よって，意図理解段階の目的は，話者の発語内
行為およびプランを認識することとなる．

しかし，対話の初期段階では話者のプランに関して複数の候補が考えられる状
況がある．この場合，どのようにして対話を維持するかについて，異なる対話
戦略が考えられる．

例えば，\cite{vanBeek93}においては，プラン候補が複数ある場合に，それら
に(1)前提の失敗，(2)順序不整合，(3)より良いプランの存在，(4)欠点なし，
のいずれかのラベルを付け，ラベルが同じものに揃うまで詳細化のための副対
話を行うアルゴリズムが提案されている．この手法はシステムが扱うプランが
多数ある場合に有効であると考えられるが，必ずしも全てのタスクが副対話生
成による冗長性をカバーするほどの数のプラン候補を持つとは限らない．

Airentiらのモデルにおいては，この段階で相手の行動ゲームが認識されなけ
れば応答段階に処理を移すことになっている．これは，相手の発話によって行
動ゲームが唯一に同定されなければ，その発話内容を無視して行動ゲームの同
定を行うための発話を生成することを意味するので，協調的なシステムの振る
舞いとしては適当ではない．

我々は，冗長な詳細化用副対話やユーザ発話を無視した副対話の生成を避ける
ために，プランが唯一に特定できなければ，表層的なやりとり規則で対話を維
持し，漸進的にプランを認識する方法を提案している\cite{araki95a}．

対話の初期段階，すなわちプランがまだ共有信念になっていない段階では，相
手の発語内行為の意図に加えて，話者のプランを伝えようとする意図
($\mbox{CINT}_{xy} \mbox{INT}_x \mbox{DO}_{xy} G(y,x)$)を共有信
念とするよう試みる．ここで，話者のプランを伝達しようとする意図を共有信
念とすることが\mbox{できれば}，心的状態の更新に進む．プラン認識の方法は
\ref{prob}章で説明する．一方，\mbox{プランが認識で}きなかった場合は，会話空間
上で典型的なやりとりを構成するような展開を行って，意図生成に進む．ここ
で典型的なやりとりとは，相手の発話と，その発話に含まれる情報のみで対応
できる応答からなるものであり，質問に対する回答や情報伝達に対する受諾な
どの発話対からなるものである．

一方，プランがすでに共有信念になっている場合は，その実行のステップとな
る行為または情報を伝えようとする意図($\mbox{CINT}_{xy} \mbox{INT}_x
\mbox{DO}_{y} e \lor \mbox{SH}_{yx}\mbox{CINT}_{xy} p$)
を共有信念とする．

意味理解段階の処理をまとめると図\ref{step2}に示すようになる．

\begin{figure}[htbp]
\begin{quote}
\noindent
{\dg 意図理解}

\noindent
{\bf if} $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
\mbox{DO}_{xy} G(y,x)\\
\lor (\mbox{SH}_{yx} \mbox{DO}_{xy} G(y,x) \land
(\mbox{SH}_{yx} \mbox{CINT}_{xy} \mbox{INT}_x \mbox{DO}_{y} e
\lor \mbox{SH}_{yx}\mbox{CINT}_{xy} p))$\\
{\bf then goto} 心的状態の更新;\\
{\bf else goto} 意図生成
\end{quote}

\caption{意図理解段階の処理}
\label{step2}
\end{figure}

\subsection{心的状態の更新}

この段階では意図理解の結果に基づいて，必要があれば心的状態を更新する．
ここでの処理はAirentiらのモデルと同様である．

意図理解で新たにプランが認識された場合は，以下の(1)の処理を行いながら，
入力発話に応じて(2)または(3)の処理を行う．既にプランを意図している場合
は，(2)または(3)の処理を行う．ここでの推論は対話エージェントとしての協
調原則\cite{allen95}に基づいたものである．(1)および(2)は入力されたプラ
ンや行為の要求を処理するという意味でattentiveness constraintを実現した
ものであり，(3)は共有知識の食い違いを最小限にするshared knowledge
preferenceを実現したものである．

\begin{enumerate}

\item 話者の意図があるプランを提示するものであれば，そのプランが達成不可
能でなければ(問題解決空間においてそのプランを達成するのに必要な分割リ
ンクのうち，達成不可能であることが判明しているものがなければ)，そのプ
ランを意図する\\($\mbox{INT}_x \mbox{DO}_{xy} G(y,x)$)．

\item 話者の意図がある行為をすることであれば，その行為が何らかの役割を果
たすものであり(その行為と認識済みのプランが分割リンクを介して繋がって
いる)，かつ達成不可能でなければ，その行為を意図する
($\mbox{INT}_y \mbox{DO}_y e$)．

\item 話者の意図がある信念を表明するものであり，自分がそれと矛盾する信
念を持っていなければ，その信念を保持する($\mbox{BEL}_y p$)．

\end{enumerate}

これらの処理を行った後，意図生成に移る．心的状態の更新段階の処理をまと
めると図\ref{step3}に示すようになる．

\begin{figure}[htbp]
\begin{quote}
\noindent
{\dg 心的状態の更新}

\noindent
{\bf if} $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_{xy} G(y,x)$
{\bf then} $\mbox{INT}_y \mbox{DO}_{xy} G(y,x)$;\\
{\bf if}   $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_y e$
{\bf then}   $\mbox{INT}_y \mbox{DO}_y e$;\\
{\bf if}   $\mbox{SH}_{yx}\mbox{CINT}_{xy} p$
{\bf then}   $\mbox{BEL}_y p$;\\
{\bf goto}   意図生成
\end{quote}

\caption{心的状態の更新段階の処理}
\label{step3}
\end{figure}

ここで得られた命題は，以後の発話の処理に用いる．共有信念として持ったゴー
ルについては，それを達成することを対話の目標とし，目標達成に関連する命
題については，これと矛盾する命題がユーザによって言及された(すなわち現
在の発話または過去の発話のどちらかに認識エラーが存在した)ことを検出す
るのに用いられる．

\subsection{意図生成}

ここでは意図理解の結果と心的状態の更新の結果から，次にどのような意図を
持つべきかを決める．この段階では，我々のモデルはAirentiらのモデルの詳
細化と位置付けられるが，その詳細化はAirentiらのモデルでは考慮されてい
なかった認識誤りに基づく誤解の解消に役立つ発話の生成に寄与するものであ
る．具体的には，相手のプラン・働き掛け・応答が受け入れられないときに，
その根拠となる命題を心的状態および問題解決空間で探索し，相手の発話内容
の問い返しとともに，受け入れられない根拠を応答として述べることによって
対話参加者間の信念の違いを明示するものである．この信念の違いが認識誤り
によって生じた場合は，それを修正する副対話が生成される．

我々のモデルにおける意図生成は以下の規則に従って行われる．

\begin{enumerate}

\item[(1)] ユーザのプランを認識した場合

\begin{enumerate}

\item[(1-a)] 心的状態の更新段階において，プランを遂行するという意図
を持った場合 ，(2)の処理に移り，ユーザの働き掛けに応じた意図を生成する
ことによって暗にプランを意図することを示す($\mbox{CINT}_{yx}
\mbox{INT}_y \mbox{DO}_{yx} G(y,x) \land \mbox{CINT}_{yx}
\mbox{INT}_y \mbox{DO}_y e$)．

\item[(1-b)] 心的状態の更新において，プランを受け入れない(プランは認識
できたがそれを意図しない)と決めた場合は，システムの知識の中にそのプラ
ンを達成不能にするものがある場合なので，システムはプランを受け入れ
ないことを明示的に示すと共に，そのプランの障害になっている命題をユーザ
に伝える．($\mbox{CINT}_{yx} \lnot \mbox{INT}_y \mbox{DO}_{yx}
G(y,x) \land \mbox{CINT}_{yx} \mbox{BEL}_y p$)

\end{enumerate}

\item[(2)] あるプランを認識しそれを遂行するという意図を持った場合(ある
いは既にプランが認識されている場合)，ユーザの働き掛けに応じて意図を生
成する．

\begin{enumerate}

\item[(2-a)] ユーザの働き掛けが情報要求ならば，検索結果をユーザに応答
する意図($\mbox{CINT}_{yx} \mbox{DONE}_y e$)を持つ．

\item[(2-b)] ユーザの働き掛けが行為要求ならば，その行為が達成可能であ
るかどうかを問題解決空間で調べる．

\begin{enumerate}

\item[(2-b-1)] 行為が達成可能である場合，その行為を遂行し，さらに問題
解決空間を探索し，そのプラン遂行に役立つ新たな行為$e'$を行う意図を伝達
する意図($\mbox{CINT}_{yx} \mbox{INT}_y \mbox{DO}_y e'$)を持つ．
新たな行為$e'$の決定に関しては\ref{prob}章で述べる．

\item[(2-b-2)] 提案された行為が達成不可能であるか，または共有されてい
るプランのステップではない場合は，その行為を行わないということと，その
理由を示す命題を伝える意図($\mbox{CINT}_{yx} \lnot \mbox{INT}_y
\mbox{DO}_y e \land \mbox{CINT}_{yx} \mbox{BEL}_y p$)を
持つ．

\end{enumerate}

\end{enumerate}

\item[(3)] ユーザ発話が信念を表明するものである場合

\begin{enumerate}

\item[(3-a)] システムが表明された命題$p$と矛盾する命題を持っていなけ
れば，その命題はシステムの信念となり，そのことは明示的に示さなくてもよく，
新たなステップとなる行為$e'$を行う意図を伝達する意図($\mbox{CINT}_{yx}
\mbox{INT}_y \mbox{DO}_y e'$)を持つ．

\item[(3-b)] 表明された命題$p$を信じないのなら否定応答をすると共に，シス
テムが持っているそれと矛盾した命題$p'$を伝える意図($\mbox{CINT}_{yx}
\lnot \mbox{BEL}_y p \land \mbox{CINT}_{yx} \mbox{BEL}_y p'$)を持つ．
\end{enumerate}
\end{enumerate}

意図生成段階の処理をまとめると図\ref{step4}に示すようになる．

\begin{figure}[htbp]
\noindent
\hspace*{1cm}
{\dg 意図生成}

\noindent
\hspace*{1cm}
{\bf if} $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_{xy} G(y,x)$\\
\hspace*{1cm}
{\bf then}  ($\mbox{CINT}_{yx} \mbox{INT}_y 
\mbox{DO}_{yx} G(y,x) \land \mbox{CINT}_{yx} \mbox{INT}_y 
\mbox{DO}_y e) \lor \\
\hspace*{1cm}
\hspace*{9mm}(\mbox{CINT}_{yx} \lnot 
\mbox{INT}_y \mbox{DO}_{yx} G(y,x) \land \mbox{CINT}_{yx} 
\mbox{BEL}_y p)$;\\
\hspace*{1cm}
{\bf if}  $\mbox{SH}_{yx}\mbox{CINT}_{xy} \mbox{INT}_x
 \mbox{DO}_y e$\\
\hspace*{1cm}
{\bf then}  $\mbox{CINT}_{yx} \mbox{DONE}_y e 
\lor \mbox{CINT}_{yx} \mbox{INT}_y \mbox{DO}_y e'
\lor (\mbox{CINT}_{yx} \lnot \mbox{INT}_y \mbox{DO}_y e
\land \mbox{CINT}_{yx} \mbox{BEL}_y p)$;
\hspace*{1cm}
{\bf if}  $\mbox{SH}_{yx}\mbox{CINT}_{xy} p$\\
\hspace*{1cm}
{\bf then}  $\mbox{CINT}_{yx} 
\mbox{INT}_y \mbox{DO}_y e'
\lor (\mbox{CINT}_{yx} \lnot \mbox{BEL}_y p
\land \mbox{CINT}_{yx} \mbox{BEL}_y p')$;\\
\hspace*{1cm}
{\bf goto} 応答生成

\caption{意図生成段階の処理}
\label{step4}
\end{figure}

\vspace{4mm}
\subsection{応答生成}

\cite{airenti93}では応答生成は例示に止まっている．我々は，応答生成を起
動された処理段階および伝達意図の違いによって異なったテンプレートを用い
ることによって実現している．

\begin{enumerate}
\item 意味理解処理の失敗によって起動された場合は単なる問い返し(「もう一度
言ってください」)を生成する．

\item  意図生成から起動された場合は，表\ref{step5}に示すそれぞれの伝達
意図に対応するテンプレートを用いて，応答文を生成する
\footnote{ある行為を意図しない場合，「〜ですか」という問い返し文を生成
するのは，誤認識を修正するきっかけを与えるためである．この方法は，シス
テムとユーザの知識が大きく違い，ユーザの知識を否定することが大きな情報
を与えるようなタスク(例えば機器のインストラクションなど)には不適切であ
る．\mbox{ユーザ知識の否定が頻繁に現われるタスクへの適応}は今後の課題としたい．}

\begin{table}[htbp]
\centering
\caption{伝達意図に対応する応答}
\label{step5}
\begin{tabular}{|l|l|}
\hline
伝達意図 & 応答 \\
\hline
\hline
$\mbox{CINT}_{yx} \mbox{INT}_y \mbox{DO}_y \mbox{assertive}$ &
 ($SUBJ$は)$VAL$です．\\
\hline
$\mbox{CINT}_{yx} \mbox{INT}_y \mbox{DO}_y \mbox{interrogative}$ &
 ($SUBJ$は)$WHAT$ですか．\\
\hline
$\mbox{CINT}_{yx} \mbox{INT}_y \mbox{DO}_y \mbox{directive}$ &
 $OBJ$を$VERB$．\\
\hline
$\mbox{CINT}_{yx} \mbox{BEL}_y p$&
 $p$です．\\
\hline
$\mbox{CINT}_{yx} \lnot \mbox{INT}_y \mbox{DO}_{yx} G(y,x)$ &
 $G$ですか．\\
\hline
$\mbox{CINT}_{yx} \lnot \mbox{INT}_y \mbox{DO}_y e$ &
 $e$ですか．\\
\hline
$\mbox{CINT}_{yx} \lnot \mbox{BEL}_y p$&
 $p$ですか．\\
\hline
\end{tabular}

\medskip

\begin{center}
\begin{minipage}{10cm}
\small
ただし，SUBJは主題，OBJは目的語，VERBは述語部分，VALは値，WHAT
は疑問詞が入るスロットである．
\end{minipage}
\end{center}
\end{table}

\end{enumerate}

\vspace{-3mm}
\section{会話レベルの管理機構}
\label{conv}

\subsection{会話空間の概要}

これまでに述べた認知プロセスモデルにおいて，発語内行為の理解，省略・参
照表現の処理，および相手の発話に対する適切な応答発話の生成のために，会
話が現在までどのように進んできたかを管理する機構が必要となる．

従来の対話モデルでは，これら(またはその一部)の処理を行うためにスタック
を用いることが多かった．例えば，Groszらのモデルでは焦点管理のために，
対話のある時点でもっとも顕著な対象・属性・対話セグメントの目的をスタッ
クを用いて管理している\cite{grosz86}．しかし我々は，スタックの利用は以
下の理由で音声対話システムには適さないと考える．

\begin{enumerate}
\item[(a)]  Groszらのモデルでは対話が入れ子構造をなすことを前提としてスタッ
クを用いているが，自然な対話では入れ子が必ずしも明確になるわけではない．

\item[(b)] 音声の誤認識による誤解の修正の際には，対話履歴の任意の時点
の情報が必要になるが，既にスタックからポップされた情報には原則としてア
クセスできない．

\end{enumerate}

我々のモデルでは会話レベルの最小単位としてやりとりを想定し，このやりと
りを管理することによって，発話の対応付けを行う．やりとりは，基本的に
「働き掛け」と，その働き掛けに対する「応答」からなる．ただし，詳細化対
話や音声の誤認識の修復のために，応答の前または代りに働き掛けおよびそれ
に対する応答が挿入される場合もある．このやりとり単位の管理と，そのやり
とりによって達成された行為を4章で説明する問題解決空間で管理することに
よって，明示的な入れ子構造を用いずに，対話の流れを追跡できる．

また，参照の解釈・省略発話の解析・誤認識による誤解の解消のために，対話
に現れた句レベルの情報から，発話レベルの情報，やりとりレベルの情報を階
層的な動的ネットワークを用いて管理する．この動的ネットワークを{\bf 会
話空間}と呼ぶ．

会話空間にはフレーズノード，インスタンスノード，スロット充足ノードの3
種類のノードを設定する．インスタンスノードとスロット充足ノードは，ほぼ
Charniakらの定義\cite{charniak93}に従っている．基本的にリンクは，両端
のノードが表す命題間の因果関係を条件付き確率の行列を用いて表現できるよ
うになっている\footnote{現在は条件付き確率を決めるのに十分なデータがな
いので，0または1の値をあらかじめ割り当てている．}．各インスタンスノー
ドはスロット充足ノードを経由して結合される．ただし，フレーズノードは直
接対応するインスタンスノードに結合される．会話空間の構成要素の関係の例
を図\ref{cs}に示す．

\begin{figure}[htbp]
\begin{center}
\epsfile{file=fig2.eps,scale=0.7}
\end{center}
\caption{会話空間の構成要素の関係}
\label{cs}
\end{figure}

\subsection{意味理解段階との相互作用}

会話空間は意味理解段階と以下のような相互作用を行い，意味表現を生成し，
対話の履歴を管理する．意味理解段階からの入力は全体として整合した部分的
な意味表現で，出力は発語内行為である．

\begin{enumerate}

\item 意味理解の結果として得られた命題表現の中で句に相当する部分をフレー
ズノードとして，会話空間に導入する．

\item フレーズノードが意味理解で，どのような概念のインスタンスとして生
成されたかを示す句レベルのインスタンスノードを生成し，フレーズノード
とリンクを張る．

\item (2)で生成された句レベルのインスタンスノードが，発話の中でどのよ
うな役割を果たすか(構文的な意味では格に相当する)を示すスロット充足ノー
ド，およびそれらをまとめる発話レベルのインスタンスノードを生成し，それ
ぞれリンクを張る．

\item (1)で生成された発話レベルのインスタンスノードが，やりとりの中で
どのような役割を果たすかを示すスロット充足ノード，およびそれらをまとめ
るやりとりレベルのインスタンスノードを生成し，それぞれリンクを張る．

\item ここまでの処理が達成されると，やりとりの中での役割を入力発話の発
語内行為として出力する．

\end{enumerate}

このように会話空間という形式で対話に現れた情報を管理することによって，
Groszらが焦点として扱った対象・属性・対話セグメントの目的のみではなく，
やりとりに現れた全ての要素を，処理対象としている発話のインスタンスノー
ドからの距離(パスの長さ)をコストとして用いることにより優先度を付けて，
誤認識による誤解の解消や省略・参照表現の処理に用いることができる．

\subsection{やりとり規則による対話の継続}

プランが同定されるまでの対話の初期段階のやりとりや，問題解決に関係のな
い誤認識の修復のやりとりなどは，心的状態の更新を経ずに意味理解段階で得
られたやりとりに関する情報を使って行う．

このようなやりとりは意図理解段階の処理の失敗(プラン認識の失敗および誤
解の検出)によって起動される．プラン認識の失敗の場合は，会話空間中で現
在展開中のやりとり単位を継続させる発語内行為を意図生成段階へ出力する．
また，誤解が検出された場合は，修復の副対話をやりとり内に挿入し，修復発
話に対応する発語内行為を意図生成段階へ出力する．

\subsection{応答生成段階との相互作用}

生成された発話意図から応答文を生成する際に，同じやりとりを構成する発話
であれば，展開された意味表現から主題格などを省略する．入力としては全て
の要素が列挙された意味表現，出力は応答として出力するのに適切な省略を行っ
た意味表現である．

\section{問題解決機構}
\label{prob}

\subsection{問題解決空間の概要}

我々のモデルでは，{\dg 問題解決空間}と呼ぶネットワーク構造の知識表現を
用いて，タスクレベルの対話管理を行っている．問題解決空間はタスクにおけ
るプランとサブプランの関係や，プランとそれを達成するための行為との関係
を記述した静的ネットワークである．本稿で説明に利用するタスクである個人
スケジュール管理を行うシステムに対応した問題解決空間の例を図
\ref{event}に示す．

\begin{figure}[htbp]
\vspace{-4mm}
\begin{center}
\epsfile{file=fig8.eps,scale=0.8}
\end{center}
\caption{問題解決空間の例}
\label{event}
\end{figure}

問題解決空間では，葉ノードが行為を表し，それ以外のノードがプランを表す．
リンクは2種類あり，プランの間の抽象関係を表現する抽象化リンク(図
\ref{event}の上向き太矢印)と，プランからサブプランや行為への分割を表す
分割リンク(図\ref{event}の下向き細矢印)がある．またプランの分割にはAND
分割(下向き細矢印をまとめる記号のついたもの)とOR分割がある．

\subsection{意図理解段階との相互作用}

意図理解段階では話者のプランを認識するために，意味理解段階で得られた発
語内行為を問題解決空間に渡し，プラン認識を行う．問題解決空間におけるプ
ラン認識には最小被覆法\cite{kautz90}を適用する．この手法は基本的には，
問題解決空間において既に実行された(または観測された)行為の全てを含むサ
ブグラフを求めるものである．問題解決空間のプランを表すノードの中で，各々
のタスクにおける基本的なプランすなわち，1まとまりの対話によって達成さ
れるプランをエンドイベントと呼ぶ．ユーザが1対話において，プランを1つし
か持たないという前提に立てば，プラン認識の問題はエンドイベント集合から，
ユーザの持っているプランに対応する要素を1つ選ぶことになる．

問題解決空間では，意味理解結果として得られたユーザの行為を入力として，
新たに入力された行為と以前に入力された行為をカバーするプランを最小被覆
法を用いて認識し，プランが認識された場合はそのプランを，プラン認識に失
敗した場合はそのことを意図理解段階に出力する．

\subsection{意図生成段階との相互作用}

発話生成段階においては，問題解決空間には意図生成段階からのユーザの行為
と，更新された心的状態が入力される．もし，ユーザの行為が情報要求であれ
ば，データベース検索を行ってその値を答えるという処理が意図生成段階でな
されるが，それ以外の場合はユーザの行為に応じて，次のシステムの行為を
AND-OR木上の未達成の行為ノードとして探索し，意図生成段階に出力する．

\section{対話モデルの処理例}

本章では，対話モデルの各段階での処理，および会話空間・問題解決空間での
処理を例によって説明する．個人スケジュールを管理するシステム$s$とユーザ$u$
との対話例を図\ref{example}に示す．

\begin{figure}[htbp]
\begin{center}
\begin{tabular}{ll}
U1: & 「2時から会議を登録してください．」\\
S2: & 「何時までですか．」\\
U3: & 「4時まで登録してください．」(「登録」→「変更」の誤認識)\\
S4: & 「変更するのですか．」\\
U5: & 「登録して下さい．」\\
S6: & 「場所はどこですか．」\\
U7: & 「中会議室です．」(「中会議室」→「小会議室」の誤認識)\\
S8: & 「小会議室は予約が入っています．」\\
U9: & 「中会議室です．」\\
S10: & 「2時から4時まで中会議室での会議を登録します．よろしいですか．」\\
U11: & 「はい．」\\
\end{tabular}
\end{center}
\caption{対話例}
\label{example}
\end{figure}

\subsection{第1ターンの処理とプラン認識}

まず前提として，表層発語内行為及び命題内容の抽出はここでの対話モデルで
扱う問題の対象外と想定しているので，U1に対して
\begin{equation}
\mbox{SH}_{su} \mbox{DO}_u \mbox{lit-illoc(} s, \mbox{DO}_s
\mbox{register([[start\_time, 2], [obj, meeting]]), directive)}
\end{equation}
という表層意味表現が得られるものとする\footnote{この意味表現では1対話
中で1つの対象(ミーティング・休暇など)しか扱えないので，スケジュール管
\mbox{理一般に適用す}るには不十分である．複数の対象を扱えるような拡張は今後の
課題としたい．}．

これに対して，まず意味理解段階の処理としては，対話の初期状態で会話空間
に何も対話履歴がない状態であることと，入力発話がdirectiveという表層発
語内行為を持つことから，これをユーザの働き掛けと解釈し，
\begin{equation}
\mbox{SH}_{su} \mbox{DO}_u \mbox{express(}s, \mbox{INT}_u \mbox{DO}_s
\mbox{register([[start\_time, 2], [obj, meeting]]))}
\end{equation}
という共有信念が形成され，意味理解段階の処理が成功したことになるので，
処理を次の意図理解段階に進める．ここまでの処理を表\ref{ex-table1}に示
す．

\begin{table}[htbp]
\centering
\caption{意味理解段階での入出力および内部表現}
\label{ex-table1}
\begin{tabular}{|l|l|c|l|l|}
\hline
入力 & 会話空間 & 問題解決空間 & 処理 & 出力 \\
\hline
\hline
& (inst 2 start\_time)  & & & \\
(1) &  (inst utt1 directive)  & ---------- & 句レベルの情報に分割 & (2)\\
&  (inst unit1 directive-reply)  & & & \\
\hline
\end{tabular}

\medskip

ただし，会話空間はインスタンスノードのみの列挙

\end{table}

次に，意図理解段階の処理としてはユーザのプランがまだ共有信念になってい
ないので，\\$\mbox{DO}_s \mbox{register([[start\_time, 2], [obj,
meeting]])}$をプラン達成のための1ステップとするようなプランが存在する
かどうかを問題解決空間で探索する．ここではregister\_meeting\_planが唯
一に定まるので，ユーザの伝達意図として以下の2つの共有信念が形成される．
ここまでの処理を表\ref{ex-table2}に示す．

\noindent
\hspace*{1cm}
$\mbox{SH}_{su}\mbox{CINT}_{us} \mbox{INT}_u
\mbox{DO}_{us} \mbox{register\_meeting\_plan}  \land\\
\hspace*{1cm}
\mbox{SH}_{su} \mbox{CINT}_{us} \mbox{INT}_u \mbox{DO}_{s} 
\mbox{register([[start\_time, 2], [obj, meeting]])} 
$\hspace*{30mm}(3)
\setcounter{equation}{3}

\begin{table}[htbp]
\centering
\caption{意図理解段階での入出力および内部表現}
\label{ex-table2}
\begin{tabular}{|l|l|l|l|l|}
\hline
入力 & 会話空間 & 問題解決空間 & 処理 & 出力 \\
\hline
\hline
&   & register\_meeting\_plan & & \\
(2) &  変更なし  &  (subplan: decide\_start\_time, 
& 最小被覆法によるプラン認識 & (3)\\
&  & decide\_end\_time, decide\_place) & & \\
\hline
\end{tabular}
\end{table}

心的状態の更新の段階では，意図理解で新たにプランが認識されたので，この
プランにシステムとして合意するか，また，ユーザの意図する行為を行うかど
うかを決め，その結果をシステムの心的状態に反映させる．ここでは，問題解
決空間のregister\_meeting\_plan以下の行為ノードの中で，達成不可能であ
ることがわかっているものがないことを確認し，このプランを意図する．また，
$\mbox{DO}_s \mbox{register([[start\_time, 2], [obj, meeting]])}$がこ
のプラン達成のための行為であることから，これを実行することを意図する．
すなわち，ここで以下の命題をシステムの心的状態に新たに導入する．ここま
での処理を表\ref{ex-table3}に示す．

\begin{equation}
\mbox{INT}_s \mbox{DO}_{us} \mbox{register\_meeting\_plan} \land
\mbox{INT}_s \mbox{DO}_s \mbox{register([[start\_time, 2], [obj, meeting]])}
\end{equation}

\begin{table}[htbp]
\centering
\caption{心的状態の更新段階での入出力および内部表現}
\label{ex-table3}
\begin{tabular}{|l|l|c|l|l|}
\hline
入力 & 会話空間 & 問題解決空間 & 処理 & 出力 \\
\hline
\hline
(3) & 変更なし  & decide\_start\_time 遂行済 & 問題解決空間における & (4) \\
 &   &  & プラン遂行可能性の検索 & \\
\hline
\end{tabular}
\end{table}

次に，意図生成段階の処理としては，プランに合意し，ユーザの意図した行為
が達成可能である場合であるので，2.6節で説明した(2-b-1)の処理を行う．こ
こで，問題解決空間のregister\_meeting\_plan以下を探索し，新たな行為
$e'$として終了時刻の同定を選び，その達成を意図する．ここまでの処理を表
\ref{ex-table4}に示す．

\begin{equation}
\mbox{CINT}_{su} \mbox{INT}_s 
\mbox{DO}_u \mbox{inform\_ref([end\_time, E])}
\end{equation}

\begin{table}[htbp]
\centering
\caption{意図生成段階での入出力および内部表現}
\label{ex-table4}
\begin{tabular}{|l|l|c|l|l|}
\hline
入力 & 会話空間 & 問題解決空間 & 処理 & 出力 \\
\hline
\hline
(4) & 変更なし & decide\_end\_time 活性化 & 問題解決空間における & (5)\\
&  & & 未遂行行為の探索 & \\
\hline
\end{tabular}
\end{table}

次に，応答生成段階の処理としては，テンプレート$\mbox{CINT}_{su}
\mbox{INT}_s \mbox{DO}_s \mbox{interrogative}$を利用して，ユーザに情
報伝達行為inform\_refを意図させるために，S2の質問文を生成する．ここま
での処理を表\ref{ex-table5}に示す．

\begin{table}[htbp]
\centering
\caption{応答生成段階での入出力および内部表現}
\label{ex-table5}
\begin{tabular}{|l|l|c|l|l|}
\hline
入力 & 会話空間 & 問題解決空間 & 処理 & 出力 \\
\hline
\hline
(5) & (inst end\_time qcase)  & 変更なし & テンプレートマッチングと&  S2 \\
&  (inst utt2 interrogative)  & & 変数の同一化 & \\
\hline
\end{tabular}
\end{table}

\vspace{-4mm}
\subsection{会話空間における意図生成の例}
\label{ex-1}

次に，述語の誤認識が生じたU3の解析例を説明する．

述語の誤認識によるエラーは，意味理解では検出できない場合がある．その時
点までの対話の文脈からして不適当な発語内行為が入力されたことが意図理解
段階によって検出されて，その修復のためのやりとりがこの会話空間上で展開
される．

ここまでのやりとりの展開はU1:「働き掛け」，S2:「働き掛け」となっており，
会話空間上でのやりとりのパターンから，U3の発話はS2の働き掛けに対する応
答またはそれに関連した働き掛けが予測されている．しかし，U3を意味理解し
た結果

\begin{equation}
\mbox{SH}_{su} \mbox{DO}_u \mbox{express(}s, \mbox{INT}_u
\mbox{DO}_s \mbox{modify([[end\_time, 4]]))}
\end{equation}

は，このどちらにも相当せず，述語の誤認識が起こったことが考えられる．

そこで会話空間上に修復のやりとり(S4-U5)を展開する．
ここで修復が成功したので，U3は改めて

\begin{equation}
\mbox{SH}_{su} \mbox{DO}_u \mbox{lit-illoc(} s, \mbox{BEL}_u
\mbox{equal(end\_time, 4), assertive)}
\end{equation}

と解釈され，以下，

\smallskip
\begin{quote}
意味理解: $\mbox{SH}_{su} \mbox{DO}_u \mbox{express(} s,
\mbox{BEL}_u \mbox{equal(end\_time, 4))}$\\
意図理解: $\mbox{SH}_{su} \mbox{CINT}_{us} 
\mbox{equal(end\_time, 4)}$\\
意図生成: $\mbox{CINT}_{us} \mbox{INT}_s \mbox{DO}_u
\mbox{inform\_ref([[place, P]])}$
\end{quote}
\smallskip

と処理され，応答発話S6が生成される．

\subsection{問題解決空間における意図生成の例}

U3の処理で示した例は述語のエラーに対処するものであった．一方，内容語の
エラーは，同一範疇の語と置換した場合は対話文脈を参照しないと検出されな
い場合が多い\footnote{これでも検出されない場合があるので，音声対話シス
テムにおいては対話の最後に伝達された情報を確認するやりとりを設けること
が必要である．}．ここでは，問題解決空間における処理で検出可能な内容語
のエラーが生じたU7の処理について説明する．

ここまでの問題解決空間の処理で，U1でユーザプランが明示されていることか
ら，プラン認識は成功している．その場合，それ以降の問題解決空間の役割は
やりとりがそのプランを達成するためのサブプラン達成を目的とするものか，
またそのサブプランが所定のインスタンスで達成可能なものかを判定すること
である．S6の発話によって，場所の設定というサブプランに「小会議室」をイ
ンスタンスとして達成を試みるが，失敗したとする．そこでこれに対応した意
図生成(2.6節の(2-b-2)の場合)を行い，エラー訂正のやりとり(S8-U9)が生成
される．問題解決空間におけるこのような処理によって，内容語の誤認識にも
対処できるようになっている．

\section{むすび}

本稿では，音声を用いて人間と機械が対話をする際の対話過程を，認知プロセ
スとしてとらえたモデルを提案した．発話理解から応答生成までを段階的に管
理する発話理解・生成機構と，発話列をセグメント化し焦点および意図と関連
付けて構造的にとらえる対話管理機構とについてモデル化を行い，音声の誤認
識によるエラーを扱う機構を組み込んだ．

今回提案したようなモデルがどの程度有効であるかを調べるために，我々は通
信路にノイズを混入させたシステム−システムの自動対話による評価法を提案
している\cite{araki97}．今後，適当なタスクを設定し，モデルの有効性を検
証するとともに，タスク・文などの複雑さの程度を，モデルを評価する上でど
のように扱うべきであるかという指針を立てることも目標とする．

\acknowledgment

本研究を進めるにあたって有意義なコメントを戴いた京都大学情報学研究科堂
下研究室の皆様に感謝いたします．また，多くの有益なご指摘をいただきまし
た査読者氏に深く感謝いたします．


\appendix

\section{述語の定義}
\label{appendixA}

\begin{table}[htbp]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
述語 & 定義 & 意味\\
\hline
\hline
$\mbox{BEL}_x p$ & primitive & xは$p$を信じている\\
\hline
$\mbox{SH}_{xy} p$ & $\mbox{BEL}_x (p \land \mbox{SH}_{yx} p)$ &
xとyは互いに$p$を信じている\\
\hline
$\mbox{DO}_x e$ & Primitive & xが$e$をするという行為\\
\hline
$\mbox{DO}_{xy} G(x, y)$ & Primitive & xとyが$G$を目標とする行為\\
\hline
$\mbox{DONE}_x e$ & Primitive & xが$e$を行った結果(命題)\\
\hline
$\mbox{INT}_x e$ & Primitive & xが$e$を意図している\\
\hline
$\mbox{CINT}_{xy} p$ & $\mbox{INT}_x \mbox{SH}_{xy} (p \land
\mbox{CINT}_{xy} p) $ &
xがyに$p$を伝えようと意図している\\
\hline
\end{tabular}\\
\end{center}

\medskip

ただし，x, yはエージェント，$e$は行為，$p$は命題，$G(x, y)$はxから見た
(yを参加者として含む)ゴールである．また，本文中で使用している述語
lit-illocは表層的な発語内行為，expressは伝達意図の表明である．

\end{table}


\bibliographystyle{jnlpbbl}
\vspace{3mm}
\bibliography{v06n4_02}


\begin{biography}
\biotitle{略歴}
\bioauthor{荒木 雅弘}{
1988年京都大学工学部情報工学科卒業．
1993年同大学院博士課程単位取得退学．京都大学博士(工学)．
京都大学工学部助手，京都大学
総合情報メディアセンター講師
を経て，1999年より京都工芸繊維大学助教授．
自然言語処理，音声対話理解の研究に従事．
人工知能学会，情報処理学会等各会員．}
\bioauthor{堂下 修司}{
1958年京都大学工学部電子工学科卒業．工学博士．京都大学工学部助手，
同助教授，東京工業大学助教授を経て，1973年京都大学工学部教授．
1998年京都大学情報学研究科教授.1999年
より龍谷大学理工学部教授.
その間，音声の分析と認識，オートマトンの学習的構成，自然言語処理，
人工知能など知的情報処理の研究に従事．
人工知能学会前会長．情報処理学会等各会員．}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}
