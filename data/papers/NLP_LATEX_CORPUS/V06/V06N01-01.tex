\documentstyle[jnlpbbl,eclepsf,epsf]{jnlp_j_b5}
\setcounter{page}{3}
\setcounter{巻数}{6}
\setcounter{号数}{1}
\setcounter{年}{1999}
\setcounter{月}{1}
\受付{1998}{4}{17}
\再受付{1998}{9}{11}
\採録{1998}{10}{2}
\setcounter{secnumdepth}{2}


\newcommand{\x}[1]{}
\newcommand{\y}[1]{}

\makeatletter
\def\@captype{}
\newcounter{ex}[section]
\def\example{}
\let\endexample
\def\p@ex{}
\makeatother

\begin{document}


\title{決定木学習による日本語対話文の格要素省略補完}
\etitle{Case Ellipsis Resolution in Japanese Dialogues\\
        via Decision-Tree Learning}

\author{
        山本 和英\affiref{ATR} \and 
        隅田 英一郎\affiref{ATR}
}
\eauthor{
        Kazuhide Yamamoto\affiref{ATR} \and
        Eiichiro Sumita\affiref{ATR}
}

\headtitle{決定木学習による日本語対話文の格要素省略補完}
\headauthor{山本，隅田}

\affilabel{ATR}
    {ATR音声翻訳通信研究所
        (〒619-0288 京都府相楽郡精華町光台2-2)}
        {ATR Interpreting Telecommunications Research Labs.
        (2-2, Hikaridai, Seika, Soraku, Kyoto 619-0288 Japan)}

\jkeywords{格要素省略、決定木、機械学習、対話処理}
\ekeywords{case ellipsis, decision tree, machine learning,
        dialogue processing}




\jabstract{
機械翻訳では目的言語で必須格となる格の人称と数を補う必要がある。本論文
では、省略補完知識の決定木による表現、及び帰納的に機械学習することによっ
て日本語対話文の格要素省略を補完する手法を提案する。本研究では形態素分
割され、品詞、省略情報が付与された任意のコーパスとシソーラスのみを用い
て行なう。決定木学習には、内容語の意味属性、機能語の出現、言語外情報の
3種類の属性を使用する。未学習文に対してテストを行なった結果、ガ、ヲ、
ニの三つの格で照応的な省略の補完を十分な精度で行なうことができた。また
ガ格とニ格に対しては人称と数の補完にも有効であることを確認した。ガ格に
関して、処理の有効性を学習量、話題依存性、使用属性との関係の三点から実
験し、以下の知見が得られた。(1)当該問題に対する決定木学習量は全体とし
て$10^4\sim10^5$事例で十分である。この時の補完精度の上限は$80\%
\sim 85\%$と予想される。(2)対話の話題が既知もしくは予測可能な時は、そ
の話題のみのコーパスによる学習が最善である。話題が未知の場合は、可能な
限り広範な話題に対して学習するのが最も効果的である。(3)学習量増加に伴
い、決定木には機能語などの話題に依存しない属性が多く採用される。}



\eabstract{
A decision-tree learning approach to ellipsis resolution that appears
in Japanese dialogue is proposed.  The method has a high flexibility
since it only requires any dialogue corpus with part-of-speech and
ellipsis taggings and any thesaurus.  We provide three kinds of
attributes to machine learning: semantic category of content words,
functional words, and exophoric information. By the open tests against
Japanese dialogue corpus in the topic of travel arrangement, it is
proven that the proposed method performs satisfactory resolution
accuracy against `ga' (subject) and `ni' (indirect object) cases.  The
following findings are also obtained in the discussion: (1) learning
topic should be restricted if it is expected, otherwise widely-learned
decision tree may perform best.  (2) as a decision tree learns more,
it tends to use more general attributes such as functional words.  The
problem of data size relative to decision-tree training is also
discussed and found that resolution accuracy of proposed method may be
saturated in $10^4\sim10^5$ samples. Resolution accuracy of $80\% \sim
85\%$ is expected at the highest.  }

\maketitle


\section{はじめに}

日本語対話文における格要素の省略補完について述べる。主語や目的語などの
表示が義務的でない日本語の言語処理においては、これら省略される
\footnote{そもそも省略ではなく非存在とする解釈もあるが、ここでは格要素
が明示されていないものすべてを「省略」と呼び、本論文の研究対象とする。}
格要素を補う処理が重要である。格要素の省略は日本語に特有の現象ではなく、
例えば韓国語、中国語などにも認められる。これら省略のある言語から英語や
ドイツ語など必須格を持つ言語への翻訳処理を行なう際には、補完処理(省略
内容の推定処理)は重要な処理となる。また情報検索など、自然言語処理に関
係する他の問題においても、省略補完処理は必要となる。

省略された内容は、言語内、つまり省略位置以前のテキスト中に存在する場合
と言語外に存在する場合に大きく分かれる。本論文では前者を文脈省略
(endophoric ellipsis)、後者を外界省略(exophoric ellipsis)と呼ぶ。

日本語の文脈省略補完に関しては従来から様々な研究がなされてきている。セ
ンタリング理論(centering theory)と呼ばれる一連の手法はこの一つである
(最近の論文としては、例えば\cite{Strube}、\cite{Byron}、\cite{Walker}
などを参照)。この理論では、`center'(談話のある時点において最も顕著な談
話要素)という概念を導入することによって照応や省略の解決を行なう。また
{}\cite{Dohsaka}は、日本語において発話から語用論的制約を抽出し、制約充
足プロセスに基づいて文脈の下で解釈することによる文脈省略の補完手法を提
案している。

一方、外界省略も含めた補完手法に対しては、ヒューリスティックスなどによ
る経験的な解決手法を中心にいくつか提案されている。このうち日本語を対象
にしたものとしては、村田ら\cite{村田}、江原ら\cite{江原}、Nakaiwa et
al.\cite{Nakaiwa}の研究などがある。\cite{村田}は補完に関係する表層的な
言語現象をヒューリスティックスで得点を付与し、それらの合計によって最尤
の省略内容を補完している。この手法は多くの言語情報を利用した省略補完手
法であるが、対話文に対しては十分な考慮がされておらず(\ref{節:比較}節を
参照)、また得点の調整には困難を伴うことが予想される。また\cite{江原}は
複文を単文に分割した際に生じる省略主語を補完するという問題に対して、経
験的に8項目の特徴パラメータを設定して、確率モデルによる手法を提案して
いる。一般の省略に対して有効であるか現時点では不明であり、少なくとも本
研究の対象とは問題が異なるために確率モデルや特徴パラメータを再検討する
必要がある。{}\cite{Nakaiwa}では用言意味属性と語用論的、意味論的制約を
用いて外界省略の解消を行なっている。必要とする知識量が膨大であり、保守
コストや他言語への適用を考えた場合に課題が残る。

本論文の目的は、(1)対話における省略という現象の分析、問題設定(2)決定木
と決定木学習による問題解決手法の提案(3)提案手法の特性の議論、の三点で
ある。後述するように、対話においては外界省略の割合が高いが、このような
状況下で我々はすべての省略を同一の枠組みで補完することは現実的でないと
考える。また対話においてどのような問題設定が適当かはこれまで十分に議論
されていない。そこでまず、対話における現象を分析し本論文における問題設
定を{}\ref{節:現象} 節において行なう。

次に、{}\ref{節:手法} 節で提案手法の説明を行なう。本論文では、省略補完
知識の決定木(decision tree)による表現、及び省略情報の正解付きコーパス
から言語現象と補完すべき省略の関係を帰納的に機械学習し、これによって日
本語対話文の格省略を補完する手法を提案する。本研究は機械学習手法の提案
が目的ではないので一般的に知られている機械学習手法を利用し、どのような
情報をどのように使用し、いかに機械学習させるべきかを提案する。

論文の後半では、提案手法の特性を議論する。{}\ref{節:実験} 節においては、
提案手法の有効性を議論するために行なった実験について述べる。
\ref{節:議論} 節では決定木を観察することによって使用属性などに対する議論を行な
う。両節での議論によって、提案手法がどのような特徴を持ち、またどのよう
な限界があるのかを明確にする。最後に本論文の結論を{}\ref{節:結論} 節で
述べる。

近年多くのテキストやシソーラスが機械可読化されてきており、多くの場合こ
れらの言語資源は入手が可能となっている。本研究では、他の話題への適用性
を考慮して、形態素分割されて品詞と省略情報が付与されたコーパス、及びシ
ソーラスのみを用いて行なう手法を試みる。提案手法は、特定のコーパス、品
詞体系、シソーラスをいずれも仮定しないため、大量の知識を作成、保守する
必要性がなく、手作業による補完規則やパラメータの調整を行なう必要もない。
また本手法では、構文解析も仮定しないため、構文解析の手法や精度とは独立
である。

本論文は、日本語対話文を英語やドイツ語に翻訳する際に必要となる処理を想
定しており、省略内容の人称と数を補完するという問題設定を行なっている。
また、省略の検出処理は他の処理部によって格要素の省略が正しく検出される
と仮定する。

なお、本論文は以前報告した文献\cite{NLPRS97}及び文献
{}\cite{Coling-ACL98}の内容を基本にして議論、検討を行ない、新たにまと
めたものである。



\section{日本語における格要素の省略現象}
\label{節:現象}

本節では格要素の省略という現象の考察を行なう。対話と文章、格による相違
という二つの視点から格要素がどのように省略されるのかを議論することによっ
て、本研究で解くべき問題の設定を明確にする。


\subsection{対話と格要素省略}

前述したように、格要素の省略には文脈省略と外界省略の二種類ある
{}\footnote{さらに、文脈省略を二つに分ける分類方法もある。例えば
{}\cite{Nakaiwa}では、補完要素が省略された格要素を持つ文中にある場合
(文内照応)とその文以前にある場合(文間照応)とに分けている。}。この二種
類の省略の出現割合はテキストの種類によって、つまりそのテキストが対話
(音声言語)か文章(新聞や小説などの文字言語)かによって大きく異なることが
想像できる。この関係を表にしたものを表\ref{文章と対話} に示す。


\begin{table}
\begin{center}
\caption{文章と対話の性質}
\label{文章と対話}
\begin{tabular}{l|cc}
\hline\hline
           & 文章        & 対話 \\
\hline
文脈省略 & 多い          & ヲ格では多い \\
外界省略 & 少ない        & 非常に多い \\
\hline
省略の頻度 & 比較的少ない  & 比較的多い \\
\hline
\end{tabular}
\end{center}
\end{table}

本研究の対象となる対話について考えると、文章とは省略の様子が大きく異な
ることがわかる\footnote{ここでは、演説などの不特定の相手への対話、及び
日記や手紙などの特定の相手への文章などは考えない。}。文章は多くの場合、
それ自体で完結していることが必要であり、読者を明確に特定できない場合が
多いため読者との共有知識を明確に定義できず、それ故省略もそれほど多く起
こらない。また省略された場合の補完内容は、その文章内にある場合が多いと
考えられる。これに対し対話(特に二者対話などの少数聴者に対する対話)では、
相手に情報を伝えることが目的であり、双方向でコミュニケーションをとりな
がら進行するため共有知識も次第に増え、その結果省略も多用される。また、
コミュニケーションをとる必要上、対話参加者に関する省略、つまり外界省略
が比較的多いと考えられる。以上のような理由により、省略の補完処理につい
てもどのようなテキストを対象にするかによってどの省略を中心に取り扱うか
が自ずと決まる。


\subsection{表層格による格要素省略の差異}

省略された格要素が外界省略か文脈省略かは格によっても大きく傾向が異なる。
以下では、日本語の主たる表層格要素であるガ格、ヲ格、ニ格について考える。

ガ格は、動作や状態の主体または対象を表す場合に使用される。これらを観察
すると、動作の主体または対象が省略される場合と、状態の主体または対象が
省略される場合で、省略及び補完に必要な情報の傾向が大きく異なることが予
想される。以下の[\ref{乗る}]は動作を表す文であり、[\ref{冷たい}]は状態
を表す文である。前者のガ格は人である場合が多いが後者ではガ格が人になる
割合はそれほど多くない。

\begin{example}
\item 早く電車に乗ってください。\label{乗る}
\item とても冷たいですね。\label{冷たい}
\end{example}

以上の検討より、本論文では省略された文の述部によってガ格を二つに分離し、
別個のものとして取り扱った。すなわち、一つは述部が動詞の場合、もう一つ
は述部が形容詞、形容動詞、あるいは「名詞＋判定詞(だ/です)」の場合であ
る。以下では、前者をガ格(動)、後者をガ格(形)と表記する。なお、ガ格分離
の妥当性は後で考察する。

ヲ格は、動作や感情を向ける対象や移動の場所、起点を示す。このため、動作
や感情の対象が対話参加者となる可能性のある一部の動詞(「紹介する」など)
を除いて、多くの場合が照応的な省略、文脈省略となることが予想される。

ニ格は、動作を向ける相手(「彼\underline{に}見せる」)、移動の着点(「京
都\underline{に}着く」)などいろいろな用法がある。ニ格となる名詞には様々
な種類が考えられるが、大別すると、人、場所、抽象物(時間を含む)、具体物
に分けられるが、多くは人であると予想される。

以上の考察の妥当性を確認するために、対話コーパス(\ref{節:コーパス} 節を
参照) 499対話(18385 文、省略総数\footnote{表に示す格以外の格、並びに特
殊な用法の省略を除く。} 15397 )における省略された格の補完内容を実際に
調査した。その結果を表\ref{調査} に示す。これより、ガ格(動)とガ格(形)で
はその省略の傾向が異なること、ヲ格はほとんどが文脈省略であること、ニ格
の89.1\%が外界省略であることなどがわかる。


\begin{table}
\begin{center}
\caption{対話文における各表層格別の省略頻度}
\label{調査}
\begin{tabular}{c|rrrrrr|r}
\hline\hline
   & 一人称(単 & 複) & 二人称(単 & 複) & 一般\footnotemark & 文脈省略 & 合計 \\
\hline           
ガ(動) & 3864 & 962 & 1879 & 284       & 361   & 1359     & 8709 \\
& 44.4\% & 11.0\% & 21.6\% & 3.3\%     & 4.1\% & 15.6\%   & \\
ガ(形) &  576 & 442 &  306 &  52       &  14   & 1365     & 2755 \\
& 20.9\% & 16.0\% & 11.1\% & 1.9\%     & 0.5\% & 49.5\%   & \\
ヲ     &   47 &   4 &    4 &   3       &   0   & 1137     & 1195 \\
& 3.9\% & 0.3\% & 0.3\% & 0.3\%        & 0\%   & 95.1\%   & \\
ニ     & 1163 &  53 & 1156 &  61       &   8   &  297     & 2738 \\
& 42.5\% & 1.9\% & 42.2\% & 2.2\%      & 8.3\% & 10.8\%   & \\
\hline           
合計   & 5650 & 1461 & 3345 & 400      & 383   & 4158     & 15397 \\
& 36.7\% & 9.5\% & 21.7\% & 2.6\%      & 2.5\% & 27.0\%   & \\
\hline
\end{tabular}
\end{center}
\end{table}
\footnotetext{「一般」については\ref{節:補完情報} 節で述べる。}


\subsection{対話文の問題設定と補完戦略}

本研究の目的は、日本語から必須格を持つ目的言語への機械翻訳において、省
略されている必須格要素の人称と数を補完することである。しかし前述したよ
うに、文章と対話によって省略の傾向が異なり、これらすべてを対象にして統
一的な処理を行なうことは適当ではないと考える。そこで、対話において比較
的重要な外界省略を主たる対象にして、本論文では以下のように問題を設定し
た。

\begin{itemize}
\item 外界省略の人称と数の補完
\item 文脈省略の認知
\end{itemize}

これまで、照応的な省略に対しての研究はいくつか行なわれている。これらの
研究は以上の問題設定とは相補的になる。すなわち、本論文の手法によって文
脈省略と認知することができれば、省略内容の補完処理はこれらの従来研究、
例えばセンタリング理論によって解くことが可能となり、対話におけるすべて
の格要素省略の問題を解くことができる。




\subsection{コーパスと話題}
\label{節:コーパス}

本研究で使用したコーパスは、チケット予約、観光案内などにおける二者の対
話を収録したATR旅行会話コーパス\cite{ATRCorpus}(以下、「コーパス」と呼
ぶ)である。おおよそ1対話は20文から40文で構成され、平均は26文である。コー
パスは全部で 618 対話からなるが、本研究ではそのうち499対話を調査、決定
木学習及び実験に使用した。

コーパスは、ホテルにおける旅行客とフロントの対話を中心に、広範な範囲の
対話を収録している。本論文ではこれを大きく表\ref{話題} に示す4つの話題
に分類した。この分類は\ref{節:話題依存性} 節での話題依存性での議論の際
に使用する。


\begin{table}
\begin{center}
\caption{コーパスの話題分類}
\label{話題}
\begin{tabular}{ll}
\hline\hline
記号  & 話題 \\
\hline
$H_1$ & ホテルにおける部屋の予約、変更、キャンセル\\
$H_2$ & ホテル利用に関する問い合わせ、苦情\\
$H_R$ & その他のホテル関連の話題：ホテル選択やホテル設備案内など\\
$R$   & ホテル関係以外の旅行対話：出入国、観光、買い物など\\
\hline
$H$   & $H=H_1+H_2+H_R$：コーパス中のホテルに関する全話題\\
$T$   & $T=H_1+H_2+H_R+R$：旅行対話の全話題\\
\hline
\end{tabular}
\end{center}
\end{table}


\section{決定木を用いた省略補完}
\label{節:手法}

本節では、省略の補完に必要な二つの側面、多要素性と相互依存性について検
討を行なった後、提案する手法について述べる。


\subsection{多要素性}

日本語における格要素の省略内容の補完には、非常に多種多様な要素が関係し
ていることは、以前から知られている。従来文献においても、例えば Dohsaka
{}\cite{Dohsaka}は、待遇関係、視点関係、制御関係、情報のなわばりに関す
る語用論的制約によって補完を試みている。また、工藤ら{}\cite{工藤}は、
謙譲、丁寧、可能、完了などの意味を持つ機能語と、動詞の語彙的な特性によ
る省略補完手法を提案している。

省略補完に必要な情報の例を、以下に示す。

\begin{itemize}
        \item 待遇表現\\
                対話において尊敬語や謙譲語などが使用された場合には、
                誰の動作か述べる必要がなくなり、ガ格が省略される。すなわち、
                ガ格の補完にはこれら敬語は重要な情報を果たす。
        \begin{example}
                \item そちらに参ります。(ガ格は一人称)
        \end{example}
        \item 平叙/疑問/命令\\
                以下の例では、疑問文かどうかでガ格が異なる。
        \begin{example}
                \item わかりました。(ガ格は一人称)
                \item わかりましたか。(ガ格は二人称)
        \end{example}
        \item 動詞の持つ意味\\
                例えば、以下の発話がホテルのフロントと客との対話と仮定すると、
                どちらの発話かに関係なく、当該動詞のガ格の内容が決まる。
        \begin{example}
                \item キャンセル待ちを調べて$\cdots$ (ガ格はフロント)
                \label{キャンセル}
                \item JRに乗って$\cdots$ (ガ格は客)
        \end{example}
        \item 前文以前の情報(文脈情報)\\
        対話におけるこれまでの話の流れ。
        \item 言語外情報\\
        その文が、どこで、誰が誰に対して発話されたか、など。
        例えば、[\ref{キャンセル}]で、ガ格の人称を決定するには、
        話者がフロントと客のどちらか、という情報が必要となる。
\end{itemize}


このように、対話文において省略を補完するためには多くの情報が必要と考え
られる。さらに用言の持つ意味は省略の補完にとって重要な情報であると思わ
れるが、その重要性は個々の用言によって異なると考えられる。このように非
常に多くの要素が考えられるが、このうち個々の補完事例に本当に必要な要素
のみを選択することが可能な補完手法が必要とされる。人手による補完規則作
成によるアプローチは、このような言語現象に対して個々に考察を行なう必要
があり、一般的には困難が伴う。


\subsection{相互依存性}

例として、以下の発話において「忘れる」のガ格を補完することを考える。

\begin{example}
\item 部屋/に/カメラ/を/\underline{忘れ}/てき/てしまっ/た/ような/んです/が。
\end{example}

この例では、動詞「忘れる」の持つ意味属性や「てくる」「てしまう」「た」
「ようだ」「んです」「が」といった文末表現など、多くの要素が省略補完に
関係する可能性があり、このうちどの要素がどの程度省略補完に影響している
かを明確に記述することは難しい。また、影響の範囲は文末表現間のみ、ある
いは用言と文末表現の組み合わせに限らず、例えば以下のように接頭辞と文末
表現の組み合わせで考慮すべき例もあり、その関係は多種、複雑である。

\begin{example}
\item 近鉄に\underline{お}乗り\underline{になっ}てください。
\label{近鉄}
\end{example}

このように、格要素の省略補完に必要な情報は独立ではなく、相互に影響しな
がら省略が可能になることに注意しなければならない。つまり、[\ref{近鉄}]
で言えば、「お$\cdots$」と「$\cdots$になる」の出現に対して、個別に補完
内容の補完をすることはできない。あるいは、ホテルのフロントにおける受付
と客の対話で、一般的に「宿泊する」の動作主は客もしくは「一般的な人」で
あるが、ある特殊な文脈によってはそれ以外の可能性も考えられ、一概に「宿
泊する」という動詞のみでは決定できない。格要素の補完では、多種多様な言
語現象からどの2要素(あるいはそれ以上)に対して、同時に考慮する必要があ
るのかを検討する必要がある。



\subsection{決定木を用いた省略補完}

以上の考察から、格要素の省略補完には、多要素性と相互依存性を同時に考慮
することが可能な枠組みが必要であることがわかる。これに対し我々は、決定
木を補完知識表現として使用し、統計を利用した決定木学習を省略補完の知識
獲得に使用することを提案する。

近年、大量のコーパスが機械可読になってきていることから、機械学習による
問題解決は自然言語処理のいくつかの問題に適用されている。例えば、田中は
動詞の訳語選択に決定木学習を導入し、有効性を確認している{}\cite{田中}。
さらに、談話処理や文脈処理にもこれらの手法が使用されつつあり、例えば談
話分割や手がかり語などに関する談話処理にも適用されるようになってきてい
る{}\cite{Summary}。



\subsection{補完情報の付与}
\label{節:補完情報}

決定木学習による学習、並びにテストを行なうことを目的に、対話コーパスに
補完内容の情報を付与した。今回付与したタグの種類を表\ref{タグ} に示す。

本論文では、表に示すように6種類のタグを設定した。タグの付与に関して、
これらの補完内容は日本語のみを考慮して付与した。

\begin{example}
\item 財布を盗まれた。\label{例:財布}
\item My wallet is stolen.\label{例:wallet}
\item Mein Geldbeutel ist gestohlen worden.\label{例:Geldbeutel}
\end{example}

例えば以上の例文において、[\ref{例:財布}]におけるガ格は「私」であるが、
その英語訳である[\ref{例:wallet}]の主格は`my wallet'、ドイツ語訳である
[\ref{例:Geldbeutel}]の主格は`mein Geldbeutel'である。このように翻訳先
の言語によって人称が変わる場合があるが、英語などへの翻訳時に人称がどう
なるかという観点では付与しなかった。つまり上記の例では用言「盗む」に対
して<1sg>(＝一人称単数)のタグを付与した。これは、一般に訳し方は一通り
でないこと、翻訳の目的言語が英語のみではないこと、などの理由による。

\begin{example}
\item 右へ曲がると交番です。\label{例:交番}
\end{example}

日本語においては、[\ref{例:交番}]などのように、特定されない人称を省略
要素とする文、つまり一般的な「人」を念頭において発話していると考えられ
る文がしばしば見受けられる\footnote{日本語のみならず、韓国語や中国語に
も見受けられる。}。このような場合、例えば英語への翻訳の場合には人称代
名詞`you'を、ドイツ語への翻訳の場合には不定代名詞`man'を主格にすること
が多い。しかし、それぞれ二人称、三人称の省略などとは異なる現象であるこ
と、想定する翻訳目的言語が英語、ドイツ語などと複数であることを理由に、
一人称や二人称とは別のタグ<g>を設定した。以下便宜上、このタグを「一般
(人称)」と呼ぶ。以上は外界省略として扱える。

省略位置以前の要素に照応先がある場合、つまり文脈照応の場合は、一括して
<a>のタグを付与した。本論文では、対話文に頻出する外界省略の補完に主眼
を置き、文脈省略に関しては当該省略が文脈省略であることの認知のみを行な
い、具体的な先行詞の補完は別処理で行なうと仮定した。


\begin{table}
\begin{center}
\caption{付与したタグの種類}
\label{タグ}
\begin{tabular}{cll}
\hline\hline
タグ    &       意味       & 備考\\
\hline
<1sg>   &       一人称単数 & 話者が個人としての立場から発言している場合 \\
<1pl>   &       一人称複数 & 話者が代表している機関、グループの場合を含む\\
<2sg>   &       二人称単数 & 聞き手を個人としてとらえている場合 \\
<2pl>   &       二人称複数 & 聞き手が代表している機関、グループを含む \\
\hline
<g>             &       一般 & 特定されない人物(一般的な「人」を念頭に置いた発話) \\
<a>             &       照応的 & 前文以前の発話に先行詞がある場合 \\
\hline
\end{tabular}
\end{center}
\end{table}




\subsection{決定木と決定木学習}

多岐にわたる情報を統一的に、かつ自動的で一意に省略を補完する手法として、
本研究では決定木を用いる。決定木は、根付き有向木で表現される知識表現構
造であり、以下の利点を持つ。

\begin{enumerate}
\item
木という単純な構造の組み合わせによって多要素が複雑に関係した概念が表現
できる
\item
透明性が高いため、要素間の影響が明確に記述され、手作業による変更が十分
に可能である
\item
処理が高速で、多くの場合処理時間は実用上無視できる程短い
\end{enumerate}

決定木の各分岐節点はある属性\footnote{特徴あるいは質問と呼ぶこともある
が、本論文では属性に用語を統一する。}に対応してその属性値によって枝分
かれしていき、それぞれの葉で意志決定が行なわれる。決定木は分岐節点にお
ける分岐数によって大きく二分木と多分木とに分かれるが、本論文では前者を
使用した。これによって、属性値は`Y'または`N'の二値になる。決定木の例を
付録の\ref{節:決定木} に示す。

コーパスからの帰納的学習により決定木の作成を行なう。本研究では
ID3\cite{Quinlan}のアルゴリズムと同様、エントロピー規準による貪欲法
(greedy algorithm)によって決定木学習を行なった。また、枝刈り(pruning)
は行なっていない。



\subsection{使用属性}
\label{使用属性}

省略された格要素を補完するためには、種々の情報を考慮して行なわなければ
ならない。本研究では計367の属性を使用した。その内訳を表\ref{属性} に示
す。表に示すように、属性は内容語、機能語、言語外情報に大きく分類できる。
以下ではそれぞれについて説明する。


\begin{description}
\item[内容語の意味属性]

省略の対象となる文において、どのような内容語が含まれているかに関する情
報。内容語は大きく、用言に関する情報と格要素(体言)に関する情報に分かれ
る。内容語の意味属性としては角川類語新辞典\cite{角川類語}における中分
類(100属性)を使用した。


\item[機能語の出現]

用言に後接する付属語群、及び助詞などの機能語の出現に関する情報。付属語
群の中には、受動/尊敬/可能/自発「れる」使役「せる」アスペクト「ている」
などの助動詞などのほか、当為を表す準体助動詞「べき」などが含まれる。ま
た、尊敬(召し上がる)、謙譲(伺う)、可能(飲める)などを示す動詞の集合をそ
れぞれ一つの属性とし、「尊敬」などを示す機能語として取り扱った。また、
受給表現「やる」や動詞「する」「なる」なども特殊な機能語と見なした。

その他の機能語には、格助詞、接続助詞、終助詞、「\underline{お}考えです
か」「\underline{ご}用意できます」の例に見られる動詞直前の敬意を表す接
頭辞がある。この他、禁止を表す形容名詞「だめ」意志を表す形式名詞「つも
り」、疑問詞集合(「どこ」「なぜ」など)なども機能語に含めた。


\item[言語外情報]

言語外情報としては、発話された文の話者が情報提供者か情報享受者か、とい
う属性を使用した。

\end{description}


\begin{table}
\begin{center}
\caption{使用属性とその要素数}
\label{属性}
\y{3}
\begin{tabular}{llr}
\hline\hline
対象               & 属性       & 属性数 \\
\hline
内容語(用言)   & 意味属性   & 100 \\
内容語(格要素) & 意味属性   & 100 \\
\hline
機能語(格助詞)   & が、に、を    &   9 \\
機能語(接続助詞) & ので、たら    &  21 \\
機能語(助動詞群) & れる、ている  & 132 \\
機能語(その他)   & お、敬語動詞  &   4 \\
\hline
言語外情報     & 話者情報     &   1 \\
\hline
合計               &              & 367 \\
\hline
\end{tabular}
\end{center}
\end{table}

すべての属性は (照合方法, 照合位置, 属性値) の三つ組によって表現される。
照合方法は、\verb+:speaker+ (話者の照合)、\verb+:regexp+ (正規形による
形態素の照合)、\verb+:semcode+ (意味属性の照合) の3種類である。照合位
置は、補完の対象となる用言の位置を基準として以下に示す5種類を設定した。
\smallskip

\begin{tabular}{ll}
\verb+:before+ & 文頭から用言の直前までの間の形態素 \\
\verb+:latest+ &  用言の直前の形態素 \\
\verb+:here+ &  用言 \\
\verb+:next+ &  用言の直後の形態素 \\
\verb+:after+ &  用言の直後から文末までの間の形態素 \\
\end{tabular}\medskip

\noindent
例えば、照合位置として補完対象用言に関しては \verb+:here+、格助詞に対
しては\verb+:before+、接頭辞に対しては \verb+:latest+ を与える。話者の
照合 \verb+:speaker+ の対象は常に省略された文であり、位置情報は一意に
決まるため不要であるが、他の属性との整合性をとるため便宜上 
\verb+:here+ を与える。照合対象が複数の形態素となる\verb+:before+と
\verb+:after+に関しては、照合範囲にある形態素のいずれかが属性の条件を
満たすかどうかによって照合を行なった。具体的な属性の例と、その意味を以
下に示す。\smallskip

\begin{enumerate}
\item{\tt (:speaker :here 情報提供者)}\\
文の話者が情報提供者である。

\item{\tt (:regexp  :after ("たい" "助動詞"))}\\
用言の後に助動詞「たい」を含む。

\item{\tt (:semcode :here 30)}\\
用言の意味属性が 30 である。

\item{\tt (:semcode :before 81)}\\
用言の前に意味属性 81 の内容語を含む。

\item{\tt 
        \begin{tabular}[t]{@{}ll}
        (or & (:regexp :latest ("お" "接頭辞"))\\
            & (:regexp :latest ("ご" "接頭辞"))\\
            & (:regexp :latest ("御" "接頭辞")))\\[2mm]
        \end{tabular}
}

用言の直前の語が接頭辞の「お/ご/御」である。

\end{enumerate}
\y{3}

複文や重文などの、文が複数の単文からなる場合には、近似的に単文に分割し
た。分割手法は、接続助詞\footnote{「$\cdots$たら/ば」のように、複数の
接続助詞が連続する場合は最後方の接続助詞。}を分割位置にしてその前後を
分割した。


\section{実験}
\label{節:実験}

本節では、学習された決定木による省略補完の有効性を検証する。まず、ガ格
(動)に対して検証を行ない、続いてガ格(形)、ヲ格、ニ格に対しての有効性を
議論する。さらに、学習量、決定木学習の話題依存性、使用属性による相違の
三点から検討を行なう。

本論文では、性能評価尺度としてF値(F-measure)を用いる。F値は、再現率
(recall)と適合率(precision)を一つの尺度として表現するために使用される
尺度で、$R$を再現率、$P$を適合率としたとき、以下の式で定義する。

\y{3}
\begin{equation}
F = \frac{(\beta^2 + 1) \times P \times R}{\beta^2 \times P + R}
\end{equation}
\y{3}

ここで、パラメータ$\beta$ は適合率の再現率に対する相対的な重要性である。
本論文ではこのパラメータを$\beta=1$とした。


\subsection{基本条件による実験}

まず、以下の条件により実験を行なった。

\begin{itemize}
\item 実験対象はガ格(動)の省略
\item 属性集合は表\ref{属性} に示した367属性
\item 学習文はコーパスから100対話を無作為に抽出した集合
\item テスト文は学習文と同一の話題の100対話
\end{itemize}

表\ref{標準} に、以上の条件による結果を示す。単位はF値である。表の「学
習文」の欄は、学習文とテスト文を同一にして行なったテスト(closed test)
の結果である。3種類の話題 $H_1$、$H$、$T$の中から各100対話を無作為に選
択して実験を行なった。「未知文」の欄は、未学習文に対するテスト(open
test)を意味する。学習文テスト$T$で用意した100対話と同一の集合をテスト
文にして、それに含まれない100対話をコーパスより無作為に抽出した集合で
決定木学習を行なった。また同表には比較対象として、補完内容を無作為に選
択した場合の精度を(比較A)に、補完内容をすべて最多事例の人称(<1sg>)に一
意に決定した場合の精度を(比較B)に示した。また表の最下段に、未知文テス
トにおける学習文およびテスト文の人称別省略事例数を示した。

また、未知文テストを行なうためにコーパス100対話から作成した決定木の一
部を付録の\ref{節:決定木} に示す。


\begin{table}
\begin{center}
\caption{基本条件による補完精度}
\label{標準}
\x{-10}
\begin{tabular}{cc|*{6}{r}|r}
\hline\hline
        &        &<1sg> &<1pl> &<2sg> &<2pl> & <g>  & <a>  & 全体 \\
\hline       
学習文  &$H_1$ & 99.7\% & 99.2\% &100.0\% &100.0\% &100.0\% &100.0\% & 99.8\%\\
        &$H$   & 99.9\% & 99.8\% &100.0\% &100.0\% &100.0\% & 99.6\% & 99.8\%\\
        &$T$   &100.0\% &100.0\% &100.0\% &100.0\% & 99.4\% & 99.4\% & 99.8\%\\
\hline       
未知文  &$T$   & 82.1\% & 59.5\% & 76.4\% & 15.8\% & 27.8\% & 77.0\% & 73.2\%\\
\hline       
(比較A) &      & 44.2\% & 10.0\% & 21.1\% &  3.7\% &  5.3\% & 15.7\% & 27.9\%\\
(比較B) &      & 61.3\% &  --- &  --- &  --- &  --- &  --- & 44.2\% \\
\hline\hline
(未知文)&学習  & 733  & 197  & 380  &  53  &  57  & 290  & 1710 \\
(未知文)&テスト& 745  & 168  & 356  &  62  &  89  & 265  & 1685 \\
\hline
\end{tabular}
\end{center}
\end{table}

決定木の再現性、弁別性を確認することを目的に行なった学習文テストでは、
決定木の枝刈りを行なっていないため、話題の広さに関係なくほぼ100\%の再
現性を示した。未知文に対するテストでは、(比較A)、(比較B)のいずれよりも
高い値を示し、本手法の有効性が確認された。なお、表はF値のみであるが、
再現率と適合率は共にF値とほぼ同一の値となっている。人称別では、ほぼ学
習事例の多い順に精度が良くなっていることがわかる。<1sg>、<2sg>、<a>に
関しては比較的良好な性能を得ることができたが、<1pl>、<2pl>、<g>につい
ては低い精度しか得ることができなかった。これは学習事例数の不足が一つの
原因と考えられる。

誤りの主な傾向を以下に分類する。

\begin{enumerate}
\item 複文の単文分割に関係する誤り
\item 照合範囲の誤り
\item 単複の弁別性に関係する誤り
\item 文脈省略に関係する誤り
\item タグ付与のゆれ
\end{enumerate}

これらのうち、単文分割に関係する誤りと照合範囲の誤りが最も多かった。前
述したように、本研究では接続助詞によって擬似的に単文分割しているが、例
えば以下の例文のような場合には、「行けば」だけに対して補完処理を行なっ
てしまい、提案手法が有効に機能しない(例文の下線は補完対象用言、`/'は形
態素区切り、`//'は設定した文区切りを示す)。

\begin{example}
\item どう/やっ/て//\underline{行け}/ば//いい/か/分から/ない/ん/です。
\end{example}

また単文であっても、以下の文で「予約」の補完を行なう場合のように、補完
対象の用言(「予約」)の補完に、これとは関係のない付属語(「いたす」「ま
す」)によって判断してしまい、その結果失敗する。

\begin{example}
\item 現在/ご/\underline{予約}/の/フライト日/と/便名/を/お/願い/いたし/ます 。
\end{example}

以上は本手法の問題点であるが、文分割と属性照合を共に厳密にすればよいの
で、今後十分に対処可能な課題である。

一方、単複の誤りと文脈省略に関係する誤りは本質的に難しい問題であり、現
在用意した属性のみによるこれ以上の精度向上は難しいと考えられる。より一
層の精度向上には別の情報が必要である。


\subsection{他手法との比較}
\label{節:比較}

日本語格要素の省略補完を行なう手法はこれまでにもいくつか提案されている。
ここでは、このうちのいくつかの手法と定性的な比較を行なう。

補完の手がかりとなる現象を人手で得点化した{}\cite{村田}では対話文章中
の省略のための規則も作成し、物語文を対象にした実験の結果、学習文(204文)
で86\%、未知文(184文)で76\%の省略が補完できたと報告している。同論文と
本論文との差異を以下に示す。

\begin{description}
\item[対象テキスト]
同論文では物語文中の対話文章のみを対象にしている。本論文では、これらを
含む対話テキストを対象としている。

\item[使用属性]
同論文では一人称と二人称に入りやすい用言として各3語を列挙している。ま
た命令表現と疑問表現は二人称に、ガ格の省略は一人称になりやすいと指
摘している。本論文では、命令や疑問以外の付属語や言語外情報も考慮にいれ
た補完手法を提案している。

\item[パラメータ調整]
同論文ではパラメータ(各規則に付与する得点)を人手で付与している。本論文
ではパラメータ(どの属性がどの順で使用されるか)を統計情報により自動的に
決定している。

\end{description}

Aone and Bennettは文献\cite{Aone}において、本論文と同様に機械学習による省略補完
処理を行なっている。ここでは、照応の先行詞補完の一部として省略補完処理
を行ない、合弁事業に関するテキストにおいて先行詞が組織名である省略の補
完実験を行なった結果、最高で再現率が40.8\%、適合率が73.0\%の補完精度が
得られたと報告している。同論文では先行詞の種類が所与(組織)で組織名を推
定することが目的であり、先行詞の種類(人称)補完を目的とする本論文とは問
題の性質が異なる。また対話文を対象にした補完処理ではないために文脈省略
の補完のみを考慮していることから、本論文と直接比較することはできない。

日本語対話文を対象に省略補完を行なっている研究として、文献\cite{工藤}
がある。工藤らの実験は本論文と同一のコーパスに対しても行なっており、補
完規則作成に使用した文に対する省略補完精度として93.2\%\footnote{複数の
対話コーパスに対する合計の精度。ATR旅行会話コーパスに対しては92.9\%と
報告している。}の補完精度が得られたと述べている。また文献
{}\cite{Nakaiwa}は日英機械翻訳システム評価用例文の175事例に対して
実験を行ない、情報抽出に使用した文に対してテストを行ない、100\%の精度
を得たと報告している。これら両論文はどちらも未知文に対しての報告がない。
これらを比べた時、本論文には以下の優位性があると考える。

\begin{description}
\item[規則作成の困難性]
例えば工藤らは14種類の動詞に対して人手で補完すべき値を分類しているが、
これを多くの動詞\footnote{例えば本実験で使用したコーパスには262種類の
動詞が出現した。}に対して作成するのは容易ではない。

\item[情報利用の局所性]
両論文では、ある文末表現の出現のみで、もしくは用言と文末表現の組み合わ
せのみで省略の多くを補完している。しかしながら、このような少数の要素の
みで正確に補完できるものばかりではないことが予想される。本提案手法では、
多数の属性の組み合わせを考慮できる枠組みとなっており、複雑な組み合わせ
による省略にも対応できる。

\end{description}


\subsection{表層格との関係}
\label{節:格}

ここでは、日本語の主たる表層格であるガ格、ヲ格、ニ格に対する補完精度の
比較を行なうことによって、格との関係を考察する。

本来ならば、補完に必要な属性は格によって異なると考えるのが自然である。
しかし本論文では、手法の有効性を議論し、格による差異を明確化することを
目的とするため、網羅的に属性を用意し、すべての格で学習時に同一の属性集
合を用意した。学習時に用意した属性集合は、これまでと同様、
表\ref{属性} の367属性である。

実験は、それぞれの格について300対話を学習対話とし、それらに含まれない
100対話をテスト対話として未知文テストを行なった。その結果を表\ref{格} に示す。
なお、表でガ格(動)として示した値は、表\ref{学習量} の`400(対話)'
の項と同一の実験である。


\begin{table}
\begin{center}
\caption{格による補完精度の比較}
\label{格}
\begin{tabular}{c|*{4}{c}}
\hline\hline
格        &<1sg>& <2sg> &<a> \hfill & 全体 \\
\hline
ガ格(形)&       58.3\% & 68.1\% & 85.9\% & 79.7\% \\
ヲ格    &       66.7\% & ---    & 97.7\% & 95.6\% \\
ニ格    &       95.2\% & 95.7\% & 81.9\% & 91.7\% \\
\hline
ガ格(動)&       84.7\% & 81.1\% & 82.0\% & 78.7\% \\
\hline
\end{tabular}
\end{center}
\end{table}

表からわかるように、ガ格(動)とガ格(形)との比較では全体としての補完精度
に大きな差異はないが、個別の人称に対する精度では両者に明確な差異が現れ
ている。表には現れていないが、ガ格(形)の補完人称に比較的多くの<a>が含
まれているため、<1sg>あるいは<2sg>に対する学習が十分に行なわれず、比較
的低い精度になったと推察される。

一方ヲ格については、90\%以上の省略が照応的(<a>)であり、外界省略がほと
んどないことから非常に高い数字となった。本手法によってヲ格の文脈省略の
認知は高精度で可能であるので、認知された文脈省略に対し従来から知られて
いる照応解決の諸手法を導入することによって解決できるものと考えられる。


ニ格に関しては十分な性能が得られた。このように高い性能が得られた背景に
は、二者対話を対象にしたテキストであること、話題が旅行対話に限定されて
いるために使用される述語がある程度限定されることなどが考えられる。ニ格
の多くは間接目的語で外界省略が多かった\footnote{表\ref{調査} に示すよう
に、実験で使用したコーパスではニ格の省略の約9割が外界省略で、文脈省略
<a>は1割前後であった。}ため、少数候補からの択一問題に有効な本手法が有
利に機能したものと考えられる。




\subsection{学習量との関係}
\label{節:学習量}

学習量との関係を見るために以下の実験を行なった。学習量として、25、50、
100、200、400対話の5種類の集合を作成した。ここで、これらの集合は包含関
係となるように作成した。テスト集合はこれらのいずれにも含まれない100対
話(ガ格(動)の省略数:1685)を用意した。また、学習属性は表\ref{属性} のも
のを使用した。主な人称に対する実験の結果をF値で表\ref{学習量} に示す。
なお、表の「100 (対話)」の欄は表\ref{標準} の「未知文」の欄と同一である。


\begin{table}
\caption{学習量と補完精度}
\label{学習量}
\begin{center}
\begin{tabular}{rr|*{4}{r}}
\hline\hline
対話 & 事例& <1sg>& <2sg>& <a>& 全省略 \\
\hline
 25 &  463 & 71.0\% & 55.6\% & 66.2\% & 59.0\% \\
 50 &  863 & 76.4\% & 69.7\% & 71.5\% & 67.2\% \\
100 & 1710 & 82.1\% & 76.4\% & 77.0\% & 73.2\% \\
200 & 3448 & 85.1\% & 79.8\% & 79.7\% & 76.7\% \\
400 & 6906 & 84.7\% & 81.1\% & 82.0\% & 78.7\% \\
\hline
\end{tabular}
\end{center}
\end{table}

表\ref{学習量} によれば、ほぼすべての人称に関して学習量の増加と共に性能
が単調に向上している。また、表には示されていないが、再現率、適合率共に
単調増加の傾向を示している。ただし、その増加の割合は徐々に鈍化し、
<1sg>に関しては400対話で精度がわずかに減少していることがわかる。

補完内容と学習量の差をグラフにしたものを片対数グラフで図\ref{図:学習量} に示す。
グラフが示すように、比較的学習事例数の少なかった<2pl>や<g>
が、学習量増加に伴い大きく精度が向上していることがわかる。その様子から、
<1pl>を含めたこれらの人称に関しては学習量の増加によって一層の精度向上
が予想される。

一方、その他の人称並びに全体的な精度に関しては、全体として400対話(6806
事例)でほぼ横ばいになっていることから、$10^4 \sim 10^5$事例の学習量で
十分であると言える。またグラフより、人称に関わらずほぼ一定の精度を示し
ていることから、この時の補完精度(本手法による補完精度の上限)は$80\%
\sim 85\%$となると予想する。


\begin{figure}
\vspace{-6mm}
\begin{center}
\epsfile{file=19.eps,height=88mm}
\caption{学習量と補完性能}
\label{図:学習量}
\end{center}
\end{figure}



\subsection{話題依存性}
\label{節:話題依存性}

ここでは、実験の結果と共に、決定木学習の話題依存性を議論する。学習用の
テキストとして、四つの話題$H_1$、$H_2$、$R$、$T$に属する対話を50対話無
作為に抽出し、これによって決定木学習を行なった。テスト用の対話は前節と
同一の未学習100対話を使用し、未知文テストを行なった。このとき、属性は
表\ref{属性} の367属性を使用した。表\ref{話題依存性} に、テスト対話(＝コー
パス全体)の話題別構成比、並びに話題依存性を示す。表の縦は学習対話の話
題、横はテスト対話の話題を示し、値はF値で表現した。

\begin{table}
\begin{center}
\caption{決定木の話題依存性}
\label{話題依存性}
\begin{tabular}{c|*{4}{r}|r}
\hline\hline
学習/テスト & /$H_1$ \hfil & /$H_2$ \hfil & /$H_R$ \hfil & /$R$ \hfil & 合計 \\
構成比 & 20.1\% & 27.7\% & 11.2\% & 40.9\% & 100.0\% \\
\hline
$H_1$/ & 78.1\% & 55.9\% & 65.3\% & 61.6\% & 63.7\% \\
$H_2$/ & 71.3\% & 67.0\% & 62.6\% & 62.6\% & 65.6\% \\
$R$/   & 75.1\% & 61.7\% & 61.1\% & 75.4\% & 69.9\% \\
$T$/   & 73.4\% & 62.5\% & 62.6\% & 66.2\% & 66.2\% \\
\hline
$T-H_R$/&73.7\% & 61.9\% & 59.5\% & 63.9\% & 64.8\% \\
\hline
\end{tabular}
\end{center}
\end{table}

表に示すように、学習対話とテスト対話が一致している時に、$H_2$を除いて
最も良好な性能となった。また$H_2$においてもかなり高い性能を示した。こ
の傾向は話題に関係なく言えることから、あらかじめテスト対話の話題がある
程度限定される、もしくは予測できる問題に対しては、できるだけ同一の話題
のみによって学習することが望ましく、その際にテスト対話以外の話題を含め
て学習しないことが重要であると考えられる。

学習文の話題別性能では、話題$R$が最も高い性能を示した。この理由は、話
題$R$が何か特殊な情報を持っているためではなく、話題$R$の構成比が最も高
かったためである。

また表によると、広範な話題で学習を行なった場合($T/$)に、全体としても平
均以上の補完精度を示した。学習文とテスト文の話題が同一の場合を除くと、
$T/$はすべての話題に対して良好な性能を示していることが観察される。この
ことから、テスト文の話題が未知の場合は、広範な話題に対して学習を行なう
ことが最も有効であることが示唆される。ただし表\ref{話題依存性} の最下段
に示すように、全く未知の話題($H_R$)に対しては若干精度が低下する。たと
え少量の学習であっても、未学習よりはかなり優位であることがわかる。



\subsection{属性との関係}

本節では、格要素の省略補完の問題解決にどの程度使用属性が関係するかを議
論する。これまでに述べてきた諸実験は、比較のため、すべて同一の属性集合
を使用して行なってきた。ここではこの使用属性を変化させることによって補
完精度がどうなるかを観察する。

ここでは、以下に示す4種類の属性集合を用意した。これらはいずれも表\ref
{属性} に示した属性の部分集合である。

\begin{enumerate}
\item 言語情報のみ(366属性)
\item 機能語のみ(166属性)
\item 内容語のみ(200属性)
\item 用言情報のみ(100属性)
\end{enumerate}

実験は100対話の学習、未学習100対話のテストにより行なった。この対話集合
はどちらも、表\ref{標準} の未知文テスト、あるいは表\ref{学習量} の`100'
の実験と同一である。実験結果を表\ref{結果:属性} に示す。比較対象として、
全属性に実験の結果を表の「全属性」欄に示す。


\begin{table}
\begin{center}
\caption{属性と補完率との関係}
\label{結果:属性}
\begin{tabular}{c|*{4}{c}}
\hline\hline
                &<1sg>  & <2sg> &<a> \hfill & 全省略 \\
\hline
全属性          &       82.1\%& 76.4\%& 77.0\%&  73.2\%\\
\hline
言語情報のみ&   81.9\%& 76.9\%& 77.4\%&  73.2\%\\
機能語のみ  &   75.4\%& 68.0\%& 67.2\%&  65.3\%\\
内容語のみ  &   75.1\%& 58.1\%& 74.5\%&  65.0\%\\
用言情報のみ&   72.3\%& 55.6\%& 71.1\%&  61.9\%\\
\hline
\end{tabular}
\end{center}
\end{table}


表より、言語情報のみを使用した学習では、言語外情報を加えた場合とほとん
ど同程度の精度が得られた。これは、言語外情報(特に実験で用意した話者情
報)がそれほど省略補完に重要でないことを示す。この結果は我々の予想に反
するが、おそらく旅行対話という限られた分野での実験であったため、用言の
情報が話者情報を包含するような関係になったことが理由として考えられる。
つまり用言によって話者が推測できたため、話者情報の必要性が低下した可能
性がある。これらを確認するには、両者が対等な関係にある状況での対話、例
えば自由対話に対して省略補完実験を行なうことが必要であろう。

機能語のみで決定木学習を行なった場合、全体で8\%程度の精度低下が観察さ
れた。この結果は、話題に依存しない機能語のみで決定木学習した場合に、そ
の精度に限界があることを示している。また、機能語のみの結果は文脈省略
(<a>)認知に対して大きな精度低下が見られることから、内容語は比較的照応
関係の維持に寄与していることが予想される。

内容語のみの場合はさらに低い精度となった。日本語対話文においては、内容
語よりも一部の機能語の存在によって省略が可能となる場合が多いということ
をこの結果は示している。さらに用言情報のみを使用した場合は最も悪い精度
を示したが、これは対話文の省略補完が書き言葉のそれと異なる大きな特徴の
一つと考えられる。すなわち、用言情報などの内容語は対話文での省略補完に
おいては相対的に重要性は低いが、文脈省略の先行詞補完など、照応処理に関
しては逆に重要性が増すと予想する。



\section{議論}
\label{節:議論}

決定木はある問題に対しては非常に便利な知識表現手段であるが、可読性もそ
の特徴の一つである\cite{田中}。本節では、これまでに述べた諸実験において
作成された決定木を観察することによって、属性の充足性、個々の属性の重要
性などを議論する。

\subsection{決定木の形状}

学習数と決定木の節数との関係を両対数グラフにしたものを図\ref{節数} に示
す。また各決定木の最深節と最大幅を表\ref{深さ} に示す。この図より、学習
量を変化させて作成したガ格(動)の決定木において、学習量と節数はほぼ対数
的に線形であることがわかる。本研究では決定木学習に際し枝刈りを行なって
いないため、このような関係になったものと推察される。ガ格(形)に関しては
ほぼガ格(動)と同様の節数となった。

ニ格に関しては、ガ格(動)よりはいくぶん小さな木となっていることがグラフ
よりわかる。またヲ格はほとんどが<a>であるため、ほとんど事例分割の必要
性がなく、最も小さな木となった。


\begin{figure}
\begin{center}
\epsfile{file=22.eps,height=71mm}
\caption{節数と学習数との関係}
\label{節数}
\end{center}
\end{figure}

\begin{table}
\begin{center}
\caption{各決定木の最深節と最大幅}
\label{深さ}
\begin{tabular}{l|*{6}{c}}
\hline\hline
  & ガ/25&ガ/100&ガ/400&ガ(形)&ヲ&ニ\\
\hline
  最深節までの節数 &  27 &   34 &   49 & 28 & 10 & 18\\
同一深さでの最大幅 &  26 &   58 &  146 & 52 & 10 & 28\\
\hline
\end{tabular}
\end{center}
\end{table}


\subsection{事例被覆率}

補完内容の決定に対する各属性の重要性を見る一つの尺度として、「事例被覆
率」を定義する。ある属性の事例被覆率は、その属性が決定木の意志決定に使
用されている事例数の、全事例数に対する割合である。例えば決定木の根で使
用されている属性の事例被覆率は、すべての事例がこの属性を(最初に)検査す
ることから、100\%となる。この尺度から、各属性の意志決定に対する寄与度
が数値化できる。

まず、学習量との関係を議論した{}\ref{節:学習量} 節での実験における主な
属性の事例被覆率を表{}\ref{事例被覆率/が} に示す\footnote{以後の表及び
説明では、煩雑のため\verb+:semcode+及び \verb+:regexp+の表記は省略する。}。
表の上部に示した通り、事例被覆率が100\%である属性(＝最上部で検査される
属性)は「\verb+:here 43+」つまり対象となる用言の意味コードが43(意向)で
あるかどうか、であった。この属性や「\verb+:here 41+」(思考)には共に
「思う/考える/願う」などの語が含まれており、話者の意図や希望を表現して
いる。これらの動詞は旅行対話に限らず広く使用されるため、この両属性はそ
の他の内容語とは異なる一種の機能語のような役割を果たしていると考えられ
る。

ただ、この両属性のように学習量に関係なく事例被覆率の高い属性はむしろ少
数で、同一の格、同一の話題であっても学習量の増加と共に多くの属性の事例
被覆率が変化していることが観察できる。表によると、学習量が少ない時は 
{}\verb+:before+、つまり対象となる用言以前にどのような内容語が存在した
かに関して多くの注意が注がれ、学習量の増加に伴って機能語、特に尊敬を示
す「$\cdots$てくださる」「召し上がる」などの語の存在によって人称を判断
するようになることがわかる。


\begin{table}
\begin{center}
\caption{学習量による事例被覆率の変化}
\label{事例被覆率/が}
\begin{tabular}{c|*{3}{r}}
\hline\hline
                    & ガ/25& ガ/100& ガ/400\\
\hline
\verb+:here 43+(意向)    &100.0\% &100.0\% &100.0\% \\
\verb+:here 41+(思考)    & 72.8\% & 84.8\% & 86.5\% \\
\verb+:after+ か(終助詞)& 53.1\% & 83.2\% & 66.3\% \\
\hline
\verb+:after+ てくださる   & 9.1\% & 49.1\% & 49.8\% \\
(尊敬語)             & --- & 39.9\% & 36.8\% \\
\verb+:after+ ていただく   & --- & 33.2\% & 33.9\% \\
\verb+:after+ する         & 4.1\% & 22.0\% & 26.1\% \\
\hline
\verb+:before 72+(施設)& 55.1\% & 0.5\% & 3.8\% \\
\verb+:before 94+(建物)& 28.5\% & 9.8\% & 7.7\% \\
\verb+:before 83+(言語)& 25.1\% & 1.1\% & 1.3\% \\
\hline
\verb+:speaker+        & 11.7\% & 9.1\% & 20.5\% \\
\hline
\end{tabular}
\end{center}
\end{table}


次に、格要素別の事例被覆率を表\ref{事例被覆率/格} に示す。ここでも、ガ
格(動)とガ格(形)の明確な差異が見受けられる。ガ格(形)の決定木は他の各要
素の内容、例えば「で」などの格の存在とその格要素に関する属性が多いのに
対して、一方ガ格(動)は述語と一部の重要な機能語に関する属性が多い。また
ニ格補完に作成した決定木は、一部の相違はあるもののガ格(動)と類似の傾向
を示した。

なお事例被覆率による結果では、話者の役割は我々が事前に予想したほどの重
要性を持っていないとの結果となった。これは、用言と話者役割の情報を共に
使用することによって補完内容が特定される場合を想定していたが、このよう
な例があまり多数存在しなかったため、もしくは旅行対話における二者対話と
いう制約が強く働き、話者を知る必要がないため、などの理由が考えられる。


\begin{table}
\begin{center}
\caption{格による事例被覆率の変化}
\label{事例被覆率/格}
\begin{tabular}{c|*{3}{r}}
\hline\hline
                   & ガ/400 & ガ(形) & ニ \hfill \\
\hline
\verb+:after+ ございます&  --- &100.0\% &  --- \\
\verb+:before 16+(状態)  &  5.1\% & 68.5\% &  0.5\% \\
\verb+:before 34+(陳述)  &  5.3\% & 59.0\% & 11.2\% \\
\verb+:before+ で(格助詞)        &  5.2\% & 23.9\% &  1.9\% \\
\hline
\verb+:latest+ お/ご & 46.4\% &  7.0\% &100.0\% \\
\verb+:here 43+(意向)  &100.0\% &  --- & 49.8\% \\
\verb+:here 41+(思考)  & 86.5\% &  --- & 43.5\% \\
\hline
\verb+:speaker+   & 20.5\% & 33.1\% & 28.0\% \\
\hline
\end{tabular}
\end{center}
\end{table}



\section{結論}
\label{節:結論}

日本語対話文の格要素省略に対して、決定木による補完処理の表現および機械
学習によって補完知識を獲得する手法を提案した。補完に必要な知識として、
内容語の意味属性、機能語の存在、話者知識の三種類を使用した。本論文で提
案した手法は入力として品詞付き形態素列のみを使用しており、構文解析を必
要としない。本手法により獲得した決定木で未学習文に対してテストを行なっ
た結果、ガ格とニ格に対しては十分な精度で省略された人称を補完することを
確認した。ヲ格に関しては、その補完内容が照応的であるという認知を行なう
のに有効であることを確認し、本手法の有効性を確認することができた。

また提案手法に関して、処理の有効性を学習量、話題依存性、使用属性との関
係の3点から議論した。本研究で得られた主な知見を以下にまとめる。

\begin{itemize}
\item
ガ格(動)やニ格は、尊敬を示す機能語などを重要視する。ガ格(形)は他の格要
素の情報によって補完を試みる傾向がある。
\item 
当該問題に対する学習量は全体として$10^4 \sim10^5$事例で十分である。
この時の補完精度の上限は$80\% \sim 85\%$と予想される。
\item
対話の話題が既知もしくは予測可能な時は、その話題のみによる学習が最高の
性能を示す。話題が未知の場合は、可能な限り広範な話題に対して学習するの
が最も効果的である。
\item
学習量増加に伴い、決定木は話題に依存しない機能語などの属性を採用する。
\end{itemize}

本論文では日本語対話文における格要素の補完処理に限定して述べてきたが、
提案手法の有効性はこれだけにとどまらない。例えば韓国語は日本語などと同
様に格要素の省略が観察される。韓国語などにおける省略補完処理も本手法の
応用によって可能になると考えられる。

本論文で述べた手法を今後、多言語話し言葉翻訳システムTDMT
{}\cite{TDMTmulti}の日英翻訳/日独翻訳部に組み込み、本処理が翻訳結果に
与える有効性について検討を行なう。


\vspace*{-10mm}

\y{10}
\subsection*{謝辞}

本研究を進めるにあたって、省略に関する正解データを提供していただいた
ATR音声翻訳通信研究所の荒川直哉氏、及びプログラミング、実験を担当して
いただいた同研究所の西村仁志氏に感謝する。



\begin{thebibliography}{}

\bibitem[\protect\BCAY{Aone \BBA\ Bennett}{Aone \BBA\ Bennett}{1995}]{Aone}
Aone, C.\BBACOMMA\  \BBA\ Bennett, S.~W. \BBOP 1995\BBCP.
\newblock \BBOQ Evaluating Automated and Manual Acquisition of Anaphora
  Resolution Strategies\BBCQ\
\newblock In {\Bem Proc. of 33rd Annual Meeting of the ACL}, \BPGS\ 122--129.

\bibitem[\protect\BCAY{Byron \BBA\ Stent}{Byron \BBA\ Stent}{1998}]{Byron}
Byron, D.\BBACOMMA\  \BBA\ Stent, A. \BBOP 1998\BBCP.
\newblock \BBOQ A Preliminary Model of Centering in Dialog\BBCQ\
\newblock In {\Bem Proc. of COLING-ACL'98}, \BPGS\ 1475--1477.

\bibitem[\protect\BCAY{Dohsaka}{Dohsaka}{1990}]{Dohsaka}
Dohsaka, K. \BBOP 1990\BBCP.
\newblock \BBOQ Identifying the Referents of Zero-Pronouns in Japanese based on
  Pragmatic Constraint Interpretation\BBCQ\
\newblock In {\Bem Proc. of European Conference on Artificial Intelligence
  (ECAI)}.

\bibitem[\protect\BCAY{江原, 金}{江原, 金}{1996}]{江原}
江原暉将, 金淵培 \BBOP 1996\BBCP.
\newblock \JBOQ 確率モデルによるゼロ主語の補完\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 3}  (4), 67--86.

\bibitem[\protect\BCAY{Furuse, Kawai, Iida, Akamine, \BBA\ Kim}{Furuse
  et~al.}{1995}]{TDMTmulti}
Furuse, O., Kawai, J., Iida, H., Akamine, S., \BBA\ Kim, D.-B. \BBOP 1995\BBCP.
\newblock \BBOQ Multi-lingual Spoken-Language Translation Utilizing Translation
  Examples\BBCQ\
\newblock In {\Bem Proc. of Natural Language Processing Pacific-Rim Symposium
  (NLPRS'95)}, \BPGS\ 544--549.

\bibitem[\protect\BCAY{Furuse, Sobashima, Takezawa, \BBA\ Uratani}{Furuse
  et~al.}{1994}]{ATRCorpus}
Furuse, O., Sobashima, Y., Takezawa, T., \BBA\ Uratani, N. \BBOP 1994\BBCP.
\newblock \BBOQ Bilingual Corpus for Speech Translation\BBCQ\
\newblock In {\Bem Proc. of AAAI'94 Workshop on the Integration of Natural
  Language and Speech Processing}, \BPGS\ 84--91.

\bibitem[\protect\BCAY{工藤, 友清}{工藤, 友清}{1993}]{工藤}
工藤育男, 友清睦子 \BBOP 1993\BBCP.
\newblock \JBOQ 日本語の述部の特性を用いた省略の補完機構について\JBCQ\
\newblock \Jem{電子情報通信学会論文誌}, {\Bbf J76-D-II}  (3), 624--635.

\bibitem[\protect\BCAY{村田, 長尾}{村田, 長尾}{1997}]{村田}
村田真樹, 長尾眞 \BBOP 1997\BBCP.
\newblock \JBOQ 用例や表層表現を用いた日本語文章中の指示詞・代名詞・
  ゼロ代名詞の指示対象の推定\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 4}  (1), 87--109.

\bibitem[\protect\BCAY{Nakaiwa \BBA\ Shirai}{Nakaiwa \BBA\
  Shirai}{1996}]{Nakaiwa}
Nakaiwa, H.\BBACOMMA\  \BBA\ Shirai, S. \BBOP 1996\BBCP.
\newblock \BBOQ Anaphora Resolution of Japanese Zero Pronouns with Deictic
  Reference\BBCQ\
\newblock In {\Bem Proc. of COLING-96}, \BPGS\ 812--817.

\bibitem[\protect\BCAY{大野, 浜西}{大野, 浜西}{1981}]{角川類語}
大野晋, 浜西正人 \BBOP 1981\BBCP.
\newblock \Jem{角川類語新辞典}.
\newblock 角川書店.

\bibitem[\protect\BCAY{Quinlan}{Quinlan}{1993}]{Quinlan}
Quinlan, J.~R. \BBOP 1993\BBCP.
\newblock {\Bem C4.5: Programs for Machine Learning}.
\newblock Morgan Kaufmann.

\bibitem[\protect\BCAY{Strube}{Strube}{1998}]{Strube}
Strube, M. \BBOP 1998\BBCP.
\newblock \BBOQ Never Look Back: An Alternative to Centering\BBCQ\
\newblock In {\Bem Proc. of COLING-ACL'98}, \BPGS\ 1251--1257.

\bibitem[\protect\BCAY{田中}{田中}{1995}]{田中}
田中英輝 \BBOP 1995\BBCP.
\newblock \JBOQ 動詞訳語選択のための「格フレーム木」の統計的な学習\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 2}  (3), 49--72.

\bibitem[\protect\BCAY{Walker \BBA\ Moore}{Walker \BBA\ Moore}{1997}]{Summary}
Walker, M.\BBACOMMA\  \BBA\ Moore, J.~D. \BBOP 1997\BBCP.
\newblock \BBOQ Empirical Studies in Discourse\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 23}  (1), 1--12.

\bibitem[\protect\BCAY{Walker, Iida, \BBA\ Cote}{Walker et~al.}{1994}]{Walker}
Walker, M.~A., Iida, M., \BBA\ Cote, S. \BBOP 1994\BBCP.
\newblock \BBOQ Japanese Discourse and the Process of Centering\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 20}  (2), 193--232.

\bibitem[\protect\BCAY{Yamamoto, Sumita, Furuse, \BBA\ Iida}{Yamamoto
  et~al.}{1997}]{NLPRS97}
Yamamoto, K., Sumita, E., Furuse, O., \BBA\ Iida, H. \BBOP 1997\BBCP.
\newblock \BBOQ Ellipsis Resolution in Dialogues via Decision-Tree
  Learning\BBCQ\
\newblock In {\Bem Proc. of Natural Language Processing Pacific-Rim Symposium
  (NLPRS'97)}, \BPGS\ 423--428.

\bibitem[\protect\BCAY{Yamamoto \BBA\ Sumita}{Yamamoto \BBA\
  Sumita}{1998}]{Coling-ACL98}
Yamamoto, K.\BBACOMMA\  \BBA\ Sumita, E. \BBOP 1998\BBCP.
\newblock \BBOQ Feasibility Study for Ellipsis Resolution in Dialogues by
  Machine-Learning Technique\BBCQ\
\newblock In {\Bem Proc. of COLING-ACL'98}, \BPGS\ 1428--1435.

\end{thebibliography}



\begin{biography}
\biotitle{略歴}
\bioauthor{山本 和英}{
1996年豊橋技術科学大学大学院博士後期課程システム情報工学専攻修了。
博士(工学)。
同年よりATR音声翻訳通信研究所客員研究員、現在に至る。
1998年中国科学院自動化研究所国外訪問学者。
要約処理、機械翻訳、韓国語及び中国語処理の研究に従事。
1995年 NLPRS'95 Best Paper Awards。
情報処理学会、ACL各会員。
}

\bioauthor{隅田 英一郎}{
1982年電気通信大学大学院計算機科学専攻修士課程修了。
ATR音声翻訳通信研究所主任研究員。
自然言語処理、並列処理、機械翻訳、情報検索の研究に従事。
情報処理学会、電子情報通信学会各会員。
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}





\appendix
\section{決定木の例}
\label{節:決定木}

本提案手法で作成される決定木の例を図\ref{決定木の例} に示す。この決定木
は、\ref{節:実験} 節の表\ref{標準} における「未知文」の欄の実験(補完対象:
ガ格(動)、使用属性数: 367、話題:$T$、学習対話数:100、省略数:1710)によ
り実際に作成されたものの一部である。例えば(1)に示す葉には128事例が学習
で集まり、最多要素(＝補完人称)が<1sg>であったことを示す。また、この意
志決定が行なわれるまでに、

\begin{enumerate}
\item \verb+:here 43+ (意向)--> [Y]
\item \verb+:here 78+ (社交)--> [N]
\item \verb+:after+ か(終助詞) --> [N]
\item \verb+:after+ できる --> [N]
\item \verb+:here 40+ (感覚)--> [Y]
\end{enumerate}

\noindent
という五つの属性に対して検査されてきていることを示す。ここで、属性の条
件を満たすときは[Y]、満たさない時は[N]と表記している。

形態素に関する属性にはすべて品詞情報も付与してあるが、以下に示す例では
省略した。ただし、多品詞語に対しては品詞名も表記した。また便宜のため、
内容語の意味属性に対してはそのラベル名も記した。

\begin{figure}[p]
\renewcommand{\baselinestretch}{}\large\normalsize
\centerline{\rule{140mm}{.3mm}}
\begin{verbatim}
:here 43 (意向)
|[Y]:here 78 (社交)
|   |[Y]:after ておる
|   |   |[Y]:after ので
|   |   |   |[N]:after 申し上げる
|   |   |       |[Y]:speaker 情報提供者
|   |   |       |   |[Y]--- <1pl> (4)
|   |   |       |[N]--- <1pl> (19)
|   |   |[N]:before 75 (報道)
|   |       |[Y]:before 16 (状態)
|   |       |   |[N]--- <1sg> (3)
|   |       |[N]:after ている
|   |           |[N]:before を
|   |               |[N]--- <2sg> (58) ----------------(3)
|   |[N]:after か(終助詞)
|       |[Y]:here 44 (要求)
|       |   |[Y]:latest お/ご/御
|       |   |   |[Y]--- <1sg> (9)
|       |   |[N]:before (疑問詞)
|       |       |[Y]--- <2sg> (9)
|       |       |[N]:after でしょう
|       |           |[N]--- <1pl> (5)
|       |[N]:after できる
|           |[Y]:before 15 (時間)
|           |   |[N]--- <1pl> (9)
|           |[N]:here 40 (感覚)
|               |[Y]--- <1sg> (128) ----------------(1)
|[N]:here 41 (思考)
    |[Y]:after た
    |   |[Y]:here 37 (授受)
    |   |   |[N]:before が(格助詞)
    |   |       |[N]:after できる
    |   |           |[Y]--- <a> (120) ----------------(2)
    |   |[N]:after ます
    |       |[N]:latest お/ご/御
    |           |[Y]:after たら
    |              |[N]--- <2sg> (7)
    |[N]:after か(終助詞)
        |[Y]:here 37 (授受)
        |   |[Y]:after できる
        |       |[Y]--- <1sg> (5)
        |[N]:after てくださる
            |[N]:latest お/ご/御
                |[N]:here (尊敬語)
                    |[Y]--- <2sg> (15)
\end{verbatim}
\centerline{\rule{140mm}{.3mm}}
\caption{決定木の例}
\label{決定木の例}
\end{figure}


\section{決定木学習に使用した発話の例}
\label{節:例文}

{}\ref{節:決定木} 節の例において、主な終端節点での発話の例を示す。
以下では、`/' は形態素区切りを、下線は補完対象となる用言を示す。
また、すべての形態素は正規形で表記する。

\subsection{節点(1):一人称単数 128事例}
\begin{itemize}
\item ケーブルカー/が/おもしろい/と/\underline{思う}/ます/ね/。
\item 予約/の/必要/は/ない/か/と/\underline{思う}/ます/。
\item バス/の/中/で/ご/ゆっくり/お/休む/いただける/と/\underline{思う}/ます/が/。
\item 一/泊/する/たい/と/\underline{思う}/ている/ます/。
\item その際/に/はっきり/する/た/お/答え/が/できる/か/と/\underline{思う}/ます/が/。
\item ええ/そう/だ/と/\underline{思う}/ます/。
\item 二/時間/で/終わる/と/\underline{思う}/ます/。
\item それでしたら/当ホテル/の/桔梗の間/が/ちょうど/大きい/さ/よろしい/か/と/\underline{思う}/ます/。
\item わたくし/ども/の/要望/する/会場/使用料/の/限度/を/分かる/ていただける/た/と/\underline{思う}/ます/。
\item 使いで/は/より/よい/なる/と/\underline{思う}/ます/けれども/。
\end{itemize}


\subsection{節点(2):文脈省略 120事例}
\begin{itemize}
\item はい/\underline{分かる}/ます/た/。
\item \underline{分かる}/ます/た/。
\item はい/\underline{分かる}/ます/た/鈴木/様/。
\item \underline{わかる}/ます/た/。
\item \underline{分かる}/ます/た/どうも/ありがとう/。
\item なるほど/\underline{分かる}/ます/た/。
\item そう/です/か/\underline{分かる}/ます/た/。
\item \underline{分かる}/ます/た/では/お/願う/いたす/ます/。
\item \underline{わかる}/ます/た/お/調べる/いたす/ます/。
\item だいたい/\underline{分かる}/ます/た/。
\end{itemize}


\subsection{節点(3):二人称単数 58事例}
\begin{itemize}
\item 少々/そのまま/で/お/\underline{待つ}/くださる/ます/。
\item 少々/お/\underline{待つ}/くださる/。
\item 少々/お/\underline{待つ}/くださる/ます/。
\item はい/少々/お/\underline{待つ}/くださる/ます/。
\item しばらく/お/\underline{待つ}/くださる/ます/。
\item それで/こちら/の/番号/が/ちょっと/\underline{待つ}/て
\item どうも/ありがとう/ちょっと/\underline{待つ}/てくださる/。
\item もう/少々/そのまま/で/お/\underline{待つ}/いただける/ます/か/。
\item お/部屋/の/ほう/で/少々/お/\underline{待つ}/くださる/ます/。
\item もう/少々/お/\underline{待つ}/いただける/ます/でしょう/か/。
\end{itemize}


\end{document}
