<?xml version="1.0" ?>
<root>
  <title>複数の表層的手がかりを統合したテキストセグメンテーション</title>
  <author>望月源本田岳夫	奥村学</author>
  <jabstract>一般に、テキストは複数の文から形成されており、文間には何らかの意味的なつながりがある．テキスト中の意味的にまとまったある範囲が，談話セグメントや意味段落と呼ばれる一貫性のある談話の単位を構成する．また，談話セグメント間の関係によってテキスト全体の談話構造が形成される．こうしたことから，セグメント境界の検出は，テキスト構造解析の第一歩であると考えられる．テキスト中には，セグメント境界の検出に利用できる多くの表層的手がかりが存在する．本稿では，複数の表層的手がかりを組み合わせて日本語テキストのセグメント境界を検出する手法について述べる．セグメント境界の検出は，複数の手がかりのスコアを基に各文間のセグメント境界への成り易さあるいは成り難さを表す文間スコアを計算することで行われる．文間のスコアは，各手がかりのスコアに重要度に応じた重みをかけ，この重み付きスコアを足し合わせることにより計算する．本稿では，各手がかりへの重み付けを人手によらず，訓練データを用いた統計的手法により自動的に行う手法について述べる．また複数の手がかりの中で，実際にセグメント境界の検出に有効な手がかりだけを選択することで訓練データへの過適合を避ける手法についても述べる．</jabstract>
  <jkeywords>セグメンテーション，テキスト構造，語彙的連鎖，表層的情報</jkeywords>
  <section title="はじめに">テキストは単なる文の集まりではなく，テキスト中の各文は互いに何らかの意味的関係を持つ．特に意味的関係の強い文が集まって談話セグメントと呼ばれる単位を形成する．文が互いに意味的関係を持つように，これらの談話セグメント間にも意味的な関係が存在する．テキストの全体的な談話構造はこの談話セグメント間の関係によって形成される．そのため，テキストのセグメント境界を検出するテキストセグメンテーションの研究は，談話構造解析の第一ステップであると考えられる．また，最近では，テキストセグメンテーションの研究は情報検索の分野においても応用されている．長いテキスト中には複数のサブトピックが存在しているため，テキスト全体を扱うよりも，テキストをセグメントに分けた方が検索対象として良いと考えられるためである．セグメント境界の検出では，テキスト中の表層的な情報が利用されることが多い．表層的な情報は比較的容易に抽出可能であり，特別な領域知識を必要としないので一般的な利用が可能だからである．多様な表層的情報の中で，意味的に類似した単語間の表層的関係である語彙的結束性が，これまで多くのテキストセグメンテーションの研究に使用されている．OkumuraとHondaは語彙的結束性の情報だけでは充分ではなく，他の表層的情報を取り入れることによって，テキストセグメンテーションの精度が向上することを報告している．本稿では，複数の表層的手がかりとして，接続詞，照応表現，省略，文のタイプ，語彙的結束性などを使用して日本語テキストのセグメント境界を検出する手法について述べる．セグメント境界の検出では，手がかりから得られるスコアを基に，各文間の境界へのなりやすさ(あるいはなり難さ)を表す文間のスコアを与えることが多い．この手がかりを複数設定し，組み合わせて使用する手法は数多く存在するが，各手がかりの出現がセグメント境界の検出に影響する度合が異なるため，各手がかりのスコアをそのまま使用せず，各手がかりの重要度に応じた重みをかけ，重み付きスコアの総和を文間のスコアとする手法が比較的良く用いられる．重み付きスコアの総和を文間のスコアとして使用する手法においては，各手がかりに最適な重み付けを行うことが，検出精度向上にとって重要になる．複数の表層的手がかりを用いてセグメント境界の検出を行う過去の研究では，各手がかりの重みは直観あるいは，人手による試行錯誤によって決定される傾向がある．しかし人手による重みの決定はコストが高く，決定された重みを使用することで，必ずしも最適あるいは最適に近い精度が得られるという保証がない．そのため人手による重み付けを避け，少なくとも最適に近い値を得るために，自動的に重みを決定する方が望ましいと考えられる．そこで本研究では，正しいセグメント境界位置の情報が付いた訓練テキストを用意し，統計的手法である重回帰分析を使用することで各表層的手がかりの重要度の重みを自動的に学習する．しかし，重みの自動学習手法では訓練データの数が少ない場合に学習精度が良くならないという問題がある．また，訓練データに対してパラメータ(手がかり)の数が多い場合には，学習された値が過適合を起す傾向があるという問題が知られている．学習された重みが訓練データに対し過適合すると，訓練データ以外のテキストに適用した場合には良い精度が得られない．また，考えられる全ての表層的手がかりが，常にセグメンテーションにとって良い手がかりになるとは限らない．そこで，過適合の問題を解消するために，重みの学習と共に使用する手がかりの最適化も行う必要がある．有効な手がかりだけを選択することができれば，良い重みの学習ができ，セグメンテーションの精度が向上すると考えられる．本研究で重みの学習に使用する重回帰分析には，有効なパラメータを選択する手法が既にいくつか開発されている．そこで，本研究ではパラメータ選択手法の一つとして広く利用されているステップワイズ法を使用する．重回帰分析とパラメータ選択手法であるステップワイズ法を使用することにより，有効な手がかりのみを選択し，最適な重みを獲得できると考えられる．我々の主張を要約すると以下のようになる．テキストセグメンテーションにおいて，複数の表層的手がかりの組み合わせは有効である．重回帰分析とステップワイズ法の使用によってテキストセグメンテーションにとって有効な手がかりの選択と重みの自動的な獲得が可能となる．上記の主張の有効性を調べるため，いくつかの実験を行う．小規模な実験ではあるが，実験結果から我々のアプローチの有効性を示す．以下，2節では本研究でテキストセグメンテーションに使用する表層的手がかりについて説明する．3節では複数の手がかりの重みを自動的に決定する手法について述べる．4節では自動的に有効な手がかりを選択する手法について述べる．5節では，本研究のアプローチによる実験について記述する．</section>
  <section title="テキストセグメンテーションに使用する表層的手がかり">テキスト中には，セグメント境界あるいは非境界の検出に使用できると考えられる多くの表層的な手がかりが存在する．しかし，良い結果を得るために，どの手がかりを使用するべきなのかは明らかでない．そのため我々はまず，使用可能な全ての表層的な手がかりを数え挙げる．次に，有効な手がかりを選択し，その手がかりを組み合わせることによってテキストセグメンテーションを行う．まず，本研究で用いるテキストセグメンテーション手法について説明する．ここで，文nと文n+1の間をp(n,n+1)と表わすことにする．nは1から「テキストの文数-1」の範囲を取る．各文間p(n,n+1)は，セグメント境界の候補となる．この文間ごとに，式()で表わすように，各手がかりiの重み付きスコアw_iscr_i(n,n+1)の合計スコアであるscr(n,n+1)を計算する．なお，各手がかりのスコアscr_i(n,n+1)には，初期値として0を与える．高いスコアscr(n,n+1)を持つ文間p(n,n+1)が，セグメント境界の候補として優先され，スコア順にセグメント境界として選択される．本研究では，以下の表層的手がかりを使用する．主語を表わす助詞の出現(i=1..4)．	文間p(n,n+1)の前の文(n)もしくは後の文(n+1)に，副助詞「は」も	しくは格助詞「が」が出現した場合，それぞれscr_i(n,n+1)に1を加	える．	ただしテキスト中には「は」や「が」の出現する文が多数存在し，すべて	を抽出してもあまり意味がないと考えられる．そこで後述する語彙的連鎖	を構成する自立語に付属する場合だけを考慮する．接続詞の出現(i=5..10)．	以下に示す6つの接続詞のどれかが文n+1の文頭に出現した場合，	scr_i(n,n+1)に1を加える．		「添加」型(例，しかも，そして)	「強調」型(例，むしろ，とにかく)	「説明」型(例，例えば，つまり)	「順接」型(例，ゆえに，だから)	「逆接」型(例，しかし，だが)	「転換」型(例，ところで，それでは)		接続詞の分類は所，国語文法を参照	し，機能によって著者が行った．照応表現の出現(i=11..13)．	以下に示す3つの前方照応詞のどれかが，文n+1の文頭に出現した場合，	scr_i(n,n+1)に1を加える．		「あ」型(例，あの，あんな)	「こ」型(例，この，こんな)	「そ」型(例，その，そんな)	主語の省略(i=14)．	文n+1に主語が出現しない場合，scr_i(n,n+1)に1を加える．同一タイプの文の連続(i=15..18)．	文nとn+1がどちらも同じタイプと判断される場合，scr_i(n,n+1)	に1を加える．	文のタイプは永野，福本を参照し，文末	表現を手がかり	にして9つに分類した．このうち特に客観的な事実や事象を提示する	「叙述文」および，判断や主張を強く提示する「判断文」と「断定文」の	連続を特に区別し，それ以外の文タイプの連続を「その他」として以下の	4種類に分ける．		叙述文(例，〜ている，〜ません)	判断文(例，〜に違いない，〜と判断する)	断定文(例，〜のである，〜なのだ)	その他	語彙的連鎖の出現(i=19..22)．	語彙的連鎖とは，語彙的結束性を持つ語の連続のことをいう	．	語彙的連鎖はテキスト中に存在する意味的なまとまりを示すと考えること	ができる．そこで，語彙的連鎖の情報と，	連鎖の範囲内で単語が出現しない部分であるギャップの情報を使用する．	語彙的連鎖のギャップは，その区間では一時的に別の話題に移っているこ	とを示していると考えられる．文nで連鎖が終わっているか，ギャップ	が始まる場合と，文n+1で連鎖が始まっているか，ギャップが終わって	いる場合に，それぞれscr_i(n,n+1)に1を加える．		なお，ギャップ長を1文とし，連鎖の範囲内で1文以上単語が出現し	ない場合にすべてギャップとする．		また，	語彙的結束性を持つ語をシソーラス上の同一クラスに属	する語として計算する．シソーラスには，角川類語新辞典		を使用する．語彙的連鎖内の単語につく修飾語の変化(i=23)．	文n+1で語彙的連鎖を構成する単語に付く修飾語が変化している場合，	scr_i(n,n+1)に1を加える．同一の語彙的連鎖を構成する語につく修	飾語が変化すると，これまで述べられていた話題の別の側面について述べ	ていると考えることができ，新しい話題に変化していると考えられる．上に挙げた手がかりのスコアは，各文間のセグメント境界への成り易さもしくは成り難さを示す文間のスコアを計算するために使用される．例えば，副助詞「は」の出現は，セグメント境界への成り易さを表わし，照応表現の出現や同じタイプの文の連続は，境界への成り難さを表わすと考えられる．各手がかりの出現がセグメント境界の検出に影響する度合が異なるため，各手がかりのスコアには重要度に応じた重みをかける必要がある．次節では，各手がかりへの重み付け手法を示す．</section>
  <section title="複数の手がかりへの自動的な重み付け">各手がかりに重みを付ける手法としては，少なくとも次の2つが考えられる．1つは人手による重み付けであり，もう1つは自動的な計算である．人手による重み付けの場合，各手がかりの重みは専門家による直観もしくは試行錯誤によって決定されることが多い．しかし，この作業は非常に手間がかかる上に，新しい領域のテキストをシステムが処理する場合，重みの調整を柔軟に行うことができない．また，人手によって決定された重みは客観性に欠け，最適あるいはほぼ最適な性能を引き出すという保証がない．一方，自動的な計算の場合，人手による労力を省くことができ，新しい領域への適用も容易に行える．また，決定された値が客観性を持ち少なくとも最適に近い値を得られると考えられる．このようなことから，重み付けを自動化することにはメリットがあると考えられる．本研究では，自動的な重み付けのために，正解セグメント境界の情報が付加されたテキストを用意し，訓練テキストとして使用する．各手がかりの自動的な重みの推定には，統計的手法である重回帰分析を使用する．重回帰分析は，ある変数(目的変数と呼ばれ，「結果」と考えられる)をもっとも良く推定あるいは予測するために役立つと考えられる複数の変数(説明変数と呼ばれ，「原因」と考えられる)の間に成り立つ関係式を求め，この関係式に基づいて説明変数の値から目的変数の値を予測したり，各説明変数の重要度を評価する分析手法である．関係式は，後述するように目的変数と説明変数の組を集めた観測データを基に計算される．本研究では，この目的変数が各文間の境界へのなりやすさを表すスコアに対応し，説明変数が各手がかりのスコアに対応する．また各説明変数の重要度の評価が各手がかりの重み付けに対応する．重回帰分析による重みの推定は以下のように行なわれる．訓練テキストの各文間p(n,n+1)に，次のような観測データがあるとする．ここで，Nは文間の総数，scr_ijの説明変数がI個の手がかりから得られるスコアであり，S(n,n+1)の目的変数がセグメント境界へのなりやすさを表す文間のスコアである．この観測データから次の予測式()を計算する．S(1,2)=a+w_1scr_11+w_2scr_21++w_Iscr_I1S(2,3)=a+w_1scr_12+w_2scr_22++w_Iscr_I2S(N,N+1)=a+w_1scr_1N+w_2scr_2N++w_Iscr_INeqnarrayここでaは定数項であり，w_1,,w_Iは回帰係数と呼ばれる．次に，予測式()のS(1,2),,S(N,N+1)と観測データ(表)のS(1,2),,S(N,N+1)との誤差を最小2乗法により最小にする．すなわち，を計算し、式()が最小となるaおよびw_1,,w_Iを定め、それを推定された回帰係数とする．この回帰係数が各手がかりに対して決定された重みに対応することから，本研究でパラメータとして設定する手がかりの重み付けに重回帰分析を利用することができる．重回帰分析を使用して各手がかりに対する最適な重みを決定するためには，セグメント境界のS(n,n+1)には高い値を与え，逆に境界にならない文間のS(n,n+1)には低い値を与える必要がある．仮に各S(n,n+1)に実際のテキストの現象を反映した良い値を与えることができれば，より最適な性能を引き出すことができると考えられる．しかし，本研究で訓練データとして使用するテキストには正解境界位置の情報しか付加されていない．そこで正解境界のS(n,n+1)には10を与え，非境界のS(n,n+1)には-1を与えて重回帰分析を適用する．これらの値は，S(n,n+1)への値の与え方を4通りの組み合わせで行った予備実験の結果から選択した．関連研究として，が挙げられる．Watanabeはテキスト中の重要な文を選択することによる新聞記事の要約生成を行っている．重要文の選択のために，文の表層的特徴の重み付けを行い，重みの決定に重回帰分析を使用している．Watanabeの研究では，訓練テキストの各文のSに人間の被験者たちが重要であると判断した度合を与えている．本研究ではSに対して同様の方法で値を与えることはしていない．訓練テキストの各文間について，セグメントへの成り易さ，成り難さを人間の被験者が判断することは，非常に困難でコストが高過ぎるためである．</section>
  <section title="有効な手がかりの自動選択">セグメンテーションにとって，節で挙げた表層的手がかりが実際にどの程度有効かは明らかでない．有効でない手がかりを含めて重回帰分析で重みを計算すると悪影響の原因となる．そのうえ，訓練データの量に比べて，表層的手がかりが多過ぎる場合には，過適合の問題が発生する．一方，節で設定した手がかり全体の中から有効な手がかりだけを選択できれば，良い重みが決定できセグメンテーションの精度も向上すると考えられる．しかし，有効な手がかりを選択するには手がかりの有効度を計算する客観的な基準が必要になる．この客観的な基準の設定は難しい問題であるが，幸いにも，本研究で重みの計算に使用する重回帰分析では，多くのパラメータ選択手法が既に開発されている．そこで本研究では，パラメータ選択手法の一つで，もっとも一般的なステップワイズ法と呼ばれるパラメータ選択手法を用いる．ステップワイズ法は，後述するアルゴリズムにより，重回帰モデルに加えることで良い推定ができると判断されたパラメータを加え，逆に別のパラメータが加えられたことにより，良い推定に役立たなくなったと判断されたパラメータを除去するという処理を繰り返し，最終的に有効なパラメータの組を選択する．パラメータの追加および削除の際に一般的に使用される判断基準は，各パラメータの重みw_iについて個別に計算したF値に基づくものである．この個別のF統計値は以下の式で与えられる．ここでSE(w_i)は標準誤差と呼ばれw_iの標準偏差を表す．この統計量の分布は自由度(p,n-p-1)のF分布に従う(pはパラメータの数，nはデータの数を示す)．よってF_0&gt;=F_(p,n-p-1)()ならば，有意水準でパラメータiは有効であると判断される．ただし，この基準値F_(p,n-p-1)()の計算が複雑であるため，一般的にはパラメータを追加する時の基準値をF_inとし，パラメータを除去する時の基準値をF_outとして，それぞれに定数,F_outの値は，1.0から4.0までの範囲から選んで与えるのが一般的であり，重要なパラメータを削除しないことに重点を置くなら小さい値，無駄なパラメータを取り込まないことに重点を置くなら大きな値を指定する．本研究ではF_in,F_outともに1.2を与えている．を与えてパラメータ選択を行う．ステップワイズ法のアルゴリズムは次のようになる．ステップ1.=重回帰モデルに何もパラメータが含まれていない状態から開始ステップ2.=if(すべてのパラメータが含まれている)&gt;=取り込むパラメータはない．ステップ3へ&gt;else&gt;=残りのパラメータを1つづつ順番に採用し，F値を計算．&gt;&gt;F値最大のパラメータを選ぶ．&gt;&gt;if(F値&gt;F_in)&gt;&gt;=そのパラメータを取り込む．ステップ3へ&gt;&gt;else&gt;&gt;&gt;取り込むべきパラメータはない．ステップ3へステップ3.=モデルに含まれているパラメータについてF値を計算．&gt;F値最小となるパラメータを選ぶ&gt;if(F値&gt;F_out)&gt;=if(取り込むべきパラメータがない)&gt;&gt;=終了&gt;&gt;else&gt;&gt;&gt;ステップ4へ&gt;else&gt;&gt;そのパラメータをモデルから取り除きステップ3へステップ4.=if(すべてのパラメータが取り込まれている)&gt;&gt;終了&gt;else&gt;&gt;ステップ2へtabbingステップワイズ法以外に良く利用される手法として，変数増加法と変数減少法があるが，変数増加法では，一度採用されたパラメータは除去されることがなく，変数減少法では，一度除去されたパラメータは採用されることがないという問題がある．ステップワイズ法は両手法の問題点を改良した手法であるため，他の手法よりも良いパラメータ選択ができると考えられる．</section>
  <section title="実験">これまでに述べた本研究の主張は以下のように要約できる．テキストセグメンテーションにおいて，複数の表層的手がかりの組み合わせは有効である．重回帰分析とステップワイズ法の使用によってテキストセグメンテーションにとって有効な手がかりの選択と重みの自動的な獲得が可能となる．本節では，本研究のアプローチの有効性を確かめるための実験を行う．実験には，日本語の国語の問題集から意味の切れ目を問う問題に使用された14テキストを使用する．問題は例えば，『次の文章を意味的に3つの部分に分けるとしたらどこで切れるか．境界になる個所を答えなさい』というようなものである．システムの性能はシステムの出力と問題集の解答を比較することで計算する．実験に使用する14テキストの平均境界候補数は20(12から47)であり，平均正解境界数は3.4(2から6)である．なお，以下の理由から，実験の正解として形式段落を使用していない．実験に使用する問題集のテキストのほとんどは，形式段落を示す字下げの情報をあらかじめ消してあり利用できないため．日本語のテキストの場合，形式段落の境界が必ずしも意味的な境界と一致するとは限らず，修辞的理由から形式段落に分けられる場合がしばしばあるため．実験では，システムは各文間のスコアscr(n,n+1)を値の高い順に出力する．システムの出力の上位10%,20%,30%および40%における精度を評価する．評価尺度には，再現率(Recall)と適合率(Precision)を使用する．Recallは全正解境界の内，システムによって正しく検出された境界の割合を示す．Precisionはシステムが境界と検出した候補の内，実際に正解境界であるものの割合を示す．RecallとPrecisionは次式で表わされる．実験は以下の6通りについて行う．語彙的連鎖の手がかり以外の手がかりによる実験．	手がかり1から18および23を使用．語彙的連鎖の手がかりのみを使用した実験．	手がかり19から22を使用．節で挙げた全ての手がかりを使用した実験．	重みの決定は人手によって行う．節で挙げた全ての手がかりを使用した実験．	重みの決定は重回帰分析によって自動的に行う．	重回帰分析では，14テキストを2テキストづつ7グループに分け，6グルー	プを訓練テキストとして使用し，残りの1グループを評価テキストとして	使用する．評価用のテキストを変えることにより，7回のクロスバリデー	ションを行い平均値で評価する．ステップワイズ法により選択された手がかりのみを使用した実験．	節で述べたように，訓練テキスト内で有効な手がかりの	選択にステップワイズ法を使用する．手がかりの選択以外の手続きは全て	4番目の実験と同じである．5人の被験者による実験．	5人の被験者に対し，システムと同様の14テキストについて，セグメント	境界位置を問う問題を解かせる．解答数は問題集の正解数を下限とし，そ	れ以上であれば，被験者が自由に選んで良いとする．	この実験により，テキストセグメンテーション実験の精度の上限の算出	を試みる．この実験の結果によってセグメンテーションタスクの難易度が	示されると考えられる．全ての実験結果を図とおよび表に示す．2つの図は14テキストに対するシステムの平均精度を示す．表は5人の被験者によるセグメンテーション実験の結果を示す．表がこのタスクにおける精度の上限を表すと考えられる．また，下限についても計算している(図の``lowerbound'')．下限はシステムがランダムにセグメント境界候補を選択した場合を考えることで計算することができる．この場合，precisionは各境界候補が正解になる平均確率と同じであり，recallは出力の割合と同じである．図では語彙的連鎖以外の手がかりによる実験(``ex.1'')，語彙的連鎖のみの手がかりによる実験(``ex.2'')および，設定した全ての手がかりによる実験(``ex.3'')の精度を比較している．結果から複数の手がかりを組み合わせて使用した``ex.3''が良い精度を引き出すことがわかる．また，語彙的連鎖が有効な手がかりである可能性が示されているといえる．図は複数の手がかりを使用し，人手によって重みを与えた実験(``ex.3'')と訓練テキストにより自動的に計算された重みを使用した実験(``ex.4.test'')との比較をしている．結果から自動的に学習された重みが概ね良い精度を出すことが示されている．人手による手間を省き，客観的な値が得られることから，自動的な重み付けは人手による重み付けよりも良い手法であるといえる．図では，全ての手がかりを使用して自動的に重みを決定した場合(``ex.4.test'')と選択された手がかりのみを使用して自動的に重みを決定した場合(``ex.5.test'')の比較も行っている．結果から有効な手がかりを選択することで良い精度を引き出していることがわかる．この結果は本研究で使用したパラメータ選択手法によって訓練テキストへの重みの過適合の問題が解消されていることも示している．実験4と実験5では訓練テキストによる結果と評価テキストによる結果の差が異なる．パラメータ選択を行う``ex.5.training''と``ex.5.test''の差は，パラメータ選択を行わない``ex.4.training''と``ex.4.test''の差よりも小さい．今回の実験(実験5)では，平均7.4の手がかりが選択され，選ばれた手がかりは訓練セットごとに異なっていた．その中で常に選択された手がかりは，逆接の接続詞(節の手がかり9)と語彙的連鎖の手がかり(手がかり19と20)であった．また重回帰分析のような統計的手法では，パラメータの選択で個々のパラメータ(手がかり)が有効かどうかを検定した場合と同様に，得られた重回帰式全体が実際に予測に役立っているかどうかを検定する必要がある．本研究で計算された各重回帰式について，F分布に基づく検定を行ったところ，有意水準が0.05から0.1の範囲で重みの推定に役立っているという結果を得た．さらに，同様の実験として，問題集の正解を使用せず，被験者による実験(実験6)で被験者の過半数(3人)以上がセグメント境界であると判断した位置を正解とした実験も行った．この場合正解境界数は平均で3.5(2から6)であった．実験の結果，システムはこちらの実験においても問題集の正解と同様な精度を得た．関連研究としてLitmanandPassonneauの研究が挙げられる．彼らも複数の手がかりを使用したテキストセグメンテーション手法を提案している．LitmanとPassonneauのモデルでは機械学習ツールを使用してspokennarrativeコーパスから訓練を行っている．彼らの研究との厳密な比較は困難であるが，本研究のタスクにおける精度の上限が彼らのタスクの場合に比べて低いことから，本研究のタスクの方がより難しいと考えられる．そのため我々のシステムの精度が彼らのものに比べて低いとは必ずしもいえない．</section>
  <section title="おわりに">本稿では，複数の表層的手がかりを使用して，テキストのセグメント境界を検出する手法について述べた．複数の表層的な手がかりを組み合わせて使用し，各手がかりへの重みを自動的に決定することがテキストセグメンテーションにとって有効であると考えられる．さらに，重回帰分析とステップワイズ法を使用することで過適合を防ぎつつ，各手がかりへの自動的な重み付けをする手法を示した．本研究の実験は小規模ではあるが，主張の有効性を示す結果を得ることができた．今後大規模なデータセットを使用して実験を行う必要がある．複数の表層的手がかりを使用するテキストセグメンテーションのアプローチとしては，本研究で使用した手がかりのスコアの重み付き総和を用いる手法以外に，C4.5のような，境界/非境界をクラスとし，各手がかりから決定木を学習して分類を行う決定木学習の手法が考えられる．今後両方のアプローチの比較をしていく必要がある．今後の課題として，訓練テキストをクラスタリングし，手がかりの重み計算をテキストのグループごとに行う手法の実験を計画をしている．テキスト間にはさまざまな違いが存在する．例えば，著者の違い，文体の違い，ジャンルの違いなどである．訓練テキストをクラスタリングし，特徴の類似したテキストのクラスタごとに手がかりの重みを計算することで，訓練テキスト全体を使用する場合よりも良い重み付けが可能になると考えられる．結果としてセグメンテーションの精度向上も期待できる．音声認識の分野では，言語モデルの精度向上のために，訓練データのクラスタリングが行われ，自動学習手法における有望な手法と考えられている．</section>
</root>
