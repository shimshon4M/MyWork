



\documentstyle[epsf,jnlpbbl]{jnlp_j}

\setcounter{page}{3}
\setcounter{巻数}{2}
\setcounter{号数}{3}
\setcounter{年}{1995}
\setcounter{月}{7}
\受付{1995}{5}{6}
\再受付{1995}{7}{8}
\採録{1995}{9}{10}

\setcounter{secnumdepth}{2}

\title{文末から解析する統計的係り受け解析アルゴリズム}
\author{関根 聡\affiref{NYU} \and 内元 清貴\affiref{CRL} 
  \and 井佐原 均\affiref{CRL}}

\headauthor{関根 聡・内元 清貴・井佐原 均}
\headtitle{文末から解析する統計的係り受け解析アルゴリズム}

\affilabel{NYU}{ニューヨーク大学 コンピュータサイエンス学科}
{Computer Science Department, New York University}
\affilabel{CRL}{郵政省通信総合研究所}
{Communications Research Laboratory, Ministry of Posts and Telecommunications}

\jabstract{
係り受け解析は日本語文解析の基本的な方法として認識されている．
日本語の係り受けは，ほとんどが前方から後方であるため，
解析は文末から文頭の方向へ解析を進める事は効率的であり，
これまでもルールベースの解析手法ではいくつかの提案がある．
また，統計的文解析は英語，日本語等の言語を問わず数多くの提案があり，
その有効性が確認されている．
本論文では，上記の二つの特徴を兼ね備えた日本語文係り受け解析を
提案し，その実験結果を示し，有効性を実証する．
システムの精度は，正しい文節解析ができた所から開始した場合，
京大コーパスを使用した実験で係り受け正解率が87.2\%，
文正解率が40.8\%と高い精度を示している．
ビームサーチのビーム幅を調整した実験では，ビーム幅を小さくする
事による精度の劣化が認められなかった．
実際にビーム幅が1の際に得られた結果の95\%は
ビーム幅20の時の最良の結果と同一であった．
また，N--best文正解率を見た時には，Nが20の時には
78.5\%という非常に高い結果を示している．
解析速度は，解析アルゴリズムから推測される通り，
文節数の2乗に比例し，平均0.03秒(平均文節数10.0)，
最長文である41文節の文に対しては0.29秒で解析を行なった．
}

\jkeywords{係り受け解析，構文解析，統計的手法，最大エントロピー法}

\etitle{Statistical Dependency Analysis using Backward Beam Search}
\eauthor{Satoshi Sekine\affiref{NYU} \and Kiyotaka Uchimoto\affiref{CRL}
  \and Hitoshi Isahara\affiref{CRL}} 

\eabstract{
Dependency analysis is regarded as a standard method
of Japanese syntactic analysis.
As dependencies normally go from left to right,
it is effective to parse from right to left, 
as we can analyze predicates first.
There have been several proposals for such methods 
using rule based parsing.
In this paper, we will propose a Japanese dependency analysis
which combines right to left parsing and a statistical method.
It performs a beam search, an effective way of limiting the
search space for right to left parsing.
We get a dependency accuracy of 87.2\% and 
a sentence accuracy of 40.8\%
using the Kyoto University corpus.
Varying the beam search width,
we observed that the best performances were achieved when
the width is small.
Actually, 95\% of the sentence analyses obtained with
beam width=1 were the same as the best analyses with
beam width=20.
The N--best sentence accuracy for N=20 was 78.5\%.
The analysis speed was proportional to the square of 
the sentence length (number of segments), 
as predicted for the algorithm.
The average analysis time was 0.03 second (average sentence length
was 10.0) and it took 0.29 second to analyze
the longest sentence, which has 41 segments.
}

\ekeywords{dependency analysis, parser, statistical method, maximum entropy}


\begin{document}
\maketitle


\section{はじめに}

係り受け解析は日本語文解析の基本的な方法として認識されている．
日本語係り受けには，主に以下の特徴があるとされている
\footnote{もちろん，例外は存在するが\cite{sshirai:jnlp98}，
その頻度は現在の解析精度を下回り，現状では無視して構わないと考える．
つまり，これらの仮定の基に解析精度を向上させた後に，
そのような例外に対し対処する手法を考えればよいのではないかと思う．
また，(4)の特徴はあまり議論されてはいないが，
我々が行なった人間に対する実験で
90\%以上の割合で成立する事が確認された．}．
我々はこれらの特徴を仮定として採用し，解析手法を作成した．
\begin{itemize}
\item[(1)] 係り受けは前方から後方に向いている．(後方修飾)
\item[(2)] 係り受け関係は交差しない．(非交差条件)
\item[(3)] 係り要素は受け要素を一つだけ持つ．
\item[(4)] ほとんどの場合，係り先決定には前方の文脈を必要としない．
\end{itemize}
このような特徴を仮定した場合，解析は文末から文頭に向けて行なえば
効率良く解析ができると考えられる．
以下に述べる二つの利点が考えられるためである．
今，文節長Nの文の解析において
M+1番目の文節まで解析が終了していると仮定し，現在M番目の
文節の係り先を決定しようとしているとする(M$<$N)．
まず，一つ目の利点は，M番目の文節の係り先は，
すでに解析を終了しているM+1番目からN番目の文節の
いずれかであるという事である．
したがって，未解決な解析状態を積み上げておく必要はないため，
チャートパーザーのように活性弧を不必要に多く作る必要はないし，
一般的なLRパーザー等で利用されているような
スタックにそれまでの解析結果を積んで後の解析に依存させるという事
をしなくて済む．
別の利点は，M番目の文節の解析を開始する時点には，
M+1番目からN番目の係り受け解析はなんらかの形式
において終了しており，
可能な係り先は，非交差条件を満足する文節だけに絞られるという事である．
実験では，この絞り込みは50\%以下になり，非常に有効である．
また，この論文で述べる統計的手法と文末からの解析手法を組み合せると，
ビームサーチが非常に簡単に実現できる．
ビームサーチは解析候補の数を絞りながら解析を進めていく手法である．
ビーム幅は自由に設定でき，サーチのための格納領域はビーム幅と
文長の積に比例したサイズしか必要としない．

これまでにも，文末からの解析手法はルールベースの係り受け解析において
利用されてきた．例えば\cite{fujita:ai88}．
しかし，ルールベースの解析では，規則を人間が作成するため，
網羅性，一貫性，ドメイン移植性という点で難がある．
また，ルールベースでは優先度を組み入れる事が難しく，
ヒューリスティックによる決定的な手法として利用せざるを得なかった．
しかし，本論文で述べるように，文末から解析を行なうという手法と
統計的解析を組み合せる事により解析速度を落す事なく，
高い精度の係り受け解析を実現する事ができた．

統計的な構文解析手法については，英語，日本語等言語によらず，色々な
提案が80年代から数多くあり
\cite{fujisaki:coling84} \cite{magerman:acl95} \cite{sekine:iwpt95} 
\cite{collins:acl97} \cite{ratnaparkhi:emnlp97}
\cite{shirai:emnlp98} \cite{fujio:emnlp98}
\cite{sekine:nlprs97}  \cite{haruno:nlpsympo97}  \cite{ehara:nlp98}，
現在，英語についてはRatnaparkhiのME(最大エントロピー法)を利用した
解析が，精度，速度の両方の点で最も進んでいる手法の一つと
考えられている．
我々も統計的手法のツールとしてMEを利用する．
次の節でMEの簡単な説明を行ない，その後，解析アルゴリズム，
実験結果の説明を行なう．

\section{最大エントロピー法の利用}

最大エントロピー法(ME)は，トレーニングデータ中の素性の頻度等の
情報から特徴的な素性を学習し，その特徴を生かした確率的なモデルを作成する
方法である．
素性とは，我々の場合，二つの文節間の係り受けの確率を計算するための
情報であり，そこで使用される基本素性には表~\ref{素性}に挙げた種類の素性を
利用した．括弧内の数字は素性値の数である．
\begin{table}[tbh]
\begin{center}
\caption{素性}
\label{素性} 
\begin{tabular}{|l|l|}
\hline
前文節/後文節 & 主辞見出し(2204)，品詞(34)，活用情報(90)，\\
              & 語形情報(218)，助詞の細い情報(135)，      \\
              & 句読点，括弧の情報(31)                    \\
\hline
文節間情報    & 距離(3)，読点，括弧の有無(6)，「は」の有無(2)，\\
              & 前文節と同じ素性を持つ物の有無等(127) \\
              & 後文節と同じ素性を持つ物の有無等(220) \\
\hline
\end{tabular}
\end{center}
\end{table}
また，これらの素性を組合せた組合せの素性も利用した．
その数は約4万個である．
素性の詳細，および素性の選択による比較実験については
\cite{uchimoto:nlken98}を参照されたい．

そして，テストの際には，トレーニングデータを使用して学習されたモデルを基に
テスト文中に与えられた二つの文節の素性から
その二つの文節の係り受けの確率を計算する．
これまでの多くの先行研究と同様にすべての係り受けは独立であると仮定し，
一文全体の係り受け確率を，その文中にあるそれぞれの係り受けの確率の積で表す．
そして，一文全体の確率が最大となるような係り受け関係が正しい係り受け
関係であると仮定する．

\section{解析アルゴリズム}

この章では，解析アルゴリズムを紹介する．
まず，例を利用して，概略を説明し，その後フォーマルな形で
解析アルゴリズムを示す．
特徴は文末から文頭に向けての係り受け解析と
確率を利用したビームサーチにある．
例には以下の入力文を用いる．文節解析まで終っていると仮定しており，
文節の区切は''$|$''で示される．
説明図において，文節の係り先は，
それぞれの文節の下にある番号で示される．
\begin{verbatim}
-----------------------------------------------------------
<初期状態>
ID     1       2       3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
-----------------------------------------------------------
\end{verbatim}
\begin{flushleft}
\underline{解析手順}
\end{flushleft}
\begin{enumerate}
\item[(1)] {\bf 文末から二つ目の文節} \\
  文末の文節は係り先はなく，文末から二つ目の文節は必ず文末の
  文節にかかる．この結果は以下のようになる．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から二つ目まで>
ID     1       2       3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補                                   6        -
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[(2)] {\bf 文末から三つ目の文節} \\
  この文節(「作り，」)は，係り先として二つの文節が考えられる．
  一つは「彼女に」であり，もう一つは「贈った」である．
  MEを利用して計算された確率を付与した二つの解析候補を
  作成する．(それぞれの確率は0.1，0.9としてあり，
  各候補の最後には，総合の確率(各係り受けの確率の積)を
  括弧の中に示す．)
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から三つ目まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1                          6       6        -    (0.9)
候補2                          5       6        -    (0.1)
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[(3)]  {\bf 文末から四つ目の文節} \\
  それぞれの候補に対して，「パイを」の文節の係り先を求める．
  候補1に対しては，非交差の条件から「パイを」の文節は「彼女に」
  の文節に係る事はありえない．したがって「パイを」が「作り，」と
  「贈った」のそれぞれに係る候補を作成する．
  候補2についても同様にする．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文末から四つ目まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1                  4       6       6        -    (0.54)
候補2                  6       6       6        -    (0.36)
候補3                  4       5       6        -    (0.05)
候補4                  6       5       6        -    (0.04)
候補5                  5       5       6        -    (0.01)
-----------------------------------------------------------
\end{verbatim}
\begin{enumerate}
\item[]
  このように計算していくと，候補の数は文頭に行くにしたがって
  増えていく．しかし，
  解析途中の候補の数に上限を設けて，ビームサーチを行なえば，
  解析候補数の爆発は防げる．
  また，上記の例から直感的に分るように，
  その場合でも解析精度の悪化も少なく抑えられる．
  実際の実験で得られたビーム幅と精度のデータは次章で紹介する．
  例えば，この例でビーム幅を3とすると，候補4と候補5は
  この段階で捨てられ，以降の解析には使用されない．
\item[(4)] {\bf それ以降} \\
      上記で示したような解析を文頭まで繰り返す．
      例えば，ビーム幅を3とした場合の解析結果は以下のようになる．
\end{enumerate}
\begin{verbatim}
-----------------------------------------------------------
<文頭まで>
ID     1        2      3       4       5        6
      彼は，| 再び | パイを | 作り，| 彼女に | 贈った．
候補1  6        4      4       6       6        -    (0.11)
候補2  4        4      6       6       6        -    (0.09)
候補3  6        4      6       5       6        -    (0.05)
-----------------------------------------------------------
\end{verbatim}

以下にフォーマルな解析アルゴリズムを示す．
\begin{verbatim}
----------------------------------------------------------------
Length: 入力文節長
Input[Length]: 入力文
N: ビーム幅
Cand[Length][N]: 解析結果候補 (各文節の係り先文節IDの配列で表される)
             例えばCand[1][1]={6,4,4,6,6,-}．この方法では，必要な
             メモリのサイズは文長とビーム幅の積以上になるが，簡単な
             変換で，上記のサイズに納める事ができる．

add(l,cand) : cand(解析結果候補)の確率がl番目の文節の解析結果候補の
             内のN番目のものより良い場合は，candをCand[l]の解析候補
             に加える．この際，N+1番目の候補になった物は捨てられる．
get(l)      : Cand[l]の候補群から候補を取り出す．候補がなければNULL
             を返す．
ins(i,cand) : iをcandの先頭に追加する．

procedure 係り受け解析 begin

  add(Length-1,{Length,-});

  for(i=Length-2;i>=1;i--) begin

    while((cand = get(i)) != NULL) begin

      for(j=i+1;j<=Length;j++) begin

        if(iからjへの係り受けがcandにおいて有効)

          add(i,ins(j,cand));

        endif
      end
    end
  end
end
----------------------------------------------------------------
\end{verbatim}
このアルゴリズムの解析時間オーダーは，文節数の2乗であり，
ビーム幅をNとすると，ビーム幅に対しNlog(N)であると推測される．

\section{実験結果}

この章では，係り受け解析の実験を色々な角度から分析する．
実験に用いたコーパスは，京大コーパス(Version 2)
\cite{kurohashi:nlp97} の一般文の部分で，
基本的にトレーニングには1月1日と1月3日から8日までの7日分(7960文)，
試験には1月9日の1日分(\mbox{1246}文)を用いた．
試験は頻繁に行なうと，高い成績を追及する結果
その試験のデータに自然とチューニングされて
しまう危険性があるので，頻繁に行なわないようにした．

\subsection{実験結果}

まず最初に，我々の結果を示し，他の手法の結果との比較を行なう．
それ以降の節では，我々の実験内で得られた興味深いデータを紹介する．

まずは，我々の解析結果を表~\ref{Result}に示す．
京大コーパス1月9日の\mbox{1246}文に対して，形態素解析，文節区切認定まで
終った状態から文節間係り受けの解析を決定的に(ビーム幅=1)
行なった結果である．
\begin{table}[tbh]
\begin{center}
\caption{解析結果}
\label{Result} 
\begin{tabular}{|l|l|}
\hline
係り受け正解率(文末から二つ目の文節も含める) & 87.14 \% (9814/11263) \\
係り受け正解率(文末から二つ目の文節を除く)   & 85.54 \% (8575/10024) \\
文正解率(文全体の解析が正しい割合) & 40.60 \% (503/1239)   \\
平均解析時間(一文当り)             & 0.03 秒 \\
\hline
\end{tabular}
\end{center}
\end{table}
また，文節数と係り受け正解率の関係を図~\ref{LengthAndAccuracy}に示す
(文節数28以上は，それぞれデータ数が1なので図に載せていない．)．
図から分るように，文節数の増加に伴なう精度の劣化は比較的に
小さいと考えられる．
日本語の係り受けは多くの場合，係り元と係り先以外の大域的な
情報を利用せず，局所的な情報のみで決められる事が多いので，
文が長くなっても係り受け正解率の劣化があまり見られないのは
納得できる．
\begin{figure}[htbp]
\beginpicture
\setcoordinatesystem units <6pt,180pt>
\setplotarea x from 0 to 30, y from 0 to 1

\axis bottom label {文節数}
      ticks short quantity 7 numbered at 0 10 20 30  /  / 
\axis left   label {係り受け正解率}
      ticks short quantity 11 numbered at 0 0.2 0.4 0.6 0.8 1.0 /  /

\multiput {*}   at 
3 0.9375   4 0.9444   5 0.9089   6 0.8945
7 0.9014   8 0.8977   9 0.8812   10 0.8880
11 0.8639   12 0.8742   13 0.8605   14 0.8778
15 0.8777   16 0.8474   17 0.8415   18 0.8529
19 0.8360   20 0.8368   21 0.8346   22 0.8214
23 0.8591   24 0.8385   25 0.7986   26 0.8640
27 0.8205   28 0.9185   /

\setlinear \plot
3 0.9375   4 0.9444   5 0.9089   6 0.8945
7 0.9014   8 0.8977   9 0.8812   10 0.8880
11 0.8639   12 0.8742   13 0.8605   14 0.8778
15 0.8777   16 0.8474   17 0.8415   18 0.8529
19 0.8360   20 0.8368   21 0.8346   22 0.8214
23 0.8591   24 0.8385   25 0.7986   26 0.8640
27 0.8205   28 0.9185   /

\put {0.8714} at -10 0.8714

\multiput {-} at
-7 0.8714 *37 1 0 /

\endpicture
  \caption{文節数と係り受け正解率}
  \label{LengthAndAccuracy}
\end{figure}

\subsection{他の手法との比較}

この節では他の手法との比較を行なう．
他の手法においては同じコーパスを使って評価した物がないため，
その精度は参考として載せる．同じプラットフォームで同じ評価方法を用いた
比較が望まれる．


\begin{flushleft}
\underline{白井およびKNPとの比較}
\end{flushleft}

白井\cite{shirai:jnlp98:1}は構文規則に基いた確率一般化LR法を
提案している．
構文および語彙的な統計情報を用い，その学習にはMEを利用している．
実験では京大コーパスの文節数7〜9の文から
ランダムに選んだ500文の内，KNPによる文節区切がコーパスと
一致した388文を対象に，白井の解析結果とKNPの解析結果の
正解率を比較している．
(KNPについては\cite{kurohashi:snlr94}を参照の事．)
そこで，我々の試験コーパスの中で文節数が7〜9の文，279文における
結果を用いて比較した(表~\ref{CompShiraiKNP})．
すべて，文末から二つ目の文節は評価から除いており，白井の方法も
文節切りができた状態からの解析である．
\begin{table}[tbh]
\caption{白井，KNPとの比較}
\label{CompShiraiKNP} 
\begin{center}
\begin{tabular}{|l|c|}
\hline
システム    &  係り受け正解率 \\
\hline
白井        &   84.53 \%  \\
KNP         &   90.76 \%  \\
本手法      &   87.41 \%  \\
\hline
\end{tabular}
\end{center}
\end{table}
対象の文が完全に一致しておらず，対象の文の選択の方法も異なるので，
参考にしかできないが，この文長の文に対しては，
白井の手法に比較して3\%程度良い結果を，
KNPと比較した場合には3\%程度悪い結果を得た．
白井の実験では，EDRコーパス，RWCコーパスを利用し，
トレーニングデータとしては我々よりも大きなデータを利用している．
また，白井はランダムに選んだ500文については84.34\%という
解析結果を示している．
KNPは，この評価で使用したテストコーパスに基づいて改良されており，
KNPの評価結果は，トレーニングデータに対するものと言う事ができる．

\begin{flushleft}
\underline{藤尾，春野との比較}
\end{flushleft}

藤尾\cite{fujio:emnlp98}は文節間の属性の共起頻度による統計的解析手法を提案した．
また，春野\cite{haruno:nlpsympo97}は決定木およびブースティングを利用した
係り受け解析を行なっている．
これらの評価はＥＤＲコーパスを利用し，試験対象データの選択手法も
我々とは異なっているため，直接的な評価は難しい．
彼等の場合は，形態素解析から解析を行なっているが，評価には
文節区切が正しい物のみを利用したり，正解を自分の文節区切の
結果に翻訳してから評価を行なっている．
しかし，共に85\%程度の正解率が出ており，
我々の手法も同様な位置を占めている．
これらの手法は，ほぼ利用している知識の種類が同様であり，
計算の手法に違いがあるものの，同様な結果を得ていると考えて
いいと思う．
手法の違いによる詳しい比較を行なうためにも，
同じプラットフォームでの実験と
それを元にした考察が望まれる．

\begin{flushleft}
\underline{江原との比較}
\end{flushleft}

江原の手法\cite{ehara:nlp98}は，
我々の手法と同様にMEを用いており，そういった意味で
比較するのは意味があるが，対象文は，NHKのニュース原稿であり，
平均文節数も17.8と我々の対象にしている京大コーパスとは全く異なっている
(平均文節数は10.0)．
ただし，図~\ref{LengthAndAccuracy}に示したように，
我々の結果は文節数と係り受け正解率の関係はあまり変化が見られず，
長いからといって必ずしも解析が困難だとは限らない．
これらの理由により，単純な比較は意味がないが，
正解率において，我々の手法が約10\%上回っているのは
なんらかの要因が存在すると考えられる．
(江原の手法では正解率は76.4\%と報告されている．)
特に江原の方法とは素性の数に大きな差があるようである．
江原が用いた一次的な素性値の数は200個程度であり，
我々の一時的な素性値の数の約5000個とは大きく異なっている．
また，我々は組合せの素性も4万個程度利用している．
この点深く掘り下げて検討する事に意味があると考える．
また，MEに利用する素性の選択に関しては，江原の他にも
白井\cite{shirai:jnlp98:2} Berger\cite{berger:emnlp98}等が
興味深い提案をしている．

\subsection{ビーム幅と精度}

次に，我々の実験の中での比較結果を報告する．

まずは，解析時に用いたビーム幅と精度の関係である．
解析時のビーム幅が広ければ広い程，全体として確率の高い解析が
得られる可能性が高くなるので，ビーム幅は高く設定した方が
望ましいと考えられる．
しかし，結果はその直観とは異なっていた．
表~\ref{BeamAndAccuracy}にビーム幅を1から20に変化させた時の
係り受け正解率と文正解率を示す．
\begin{table}[tbh]
\caption{ビーム幅と係り受け正解率，文正解率との関係}
\label{BeamAndAccuracy} 
\begin{center}
\begin{tabular}{|c||c|c|}
\hline
ビーム幅    &  係り受け正解率 & 文正解率 \\
\hline
1           &    87.14        &  40.60  \\
2           &    87.16        &  40.76  \\
3           &    87.20        &  40.76  \\
5           &    87.14        &  40.60  \\
10          &    87.20        &  40.60  \\
15          &    86.21        &  40.60  \\
20          &    86.21        &  40.60  \\
\hline
\end{tabular}
\end{center}
\end{table}
全体的に変化は小さいが，係り受け正解率はビーム幅が3と10の時に，
文正解率はビーム幅が2と3の時に最大になっている．
これは，全体の確率が最大の物が正解ではなく，各段階ごとに
正解を絞っていった方が正解になるという場合がある事を示している．
これは「はじめに」で書いた，日本語係り受けの特徴(4)にも関係していて
面白い．

この結果によると，文末から文頭に係り受け解析をする際に，
最良の結果のみを得たい場合には，決定的に行なってもかなり精度の良い
ものが得られるという事が言える．
実際に，ビーム幅を1とした時に得られた答が，ビーム幅20とした時の
解析結果のどこに現われるかを調査した結果を表~\ref{OneOnTwenty}に
示す．
\begin{table}[tbh]
\caption{決定的解析結果の位置}
\label{OneOnTwenty} 
\begin{center}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|c|}
\hline
位置    &    1 &  2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\hline
頻度    & 1175 & 20 & 11 & 8 & 4 & 2 & 1 & 2 & 0 & 3 \\ 
(\%)    & (95.3) & (1.6) & (0.9) & (0.6) & (0.3) & (0.2) & (0.1) & (0.2) & & (0.2) \\
\hline
\hline
位置    & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20以上 \\
\hline
頻度    & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 1 & 0 & 8   \\
(\%)    & (0.1) & & (0.1) & & (0.1) & & (0.1) & (0.1) & & (0.6) \\
\hline
\end{tabular}
\end{center}
\end{table}
実際に全体の95\%の場合，ビーム幅1の解析結果がビーム幅20の
解析において最大の確率を持つ結果と同等であった．
また，ビーム幅が1の解析において
文全体が正解であった503文の中では，
N=20での結果において1位の場所に同じ解析結果が
あったものが498文(99.0\%)と非常に高い率であった
(以下2位の位置が3文，3位と5位の位置がそれぞれ1文づつあった．)．
これらの文においては，最大の確率を持つ解析は，
文末から解析していった場合に，各文節ごとの段階において
つねに最良の結果であったという事を意味している．
これは，「はじめに」で書いた特徴(4)とも関係がある．
「はじめに」の脚注に書いた人間に対する実験は文節に対する割合で
あるので，上記の文に対しての数字は，人間の実験で得られたよりも
かなり高い割合で，前方の文脈の不必要さを実証したという事になる．


\subsection{N--Best文正解率}

文正解率はビーム幅が1の実験では40.60\%であったが，
最終的に得られる解析の数を広くすればする程，
正解率が向上する事が考えられる．
図~\ref{NBestAccuracy}にビーム幅を20として解析を行なった場合の
N--best文正解率を示す．
N--best文正解率とは，上位N個の解析結果を見た場合に，
文中のすべての文節係り受けの解析が正しい解析結果がその中にある
割合の事を言う．

\begin{figure}[htbp]
\beginpicture
  \setcoordinatesystem units <10pt,4pt>
  \setplotarea x from 0 to 20, y from 30 to 80

\axis bottom label {N}
      ticks short quantity 21 numbered at 0 5 10 15 20 /  / 
\axis left   label {文正解率}
      ticks short quantity 6 numbered at 30 40 50 60 70 80 /  /

\multiput {*}   at 
1    40.60  2    53.19   3    58.35   4    62.71
5    65.54  6    67.96   7    69.65   8    70.70
9    71.27  10    72.48   11    73.77   12    75.06
13    75.54  14    76.43   15    76.67   16    77.24
17    77.89  18    78.29   19    78.29   20    78.53 /

\setlinear \plot
1    40.60  2    53.19   3    58.35   4    62.71
5    65.54  6    67.96   7    69.65   8    70.70
9    71.27  10    72.48   11    73.77   12    75.06
13    75.54  14    76.43   15    76.67   16    77.24
17    77.89  18    78.29   19    78.29   20    78.53 /

\put {40.60\%} [lb] at 2 40.60
\put {78.53\%} [lb] at 19 73
\endpicture
  \caption{N--best文正解率}
  \label{NBestAccuracy}
\end{figure}
N=20，つまり，ビーム幅と同様の最終結果を見た場合に，
文全体の係り受けが正解である解析結果が上位20個の
解析結果に含まれる割合は78.5\%であるという事である．
この中から正解を捜し出せる理想的なシステムを
開発できた場合には，文正解率が78.5\%という非常に優れた
解析システムができる可能性があるという事である．

この結果から二つの考察ができる．
まず，一点はN=1の文正解率は約40\%であるのに対して，
N=2で向上した割合，つまり，2番目の解析結果が正解であった
割合は10\%程度と非常に低くなっている．
また，この40\%という数字は，N=20の場合の78.5\%という数字の
半分以上であり，半分以上の場合においてN=1の所に正解が
存在したという事を意味する．
これは，我々の確率の計算手法が，まだ改善の余地はあるものの，
かなり正確であるという事を示している．

もう一点は，文正解率が80\%あたりで飽和しており，80\%程度以上の向上は
Nを多少大きくしても望めなさそうであるという事である
(もちろん，Nをすべての組み合わせの数にすれば100\%にはなるが
現実的に意味はない．)．
これは，我々が何か大きな要因を見過ごしている可能性がある．
特に，並列構造についての解析能力が低いようである．
この点を改良し，再度検討していきたいと思う．


\subsection{解析速度}

前章にあるアルゴリズムを分析すると，解析時間は文節長に対して
2乗になっていると推測できる．
実際に，ビーム幅1の時の文節長と解析速度の関係を調べた
(図~\ref{Kaisekisokudo})．
実験はSunのUltra10，周波数(300MHz)を利用した．
係り受け解析のプロセスの大きさは8M程度であった．
\begin{figure}[htbp]
\beginpicture
\setcoordinatesystem units <4pt,360pt>
\setplotarea x from 0 to 50, y from 0 to 0.5

\axis bottom label {文長}
      ticks short quantity 6 numbered at 0 10 20 30 40 50 /  / 
\axis left   label {解析時間(秒)}
      ticks short quantity 11 numbered at 0 0.1 0.2 0.3 0.4 0.5 /  /

\multiput {*}   at 
17 0.067  5 0.008  12 0.048  15 0.061  
9 0.029  12 0.045  10 0.026  6 0.014  5 0.008  
8 0.011  19 0.055  6 0.014  10 0.039  10 0.040  
7 0.017  9 0.025  14 0.035  13 0.033  5 0.010  
11 0.039  7 0.016  19 0.057  8 0.019  9 0.022  
6 0.014  10 0.022  16 0.038  1 0.000  4 0.007  
23 0.123  6 0.012  15 0.043  4 0.006  13 0.031  
6 0.016  6 0.015  10 0.018  10 0.017  1 0.001  
6 0.012  3 0.004  1 0.001  1 0.001  4 0.005  
14 0.045  5 0.011  2 0.002  4 0.005  5 0.010  
3 0.003  6 0.010  5 0.008  6 0.009  3 0.003  
5 0.010  8 0.026  2 0.002  9 0.031  14 0.058  
16 0.087  14 0.033  15 0.041  11 0.035  10 0.037  
7 0.018  10 0.030  9 0.020  17 0.109  10 0.030  
10 0.033  5 0.014  6 0.011  14 0.041  13 0.025  
4 0.008  7 0.020  9 0.022  7 0.019  2 0.003  
1 0.001  4 0.008  2 0.002  8 0.017  2 0.002  
12 0.041  6 0.014  1 0.001  9 0.016  5 0.007  
4 0.011  3 0.005  3 0.004  7 0.022  11 0.034  
4 0.008  16 0.050  4 0.005  6 0.017  8 0.014  
4 0.005  6 0.008  7 0.015  4 0.006  2 0.002  
9 0.031  2 0.003  3 0.004  5 0.010  10 0.025  
9 0.027  13 0.036  5 0.008  6 0.013  7 0.012  
17 0.039  11 0.042  10 0.023  1 0.001  9 0.020  
6 0.016  9 0.030  16 0.063  8 0.020  7 0.013  
2 0.002  12 0.026  4 0.009  5 0.011  16 0.040  
5 0.008  13 0.055  8 0.019  7 0.015  1 0.001  
6 0.008  6 0.016  6 0.013  8 0.019  8 0.015  
9 0.025  16 0.099  7 0.020  2 0.003  11 0.041  
14 0.059  8 0.026  13 0.051  17 0.063  27 0.087  
13 0.031  11 0.030  8 0.020  14 0.050  21 0.191  
21 0.067  12 0.045  8 0.016  8 0.019  5 0.008  
11 0.030  5 0.008  10 0.035  14 0.083  20 0.111  
5 0.010  13 0.037  10 0.051  10 0.022  5 0.011  
6 0.016  5 0.012  4 0.007  4 0.006  19 0.076  
6 0.010  6 0.011  11 0.025  11 0.026  11 0.032  
13 0.034  5 0.008  8 0.017  10 0.026  11 0.028  
4 0.006  5 0.013  13 0.042  6 0.013  13 0.039  
10 0.024  8 0.018  10 0.021  11 0.027  23 0.092  
8 0.018  14 0.058  10 0.038  4 0.006  4 0.009  
7 0.010  5 0.010  9 0.018  7 0.015  10 0.035  
4 0.008  15 0.064  4 0.006  15 0.034  5 0.015  
5 0.010  2 0.003  12 0.029  6 0.015  9 0.023  
1 0.001  5 0.007  18 0.049  8 0.016  7 0.013  
12 0.065  12 0.032  14 0.046  7 0.022  11 0.043  
8 0.020  5 0.009  14 0.025  6 0.012  7 0.015  
9 0.027  3 0.004  3 0.005  10 0.038  4 0.005  
12 0.039  9 0.019  5 0.006  11 0.028  3 0.007  
9 0.023  12 0.044  14 0.047  3 0.003  8 0.025  
11 0.028  8 0.018  12 0.053  7 0.014  5 0.009  
8 0.018  9 0.017  12 0.033  14 0.037  9 0.038  
7 0.014  7 0.013  6 0.016  8 0.026  10 0.042  
7 0.018  10 0.022  15 0.071  3 0.005  5 0.012  
19 0.060  10 0.036  22 0.111  23 0.064  3 0.004  
4 0.006  18 0.042  21 0.105  6 0.012  7 0.014  
8 0.016  19 0.075  11 0.022  3 0.004  9 0.022  
13 0.037  8 0.013  5 0.010  4 0.006  9 0.017  
14 0.038  13 0.039  11 0.016  13 0.035  4 0.005  
4 0.005  9 0.023  9 0.023  4 0.010  9 0.035  
6 0.021  6 0.014  3 0.005  4 0.006  10 0.020  
4 0.008  5 0.008  5 0.007  3 0.005  5 0.011  
4 0.005  2 0.004  3 0.004  3 0.003  6 0.012  
6 0.013  10 0.022  7 0.016  2 0.003  8 0.017  
1 0.001  6 0.010  9 0.032  9 0.023  13 0.032  
2 0.003  6 0.014  6 0.012  11 0.033  8 0.024  
8 0.019  5 0.013  2 0.003  9 0.026  10 0.027  
9 0.033  8 0.016  8 0.018  15 0.046  4 0.008  
22 0.082  5 0.008  15 0.050  6 0.015  9 0.025  
6 0.014  11 0.030  6 0.020  14 0.046  8 0.022  
15 0.045  14 0.039  14 0.034  25 0.082  14 0.038  
15 0.042  10 0.031  14 0.049  11 0.028  12 0.046  
15 0.057  12 0.029  9 0.020  15 0.050  9 0.038  
10 0.027  8 0.027  2 0.003  5 0.012  9 0.019  
3 0.005  10 0.041  7 0.021  11 0.034  12 0.044  
19 0.090  21 0.078  14 0.059  19 0.119  13 0.043  
3 0.003  17 0.036  7 0.017  12 0.026  7 0.016  
6 0.013  3 0.003  18 0.075  6 0.010  8 0.020  
11 0.048  10 0.060  8 0.026  1 0.001  9 0.045  
3 0.005  1 0.002  1 0.001  18 0.059  10 0.033  
12 0.045  9 0.019  4 0.008  9 0.030  
9 0.024  13 0.044  7 0.019  4 0.008  16 0.054  
3 0.003  10 0.062  9 0.018  5 0.009  15 0.038  
9 0.028  5 0.012  6 0.009  9 0.021  1 0.001  
4 0.007  2 0.002  1 0.001  5 0.009  24 0.103  
2 0.003  2 0.002  3 0.004  5 0.007  1 0.001  
6 0.014  2 0.003  10 0.027  4 0.008  8 0.018  
13 0.027  8 0.023  18 0.082  10 0.024  9 0.029  
1 0.000  2 0.001  5 0.009  4 0.006  4 0.008  
8 0.017  8 0.012  4 0.007  8 0.023  14 0.042  
6 0.009  4 0.007  10 0.023  10 0.037  13 0.031  
11 0.035  3 0.003  12 0.029  5 0.011  15 0.091  
5 0.007  12 0.030  9 0.018  5 0.011  11 0.031  
25 0.104  27 0.118  6 0.011  3 0.006  13 0.044  
5 0.012  8 0.017  30 0.126  10 0.021  16 0.059  
4 0.007  11 0.043  26 0.125  7 0.014  9 0.021  
7 0.019  7 0.015  28 0.133  20 0.078  12 0.040  
10 0.031  22 0.066  6 0.015  17 0.074  6 0.025  
7 0.020  20 0.079  13 0.039  1 0.000  10 0.020  
12 0.052  8 0.018  12 0.026  1 0.001  13 0.030  
8 0.017  12 0.039  12 0.041  9 0.017  9 0.020  
5 0.008  16 0.042  2 0.002  4 0.010  11 0.030  
4 0.008  1 0.001  6 0.009  14 0.072  8 0.023  
5 0.011  7 0.019  9 0.018  3 0.004  5 0.008  
13 0.026  8 0.019  4 0.005  4 0.005  9 0.020  
4 0.008  8 0.016  9 0.018  5 0.005  5 0.009  
15 0.056  8 0.014  10 0.022  8 0.013  4 0.008  
15 0.035  4 0.007  6 0.011  18 0.054  8 0.020  
10 0.040  9 0.019  13 0.033  9 0.019  9 0.019  
14 0.052  4 0.012  2 0.003  10 0.025  9 0.020  
17 0.052  7 0.024  5 0.010  12 0.022  11 0.034  
16 0.057  6 0.012  5 0.011  9 0.032  12 0.034  
12 0.039  14 0.037  7 0.018  3 0.007  4 0.007  
4 0.007  6 0.013  12 0.027  5 0.009  7 0.016  
9 0.024  19 0.053  3 0.004  7 0.014  15 0.077  
8 0.021  3 0.005  6 0.012  12 0.026  5 0.011  
16 0.041  12 0.039  6 0.010  2 0.002  7 0.015  
9 0.020  13 0.053  4 0.010  9 0.024  4 0.005  
18 0.046  8 0.014  10 0.024  2 0.003  9 0.022  
8 0.021  8 0.032  3 0.004  2 0.003  14 0.038  
5 0.011  7 0.021  14 0.060  6 0.012  7 0.013  
11 0.032  12 0.032  6 0.018  13 0.031  18 0.055  
9 0.022  13 0.049  8 0.018  11 0.032  5 0.008  
8 0.019  3 0.004  9 0.018  14 0.039  5 0.007  
4 0.009  6 0.010  10 0.027  1 0.001  2 0.002  
6 0.009  1 0.002  4 0.006  6 0.014  14 0.053  
7 0.014  14 0.036  8 0.020  3 0.005  8 0.019  
7 0.018  9 0.020  13 0.028  1 0.001  15 0.026  
14 0.055  11 0.035  24 0.142  18 0.084  9 0.021  
17 0.055  17 0.096  9 0.026  10 0.029  15 0.035  
3 0.006  14 0.035  9 0.022  8 0.021  6 0.009  
8 0.020  7 0.022  7 0.019  4 0.007  6 0.017  
8 0.016  7 0.017  6 0.013  9 0.016  6 0.014  
4 0.008  16 0.052  3 0.004  12 0.024  7 0.014  
1 0.001  3 0.005  10 0.031  11 0.025  4 0.009  
9 0.020  4 0.009  8 0.023  4 0.006  5 0.012  
8 0.020  13 0.033  9 0.024  2 0.003  4 0.006  
4 0.008  9 0.035  3 0.003  6 0.011  7 0.013  
7 0.013  4 0.009  15 0.043  11 0.038  12 0.031  
5 0.008  12 0.034  5 0.009  8 0.023  1 0.001  
2 0.003  4 0.010  18 0.102  9 0.019  9 0.017  
4 0.009  3 0.004  9 0.017  9 0.034  3 0.005  
9 0.023  3 0.004  15 0.048  4 0.008  27 0.139  
13 0.029  14 0.053  5 0.009  7 0.017  10 0.022  
9 0.017  9 0.031  8 0.028  13 0.047  16 0.046  
10 0.026  14 0.046  6 0.012  6 0.012  15 0.080  
12 0.029  12 0.035  8 0.019  3 0.004  
17 0.060  23 0.143  23 0.096  11 0.029  10 0.040  
14 0.042  8 0.014  24 0.097  9 0.032  9 0.031  
22 0.066  15 0.043  10 0.023  15 0.051  8 0.021  
15 0.061  9 0.029  21 0.088  11 0.022  3 0.006  
11 0.026  14 0.038  18 0.039  10 0.028  20 0.102  
14 0.045  8 0.029  5 0.010  9 0.055  14 0.064  
21 0.124  10 0.046  8 0.018  11 0.051  14 0.097  
12 0.059  3 0.005  16 0.052  9 0.028  4 0.007  
16 0.045  20 0.066  9 0.032  18 0.047  2 0.002  
6 0.010  7 0.017  1 0.001  2 0.002  4 0.008  
6 0.008  2 0.006  2 0.003  4 0.006  11 0.028  
3 0.003  15 0.057  4 0.006  5 0.013  16 0.077  
3 0.005  5 0.013  6 0.013  1 0.001  5 0.012  
13 0.030  20 0.066  5 0.012  8 0.027  11 0.035  
4 0.011  5 0.013  6 0.013  21 0.092  8 0.035  
10 0.021  7 0.024  7 0.014  7 0.013  6 0.013  
14 0.040  9 0.026  7 0.021  12 0.023  14 0.039  
1 0.001  3 0.003  15 0.034  5 0.011  7 0.026  
6 0.012  4 0.007  6 0.018  5 0.010  3 0.006  
4 0.004  5 0.012  5 0.008  10 0.028  9 0.025  
6 0.013  8 0.018  6 0.013  8 0.019  9 0.027  
6 0.009  2 0.003  1 0.001  9 0.026  7 0.024  
3 0.007  9 0.021  8 0.023  13 0.050  4 0.007  
2 0.002  6 0.012  6 0.011  3 0.004  8 0.020  
10 0.023  4 0.006  9 0.025  7 0.013  8 0.016  
9 0.014  11 0.028  4 0.008  13 0.041  7 0.015  
21 0.065  5 0.012  6 0.010  19 0.065  20 0.062  
11 0.027  5 0.009  12 0.039  9 0.018  14 0.031  
9 0.025  5 0.014  25 0.087  15 0.080  16 0.059  
18 0.070  12 0.041  16 0.047  15 0.044  22 0.104  
13 0.040  10 0.024  16 0.053  8 0.020  8 0.019  
12 0.031  10 0.029  18 0.063  20 0.078  11 0.028  
9 0.026  9 0.022  16 0.062  1 0.000  4 0.007  
6 0.011  17 0.045  4 0.007  4 0.006  3 0.006  
17 0.037  5 0.008  7 0.016  8 0.013  9 0.026  
9 0.026  2 0.001  7 0.018  11 0.026  4 0.007  
2 0.002  8 0.026  5 0.010  25 0.069  7 0.017  
9 0.023  10 0.021  2 0.004  1 0.001  3 0.004  
1 0.001  9 0.019  6 0.012  18 0.069  8 0.023  
4 0.006  14 0.062  7 0.020  8 0.040  17 0.061  
13 0.026  6 0.015  13 0.050  12 0.032  9 0.031  
1 0.001  9 0.030  20 0.063  5 0.009  17 0.041  
11 0.029  6 0.013  11 0.030  15 0.086  9 0.022  
11 0.033  7 0.013  14 0.035  14 0.039  10 0.026  
11 0.017  7 0.012  9 0.033  4 0.006  20 0.065  
11 0.033  17 0.051  1 0.000  4 0.009  17 0.047  
9 0.020  10 0.041  15 0.036  6 0.014  5 0.011  
3 0.006  6 0.017  2 0.004  3 0.004  1 0.001  
4 0.010  3 0.005  4 0.006  2 0.003  9 0.024  
9 0.020  16 0.037  2 0.003  8 0.022  1 0.001  
5 0.008  2 0.002  3 0.003  10 0.026  
4 0.006  14 0.053  2 0.002  40 0.287  9 0.016  
0 0.000  8 0.017  15 0.061  10 0.042  11 0.031  
13 0.064  4 0.008  17 0.074  10 0.030  9 0.026  
7 0.014  6 0.019  9 0.030  13 0.034  24 0.101  
4 0.006  2 0.003  4 0.010  7 0.022  7 0.014  
0 0.000  8 0.019  4 0.006  4 0.009  6 0.017  
8 0.016  6 0.013  5 0.010  10 0.032  26 0.072  
4 0.004  11 0.029  3 0.003  4 0.009  1 0.001  
6 0.014  6 0.017  8 0.018  2 0.003  9 0.020  
9 0.021  5 0.015  4 0.006  7 0.016  4 0.008  
4 0.008  4 0.006  12 0.046  11 0.026  
6 0.015  25 0.114  6 0.015  1 0.001  18 0.094  
12 0.059  11 0.041  13 0.038  6 0.014  27 0.113  
14 0.076  14 0.042  5 0.008  8 0.024  9 0.026  
21 0.091  13 0.038  9 0.023  17 0.065  15 0.046  
17 0.090  14 0.039  6 0.008  10 0.024  13 0.044  
5 0.010  20 0.094  9 0.027  9 0.022  9 0.031  
9 0.024  4 0.009  8 0.018  5 0.009  27 0.267  
17 0.133  16 0.046  6 0.013  9 0.021  8 0.024  
7 0.017  8 0.021  15 0.050  11 0.031  10 0.030  
10 0.026  5 0.009  19 0.062  2 0.004  5 0.009  
4 0.003  8 0.016  7 0.011  13 0.038  18 0.054  
4 0.008  3 0.008  9 0.025  3 0.003  6 0.011  
9 0.035  7 0.014  15 0.060  13 0.034  13 0.034  
3 0.007  10 0.031  10 0.031  14 0.043  7 0.015  
8 0.022  24 0.067  3 0.006  10 0.023  8 0.020  
11 0.034  4 0.008  11 0.039  5 0.009  4 0.007  
10 0.032  22 0.100  7 0.018  17 0.058  7 0.012  
16 0.036  7 0.015  3 0.003  11 0.027  23 0.067  
20 0.091  3 0.005  24 0.076  26 0.161  7 0.026  
16 0.043  9 0.021  2 0.004  7 0.032  10 0.039  
5 0.013  23 0.130  6 0.023  10 0.032  18 0.086  
3 0.006  16 0.076  37 0.151  18 0.062  13 0.030  
3 0.004  18 0.040  15 0.045  8 0.021  7 0.015  
3 0.005  8 0.026  21 0.059  10 0.022  9 0.027  
10 0.031  3 0.005  15 0.061  3 0.005  10 0.041  
13 0.046  11 0.034  7 0.026  11 0.040  10 0.033  
1 0.001  6 0.010  2 0.002  16 0.055  22 0.119  
36 0.192  5 0.009  8 0.026  4 0.008  21 0.090  
5 0.013  10 0.021  5 0.014  9 0.017  6 0.012  
8 0.029  9 0.025  22 0.118  9 0.025  8 0.033  
21 0.084  2 0.002  3 0.005  11 0.037  7 0.012  
4 0.005  12 0.035  14 0.058  1 0.001  8 0.021  
4 0.010  7 0.019  3 0.006  10 0.033  6 0.013  
7 0.015  12 0.044  11 0.033  13 0.058  10 0.023  
14 0.052  10 0.033  18 0.059  20 0.059  12 0.046  
15 0.057  10 0.023  16 0.052  5 0.011  6 0.013  
6 0.012  14 0.075  3 0.007  4 0.007  17 0.056  
8 0.016  13 0.036  12 0.045  9 0.022  16 0.045  
3 0.006  4 0.006  3 0.006  7 0.012  22 0.098  
22 0.148  4 0.008  9 0.025  4 0.008  13 0.039  
12 0.058  4 0.013  13 0.056  8 0.023  
11 0.027  3 0.005  /

\setquadratic
\plot 0 0 20 0.08 40 0.32 /

\put {$t = 0.0002 * n^{2}$} [lb] at 30 0.4

\endpicture
  \caption{ビーム幅1の時の文節長と解析速度の関係}
  \label{Kaisekisokudo}
\end{figure}
図から実際の解析時間も，文長に対してほぼ2乗になっている事が分かる
(参考の為に描き入れた二次曲線を参照．)．
実際は定数部分がある為に
曲線の最初の部分は分布よりも下になっていると考えられる．
一文あたりの平均解析時間は0.03秒(平均文節数10.0)，
最長文である41文節の文に対しては0.29秒で解析を行なった．
実際，プログラムを最適化する余地は存在し，
その係数については改善の余地があると考えている．
また，プロセスサイズについても必要ならば，
縮小する余地はあると考えている．

\section{まとめ}

本論文では文末から解析する統計的係り受け解析アルゴリズムを示した．
日本語の係り受けは，ほとんどが前方から後方であるという
特徴を生かし，解析は文末から文頭の方向へ解析を進めるという点と，
色々な提案によって有効性が示されている統計的文解析を利用するという
二つの特徴を兼ね備えた日本語文係り受け解析を提案した．
係り受けの正解率は，正しい文節解析ができた結果から開始した場合，
京大コーパスを使用した実験で係り受け正解率が87.2\%，
文正解率が40.8\%と高い精度を示している．
ビームサーチのビーム幅を調整した実験では，ビーム幅を小さくする
事による精度の劣化が認められなかった．
実際にビーム幅が1の際に得られた結果の95\%は
ビーム幅20の時の最良の結果と同一であった．
また，N--best文正解率を見た時には，Nが20の時には
78.5\%という非常に高い結果を示している．
解析速度は，解析アルゴリズムから推測される2乗程度であり，
平均0.03秒(平均文節数10.0)，
最長文である41文節の文に対しては0.29秒で解析を行なった．

また，他の手法との比較では，共通のベンチマークがない為，
直接的な比較はできなかったが，各手法と同程度か優れた結果が
得られたと判断した．
共通のベンチマークを作る事は，お互いのシステムの
特徴を直接的に比較し，技術の向上を計る為に有意義であると考えられる．
また，今回は，文節切りができている点から解析を開始したが，
そうでなく文からの解析を行なった場合には，評価の方法も
難しくなる．
特に文節切りが正解とシステムが出した結果とで異なる場合には
どのように判断したらよいかスタンダードな方法がない状態である．
協力しあってこのようなスタンダードを決める事は意味があると思われる．


\bibliographystyle{jnlpbbl}
\bibliography{jpaper}

\begin{biography}
\biotitle{略歴}
\bioauthor{関根 聡}{
1987年東京工業大学応用物理学科卒．同年松下電器東京研究所入社．
1990-1992年UMIST，CCL，Visiting Researcher．1992年MSc．
1994年からNew York University，Computer Science Department，
Assistant Research Scientist．1998年PhD．
同年からAssistant Research Professor．
自然言語処理の研究に従事．
情報処理学会，人工知能学会，言語処理学会，ACL会員．
}
\bioauthor{内元 清貴}{
1994年京都大学工学部電気工学第二学科卒業．
1996年同大学院修士課程修了．
同年郵政省通信総合研究所入所，郵政技官．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，各会員．
}
\bioauthor{井佐原 均}{
1978年京都大学工学部電気工学第二学科卒業．1980年同大学院修士課程修了．
工学博士．同年通商産業省電子技術総合研究所入所．1995年郵政省通信総合研究所
関西支所知的機能研究室室長．自然言語処理，機械翻訳の研究に従事．
情報処理学会，言語処理学会，人工知能学会，日本認知科学会，各会員．
}

\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}

\end{biography}

\end{document}

