




\documentstyle[epsf,jnlpbbl]{jnlp_j_b5}

\setcounter{page}{61}
\setcounter{巻数}{6}
\setcounter{号数}{7}
\setcounter{年}{1999}
\setcounter{月}{10}
\受付{1999}{3}{2}
\再受付{1999}{4}{26}
\再々受付{1999}{6}{17}
\採録{1999}{6}{29}

\setcounter{secnumdepth}{2}
\setlength{\parindent}{\jspaceskip}

\title{日本語文と英語文における統語構造認識と\\マジカルナンバー７±２}
\author{村田 真樹\affiref{CRL} \and 内元 清貴\affiref{CRL} \and 馬 青\affiref{CRL} \and 井佐原 均\affiref{CRL}}

\headauthor{村田, 内元, 馬, 井佐原}
\headtitle{日本語文と英語文における統語構造認識とマジカルナンバー７±２}

\affilabel{CRL}{郵政省 通信総合研究所}
{Communications Research Laboratory, Ministry of Posts and Telecommunications}

\jabstract{
 George A. Miller は人間の短期記憶の容量
は７±２程度のスロットしかないことを提唱
している．本研究では，京大
コーパスを用い
て日本語文の各部分において係り先が未決定
な文節の個数を数えあげ，その個数がおおよそ
７±２の上限9程度でおさえられていたことを報告
した．また，英語文でも同様な調査を行ない
NP程度のものをまとめて認識すると仮定した場合
７±２の上限9程度でおさえられていたことを確認した．
これらのことは，文理解における情報の認知単位として
日本語で文節，英語ではNP程度のものを仮定すると，
Miller の7±2の理論と，言語解析・生成において
短期記憶するものは7±2程度ですむという Yngve の主張を
整合性よく説明できることを意味する．
}

\jkeywords{マジカルナンバー７±２，統語構造，文節，名詞句，認知単位}

\etitle{Magical Number Seven Plus or Minus Two:\\ 
Syntactic Structure Recognition\\ 
in Japanese and English Sentences}
\eauthor{Masaki Murata\affiref{CRL} \and Kiyotaka Uchimoto\affiref{CRL} \and Qing Ma\affiref{CRL} \and Hitoshi Isahara\affiref{CRL}} 

\eabstract{
George A. Miller insisted that 
human beings have only 
seven chunks in short term memory plus or minus two. 
We counted the number of 
bunsetsus whose modifiees were not recognized 
in each step when investigating 
the dependencies from the beginning of Japanese sentences   
by using the Kyoto University corpus, 
and we report that the number was roughly lower 
than nine, the upper bound of seven plus or minus two. 
We also investigated English sentences, 
and we got a result similar to Japanese 
when we assumed that human beings 
recognize 
a series of words such as a noun phrase (NP) 
as a unit. 
This indicates that 
if we assume that human beings' cognitive unit 
in Japanese and English are 
bunsetsu and NP respectively, 
we can accept Miller's theory. 
}

\ekeywords{Magical Number Seven Plus or Minus Two, Syntactic Structure, 
Bunsetsu, Noun Phrase, Cognitive Unit}

\begin{document}
\maketitle


\section{はじめに}
George A. Miller は1956年に人間の短期記憶の容量
は７±２程度のチャンク\footnote{
チャンクとは
ある程度まとまった情報を計る，情報の認知単位のこと．}
(スロット)しかないこと，
つまり，人間は短期的には７±２程度のものしか覚えられないこと
を提唱した\cite{miller56}．本研究では，京大
コーパス\cite{kurohashi_nlp97}を用いて
日本語文の各部分において係り先が未決定な
文節の個数を数えあげ，その個数がおおよそ
７±２程度でおさえられていたことを報告する．
この結果は，人間の文の理解過程において
係り先が未決定な文節を短期記憶に格納するものであると仮定した場合，
京大コーパスでは
その格納される量がちょうど Miller のいう７±２の上限の9程度で
おさえられており，
Miller の７±２の提唱と矛盾しないものとなっている．
また Yngve によって提案されている方法\cite{yngve60}により
英語文でも同様な調査を行ない，
NP程度のものをまとめて認識すると仮定した場合，
必要となる短期記憶の容量が７±２の上限の9程度で
おさえられていたことを確認した．

近年，タグつきコーパスの増加により，
コーパスに基づく機械学習の
研究が盛んになっているが\cite{murata:nlken98}，
タグつきコーパスというものは機械学習の研究のためだけに
あるのではなく，
本研究のような言語の数量的な調査にも役に立つものである．
現在の日本の言語処理研究では
コーパスを機械学習の研究に用いるものがほとんどであるが，
本論文のようにコーパスの様々な使い道を考慮する
べき時代がきていると思っている．

\section{短期記憶と７±２}

 Miller は短期記憶の容量を計る，
言葉，音感，味覚，視覚などを対象とした種々の実験に
おけるデータが，いずれも概ね７±２であったことから，
人間の短期記憶の容量は７±２程度のチャンク
であることを提唱した．
７±２の「±２」は個人差を意味しており，
一般の人は7個程度，人によっては二つ多いめに，もしくは
二つ少なめに覚えることができることを意味している
\footnote{
\baselineskip=0.85\baselineskip
Miller の７±２とは直接関係ないが，
言語の特性を短期記憶と結びつけて議論しているものに
Lewis のマジカルナンバ2or3\cite{Lewis96}という研究が
ある．これは中央埋め込みの数に関する研究で，
英語では主節と一つの中央埋め込みの二つの文(
ここでいう文は，句点によって区切られる文ではなく，
動詞によって構成される節のような部分的な文のことを意味する．)まで
(日本語では主節と二つの中央埋め込みの三つまで)しか
短期的に覚えることができないと主張するもので，
これは英語については
古くはKimballの7つの原則\cite{Kimball73}のうちの
四つ目の「文二つの原則」にあげられていることである．
これらの研究は
文理解において中央埋め込みの数に制限があるのは
人間の短期記憶の容量に限界があるためであると考えているものである．}．

７±２の研究は心理学の分野に属するものではあるが，
工学の分野にも応用することができる．
例えば，文生成の研究では
７±２の容量を越える文を作成すると
わかりにくい文になるであろうから\cite{matsuoka96}，
その条件を満足するように文生成を行なう
ということがある\cite{yngve60}．
また，画像処理の分野では
最近はやりのカーナビを構築する際に，
一画面に多くの情報を与えすぎると人間の認識に
支障をきたすので，
７±２程度のものしか提示しないようにするなどの
研究を行なっているものもある\cite{Inui91}．
７±２の研究は，単なる知的好奇心による人間の解明に役に立つだけでなく，
実際の社会においても利用されうる
有益な研究なのである．

\section{日本語文での調査報告}

\begin{figure}[t]
  \begin{center}
\fbox{
    \begin{minipage}{7cm}
      \begin{center}
      \epsfile{file=jap.eps,height=4cm,width=7cm} 
      \end{center}
      \vspace{-0.5cm}
    \caption{係り先が未決定の文節数の数え方}
    \label{fig:jap}
    \end{minipage}
}
  \end{center}
\end{figure}


本節では実際に京大コーパスを用いて行なった調査結果を報告する．
(京大コーパスは1995年の毎日新聞のデータをもとに作成された
タグつきコーパスである．)
まず調査方法を述べる．
本研究では文の理解とは文の係り受け構造の解析であるとみなし，
文を理解するときに短期記憶に格納することが必要とされるものは，
係り先が未決定な文節であると考える．
図\ref{fig:jap}に例を示す．
図は「その少年は小さい人形を持っている．」という文の
係り受け構造を頭から解析するときに，
各文節において係り先が未決定になっている文節の数を
数えているものである．
図の矢印は係り受け構造を示し，
数字は係り先が未決定な文節の個数を示し，
その下に係り先が未決定な文節として短期記憶に格納しなければならない
要素を示している．
この文を頭から見てみると，
「その」が入ってきたときはそれの係り先はまだ決まっていないので
それは覚えておかなければならず，
係り先が未決定なものとして短期記憶に格納される．
次に「少年は」が入ってきたときは，
「その」は「少年は」に係るとわかり
「その」単独ではもう今後係り受けの解析に利用する必要はないので
単独で認識する必要はなく，
「少年は」とくっつけて「その少年は」という形で認識され，
結局係り先が未決定な「その少年は」が一つだけ短期記憶に格納される
ことになる．
その次に「小さい」が入ってくる．
このときは新たに係り受け関係が定まるものはないので，
「その少年は」と「小さい」が短期記憶に格納される．
その次の「人形を」が入ってきたときは，
「小さい」は「人形を」に係るので
「小さい」はもう今後単独では解析に用いられることはないので，
「人形を」とくっつけて「小さい人形を」とまとめて認識され，
前から覚えていた「その少年は」とあわせて
二つ覚えるだけでよい．
最後に文末の「持っている。」が入ってくると，
すべての係り受け関係が定まるので
係り先の未決定数は0となり，
短期記憶に覚えていたものはすべて忘れてもよいこととなる．

\begin{table}[t]
  \caption{係り先が未決定な文節の個数の頻度統計}
  \label{tab:hindo_toukei}
  \begin{center}
\small\small\renewcommand{\arraystretch}{}
\begin{tabular}[c]{|r|r|r|}\hline 
未決定文節数 & \multicolumn{2}{c|}{頻度}\\\cline{2-3}
    &   \multicolumn{1}{c|}{文節数} & \multicolumn{1}{c|}{文数}\\\hline
  0 &      19954 &         90\\
  1 &      52751 &       1352\\
  2 &      59494 &       5022\\
  3 &      38465 &       6823\\
  4 &      15802 &       4468\\
  5 &       4488 &       1593\\
  6 &       1143 &        480\\
  7 &        195 &        102\\
  8 &         47 &         17\\
  9 &         10 &          5\\
 10 &          3 &          2\\\hline
\end{tabular}
\end{center}
\end{table}

\begin{table*}[t]
\vspace{-5mm}
  \caption{係り先が未決定な文節の個数が10であった箇所を持つ文}
  \label{tab:10deatta_bun}
  \begin{center}
\small
\begin{tabular}[c]{|p{13.5cm}|}\hline 
調べでは、同町○○(地名)、建設業、○○○○(人名)容疑者は、九月六日告示の町議選を無投票にするため、逮捕された議員十五人が出し合った現金四百五十万円を告示日の六日、同町○○○(地名)、元町議で農業の○○○○(人名)容疑者に、また百万円を告示翌日の七日、新人で出馬予定だった同町○○○(地名)、会社員、○○○○(人名)容疑者と夫の会社代表、○○(人名)容疑者の二人に渡した疑い。\\\hline 
国はその後、このうち二十三点の公開は「やむを得ない」と認めたものの、主に電子機器などを置いてある地下部分の資料二十一点については「ＡＳＷＯＣはシーレーン防衛のための中枢基地であり、公開されると国防や警備上、重大な支障が生じる」などと主張、決定の取り消しなどを要求して争ってきた。\\\hline 
\end{tabular}
\end{center}
\end{table*}
本稿では，人間が文を理解する際に以上のような過程を
たどると想定し，
実際に係り受け構造のタグがふってある京大コーパスにおいて，
実際に上記の方法で係り先が未決定な文節の数を数えあげた．
その結果を表\ref{tab:hindo_toukei}に示す．
この表の「文節数」の列の数字は，
京大コーパス(未定義のタグがふってあった2文を
除く19,954文, 192,352文節)の全文節において
上記の方法で係り先が未決定な文節の数を調べ，
その係り先未決定文節数ごとに，文節の頻度を調べたものである．
また，表の「文数」の列は，
一文中で最も大きかった係り先未決定文節数をその文の
係り先未決定文節数と考えて，
係り先未決定文節数ごとに文の頻度を調べたものである．
この表では，未決定文節数が10つまり，Miller の7±2の上限9を越える
文が二つあったが，おおよそ7±2の理論の範囲でおさまっていることを
意味する．
7±2を越えた二つの文を表\ref{tab:10deatta_bun}に示す．
これらの文は極めて読解が難解なもので真剣に読んでもなかなか理解が
できない文である．
7±2の上限の9を越えた文が少ないこと，また，
7±2の上限の9を越えた二文も読解が難解な文であったことから，
この調査結果は Miller の7±2の理論と矛盾しないものと
なっている．

本研究では京大コーパスの係り受けのタグにしたがって
係り先が未決定な文節の個数を数えたが，
京大コーパスは助詞「は」がつく文節が
複数の係り先が想定される場合なるべく後ろの文節に係るようにタグづけされており，
これを近くにかかるようにすれば統計結果は変化するだろう．
また，接続詞など，記憶が必要でないかもしれない文節も
数えてしまっている．これらに対して適切な処理を
施せば，係り先の未決定な文節の個数は
さらに少なくなると予想される．

\section{英語文での調査報告}

前節は日本語コーパスを用いて
文の理解に必要な短期記憶の上限を調査するものだった．
本節では，英語コーパスにおける調査結果について記述する．
まず，Yngve により提案されている英語コーパスでの
短期記憶の容量の計算方法を述べる．
次に Sampson が行なった英語の SUSANNE コーパスにおける
同様な調査\cite{Sampson97}の紹介と，
われわれが行なった英語の Penn Treebank コーパス
における調査結果を報告する．

\begin{figure}[t]
  \begin{center}
\fbox{
    \begin{minipage}{7cm}
      \begin{center}
      \epsfile{file=eng.eps,height=5.5cm,width=5cm} 
      \end{center}
      \vspace{-0.5cm}
    \caption{スタックに蓄える非終端記号の数の数え方}
    \label{fig:eng}
    \end{minipage}
}
  \end{center}
\end{figure}

英語での文の構造解析に必要な短期記憶の容量を求める方法は
Yngve\cite{yngve60}によってすでに提案されている．
この方法は文をプッシュダウンオートマトンでトップダウンに
解析する際にスタックに蓄えられるSやNPなどの非終端記号を
短期記憶するべきものと考え，このスタックにつまれる
記号の個数を数えるものである．
図\ref{fig:eng}は
``The boy has a small doll.''を
プッシュダウンオートマトンで解析したときに
スタックに蓄える非終端記号の数の
数え方を示したものである．
\begin{figure}[t]
\vspace{-5mm}

  \begin{center}

\fbox{
    \begin{minipage}{7cm}
      \begin{center}
      \epsfile{file=eng_1.eps,height=0.5cm,width=2cm} 
      \end{center}
      \vspace{-0.5cm}
    \caption{各枝への数の付与の仕方}
    \label{fig:eng_1}
    \end{minipage}
}
  \end{center}
\end{figure}
\begin{figure}[t]
\vspace{-1mm}
  \begin{center}
\fbox{
    \begin{minipage}{7cm}
      \begin{center}
      \epsfile{file=eng_3.eps,height=3cm,width=5cm} 
      \end{center}
      \vspace{-0.5cm}
    \caption{Sampson の変更した計算方法}
    \label{fig:eng_3}
    \end{minipage}
}
  \end{center}
\end{figure}
図\ref{fig:eng_3}の下の方にある四角い箱は
人間の短期記憶の格納庫に相当するスタックを表す．
この文を頭から見て``The''が入ってきたときに，
トップダウンで解析するのでまず最初にSから始まって
Sを(NP VP)に変形しVPを覚えておいてNPを(DT N)に変形して
Nを覚えておいてDTの部分を``The''と認識するので\footnote{
\baselineskip=0.85\baselineskip
このトップダウンの認識はわれわれ日本人には若干不自然に思えるものだが，
英語文の場合はボトムアップよりも，文が成立すると仮定しまた
主語と述部があると仮定して読み進める
トップダウンの方が人間の文理解のモデルとしても
よいとされている\cite{Kimball73}．}$^{,}$\footnote{
\baselineskip=0.85\baselineskip
図\ref{fig:eng}では
NP を展開する際に(DT N)と(DT J N)の二種類が想定でき，
``The'' が入ってきただけではそのどちらであるかを特定できないという
問題がある．
また，前提とする文法ルールを変更したりすることで，
構文木の表現がかわり集計結果が変わってしまう問題がある．
Yngve の方法はそういう問題を持っているが，
タグつきコーパスからの計数方法が非常に容易であるため
本稿はそれにしたがって計数している．}，
都合``The''のところではVPとNの二つをスタックに
覚えておく必要がある．
同様な考え方でスタックに積む必要のある非終端記号は
図\ref{fig:eng}のようになり各単語でのスタックに積んでおく必要のある
数は図\ref{fig:eng}のように``2,1,1,2,1,0''となる．
Yngve はこのスタックに積んでおく必要のある数を
簡単に数える方法も示している．
それは，図\ref{fig:eng}の構文木の
各枝に図\ref{fig:eng_1}に示した要領で数字をふり
Sから単語までの経路の数字を足したものが
スタックに積む個数とする方法である．
``The''を見るとS,NP,DTと見て1と1があるので
足して2となりスタックの数2と一致する．

\begin{table}[t]
\vspace{-1mm}
  \caption{スタックに積まれる非終端記号の個数の頻度統計(SUSANNE コーパス)}
  \label{tab:hindo_toukei_eng_sussane}
  \begin{center}
\small\small\renewcommand{\arraystretch}{}
\begin{tabular}[t]{|r|r|}
\multicolumn{2}{c}{(a)Yngve の方法で集計}\\\hline
\multicolumn{1}{|l|}{積む} & \multicolumn{1}{c|}{頻度}\\
記号数    &   \multicolumn{1}{c|}{(単語数)} \\\hline
0 & 7851 \\
1 & 30798 \\
2 & 34352 \\
3 & 26459 \\
4 & 16753 \\
5 & 9463 \\
6 & 4803 \\
7 & 2125\\
8 & 863\\
9 & 313\\
10 & 119\\
11 & 32\\
12 & 4\\
13 & 1\\\hline
\end{tabular}
\vspace{-5mm}
\begin{tabular}[t]{|r|r|}
\multicolumn{2}{c}{(b)Sampsonの変更した方法で集計}\\\hline
\multicolumn{1}{|l|}{積む}& \multicolumn{1}{c|}{頻度}\\
記号数     &   \multicolumn{1}{c|}{(単語数)} \\\hline
0 & 55866\\
1 & 64552\\
2 & 12164\\
3 & 1274\\
4 & 76\\
5 & 4\\\hline
\end{tabular}
\end{center}
\vspace{3mm}
\end{table}

\begin{table}[t]
\vspace{-3mm}
  \caption{スタックに積まれる非終端記号の個数の頻度統計(Penn Treebank コーパス)}
  \label{tab:hindo_toukei_eng}
  \begin{center}
\small\small\renewcommand{\arraystretch}{}
\begin{tabular}[t]{|r|r|r|}
\multicolumn{3}{c}{Yngveの方法で単語部分で集計}\\\hline
\multicolumn{1}{|l|}{積む} & \multicolumn{2}{c|}{頻度}\\\cline{2-3}
記号数    &   \multicolumn{1}{c|}{単語数} & \multicolumn{1}{c|}{文数}\\\hline
0 & 49208 & 132\\
1 & 377740 & 772\\
2 & 309255 & 3921\\
3 & 213294 & 9528\\
4 & 103864 & 13324\\
5 & 44274 & 11163\\
6 & 16478 & 6158\\
7 & 5750 & 2719\\
8 & 1939 & 981\\
9 & 661 & 338\\
10 & 243 & 111\\
11 & 92 & 29\\
12 & 43 & 17\\
13 & 15 & 14\\
14 & 1 & 1\\\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[t]
\vspace{-1mm}
  \caption{スタックに積まれる非終端記号の個数の頻度統計(Penn Treebank コーパス)}
  \label{tab:hindo_toukei_engb}
  \begin{center}
\small\small\renewcommand{\arraystretch}{}
\begin{tabular}[t]{|r|r|r|}
\multicolumn{3}{c}{Sampsonの方法で単語部分で集計}\\\hline
\multicolumn{1}{|l|}{積む}& \multicolumn{2}{c|}{頻度}\\\cline{2-3}
記号数     &   \multicolumn{1}{c|}{単語数} & \multicolumn{1}{c|}{文数}\\\hline
0 & 49208 & 132\\
1 & 485849 & 1956\\
2 & 414945 & 13367\\
3 & 140611 & 22966\\
4 & 28317 & 9124\\
5 & 3616 & 1518\\
6 & 283 & 133\\
7 & 28 & 12\\\hline
\end{tabular}
\end{center}
\end{table}
\begin{table}[t]
\vspace{-0.5mm}
  \caption{スタックに積まれる非終端記号の個数の頻度統計(Penn Treebank コーパス)}
  \label{tab:hindo_toukei_engc}
\vspace{-2mm}
  \begin{center}
\small\small\renewcommand{\arraystretch}{}
\begin{tabular}[t]{|r|r|r|}
\multicolumn{3}{c}{Yngveの方法でNP部分で集計}\\\hline
\multicolumn{1}{|l|}{積む}& \multicolumn{2}{c|}{頻度}\\\cline{2-3}
記号数     &   \multicolumn{1}{c|}{NP数} & \multicolumn{1}{c|}{文数}\\\hline
0 & 69820 & 4546\\
1 & 102337 & 7634\\
2 & 74126 & 16847\\
3 & 30025 & 11489\\
4 & 11432 & 5780\\
5 & 3336 & 2020\\
6 & 963 & 633\\
7 & 273 & 187\\
8 & 76 & 51\\
9 & 29 & 13\\
10 & 13 & 8\\\hline
\end{tabular}
\end{center}
\vspace{-3mm}
\end{table}



\begin{figure}[t]
\vspace{-0.5mm}
  \begin{center}
\fbox{
    \begin{minipage}{7cm}
      \begin{center}
      \epsfile{file=eng_2.eps,height=3cm,width=5cm} 
      \end{center}
      \vspace{-0.5cm}
    \caption{並列節の各枝の数の修正方法}
    \label{fig:eng_2}
    \end{minipage}
}
  \end{center}
\end{figure}

この方法を用いて Sampson は SUSANNE コーパス(約13万語)において
表\ref{tab:hindo_toukei_eng_sussane}(a)の結果を得ている．
表の「頻度(単語数)」は
スタックに積まれる非終端記号数ごとの単語の頻度を意味している．
詳細な計算方法は Sampson の論文を参照のこと．
この結果では，
7±2の上限9を越える文が多く存在している．
そこで，Sampson は各ノードでふられている
数字を図\ref{fig:eng_3}のように変更して
計数している．
図\ref{fig:eng_3}のトップダウンの文の構造認識において
A を認識する際に B, C, D, E を個々に覚えておくのではなく，
B, C, D, E をまとめて認識し覚えておくのは
(B, C, D, E)の一つのセットでよい
(もしくは，A を認識する際に B, C, D, E を個々に覚えておくのではなく，
その親のノードを一個だけを覚えておく)と仮定するものである．
この計数方法により Sampson は
表\ref{tab:hindo_toukei_eng_sussane}(b)の結果を得ている．
この結果は7±2の下限5以下でおさえられており，
Millerの7±2の理論と矛盾しないものとなっている．

われわれは上記の調査を
Penn Treebank\cite{Marcus93} の Wall Street Journal の
コーパス(49,208文，1,122,857単語)で行なってみた．
SUSANNE コーパスで調査を行なわなかったのは，
SUSANNE コーパスの構造が若干複雑なことと，
Penn Treebank の方がデータ量が多いことと
SUSANNE コーパスではすでにSUSANNE コーパスの作成者の
Sampson が調査を行なっていたことに起因する．
Penn Treebank における実験結果を
表\ref{tab:hindo_toukei_eng}に示す．
表の「単語数」は
スタックに積まれる非終端記号数ごとの単語の頻度を意味し，
「文数」は一文で最も多く積んだときの非終端記号数を
その文の非終端記号数としたときの非終端記号数ごとの文の頻度を
意味する．
ただし，ピリオドなどの記号は削除し，
また``and''などによって構成される並列節の表現形式が
このコーパスではスタックの非終端記号の数を
余分に数えるような構造になっていたので，
その部分は図\ref{fig:eng_2}のように数値をふり直すことで
余分に数えなくてすむようにして数えあげた．
表\ref{tab:hindo_toukei_eng}の結果は
表\ref{tab:hindo_toukei_eng_sussane}(a)の結果とよく似ていることが
わかる．
この結果でも
7±2の上限9を越える文が多く存在することが気になる．
そこで，Sampson の修正した方法で計数してみた．
その結果を表\ref{tab:hindo_toukei_engb}に示す．
Sampson の SUSANNE コーパスでの結果では5でおさえられていたが，
Penn Treebank の結果では 7 のものもあることがわかる．

われわれはさらに Yngve と Sampson と異なる
英語コーパスにおける新しい計数方法を考えた．
これは，日本語では文節を単位としてカウントし
英語では単語を単位としてカウントするのは若干不公平では
ないだろうかという考えに基づく．
そのわれわれの方法は，人間は日本語の文節のように
個々の単語にまで分解せずにNP程度のものはまとめて
認識すると仮定して
NPの部分におけるスタックの数を勘定するものである．
つまり，SからNPにいたる経路に書いてある数字を足しあわせたものを
用いて集計した．
その結果を表\ref{tab:hindo_toukei_engc}に示す．
この結果では，10のものがあり Miller の7±2を逸脱している
文もいくつかあるが，表\ref{tab:hindo_toukei}の日本語文での結果
とよく似ており，また Miller の7±2 のプラス2の部分に相当する
 8,9 の文もあるということで
我々の計数方法も有力ではないかと考えている．

いずれにせよ，Yngve の方法のまま計数すれば Miller の7±2 の理論を
満足しないが，Sampson の新しい計数方法か我々の新しい
計数方法を採用すれば，
Miller の 7±2 と矛盾しない説明をつけることができることがわかる．
また，Sampson の計数方法に比べわれわれの計数方法は以下の
二つの利点がある．
\begin{itemize}
\item 
われわれの英語における計数方法は，
計数の単位に文節に対応するNPを考慮するものであり，
われわれの日本語における計数方法から学んだものであるという
理由づけがある．

\item 
Sampson の方法だと Miller の 7±2 の7あたりまで
(SUSANNEコーパスでは5あたりまで)しか
出現しないことになるが，われわれの方法では
Miller の7±2 の 8,9 あたりの文も出現している．

\end{itemize}
\vspace{-1.5mm}
\section{おわりに}

 George A. Miller は人間の短期記憶の容量
は７±２程度のスロットしかないことを提唱
している\cite{miller56}．本研究では，京大
コーパス\cite{kurohashi_nlp97}を用い
て日本語文の各部分において係り先が未決定
な文節の個数を数えあげ，その個数がおおよ
そ７±２の上限9程度でおさえられていたことを報告
した．また，英語文でも同様な調査を行ない
NP程度のものをまとめて認識すると仮定した場合
７±２の上限9程度でおさえられていたことを確認した．
これらのことは，文理解における情報の認知単位(チャンク)として
日本語と英語で文節，NPといったフレーズという同程度のものを仮定すると，
Miller の7±2の理論と，言語解析・生成において
短期記憶するものは7±2程度ですむという Yngve の主張を
整合性よく説明できることを意味する．

最後に本論文で得られた知見を再度整理しておくと以下のようになる．
\begin{itemize}
\item 
  日本語文の統語構造認識に関する調査結果において，
  文節を認知単位とすると
  Miller の7±2の理論と矛盾しない．
  
\item 
  英語文の調査結果において
  NPレベルを認知単位とすると
  Miller の7±2の理論と矛盾しない．
  このことから，NPレベルを認知単位とするとよさそうであることが
  推測される．
  また，日本語文では文節を認知単位としており，
  文節と同レベルのNPレベルを認知単位とするのは
  自然なように思える\footnote{正しいかどうかはわからないが，
    われわれの直観としては，
    短期記憶から長期記憶の意味ネットワークへの変換過程で
    格にとられるもの，格をとるものといったものが
    認知単位になるように思われるため，
    その直観から日本語と英語で同じフレーズというものが
    認知単位になるのは自然に感じられる．}．

\item 
  上記二つを仮定すると，
  日本語文，英語文の調査結果と，
  Miller の7±2の理論・Yngve の主張(言語解析・生成において
  短期記憶するものは7±2程度ですむという主張)は
  矛盾しないものとなる．
  このことから，Miller の7±2の理論・Yngve の主張が
  必ず正しいということが証明されるわけではないが，
  矛盾しない事柄が増えたという意味で理論・主張が補強された
  ことになる．
  言語処理の立場からすると，
  Yngve の主張が正しければ
  「言語解析・生成において
  短期記憶するものは7±2程度である」ことを
  実際のシステム作りに役立てることができることになる．
\end{itemize}


\section*{謝辞}

本研究の初期の段階において京大長尾真総長と議論した．
また，慶応大学メディアセンターの榎沢康子さんには
文献検索において非常にお世話になった．
また，郵政省通信総研の藤原伸彦研究員には
心理学の基礎的な事柄について教わった．
ここに感謝する．


\bibliographystyle{jnlpbbl}
\bibliography{v06n7_03}

\begin{biography}
\biotitle{略歴}
\bioauthor{村田真樹}{
1993年京都大学工学部卒業．
1995年同大学院修士課程修了．
1997年同大学院博士課程修了，博士（工学）．
同年，京都大学にて日本学術振興会リサーチ・アソシエイト．
1998年郵政省通信総合研究所入所．研究官．
自然言語処理，機械翻訳の研究に従事．
言語処理学会，情報処理学会，ACL，各会員．}
\bioauthor{内元清貴}{
1994年京都大学工学部卒業．
1996年同大学院修士課程修了．
同年郵政省通信総合研究所入所，郵政技官．
自然言語処理の研究に従事．
言語処理学会，情報処理学会，ACL，各会員．}
\bioauthor{馬 青}{
1983年北京航空航天大学自動制御学部卒業．
1987年筑波大学大学院理工学研究科修士課程修了．
1990年同大学院工学研究科博士課程修了．工学博士．
1990 $\sim$ 93年株式会社小野測器勤務．
1993年郵政省通信総合研究所入所，主任研究官． 
人工神経回路網モデル，知識表現，自然言語処理の研究に従事． 
日本神経回路学会，言語処理学会，電子情報通信学会，各会員．}
\bioauthor{井佐原均}{
1978年京都大学工学部電気工学第二学科卒業．
1980年同大学院修士課程修了．博士（工学）．
同年通商産業省電子技術総合研究所入所．
1995年郵政省通信総合研究所
関西支所知的機能研究室室長．自然言語処理，機械翻訳の研究に従事．
言語処理学会，情報処理学会，人工知能学会，日本認知科学会，ACL，各会員．}

\bioreceived{受付}
\biorevised{再受付}
\biorerevised{再々受付}
\bioaccepted{採録}

\end{biography}

\end{document}

        
