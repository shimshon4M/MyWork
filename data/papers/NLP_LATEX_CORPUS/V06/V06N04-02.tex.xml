<?xml version="1.0" ?>
<root>
  <title>音声対話システムのための対話の認知プロセスモデル</title>
  <author>荒木雅弘堂下修司</author>
  <jabstract>本稿では，音声を用いて人間と機械が対話をする際の対話過程を，認知プロセスとしてとらえたモデルを提案する．対話システムをインタラクティブに動作させるためには，発話理解から応答生成までを段階的に管理する発話理解・生成機構と，発話列をセグメント化し，焦点および意図と関連付けて構造的にとらえる対話管理機構とが必要である．さらに，入力に音声を用いた音声対話システムでは，音声の誤認識によるエラーを扱う機構を組み込む必要がある．本稿で提案するモデルは，発話理解・生成機構における各段階での処理を具体化し，それらと対話管理機構とのやりとりを規定することによる統合的な認知プロセスモデルとなっている．それらの処理の中に，音声の誤認識によって生じ得るエラーを具体的に記述し，その対処法を網羅的に記述している．このモデルを実装することによって，ある程度のエラーにも対処できる協調的な音声対話システムの実現が期待できる．</jabstract>
  <jkeywords>音声対話，対話モデル，認知プロセス，プラン認識</jkeywords>
  <section title="まえがき">本稿では，音声を用いて人間と機械が対話をする際の対話過程を，認知プロセスとしてとらえたモデルを提案する．対話システムをインタラクティブに動作させるためには，発話理解から応答生成までを段階的に管理する発話理解・生成機構と，発話列をセグメント化し，焦点および意図と関連付けて構造的にとらえる対話管理機構とが必要である．さらに，入力に音声を用いた音声対話システムでは，音声の誤認識によるエラーを扱う機構を組み込む必要がある．これらの機構は従来，比較的独立して研究されてきた．発話理解から応答生成までを通してモデル化したものに関しては，大きく分類して並列マルチエージェント(およびそれに付随する分散データベース)によるモデルと，逐次的なモジュールの結合によるモデル,とが提案されている．並列マルチエージェントモデルは様々なレベルの制約を同時に発話理解・生成に用いているという人間の認知プロセスのモデル化になっているが，制御の難しさ・確実な動作保証の難しさから，対話システムの実現には逐次的なモジュール結合方式がよく用いられている．逐次的なモジュール結合方式において，音声対話システムに不可欠な発話の柔軟な解釈や次発話の予測を行うためには，個々のモジュールが常に参照できる情報を集中的に管理する対話管理機構が必要になる．対話管理機構に関して，Groszらは言語構造・意図構造・注意状態の3要素に分割してモデル化を行っている．言語構造をとらえる方法としては，スタックによるモデル化,,とAND-OR木によるモデル化,,がある．スタックによるモデル化は実現しやすく，注意状態との関係が明確であるという利点を持つ．しかし，入れ子構造をなさないような副対話が生じた場合にその管理が難しい．また，ユーザから主導権を取る発話(典型的にはユーザの誤った知識・方略を協調的に修正する発話)を生成した場合には，いくつかのスタック要素のポップを伴うことが多く，ユーザが主導権を改めて取ろうとしたときに必要な情報がスタックから消えているという状況が生じる．また，原則としてスタックからポップした情報にはアクセスできないので，音声の誤認識による誤解を(しばらく対話が進んだ後で)修正する必要のある音声対話システムに用いるには適していない．一方，AND-OR木によるモデル化は，基本的にタスクの問題構造の記述であり，Groszらの言語構造と意図構造とを混同してしまっているので，タスクの問題構造に従わない対話(例えば詳細化対話やシステムの能力に関するメタ的な質問など)は特別に扱わなければならないという欠点を持つ．これらのことを考え合わせると，音声対話に適した対話管理は，焦点とする範囲を適当に絞りながらも過去の対話履歴にアクセスする可能性を残した方法を用いて，言語構造と意図構造を区別して管理する必要があるといえる．では言語構造と意図構造とを区別してモデル化し，これらを会話ゲームと行動ゲームと呼んでいる．しかし，それぞれのゲームがどのように表現されるかについては部分的にしか示されておらず，音声対話システムを構成するには不十分であるといえる．さらに，音声対話システムに適用する対話モデルには，音声の誤認識によるエラーに対処する機能が不可欠である．従来研究の多くは発話単位でのロバストな解析を実現することに目標が置かれ，いくつかの例外を除いては，対話システムに入力される発話または意味表現はユーザの意図したものであることが前提になっていた．しかし，ある単語が同一カテゴリーの単語と置き換わった場合や選択格に関する情報が欠落していた場合などは，ロバストな解析では対処できないので，対話レベルでの対処が必要となる．以上の議論より，我々は音声対話システムのための対話モデルとして，逐次的なモジュール結合による発話理解・生成機構，言語構造と意図構造とを区別した対話管理機構，それら相互の密接な情報のやりとりによる頑健な処理の実現が必要であると考えた．本稿で提案するモデルは，(1)で提案された伝達行為理解のプロセスモデルを音声対話システムに適用可能なレベルまで具体化し，(2)それらと言語構造を表現した会話空間，意図構造を表現した問題解決空間とのやりとりを規定し，(3)個々のプロセスで同定可能な誤りへの対処法を網羅的に記述したものである．このモデルを実装することによって，ある程度のエラーにも対処できる協調的な音声対話システムの実現が期待できる．以後本稿では，我々のモデルに関して発話理解・生成機構，会話レベルの管理機構，問題解決レベルの管理機構について順に説明し，最後に動作例を示す．</section>
  <section title="対話処理の認知プロセスモデル">本章ではまず，我々のモデルのベースとなっているAirentiらの伝達行為理解のモデルについて概観した後，我々のモデルで拡張を行った点を中心に各段階での処理について説明する．</section>
  <subsection title="Airentiらの伝達行為理解のモデル">対話における認知プロセスのモデル化では，相手の発話を聞いてから自分の発話を生成するまでに，どのようなプロセスによって，どのような信念の変化が起こっているのかをとらえる必要がある．Airentiらは，この認知プロセスを会話ゲームと行動ゲームという2つのゲームによってモデル化し，主に伝達行為を理解するという側面においての分析を行っている．会話ゲームは(1)意味理解，(2)意図理解，(3)伝達効果，(4)意図生成，(5)応答生成の5段階に分れており，各段階の処理における目標とするタスクの集合および処理の流れを決めるメタルールからなっている．図にAirentiらの提案した会話ゲームを示す．ここで用いる述語の定義を付録に示す．これらのプロセスは標準的な処理では(1)から(5)までが順に行われ，いずれかの段階でタスクが達成できなかった場合は，即座に応答生成に行く．会話ゲームは，基本的に理解から生成に至るまでの1ターンを説明するために用いられたもので，対話全体を管理できるほどには具体化されていない．また，会話ゲームを対話全体が扱える程度に拡張しようとすると，明確化対話の挿入や応答の省略などの現象を会話ゲームの規則として記述せねばならず，規則の組合わせが手に負えないほどの量になってしまうことが予測される．一方，行動ゲームは妥当性条件と参加者の行為の集合からなるとされている(図)．しかし，どのような知識表現を用いるか，どのような推論ができるのかが明確にされていないため，意味理解段階において，ある表層発話がその行動ゲームの手となるかどうかの判定に用いられたり，意図理解段階において，ある行為がその行動ゲームの手となるかどうかの判定に用いられたりしており，あやふやな位置付けになっている．</subsection>
  <subsection title="認知プロセスモデルの概要">我々は，対話における言語構造に関して，会話ゲーム中の局所的な制約として記述するのではなく，行動ゲームと同様に認知プロセス中から参照されるものとして，言語構造を表現した空間を設定する．行動ゲームに対応するものを問題解決空間，言語構造を表現したものを会話空間と定義する．このことによって，各プロセスの処理は比較的単純でありながら，対話の局所的な単位であるやりとりにおけるフェーズの把握や対話全体における問題解決過程の把握ができるモデルとなる．我々の認知プロセスモデルの概要を図に示す．さらに我々はこのモデルの各段階において，音声の誤認識への対処が行えるように拡張を行った．認知プロセスに誤認識への対処法を組み込むアプローチは，発話理解や問題解決構造に組み込む方法に比べて，発話スタイルやタスクへの依存度が少ないので，より一般性のある方法であるといえる．以後，我々のモデルにおける各段階での処理について，主にAirentiらのモデルをどのように拡張したかという視点から説明する．</subsection>
  <subsection title="意味理解">Airentiらのモデルにおける意味理解段階の処理は，ゴールとして_yx_xまたは_yx_xyG(x,y)を得ることとしている．後者は，発話が直接に行動ゲームの手となるような場合(行動ゲームgreetingにおける``Haveaniceday.''のような発話)であり，システムとの対話においては例外的であると思われるので，ここでは前者の拡張について議論する．Airentiらは表層発語内行為(assertive,interrogative,directive)から話者の意味したもの(述語express中の命題)を導き出す規則を明示しているが，自然な音声対話においては述語の省略や代用表現(「〜お願いします」など)がよく用いられるので，表層的な情報だけでは話者の意味したものが特定できない場合が多い．そこで，対話の局所的な情報を何らかの形式で保持しておき，それを参照しながら意味表現を生成する処理が必要になる．我々のモデルでは，表層発語内行為と発語内行為との対応規則を用いるのではなく，ロバストパーサの出力として仮定している「全体として整合した部分的な意味表現」を，局所的な対話文脈に位置付けるという方法で意味理解を行っている．ここで部分的な意味表現とは，キーワード・句・文のそれぞれのレベルで解析できた範囲でロバストパーサが出力する意味表現であり，例えば述語部分の解析に失敗した場合には，句に相当する意味表現が複数出力されることを仮定している．それが全体として整合しているとは，複数出力された意味表現を組み合わせてひとつの発話の意味表現を構成し得ることを指しており，一文一格の原理を満たさない場合や，従属関係になりえない述語レベルの意味表現が複数ある場合などは全体として整合していないことになり，ロバストパーサの段階で解析失敗となる．この意味表現を対話文脈に位置付けるという方法は発話には文脈独立な意味表現が存在するという表層発語内行為仮説(literalmeaninghypothesis)に基づいたものであり，処理は以下の2段階に分割される．入力発話から，全体として整合した部分的な意味表現を抽出する．これは表層情報のみから決まるもので，理想的には表層発語内行為と命題内容を導き出す．その部分意味情報から発語内行為への対話文脈に応じたマッピングを行う．ここで，(1)の段階が達成されない場合(すなわちロバストパーサによって何も意味表現が生成されない場合)は，応答生成段階に制御を移し，再入力を促す発話を生成する．(1)の処理をいかに頑健に行うかということはロバストパーサの問題であり本稿では扱わないが，この時点でいかなる誤りも存在しないと仮定するわけではない．すなわち，表層発語内行為や命題内容を構成する要素の中に音声の誤認識による誤りが含まれている場合でも，これ以降の処理で検出・修復を行う．例えば(1)の段階の処理としては，個人スケジュール管理タスクにおける「2時から会議を登録して下さい．」というユーザxからシステムyへの発話に対して，その命題内容register([[start_time,2],[obj,meeting]])を抽出し，表層発語内行為を組み合わせて，という命題が共有信念として得られる．これに続く(2)の処理として，この共有信念からユーザの発語内行為を認識することを目的とする．発語内行為の認識の前提として，意味理解段階ではまず発語内行為の分類を考える．発語内行為は大きく働き掛けと応答に分類できる自然な対話では，応答に対する了解・相手の発話を促す相槌・伝達そのものの調整などの行為があるが，本稿におけるモデルでは音声対話システムを対象としているので，働き掛けと応答のみを扱う．ので，ここでは命題内容と表層発語内行為を基にして得られた共有信念から，以下のどちらに分類できる行為であるかを認識し，その表明された内容を共有信念とすることを意味理解段階の目標とする．ユーザxがシステムyに行為eをしてほしい(_x_ye)と表明した(働き掛け)ユーザxが信念pを持っている(_xp)ということを表明した(応答)しかし，表層発語内行為には働き掛け／応答の双方の機能と対応するものがあり，また，音声対話によく出現する述語の省略・代用表現によって，この機能を決定するためには対話の局所的な知識が必要となる．我々のモデルでは章で述べる会話空間に対して，ここで得られた要素を局所的対話文脈に位置づけるという処理を行うことによって，これらの問題を扱っている．さらに会話空間では入力発語内行為および命題が，現在維持している対話履歴と整合しているかどうかを判定し，整合していなければ誤認識とみなして応答生成段階に処理を移し，問い返しの応答を生成する．以上の意味理解段階の処理をまとめると図に示すようになる．</subsection>
  <subsection title="意図理解">対話において発語内行為を成功させるには，話者の意図と，その意図を伝えようとする意図(伝達意図)とが聴者に理解されることが必要であり，さらにそれらが相互に信念として持たれている必要がある．すなわち，対話において聴者が話者の意図を理解する(あるいは話者の発語内行為が成功する)とは，「話者の意図と，その意図を伝達しようとする意図とを話者と聴者の共有信念とすること」である．では，ここでは話者の持つ意図はどの程度具体化されているべきであろうか．対話システムが知的な振る舞いをするためには，対話がタスク構造に従って構造化されており，かつ各副対話が適切にその機能を明らかにされている必要がある．すなわち話者の意図として話者が持つプランが聴者に理解されている状況が望ましい．よって，意図理解段階の目的は，話者の発語内行為およびプランを認識することとなる．しかし，対話の初期段階では話者のプランに関して複数の候補が考えられる状況がある．この場合，どのようにして対話を維持するかについて，異なる対話戦略が考えられる．例えば，においては，プラン候補が複数ある場合に，それらに(1)前提の失敗，(2)順序不整合，(3)より良いプランの存在，(4)欠点なし，のいずれかのラベルを付け，ラベルが同じものに揃うまで詳細化のための副対話を行うアルゴリズムが提案されている．この手法はシステムが扱うプランが多数ある場合に有効であると考えられるが，必ずしも全てのタスクが副対話生成による冗長性をカバーするほどの数のプラン候補を持つとは限らない．Airentiらのモデルにおいては，この段階で相手の行動ゲームが認識されなければ応答段階に処理を移すことになっている．これは，相手の発話によって行動ゲームが唯一に同定されなければ，その発話内容を無視して行動ゲームの同定を行うための発話を生成することを意味するので，協調的なシステムの振る舞いとしては適当ではない．我々は，冗長な詳細化用副対話やユーザ発話を無視した副対話の生成を避けるために，プランが唯一に特定できなければ，表層的なやりとり規則で対話を維持し，漸進的にプランを認識する方法を提案している．対話の初期段階，すなわちプランがまだ共有信念になっていない段階では，相手の発語内行為の意図に加えて，話者のプランを伝えようとする意図(_xy_x_xyG(y,x))を共有信念とするよう試みる．ここで，話者のプランを伝達しようとする意図を共有信念とすることが，心的状態の更新に進む．プラン認識の方法は章で説明する．一方，きなかった場合は，会話空間上で典型的なやりとりを構成するような展開を行って，意図生成に進む．ここで典型的なやりとりとは，相手の発話と，その発話に含まれる情報のみで対応できる応答からなるものであり，質問に対する回答や情報伝達に対する受諾などの発話対からなるものである．一方，プランがすでに共有信念になっている場合は，その実行のステップとなる行為または情報を伝えようとする意図(_xy_x_ye_yx_xyp)を共有信念とする．意味理解段階の処理をまとめると図に示すようになる．</subsection>
  <subsection title="心的状態の更新">この段階では意図理解の結果に基づいて，必要があれば心的状態を更新する．ここでの処理はAirentiらのモデルと同様である．意図理解で新たにプランが認識された場合は，以下の(1)の処理を行いながら，入力発話に応じて(2)または(3)の処理を行う．既にプランを意図している場合は，(2)または(3)の処理を行う．ここでの推論は対話エージェントとしての協調原則に基づいたものである．(1)および(2)は入力されたプランや行為の要求を処理するという意味でattentivenessconstraintを実現したものであり，(3)は共有知識の食い違いを最小限にするsharedknowledgepreferenceを実現したものである．話者の意図があるプランを提示するものであれば，そのプランが達成不可能でなければ(問題解決空間においてそのプランを達成するのに必要な分割リンクのうち，達成不可能であることが判明しているものがなければ)，そのプランを意図する(_x_xyG(y,x))．話者の意図がある行為をすることであれば，その行為が何らかの役割を果たすものであり(その行為と認識済みのプランが分割リンクを介して繋がっている)，かつ達成不可能でなければ，その行為を意図する(_y_ye)．話者の意図がある信念を表明するものであり，自分がそれと矛盾する信念を持っていなければ，その信念を保持する(_yp)．これらの処理を行った後，意図生成に移る．心的状態の更新段階の処理をまとめると図に示すようになる．ここで得られた命題は，以後の発話の処理に用いる．共有信念として持ったゴールについては，それを達成することを対話の目標とし，目標達成に関連する命題については，これと矛盾する命題がユーザによって言及された(すなわち現在の発話または過去の発話のどちらかに認識エラーが存在した)ことを検出するのに用いられる．</subsection>
  <subsection title="意図生成">ここでは意図理解の結果と心的状態の更新の結果から，次にどのような意図を持つべきかを決める．この段階では，我々のモデルはAirentiらのモデルの詳細化と位置付けられるが，その詳細化はAirentiらのモデルでは考慮されていなかった認識誤りに基づく誤解の解消に役立つ発話の生成に寄与するものである．具体的には，相手のプラン・働き掛け・応答が受け入れられないときに，その根拠となる命題を心的状態および問題解決空間で探索し，相手の発話内容の問い返しとともに，受け入れられない根拠を応答として述べることによって対話参加者間の信念の違いを明示するものである．この信念の違いが認識誤りによって生じた場合は，それを修正する副対話が生成される．我々のモデルにおける意図生成は以下の規則に従って行われる．ユーザのプランを認識した場合心的状態の更新段階において，プランを遂行するという意図を持った場合，(2)の処理に移り，ユーザの働き掛けに応じた意図を生成することによって暗にプランを意図することを示す(_yx_y_yxG(y,x)_yx_y_ye)．心的状態の更新において，プランを受け入れない(プランは認識できたがそれを意図しない)と決めた場合は，システムの知識の中にそのプランを達成不能にするものがある場合なので，システムはプランを受け入れないことを明示的に示すと共に，そのプランの障害になっている命題をユーザに伝える．(_yx_y_yxG(y,x)_yx_yp)あるプランを認識しそれを遂行するという意図を持った場合(あるいは既にプランが認識されている場合)，ユーザの働き掛けに応じて意図を生成する．ユーザの働き掛けが情報要求ならば，検索結果をユーザに応答する意図(_yx_ye)を持つ．ユーザの働き掛けが行為要求ならば，その行為が達成可能であるかどうかを問題解決空間で調べる．行為が達成可能である場合，その行為を遂行し，さらに問題解決空間を探索し，そのプラン遂行に役立つ新たな行為e'を行う意図を伝達する意図(_yx_y_ye')を持つ．新たな行為e'の決定に関しては章で述べる．提案された行為が達成不可能であるか，または共有されているプランのステップではない場合は，その行為を行わないということと，その理由を示す命題を伝える意図(_yx_y_ye_yx_yp)を持つ．ユーザ発話が信念を表明するものである場合システムが表明された命題pと矛盾する命題を持っていなければ，その命題はシステムの信念となり，そのことは明示的に示さなくてもよく，新たなステップとなる行為e'を行う意図を伝達する意図(_yx_y_ye')を持つ．表明された命題pを信じないのなら否定応答をすると共に，システムが持っているそれと矛盾した命題p'を伝える意図(_yx_yp_yx_yp')を持つ．意図生成段階の処理をまとめると図に示すようになる．</subsection>
  <subsection title="応答生成">では応答生成は例示に止まっている．我々は，応答生成を起動された処理段階および伝達意図の違いによって異なったテンプレートを用いることによって実現している．意味理解処理の失敗によって起動された場合は単なる問い返し(「もう一度言ってください」)を生成する．意図生成から起動された場合は，表に示すそれぞれの伝達意図に対応するテンプレートを用いて，応答文を生成する</subsection>
  <section title="会話レベルの管理機構"/>
  <subsection title="会話空間の概要">これまでに述べた認知プロセスモデルにおいて，発語内行為の理解，省略・参照表現の処理，および相手の発話に対する適切な応答発話の生成のために，会話が現在までどのように進んできたかを管理する機構が必要となる．従来の対話モデルでは，これら(またはその一部)の処理を行うためにスタックを用いることが多かった．例えば，Groszらのモデルでは焦点管理のために，対話のある時点でもっとも顕著な対象・属性・対話セグメントの目的をスタックを用いて管理している．しかし我々は，スタックの利用は以下の理由で音声対話システムには適さないと考える．Groszらのモデルでは対話が入れ子構造をなすことを前提としてスタックを用いているが，自然な対話では入れ子が必ずしも明確になるわけではない．音声の誤認識による誤解の修正の際には，対話履歴の任意の時点の情報が必要になるが，既にスタックからポップされた情報には原則としてアクセスできない．我々のモデルでは会話レベルの最小単位としてやりとりを想定し，このやりとりを管理することによって，発話の対応付けを行う．やりとりは，基本的に「働き掛け」と，その働き掛けに対する「応答」からなる．ただし，詳細化対話や音声の誤認識の修復のために，応答の前または代りに働き掛けおよびそれに対する応答が挿入される場合もある．このやりとり単位の管理と，そのやりとりによって達成された行為を4章で説明する問題解決空間で管理することによって，明示的な入れ子構造を用いずに，対話の流れを追跡できる．また，参照の解釈・省略発話の解析・誤認識による誤解の解消のために，対話に現れた句レベルの情報から，発話レベルの情報，やりとりレベルの情報を階層的な動的ネットワークを用いて管理する．この動的ネットワークを会話空間と呼ぶ．会話空間にはフレーズノード，インスタンスノード，スロット充足ノードの3種類のノードを設定する．インスタンスノードとスロット充足ノードは，ほぼCharniakらの定義に従っている．基本的にリンクは，両端のノードが表す命題間の因果関係を条件付き確率の行列を用いて表現できるようになっている．各インスタンスノードはスロット充足ノードを経由して結合される．ただし，フレーズノードは直接対応するインスタンスノードに結合される．会話空間の構成要素の関係の例を図に示す．</subsection>
  <subsection title="意味理解段階との相互作用">会話空間は意味理解段階と以下のような相互作用を行い，意味表現を生成し，対話の履歴を管理する．意味理解段階からの入力は全体として整合した部分的な意味表現で，出力は発語内行為である．意味理解の結果として得られた命題表現の中で句に相当する部分をフレーズノードとして，会話空間に導入する．フレーズノードが意味理解で，どのような概念のインスタンスとして生成されたかを示す句レベルのインスタンスノードを生成し，フレーズノードとリンクを張る．(2)で生成された句レベルのインスタンスノードが，発話の中でどのような役割を果たすか(構文的な意味では格に相当する)を示すスロット充足ノード，およびそれらをまとめる発話レベルのインスタンスノードを生成し，それぞれリンクを張る．(1)で生成された発話レベルのインスタンスノードが，やりとりの中でどのような役割を果たすかを示すスロット充足ノード，およびそれらをまとめるやりとりレベルのインスタンスノードを生成し，それぞれリンクを張る．ここまでの処理が達成されると，やりとりの中での役割を入力発話の発語内行為として出力する．このように会話空間という形式で対話に現れた情報を管理することによって，Groszらが焦点として扱った対象・属性・対話セグメントの目的のみではなく，やりとりに現れた全ての要素を，処理対象としている発話のインスタンスノードからの距離(パスの長さ)をコストとして用いることにより優先度を付けて，誤認識による誤解の解消や省略・参照表現の処理に用いることができる．</subsection>
  <subsection title="やりとり規則による対話の継続">プランが同定されるまでの対話の初期段階のやりとりや，問題解決に関係のない誤認識の修復のやりとりなどは，心的状態の更新を経ずに意味理解段階で得られたやりとりに関する情報を使って行う．このようなやりとりは意図理解段階の処理の失敗(プラン認識の失敗および誤解の検出)によって起動される．プラン認識の失敗の場合は，会話空間中で現在展開中のやりとり単位を継続させる発語内行為を意図生成段階へ出力する．また，誤解が検出された場合は，修復の副対話をやりとり内に挿入し，修復発話に対応する発語内行為を意図生成段階へ出力する．</subsection>
  <subsection title="応答生成段階との相互作用">生成された発話意図から応答文を生成する際に，同じやりとりを構成する発話であれば，展開された意味表現から主題格などを省略する．入力としては全ての要素が列挙された意味表現，出力は応答として出力するのに適切な省略を行った意味表現である．</subsection>
  <section title="問題解決機構"/>
  <subsection title="問題解決空間の概要">我々のモデルでは，問題解決空間と呼ぶネットワーク構造の知識表現を用いて，タスクレベルの対話管理を行っている．問題解決空間はタスクにおけるプランとサブプランの関係や，プランとそれを達成するための行為との関係を記述した静的ネットワークである．本稿で説明に利用するタスクである個人スケジュール管理を行うシステムに対応した問題解決空間の例を図に示す．問題解決空間では，葉ノードが行為を表し，それ以外のノードがプランを表す．リンクは2種類あり，プランの間の抽象関係を表現する抽象化リンク(図の上向き太矢印)と，プランからサブプランや行為への分割を表す分割リンク(図の下向き細矢印)がある．またプランの分割にはAND分割(下向き細矢印をまとめる記号のついたもの)とOR分割がある．</subsection>
  <subsection title="意図理解段階との相互作用">意図理解段階では話者のプランを認識するために，意味理解段階で得られた発語内行為を問題解決空間に渡し，プラン認識を行う．問題解決空間におけるプラン認識には最小被覆法を適用する．この手法は基本的には，問題解決空間において既に実行された(または観測された)行為の全てを含むサブグラフを求めるものである．問題解決空間のプランを表すノードの中で，各々のタスクにおける基本的なプランすなわち，1まとまりの対話によって達成されるプランをエンドイベントと呼ぶ．ユーザが1対話において，プランを1つしか持たないという前提に立てば，プラン認識の問題はエンドイベント集合から，ユーザの持っているプランに対応する要素を1つ選ぶことになる．問題解決空間では，意味理解結果として得られたユーザの行為を入力として，新たに入力された行為と以前に入力された行為をカバーするプランを最小被覆法を用いて認識し，プランが認識された場合はそのプランを，プラン認識に失敗した場合はそのことを意図理解段階に出力する．</subsection>
  <subsection title="意図生成段階との相互作用">発話生成段階においては，問題解決空間には意図生成段階からのユーザの行為と，更新された心的状態が入力される．もし，ユーザの行為が情報要求であれば，データベース検索を行ってその値を答えるという処理が意図生成段階でなされるが，それ以外の場合はユーザの行為に応じて，次のシステムの行為をAND-OR木上の未達成の行為ノードとして探索し，意図生成段階に出力する．</subsection>
  <section title="対話モデルの処理例">本章では，対話モデルの各段階での処理，および会話空間・問題解決空間での処理を例によって説明する．個人スケジュールを管理するシステムsとユーザuとの対話例を図に示す．</section>
  <subsection title="第1ターンの処理とプラン認識">まず前提として，表層発語内行為及び命題内容の抽出はここでの対話モデルで扱う問題の対象外と想定しているので，U1に対してという表層意味表現が得られるものとする．これに対して，まず意味理解段階の処理としては，対話の初期状態で会話空間に何も対話履歴がない状態であることと，入力発話がdirectiveという表層発語内行為を持つことから，これをユーザの働き掛けと解釈し，という共有信念が形成され，意味理解段階の処理が成功したことになるので，処理を次の意図理解段階に進める．ここまでの処理を表に示す．次に，意図理解段階の処理としてはユーザのプランがまだ共有信念になっていないので，_sをプラン達成のための1ステップとするようなプランが存在するかどうかを問題解決空間で探索する．ここではregister_meeting_planが唯一に定まるので，ユーザの伝達意図として以下の2つの共有信念が形成される．ここまでの処理を表に示す．*1cm_su_us_u_us*1cm_su_us_u_s*30mm(3)3心的状態の更新の段階では，意図理解で新たにプランが認識されたので，このプランにシステムとして合意するか，また，ユーザの意図する行為を行うかどうかを決め，その結果をシステムの心的状態に反映させる．ここでは，問題解決空間のregister_meeting_plan以下の行為ノードの中で，達成不可能であることがわかっているものがないことを確認し，このプランを意図する．また，_sがこのプラン達成のための行為であることから，これを実行することを意図する．すなわち，ここで以下の命題をシステムの心的状態に新たに導入する．ここまでの処理を表に示す．次に，意図生成段階の処理としては，プランに合意し，ユーザの意図した行為が達成可能である場合であるので，2.6節で説明した(2-b-1)の処理を行う．ここで，問題解決空間のregister_meeting_plan以下を探索し，新たな行為e'として終了時刻の同定を選び，その達成を意図する．ここまでの処理を表に示す．次に，応答生成段階の処理としては，テンプレート_su_s_sを利用して，ユーザに情報伝達行為inform_refを意図させるために，S2の質問文を生成する．ここまでの処理を表に示す．</subsection>
  <subsection title="会話空間における意図生成の例">次に，述語の誤認識が生じたU3の解析例を説明する．述語の誤認識によるエラーは，意味理解では検出できない場合がある．その時点までの対話の文脈からして不適当な発語内行為が入力されたことが意図理解段階によって検出されて，その修復のためのやりとりがこの会話空間上で展開される．ここまでのやりとりの展開はU1:「働き掛け」，S2:「働き掛け」となっており，会話空間上でのやりとりのパターンから，U3の発話はS2の働き掛けに対する応答またはそれに関連した働き掛けが予測されている．しかし，U3を意味理解した結果は，このどちらにも相当せず，述語の誤認識が起こったことが考えられる．そこで会話空間上に修復のやりとり(S4-U5)を展開する．ここで修復が成功したので，U3は改めてと解釈され，以下，と処理され，応答発話S6が生成される．</subsection>
  <subsection title="問題解決空間における意図生成の例">U3の処理で示した例は述語のエラーに対処するものであった．一方，内容語のエラーは，同一範疇の語と置換した場合は対話文脈を参照しないと検出されない場合が多い．ここでは，問題解決空間における処理で検出可能な内容語のエラーが生じたU7の処理について説明する．ここまでの問題解決空間の処理で，U1でユーザプランが明示されていることから，プラン認識は成功している．その場合，それ以降の問題解決空間の役割はやりとりがそのプランを達成するためのサブプラン達成を目的とするものか，またそのサブプランが所定のインスタンスで達成可能なものかを判定することである．S6の発話によって，場所の設定というサブプランに「小会議室」をインスタンスとして達成を試みるが，失敗したとする．そこでこれに対応した意図生成(2.6節の(2-b-2)の場合)を行い，エラー訂正のやりとり(S8-U9)が生成される．問題解決空間におけるこのような処理によって，内容語の誤認識にも対処できるようになっている．</subsection>
  <section title="むすび">本稿では，音声を用いて人間と機械が対話をする際の対話過程を，認知プロセスとしてとらえたモデルを提案した．発話理解から応答生成までを段階的に管理する発話理解・生成機構と，発話列をセグメント化し焦点および意図と関連付けて構造的にとらえる対話管理機構とについてモデル化を行い，音声の誤認識によるエラーを扱う機構を組み込んだ．今回提案したようなモデルがどの程度有効であるかを調べるために，我々は通信路にノイズを混入させたシステム−システムの自動対話による評価法を提案している．今後，適当なタスクを設定し，モデルの有効性を検証するとともに，タスク・文などの複雑さの程度を，モデルを評価する上でどのように扱うべきであるかという指針を立てることも目標とする．</section>
  <section title="述語の定義">document</section>
</root>
