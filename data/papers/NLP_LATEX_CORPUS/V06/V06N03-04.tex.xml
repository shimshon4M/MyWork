<?xml version="1.0" ?>
<root>
  <title>文末から解析する統計的係り受け解析アルゴリズム</title>
  <author>関根聡内元清貴井佐原均</author>
  <jabstract>係り受け解析は日本語文解析の基本的な方法として認識されている．日本語の係り受けは，ほとんどが前方から後方であるため，解析は文末から文頭の方向へ解析を進める事は効率的であり，これまでもルールベースの解析手法ではいくつかの提案がある．また，統計的文解析は英語，日本語等の言語を問わず数多くの提案があり，その有効性が確認されている．本論文では，上記の二つの特徴を兼ね備えた日本語文係り受け解析を提案し，その実験結果を示し，有効性を実証する．システムの精度は，正しい文節解析ができた所から開始した場合，京大コーパスを使用した実験で係り受け正解率が87.2%，文正解率が40.8%と高い精度を示している．ビームサーチのビーム幅を調整した実験では，ビーム幅を小さくする事による精度の劣化が認められなかった．実際にビーム幅が1の際に得られた結果の95%はビーム幅20の時の最良の結果と同一であった．また，N--best文正解率を見た時には，Nが20の時には78.5%という非常に高い結果を示している．解析速度は，解析アルゴリズムから推測される通り，文節数の2乗に比例し，平均0.03秒(平均文節数10.0)，最長文である41文節の文に対しては0.29秒で解析を行なった．</jabstract>
  <jkeywords>係り受け解析，構文解析，統計的手法，最大エントロピー法</jkeywords>
  <section title="はじめに">係り受け解析は日本語文解析の基本的な方法として認識されている．日本語係り受けには，主に以下の特徴があるとされている．我々はこれらの特徴を仮定として採用し，解析手法を作成した．係り受けは前方から後方に向いている．(後方修飾)係り受け関係は交差しない．(非交差条件)係り要素は受け要素を一つだけ持つ．ほとんどの場合，係り先決定には前方の文脈を必要としない．このような特徴を仮定した場合，解析は文末から文頭に向けて行なえば効率良く解析ができると考えられる．以下に述べる二つの利点が考えられるためである．今，文節長Nの文の解析においてM+1番目の文節まで解析が終了していると仮定し，現在M番目の文節の係り先を決定しようとしているとする(M&lt;N)．まず，一つ目の利点は，M番目の文節の係り先は，すでに解析を終了しているM+1番目からN番目の文節のいずれかであるという事である．したがって，未解決な解析状態を積み上げておく必要はないため，チャートパーザーのように活性弧を不必要に多く作る必要はないし，一般的なLRパーザー等で利用されているようなスタックにそれまでの解析結果を積んで後の解析に依存させるという事をしなくて済む．別の利点は，M番目の文節の解析を開始する時点には，M+1番目からN番目の係り受け解析はなんらかの形式において終了しており，可能な係り先は，非交差条件を満足する文節だけに絞られるという事である．実験では，この絞り込みは50%以下になり，非常に有効である．また，この論文で述べる統計的手法と文末からの解析手法を組み合せると，ビームサーチが非常に簡単に実現できる．ビームサーチは解析候補の数を絞りながら解析を進めていく手法である．ビーム幅は自由に設定でき，サーチのための格納領域はビーム幅と文長の積に比例したサイズしか必要としない．これまでにも，文末からの解析手法はルールベースの係り受け解析において利用されてきた．例えば．しかし，ルールベースの解析では，規則を人間が作成するため，網羅性，一貫性，ドメイン移植性という点で難がある．また，ルールベースでは優先度を組み入れる事が難しく，ヒューリスティックによる決定的な手法として利用せざるを得なかった．しかし，本論文で述べるように，文末から解析を行なうという手法と統計的解析を組み合せる事により解析速度を落す事なく，高い精度の係り受け解析を実現する事ができた．統計的な構文解析手法については，英語，日本語等言語によらず，色々な提案が80年代から数多くあり，現在，英語についてはRatnaparkhiのME(最大エントロピー法)を利用した解析が，精度，速度の両方の点で最も進んでいる手法の一つと考えられている．我々も統計的手法のツールとしてMEを利用する．次の節でMEの簡単な説明を行ない，その後，解析アルゴリズム，実験結果の説明を行なう．</section>
  <section title="最大エントロピー法の利用">最大エントロピー法(ME)は，トレーニングデータ中の素性の頻度等の情報から特徴的な素性を学習し，その特徴を生かした確率的なモデルを作成する方法である．素性とは，我々の場合，二つの文節間の係り受けの確率を計算するための情報であり，そこで使用される基本素性には表~に挙げた種類の素性を利用した．括弧内の数字は素性値の数である．また，これらの素性を組合せた組合せの素性も利用した．その数は約4万個である．素性の詳細，および素性の選択による比較実験についてはを参照されたい．そして，テストの際には，トレーニングデータを使用して学習されたモデルを基にテスト文中に与えられた二つの文節の素性からその二つの文節の係り受けの確率を計算する．これまでの多くの先行研究と同様にすべての係り受けは独立であると仮定し，一文全体の係り受け確率を，その文中にあるそれぞれの係り受けの確率の積で表す．そして，一文全体の確率が最大となるような係り受け関係が正しい係り受け関係であると仮定する．</section>
  <section title="解析アルゴリズム">この章では，解析アルゴリズムを紹介する．まず，例を利用して，概略を説明し，その後フォーマルな形で解析アルゴリズムを示す．特徴は文末から文頭に向けての係り受け解析と確率を利用したビームサーチにある．例には以下の入力文を用いる．文節解析まで終っていると仮定しており，文節の区切は''|''で示される．説明図において，文節の係り先は，それぞれの文節の下にある番号で示される．-----------------------------------------------------------&lt;初期状態&gt;ID123456彼は，|再び|パイを|作り，|彼女に|贈った．-----------------------------------------------------------verbatim解析手順flushleft文末から二つ目の文節文末の文節は係り先はなく，文末から二つ目の文節は必ず文末の文節にかかる．この結果は以下のようになる．-----------------------------------------------------------&lt;文末から二つ目まで&gt;ID123456彼は，|再び|パイを|作り，|彼女に|贈った．候補6------------------------------------------------------------verbatim文末から三つ目の文節この文節(「作り，」)は，係り先として二つの文節が考えられる．一つは「彼女に」であり，もう一つは「贈った」である．MEを利用して計算された確率を付与した二つの解析候補を作成する．(それぞれの確率は0.1，0.9としてあり，各候補の最後には，総合の確率(各係り受けの確率の積)を括弧の中に示す．)-----------------------------------------------------------&lt;文末から三つ目まで&gt;ID123456彼は，|再び|パイを|作り，|彼女に|贈った．候補166-(0.9)候補256-(0.1)-----------------------------------------------------------verbatim文末から四つ目の文節それぞれの候補に対して，「パイを」の文節の係り先を求める．候補1に対しては，非交差の条件から「パイを」の文節は「彼女に」の文節に係る事はありえない．したがって「パイを」が「作り，」と「贈った」のそれぞれに係る候補を作成する．候補2についても同様にする．-----------------------------------------------------------&lt;文末から四つ目まで&gt;ID123456彼は，|再び|パイを|作り，|彼女に|贈った．候補1466-(0.54)候補2666-(0.36)候補3456-(0.05)候補4656-(0.04)候補5556-(0.01)-----------------------------------------------------------verbatimこのように計算していくと，候補の数は文頭に行くにしたがって増えていく．しかし，解析途中の候補の数に上限を設けて，ビームサーチを行なえば，解析候補数の爆発は防げる．また，上記の例から直感的に分るように，その場合でも解析精度の悪化も少なく抑えられる．実際の実験で得られたビーム幅と精度のデータは次章で紹介する．例えば，この例でビーム幅を3とすると，候補4と候補5はこの段階で捨てられ，以降の解析には使用されない．それ以降上記で示したような解析を文頭まで繰り返す．例えば，ビーム幅を3とした場合の解析結果は以下のようになる．-----------------------------------------------------------&lt;文頭まで&gt;ID123456彼は，|再び|パイを|作り，|彼女に|贈った．候補164466-(0.11)候補244666-(0.09)候補364656-(0.05)-----------------------------------------------------------verbatim以下にフォーマルな解析アルゴリズムを示す．----------------------------------------------------------------Length:入力文節長Input[Length]:入力文N:ビーム幅Cand[Length][N]:解析結果候補(各文節の係り先文節IDの配列で表される)例えばCand[1][1]=6,4,4,6,6,-．この方法では，必要なメモリのサイズは文長とビーム幅の積以上になるが，簡単な変換で，上記のサイズに納める事ができる．add(l,cand):cand(解析結果候補)の確率がl番目の文節の解析結果候補の内のN番目のものより良い場合は，candをCand[l]の解析候補に加える．この際，N+1番目の候補になった物は捨てられる．get(l):Cand[l]の候補群から候補を取り出す．候補がなければNULLを返す．ins(i,cand):iをcandの先頭に追加する．procedure係り受け解析beginadd(Length-1,Length,-);for(i=Length-2;i&gt;=1;i--)beginwhile((cand=get(i))!=NULL)beginfor(j=i+1;j&lt;=Length;j++)beginif(iからjへの係り受けがcandにおいて有効)add(i,ins(j,cand));endifendendendend----------------------------------------------------------------verbatimこのアルゴリズムの解析時間オーダーは，文節数の2乗であり，ビーム幅をNとすると，ビーム幅に対しNlog(N)であると推測される．</section>
  <section title="実験結果">この章では，係り受け解析の実験を色々な角度から分析する．実験に用いたコーパスは，京大コーパス(Version2)の一般文の部分で，基本的にトレーニングには1月1日と1月3日から8日までの7日分(7960文)，試験には1月9日の1日分(文)を用いた．試験は頻繁に行なうと，高い成績を追及する結果その試験のデータに自然とチューニングされてしまう危険性があるので，頻繁に行なわないようにした．</section>
  <subsection title="他の手法との比較">この節では他の手法との比較を行なう．他の手法においては同じコーパスを使って評価した物がないため，その精度は参考として載せる．同じプラットフォームで同じ評価方法を用いた比較が望まれる．白井およびKNPとの比較flushleft白井は構文規則に基いた確率一般化LR法を提案している．構文および語彙的な統計情報を用い，その学習にはMEを利用している．実験では京大コーパスの文節数7〜9の文からランダムに選んだ500文の内，KNPによる文節区切がコーパスと一致した388文を対象に，白井の解析結果とKNPの解析結果の正解率を比較している．(KNPについてはを参照の事．)そこで，我々の試験コーパスの中で文節数が7〜9の文，279文における結果を用いて比較した(表~)．すべて，文末から二つ目の文節は評価から除いており，白井の方法も文節切りができた状態からの解析である．対象の文が完全に一致しておらず，対象の文の選択の方法も異なるので，参考にしかできないが，この文長の文に対しては，白井の手法に比較して3%程度良い結果を，KNPと比較した場合には3%程度悪い結果を得た．白井の実験では，EDRコーパス，RWCコーパスを利用し，トレーニングデータとしては我々よりも大きなデータを利用している．また，白井はランダムに選んだ500文については84.34%という解析結果を示している．KNPは，この評価で使用したテストコーパスに基づいて改良されており，KNPの評価結果は，トレーニングデータに対するものと言う事ができる．藤尾，春野との比較flushleft藤尾は文節間の属性の共起頻度による統計的解析手法を提案した．また，春野は決定木およびブースティングを利用した係り受け解析を行なっている．これらの評価はＥＤＲコーパスを利用し，試験対象データの選択手法も我々とは異なっているため，直接的な評価は難しい．彼等の場合は，形態素解析から解析を行なっているが，評価には文節区切が正しい物のみを利用したり，正解を自分の文節区切の結果に翻訳してから評価を行なっている．しかし，共に85%程度の正解率が出ており，我々の手法も同様な位置を占めている．これらの手法は，ほぼ利用している知識の種類が同様であり，計算の手法に違いがあるものの，同様な結果を得ていると考えていいと思う．手法の違いによる詳しい比較を行なうためにも，同じプラットフォームでの実験とそれを元にした考察が望まれる．江原との比較flushleft江原の手法は，我々の手法と同様にMEを用いており，そういった意味で比較するのは意味があるが，対象文は，NHKのニュース原稿であり，平均文節数も17.8と我々の対象にしている京大コーパスとは全く異なっている(平均文節数は10.0)．ただし，図~に示したように，我々の結果は文節数と係り受け正解率の関係はあまり変化が見られず，長いからといって必ずしも解析が困難だとは限らない．これらの理由により，単純な比較は意味がないが，正解率において，我々の手法が約10%上回っているのはなんらかの要因が存在すると考えられる．(江原の手法では正解率は76.4%と報告されている．)特に江原の方法とは素性の数に大きな差があるようである．江原が用いた一次的な素性値の数は200個程度であり，我々の一時的な素性値の数の約5000個とは大きく異なっている．また，我々は組合せの素性も4万個程度利用している．この点深く掘り下げて検討する事に意味があると考える．また，MEに利用する素性の選択に関しては，江原の他にも白井Berger等が興味深い提案をしている．</subsection>
  <subsection title="ビーム幅と精度">次に，我々の実験の中での比較結果を報告する．まずは，解析時に用いたビーム幅と精度の関係である．解析時のビーム幅が広ければ広い程，全体として確率の高い解析が得られる可能性が高くなるので，ビーム幅は高く設定した方が望ましいと考えられる．しかし，結果はその直観とは異なっていた．表~にビーム幅を1から20に変化させた時の係り受け正解率と文正解率を示す．全体的に変化は小さいが，係り受け正解率はビーム幅が3と10の時に，文正解率はビーム幅が2と3の時に最大になっている．これは，全体の確率が最大の物が正解ではなく，各段階ごとに正解を絞っていった方が正解になるという場合がある事を示している．これは「はじめに」で書いた，日本語係り受けの特徴(4)にも関係していて面白い．この結果によると，文末から文頭に係り受け解析をする際に，最良の結果のみを得たい場合には，決定的に行なってもかなり精度の良いものが得られるという事が言える．実際に，ビーム幅を1とした時に得られた答が，ビーム幅20とした時の解析結果のどこに現われるかを調査した結果を表~に示す．実際に全体の95%の場合，ビーム幅1の解析結果がビーム幅20の解析において最大の確率を持つ結果と同等であった．また，ビーム幅が1の解析において文全体が正解であった503文の中では，N=20での結果において1位の場所に同じ解析結果があったものが498文(99.0%)と非常に高い率であった(以下2位の位置が3文，3位と5位の位置がそれぞれ1文づつあった．)．これらの文においては，最大の確率を持つ解析は，文末から解析していった場合に，各文節ごとの段階においてつねに最良の結果であったという事を意味している．これは，「はじめに」で書いた特徴(4)とも関係がある．「はじめに」の脚注に書いた人間に対する実験は文節に対する割合であるので，上記の文に対しての数字は，人間の実験で得られたよりもかなり高い割合で，前方の文脈の不必要さを実証したという事になる．</subsection>
  <subsection title="N--Best文正解率">文正解率はビーム幅が1の実験では40.60%であったが，最終的に得られる解析の数を広くすればする程，正解率が向上する事が考えられる．図~にビーム幅を20として解析を行なった場合のN--best文正解率を示す．N--best文正解率とは，上位N個の解析結果を見た場合に，文中のすべての文節係り受けの解析が正しい解析結果がその中にある割合の事を言う．N=20，つまり，ビーム幅と同様の最終結果を見た場合に，文全体の係り受けが正解である解析結果が上位20個の解析結果に含まれる割合は78.5%であるという事である．この中から正解を捜し出せる理想的なシステムを開発できた場合には，文正解率が78.5%という非常に優れた解析システムができる可能性があるという事である．この結果から二つの考察ができる．まず，一点はN=1の文正解率は約40%であるのに対して，N=2で向上した割合，つまり，2番目の解析結果が正解であった割合は10%程度と非常に低くなっている．また，この40%という数字は，N=20の場合の78.5%という数字の半分以上であり，半分以上の場合においてN=1の所に正解が存在したという事を意味する．これは，我々の確率の計算手法が，まだ改善の余地はあるものの，かなり正確であるという事を示している．もう一点は，文正解率が80%あたりで飽和しており，80%程度以上の向上はNを多少大きくしても望めなさそうであるという事である(もちろん，Nをすべての組み合わせの数にすれば100%にはなるが現実的に意味はない．)．これは，我々が何か大きな要因を見過ごしている可能性がある．特に，並列構造についての解析能力が低いようである．この点を改良し，再度検討していきたいと思う．</subsection>
  <subsection title="解析速度">前章にあるアルゴリズムを分析すると，解析時間は文節長に対して2乗になっていると推測できる．実際に，ビーム幅1の時の文節長と解析速度の関係を調べた(図~)．実験はSunのUltra10，周波数(300MHz)を利用した．係り受け解析のプロセスの大きさは8M程度であった．図から実際の解析時間も，文長に対してほぼ2乗になっている事が分かる(参考の為に描き入れた二次曲線を参照．)．実際は定数部分がある為に曲線の最初の部分は分布よりも下になっていると考えられる．一文あたりの平均解析時間は0.03秒(平均文節数10.0)，最長文である41文節の文に対しては0.29秒で解析を行なった．実際，プログラムを最適化する余地は存在し，その係数については改善の余地があると考えている．また，プロセスサイズについても必要ならば，縮小する余地はあると考えている．</subsection>
  <section title="まとめ">本論文では文末から解析する統計的係り受け解析アルゴリズムを示した．日本語の係り受けは，ほとんどが前方から後方であるという特徴を生かし，解析は文末から文頭の方向へ解析を進めるという点と，色々な提案によって有効性が示されている統計的文解析を利用するという二つの特徴を兼ね備えた日本語文係り受け解析を提案した．係り受けの正解率は，正しい文節解析ができた結果から開始した場合，京大コーパスを使用した実験で係り受け正解率が87.2%，文正解率が40.8%と高い精度を示している．ビームサーチのビーム幅を調整した実験では，ビーム幅を小さくする事による精度の劣化が認められなかった．実際にビーム幅が1の際に得られた結果の95%はビーム幅20の時の最良の結果と同一であった．また，N--best文正解率を見た時には，Nが20の時には78.5%という非常に高い結果を示している．解析速度は，解析アルゴリズムから推測される2乗程度であり，平均0.03秒(平均文節数10.0)，最長文である41文節の文に対しては0.29秒で解析を行なった．また，他の手法との比較では，共通のベンチマークがない為，直接的な比較はできなかったが，各手法と同程度か優れた結果が得られたと判断した．共通のベンチマークを作る事は，お互いのシステムの特徴を直接的に比較し，技術の向上を計る為に有意義であると考えられる．また，今回は，文節切りができている点から解析を開始したが，そうでなく文からの解析を行なった場合には，評価の方法も難しくなる．特に文節切りが正解とシステムが出した結果とで異なる場合にはどのように判断したらよいかスタンダードな方法がない状態である．協力しあってこのようなスタンダードを決める事は意味があると思われる．document</section>
</root>
