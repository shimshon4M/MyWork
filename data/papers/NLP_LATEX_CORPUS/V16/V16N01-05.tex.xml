<?xml version="1.0" ?>
<root>
  <jtitle>辞書からの上位語情報抽出とオントロジー自動生成</jtitle>
  <jauthor>鈴木敏</jauthor>
  <jabstract>辞書の定義文を基にした上位語情報の抽出手法を提案し，その結果に基づく単語オントロジーの自動生成を試みた．提案するのは再帰的語義展開による情報抽出手法である．本手法では定義文を再帰的に展開し，巨大な単語集合として定義文を再定義する．このとき，定義文中に上位語が含まれるという仮定を利用すれば，非常に多くの単語を上位語候補とすることができる．この手法では上位語となる尤もらしさの指標を得ることができるため，これを利用して多数の候補の中から上位語を効率よく選択できるようになる．本手法を適用した上位語抽出実験では，構文解析を用いた既存手法を上回る精度を示した．更に本論文では，取り出された上位語情報を用いて単語オントロジーの自動生成を試みた．自動生成の手法はまだ完全なものではないが，実験結果は上位語情報の有用性を示すものであり，今後のオントロジー自動生成の可能性を示している．</jabstract>
  <jkeywords>辞書，上位語，オントロジー，自動生成</jkeywords>
  <section title="まえがき">単語オントロジーは自然言語処理の基礎データとして様々な知識処理技術に利用されており，その重要性は年々高まっている．現在広く知られている日本語オントロジーとしては，例えば日本語語彙大系等が挙げられる．日本語語彙大系は人手により編集された大規模オントロジーであり，約3,000の意味カテゴリーを木構造状に分類し，約40万語を各意味カテゴリーに割当てている．しかしながら，これらは翻訳への適用を主な目的として作成されており，利用目的によっては必ずしも適切な分類とはならない．言い換えれば，オントロジーは利用目的に応じて異なるものが求められるのである．ところが，オントロジーの作成には膨大な労力が必要であり，また，言葉が日々進化するものであることを考えると，特定目的に応じたオントロジー作成を人手で行うことは現実的に不可能である．従って，オントロジーの生成は自動化されることが望まれる．そこで本論文ではオントロジー自動生成手法の検討を行う．技術的検討を行う上では特定目的のオントロジー生成よりも，むしろ一般のオントロジーを取り扱う方が検証を行いやすい．従って，本論文ではオントロジー自動生成の第一歩として，日本語語彙大系のような一般的なオントロジーの自動生成を目的とし，検討を進めることとする．オントロジーは単語の意味的関連性を表すものであり，この点からみると，基礎となるデータは共起情報を与えるコーパスよりも単語の意味を直接定義している辞書（国語辞典）の方が適していると考えられる．辞書を用いた関連性抽出の例を挙げると，例えば，鶴丸らは辞書の定義文のパターン抽出により上位語の同定が可能であることを示している．また，オントロジーの自動獲得の試みも行われており，例えばNicholsらは定義文中に上位語が含まれているという仮定の下での単語階層化手法を提案している．上記の手法は，定義文を構文解析し，その主辞を上位語とするものであるが，必ずしも定義文の主辞が上位語であるとは限らないため，決定論的に上位語を決めてしまうとオントロジー生成時に矛盾を引き起こすことになる．従って，決定論的に上位語を決めるのではなく，順位づけられた上位語候補を取り出すことが望まれる．しかしながら，辞書の短い定義文からこれを行うことは難しい．一方で，上位語を抽出する方法として，コーパスから''is-a''構造等を取り出すという方法がある．この方法は統計量が大きければ信頼性の高い情報が得られる一方，基本的な単語が網羅される保証はなく，単語の偏りが起こる可能性が高い．また，Snowらは''is-a''構造を持つデータを利用してオントロジーを構築する手法を提案しているが，この手法は既存のオントロジーに単語を追加する手法としては有効であるが，オントロジーの骨格をゼロから作り上げることには向いていない．このように，上位語抽出とオントロジー構築にはそれぞれの課題があり，オントロジーを生成するためには，上位語の抽出方法と上位語候補を用いたオントロジー生成手法とを分けて考えるべきであり，まず適切な上位語情報を抽出することが重要である．以上の点から，本論文では，順位付け可能な上位語情報を取り出し，その情報を利用した最適化学習によりオントロジーを生成することを目指す．ところで，鈴木は辞書の定義文を再帰的に展開することでカバー率の非常に大きい単語類似度計算手法を提案している．この方法によると，辞書の定義文を仮想的に巨大な単語集合と見なすことができ，各単語の出現頻度は確率として与えられるため，上位語候補の不足を解決できる可能性がある．そこで本論文では上位語情報の抽出を主な目的とし，辞書の定義文を巨大な単語集合として再定義することにより上位語侯補を増やすという手法を試みる．提案手法では，定義文中に上位語が含まれるという前堤を保ちつつ，大きな単語集合の中から上位語候補を確率的指標を伴った形でリストアップする．即ち，辞書の定義文を基に，上位語の尤もらしさを数値として表す手法を提案する．更に，この上位語候補情報を利用したオントロジー自動生成も試みる．本論文に示す自動生成手法は簡易的なものであるが，前述の上位語候補情報の効果を確認するには非常に有効である．以下，確率モデルによる定義文の拡張方法を簡単に説明し，この手法により一般的な国語辞典から上位語候補が確率的指標と共に取り出せることを示す．また同時に，従来手法との比較も行い，その有効性を検証する．次に，この指標の利用例としてオントロジー自動生成手法を提案し，この手法に上記指標を適用した結果を示す．</section>
  <section title="辞書からの上位語情報抽出">まずはじめに，辞書から単語の上位語情報を取り出すことを考える．ここで言う上位語情報とは，上位語と相関のある数値情報のことであり，上位語を一意に決定するものではない．一般に定義文中に同じ単語が複数回現れることは稀なので，そのままでは単語間で差を付けることはできない．そこで，定義文を再帰的に展開し，拡張した定義文の中での出現頻度の差を利用することにする．この再帰的展開は適当な回数の展開を設定しても良いが，本稿は上位語抽出方法として鈴木による再帰的語義展開手法を利用することにする．この手法によれば，定義文を無限に再帰的に展開することにより巨大な仮想定義文を生成し，そこから頻度情報を取り出すことができる．辞書の定義文が見出語に意味を与えるためのものであるとすれば，上位語は単語に意味付けするために非常に重要な要素である．従って，この仮想定義文中には上位語が高い頻度で出現することを期待できる．</section>
  <subsection title="再帰的語義展開">再帰的語義展開の基本的な考えは，定義文中の単語頻度を再帰的に展開し，より多くの単語からなる定義文を作成するということである．辞書（国語辞典）は見出語と定義文の組合せから成り立っている．定義文は単語の集合であり，これを見出語の集合とみなせば，一つの定義文を複数の定義文の集合として再定義することができる．ところが，このような展開は無限に続いてしまう．従って，展開された定義文中の単語数も無限になり，頻度計算は一般に不可能になる．しかしながら，定義文の展開を行なう毎に一定の割合でその影響が小さくなるとすれば，無限に展開された定義文の影響は元の定義文に比べて微小になる．このとき，定義文の影響力は語義展開の回数に従う等比数列として表すことができる．同時に，様々な深さまで展開した定義文の集合体を考え，その総和を無限級数として計算すると必ず有限な値となる．これにより，定義文の集合体中の単語頻度も有限になり，計算可能となる．これらを確率モデルに置き換えることで，無限の展開を含めた定義文の集合体から単語の出現確率を取り出すことが可能になり，拡張された定義文として再定義することができる．計算の概要を以下にまとめる．以下，n回展開された定義文をn次の定義文と呼ぶ．また，辞書中の定義文を0次定義文とする．まず，見出語w_iと0次定義文中の単語w_jの関係はP(w_j^(0)|w_i)と表すものとする．ここで，w^(n)はn次の定義文中の単語wを表す．従って，確率P(w_j^(0)|w_i)は，見出語w_iの0次定義文中に現れるw_jの出現確率である．この表記を用いると，各見出語に関する0次定義文中の単語の出現確率はの列ベクトルとして表される．ここで，mは辞書中の見出語の数である．行列Aの各要素P(w_j^(0)|w_i)は見出語w_iの定義文中の単語頻度N_i(w)を用いてと書ける．このとき，全ての列ベクトルは，要素の合計が1であり，確率表現となっている．さらに，この表記に従うと，n次定義文はA^n+1により表される．目的とする定義文の集合体Cは，語義展開の度に定義文の影響が一定の割合aで減少すると仮定すると，と書ける．ここで，係数1-aは正規化のための定数である．式()は無限級数の計算からと書け，線型計算により解を求めることができる．計算により得られる行列Cは，列ベクトルの各要素の合計が必ず1となり，確率として扱うことが出来る．Cの(j,i)要素をP(w_j^*|w_i)と書くと，w^*は定義文の集合体の中の単語を意味することになる．以下，この定義文の集合体を拡張定義文と呼ぶことにする．すなわち，P(w_j^*|w_i)は拡張定義文中の単語の確率頻度である．</subsection>
  <subsection title="拡張定義文">上記の手法を実際に国語辞典に適用した結果を以下に示す．前処理として，扱う単語を一般名詞とサ変名詞に限定（形態素解析は茶筌を利用）し，語義の区別はせず，語義文と例文をまとめて見出語の定義文とした．その結果，43,915語の見出語と，平均約7語の0次定義文を得た．以下，a=0.9で行った実験結果を例に詳細を記す．まず，式()()から確率行列Aを計算した．これはスパースな43,915次元の正方行列である．次に式()から線形ライブラリCLAPACKを利用してCを求めた．このときの計算精度は32~bit長の浮動小数点演算で，有効桁は10^-7までとした．この結果得られた列ベクトルの非ゼロの値を持つ次元数は平均約33,000であった．すなわち，平均約33,000語の仮想定義文ができたことになる．表に0次定義文と拡張定義文との比較を示す．まず，見出語「通信」に関しては，0次定義文では「通信」が頻度4，他の13語が等しく頻度1で，「通信」のみが突出して頻度が高い．一方，拡張定義文では全ての単語の確率頻度が異なっており，順位づけすることができる．また，頻度1位の「通信」と2位の「人」との差は相対的に小さくなっている．さらに，0次定義文に現れていなかった「物事」「一つ」が拡張定義文では上位の頻度で現れている．定義文中の語数は，0次定義文では14語だったものが，拡張定義文では32,182語に大幅に増えている．同様に，見出語「傍受」に関しては，0次定義文では5単語が等しく頻度1で現れているのに対し，拡張定義文では順位が付けられ，中でも「通信」が相対的に大きな頻度を示している．また，見出語「通信」の場合と同様に「人」「物事」「自分」「行動」といった一般的な単語が現れているほか，「電線」「有線」「発信」といった見出語と関連の深い特徴的な単語が現れている．本手法を用いると，辞書全体でよく使われる単語，即ち一般的な単語が上位に現れやすくなる．この性質により，等しい頻度の単語でも，より一般的な語が拡張定義文中の上位に現れる傾向があり，場合によっては0次定義文に現れない単語が確率頻度最大となることもある．</subsection>
  <subsection title="上位語情報としての評価">見出語w_iの拡張定義文中に上位語w_jがあるとすれば，上位語w_jは見出語w_iを説明するために非常に重要な単語であるため，その確率頻度P(w_j^*|w_i)は高いことが予想される．従って，見出語w_iの上位語は，その拡張定義文の中から確率頻度P(w_j^*|w_i)が高い順に尤もらしいと考えることができる．この仮説を検証するために，日本語語彙大系を正解データとした検証実験を行った．対象としたのは，前節で用いた43,915語のうち，日本語語彙大系と表記が一致する39,982語である．節で記したように，日本語語彙大系は意味的上下関係を表した約3,000のカテゴリーからなるオントロジーと各カテゴリーに割当てられた合計約40万語からなる大規模語彙データである．ただし，単語の割当てに関しては翻訳への適用を主な目的として作成されているため，オントロジーとしては必ずしも正しいとは限らない．そこで，本論文では，まずはじめに日本語語彙大系をオントロジー検証のための正解データとして適切に利用する方法を検討し，その後，提案手法に対する評価を行うことにする．まず，日本語語彙大系のオントロジーとしての性質を調べるため，既存手法による上位語抽出結果と，その結果を人手により修正した正解データを利用した．この既存手法は，Nicholsらにより提案された，辞書定義文の構文解析により得られた主辞を上位語とみなす手法である．ただし，ここで用いた辞書(Lexeed)は前節の実験で用いた辞書（学研国語辞典）とは異なる．これらのデータを利用して，日本語語彙大系の意味カテゴリー間の関係を上位語の評価指標としての妥当性という観点から評価した．評価方法は，次に示す3種類をそれぞれ上位語の正解データとして精度を計算するものである．見出語の含まれる意味カテゴリーの直接上位カテゴリー中の全単語直接上位カテゴリーを除く全ての上位カテゴリー（間接上位カテゴリー）中の全単語見出語と同一カテゴリーに属する全単語評価結果を表に示す．人手修正データの評価結果を見ると，直接上位カテゴリーよりもむしろ同一カテゴリーの単語に上位語が多く含まれていることがわかる．人手修正による精度の向上も同一カテゴリーの方が大きく，上位語の多くはここに集まっていると考えられる．逆に，間接上位カテゴリーでは，人手修正による精度向上率は-24.5%であり，精度を大きく下げている．この結果は，間接上位カテゴリーは上位語以外の単語を多く含んでおり，間違った結果を正解と判断している率が非常に高いことを示している．言い替えると，間接上位カテゴリーは再現率が非常に低く，一方，直接上位カテゴリーと同一カテゴリーには従来手法のような構文解析手法では取り出しにくい上位語が集まる傾向があるといえる．ここで，人手修正データに強いバイアスが掛っている（脚注参照）点を考慮すると，実際に修正を加えられた人手修正データの方がより信頼性の高いデータであることに気附く．従って，精度の絶対値ではなく，向上率を重視したほうが信頼性が高いと考えられる．よって，本論文においては，日本語語彙大系を上位語の評価として使う場合には，同一カテゴリーあるいは直接上位カテゴリーを正解とみなして評価を行うことにする．特に同一カテゴリーによる評価を重視する方向で検討をすすめることとする．この結果を考慮して，提案手法による上位語情報の抽出結果を日本語語彙大系の直接上位カテゴリーおよび同一カテゴリーを正解データとして評価した．その結果を図,に示す．図は直接上位カテゴリーを正解とした場合，図は同一カテゴリーを正解とした場合である．それぞれの図には，横軸に拡張定義文中の確率頻度を降順に並べた順位を，縦軸に正解データに対する精度をとり，全ての見出語に関する統計量でプロットしている．黒丸は前述の人手修正による正解データを，白丸は同じく前述の既存手法による結果である．太い実線は再帰的展開を行わない場合，即ちa=0の結果である．ここでは同一頻度のものは任意に順位を割当てた．破線，細い実線，鎖線はそれぞれa=0.1,0.5,0.9の場合の結果を示している．図の順位1位を比較すると，既存手法の精度0.0399に対してa=0.1では0.0402であり，提案手法の精度が上回っている．また，a=0.5,0.9でもそれぞれ0.0389,0.0378であり，ほぼ同等の結果を得ている．ただし，人手修正による正解データの精度0.0510には及んでいない．一方，図の順位1位での比較では，既存手法の精度0.2170に対してa=0.1,0.5,0.9のそれぞれで0.2628,0.2915,0.2932と大きく上回る結果を出している．さらに，a=0.5,0.9は人手修正による正解データの精度0.2793をも僅かに上回っている．また，再帰的展開前の結果(a=0)と展開後の結果(a=0.1,0.5.0.9)とを比較してみると，展開後の結果は，展開前に比べて順位1位の精度が上り，順位2,3位以下では精度が下っている．これは，再帰的展開により，低い順位にあった上位語が高い順位に移動したことを示しており，再帰的展開の効果を明確に表す結果である．以上の結果から，提案手法は既存手法と同等以上の精度を持ち，評価方法によっては手作業にも劣らない精度を出せることが示された．さらに，上位語候補として1語あるいは数語しか提示できない既存手法に比べて，提案手法では順位2位以下の情報を多量に持っているため，アプリケーションへの応用の際にこれらの情報が有効に働くことを期待できる．</subsection>
  <section title="オントロジーの生成"/>
  <subsection title="学習モデル">節で得られた上位語情報を利用して，単語オントロジーの自動生成を試みた．以下は，今回検証したモデルである．まず，目的とするオントロジーは上位語が下位語を意味的に包含するものである．従って，下位語は上位語の意味を要素として含まなければならない．逆に，下位語は上位語以外の単語の意味を要素として含んではいけないことになる．いま，あるオントロジーが存在し，その中の単語Cの上位語がA,Bである場合を考える（図(a)参照）．このとき，Cの持つ意味はA,B及びC自身により特徴づけられると考える．ところが，Cは拡張定義文において様々な単語から成り立っている．そこで，単語の意味空間の集合としての見出語の意味空間を考える（図(b)参照）．拡張定義文中の各単語は見出語を構成する要素（部分空間）であると考え，見出語自身とその上位語のみが，その見出語を特徴づける意味要素として有効であると仮定する．即ち，と考える．この再現率がオントロジー全体で高いほど，良いオントロジーとなる．これにオントロジー上の距離の要素を加味し，単語の確率頻度（節参照）を用いて，上位語をA,B,C,D,としたときの再現率をと書くことにする．ただし，b_xは単語w_x^*の木構造の頂点からのトポロジカルな距離に従う定数(_xb_x=1)である．以下，このP'(w)を意味再現率と呼ぶ．この仮定の下で，あるオントロジーTが存在している場合，Tが存在する確からしさは全単語の意味再現率の積，即ち，で表すことができる．つまり，全ての単語がより良く元の意味を再現できている状態がオントロジーの存在が最も安定している状態であると考える．計算を簡単にするため，式()の対数をとれば，となる．このL(T)を最大化することにより，前述の仮定の下での最適な単語オントロジーが取り出せる．</subsection>
  <subsection title="計算機実験">本論文では，計算コストを抑えるため，最適化アルゴリズムを各単語の意味再現率最大化と，その組合せとしての全体の最適化の2段階に分離して行った．即ち，w_x,P'(w_x)=_w_y^*^all;hypernymsb_yP(w_y^*|w_x)の最大化L(T)=_w_x^all;wordsP'(w_x)の最大化を交互に行うことで，近似的に最適化を行った．オントロジー上の距離に関するパラメータb_yは，上位語の木構造の最上位からの階層の深さをnとしたとき，b_yz^n,z=0.1,0.5,0.9,0.99の4種類とした．学習の前提として，オントロジー上での各単語の直接上位語は1語に限定し，自身を上位語とすることを許可している．自身が上位語となる場合は，当該単語は木構造の最上位に位置するものと考える．これらの前提の下，学習の初期状態は全ての単語が自身を上位語とする状態にあるものとし，学習を行った．具体的な学習手順は，次の通りである．見出語を1つ選ぶ．上位語候補をN個選ぶ．各上位語候補に対してP'(w_x)を計算し，最大となる上位語を決定する．上記に対しL(T)を計算し，値が増加すれば上位語を置換，それ以外なら元に戻す．を全見出語に関し変化がなくなるまで繰り返す．ただし，Nは事前に与えられる定数であり，今回の実験ではN=100とした．</subsection>
  <subsection title="結果">以下，a=0.1の場合を例に，結果の詳細を記す．学習の結果得られたオントロジーの一部を図に示す．「通信」の全上位語および全下位語の構造を表示している．(a)はオントロジー上の距離に関するパラメータb(z=0.1)を用いて学習した結果である．同様に(b),(c),(d)はそれぞれb(z=0.5,0.9,0.99)のときの結果である．この値が大きくなる程，上位語の影響は階層の離れた下位語まで届くため，深い木構造が期待できる．逆にこの値が小さいと，浅い木構造ができることが期待される．今回の実験では，独立した木構造の数は，(a)1687，(b)1472，(c)788，(d)142であった．(a),(b),(c)では「通信」は木構造の最上位に位置しているが，(d)では「人」を頂点とする巨大な木構造の一部であり，多くの上位語の下に位置している．これらの結果から，パラメータzの値が増加するに従い木構造の階層がより深く大きくなるのが確認できる．また，図を詳細にみると，上下関係が特定の意味関係で統一されているとは言い難いものの，関連のある言葉が集まり木構造を構築していることは確認できる．次に，生成されたオントロジーの精度を，節同様，日本語語彙大系のカテゴリー間の上下関係との一致度を測ることにより調べた．評価方法は節の結果を考慮して，2種類の正解データを設定した．一つは，見出語の含まれる意味カテゴリーの直接上位カテゴリーを正解とするもの，もう一つは，見出語の含まれる意味カテゴリーと同一カテゴリーを正解とするものである．これら正解カテゴリー内の単語のいずれかに，生成したオントロジーから得られる上位語が一致すれば正解とみなした．この手法による評価を，オントロジー上での上位語の距離に対する精度としてプロットしたのが図および図である．横軸は上位語のトポロジカルな距離で，直接上位語であれば``1''，さらにその上位語であれば``2''というように，オントロジー上の距離を表している．縦軸は精度である．図の各線は，学習時のパラメータb(z=0.1,0.5,0.9,0.99)のそれぞれの結果をプロットしたものである．また，白丸はオントロジー生成学習前（拡張定義文中の出現頻度最大の単語を正解とみなした場合）の精度を，黒丸は人手で修正したデータの精度（表参照）を表している．全体的に，学習時のパラメータzが小さいほど距離1での精度が高く，また，距離が大きくなるに従い急激に精度を落している．zが小さいと，生成された木構造の階層が浅いため大きな距離の上位語は非常に少くなり，逆に，zが大きいと，木構造の階層が深くなり，多くの上位語を同時に学習するため直接上位語の精度が犠牲になると考えられる．ただし，この差は僅かであり，距離2以上では逆転するものもあるので，zを如何に設定すべきかは更なる検討が必要である．さらに，これらの結果を学習の前後で比較してみる．図の距離が1（直接上位語）の場合を見ると，オントロジー生成学習前（図では白丸）よりも後の方が大きく精度を下げている．人手修正データの場合（図では黒丸）と比べると，半分程度の精度である．ここで人手修正データの性質を考える．このデータはオントロジーを意識して作成されたものではないので，上位語にさらにその上位語を積上げる手法をとっても木構造にはならず，ループ状につながってしまう．従って，木構造にするには，いくつかの上位語を変える必要があり，多少の精度低下が起る．この点を考慮すると，学習前後で精度が低下することは妥当であると思われる．一方，図では距離が1の各値はオントロジー生成学習前（図の白丸）および人手修正データ（図の黒丸）と比べて大きく精度を上げている．節の結果を考慮すれば同一カテゴリーによる評価がより重要であるとも考えられるが，同義語など他の要素が影響している可能性も考えられる．この点に関しても更なる検討が必要である．以上の結果は，a=0.5,0.9の場合でも同様の傾向がみられる．上述のように，オントロジーとしての十分な評価を下すためには更に検証を加える必要があるが，上記の実験結果は計算により得られた上位語情報を学習によって木構造に組み上げる方法論の妥当性を示唆している．また，再帰的展開の影響が小さいa=0.1での結果が学習前から大きく改善したことは，辞書から得たカバー率の高い上位語情報が有効に活用されていることを表すものである．</subsection>
  <section title="むすび">本論文では辞書の定義文から上位語情報を取り出し，検証を行った．取り出した上位語情報はカバー率が非常に高いという特徴をもっており，精度の検証では既存の手法を上回る結果を示した．また，上位語情報を利用したオントロジー生成手法を提案し，上位語情報のカバー率の高さが有効に働いていることを示した．提案したオントロジー生成手法はまだ簡易的なものであるが，パラメータに従い様々な深さの階層をもつオントロジーを生成できる．ただし，その精度の評価方法に関しては更なる検討が必要であることも明らかになった．今後の課題としては，第一に評価手法の確立が挙げられる．今回は正解データとして日本語語彙大系のみを利用したが，様々な辞書等を組合せて，より精度の高い評価手法を確立したいと考えている．更に，学習の最適化手法の改良に関しても今後の課題である．今回用いた最適化手法は簡易的なもので，極めて局所的な最適解しか得られない．この点を改善すれば，今後の更なる精度の向上も期待できる．また，今回の実験では語義の曖昧性については考慮せず，1表記につき1語義として実験を行ったが，定義文中の語義曖昧性を排除した辞書（例えばLexeed）を利用することにより，語義レベルの上位語抽出，オントロジー生成が可能である．今回は特殊な辞書であるLexeedの利用は避けたが，これの再帰的展開への適用については現在検討を進めているところである．document</section>
</root>
