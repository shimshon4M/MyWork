<?xml version="1.0" ?>
<root>
  <jtitle>概念ベースとEarthMover'sDistanceを用いた文書検索</jtitle>
  <jauthor>藤江悠五渡部広一河岡司</jauthor>
  <jabstract>近年，コンピュータとネットワークの発達に伴って，個人が扱える情報は膨大なものとなり，その膨大な情報の中から必要な情報を探し出すのは非常に困難となっている．既存の検索システムは基本的には表記のみを活用するため，意味的には同じ内容の検索でもユーザが入力する語によって検索結果が異なってしまう．そのためユーザが適切なキーワードを考えなければならない．そこで本稿では文書の意味を捉えた検索を実現するために単語の関連性にもとづいた文書間の類似性の定量化手法を提案する．具体的には概念ベースを用い単語間の関連性を求め，EarthMover'sDistanceにより文書間の類似度を計算する方法を提案する．また概念ベースに存在しない固有名詞や新語に対して，Web情報をもとに新概念として意味を定義し，概念ベースを自動的に拡張する方法を提案する．これら提案手法をNTCIR3-WEBによって他の手法と比較実験したところ，本手法が他手法に比べ良好な結果が得られた．</jabstract>
  <jkeywords>情報検索，概念ベース，EarthMover'sDistance,NTCIR</jkeywords>
  <section title="はじめに">一般家庭にもPC，ブロードバンドが普及し，ユーザは手軽に情報を収集できるようになってきている．しかし一方では，情報が過度に溢れ過ぎ，利用者の要求に合った情報を探し出す必要性が高まっている．その中で要求に適合した情報のみを選出するのではなく，情報をランキング付けして提示することも重要となっている．ランキング付けは，検索要求と検索対象との間の類似性や関連性をもとに行われ，これらを定量化することが求められる．その際，従来の情報検索でよく用いられているベクトル空間モデルなどでは文書における単語の出現頻度や統計情報などを利用して検索要求と文書間の類似性を判断し，文書を選別している．このような手法は検索要求と文書内の各単語の表記が一致しない場合は関連性がないとの仮定にもとづいている．しかし，実際の文書において，語の表記が同じでも異なる意味を有したり（多義性），同じ意味でも語の表記が異なる場合（表記揺れ，同類義語）がある．さらに単語間には，互いに意味的な関連性を持って存在しており，表記だけを頼りに検索を行う手法ではユーザが入力する語によって検索結果が異なってしまう．そのためユーザが適切なキーワードを考えなければならない．その問題を解消するために，ユーザが入力したキーワードの意味を捉えた検索手法が必要である．このような背景から，本研究では文書における意味を捉えた検索を実現すべく，単語の意味特徴を定義した概念ベースを用いた検索手法を提案する．概念ベースを用いることによって，単語の表記のみでの検索方式とは異なり，意味を捉えた検索が可能になる．つまり，ユーザの入力語の表記的揺らぎに影響されず，意味的近さを定量化できる手法である．具体的には，概念ベースによって単語間の意味的な関連性を0から1までの数値として算出する．そして，その値をもとに検索要求と検索対象との類似度を画像検索等の分野で注目されている距離尺度であるEarthMover'sDistance(EMD)により求める方法を提案する．また，概念ベースに存在しない固有名詞や新語に対して，Webをもとに新概念として定義し概念ベースを自動的に拡張する手法を提案する．</section>
  <section title="先行研究と本研究の位置付け">体系的に整理された辞書であるWordNetを用いて単語間の距離を定義し，EMDにより文書間の類似度を定義する手法が提案されている．これにより単語の意味的な関連性に着目した情報検索が実現されている．また，単語の共起情報をもとに単語間の関連性を定義し，EMDにより文書間の類似度を定義する手法が提案されている．この手法では，単語の共起情報を用いることにより，全ての単語間の関連性を定義し，文書間の類似度を定義することを実現している．しかしながらこれらの手法の問題点として，WordNetなどの整理された辞書を用いる場合は，索引語の全てが辞書に含まれる保証がなく，全ての索引語間の関連性を求めることができない可能性がある．共起情報を手がかりにした場合は，用いる文書集合の特性や容量の影響を大きく受け，正確に関連性を定義しているとは言い難い．提案手法では，概念ベースを用いて索引語間の関連性を求め，さらに概念ベースに存在しない語においてはWebをもとに自動的に概念として定義する．これにより，単語間の関連性をより正確に定義し，さらにあらゆる新語に対応できる索引語の網羅性を実現する．</section>
  <section title="基本事項"/>
  <subsection title="NTCIR3-WEB">本研究では提案手法の効果を検証するため，日本での代表的な情報検索システム評価用のテストコレクションであるNTCIRを用いた．NTCIRは文献データ集合，検索課題集合，各検索課題に対する文献の適合不適合判定からなるもので，同一のテストコレクションを利用することにより共通の基準で情報検索システムを評価することができるようにしたものである．その中でも，本研究では一般の利用者が実際に検索する環境に近いWeb検索用のテストコレクションであるNTCIR3-WEBを用いた．図にNTCIR3-WEBの検索課題の一例を示す．検索課題にはNUM，TITLE，DESC，NARR，CONC，RDOC，USERの7つのフィールドが含まれているが，このうち標準的なフィールドはTITLE(title)，DESC(description)，NARR(narrative)，CONC(concept)の4つである．TITLEとは検索課題の内容を簡単に表したタイトル，DESCは検索する内容を文で記述したもの，NARRは検索する内容の詳細な説明，CONCは検索する内容を表すキーワードである．本研究では検索要求を文章で入力するシステムの開発を想定し，DESCのみを使用する．図に検索対象（HTMLもしくはプレーンテキストファイル．言語は主に日本語と英語，ごく一部にその他の言語．100~GB）の一例を示す．実験には検索対象のタグを省いた全文を用いる．</subsection>
  <subsection title="索引語の取得と重み付け">本研究は日本語での検索を想定している．日本語は英語などとは異なり，単語間に明確な区切りがない．そこで，文章から単語を切り出す必要がある．本研究では形態素解析器を用いて行う．</subsection>
  <subsubsection title="形態素解析器">日本語構造の制約を利用し，単語の切り出しや品詞を同定することを形態素解析という．例えば，形容詞は名詞の前に付くことができるという法則である．実際は，日本語の複雑さのため完全に単語を切り出すことは難しいが，代表的な形態素解析器である茶筌は様々な工夫により高い精度で単語を正しく切り出すことができる．本研究では単語の切り出しに茶筌を用い，「名詞」，「形容詞」，「動詞」を索引語として用いる．</subsubsection>
  <subsubsection title="tf・idf">索引語に対する重み付けは，情報検索の分野で広く用いられているtf・idf重み付けを使用する．tf・idfによる重み付けとは，対象としている単語の頻度と網羅性に基づいた重み付け手法である．文書dにおける索引語tの重みwd(t,d)は以下の式によって得られる．tf(t,d)は文書dにおける索引語tの出現頻度である．ただし，tf(t,d)は文書長の影響を受けやすいため，本論文では以下の式に示す正規化手法を用いた．単語tの出現頻度をtfreq(t,d)，文書dに含まれる単語数をtnum(d)とする．また，idf(t)は文書数Nと索引語tが出現する文書の数df(t)によって決まり，式によって定義される．</subsubsection>
  <subsubsection title="不要語の削除">本研究では不要語を削除するために評価データの実験に使用する検索対象の空間でのidf値をもとに検索対象内の不要語を削除した．不要語とは「する」や「こと」のような，どの文書にも出現し，文書を特定するために有効でない語を指す．検索対象の不要語削除の閾値は提案手法が適合判定レベルのLEVEL1においての評価(MAP)がidf値0から9の間で一番高くなるidf値5に設定した．適合判定LEVELと評価(MAP)などの評価方法については節で述べる．さらに検索課題空間でのidf値を利用し検索課題の索引語中の不要語を削除した．削除の例を図に示す．これにより検索課題によく出現する「文書」や「様々」などの語を削除でき，検索課題として比較的意味があると考えられる「将来」，「歴史」，「地域」などを残すことができる．この閾値は目視により設定した．</subsubsection>
  <section title="概念ベース">概念ベースとは複数の国語辞書や新聞などから機械的に構築した単語（概念）とその意味特徴を表す単語（属性）の集合からなる知識ベースである．概念には属性とその重要性を表す重みが付与されている．概念ベースには約12万語の概念表記が収録されており，1つの概念に平均約30個の属性が存在する．ある概念Aは属性a_iとその重みwc_iの対の集合として，式で表される．任意の一次属性a_iは，その概念ベース中の概念表記の集合に含まれている単語で構成されている．したがって，一次属性は必ずある概念表記に一致するため，さらにその一次属性を抽出することができる．これを二次属性と呼ぶ．概念ベースにおいて，「概念」はn次までの属性の連鎖集合により定義されている（図）．以下に，本研究で使用した大規模概念ベースの構築方法について述べる．</section>
  <subsection title="概念ベースの構築方法">まず，基本となる概念ベースを複数の国語辞書から構築する．概念は国語辞書の見出し語から，属性は見出し語の語義説明文の自立語から，その重みは自立語の出現頻度に基づいて決定される．そして，属性信頼度（語に関する種々の知識から属性としての確からしさを定量化した値）により不適切な属性の削除を行い，信頼性の高い属性を抽出する．これらにより概念数約3万4千語で平均属性数が16個の基本となる概念ベースが構築される．複数の国語辞書には約12万語の見出し語（辞書に収録されている約20万語語彙のうち見出し語として不適切な表記を除去した語）があり，辞書中の語義説明文だけでは属性が付与できない語が約9万語もあった．そこで，概念総数と属性数を拡張するために電子化新聞（毎日新聞，日本経済新聞）を用いて，各概念に対する共起語を属性候補として追加する．この際，もともと概念ベースに定義されている概念についても，同様に属性を取得する．その後，節で説明する関連度計算により概念と属性の関連の強さを求め，その値と概念ベースの頻度情報をもとに属性の重み付けを行う．以上の処理により本研究で使用した概念数が約12万語，平均属性数約30個の大規模概念ベースが構築できる．</subsection>
  <section title="概念ベースを用いた単語間の関連性の定量化">概念ベースを用いた単語間の関連性の定量化は，基本的に語意の展開結果を利用し数値として表す．何次属性まで展開するか，どの属性を用いるかによって値が変わってくるため，状況に応じてどのように計算するかが問題になってくる．そこで本研究では二種類の方法を使い分ける．文書間の類似度を求めるための単語間の関連性の定量化には，概念ベースの一次属性までを使用する一致度を用い，概念ベースの自動拡張手法における単語間の関連性の定量化には，概念ベースの二次属性までを使用する関連度計算を使用する．二次属性までを使用する方法が，概念ベースを用いた単語間の関連性の定量化には一番有効であると報告されている．一次属性までしか展開しないと，関連が薄い概念同士の関連性を定量化できず，三次属性まで用いると概念とはかけ離れた語が属性となり，雑音として働くため精度が低下してしまう．本研究では，文書を概念と文書間の類似度を求めるための単語間の関連性の定量化には一次属性までしか展開しない一致度を用いる．これは文書を概念と見立てた場合，索引語が一次属性となり，索引語の属性が二次属性となる．つまり，索引語の二次属性まで展開すると文書を概念とした場合の三次属性まで展開したこととなり雑音が増加し，概念（文書）とはかけ離れた語が計算に使用されてしまうためである．</section>
  <subsection title="一致度計算">任意の概念A，Bについて，それぞれ一次属性をa_i，b_jとし，対応する重みをu_i，v_jとする．また，概念A，Bの属性数をL個，M個(LM)とする．A=(a_i,u_i)i=1〜L=(b_j,v_j)j=1〜Mgather*このとき，概念A，Bの一致度MatchWR(A,B)を以下の式，で定義する．MatchWR(A,B)=_a_i=b_j(u_i,v_j)	(,)=	&amp;(&gt;)	&amp;()cases	.gatherただし，各概念の重みの総和をそれぞれ1に正規化する．概念A，Bの属性a_i，b_jに対し，a_i=b_j（概念A，Bに共通する属性がある）となる属性があった場合，共通する属性の重みの共通部分，つまり，重みの小さい分だけ有効に一致すると考え，その合計を一致度とする．定義から明らかなように両概念の属性と重みの両方が完全に一致する場合には一致度は1.0となる．</subsection>
  <subsection title="関連度計算">関連度計算は概念の二次属性間の一致度計算により求めた値をもとに概念間の関連性を数値として算出する．具体的には，計算する二つの概念の内，一次属性の数の少ない方の概念をAとし(LM)，概念Aの一次属性を基準とする．[A=(a_1,u_1),(a_2,u_2),,(a_i,u_i),,(a_L,u_L)]そして概念Bの一次属性を，概念Aの各一次属性との一致度MatchWR(a_i,b_xi)の和が最大になるように並び替える．[B_x=(b_x1,v_x1),(b_x2,v_x2),,(b_xi,v_xi),,(b_xL,v_xL)]これによって，概念Aの一次属性と概念Bの一次属性の対応する組を決める．対応にあふれた概念Bの一次属性は無視する（この時点では組み合わせはL個）．ただし，一次属性同士が一致する（概念表記が同じ）ものがある場合(a_i=b_j)は，別扱いにする．これは概念ベースには約12万の概念表記が存在し，属性が一致することは稀であるという考えに基づく．従って，属性の一致の扱いを別にすることにより，属性が一致した場合を大きく評価する．具体的には，対応する属性の重みu_i，v_jの大きさを重みの小さい方にそろえる．このとき，重みの大きい方はその値から小さい方の重みを引き，もう一度，他の属性と対応をとることにする．例えば，a_i=b_jでu_i=v_j+とすれば，対応が決定するのは(a_i,v_j)と(b_j,v_j)であり，(a_i,)はもう一度他の属性と対応させる．このように対応を決めて，対応の取れた属性の組み合わせ数をT個とする．このとき，概念A，Bの一致度DoA(A,B)を以下の式により定義する．関連度の値は概念間の関連の強さを0〜1の間の連続値で表す．1に近づくほど関連が強い．概念AとBに対して関連度計算を行った例を表に挙げる．最後に，概念「机」と「椅子」を例に用いて，関連度の計算例を説明する．概念「机」と「椅子」の一次属性および二次属性を表，表に示す．まず，概念「机」と「椅子」の一致度の計算を行う．例えば，概念「机」の一次属性「学校」と概念「椅子」の一次属性「木」は，「木造」という共通する属性を持っているため，一致度は以下のように計算される．[MatchWR(学校,木)=(0.2,0.4)=0.2]同様に全ての一次属性の組み合わせについて一致度を計算した結果を表に示す．次に，関連度の計算を行う．関連度の計算は，まず属性が完全に一致している部分から行われる．続いて，一致度の大きい部分から順に対応を決める．この場合，表から一次属性「勉強」と「勉強」，「学校」と「教室」，「本棚」と「勉強」の順に対応が決まることになる．結果，関連度は次式のように計算される．DoA(机,椅子)	&amp;=1.0(0.3+0.3)(0.3/0.3)/0.2+0.4(0.6+0.3)(0.3/0.6)/2			&amp;	+0.1(0.1+0.2)(0.1/0.2)/2			&amp;=0.3975align*本研究では節で述べる概念ベースに属性として追加する概念と追加される側の概念との間の関連性の定量化に関連度計算を用いる．</subsection>
  <section title="概念ベースの自動拡張手法">概念ベースに存在しない語（未定義語）にも属性を与えなければ，未定義語と他の単語との関連性を求めることができない．そこで，現在考えうる最大の言語データであるWeb情報をもとに未定義語の概念化を行い，概念ベースに追加する方法を提案する．本章ではこの手法について説明する．</section>
  <subsection title="未定義語の概念化">以下の手順により，未定義語の概念化を行うために，未定義語の属性とその重みをWebから獲得する．入力された未定義語をキーワードとして検索エンジンを用いて検索を行い，検索上位100件の検索結果ページの内容を取得する．HTMLタグなど不要な情報を取り除いた文書群に対して，形態素解析を行い，自立語を抽出する．得られた自立語の中から概念ベースに存在する単語のみを未定義語の属性として抜き出す．得られた属性の頻度にWeb上の単語のidfを統計的に調べたもの(SWeb-idf)の値を掛け合わせたものを属性の重みとし，得られた重み順に並び替える．SWeb-idfについては次節で説明する．なお，SWeb-idfのデータベースに存在しない属性については，Web上にあまり存在しない単語と考え，SWeb-idf値の最大値を掛け合わせている．表に未定義語を概念化した例を示す．</subsection>
  <subsection title="SWeb-idf">SWeb-idf(StaticsWeb-InverseDocumentFrequency)とは，Web上の単語のidfを統計的に調べたidf値である．まず，無作為に選んだ固有名詞1,000語を作成する．表に無作為に選択した固有名詞の一部を示す．この作成した1,000語に対して個々に検索エンジンで検索を行い，1語につき検索上位10件の検索結果ページの内容を取得する．よって，得られた検索結果ページ数は10,000ページとなる．この10,000ページから，複数の国語辞書や新聞などから概念（単語）を抽出した知識ベースである概念ベースの収録語数である約12万語とほぼ同等の単語数が得られたことから，獲得した10,000ページをWebの全情報情報空間とみなしている．そして，その中での単語のidf値を表すSWeb-idfは，式で求められる．これらにより得られた単語とそのidf値をデータベースに登録した．なおdf(t)項は，全文書空間（10,000ページ）に出現する概念tのページ数である．獲得したSWeb-idfの値の例を表に挙げる．なお，固有名詞の選び方を変えてもSWeb-idfの値に大きな変化は見られないという報告がなされている．</subsection>
  <subsection title="属性内出現頻度を用いた重み付け手法">未定義語の属性の重みはSWeb-idfによっても求まるが，Web情報と概念ベースでは語の頻度情報が異なり重みの値も変わるため，Web情報の重みをそのまま用い概念ベースに追加すると概念ベースの頻度情報に歪みが生じる．よってSWeb-idfは未定義語の属性候補を獲得する時にのみ用い，未定義語の属性の重み付けには使用せず，概念ベースに未定義語を追加する場合には概念ベースの頻度情報を用いて重み付けを行う必要がある．そこで，未定義語の属性に対して重みを付与する方法として，概念ベースの属性空間を考慮した重み付け手法を提案する．概念に付与された属性は，特徴を表す語であるため，概念の説明文書であると捉えることが出来る．この文書空間内での属性の出現頻度を，概念に対する属性の確からしさだと考える．例として「個人情報」の属性を表に示す．網掛けのセルに一次属性，各網掛けの下方のセルにはその二次属性を示している．個人情報という概念を特徴付ける一次属性には，「個人，情報，識別，…」という属性が存在する．これは，「個人を識別することができる情報を指す」という文書であると捉えることができる．このように，概念に対するn次属性空間はその概念についての説明文書の集合だとみなすことができる．このn次属性空間から算出した出現頻度をn次属性内出現頻度と呼ぶ．本稿では2次属性空間を用いる．3次属性空間までを用いると，概念「個人情報」に対して2次属性「力」の属性「動物，筋肉，物体，…」が含まれる．このため，概念に関係のない語が多くなってしまうためである．節で説明したtf・idf重みの考え方をもとに，未定義語の属性Aの2次属性内出現頻度をfreq(A)，未定義語の一次属性の総数をRとし，未定義語の属性Aの概念ベース空間のidf値をcidf(A)とすると，重みwc(A)は以下の式で表される．</subsection>
  <subsection title="相互追加">新規概念に属性を追加した場合，その概念自身は属性として他の概念を持つが，その概念を属性として持つ概念は存在しない．したがって，他の概念に新しく追加をした概念を属性として追加する手法が必要となる．新概念と属性の例を表に示す．新概念とその獲得した属性にはWeb上のホームページにともに出現しており，共起という関係があり，属性から見ても新概念とのなんらかの関連性があると考えられる．このため，新概念を属性の追加候補とする．例であると，概念「放送」，「テレビ」，「車両」に「ワンセグ」という語を属性追加候補とする．しかし，全ての属性追加候補を属性として追加すると雑音が非常に多くなってしまう．概念「車両」に対して「ワンセグ」という属性は不必要であるため，選別して追加を行う．このように，新概念から取得した語に対して新概念を属性として選別して追加することを相互追加と呼ぶこととする．選別方法としては，2次属性内出現頻度を属性数で割った値（以下2次属性内出現頻度割合と記述）が0.149以上かつ関連度0.068以上の場合に追加を行う．選別のための閾値の設定は実験により定めた．実験方法としては，概念とその概念と関係がある概念の組を1,780組集め，その全ての組における2次属性内出現頻度割合と関連度を求め，その平均値を閾値に設定した．実験に使用した2対の関係がある概念の組を表に示す．追加する概念Aと追加される概念Bとの間の関連度DoA(A,B)と追加する属性の概念ベース空間のidf値をcidf(A)とすると追加した属性の重みwc(A)は以下の式で表される．</subsection>
  <section title="EMDを用いた文書検索">検索要求と検索対象の間の類似度を求める際，いくら単語間の関連性を正確に定義できたとしても，その値をもとにうまく計算できないと文書間の正確な類似度を求めることはできない．計算の仕方としては，様々な方法が考えられ，例えば単語間の関連性が高い順に単語の対応をとり計算する方法などが挙げられる．1対1で対応を取る方法では，検索要求と検索対象の語の少ない方の語の数しか対応がとれない．例えば，検索要求の語が3語，検索対象の語が100語であった場合，検索対象の97語は計算の対象外となる．さらに，実際の検索において，ユーザは検索要求にあまり多くの語を入力しないと考えられ，検索要求と検索対象との語数の差は非常に大きいと想定され，文書内の単語の重要性と単語間の関連性を考慮しM対Nで柔軟に対応を取る必要がある．そこで本研究では類似画像検索の分野で注目されているEMD~を用いて文書間の類似度を算出する方法を用いる．EMDは輸送問題における輸送コストの最適解を求めるアルゴリズムであり，需要地（供給地）の重みと需要地と供給地間の距離を定義できればどのような問題にも適用できる．このEMDを用いることで単語の重みと単語間の関連性を考慮して柔軟に対応を取り，文書間の類似度を求めることができる．</section>
  <subsection title="EMDとは">EMDは線形計画問題の一つであるヒッチコック型輸送問題において計算される距離尺度であり，2つの離散分布において，一方の分布を他方の分布に変換するための最小コストとして定義される．輸送問題とは，需要地の需要を満たすように供給地から需要地へ輸送を行う場合の最小輸送コストを解く問題である．EMDを求める際，二つの分布は要素の重み付き集合として表現される．一方の分布Pを集合として表現すると，P=(p_1,w_p_1),,(p_m,w_p_m)となる．今，分布Pはm個の特徴量で表現されており，p_iは特徴量，w_piはその特徴量に対する重みである．同様に，一方の分布Qも集合として表すと，Q=(q_1,w_q_1),,(q_n,w_q_n)となる．EMDの計算は，2つの分布において特徴量の数が異なっている場合でも計算が可能であるという性質を持っている．今，p_iとq_jの距離をd_ijとし，全特徴間の距離をD=[d_ij]とする．ここで，p_iからq_jへの輸送量をf_ijとすると，全輸送量はF=[f_ij]となる．ここで，式に示すコスト関数を最小とする輸送量Fを求め，EMDを計算する．ただし，上記のコスト関数を最小化する際，以下の制約条件を満たす必要がある．f_ij0，1im，1jn	_j=1^nf_ijw_p_i，1im	_i=1^mf_ijw_q_j，1jn	_i=1^m_j=1^nf_ij=(_i=1^mw_p_i，_j=1^nw_q_j)	gatherここで，式は輸送量が正であることを表し，p_iからq_jに送られる一方通行であることを表している．式は輸送元であるp_iの重み以上に輸送できないことを表す．式は輸送先であるq_jの重み以上に受け入れることができないことを表す．最後に式は総輸送量の上限を表し，それは輸送先または輸送元の総和の小さい方に制限されることを表す．以上の制約条件の下で求められた最適な全輸送量Fを用いて分布P，Q間のEMDを以下のように求める．ここで，最適なコスト関数WORK(P,Q,F)をEMDとしてそのまま用いないのは，コスト関数は輸送元もしくは輸送先の重みの総和に依存するので，正規化することによってその影響を取り除くためである．</subsection>
  <subsection title="EMDの文書検索への適用">図にEMDを文書検索に適用した例を示す．EMDを文書検索に適用するには需要地と供給地，需要量と供給量，各需要地と供給地間の距離を定義する必要がある．需要地としては，検索課題の索引語を，供給地としては検索対象の索引語を割り当てる．需要量と供給量はそれぞれ索引語の節で説明したtf・idf重みを用いる．そして，需要地と供給地間の距離は索引語間の関連性と見立てることができ，提案手法においては概念ベースを用いた一致度計算により求めることができる．一致度は関連性が高いと値も大きくなるため，1から一致度の値を引いた値に変換する．EMDの計算は図の下方で求まる．「梅」と「祭り」間の輸送量が1となっているのは，「梅」から「うめ」に重み2を輸送し，「梅」の余った重み1を「祭り」に輸送したためである．このように，関連性が高い語に優先して重みを輸送し，供給量がなくなるか需要量が満たされるまで輸送を行う．このように索引語間の関連性と重みを考慮したM対Nでの柔軟な対応が可能である．EMDの特徴として．索引語間の距離の値が0から1であるなら，EMDも0から1の値になる．そして，EMDは文書間が似ていると値が低くなり，似ていないと値が高くなる．よって値が低い文書から順にユーザに提示することで文書検索が実現できる．</subsection>
  <section title="実験と評価">単語の関連性に着目した提案手法の有効性を検証するため情報検索システムテストコレクションNTCIR3-WEBを用いて，表記を用いる他の手法との比較実験を行った．比較手法としては，ベクトル空間モデル，OkapiBM25と，同じ索引語間の距離を0，それ以外を1とした素朴なEMDを用いた．</section>
  <subsection title="評価方法">今回の評価では，検索課題41件と正解文書とランダムに選択した文書を合わせた10,000件の文書を使用し，評価実験を行った．また，正解文書リストが存在し，各検索課題に対して，各文書がH（高適合），A（適合），B（部分的適合），C（不適合）の4段階の適合度が設定されており，以下の基準で評価する．LEVEL1:H判定とA判定を適合LEVEL2:H判定とA判定とB判定を適合各検索課題に対して，10,000件の検索対象全てのスコアを求め，スコア順に並べ変える．そして，正解文書リストを参照し正解文書の順位を調べ評価する．</subsection>
  <subsection title="評価指標">評価指標には，各検索課題毎の平均精度(AvelagePrecision，AP)，平均精度の平均(MeanAveragePrecision，MAP)と再現率—精度グラフを使用した．検索課題に対する平均精度APは式のように定義される．まず順位i位の文書が適合しているならば1，そうでなければ0となる変数をz_iとする．Sを適合文書の総数，nは出力文書数である．平均精度の平均(MAP)は，全ての検索課題に対して平均精度を平均したものであり，式によって求められる．具体的には，検索課題がK件ありそれぞれの課題に対するあるシステムの平均精度をAP_hと表記すれば(h=1,...,K)，その平均がMAPに相当し，以下の式に示す．再現率—精度グラフとは再現率の11個の点ごとに，41個の検索課題の精度を平均してグラフを描いたものである．</subsection>
  <subsection title="比較手法">本節では，提案手法との比較に用いているベクトル空間モデルとOkapiBM25について述べる．</subsection>
  <subsubsection title="ベクトル空間モデル">ベクトル空間モデルは，情報検索の分野で幅広く利用されている検索モデルである．各語の重みから構成されるベクトルとして検索課題と文書をそれぞれ表現し，二つのベクトルの成す角度の余弦によって類似度を計算する点に特徴がある．重みの種類にはいくつかの種類があるが，本実験では節で説明したtf・idf重みを用いる．検索課題qと文書d_iの索引語の語の総数（異なり）をMとすれば，文書と検索課題はそれぞれ以下のようなM次元ベクトルで表現できる．d_i=(w_i1,w_i2,…,w_iM)q=(w_q1,w_q2,…,w_qM)gather検索課題qに対する文書d_iの得点s_q(d_i)は2つのベクトルの角度の余弦により求まる．式を以下に示す．</subsubsection>
  <subsubsection title="Okapi BM25">S.Robertsonを中心に開発されたOkapiと呼ばれる次世代検索システムにおいて使用されている確率型の検索モデルBM25は，ベクトル空間モデルと同等，あるいはそれ以上の性能を示すことでよく知られている．原理的には，検索課題qと文書ベクトルd_iが与えられた時に，その文書が検索課題に適合している確率を推計するものである．検索課題qと文書d_iの索引語の語の総数（異なり）をMとすれば，検索課題qに対する文書d_iの得点s_q(d_i)は以下の式で表される．ただし，x_qjは検索課題qでの語t_jの出現回数である．ここでw_ij=3.0x_ij(0.5+1.5l_i/l)+x_ij_j=N-n_j+0.5n_j+0.5gatherである．x_ijは文書d_iでのt_jの出現回数であり，Nは文書総数で，n_jは語t_jが出現する文書数である．なお，は文書d_iの長さであり，はデータベース全体での文書長の平均を意味する．</subsubsection>
  <subsection title="評価結果">平均精度の平均(MAP)を表に示す．再現率—精度グラフを図，に示す．表より，LEVEL1では提案手法の精度はベクトル空間モデルより20.30%，OkapiBM25より17.91%，EMDより9.22%の精度向上を達成し，LEVEL2では提案手法の精度はベクトル空間モデルより10.71%，OkapiBM25より9.45%，EMDより4.03%の精度向上を達成した．図，より全ての再現率レベルで精度が改善している．この結果より単語間の関連性にもとづき文書間の類似性を求める本手法が有効であることがわかる．また，ベクトル空間モデルより素朴なEMDがよりよい結果となっている．これは，EMDが輸送問題として距離を計算していることに起因する．例えば，検索課題を(3/2,1/2)としたとき，ベクトル空間モデルでは(1,0)と(1/2,3/2)では同じ類似度の0.866となるが，EMDでは0.134と0.268と異なり，(1,0)の方が検索要求に近くなる．これは(1,0)では一番目の方が大きいが，(1/2,3/2)では反転していることが理由である．本実験ではこの効果が良い方に働いていると考えられる．次に，比較手法と提案手法が統計的に有意な差があるか検定を行った．検定方法は参考文献を参考にした．以下にその検定方法を述べる．比較する2つの手法をaとb，検索課題数をK，検索課題hの平均精度をv_hとし，MAPをv=K^-1_h=1^Kv_hとする．同一の検索課題に対する2つの平均精度を比較することになるので，対標本と捉えることができ，検索課題ごとの手法間の差自体を標本と考える．すると，帰無仮説「2つの手法の平均精度の母平均の差は0である」の下に正規母集団を仮定すれば，が自由度K-1のt分布に従うことになる．この時，s_a^2とs_b^2は平均精度の標本分散であり，Cov_abはv_haとv_hbとの共分散で，Cov_ab=(K-1)^-1_h=1^K(v_ha-v_a)(v_hb-v_b)となる．この検定方法を利用し，今回の実験でのLEVEL1における提案手法と比較手法の中で一番評価が高かった素朴なEMDとの評価に有意な差があるかどうか片側検定を行う．aを提案手法，bを素朴なEMDとすると，s_a^2=0.071701，s_b^2=0.067863，v_a-v_b=0.044005，Cov_ab=0.056419となるので，t=1.723548となる．自由度40のt分布に従うので，1.723548&gt;1.684より，帰無仮説は棄却され，5%水準で提案手法と素朴なEMDとの差は有意であることがわかる．また，同様の検定をベクトル空間モデルと行うとt=3.01916，OkapiBM25ではt=3.563336となり1%水準で有意な差があることを確認できた．提案手法が表記に頼る比較手法に比べ統計的に有意な差があることがわかった．</subsection>
  <section title="概念ベースの自動拡張手法の評価">概念ベースの自動拡張手法の効果を検証するために，自動拡張手法を用いない手法（概念ベースに存在しない索引語で同じ索引語間の距離を0それ以外の距離を1）と提案手法との比較評価を行った．評価方法は節と同様の方法で行った．以下，自動拡張手法を用いないEMDと概念ベースを組み合わせた手法をEMD＋CBと記す．平均精度の平均(MAP)を表に示す．再現率—精度グラフを図，に示す．表から分かるように，LEVEL1において1.58%の精度向上を達成し，LEVEL2において3.04%向上している．LEVEL1においては全ての再現率レベルで提案手法がEMD+CBを上回っているが，LEVEL2においては再現率レベル0.3の点で0.0001だけEMD＋CBを下回っている．より詳細に検証するために，検索課題ごとの平均精度の差をプロットしたものを図に示す．横軸は本実験における検索課題の番号（1〜41）で，縦軸は検索課題毎のグラフが上に伸びているほど自動拡張手法によって精度が向上したことを示し，逆に下にのびているほど精度は低下していることを示している．この結果から検索課題14と検索課題29の時に精度の低下が著しいことがわかる．課題14は「宮部みゆきの執筆した小説に対する書評・レビューが読みたい」という課題で，課題29は「シフォンケーキの作り方が書かれている文書を探したい．」といった課題である．これらに形態素解析を施し，検索課題idfによる不要語の削除を行うと，検索課題14は「宮部／みゆき／執筆／小説／書評／レビュー」となり，検索課題29は「シフォンケーキ／作り方」となる．このうち未定義語は「宮部／シフォンケーキ」であった．検索課題14と検索課題29における上位25件の順位の変動を図に示す．図において色が付いてる文書がLEVEL1における正解文書である．一番精度低下が著しかった課題29で，EMD+CBにおいて47位であった不適合文書が提案手法では3位に，5位であった不適合文書が4位になり，適合文書が3位から5位に下がった．提案手法において5位であった高適合文書と3位であった不適合文書を図，に示す．3位の文書はケーキ屋の紹介が書かれている文書で，4位の文書もケーキに関する文書であった．5位の高適合文書はシフォンケーキの作り方の手順が書いてあった．提案手法では，シフォンケーキがケーキに関する様々な語と高関連であると判定し，ケーキに関する文書が検索の上位にきてしまった．ユーザは「ケーキの作り方」と入力せず「シフォンケーキの作り方」と入力したのはケーキ全般の情報よりシフォンケーキに絞った情報が欲しいといったことを暗に示していると考えられ，シフォンケーキを定義してしまったことが悪影響を及ぼしてしまった．シフォンケーキのようなケーキといった一般的な語に比べ，具体的な語はユーザが検索結果を絞るために用いる語であり，具体的な語に対しては，表記に頼る方が有効に働くと考えられる．具体的な語を判別し，なんらかの対応を行うことでこの問題は解決できると考えられる．</section>
  <section title="おわりに">本論文では，索引語の関連性を概念ベースにより定義し，それをもとにEMDによって文書間の類似性を求める手法を提案した．さらに概念ベースに存在しない語においてはWebをもとに語の意味を定義し概念ベースを自動的に拡張することで対応し，全ての索引語間の距離を概念ベースにより求めることを可能とする手法を提案した．そして，その有効性をWeb検索評価用テストコレクションNTCIR3-WEBを用いて検証した．結果として，表記に頼る他の手法に比べ良好な結果を得て，単語の関連性に着目した本手法の有効性を確認できた．さらに，統計的検定を用いることで，提案手法と比較手法の性能の差に有意性があることを確認した．またWebにより概念ベースを自動的に拡張する手法を使用と未使用で比較評価を行い，Webにより未定義語を定義することの有効性を示し，あらゆる新語に対応できる索引語の網羅性を実現した．今後の研究課題としては，検索要求内に具体的な語が含まれている場合の対応である．ユーザは検索結果を絞るために具体的な語を用いていると考えられ，これらの語をシソーラスなどをもとに判別し対応を行えば更なる精度向上が期待できる．また，今後は情報検索に限らず文書分類など様々な分野へ応用していきたい．document</section>
</root>
