<?xml version="1.0" ?>
<root>
  <jtitle>半教師有りクラスタリングを用いたWeb検索結果における	人名の曖昧性解消</jtitle>
  <jauthor>杉山一成奥村学</jauthor>
  <jabstract>人名は検索語として，しばしば検索エンジンに入力される．しかし，この入力された人名に対して，検索エンジンは，いくつかの同姓同名人物についてのWebページを含む長い検索結果のリストを返すだけである．この問題を解決するために，Web検索結果における人名の曖昧性解消を目的とした従来研究の多くは，凝集型クラスタリングを適用している．一方，本研究では，ある種文書に類似した文書をマージする半教師有りクラスタリングを用いる．我々の提案する半教師有りクラスタリングは，種文書を含むクラスタの重心の変動を抑えるという点において，新規性がある．</jabstract>
  <jkeywords>Web情報検索，半教師有りクラスタリング，人名の曖昧性解消</jkeywords>
  <subsubsection title="パラメータcの設定">我々の提案する手法では，seedページを含むクラスタC_s_jと，それに最も類似したクラスタC_iをマージした後の新しいクラスタの重心ベクトルは，章で述べたように，式()に基づいてクラスタC_iに含まれるWebページの特徴ベクトルw^p_l_C_i(l=1,,n_i)を重み付けし，この重み付けした特徴ベクトルを用いて，式()によって計算される．式()におけるcは，D(G^C_i,G^C_s_j)が0に非常に近い値となったとき，w^pの各要素が極端に大きな値となることを防ぐために導入した定数であるが，この値によっては，クラスタリングの精度にも影響が及ぶものと考えられる．そこで，WePSコーパスの訓練集合を用いて，上述した2種類のseedページ(a)，(b)ともに7個までのseedページを用いた場合について，0.1c50として得られるクラスタリング精度について検証した．ここで，seedページの数を7個までと定めたのは，少数のseedページでの効果を確認するためである．この結果，表〜に示すcの値のときに，F_0.5，F_0.2ともに，最良なクラスタリング精度が得られた．なお，以下の3.3.3節では，距離尺度，seedページの種類とその数，に応じて，表〜に示したcの値を，WePSコーパスのテスト集合に適用して得られた実験結果を示している．</subsubsection>
  <section title="はじめに">検索エンジンALLTheWebにおいて，英語の検索語の約1割が人名を含むという報告があるように，人名は検索語として検索エンジンにしばしば入力される．しかし，その検索結果としては，その人名を有する同姓同名人物についてのWebページを含む長いリストが返されるのみである．例えば，ユーザが検索エンジンGoogleに``WilliamCohen''という人名を入力すると，その検索結果には，この名前を有する情報科学の教授，アメリカ合衆国の政治家，外科医，歴史家などのWebページが，各人物の実体ごとに分類されておらず，混在している．こうしたWeb検索結果における人名の曖昧性を解消する従来研究の多くは，凝集型クラスタリングを利用している，，，．しかし，一般に人名の検索結果では，その上位に，少数の同姓同名だが異なる人物のページが集中する傾向にある．したがって，上位に順位付けされたページを種文書として，クラスタリングを行えば，各人物ごとに検索結果が集まりやすくなり，より正確にクラスタリングができると期待される．以下，本論文では，このような種文書となるWebページを「seedページ」と呼ぶことにする．本研究では，このseedページを用いた半教師有りクラスタリングを，Web検索結果における人名の曖昧性解消のために適用する．これまでの半教師有りクラスタリングの手法は，(1)制約に基づいた手法，(2)距離に基づいた手法，の二つに分類することができる．制約に基づいた手法は，ユーザが付与したラベルや制約を利用し，より正確なクラスタリングを可能にする．例えば，Wagstaffら，の半教師有りK-meansアルゴリズムでは，``must-link''（2つの事例が同じクラスタに属さなければならない）と，``cannot-link''（2つの事例が異なるクラスタに属さなければならない）という2種類の制約を導入して，データのクラスタリングを行なう．Basuらもまた，ラベルの付与されたデータから初期の種クラスタを生成し，これらの間に制約を導入する半教師有りK-meansアルゴリズムを提案している．また，距離に基づいた手法では，教師付きデータとして付与されたラベルや制約を満たすための学習を必要とする．例えば，Kleinらの研究では，類似した2点(x_i,x_j)間には``0''，類似していない2点間には(_i,jD_ij)+1と設定した隣接行列を作成して，クラスタリングを行なう．また，Xingらの研究では，特徴空間を変換することで，マハラノビス距離の最適化を行う．さらに，Bar-Hillelらの研究では，適切な特徴には大きな重みを，そうでない特徴には小さな重みを与えるRCA(RelevantComponentAnalysis)により，特徴空間を変換する．一方，我々の提案する半教師有りクラスタリングでは，seedページを含むクラスタの重心の変動を抑える点において，新規性がある．本論文の構成は次のとおりである．章では，我々の提案する新たな半教師有りクラスタリングの手法について説明する．章では，提案手法を評価するための実験結果を示し，その結果について考察する．最後に章では，本論文のまとめと今後の課題について述べる．</section>
  <section title="提案手法">章で述べた凝集型クラスタリングに基づいた人名の曖昧性解消は，クラスタリングを適切に導いていく基準がないため，正確なクラスタリングを行うことは難しい．一方，これまでに提案されている半教師有りクラスタリングは，クラスタ数Kをあらかじめ設定する必要があるK-meansアルゴリズムを改良することを目的としている．しかし，本研究においては，Web検索結果における同姓同名人物の数は，事前にわかっているわけではない．したがって，我々の手法においては，事前にクラスタ数を設定するのではなく，新たに生成されたクラスタと，すでに生成されているクラスタ間の類似度を計算し，これらの値がすべて，あらかじめ設定した閾値よりも小さくなった場合に，クラスタリングの処理を終え，その時点で生成されているクラスタ数を最終的な同姓同名人物の数とする．また，従来の半教師有りクラスタリングアルゴリズムは，制約を導入したり，，，距離を学習したり，，することにのみ着目していた．しかし，半教師有りクラスタリングにおいて，より正確なクラスタリング結果を得るためには，seedページ間への制約の導入とともに，seedページを含むクラスタの重心の変動の抑制も重要である．これは，(1)seedページを導入して半教師有りクラスタリングを行なう場合，通常の重心の計算法では重心の変動が大きくなる傾向にあり，クラスタリングの基準となるseedページを導入する効果が得られない，(2)重心を完全に固定して半教師有りクラスタリングを行なう場合，その重心と類似度が高いWebページしかマージされなくなり，多数の独立したクラスタが生成されやすくなる，という二つの考えに基づく．したがって，seedページを含むクラスタの重心の変動を抑えることができれば，より適切なクラスタリングが実現できると期待される．本章では，我々の提案する半教師有りクラスタリングの手法について説明する．以下，検索結果集合W_p中のWebページp_iの特徴ベクトルw^p_i(i=1,,n)を式()のように表す．ここで，mは検索結果集合W_pにおける単語の異なり数であり，t_k(k=1,2,,m)は，各単語を表す．予備実験として，(a)TermFrequency(TF)，(b)InverseDocumentFrequency(IDF)，(c)residualIDF(RIDF)，(d)TF-IDF，(e)x^I-measure，(f)gainの6つの単語重み付け法を比較した．これらの単語重み付け法は，それぞれ，次のように定義される．(a)TermFrequency(TF)TFは，与えられた文書において，ある単語がどれだけ顕著に出現するかを示し，この値が大きければ大きいほど，その単語が文書の内容をよく表現していることを示す．tf(t_k,p_i)をWebページp_iにおける単語t_kの頻度とする．このとき，w^p_iの各要素w_t_k^p_iは，式()によって定義される．w_t_k^p_i=tf(t_k,p_i)_s=1^mtf(t_s,p_i)eqnarray(b)InverseDocumentFrequency(IDF)によって導入されたIDFは，その単語が出現する文書数が少なければ少ないほど，その単語が出現する文書にとっては，有用であることを示すスコアである．このとき，w^p_iの各要素w_t_k^p_iは，式()によって定義される．w_t_k^p_i=Ndf(t_k)eqnarrayここで，NはWebページの総数，df(t_k)は単語t_kが現れるWebページ数である．(c)ResidualInverseDocumentFrequency(RIDF)ChurchandGaleは，ほとんどすべての単語は，ポアッソンモデルのような独立性に基づいたモデルに応じて，非常に大きなIDFスコアを持つことを示した．また，単語の有用性は，推定されるスコアからは大きな偏差を持つ傾向があるという考えに基づいて導入したスコアがresidualIDFである．このスコアは，実際のIDFとポアッソン分布によって推定されるIDFとの差として定義される．cf_kを文書集合中における単語t_kの総出現数，NをWebページの総数としたとき，1つのWebページあたりの単語t_kの平均出現数は，_k=cf_kNと表される．このとき，w^p_iの各要素w_t_k^p_iは，式()によって定義される．w_t_k^p_i&amp;=IDF-11-p(0;_i)&amp;=Ndf(t_k)+(1-p(0;_k))alignここで，pは，パラメータ_kを伴うポアッソン分布である．この手法は，少数の文書のみに出現する単語は，より大きなRIDFスコアを持つ傾向がある．(d)TF-IDFTF-IDF法は，文書中の単語を重み付けするために，情報検索の研究において広く使われている．TF-IDFは，上述した(a)TFと(b)IDFに基づいて，式()のように定義される．w_t_k^p_i=tf(t_k,p_i)_s=1^mtf(t_s,p_i)Ndf(t_k)eqnarrayここで，tf(t_k,p_i)とdf(t_k)は，それぞれ，Webページp_iにおける単語t_kの頻度と，単語t_kが出現するWebページ数を表す．また，NはWebページの総数である．(e)x^I-measureBooksteinandSwansonは，単語t_kに対するx^I-measureというスコアを導入した．tf(t_k,p_i)をWebページp_iにおける単語t_kの頻度，df(t_k)を単語t_kが現れるWebページ数とすると，w^p_iの各要素w_t_k^p_iは，式()によって定義される．w_t_k^p_i=tf(t_k,p_i)-df(t_k)eqnarrayこの手法は，同程度の出現頻度である2つの単語のうち，少数の文書に集中して出現する単語ほど，高いスコアを示す．(f)gain一般に，IDFは単語の重要性を表すと考えられているが，Papineniは，IDFは単語の特徴を表す最適な重みに過ぎず，単語の重要性とは異なるものであるため，利得を単語の重要性と考え，gainを提案した．本手法では，w^p_iの各要素w_t_k^p_iは，式()によって定義される．w_t_k^p_i=df(t_k)N(df(t_k)N-1-df(t_k)N)eqnarrayここで，df(t_k)は，単語t_kが現れるWebページ数を，NはWebページの総数を示す．本手法では，ほとんど出現しない単語と，非常に頻出する単語は，両方とも低いスコアとなり，中頻度の単語は高いスコアとなる．上述した(a)〜(f)の単語重み付け手法の中で，本研究においては，``(f)gain''が最も効果的な単語の重み付け法であることがわかったため，これを本研究における単語の重み付け法として用いる．さらに，クラスタCの重心ベクトルG^Cを式()のように定義する．G^C=(g^C_t_1,g^C_t_2,,g^C_t_m)eqnarrayここで，g^C_t_kはG^Cにおける各単語の重みであり，t_k(k=1,2,,m)は各単語を表す．なお，以下で述べるクラスタリング手法では，2つのクラスタC_i，C_j間の類似度sim(C_i,C_j)を，式()によって計算する．sim(C_i,C_j)=G^C_iG^C_j|G^C_i||G^C_j|eqnarrayただし，G^C_i，G^C_jは，それぞれ，クラスタC_i，C_jの重心ベクトルを表す．</section>
  <subsection title="凝集型クラスタリング">凝集型クラスタリングにおいては，はじめに各Webページを，個々のクラスタとして設定する．次に，二つのクラスタ間の類似度が，あらかじめ設定された閾値より小さくなるまで，類似度が最大となる二つのクラスタをマージして新たなクラスタを生成する．図に凝集型クラスタリングのアルゴリズムを示す．このアルゴリズムでは，あるクラスタC_i(要素数n_i)を最も類似したクラスタC_j(要素数n_j)にマージした後の，新たなクラスタC^newの重心ベクトルG^newは，式()のように定義される．G^new=_w^pC_iw^p+_w^pC_jw^pn_i+n_jeqnarray</subsection>
  <subsection title="提案する半教師有りクラスタリング">一般に，seedページを含むクラスタC_s_jと，seedページを含まないクラスタC_iの類似度が大きい場合には，両者を新たなクラスタとしてマージすべきであるが，両者の距離が大きい場合には，通常の重心の計算法では，重心の変動が大きくなる傾向にある．そこで，はじめに，あるクラスタC_i(重心ベクトルG^C_i)を，seedページを含むクラスタC_s_j(重心ベクトルG^C_s_j)にマージする際，これらのクラスタの重心間の距離D(G^C_i,G^C_s_j)に基づいて，Webページpの特徴ベクトルw^pC_iを重み付けする．次に，この重み付けした特徴ベクトルを用いて重心の計算を行なうことで上述した傾向を防ぎ，重心の変動を抑える．まず，これまでにk_j個のクラスタがマージされたseedページを含むクラスタC_s_j^(k_j)(要素数n_s_j)に対して，クラスタC_i(要素数n_i)がk_j+1回目にマージされるクラスタであるとする．なお，クラスタC_s_j^(0)の要素は，初期のseedページとなる．(1)このC_s_j^(k_j)にマージされるクラスタC_iに含まれる各要素について，C_s_j^(k_j)の重心G^C_s_j^(k_j)と，クラスタC_iの重心G^C_i間の距離尺度D(G^C_i,G^C_s_j^(k_j))を用いて，クラスタC_iに含まれるWebページの特徴ベクトルw^p_l_C_i(l=1,,n_i)を重み付けし，その後に生成されるクラスタをC_i'(要素数n_i')とする．このとき，C_i'の要素となる重み付けした後のWebページの特徴ベクトルw^p_l_C_i'は，式()で表される．w^p_l_C_i'=w^p_l_C_iD(G^C_i,G^C_s_j^(k_j))+ceqnarray本研究では，D(G^C_i,G^C_s_j^(k_j))として，(i)ユークリッド距離，(ii)マハラノビス距離，(iii)適応的マハラノビス距離，の三つの距離尺度を比較する．また，cはD(G^C_i,G^C_s_j^(k_j))が0に非常に近い値となったとき，w^pの各要素が極端に大きな値となることを防ぐために導入した定数である．このcの値の影響については，3.3.1節で述べる．(2)次に，seedページを含むクラスタC_s_j^(k_j)(要素数n_s_j)にC_i'(要素数n_i')の要素を追加し，クラスタC_s_j^(k_j+1)(要素数n_s_j+n_i')を作成する．[C_s_j^(k_j+1)=w^p_1_C_s_j^(k_j),,w^p_n_s_j_C_s_j^(k_j),w^p_1_C_i',,w^p_n_i'_C_i'](3)このとき，k_j+1回目のクラスタをマージしたクラスタC_s_j^(k_j+1)の重心G^C_s_j^(k_j+1)は，式()のように計算される．ここで，式()において，マージされるクラスタの特徴ベクトルw^p_l_C_iに重み付けをしているため，重み付き平均の計算となるように，n_i'にも同様の重みを乗じている．G^C_s_j^(k_j+1)=_w^pC_s_j^(k_j+1)w^pn_s_j+n_i'1D(G^C_i,G^C_s_j^(k_j))+ceqnarrayこのように本研究では，seedページを含むクラスタを重視してクラスタリングの基準を明確にし，正確なクラスタリングを行うことを目的とする．もし，2つのクラスタが種用例を含まないのであれば，新たなクラスタの重心ベクトルG^newは，式()のように計算される．G^new=_w^pC_iw^p+_w^pC_jw^pn_i+n_jeqnarray本研究では，seedページを含むクラスタに，それと最も類似したクラスタをマージする際，seedページを含むクラスタの重心の変動を抑える半教師有りクラスタリングを適用して，Web検索結果における人名の曖昧性を解消する．従来の半教師有りクラスタリングの手法のうち，制約を導入する手法では，クラスタの基準となる重心についての検討は見逃されており，また，距離を学習する手法では，特徴空間が大域的に変換される．一方，我々の手法は，seedページを含むクラスタの重心の変動を抑え，その重心を局所的に調整できる効果が期待される．なお，seedページを導入することで，検索結果を改善することは，適合性フィードバックに類似した手法であると考えられる．しかし，適合性フィードバックでは，検索結果中の文書に対して，ユーザが判断した適合文書・非適合文書に基づいた検索語の修正を目的としているのに対し，本手法は，あらかじめ設定したseedページに基づいて，検索結果の改善，特に本研究においては，検索結果のクラスタリング精度の改善を目的としている点が異なる．また，検索結果をクラスタリングする検索エンジンとして，``Clusty''が挙げられる．しかし，そのクラスタリングされた検索結果には，適合しないWebページが含まれることも多く，クラスタリングを行う上で，何らかの基準が必要である．すなわち，本研究のように，seedページをクラスタリングの基準として導入し，かつ，そのseedページを含むクラスタの重心を抑えることで，その基準を保つような手法が必要であると考えられる．図に，我々の提案する半教師有りクラスタリングアルゴリズムの詳細を示す．なお，提案する半教師有りクラスタリングでは，対象とするすべてのWebページが，いずれかのseedページを含むクラスタにマージされるのではなく，seedページを含まないクラスタにもマージされることに，注意されたい（図下から7行目，``elseif''以降参照）．ここで，本研究において比較する式()直後に述べた(i)，(ii)，(iii)の3つの距離尺度は，それぞれ，以下のように定義される．(i)ユークリッド距離式()において，ユークリッド距離を導入した場合，seedページを含むクラスタの重心ベクトルG^C_sと，あるクラスタCの重心ベクトルG^C間の距離D(G^C_s,G^C)は，式()に基づいて，式()のように定義される．D(G^C_s,G^C)=_k=1^m(g^C_s_t_k-g^C_t_k)^2eqnarray(ii)マハラノビス距離マハラノビス距離は，データ集合の相関を考慮した尺度であるという点において，ユークリッド距離とは異なる．したがって，ユークリッド距離を用いるよりもマハラノビス距離を用いた方が，クラスタの重心の変動を，より効果的に抑えられることが期待される．式()において，マハラノビス距離を導入した場合，seedページを含むクラスタC_sの重心ベクトルG^C_sと，あるクラスタCの重心ベクトルG^C間の距離D(G^C_s,G^C)は，式()のように定義される．D(G_C_(s),G_C)=(G^C_s-G^C)^T^-1(G^C_s-G^C)eqnarrayここで，は，seedページを含むクラスタC_sの要素によって定義される共分散行列である．すなわち，クラスタC_s内の要素を，[C_s=w^p_1_C_s,w^p_2_C_s,,w^p_m_C_s]と表せば，重心ベクトルG^C_s，[G^C_s=1m_i=1^mw^p_i_C_s]を用いて，共分散_ijを式()のように定義することができる．_ij=1m_i=1^m(w^p_i_C_s-G^C_s)(w^p_j_C_s-G^C_s)^Teqnarray以上から，共分散行列は，[=[]]と表すことができる．(iii)適応的マハラノビス距離(ii)のマハラノビス距離は，クラスタ内の要素数が少ないときに，共分散が大きくなる傾向がある．そこで，seedページを含むあるクラスタC_s_jについて，このクラスタに含まれるWebページの特徴ベクトル間の非類似度を局所最小化することを考える．この局所最小化で得られる分散共分散行列を用いて計算したC_s_jの重心ベクトルG^C_s_jと，このクラスタにマージされるクラスタC_lの重心ベクトルG^C_l間の距離が，適応的マハラノビス距離である．この分散共分散行列は，次のように導出される．(1)まず，クラスタC_s_jにおいて，このクラスタに含まれるWebページの特徴ベクトルw^p_iと，それ以外の特徴ベクトルv(w^p_iv)との非類似度d_s_j(w^p_i,v)を，式()により定義する．d_s_j(w^p_i,v)=(w^p_i-v)^TM_s_j^-1(w^p_i-v)eqnarrayただし，M_s_jはC_s_jの分散共分散行列を表す．すなわち，クラスタC_s_j内の要素を，[C_s_j=w^p_1_C_s_j,w^p_2_C_s_j,,w^p_m_C_s_j]と表せば，重心ベクトルG^C_s_j，[G^C_s_j=1m_i=1^mw^p_i_C_s_j]を用いて，共分散M_ijを式()のように定義することができる．M_ij=1m_i=1^m(w^p_i_C_s_j-G^C_s_j)(w^p_j_C_s_j-G^C_s_j)^Teqnarray以上から，共分散行列M_s_jは，[M_s_j=[]]と表すことができる．(2)次に，目的関数_s_j(v,M_s_j)	&amp;=_w^p_iC_s_jd_s_j	(w^p_i,v)&amp;=_w^p_iC_s_j	(w^p_i-v)^TM_s_j^-1	(w^p_i-v)align*を定義し，これを局所最小化するようなC_s_jの代表点の特徴ベクトルL_s_jと分散共分散行列S_s_jを求める．(i)まず，クラスタC_s_jの要素により定義される共分散行列M_s_jを固定し，_s_jを最小化するL_s_jを求める．L_s_j=_v_w^p_iC_s_j(w^p_i-v)^TM_s_j^-1(w^p_i-v)eqnarray式()において，クラスタC_s_jの重心Gに最も近い点G'の特徴ベクトルをv_G'と表せば，L_s_j=v_G'と求めることができる．(ii)次に，(i)で求めた代表点の特徴ベクトルL_s_j=v_G'を固定する．ここで，det(M_s_j)=1のもとで，_s_jを局所最小化するS_s_jを求める．S_s_j=_M_s_j_w^p_iC_s_j(w^p_i-v_G')^TM_s_j^-1(w^p_i-v_G')eqnarrayこのS_s_jは，クラスタC_s_jの共分散行列M_s_jを用いて，式()によって与えられることが，文献により示されている．S_s_j=(det(M_s_j))^1/mM_s_j^-1eqnarrayただし，det(M_s_j)0であり，mは検索結果集合における単語の異なり数を表す．以上から，seedページを含むあるクラスタC_s_jにおいて，Webページ間の非類似度を局所最小化することを考慮した分散共分散行列S_s_jを求めることができる．このS_s_jを用いて，C_s_jの重心ベクトルG^C_s_jと，このクラスタにマージされるべきクラスタC_lの重心ベクトルG^C_l間の適応的マハラノビス距離は，式()のように定義される．D(G^C_s_j,G^C_l)=(G^C_s_j-G^C_l)^TS_s_j^-1(G^C_s_j-G^C_l)eqnarrayなお，式()は，上述した(1)〜(2)によるクラスタC_s_jにおけるWebページ間の非類似度を考慮して得られた式()の分散共分散行列S_s_jを適用している点で，式()とは異なる．</subsection>
  <section title="実験"/>
  <subsection title="実験データ">本研究では，``WebPeopleSearchTask''において作成された「WePSコーパス」を，実験に用いた．このWePSコーパスは，訓練集合とテスト集合から構成され，それぞれ49，30，合計で79の人名が含まれる．これらは，人名を検索語として，Yahoo!の検索APIを通じて得られた上位100件の検索結果から取得されたものである．すなわち，このコーパスは約7,900のWebページから構成される．具体的な統計量を表に示す．まず前処理として，このコーパスにおけるすべてのWebページに対して，不要語リストに基づいて，不要語を取り除き，PorterStemmermartin/PorterStemmer/を用いて語幹処理を行なった．次に，WePSコーパスの訓練集合を用いて類似したクラスタをマージするための最適なパラメータを決定し，これをWePSコーパスのテスト集合に適用した．</subsection>
  <subsection title="評価尺度">本研究では，``purity''，``inversepurity''と，これらの調和平均であるF値に基づいて，クラスタリングの精度を評価する．これらは，``WebPeopleSearchTask''において採用されている標準的な評価尺度である．以下，生成されたクラスタに割り当てられるべき，人手で定めた正解を「カテゴリ」と呼ぶことにする．``purity''は，各クラスタにおいて最もよく現れるカテゴリの頻度に注目し，ノイズの少ないクラスタを高く評価する．Cを評価対象となるクラスタの集合，Lを人手で作成したカテゴリの集合，nをクラスタリング対象の文書数とすると，purityは，式()に基づいて，最大となる適合率の重み付き平均をとることで計算される．Purity=_i|C_i|nPrecision(C_i,L_j)eqnarrayここで，あるカテゴリL_jに対するクラスタC_iの適合率Precision(C_i,L_j)は，式()によって定義される．Precision(C_i,L_j)=|C_iL_j||C_i|eqnarray``inversepurity''は，各カテゴリに対して最大の再現率となるクラスタに着目する．ある一つのクラスタにおいて，各カテゴリで定められた要素を多く含むクラスタを高く評価する．inversepurityは，式()によって定義される．InversePurity=_j|L_j|nRecall(C_i,L_j)eqnarrayここで，あるカテゴリL_jに対するクラスタC_iの再現率Recall(C_i,L_j)は，式()によって定義される．Recall(C_i,L_j)=|C_iL_j||L_j|eqnarrayまた，purityとinversepurityの調和平均Fは，式()によって定義される．F=11Purity+(1-)1InversePurityeqnarrayなお，本研究では，=0.5，0.2として，評価を行なった．以下，=0.5，0.2のときのF値を，それぞれ，F_0.5，F_0.2と示すことにする．</subsection>
  <subsection title="実験結果">我々の提案する半教師有りクラスタリングの手法では，次の2種類のseedページを用いた実験を行なった．Wikipediaにおける各人物の記事，Web検索結果において上位に順位付けされたWebページ．</subsection>
  <subsubsection title="文書全体を用いた実験結果">(1)凝集型クラスタリングを用いた実験結果凝集型クラスタリングによって得られた精度を表に示す．(2)半教師有りクラスタリングを用いた実験結果seedページを導入することによる効果を確かめるため，はじめに一つのseedページを用いて実験を行なった．この際，節はじめに述べた2種類のseedページに関して，(a)は検索結果の上位にあるWikipediaの記事を，(b)は第1位に順位付けされたWebページを用いた．しかしながら，節で述べたWePSコーパスのテスト集合におけるすべての人名が，必ずしもWikipediaに対応する記事を有するわけではない．したがって，ある人名がWikipediaに記事を有するのであれば，これをseedページとして用いた．そうでなければ，Web検索結果において第1位に順位付けされたWebページを用いた．この方針に基づき，WePSコーパスのテスト集合における30の人名のうち，16の人名に対してはWikipediaの記事を，14の人名に対しては第1位に順位付けされたWebページをseedページとして用いた．なお，人名の曖昧性解消にWikipediaを利用した最近の研究として，Bunescuらは，Wikipediaの構造を用いることによって固有名を同定するとともに，その固有名の曖昧性を解消している．表に，一つのseedページでの半教師有りクラスタリングを用いて得られたクラスタリング精度を示す．さらに，一つのseedページを用いた実験において，最も良いF値(F_0.5=0.68，F_0.2=0.66)が得られた適応的マハラノビス距離に関して，seedページの数を変えることによって，さらなる実験を行なった．3.3.1節でも述べたように，少数のseedページでの効果を確認するために，導入するseedページの数は7個までとした．また，図に示したように，これらのseedページの間には，``cannot-link''の制約を導入している．これは，上位に順位付けされる検索エンジンの出力結果を信頼し，それぞれのWebページが異なる人物について記述していると想定していることに基づく．図，は，それぞれ,複数のWikipedia記事，上位7位までに順位付けされたWebページを用いて得られたクラスタリング精度(F値)を示す．また，この実験では，章で述べたように，seedページを含むクラスタの重心と，それにマージされるクラスタの重心間の距離を考慮する．この提案手法の有効性を確認するために，章で述べた距離を学習する半教師有りクラスタリング手法であるKleinら，Xingら，Bar-Hillelらの手法を用いて得られた結果との比較を示す．また，seedページを含むクラスタの重心の変動を抑えることによる効果を確認するために，重心を固定する手法との比較も示す．</subsubsection>
  <subsubsection title="文書を部分的に用いた実験結果">3.3.2節で述べた実験では，検索結果のWebページとseedページの全文を用いた．しかし，人物について記述されたWebページにおいて，その人物を特徴付ける単語は，人名の周囲にしばしば現れること，また，検索結果のスニペットにおいても，同様の傾向が観察される．そこで，seedページを用いて最も良い結果が得られている場合，すなわち，図において，5つのWikipedia記事を用いた場合(F_0.5=0.76,F_0.2=0.74)に，さらに精度が改善されるかを確認するために，seedページと検索結果のWebページにおいて，人名前後の単語，および文の数を変化させる，検索結果のスニペットを用いる，実験を行なった．(i)については，まず，WePSコーパスの訓練集合を用いて，最も良いF値を与えるseedページと検索結果のWebページのそれぞれにおいて用いる人名前後の単語数，または文数を求める．この結果を図に示す．次に，これらのパラメータをテスト集合に適用し，評価する．(ii)についても同様に，WePSコーパスの訓練集合を用いて，最も良いF値を与えるseedページでの人名前後の単語数，または文数を求める．この結果を図に示す．次に，これらのパラメータをテスト集合に適用し，評価する．最終的に(i)，(ii)の実験によって得られたクラスタリング精度を，表に示す．</subsubsection>
  <subsubsection title="他手法との比較">``WebPeopleSearchTask''における上位3チームのクラスタリング精度(F値)を，表に示す．なお，これらのチームで採用している手法の詳細については，表に示した文献を参照されたい．基本的には，凝集型クラスタリングの手法が採用されている．また，提案手法によって得られた結果も，比較のために示す．</subsubsection>
  <subsection title="処理時間に関する検討">3.3.2節で述べたように，式()において，適応的マハラノビス距離を用いて，seedページを含むクラスタにマージされるクラスタに含まれるWebページの特徴ベクトルを重み付けし，この変換された特徴ベクトルを用いて重心の計算を行なった場合に，最良なクラスタリング精度が得られることがわかった．この場合について，7つまでのWikipedia記事，上位7位までに順位付けされたWebページをseedページとして用い，最も処理時間を要すると考えられる3.3.2節の文書全体を用いた場合についての処理時間を測定した．なお，提案手法は，PC(CPU:IntelPentiumM・2.0~GHz，Memory:2~GByte，OS:WindowsXP)上にPerlを用いて実装されている．図に，その結果を示す．</subsection>
  <subsection title="考察">式()におけるcの値について，特徴ベクトルを重み付けする際には，表〜からc=0.95前後の値を用いたときに，最良なクラスタリング精度が得られることがわかった．なお，5c50の大きな値のときには，それほど高いクラスタリング精度が得られないことも観察された．これは，式()において，距離尺度よりもcが支配的になることにより，クラスタにマージすべきWebページの特徴ベクトルの各要素の値が小さくなりすぎることによる影響であると考えられる．凝集型クラスタリングの手法においては，表から，purity(0.67)は，inversepurity(0.48)よりも高いことがわかる．このように，purityが高いことは，凝集型クラスタリングが，一つの要素しか含まないクラスタを生成する傾向にあることを示す．また，F値がF_0.5=0.52，F_0.2=0.49であり，それほど高い精度が得られていないことは，凝集型クラスタリングでは，クラスタリングを適切に行なうことが難しいことを改めて確認できたといえる．章で述べた半教師有りクラスタリングの手法において，表からpurityの値(0.47〜0.57)は，表の凝集型クラスタリングを用いて得られたpurityの値(0.67)を上回ることができなかったが，inversepurityの値(0.75〜0.88)は，すべての手法が凝集型クラスタリングの値(0.48)を上回っていることがわかる．また，良好なinversepurityの値によって，F値においても，良い結果が得られている．これは，seedページを導入したこと，ならびに，そのseedページを含むクラスタの重心の変動を抑えられたことによる効果であると考えられる．さらに，表からは，seedページとしてWikipediaの記事を用い，適応的マハラノビス距離を適用した場合において，最も良いF値(F_0.5=0.68，F_0.2=0.66)が得られたことがわかる．複数のseedページを用いた半教師有りクラスタリング手法においては，図，から，次の内容が観察される．まず，いずれのseedページを用いても，また，いずれの手法においても，導入する種文書数の増加とともに，クラスタリング精度(F値)が改善されている．seedページの数について，7個まで導入したが，いずれのseedページとも5個の時点でのクラスタリング精度が最も良いことが観察される．さらに，重心を固定する方法は，他の手法に比べて非常に精度が劣る結果となった．これは，重心を完全に固定してしまうと，その重心と類似度が高いWebページしかマージされなくなるため，本来クラスタにマージされるべきWebページが独立したクラスタとなってしまうことが原因であると考えられる．この実験においては，高いpurityの値が得られていたことからも，上述した原因が裏付けられるといえる．一方，距離を学習するクラスタリング手法では，Bar-Hillelら，Xingら，Kleinらの手法の順に良いクラスタリング精度が得られている．章で述べたように，Kleinらの手法では，類似した2点(x_i,x_j)間を0，類似していない2点間を(_i,jD_ij)+1と設定した単純な隣接行列を作成した上で，クラスタリングを行なうのに対し，Xingら，Bar-Hillelらの方法では，特徴空間を適切に変換する手法が用いられている．後者の二つの手法では，この変換手法が有効に作用しているものと考えられる．しかし，これらの距離を学習する手法と比較しても，重心の変動を抑えたクラスタリングを行なう我々の提案手法が，最も良いクラスタリング精度を示した．これは，あるクラスタをseedページを含むクラスタにマージするたびに，そのseedページを含むクラスタの重心を局所的に調整できることによる効果であると考えられる．さらに，seedページについては，Wikipediaにおける各人物の記事を用いたほうが，Web検索結果の上位に順位付けされたWebページを用いるよりも良い精度が得られた．これは，クラスタリングのためのseedページとして，Wikipediaの記述内容を用いることが有効であることを示す事例であると考えられる．また，文書を部分的に用いた場合には，以下に述べるような傾向が観察される．まず，WePSコーパスの訓練集合において，3.3.3節(i)で述べたように，seedページ，および検索結果のWebページ中の人名前後の単語数または文数を変化させた場合，図から，検索結果のWebページに関して，単語よりも文を用いることで，より良いクラスタリング精度が得られることが観察される．これは，人名前後の数語のみでは，人物の実体を識別することは難しいが，人名前後の数文を用いることで，その人物を特徴付ける情報を獲得でき，人物の実体を識別しやすくなったことによる効果であると考えられる．また，図からは，seedページ，検索結果のWebページについて，それぞれ，人名前後の2文，3文を用いた場合に最も良いF値(F_0.5=0.79，F_0.2=0.80)が得られることがわかった．これらの文数をWePSコーパスのテスト集合に適用した場合，[purity:0.80，inversepurity:0.83,F_0.5=0.81，F_0.2=0.82]の結果が得られた．特にF値は，=0.5のとき，表に示した``WebPeopleSearchTask''の第1位のチーム(CU_COMSEM)の結果を0.03上回り，提案手法が有効であることが確認される．なお，3.3.2節(2)で述べたように，Wikipediaに記事のある16人名のうち，Wikipediaから取得した人名数は10(表参照，以下(A)とする)，ACL'06参加者リスト，アメリカ合衆国・国勢調査の人名のうち，Wikipediaにも記事のある人名数は6（表参照，以下(B)とする）である．これらの人名について，Wikipediaをseedページとしてクラスタリングした場合に，その精度に差があるか否かを検証した．その結果を表に示す．(A)の方が(B)よりも，0.02〜0.04上回る結果が得られているが，それほど大きな差ではない．このことから，seedページとしてWikipediaの記述内容を用いることは，(B)のように他分野から取得した人物のWebページに対しても有効であり，Wikipediaの記述内容の汎用性が特徴付けられる結果であると考えられる．また，クラスタ数については，seedページを導入したことで，このseedページを中心に，Webページのグループが形成され，実際の正解クラスタ数よりも少ない数のクラスタが生成される傾向が観察された．これは，表において，inversepurityの値が高いことからも裏付けられる．なお，``WebPeopleSearchTask''の上位3チームは，凝集型クラスタリングの手法を採用しているが，これらの手法は素性を工夫することで，比較的高い精度を得ている．一方，我々の提案する半教師有りクラスタリングでは，seedページを含むクラスタの重心の変動を抑えることで，表に示した凝集型クラスタリングよりも精度が改善されている．我々が導入した素性は，章で述べたように，gainによって単語を重み付けする簡単なものであるが，``WebPeopleSearchTask''の上位3チームが使用した素性を我々の手法に適用すれば，さらなる精度の向上が期待される．そこで，これらの3チームの素性を，我々の手法で用いた結果を表に示す．なお，表に示した我々の提案手法で得られた最良の結果と比較するため，seedページとしてWikipediaにおける各人物の記事を5つ導入した場合についての比較を行った．まず，CU_COMSEMについて，表に示した凝集型クラスタリングのF値(F_0.5=0.78，F_0.2=0.83)と比較して，半教師有りクラスタリングのF値も高め(F_0.5=0.81，F_0.2=0.84)となっている．しかし，F_0.5で0.03，F_0.2で0.01程度の改善に過ぎない．これは，文中の単語，URLのトークン，名詞句など，すでに多くの素性を導入しているため，半教師有りクラスタリングを適用しても，それほど効果は得られないことによると考えられる．IRST-BPについては，表に示した凝集型クラスタリングのF値(F_0.5=0.75，F_0.2=0.77)と比較しても，半教師有りクラスタリングの精度は(F_0.5=0.76，F_0.2=0.81)であり，改善の程度はF_0.5で0.01，F_0.2で0.04であった．このチームが使用している固有名詞，時制表現，人名のある段落で最も良く出現する単語といった素性は，あまり有効な素性ではないと考えられる．PSNUSについては，NE素性をTF-IDFで重み付けしたのみの単純な素性であるが，表に示した凝集型クラスタリングのF値(F_0.5=0.75，F_0.2=0.78)と比較して，半教師有りクラスタリングで得られたF値はF_0.5=0.78，F_0.2=0.82であり，F_0.5で0.03，F_0.2で0.04の改善が観察される．一方，我々の手法では素性としてgainを用い，表に示したとおり，F_0.5=0.81，F_0.2=0.82のF値を得ている．これは，CU_COMSEMで使用されている多数の素性で得られたF値とほぼ同じ値が得られていることから，gainによって単純にWebページ中の単語を重み付けした素性だけでも，我々の提案する半教師有りクラスタリングを適用することで，高い精度が得られることが確認された．また，表に示した凝集型クラスタリングによるF値(F_0.5=0.52，F_0.2=0.49)と比較しても，F_0.5で0.29，F_0.2で0.33の改善が観察されたことから，我々の提案する半教師有りクラスタリングの有効性が確認される．次に，WePSコーパスの訓練集合において，3.3.3節(ii)で述べたように，検索結果のスニペットを用い，seedページ中の人名前後の単語数または文数を変化させた場合，図から，seedページ中の人名前後の単語ではなく，同様に文を用いたときに，より良いクラスタリング精度が得られることが観察される．この場合も同様に，人名前後の数語の情報よりも，人名前後の数文を用いることで，その人物を特徴付ける情報が獲得でき，人物の実体が識別しやすくなった効果によるものと考えられる．また，図からは，seedページについて，人名前後の3文を用いた場合に最も良いF値(F_0.5=0.64，F_0.2=0.67)が得られることがわかった．この文数をWePSコーパスのテスト集合に適用した場合，[purity:0.70，inversepurity:0.62，F_0.5=0.66，F_0.2=0.68]の結果が得られた．この結果は，WebPeopleSearchTaskの上位3チームの結果，および本研究における他の実験結果と比較して，かなり劣っている．これは，スニペットのような数語程度の情報だけでは，seedページで人名前後の3文という情報を用いたとしても，該当する人物について述べた適切なWebページが，そのseedページには集まらず，結果として，クラスタリング精度が悪くなったことによるためであると考えられる．以上から，提案手法ではWikipediaの記事をseedページとして利用し，人名前後の2文を，また，検索結果のWebページについては人名前後の3文を用いた場合に，良好な検索結果が得られることがわかった．さらに，処理時間に関して，最良なクラスタリング精度が得られた適応的マハラノビス距離の式()における分散共分散行列の計算には，単語数の2乗の計算量が必要となるが，1人名について100件のWebページのクラスタリングを行なうのに，最も多い5つのseedページを用い，seedページと検索結果のWebページの双方ともに文書全体を用いた場合でも，0.8秒余りで処理できることが図から観察され，妥当な応答性を実現できていると考えられる．</subsection>
  <section title="むすび">本論文では，Web検索結果における人名の曖昧性を解消するため，seedページを含むクラスタの重心の変動を抑える半教師有りクラスタリングの手法を提案した．実験の結果，最良な場合において，[purity:0.80，inversepurity:0.83，F_0.5:0.81，F_0.2:0.82]の評価値が得られた．今回は，上位に順位付けされる検索エンジンの出力結果が異なることを想定して実験を行った．すなわち，同一人物のseedページ間にも``cannot-link''の制約が導入されている可能性がある．しかし，クラスタが生成される過程で，seedページ以外の人物のページがクラスタ内の要素として支配的になり，最終的には比較的正確なクラスタが生成されることが観察された．同一人物のseedページ間でも，その人物を正確に表現しているページ，そうでないページがあることによるためであると考えられる．したがって，その人物についてより正確に記述されたWebページをseedページとして選択することが，今後の課題の一つとして挙げられる．また，Web検索結果における人名の曖昧性解消の精度を高めるには，その人物を特徴付ける単語の重みが大きくなるように，Webページの特徴ベクトルを作成して，クラスタリングを行なうことが重要である．そのために，特に，seedページの内容に適合する人物のページが集まるように，より的確なseedページの特徴ベクトルを作成するための手法を開発してクラスタリングを行なうことも，今後の課題として挙げられる．document</section>
</root>
