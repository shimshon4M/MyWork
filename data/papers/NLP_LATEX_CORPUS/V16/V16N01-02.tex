    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}
\usepackage{udline}
\setulminsep{1.2ex}{0.2ex}
\let\underline


\Volume{16}
\Number{1}
\Month{January}
\Year{2009}

\received{2007}{11}{22}
\revised{2008}{7}{4}
\accepted{2008}{10}{2}

\setcounter{page}{25}

\newcommand{\tuple}[1]{}
\newcommand{\NN}{}
\renewcommand{\vec}[1]{}
\newcommand{\svec}[1]{}
\newcommand{\vX}{}
\newcommand{\vx}{}




\jtitle{仮説検定に基づく英文書の母語話者性の判別}
\jauthor{冨浦　洋一\affiref{Author_1} \and 青木さやか\affiref{Author_2} \and
	柴田　雅博\affiref{Author_1} \and 行野　顕正\affiref{Author_4}}
\jabstract{
本論文では，
ベイズ識別と仮説検定に基づいて，
英文書の作成者の母語話者／非母語
話者の判別を高精度で行う手法を提案する．
品詞 $n$-gram モデルを言語モデルとし，
判別対象の文書の品詞列の生起確率を，母語話者言語モデルにより
求めた場合と非母語話者言語モデルにより求めた場合とで比較し，判別を行う．
$n$ を大きくすると，母語話者／非母語話者固有の特徴をより良く扱うこ
とが可能となり，判別精度の向上が期待できる反面，
ゼロ頻度問題およびスパースネスの問題が顕在化し，
品詞 $n$-gram モデルのパラメタの最尤推定値を信頼すること
はできくなる．そこで，提案手法では，
仮説検定に基づいた方法で両言語モデルにおける生起確率の比を推定する．
実験の結果，従来手法を上回る 92.5\% の精度で判別できることを確認している．
}
\jkeywords{母語話者性判別，言語推定，仮説検定}

\etitle{Discernment of Nativeness of English Documents Based on 
	Statistical Hypothesis Testing}
\eauthor{Yoichi Tomiura\affiref{Author_1} \and Sayaka Aoki\affiref{Author_2}\and 
	Masahiro Shibata\affiref{Author_1} 
	\and Kensei Yukino\affiref{Author_4}} 
\eabstract{
This paper proposes a method to discern the nativeness of English
documents with high precision
based on Bayes decision and a statistical hypothesis testing.
Regarding a document as a sequence of part-of-speeches, 
the proposed method makes a
comparison between probabilities of a document by the statistical
language model of native English and by that of non-native English to
discern the nativeness of the document. The statistical language model
used here is a $n$-gram model.  The $n$-gram model with a large $n$ can
be expected to treat well the difference between the native English and
the non-native one and has the potential to discern the nativeness
with high precision.
However,
when we use the $n$-gram model with a large $n$,
the zero frequency problem and the sparseness problem become acute
and we cannot rely on
the maximum likelihood estimates of $n$-gram probabilities. 
The proposed method estimates the
ratio of the probability of the document by the native English language
model to that by the non-native English language model
using a statistical hypothesis testing.
The experimental result shows that the proposed
method discerns the nativeness with the precision 92.5\%, 
which is significantly higher than by traditional methods. 
}
\ekeywords{
Discernment of Nativeness, Language Identification,  Statistical Hypothesis Testing}

\headauthor{冨浦，青木，柴田，行野}
\headtitle{仮説検定に基づく英文書の母語話者性の判別}

\affilabel{Author_1}{九州大学 大学院システム情報科学研究院}{Faculty of Information Science and Electrical Engineering, Kyushu University}
\affilabel{Author_2}{新日鉄ソリューションズ（株）}{NS Solutions Corporation}
\affilabel{Author_4}{株式会社ジャストシステム}{JustSystems Corporation}



\begin{document}
\maketitle



\section{はじめに}

本論文では，
ベイズ識別と仮説検定に基づいて，
英文書の作成者の母語話者／非母語
話者の判別（母語話者性の判別）を高精度で行う手法を提案する．
 
WWW上の英文書を英語教育や英文書作成支援に利用する研究が盛んに行われて
いる\cite{大鹿,佐野,大武}．WWW上にはオーサライズされた言語コーパスとは比
べものにならないくらいの大量の英文書が存在するため，これを言語データとし
て活用することで，必要な言語データの量の問題をかなり克服できる．
しかし，WWW上
の英文書の質は様々であり，英語を母語とする者あるいはそれと同等の英語運用
能力を有する者が書いた英文書（本論文では母語話者文書と呼ぶ）と英語を母語とし
ない者が書いた誤りや不自然な表現を含む英文書（本論文では非母語話者文書と
呼ぶ）とが混在している．
WWW上の英文書を英語学習教材として使用する場合，あるいは，英語表現の用例
集として使用する場合は，使用する英文書を母語話者文書に制限するのが望まし
い．また，非母語話者に特有の文法的特徴や使用語彙の傾向を調査したり，非母
語話者が犯しがちな不自然な表現を収集するには，大量の母語話者文書および非
母語話者文書を必要とする．したがって，英語教育や英文書作成支援を目的として
WWW上の英文書を使用する場合，英文書の母語話者性判別を行う技術は非常に重
要である．

本論文で提案する英文書の母語話者性判別手法では，品詞 $n$-gram モデ
ルを言語モデ
ルとし，判別対象の文書の品詞列（文書中の単語をその品詞で置き換えた列）の
母語話者言語モデルによる生起確率と非母語話者言語モデルによる生起確率との
比に基づいて判別を行う．$n=5,6,7$ といった比較的大きな $n$-gram モデル
を言語モデルとすることで，母語話者／非母語話者固有の特徴をより良く扱うこ
とが可能となり，判別精度の向上が期待できる．しかしその反面，
両言語モデルのパラメタ
（$n$-gram 確率）
を最尤推定した場合，母語話者／非母語話者文書間で品詞 $n$-gram モデル
のパラメタ値に大きな違いがあるのか，学習データの統
計的な揺らぎに起因するものなのかが区別できない．
$n=3$ という条件部が短い $n$-gram モデルを用いて判別を行
う場合でさえ，ゼロ頻度問題およびスパースネスの問題に対処するために，
通常なんらかのスムージングを行う．これに対し，提案手法では，
仮説検定に基づいた方法で両言語モデルにおける文書の生起確率の比を推定する．



\section{文書クラス識別の枠組み}
\label{節：文書クラス識別の枠組み}

本研究で扱う母語話者性の判別問題は，文書 $d$ が属すクラスの
識別問題の一種である．本節では，文書が属すクラスの識別の枠組み
について，その一般論を述べておく．

文書が属す可能性のあるクラスとして，$C_1,C_2,\cdots, C_M$ があるとする．
文書 $d$ がクラス $C$ に属す文書である尤もらしさ（尤度）$Lh(d,C)$ を何ら
かの方法で設定し，$Lh(d,C)$ が最大の $C$，つまり，
\[
 \arg\max_{C\in\{C_1,C_2,\cdots,C_M\}} Lh(d,C)
\]
を文書 $d$ が属すクラスとして識別する．
文書 $d$ のどのような構成要素（特徴）を用いて $Lh(d,C)$ をどのように
定義するかにより，どのようなクラスの識別ができるか，および，その識別
精度が異なって来る．次節で述べる言語識別，本論文で扱う母語話者性の判別の
他，ジャンルの識別，著者識別，さらに迷惑メールの判別(spam filter)も
この枠組みで議論することができる．

文書 $d$ の属すクラスが $C$ である尤度 $Lh(d,C)$ を $d$ が与えられたと
きのクラス $C$ の事後確率 $P(C|d)$ とし，文書 $d$ の属すクラスを，
\begin{equation}\label{式：ベイズ識別1}
 \arg\max_{C\in\{C_1,C_2,\cdots,C_M\}} P(C|d)
\end{equation}
と推定することもできる．これは，統計的パターン認識で用いられる事後確率最
大化識別（ベイズ識別）\cite{パターン認識テキスト}である．
文書 $d$ の生起確率を $P(d)$，クラス $C$ での $d$ の生起確率（クラ
ス $C$ に属す文書が生起するときにその文書が $d$ である条件付き確率）
を $P_C(d)$，クラス $C$ に属す文書の生起確率（$C$ の事前確率）を $P(C)$ と
すると，上記の事後確率 $P(C|d)$ は
\[
 P(C|d)=\frac{P(C)P_C(d)}{P(d)}
\]
と表せるので，式(\ref{式：ベイズ識別1})は，
\begin{equation}\label{式：ベイズ識別2}
 \arg\max_{C\in\{C_1,C_2,\cdots,C_M\}} P(C)P_C(d)
\end{equation}
と等しい．適当な統計的言語モデルを設定し，各クラス $C_i$ の文書集合（$C_i$ の
学習データ）を用いて，$C_i$ の言語モデルのパラメタを推定すれば，
式(\ref{式：ベイズ識別2})を用いて $d$ が属すクラスの識別をすることが
できる．

代表的な統計的言語モデルとして，$n$-gram モデルがある．一般に，
ある時点で生起する事象の確率が，その直前の $n$ 個の時点で生起した
事象だけの影響を受けるとき，これを $n$ 重マルコフ過程と呼び，
$n$-gram モデルは，記号の生起を $(n-1)$ 重マルコフ過程で近似した
モデルである\cite{確率的言語モデルテキスト}．
特に，$n=1$ の場合を uni-gram モデル，
$n=2$ の場合を bi-gram モデル，
$n=3$ の場合を tri-gram モデルと呼ぶ．$n$-gram モデルでは，
記号列 $\vec{a}=a_1a_2\cdots a_\ell$ の生起確率は，
\[
 P(\vec{a})
=\prod_{i=1}^{\ell+1} P(a_i\:|\: a_{i-n+1}\cdots a_{i-2}\,a_{i-1})
\]
で表される．ただし，$j\leq 0$ のとき $a_j=@_s$ であり，$@_s$ は文頭を
表す特殊記号である．また，$a_{\ell+1}=@_e$ であり，$@_e$ は文末を
表す特殊記号である．記号としては，文字，単語，品詞などが考えられる．
本論文では，記号が文字であるものを文字 $n$-gram モデル，
記号が品詞であるものを品詞 $n$-gram モデルと呼ぶことにする．
条件付き確率 $P(a_i\:|\: a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ は $n$-gram 確
率と呼ばれる．
本論文では，言語クラス $C$ の $n$-gram 確率を
$P_C(a_i\:|\: a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ と添え字を付けて
表す．
学習データの生起確率を最大にするようにモデルのパラメタを推定する最尤推
定\cite{統計テキスト}では，
$P_C(a_i\:|\: a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ は
\begin{equation}\label{式：n-gram確率の最尤推定値}
 \frac{f_C(a_{i-n+1}\cdot a_{i-2}\,a_{i-1}\,a_i)}
      {\sum_{a\in A} f_C(a_{i-n+1}\cdot a_{i-2}\,a_{i-1}\,a)},
\end{equation}
すなわち，
\[
 \frac{f_C(a_{i-n+1}\cdot a_{i-2}\,a_{i-1}\,a_i)}
      {f_C(a_{i-n+1}\cdot a_{i-2}\,a_{i-1})}
\]
と推定される．$f_C(\vec{a})$ は言語クラス $C$ の学習データ
における記号列 $\vec{a}$ の出現頻度であり，$A$ は記号の全体集合である．
しかし，$n$ が大きい場合，
$n$-gram 確率を単純に式(\ref{式：n-gram確率の最尤推定値})により推定する
と，学習データ中に出現しない記号列
$a_{i-n+1}\cdots a_{i-2}\,a_{i-1}\,a_i$ に対して，
$P_C(a_i\:|\: a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ を 0 と推定してしまうと
いう大きな問題がある．また，たとえ学習データ中に出現したとしても，
条件部の記号列 $a_{i-n+1}\cdots a_{i-2}\,a_{i-1}$ の出現頻度が小さい
場合は，統計的に信頼性のある確率値を推定するのが難しい．前者はゼロ頻度
問題，後者はスパースネスの問題と呼ばれている\cite{確率的言語モデルテキスト}．
したがって，これらの問題
に対処するために，通常は $n$-gram 確率のスムージングを行う．
代表的なスムージング手法としては，加算スムージング，線形補間などがある
\cite{確率的言語モデルテキスト}．一般に，線形補間の方が加算スムージング
より精度が高いと言われている．

また，多くの識別問題で高い性能を実現している2クラスの識別器であ
る Support Vector Machine\cite{パターン認識テキスト}を使って，文書 $d$ の属す
クラスを識別することもできる．

\section{関連研究}
\label{節：関連研究}

文書の母語話者性の判別と関連の深い研究分野として，文書の記述言語を推定す
る言語識別がある．

Cavnar らは，出現頻度上位の文字列とその順位を言語および文書の特徴と考え
る言語識別を行っている\cite{cavnar}．
各言語 $L_i$ の学習データ文書中での 1〜5 の長さの文字列のうち出現頻度上
位 300 個の文字列とその順位を求めて，言語 $L_i$ における順位表を作成し
ておく．同様に，識別対象文書 $d$ に対しても順位表を作成する．$d$ の順位
表中の各文字列の順位と $L_i$ の順位表での順位との差の絶対値の和を
$d$ と $L_i$ の非類似度 $dissim(d,L_i)$ と考え，$dissim(d,L)$ が最小の
言語 $L$を $d$ の記述言語として識別する．これは，前節で述べた枠組みに
対して，$dissim(d,L_i)$ の逆数を尤度 $Lh(d,L_i)$ と考えたことに相当する．

また，前田らは，長さ2の文字列の出現頻度分布をユークリッド空間上の
ベクトル（頻度ベクトル）であると考え，識別対象文書 $d$ の頻度ベクトルと
各言語 $L_i$ の学習データ文書の頻度ベクトルとの余弦を，
$d$ と言語 $L_i$ の類似度 $sim(d,L_i)$ とする言語識別を行っている\cite{前田}．
これは，前節で述べた枠組みに対して，
$sim(d,L_i)$ を尤度 $Lh(d,L_i)$ と考えたことに相当する．

行野らは，長い文字列の頻度は統計的な揺らぎが大きいものの，言語を特定する
能力が高いと考え，1〜7 の長さの文字列を言語および文書の特徴と考える言語
識別の手法を提案している\cite{行野}．彼らの手法は，識別対象文書 $d$ に出
現する 1〜7 の長さの文字列集合と言語 $L_i$ の学習データに出現
する 1〜7 の長さの文
字列集合の積集合の大きさを $Lh(d,L_i)$ とする手法である．長い文字列を特徴
として使用した結果，類似言語間の識別や識別対象文書が極めて短い場合の識別
でも，Cavanr らの手法，前田らの手法に比べ高い識別精度を実現したと報告している．

Dunning は文字 $n$-gram モデルにより $P_{L_i}(d)$ を求め，
言語の事前確率を等確率($P(L_i)=P(L_j)$)と仮定して，ベイズ識別に
より，$d$ の属す言語の識別を行っている\cite{dunning}．
ただし，ゼロ頻度問題に対処するため，
加算スムージングによる $n$-gram 確率のスムージングを行っている．
$n=1\sim 5$ を試した結果，$n=2$ の場合，
つまり，bi-gram モデルの場合が最も識別精度が高かったと報告している．

Sibun らは，長さ $n$ の文字列の確率分布を言語および文書の特徴と考え（実
際には $n=1$ または $n=2$ を採用している），
確率分布間の相違尺度である KL-Divergence に基づいた言語識別手法を提案
している\cite{sibun}．
確率分布 $P$ と $Q$ の KL-Divergence（Kullback-Leibler 距離）
$D_{KL}(P||Q)$ は
\[
 D_{KL}(P||Q)=\sum_{x\in{\cal X}} P(x)\log \frac{P(x)}{Q(x)}
\]
で定義される\cite{確率的言語モデルテキスト}．Sibun らの手法は，
$D_{KL}(P_d||P_{L_i})$ が最小の $L_i$ を $d$ の記述言語として識別す
る手法である．ただし，
$P_d(\vec{a})$ は文書 $d$ における文字列 $\vec{a}$ の生起確率 ，
$P_{L_i}(\vec{a})$ は言語クラス $L_i$ における文字列 $\vec{a}$ の生起確
率である．
$P_d(\vec{a})$ は
\[
 P_d(\vec{a})=\gamma\cdot f_d(\vec{a})
 \qquad \text{ただし，}
 \gamma=\frac{1}
       {\sum_{\svec{a}\in A^n}f_d(\vec{a})}
\]
と推定されるので（$f_d(\vec{a})$ は $d$ での文字列 $\vec{a}$ の出現頻度，
$A$ は記号の全体集合，$A^n$ は可能な $n$ 長さの文字列
の全体の集合），言語 $L_i$ における文書 $d$ の生起確率 $P_{L_i}(d)$ を
\begin{equation}\label{式：文書の生起確率の大胆な近似}
 P_{L_i}(d)=\prod_{\svec{a}\in A^n} P_{L_i}(\vec{a})^{f_d(\vec{a})}
\end{equation}
と大胆に近似するならば，
\[
 D_{KL}(P_d||P_{L_i})
 = \sum_{\svec{a}\in A^n} P_d(\vec{a}) \log \frac{P_d(\vec{a})}
                                                   {P_{L_i}(\vec{a})}
 = -\gamma\cdot\log P_{L_i}(d)+
         \sum_{\svec{a}\in A^n} P_d(\vec{a}) \log P_d(\vec{a})
\]
となる．つまり，$D_{KL}(P_d||P_{L_i})$ が最小の $L_i$ を $d$ の記述
言語として識別する Sibun らの手法は，
式(\ref{式：文書の生起確率の大胆な近似})の近似を行った上で，
言語の事前確率を等確率と仮定して，ベイズ識別により，
$d$ の属す言語の識別を行うことと等価である．
なお，Sibun らもゼロ頻度問題に対処するために，$P_{L_i}(\vec{a})$ は
\begin{equation}\label{式：Sibun加算スムージング}
P_{L_i}(\vec{a})=\frac{f_{L_i}(\vec{a})+\delta}
                      {\sum_{\svec{a}\in A^n} \{f_{L_i}(\vec{a})+\delta\}}
\end{equation}
のように，加算スムージングによりスムージングしている
（$\delta$ は非負の定数）．

次に，本論文で扱う文書の母語話者性判別に関する従来研究について述べる．

Tomokiyo らは，長さ $n$ ($n=1,2,3$)の記号列（記号として
は，単語，品詞，および単語品詞混合の3種を試している）を言語および
文書の特徴と考え，文書（あるいは，文書を構成する単語をその品詞に置き換えた
もの，文書を構成する一部の単語を品詞に置き換えたもの）の生起確率を
式(\ref{式：文書の生起確率の大胆な近似})で近似し，ベイズ識別に基づく
母語話者／非母語話者クラスの判別を行っている\cite{Tomokiyo}．
しかし，彼らは，子
供用ニュース記事の音読による発話や観光などに関する自発的発話を，音声認
識器によりテキストにした文書，および，人手で書き起こした文書を対象として
いる．音読では読み間違いが非母語話者の大きな特徴であり，自発的発話では，
使用語彙が母語話者／非母語話者の間の大きな違いである．一方，我々は，論文
などのように十分推敲して作成されているフォーマルな文書を対象としており，
母語話者／非母語話者判別に有効な特徴量も異なってくるため，彼らの判別
実験結果と直接比較することはできない．

藤井らは，品詞 tri-gram モデルを言語モデルとし，ゼロ頻度問題に対処できる
Skew Divergence を用いて英文書の母語話者性の判別を行っている\cite{藤井}．
以下で定義される判別対象文書 $d$ と言語クラス $C$（$\in\{N,\NN\}$,
$N$: 母語話者言語クラス，$\NN$: 非母語話者言語クラス）との相違度
$ED(d\:;\:C)$ 
\[
   ED(d\:;\:C)=\sum_{\tuple{ab}\in H^2}
                  f_d(ab)D(P_d^\tuple{ab}\:||\:P_C^\tuple{ab})
\]
を求め，$ED(d\:;\:C)$ を最小にする $C(\in\{N,\NN\})$ を $d$ が属すクラ
スとして推定する．ただし，$H$ は品詞の全体集合，
$P_d^\tuple{ab}$ は文書 $d$ における条件を $ab$ とする品詞 tri-gram 
分布，$P_C^\tuple{ab}$ はクラス $C$ における条件を $ab$ とする品詞 tri-gram 
分布\footnote{
つまり，$P_d^\tuple{ab}(x)$ は文書 $d$ において，
品詞列 $ab$ の次に品詞 $x$ が生起する確率 $P_d(x|ab)$，
$P_C^\tuple{ab}(x)$ は言語クラス $C$ において，
品詞列 $ab$ の次に品詞 $x$ が生起する確率 $P_C(x|ab)$である．
}，$D$ は確率分布間の相違度である．確率分布間の相違度 $D$ として KL Divergence 
を用いた場合，$ED(d\:;\:C)$ を最小にする $C(\in\{N,\NN\})$ は，文書 $d$ 
の各単語をその品詞で置き換えた品詞列の生起確率を最大にする言語クラスであ
る．したがって藤井らの手法は，品詞 tri-gram モデルを言語モデル
とし，言語の事前確率を等確率と仮定して，Bayes 識別
に基づいて $d$ が属すクラスを判定する方法と本質的には同じである．
藤井らの手法の特徴は，分布間の相違度 $D$ として KL Divergenceを用
いるのではなく，以下で定義される Skew Divergence \cite{Lee} を用いている
点にある．
\[
 D_{skew}(p\:||\:q)
  =\sum_{x\in {\cal X}} p(x)\log\frac{p(x)}{\alpha\cdot q(x)+(1-\alpha)\cdot p(x)}
\]
Skew Divergence はゼロ頻度問題に弱い KL Divergence を改良したものである．
藤井らは，$\alpha$ を，分布 $q$（つまり，
$P_N^\tuple{ab}$，$P_{\NN}^\tuple{ab}$）の推定に用いた学習データのサイズに応じて，$ab$ 毎に
\begin{equation}\label{Skew:α}
\alpha(ab)=1-\exp\left( -\sqrt{\beta\cdot \min(f_N(ab),f_{\NN}(ab))} \right)
\end{equation}
と設定している．彼らは，Skew Divergence を用いることで，線
形補間を施した品詞 tri-gram 分布による KL Divergence を用いた手法
および多くの識別問題で高い精度を実現している Support Vector Machine を用
いた手法よりも有意に高い判別精度を実現できたと報告している．

英文書の母語話者性判別は，母語話者英語，非母語話者英語という類似した言語の
識別問題と捉えることもできる．
青木らは，文書を，それを構成する単語を品詞で置き換えた品詞列と見なし，
基本的には KL-Divergence を用いた Sibun らの言語識別手法に基づいて，
文書の母語話者性の判別を行っている\cite{青木}．
「長い文字列も言語特徴とすることで類似言語の識別精度が向上する」と
いう行野らの知見
からの予想通り，長い品詞列の頻度情報を利用した場合の判別精度が高く（
$n=6$ のときが最も精度が高い），藤井らの手法より高精度で母語話者性を判別
できたと報告している．

著者らは，青木らの主張と同じく，長い品詞列の頻度情報も利用すること
が文書の母語話者性判別に有効であると考えている．
藤井らの手法は言語モデルを $n>3$ の品詞 $n$-gram モデルとしてもそ
のまま適用できる．しかし，藤井らは，式 (\ref{Skew:α})を
\begin{itemize}
\item $\alpha$ は $f=\min(f_N(ab),f_{\NN}(ab))$ の単調増加関数，
\item $\lim_{f\rightarrow\infty} \alpha =1$，
      $\lim_{f\rightarrow 0} \alpha =0$
\end{itemize}
を満たす $\alpha$ の設定法の一例として用いたに過ぎず，$n$ を大きくした
場合に，式 (\ref{Skew:α}) で良いのかどうかは疑問である．さらに，
$n$ を大きくしたとき，式 (\ref{Skew:α})では高い精度が得られない
場合に，式 (\ref{Skew:α})に代えて，上記の性質を満たす
$f=\min(f_N(ab),f_{\NN}(ab))$ のどのような関数を $\alpha$ の
設定に用いればよいのかも明らかではない．
一方，青木らの手法は，統計的パターン認識の立場で見るならば，
近似式(\ref{式：文書の生起確率の大胆な近似})を仮定したベイズ識別による
判別法である．しかし，品詞 $n$-gram モデルに比べ，
式(\ref{式：文書の生起確率の大胆な近似})は，近似としては非常に粗い．

$n$が大きな品詞 $n$-gram モデルを言語モデルとして使用し，かつ，
ゼロ頻度問題およびスパースネスの問題を克服する新たな
母語話者性判別手法を次節で述べる．


\section{提案手法}

本論文で提案する母語話者性判別手法は，長い品詞列の頻度情報を利用する
ことで，より高精度で判別を行うことをねらったもので，長い品詞列の頻度
情報を使うことによる信頼性の低下を防ぐために
仮説検定を利用しているのが大きな特徴である．

藤井らおよび青木らの研究と同じく，
文書をそれを構成する単語を品詞で置き換えた品詞列と
みなす．品詞 $n$-gram モデルを言語モデルとし，
文書内の各文が独立に生起すると仮定すると，
品詞列に変換した文書 $d$ のクラス $C$ での生起確率 $P_C(d)$ は，
\begin{equation}
\label{式：文書の生起確率}
     P_C(d)
     = \prod_{\svec{a}\in d} \prod_{i=1}^{\ell(\svec{a})+1} 
              P_C(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})
\end{equation}
と表せる．ただし，$\ell(\vec{a})$ は文（品詞列）$\vec{a}$ の
長さであり，$a_i$ は $\vec{a}$ の $i$ 番目の品詞である．また，
$j\leq 0$ のとき $a_j=@_s$ であり，$a_{\ell(\svec{a})+1}=@_e$ である（
\ref{節：文書クラス識別の枠組み}節参照）．
Bayes 識別に基づく文書 $d$ の母語話者性判別では，
母語話者文書と非母語話者文書の事前確率を $0.5$ とすると\footnote{
事前確率は，どの分野や範囲の文書を判別したいかで異なってくる
ため，一般には不明である．そこで
Dunning や藤井らの研究と同様，事前確率を等確率とした．
}，
\[
\begin{array}{lcl}
\displaystyle
\frac{P_N(d)}{P_{NN}(d)}>1
&\Longrightarrow& \mbox{母語話者文書クラス($N$)}\\[4mm]
\displaystyle
\frac{P_N(d)}{P_{NN}(d)}<1
&\Longrightarrow& \mbox{非母語話者文書クラス($N\!N$)}\\[4mm]
その他 &\Longrightarrow& \mbox{未定}
\end{array}
\]
と判別することになる．

生起確率の比の対数を取り，
文書（品詞列）の生起確率を
式(\ref{式：文書の生起確率})を用いて展開すると，
\begin{equation}\label{判別式}
 \log \frac{P_N(d)}{P_{\NN}(d)}=
 \sum_{\svec{a}\in d} \sum_{i=1}^{\ell(\svec{a})+1}
         \log \frac{P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})}
                   {P_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})}
\end{equation}
となる．
上式が正ならば $d$ は母語話者文書，負ならば $d$ は非母語話者
文書と判別することになる．

より大きな $n$ における品詞 $n$-gram モデルは，母語話者英語と非母語話者英語
における品詞列の生起確率の相違をより良く取り扱うことができると予想される．
しかし，現実的なサイズの学習データから最尤推定
により求めた品詞 $n$-gram 確率による
\begin{equation}\label{式：n-gram確率の比}
 \frac{P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})}
                   {P_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})}
\end{equation}
では，この値が1から大きくずれる場合に，これが両言語の大きな相違を示して
いるのか，統計的な揺らぎに起因するものかが分からない
（ゼロ頻度問題，スパースネスの問題）．
そこで，式(\ref{式：n-gram確率の比})を仮説検定に基づいた
以下に述べる2種類の手法により控えめに（最尤推定値を用いた場合の比よ
り1に近い値として）推定し，
これを用いて式(\ref{判別式})の計算を行い母語話者性の判別を行う．


\subsection{手法1}

手法1では，式(\ref{式：n-gram確率の比})の値
を以下のようにして推定する．ただし，
$\widehat{P}_C(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ を
$P_C(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ の最尤推定値とする．

\begin{itemize}
 \item[(A)] $\widehat{P}_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1}) > 
	    \widehat{P}_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ の場合
	    \[
	    \begin{cases}
	     帰無仮説：& 
	      P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1}) \leq 
	      \mu\cdot P_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})\\
	     対立仮説：&
	      P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1}) >
	      \mu \cdot P_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})\\
	    \end{cases}
	    \]
	    なる有意水準 $\alpha$ の検定において，帰無仮説を棄却できる
	    最大の $\mu$ を求め，$\mu>1$ ならば $n$-gram 確率の比
	    (\ref{式：n-gram確率の比})
	    を $\mu$ と推定し，$\mu\leq 1$ （つまり，
	    $P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ が
	    $P_{N\!N}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ より有意に
	    大きいと言えない）ならば 1 と推定する．
	    $f_C(\vec{a})$ を言語クラス $C$ ($\in \{N,\NN\}$) のモデルの
	    学習データにおける品詞列 $\vec{a}$ の出現頻度とすると，
	    上記の $\mu$ は，
	    \begin{align*}
	     x &= f_N(a_{i-n+1}\cdots a_{i-2}\,a_{i-1}\,a_i), &  
		y &= f_{\NN}(a_{i-n+1}\cdots a_{i-2}\,a_{i-1}\,a_i),\\
	     m &= f_N(a_{i-n+1}\cdots a_{i-2}\,a_{i-1}), & 
		n &= f_{\NN}(a_{i-n+1}\cdots a_{i-2}\,a_{i-1})
	    \end{align*}
	    として，付録\ref{付録：estimateMu} の
	    $\widehat{\mu}(x,m,y,n)$ で求めることができる．
 \item[(B)] $\widehat{P}_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1}) < 
	    \widehat{P}_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ の場合
	    \[
	    \begin{cases}
	     帰無仮説：& 
	      \mu\cdot P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1}) \geq 
	      P_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})\\
	     対立仮説：&
	      \mu \cdot P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1}) <
	      P_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})\\
	    \end{cases}
	    \]
	    なる有意水準 $\alpha$ の検定において，帰無仮説を棄却できる
	    最大の $\mu$ を求め，$\mu>1$ ならば $n$-gram 確率の比
	    (\ref{式：n-gram確率の比})を $1/\mu$ と推定し，
	    $\mu\leq 1$ （つまり，
	    $P_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ が
	    $P_{N\!N}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ より有意に
	    小さいと言えない）ならば 1 と推定する．
	    このような $\mu$ は，$x$, $m$, $y$, $n$ を前述(A)のように
	    定めると，$\widehat{\mu}(y,n,x,m)$ として求めることができる．
	    

 \item[(C)] $\widehat{P}_N(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1}) = 
        \widehat{P}_{\NN}(a_i|a_{i-n+1}\cdots a_{i-2}\,a_{i-1})$ の場合

	$n$-gram 確率の比(\ref{式：n-gram確率の比})を 1 と推定する．
\end{itemize}

\begin{table}[b]
\caption{$n$-gram 確率の比の推定例}
\label{表：n-gram確率の比の推定例}
\input{02table01.txt}
\end{table}

つまり，頻度情報の統計的揺らぎを考慮し，$1-\alpha$ の信頼度で，
$n$-gram 確率の比(\ref{式：n-gram確率の比})
を控えめに（最尤推定値を用いた場合の比より 1 に近い値として）推定する．
一方の $n$-gram 確率が他方より有意に大きいと言えない場合，
両 $n$-gram 確率に大きな違いはないということで，この $n$-gram 確率
の比を 1 と推定し，母語話者性判別に影響しないようにする．


表\ref{表：n-gram確率の比の推定例}に $n$-gram 確率の比の推定例を示す
（有意水準 $\alpha=0.05$）．
例(a)は頻度が小さいため有意水準 0.05 で一方の $n$-gram 確率
が他方の $n$-gram 確率より大きいと判断できない
場合で，比を1と推定している．例(b)〜(e) は最尤推定値を用いた場合
より 1 に近い値を推定している
（つまり，スパースネスの問題に対処できている）．
例(f)(g)は，最尤推定値を用いると $n$-gram 確率
の比がそれぞれ $\infty$，$0$ となってしまう場合であるが，
有意水準 0.05 での推定では 0 より大きな有限の値となっており，母語話者性の
判別に決定的な影響を与えることを避けている（つまり，ゼロ頻度問題
にも対処できている）．


\subsection{手法2}

手法2は，手法1を拡張し，
$n$-gram 確率の比(\ref{式：n-gram確率の比})の推定において，
有意水準 $\alpha$ では両言語モデルにおける $n$-gram 確率の一方が
他方より有意に大きいと
判断できない場合に，$3\leq k<n$ の $k$-gram 確率
の比の推定値を用いるものである\footnote{
$2\leq k<n$ も実験では試してみたが，$3\leq k <n$ の場合より，若干精度が
低下した．これは，bi-gram モデルでは母語話者／非母語話者文書の相違を扱うには
モデルが単純過ぎることを意味している．
}．

\begin{enumerate}
\item $k\longleftarrow n$

\item \label{手法2繰り返し}
      以下の3つの場合に応じて，
      \begin{equation}\label{式：n-gram確率の比（手法2）}
       \frac{P_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})}
                   {P_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})}
      \end{equation}
      を推定する．
      \begin{itemize}
       \item[(A)] $\widehat{P}_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1}) > 
		  \widehat{P}_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})$
		  の場合
		  \[
		   \begin{cases}
		    帰無仮説：& 
		     P_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1}) \leq 
		     \mu\cdot P_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})\\
		    対立仮説：&
		     P_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1}) >
		     \mu \cdot P_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})\\
		   \end{cases}
		  \]
		  なる有意水準 $\alpha$ の検定において，帰無仮説を棄却できる
		  最大の $\mu$ を求め，$\mu>1$ ならば $k$-gram 確率の比
		  (\ref{式：n-gram確率の比（手法2）})
		  を $\mu$ と推定し，$\mu\leq 1$ ならば 1 と推定する．
		  
       \item[(B)] $\widehat{P}_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1}) < 
		  \widehat{P}_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})$ 
		  の場合
		  \[
		   \begin{cases}
		    帰無仮説：& 
		     \mu\cdot P_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1}) 
		     \geq 
		     P_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})\\
		    対立仮説：&
		     \mu \cdot P_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1}) 
		     <
		     P_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})\\
		   \end{cases}
		  \]
		  なる有意水準 $\alpha$ の検定において，帰無仮説を棄却できる
		  最大の $\mu$ を求め，$\mu>1$ ならば $k$-gram 確率の比
		  (\ref{式：n-gram確率の比（手法2）})を $1/\mu$ と推定し，
		  $\mu\leq 1$ ならば 1 と推定する．
		  
       \item[(C)] $\widehat{P}_N(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1}) = 
		  \widehat{P}_{\NN}(a_i|a_{i-k+1}\cdots a_{i-2}\,a_{i-1})$
		  の場合
		  
		  $k$-gram確率の比(\ref{式：n-gram確率の比（手法2）})を 1 と
		  推定する．
      \end{itemize}
 \item 推定した $k$-gram 確率の比(\ref{式：n-gram確率の比（手法2）})が 1 で，
      かつ，$k>3$ ならば，
      $k\longleftarrow k-1$ として (\ref{手法2繰り返し}) へ．
      そうでないならば，この推定値を式(\ref{式：n-gram確率の比})の推
      定値とする．
\end{enumerate}


\section{実験}

2つの提案手法，つまり，
\begin{itemize}
\item 式(\ref{式：n-gram確率の比})の値の推定を手法1で行う判別手法
	   (Hypo1)，
\item 式(\ref{式：n-gram確率の比})の値の推定を手法2で行う判別手法(Hypo2)
\end{itemize}
を用いた母語話者性判別実験を行った．
また，
\begin{itemize}
\item 藤井らの手法で使用する言語モデルを $n$-gram に拡張した手法(Skew)，
\item 青木らの手法(KL)
\end{itemize}
による
母語話者性判別を行い，提案手法との比較を行った．

実験データは以下の2種類を用意した．
\begin{itemize}
 \item {\bf データ1}\\
       電気情報関係の国際会議で発表された英語科学技術論文．内訳は，
       \begin{itemize}
	\item 英語圏（米国，英国，カナダ，オーストラリア）で開催された採択率
	      50\%未満の国際会議の論文で，第一著者が英語圏所属の非日本人名で
	      ある論文 602 件，
	\item 東／東南アジアで開催された採択率50\%以上の国際会議の論文で，
	      第一著者が日本所属の日本人名の論文 679 件
       \end{itemize} 
       である．
       擬似的に，前者を母語話者文書集合，
       後者を非母語話者文書集合とした．なお，母語話者文書集合／非母語話者
       文書集合における品詞列の出現頻度情報の信頼度がほぼ同一となるよう
       に，両文書集合中の延べ単語数（下記の前処理後の単語数）がほぼ同数
       になるように文書数を設定した．
 \item {\bf データ2}\\
       電気情報関係の国際会議で発表された英語科学技術論文で，
       校正専門家（母語話者）が母語話者性を判定したもの60件（母語話者文
       書 25 件，非母語話者文書 35 件）．これは，\cite{青木}で使用されて
       いる評価用論文と同一のものである．
\end{itemize}

なお，論文の収集に際しては，両文書集合に母語話者／非母語話者以外の
特徴の差が現れないように注意を払った．すなわち，複数の研究分野から
論文を収集し，図表や数式，ヘッダやフッタなどの情報を削除するという
前処理を行った．単語列から品詞列への変換には Tree Tagger\footnote{
http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisonTreeTagger.html
}を用いた．変換後の品詞異なり数は 57 であった（文頭，文末の特殊記号
$@_s$，$@_e$ を除く）．

データ1に付与された母語話者性
（$N$/$N\!N$ の別）
はかなり精度は高いものの，勿論誤りを含む．
そこで，参考としてデータ2をテストデータ（判別対象文書）とした実験（評価実験2）
も行った．データ数が少ないため，各手法に対して有意な差は期待できないが，
データ1での結果と同様の傾向が見られるかどうかを調べた．

各手法の評価は，以下の2つの精度
\begin{align*}
 Prec(N)   &= \frac{母語話者文書で母語話者文書と判別された文書数}
                    {母語話者文書と判別された文書数}\\[4mm]
 Prec(\NN) &= \frac{非母語話者文書で非母語話者文書と判別された文書数}
                    {非母語話者文書と判別された文書数}
\end{align*}
のうち値の低い方（これを MinPrec と表記する）を用いて評価する．
これは，本手法の目的が，母語話者文書および
非母語話者文書をともに高精度で収集することにあるからである．


\subsection{評価実験1}

以下のようにして，各手法の精度をデータ1を用いて10交差検定
(10-fold cross validation)\cite{確率的言語モデルテキスト}
で求める．

\begin{itemize}
 \item[(1)] データ1の母語話者文書集合を $B_1^N, B_2^N, \cdots, B_{10}^N$
	    と10ブロックに分割する．同様にデータ1の非母語話者文書集合
	    を $B_1^\NN, B_2^\NN, \cdots, B_{10}^\NN$ と10ブロックに分割
	    する．
 \item[(2)] 各 $t=1,2,\cdots,10$ に対して，以下を行う．
	    \begin{itemize}
	     \item[(a)] 各 $i=1,2,\cdots,10\,(\neq t)$ に対して，\\
		   $B_t^N,\,B_i^N$ を除く8ブロックの母語話者文書を
		   母語話者言語モデルの学習データ，
		   $B_t^\NN,\,B_i^\NN$ を除く8ブロックの非母語話者文書を
		   非母語話者言語モデルの学習データとして，
		   $(B_i^N,B_i^\NN)$ の各文書の母語話者性を判別し，
		   MinPrec が最大となるメタパラメタの値を求める．
	     \item[(b)] 上記で求めたメタパラメタの値（9個）の平均値をメ
		   タパラメタの値として設定し，
		   $B_t^N$ を除く9ブロックの母語話者文書を
		   母語話者言語モデルの学習データ，
		   $B_t^\NN$ を除く9ブロックの非母語話者文書を
		   非母語話者言語モデルの学習データとして，
		   $(B_t^N,B_t^\NN)$ の各文書の母語話者性を判別する．
	    \end{itemize}
 \item[(3)] 上記(b)で求めた母語話者性判別結果より，精度を求める．
\end{itemize}
なお，各手法におけるメタパラメタは，手法 Hypo1 
と Hypo2 では有意水準 $\alpha$，
手法 Skew では式(\ref{Skew:α})の $\beta$，
手法 KL では式(\ref{式：Sibun加算スムージング})の
加算項 $\delta$ である．上記 (2) の (a) での各 $(B_i^N,B_i^\NN)$ に
対する MinPrec が最大となるメタパラメタの値は，
\begin{align*}
 \alpha &\in \{0.01,\; 0.03,\; 0.05,\; 0.07,\; 0.09,\; 0.11\} 
  \quad\mbox{(Hypo 1, 2)}\\
  \beta &\in \{0.01,\; 0.02,\;\cdots,\;0.15\}
  \quad\mbox{(Skew)}\\
  \delta &\in \{1\times10^{-7},\; 3\times10^{-7},\; 5\times10^{-7},\;
                 1\times10^{-6},\; 3\times10^{-6},\; 
                  \cdots,\; 5\times10^{-4}\}
  \quad\mbox{(KL)}
\end{align*}
の範囲で求めた．


\subsection{評価実験2}

以下のようにして，データ1を学習データ，データ2をテストデータとした場合の
各手法の精度を求める．

\begin{itemize}
 \item[(1)] データ1の母語話者文書集合を $B_1^N, B_2^N, \cdots, B_{10}^N$
	    と10ブロックに分割する．同様にデータ1の非母語話者文書集合
	    を $B_1^\NN, B_2^\NN, \cdots, B_{10}^\NN$ と10ブロックに分割
	    する．
 \item[(2)] 各 $i=1,2,\cdots,10$ に対して，\\
	    $B_i^N$ を除く9ブロックの母語話者文書を
	    母語話者言語モデルの学習データ，
	    $B_i^\NN$ を除く9ブロックの非母語話者文書を
	    非母語話者言語モデルの学習データとして，
	    $(B_i^N,B_i^\NN)$ の各文書の母語話者性を判別し，
	    MinPrec が最大となるメタパラメタの値を求める．
 \item[(3)] 上記で求めたメタパラメタの値（10個）の平均値をメタパラメタの
	    値として設定し，データ1の全母語話者文書を母語話者言語モデル
	    の学習データ，データ1の全非母語話者文書を非母語話者言語モデル
	    の学習データとして，データ2の各文書の母語話者性を判別し，
	    精度を求める．
\end{itemize}
上記(2)での MinPrec が最大となるメタパラメタ値は前節と同様の範囲で求めた．


\subsection{結果と考察}

$n=3,4,5,6,7,8$ なる品詞 $n$-gram を言語モデルとした場合の
2つの評価実験の結果を表\ref{実験結果}に示す．
表には，MinPrec だけでなく，参考のため，Prec(N)，Prec(NN) も挙げている．
また，『未定』の判定になった数を挙げている．
手法 Skew のみ未定があるが，これは，条件部の品詞列の学習データにおける
頻度が高い品詞 $n$-gram 分布が存在し，
用いた計算機の精度では式(\ref{Skew:α})の値が1となり，
その結果 $ED(d\;;\;N)$ も $ED(d\;;\;\NN)$ も$\infty$ となってしまっ
たことによる．

評価実験1では，
各手法とも，$n>3$ で MinPrec が最も高い．
手法 Skew は，$\alpha$ の設定式(\ref{Skew:α})が最適とは限らないことを
述べたが，それでも，$n=5$ の場合は $n=3$ の場合より精度が1\%向上しており，
このことからも，条件部の長い品詞 $n$-gram モデルを言語モ
デルとすることの有効性が分かる．

提案手法では，Hypo2 の $n=7$ の場合の MinPrec が最も高く，
$\mbox{MinPrec}=Prec(N)=552/597\simeq 0.925$ である．一方，
従来手法では，Skew の $n=5$ の場合の MinPrec が最も高く，
$\mbox{MinPrec}=Prec(N)=546/606\simeq 0.901$ である．
2つの二項母集団の母比率の差の検定\cite{統計テキスト2}
を行うと，有意水準
約 8 \% で有意差があることが示せ，AICに基づく2つの二項母集団の母比率
の差の検定\cite{統計テキスト3}
でも有意差が示せる．

2つの提案手法 Hypo1 と Hypo2 の比較では，
同一の $n$ に対する MinPrec は Hypo2 の方が概ね高い．特に，$n=6,7,8$ では
その差は大きく，$n$-gram 確率に関して，
母語話者／非母語話者文書間で有意な差がない場合に，$k<n$ なる $k$-gram 確率
を利用して式(\ref{式：n-gram確率の比})を推定する効果が現れていることが分かる．

評価実験2でも，
各手法とも $n>3$ で MinPrec が最も高く，そのうち，Hypo2 の MinPrec が最
も高い．また，Hypo1 と Hypo2 における同一の $n$ に対する MinPrec は
Hypo2 の方が概ね高い．評価実験2では使用したテスト文書数が少ないため，
信頼性のある結果とは言えないが，このように評価実験1とある程度同様の傾向
が現れていることが分かる．

\begin{table}[t]
\caption{評価実験 1，2 の結果}
\label{実験結果}
\input{02table02.txt}
\end{table}


\section{おわりに}

英文書を品詞列と見なし，品詞 $n$-gram モデルを統計的言語モデルとした
ベイズ識別に基づく母語話者性判別手法を提案した．
提案した手法は，長い品詞列の頻度情報を利用し，仮説検定を
利用して，長い品詞列の頻度情報を使うことによ
る信頼性の低下を防ぐもので，従来手法からの判別精度の改善
が確認できた．

現在，Web 上から科学技術論文を収集し，提案した母語話者性判別システムを用
いて母語話者／非母語話者英語論文コーパスを構築することを検討している．



\acknowledgment
本研究の一部は，科学研究費補助金・基盤研究 B（課題番号 20320082）により行わ
れた．



\bibliographystyle{jnlpbbl_1.3}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Cavnar \BBA\ Trenkle}{Cavnar \BBA\
  Trenkle}{1994}]{cavnar}
Cavnar, W.~B.\BBACOMMA\ \BBA\ Trenkle, J.~M. \BBOP 1994\BBCP.
\newblock \BBOQ {N}-Gram-Based Text Categorization\BBCQ\
\newblock In {\Bem Proceedings of {SDAIR}-94, 3rd Annual Symposium on Document
  Analysis and Information Retrieval}, \mbox{\BPGS\ 161--175}\ Las Vegas, US.

\bibitem[\protect\BCAY{Dunning}{Dunning}{1994}]{dunning}
Dunning, T. \BBOP 1994\BBCP.
\newblock \BBOQ Statistical Identification of Language\BBCQ\
\newblock Techical report\ MCCS-94-273, Computing Research Lab (CRL), New
  Mexico State University.

\bibitem[\protect\BCAY{Lee}{Lee}{1999}]{Lee}
Lee, L. \BBOP 1999\BBCP.
\newblock \BBOQ Measures of Distributional Similarity\BBCQ\
\newblock In {\Bem 37th Annual Meeting of the Association for Computational
  Linguistics}, \mbox{\BPGS\ 25--32}.

\bibitem[\protect\BCAY{Sibun \BBA\ Reynar}{Sibun \BBA\ Reynar}{1996}]{sibun}
Sibun, P.\BBACOMMA\ \BBA\ Reynar, J.~C. \BBOP 1996\BBCP.
\newblock \BBOQ Language Identification: Examining the Issues\BBCQ\
\newblock In {\Bem 5th Symposium on Document Analysis and Information
  Retrieval}, \mbox{\BPGS\ 125--135}\ Las Vegas, Nevada, U.S.A.

\bibitem[\protect\BCAY{Tomokiyo \BBA\ Jones}{Tomokiyo \BBA\
  Jones}{2001}]{Tomokiyo}
Tomokiyo, L.~M.\BBACOMMA\ \BBA\ Jones, R. \BBOP 2001\BBCP.
\newblock \BBOQ You're Not From Round Here, Are You? Naive Bayes Detection of
  Non-native Utterance Text\BBCQ\
\newblock In {\Bem Proceedings of the 2nd Meeting of the North American Chapter
  of the Association for Computational Linguistics (NAACL-01)}, \mbox{\BPGS\
  239--5246}.

\bibitem[\protect\BCAY{青木\JBA 冨浦\JBA 行野\JBA 谷川}{青木\Jetal
  }{2005}]{青木}
青木さやか\JBA 冨浦洋一\JBA 行野顕正\JBA 谷川龍司 \BBOP 2005\BBCP.
\newblock \JBOQ
  言語識別技術を応用した英語における母語話者文書・非母語話者文書の判別\JBCQ\
\newblock \Jem{情報科学技術レターズ，第5巻}, \mbox{\BPGS\ 85--88}.

\bibitem[\protect\BCAY{野田\JBA 宮岡}{野田\JBA 宮岡}{1992}]{統計テキスト}
野田一雄\JBA 宮岡悦良 \BBOP 1992\BBCP.
\newblock \Jem{数理統計学の基礎}.
\newblock 共立出版.

\bibitem[\protect\BCAY{麻生\JBA 津田\JBA 村田}{麻生\Jetal
  }{2003}]{パターン認識テキスト}
麻生英樹\JBA 津田宏治\JBA 村田昇 \BBOP 2003\BBCP.
\newblock \Jem{統計科学のフロンティア 6 パターン認識と学習の統計学}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{鈴木}{鈴木}{1995}]{統計テキスト3}
鈴木義一郎 \BBOP 1995\BBCP.
\newblock \Jem{情報量規準による統計解析入門}.
\newblock 講談社.

\bibitem[\protect\BCAY{北}{北}{1999}]{確率的言語モデルテキスト}
北研二 \BBOP 1999\BBCP.
\newblock \Jem{言語と計算 4 確率的言語モデル}.
\newblock 東京大学出版会.

\bibitem[\protect\BCAY{行野\JBA 田中\JBA 冨浦\JBA 松本}{行野\Jetal
  }{2006}]{行野}
行野顕正\JBA 田中省作\JBA 冨浦洋一\JBA 松本英樹 \BBOP 2006\BBCP.
\newblock \JBOQ 低頻度 byte 列を活用した言語識別\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 47}  (4), \mbox{\BPGS\ 1287--1294}.

\bibitem[\protect\BCAY{藤井\JBA 冨浦\JBA 田中}{藤井\Jetal }{2005}]{藤井}
藤井宏\JBA 冨浦洋一\JBA 田中省作 \BBOP 2005\BBCP.
\newblock \JBOQ Skew Divergence に基づく文書の母語話者性の推定\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (4), \mbox{\BPGS\ 79--96}.

\bibitem[\protect\BCAY{大鹿\JBA 佐藤\JBA 安藤\JBA 山名}{大鹿\Jetal
  }{2005}]{大鹿}
大鹿広憲\JBA 佐藤学\JBA 安藤進\JBA 山名早人 \BBOP 2005\BBCP.
\newblock \JBOQ Google を活用した英作文支援システムの構築\JBCQ\
\newblock In {\Bem Data Engineering Workshop}, \mbox{\BPGS\ 4B--i8}.

\bibitem[\protect\BCAY{竹村}{竹村}{1991}]{統計テキスト2}
竹村彰通 \BBOP 1991\BBCP.
\newblock \Jem{現代数理統計学}.
\newblock 創文社.

    \bibitem[\protect\BCAY{大武\JBA 河本\JBA 竹腰\JBA 国村\JBA Morren\JBA 竹内\JBA
  鵜川\JBA 藤田\JBA 金子}{大武\Jetal }{2004}]{大武}
    大武博\JBA 河本健\JBA 竹腰正隆\JBA 国村正子\JBA Brian Morren\JBA 竹内浩昭\JBA
  鵜川義弘\JBA 藤田信之\JBA 金子周司 \BBOP 2004\BBCP.
\newblock \JBOQ
  インターネット利用による電子英文情報の即時教材化システムの開発とその教育利用
\JBCQ\
\newblock \Jem{情報処理学会研究会報告，FI, No.77}, \mbox{\BPGS\ 23--32}.

\bibitem[\protect\BCAY{佐野\JBA 猪野}{佐野\JBA 猪野}{2000}]{佐野}
佐野洋\JBA 猪野真理枝 \BBOP 2000\BBCP.
\newblock \JBOQ 英語文法の難易度計測と自動分析\JBCQ\
\newblock \Jem{情報処理学会研究会報告，CE, No.58}, \mbox{\BPGS\ 5--12}.

\bibitem[\protect\BCAY{前田\JBA 関\JBA 吉川\JBA 植村}{前田\Jetal }{2001}]{前田}
前田亮\JBA 関慶妍\JBA 吉川正俊\JBA 植村俊亮 \BBOP 2001\BBCP.
\newblock \JBOQ Web文書の符号系および使用言語の自動識別\JBCQ\
\newblock \Jem{電子情報通信学会論文誌}, {\Bbf J84-D-II}  (1), \mbox{\BPGS\
  150--158}.

\end{thebibliography}

\appendix


\section{2つの二項母集団の母比率の比の検定}

標本 $\vX$ の統計モデル
を $\{P(\cdot \:;\:\theta)\:|\:\theta\in\Theta\}$ とし
（$\Theta$ はパラメタ空間），
$\Theta_0$ と $\Theta_1$ を $\Theta_0\cap\Theta_1=\emptyset$，
$\Theta_0\cup\Theta_1=\Theta$ なる $\Theta$ の部分集合とする．
$\theta\in\Theta_0$ は帰無仮説，$\theta\in\Theta_1$ は対立仮説と呼ばれる．
標本 $\vX$ の値（観測値）$\vx$ を基に $\theta\in\Theta_0$ か 
$\theta\in\Theta_1$ かを決定することを
統計的仮説検定という（詳しくは，たとえば，文献\cite{統計テキスト}を参照）．
標本 $\vX$ の統計量 $T(\vX)$ を用いて
$T(\vx)\geq t$ のとき帰無仮説を棄却する検定を考える．
与えられた $\Theta_0$ と $\alpha$ に依存させて $t$ を
\begin{equation}\label{式：有意水準αの検定}
 \forall \theta \in \Theta_0 \; P(T(\vX) \geq t \:;\: \theta) \leq \alpha
\end{equation}
を満たすように設定すると，この検定は，
有意水準 $\alpha$ の検定（帰無仮説が正しいにもかかわらず帰無仮説を棄却し
てしまう確率が $\alpha$ 以下である検定）となる．


確率変数 $X$ が二項分布 $B(m,p)$\footnote{
$X$ の確率関数 $f_X(x)$ が以下で与えられる分布である．
\[
 f_X(x)=
   \begin{cases}
   _mC_x\: p^x(1-p)^{m-x} &\ ; x=0,1,2,\cdots,m,\\
   0 &\ ; その他
   \end{cases}
\]
}
に従い，確率変数 $Y$ が二項分布 $B(n,q)$ に従うとし，
$x/m>y/n$ である場合に，
$(X,Y)$ の観測値 $(x,y)$ を基に $p/q>\mu$ であるか否かの判定
を行いたい．
このような判定を行う検定は，著者の知る限りでは，確率・統計のテキストなどでは
解説されていない．
望ましい性質を持つことで知られる尤度比検定を行うことも考えられるが，
$m$，$n$ が大きくなった場合，棄却判定の計算に
時間を要する．したがって，尤度比検定を用いた場合，現実的な時間内で
一つの文書の母語話者性の判別ができないことがある．

そこで，本研究では，このような判定を高速に行う近似的な検定手法を新たに考
案し，これを母語話者性の判別に利用する．一様最強力検定や第2種の誤り（帰
無仮説が正しくないにもかかわらず帰無仮説を採択してしまう）確
率が本手法より小さな検定で高速なものが求まるならば，これらの検定を利用す
ることで母語話者性の判別の精度はより向上すると考えられる．

帰無仮説と対立仮説を以下のように設定した検定を考える．
\begin{align*}
 帰無仮説 &: 
   (p,q)\in \Theta_0 
        = \{(p,q) \:|\: p \leq \mu q, \; 
                                   0\leq p \leq 1, \; 0\leq q \leq 1 \}\\
 対立仮説 &: 
   (p,q)\in \Theta_1 
        = \{(p,q) \:|\: p > \mu q, \; 
                                   0\leq p \leq 1, \; 0\leq q \leq 1 \}
\end{align*}
本論文では母比率の比の検定と呼ぶ．本質的には，
$p\leq \mu q$ であるか否かであるが，ここでは上記のように正確に両仮説を記
述しておく．帰無仮説が
棄却されるならば，$p/q>\mu$ と判定したことになる．
対立仮説が正しい場合に，その観測値が大きな値となる傾向を持つ
統計量$T^\dagger(X,Y)$
\[
 T^\dagger(X,Y)=\frac{X/m}{(Y+1)/(n+1)}
\]
を用いて，$T^\dagger(x,y)\geq t^\dagger(\mu)$ のとき帰無仮説を棄却するこ
とにする．
分母の `$+1$' は $Y$ の観測値が 0 の場合でも $T^\dagger$ が定義できる
ように導入したものである．
式(\ref{式：有意水準αの検定}) より，
$t^\dagger(\mu)$ は
\begin{equation}\label{式：検定基礎}
\forall (p,q)\in \Theta_0\;\;
 P(T^\dagger(X,Y)\geq t^\dagger(\mu) \:;\: p,q) \leq \alpha
\end{equation}
を満たすように，$\mu$ と有意水準 $\alpha$ に応じて設定される．

本手法では，$t^\dagger(\mu)$ を求めて帰無仮説の棄却判定を行う代わりに，
観測値 $(x,y)$ の $p$-値を用いて棄却判定を行う．
$(x,y)$ の $p$-値とは，$(x,y)$ を基に帰無仮説を棄却できる最小の有意水準のこ
とである．明らかに，$P(T^\dagger(X,Y)\geq t \:;\: p, q)$ は $t$ の減少関数であ
り，$T^\dagger(x,y)\geq t^\dagger(\mu)$ のとき帰無仮説を棄却するのであるから，
$(x,y)$ の $p$-値は以下で与えられ，
\begin{equation}\label{式：p-値1}
\max_{(p,q) \in \Theta_0}\; P(T^\dagger(X,Y)\geq T^\dagger(x,y) \:;\: p, q)
\end{equation}
この値が $\alpha$ 以下である場合に，有意水準 $\alpha$ で帰無
仮説を棄却することになる．ここで新たに
\[
T(X,Y)=\frac{X}{Y+1}
\]
と定義すると，式(\ref{式：p-値1})は，以下と等しい．
\begin{equation}\label{式：p-値2}
\max_{(p,q)\in \Theta_0}\; P(T(X,Y)\geq T(x,y) \:;\: p, q).
\end{equation}

$Y$ が $B(n,q)$ に従うとき，
$0\leq y_0 <n$ なる任意の $y_0$ に対して
$P(Y\leq y_0 \:;\: q)$ は $q$ の単調減少関数であり，
$y_0 <0$ なる任意の $y_0$ に対して $P(Y\leq y_0 \:;\: q)=0$ であり，
$y_0 \geq n$ なる任意の $y_0$ に対して $P(Y\leq y_0 \:;\: q)=1$ である．
この性質と，$0<x,\;y<n$（∵ 前提 $x/m>y/n$），および，
\[
P(T(X,Y)\geq T(x,y)\:;\: p,q)
= \sum_{x'=0}^m \: 
     \rule{0pt}{1pt}_mC_{x'} p^{x'}(1-p)^{m-x'}\cdot 
        P\left(\frac{x'}{Y+1}\geq T(x,y) \:;\: q \right)
\]
と表すことができることから，
$(x,y)$ の $p$-値である式(\ref{式：p-値2})は，
\begin{equation}\label{式：p-値3}
\max_{(p,q)\in \Theta_0'}\; P(T(X,Y)\geq T(x,y) \:;\: p, q)
\end{equation}
と等しい．ただし，
$ \Theta_0' = \{(p,q)\:|\: p=\mu q,\; 0\leq p\leq 1,\; 0\leq q\leq 1 \}$
である．



観測値 $(x,y)$ に基づいた，$(p,q)\in \Theta_0'$ の下での $p$，
$q$ の最尤推定値（つまり，$(x,y)$ の生起確率を最大にする $p$，$q$
の値）を $p^*(\mu)$，$q^*(\mu)$ で表すと，
\begin{align*}
p^*(\mu) &=\mu\cdot q^*(\mu)\\
q^*(\mu) &=
 \frac{x+\mu y + \mu m + n 
  - \sqrt{(x+\mu y + \mu m + n)^2-4(x+y)(m+n)\mu}}{2(m+n)\mu}
\end{align*}
である．
本手法では，検定に要する時間を考慮し，式(\ref{式：p-値3})を
$P(T(X,Y)\geq T(x,y) \:;\: p^*(\mu),q^*(\mu))$ で近似し，
\[
 P(T(X,Y)\geq T(x,y) \:;\: p^*(\mu),q^*(\mu))\leq\alpha
\]
ならば帰無仮説を棄却する．

二項分布 $B(m,p)$ に従う確率変数の分布関数は，
$mp>5$ かつ $m(1-p)>5$ の場合，正規分布で近似できる．そこで，
$P(T(X,Y)\geq T(x,y) \:;\: p^*(\mu),q^*(\mu))\leq\alpha$ の
判定に必要な $P(T(X,Y)\geq t \:;\: p,q)$ の計算は，
$X$，$Y$ の分布を正規分布で近似できるか否かにより，4つの
場合に分けて行った．$X$，$Y$ 共に正規分布で近似できる場合と，
$X$ のみ正規分布で近似できる場合の計算をそれぞれ以下の(1)(2)に示す．
以下に示すとおり，正規分布の性質を利用して高速な計算が可能である．


\medskip
\noindent
\underline{\mbox{(1) $5<m p<m-5$ かつ $5<n q<n-5$ の場合}}
\[
 P\left(T(X,Y)\geq t\:;\: p, q\right)
 = P(X-tY\geq t\:;\: p,q)
\]
である．$X$ の分布は正規分布 $N(m p, m p(1-p))$ で近似でき\footnote{
平均が $\xi$，分散が $\sigma^2$ の正規分布を $N(\xi,\sigma^2)$ で
表す．
}，
$Y$ の分布は $N(n q, n q(1-q))$ で近似できるので，
正規分布の性質より，
\[
 P(T(X,Y) \geq t\:;\: p,q) 
  = P\left(Z\geq \frac{t-mp+tnq}{\sqrt{mp(1-p)+t^2nq(1-q)}}\right)
\]
である．ただし，$Z$ は標準正規分布に従う確率変数である．

\medskip

\noindent
\underline{\mbox{(2) $5<m p<m-5$ かつ [$n q\leq 5$ または $n-5\leq n q$] の
場合}}
\[
P\left(T(X,Y)\geq t\:;\: p,q\right)
 = \sum_{y'=0}^n P(Y=y'\:;\: q)\cdot P(X\geq t(y'+1)\:;\: p)
\]
である．$X$ の分布は正規分布 $N(mp,mp(1-p))$ で近似できるので，
\[
P\left(T(X,Y)\geq t\:;\: p,q\right)
= \sum_{y'=0}^n \:\rule{0pt}{1pt}_nC_{y'}\: {q}^{y'}(1-q)^{n-y'}\cdot 
       P\left(Z\geq \frac{t(y'+1)-mp}{\sqrt{mp(1-p)}}\right).
\]
である．ただし，$Z$ は標準正規分布に従う確率変数である．


\section{仮説検定を利用した母比率の比の推定}
\label{付録：estimateMu}

$X$ を二項分布 $B(m,p)$ に従う確率変数，$x$ をその観測値，
$Y$ を二項分布 $B(n,q)$ に従う確率変数，$y$ をその観測値とする
（勿論，$p$，$q$ は未知である）．
$x/m > y/n$ を前提として，前節の仮説検定で，帰無仮説を棄却できる最大の
$\mu$，つまり，
\begin{equation}
 P(T(X,Y)\geq T(x,y)\;;\;
    p^*(\widehat{\mu}(x,m,y,n)),q^*(\widehat{\mu}(x,m,y,n))) =\alpha
\end{equation}
なる $\widehat{\mu}(x,m,y,n)$ を以下のようにして求める．
\[
 pv(\mu\:;\:x,y)=P(T(X,Y)\geq T(x,y)\:;\:p^*(\mu),q^*(\mu))
\]
とおき，$pv(\mu\:;\:x,y)$ が $\mu$ の
増加関数になっていることを利用して\footnote{
$p^*(\mu)$ は $\mu$ の増加関数，$q^*(\mu)$ は $\mu$ の減少関数
になっていることが示せる．\\このことから，
$P(T(X,Y)\geq T(x,y)\;;\; p^*(\mu),q^*(\mu))$ が $\mu$ の増加関数になっている
ことが示せる．
}，2分法により求める．

\begin{itemize}
\item[(1)] $\mu_L=1$ とし，$pv(\mu_L\;;\; x,y)<\alpha$
           となるまで，$\mu_L\leftarrow \mu_L/2$ を繰り返す．\\
           $\mu_R=1$ とし，$pv(\mu_R\;;\; x,y)>\alpha$
           となるまで，$\mu_R\leftarrow 2\cdot\mu_R$ を繰り返す．
\item[(2)] $\mu_R-\mu_L$ が十分小さくなるか，
           $pv((\mu_L+\mu_R)/2\;;\;x,y)=\alpha$ となる
           まで以下を繰り返す．
           \begin{itemize}
           \item $\mu_C\leftarrow(\mu_L+\mu_R)/2$
           \item $\{pv(\mu_L\;;\;x,y)-\alpha\}$
                 と $\{pv(\mu_C\;;\;x,y)-\alpha\}$
                 が同符号ならば，$\mu_L\leftarrow\mu_C$ とし，
		 そうでないならば，$\mu_R\leftarrow\mu_C$ とする．
           \end{itemize}
\item[(3)] $(\mu_L+\mu_R)/2$ が $\widehat{\mu}(x,m,y,n)$ である．
\end{itemize}

最後に，前節で述べた $T^\dagger(X,Y)$ による $p/q$ の
信頼区間を文献\cite{統計テキスト}に従って求め，
$(\widehat{\mu}(x,m,y,n),\infty)$ が
近似的に $p/q$ の $100(1-\alpha)\%$ 信頼区間になっている
ことを述べ，シミュレーションによりこれを確かめる．

標本 $\vX$ の統計モデルを $\{P(\cdot\:;\: \theta)\:|\:\theta\in\Theta\}$ と
し，$S(\vx)$ を $\Theta$ の部分集合とする．
\[
 \forall \theta\in\Theta\;\; P(\theta\in S(\vX) \:;\: \theta)\geq 1-\alpha
\]
となるとき，$S(\vX)$ を $\theta$ の $100(1-\alpha)\%$ 信頼領域
（$S(\vX)$ が区間になる場合は信頼区間）と言う．
$p/q$ はパラメタではないが，この定義に当てはめるならば，
統計量 $L(X,Y)$ が
\begin{equation}\label{式：信頼区間定義式}
 \forall (p,q)\in[0,1]^2 \;\; P(L(X,Y)<p/q \:;\: p,q)\geq 1-\alpha
\end{equation}
を満たすならば，$(L(X,Y),\infty)$ は $p/q$ の $100(1-\alpha)\%$ 信頼区間
である．これは，$(X,Y)$ の観測値を 100 個得たとき，
$L(x,y)<p/q$ を満たす観測値 $(x,y)$ が $100(1-\alpha)$
個程度以上あることを意味している．
観測値 $(x,y)$ に対する $L(x,y)$ は，
\[
 L(x,y)=\max\{\mu\:|\: T^\dagger(x,y)\geq t^\dagger(\mu)\}
\]
で求めることができる．以下にこれを示す．
上記定義より，$(p_0,q_0)$ を任意に選んだとき，
\[
 L(x,y)<p_0/q_0 \Longleftrightarrow T^\dagger(x,y)<t^\dagger(p_0/q_0)
\]
が成立する．したがって，
\begin{align*}
 P(L(X,Y)<p_0/q_0 \:;\: p_0,q_0)
  &= P(T^\dagger(X,Y)<t^\dagger(p_0/q_0)\:;\: p_0,q_0)\\
  &= 1-P(T^\dagger(X,Y)\geq t^\dagger(p_0/q_0)\:;\: p_0,q_0)\\ 
  &\geq 1-\alpha \quad
    (\mbox{∵ $p_0\leq (p_0/q_0)q_0$ と式(\ref{式：検定基礎})})
\end{align*}
$p_0$，$q_0$ は任意に選んだので，$L(X,Y)$ は式(\ref{式：信頼区間定義式})
を満たすことが分かる．
$L(x,y)$ の定義より，$L(x,y)$ は帰無仮説($p \leq\mu q$) を棄却できる
最大の $\mu$ である．前節で述べた検定は，
$p$-値(\ref{式：p-値3})（つまり $p$-値(\ref{式：p-値1})）を $P(T(X,Y)\geq T(x,y)\:;\: p^*(\mu),q^*(\mu))$ で
近似しているため，$\widehat{\mu}(x,m,y,n)$ は $L(x,y)$ の近似と
考えられる．

$\widehat{\mu}(x,m,y,n)$ が $L(x,y)$ の近似となっていることを確かめる
ために，シミュレーションを行った．
有意水準 $\alpha$ を 0.05 とし，
いくつかの $m$，$p$，$n$，$q$ に対して，$B(m,p)$ および $B(n,q)$ に従って
$(x,y)$ を $10,000$ 個発生させ，$x/m \neq y/n$ なる各 $(x,y)$ に対し，
\begin{itemize}
\item $x/m > y/n$ のとき，$\widehat{\mu}(x,m,y,n)<p/q$ ならば成功，
      $\widehat{\mu}(x,m,y,n)\geq p/q$ ならば失敗，
\item $x/m < y/n$ のとき，$p/q<1/\widehat{\mu}(y,n,x,m)$ ならば成功
      $p/q\geq 1/\widehat{\mu}(y,n,x,m)$ ならば失敗
\end{itemize}
とし，求めた信頼区間に $p/q$ が含まれる割合を求めた．
結果を表\ref{表：estimateMu}に示す．
この表から，近似の影響はあるものの，
$\widehat{\mu}(x,m,y,n)<p/q$ あるいは $p/q<1/\widehat{\mu}(y,n,x,m)$ が
ほぼ $100(1-\alpha)\%$ の割合で成立していることが分かる．

\clearpage
\begin{table}[t]
\caption{ $p/q$ の信頼区間の推定の成功率}
\label{表：estimateMu}
\input{02table03.txt}
\end{table}



\begin{biography}
\bioauthor{冨浦　洋一}{
1984年九州大学工学部電子工学科卒業，
1989年同大学院工学研究科電子工学専攻博士課程単位取得退学．
同年九州大学工学部助手，1995年同助教授，現在，九州大学大学院
システム情報科学研究院准教授．博士（工学）．自然言語処理，
計算言語学に関する研究に従事．
}
\bioauthor{青木さやか}{
2006年九州大学工学部電気情報工学科卒業，
2008年同大学院システム情報科学府知能システム学専攻修了，
現在，新日鉄ソリューションズ（株）に勤務．自然言語処理に関する研究に従事．
}
\bioauthor{柴田　雅博}{
1996年九州大学工学部情報工学科卒業，
2005年同大学院システム情報科学研究科知能システム学専攻博士課程単位取得退学．
同年九州システム情報技術研究所特別研究助手，
2006年九州大学ベンチャー・ビジネス・ラボラトリー講師（中核的研究機関
研究員），現在，九州大学大学院システム情報科学研究院テクニカルスタッフ．
博士（工学）．自然言語処理に関する研究に従事．
}
\bioauthor{行野　顕正}{
2001年九州大学工学部電気情報工学科卒業，
2007年同大学院システム情報科学府知能システム学専攻博士課程修了，
現在，株式会社ジャストシステムに勤務．
博士（工学）．自然言語処理に関する研究に従事．
}
\end{biography}


\biodate




\end{document}
