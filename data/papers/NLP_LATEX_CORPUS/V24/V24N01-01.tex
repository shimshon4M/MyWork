    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvipdfm]{graphicx}
\usepackage{amsmath}
\usepackage{hangcaption_jnlp}


\Volume{24}
\Number{1}
\Month{February}
\Year{2017}

\received{2016}{5}{20}
\revised{2016}{8}{5}
\accepted{2016}{9}{15}

\setcounter{page}{3}

\jtitle{音声対話ロボットのための傾聴システムの開発}
\jauthor{下岡　和也\affiref{tytlabs} \and 徳久　良子\affiref{tytlabs} \and 吉村　貴克\affiref{tytlabs} \and 星野　博之\affiref{tytlabs} \and 渡部　生聖\affiref{toyota}}
\jabstract{
高齢者の認知症や孤独感の軽減に貢献できる対話ロボット開発のため，回想法に基づく傾聴を行う音声対話システムの開発を行った．本システムは，ユーザ発話の音声認識結果に基づき，相槌をうったり，ユーザ発話を繰り返したり，ユーザ発話中の述語の不足格を尋ねたりする応答を生成する．さらに，感情推定結果に基づき，ユーザ発話に対して共感する応答を生成する．本システムの特徴は，音声認識結果に誤りが含まれることを前提とし，音声認識信頼度を考慮して応答を生成する点である．110 名の一般被験者に対する評価実験の結果，「印象深い旅行」を話題とした場合で，45.5\% の被験者が 2 分以上対話を継続できた．また，システムの応答を主観的に評価した結果，約 77\% のユーザ発話に対して対話を破綻させることなく応答生成ができた．さらに，被験者へのアンケートの結果，特に高齢の被験者から肯定的な主観評価結果が得られた．
}
\jkeywords{音声対話ロボット，傾聴，回想法，高齢者}

\etitle{Active Listening System for a Conversation Robot}
\eauthor{Kazuya Shitaoka\affiref{tytlabs} \and Ryoko Tokuhisa\affiref{tytlabs} \and Takayoshi Yoshimura\affiref{tytlabs} \and Hiroyuki Hoshino\affiref{tytlabs} \and Narimasa Watanabe\affiref{toyota}} 
\eabstract{
We have developed an active listening system for a conversation robot, specifically for reminiscing. The aim of the system is to contribute to the prevention of dementia in elderly persons and to reduce loneliness in seniors living alone. Based on the speech recognition results from a user's utterance, the proposed system produces back-channel feedback, repeats the user's utterance and asks information about predicates that were not included in the original utterance. Moreover, the system produces an appropriate empathic response by estimating the user's emotion from their utterances. One of the features of our system is that it can determine an appropriate response even if the speech recognition results contain some errors. Our results show that the conversations of 45.5\% of the subjects (n = 110) with this robot continued for more than two minutes on the topic ``memorable trip''. The system response was deemed correct for about 77\% of user utterances. Based on the results of a questionnaire, positive evaluations of the system were given by the elderly subjects.
}
\ekeywords{Dialogue Robot, Active Listening, Reminiscence Therapy, Elderly Person}

\headauthor{下岡，徳久，吉村，星野，渡部}
\headtitle{音声対話ロボットのための傾聴システムの開発}

\affilabel{tytlabs}{（株）豊田中央研究所}{Toyota Central R\&D Labs. INC}
\affilabel{toyota}{トヨタ自動車株式会社}{Toyota Motor Corporation}



\begin{document}
\maketitle


\section{はじめに}

日本は，2007年に高齢化率が21.5\%となり「超高齢社会」になった\cite{no1}．世界的に見ても，高齢者人口は今後も増加すると予想されており，認知症治療や独居高齢者の孤独死が大きな問題となっている．また，若い世代においても，学校でのいじめや会社でのストレスなどにより精神状態を崩すといった問題が起きている．このような問題を防ぐ手段として，カウンセリングや傾聴が有効であると言われている\cite{no2}．しかし，高齢者の介護職は人手不足であり，また，家庭内においても，身近に，かつ，気軽に傾聴してもらえる人がいるとは限らない．

このような背景のもと，本論文では，音声対話ロボットのための傾聴対話システムを提案する．我々は，介護施設や病院，あるいは，家庭に存在する音声対話ロボットが傾聴機能を有することにより，上記の問題の解決に貢献できると考えている． 

傾聴とは，話を聴いていることを伝え，相手の気持ちになって共感を示しつつ，より多くのことを話せるように支援する行為であり，聴き手は，表1に挙げる話し方をすることが重要であるとされる\cite{no3,no4,no5}．また，傾聴行為の一つとして回想法が普及している．回想法とは，アメリカの精神科医Butlerによって1963年に提唱されたものであり\cite{no6}，過去の思い出に，受容的共感的に聞き入ることで高齢者が自分自身の人生を再評価し，心理的な安定や記憶力の改善をはかるための心理療法である\cite{no7}．本論文は，この回想法による傾聴を行う音声対話システムの実現を目指す．

\begin{table}[b]
\caption{傾聴において重要とされる話し方}
\label{table:1}
\input{01table01.txt}
\end{table}

音声対話システムとして，音声認識率の向上やスマートフォンの普及などを背景に，AppleのSiri \cite{no8} やYahoo!の音声アシスト\cite{no9}，NTTドコモのしゃべってコンシェル\cite{no10}といった様々な音声アプリケーションが登場し，一般のユーザにも身近なものになってきた．単語単位の音声入力や一問一答型の音声対話によって情報検索を行うタスク指向型対話システムに関しては，ある一定の性能に達したと考えられる\cite{no11}．しかしながら，これらの音声対話システムは，音声認識率を高く保つために，ユーザが話す内容や発声の仕方（単語に区切るなど）を制限している．

一方で，雑談対話のような達成すべきタスクを設定しない非タスク指向型対話システムも多く提案されており(Tokuhisa, Inui, and Matsumoto 2008; Banchs and Li 2012; Higashinaka, \linebreak
Imamura, Meguro, Miyazaki, Kobayashi, Sugiyama, Hirano, Makino, and Matsuo 2014; \linebreak
Higashinaka, Funakoshi, Araki, Tsukahara, Kobayashi, and Mizukami 2015)\nocite{no12,no13,no14,no15}，傾聴対話システムも提案されている．

傾聴対話システムの先行研究として，Hanらの研究\cite{no16,no17}，および，大竹らの研究がある\cite{no18,no19}．これらの研究は，いずれも対話システムによる傾聴の実現を目的としており，5W1H型の疑問文による問い返し（e.g., Usr: とっても美味しかったよ．⇒　Sys: 何が美味しかったの？）や，固有名詞に関する知識ベースに基づく問い返し (e.g., Usr: I Like Messi.　⇒　Sys: What is Messi's Position?)，あるいは，評価表現辞書を用いた印象推定法による共感応答（e.g., Usr: 寒いしあまり炬燵から出たくないね．⇒　Sys: 炬燵は暖かいよね．）などの生成手法が提案されている． Hanら，大竹らの研究は傾聴対話システムの実現を目的としている点において，我々と同様である．しかしながら，これらの研究はテキスト入力を前提としているため，音声入力による対話システムへ適用する際には，音声認識誤りへの対応という課題が残る．

傾聴のような聞き役対話システムの先行研究としては，目黒らの研究がある\cite{no20,no21,no22}．この研究では，人同士の聞き役対話と雑談を収集し，それぞれの対話における対話行為の頻度を比較・分析し，さらに，聞き役対話の流れをユーザ満足度に基づいて制御する手法を提案している．ただし，この研究の目的は，人と同様の対話制御の実現であり，また，カウンセリングの側面を持つ傾聴ではなく，日常会話においてユーザが話しやすいシステムの実現を目指している点で，我々と異なる．

また，山本，横山，小林らの研究\cite{no23,no24,no25,no26,no27}は，対話相手の画像や音声から会話への関心度を推定し，関心度が低い場合は話題提示に，関心度が高い場合は傾聴に切り替えることで雑談を継続させる．発話間の共起性を用いて，音声の誤認識による不適切な応答を低減する工夫も導入している．さらに，病院のスタッフと患者間の対話から対話モデル（隣接ペア）を用いた病院での実証実験を行っており，ロボットとの対話の一定の有効性を示している．しかしながら，傾聴時において生成される応答は「単純相槌」「反復相槌」「質問」の3種類であり，ユーザ発話中のキーワードを抽出して生成されるため，ユーザ発話中に感情表現がない場合に（e.g., Usr: 混雑していたよ），傾聴において重要とされる「共感応答」（e.g., Sys: それは残念でしたね）は扱っていない．

同様に，戦場の兵士らの心のケアを目的とした傾聴対話システムSimCoachや，意思決定のサポートをするSimSenseiという対話システムも構築されている\cite{no28,no29}．SimCoachやSimSenseiはCGによるAgent対話システムで，発話内容に合わせた豊かな表情や頷きを表現することで，人間とのより自然な対話を実現している点も特徴である．

我々は，対話システムの機能を，回想法をベースとした傾聴に特化することにより，音声認識や応答生成のアルゴリズムをシンプル化し，対話が破綻することなく継続し，高齢者から若者まで満足感を感じさせるシステムの実現を目指す．Yamaguchiら，Kawaharaらは，傾聴対話システムがユーザ発話に対して傾聴に適した相槌を生成する手法とその有効性について報告している\cite{no30,no34}．具体的には，人同士の傾聴時の対話で生じる相槌を対象として相槌が持つ先行発話との関係を分析し，それに基づいて相槌生成の形態，韻律を決定する手法を検討した．結果として，先行発話の境界のタイプや構文の複雑さに応じて相槌を変えることや，先行発話の韻律的特徴と同調するように韻律的特徴を制御することの有効性を述べている．相槌の生成ではタイミング，形態，韻律が重要であるが，今回のシステムでは，適切な内容の応答生成による対話の継続と満足感の評価を目的としている．

本論文の貢献は，音声認識誤りを考慮した上で，傾聴時に重要な応答の生成を可能にする手法の提案，および，提案手法が実装されたシステムの有効性を，応答正解率の観点と，100人規模の被験者実験による対話継続時間と主観評価による満足度の観点で評価した点である．本論文の構成は，次のようになっている．第2章で本傾聴対話システムの概要を述べる．第3, 4, 5章は，本対話システムの機能である音声認識，および，認識信頼度判定部，問い返し応答生成部，共感応答生成部に関する実装に関して，第6章で評価実験と結果について説明し，第7章でまとめる．


\section{傾聴システムの概要}

本章では，提案する傾聴システムの概要について述べる．
 
\subsection{目指す対話例}

図\ref{fig:1}に，回想法の実施事例を示す\cite{no32}．聞き手(S)は，話し手(A)が自身の過去を思い出しやすいように「問い返し」を重ね，それに対して話し手が答える，というスタイルがベースとなって対話が進行している．また，聞き手は，適切なタイミングで，「言い換え」「要約」「相槌」「共感」「繰り返し」といった，傾聴に重要とされる応答を行っていることが分かる．我々は，図1に示すような回想法による傾聴対話を実現するため，対話のテーマを「過去の出来事」に設定し，ユーザが語る過去の行動や感情に対して，音声認識誤りを考慮した上で，システムが傾聴に重要とされる応答を生成するための手法を提案する．

\begin{figure}[t]
\begin{center}
\includegraphics{24-1ia1f1.eps}
\end{center}
\caption{回想法の実施例（須田2013より抜粋）}
\label{fig:1}
\end{figure}

なお，本論文では，上記の応答のうち，「繰り返し」「問い返し」「共感」「相槌」の4種類の応答を対象とする．なぜなら，「言い換え」および「要約」については「繰り返し」により粗い近似が可能である，と考えたためである．次節では，このような対話を実現するための傾聴システムの機能構成について述べる．

\subsection{傾聴システムの機能構成}

提案する傾聴システムの機能構成を図2に示す．大きく分けて，「音声認識・信頼度判定」「繰り返し／問い返し応答の生成」「共感応答の生成」「相槌応答の生成」「応答選択」の5つの機能で構成されている．以下で，それぞれの機能の概要を述べる．


\noindent\textbf{■　音声認識・信頼度判定}

入力されたユーザ発話を音声認識し，音声認識結果の信頼度を算出する．認識結果が信頼できると判定された場合は，当該認識結果を用いて，繰り返し／問い返し応答，および，共感応答を生成する．一方，信頼できないと判定された場合には，当該認識結果を用いた応答を行うのではなく，予め用意された相槌応答を生成する．これにより，誤認識結果を用いた応答生成を低減し，対話の破綻を防ぐ．詳細は3章で述べる．

\clearpage
\noindent\textbf{■　繰り返し／問い返し応答の生成}

ユーザ発話の最終述語に着目し，認識信頼度が高いと判定された当該述語，および，当該述語が持つ格に基づき，繰り返し／問い返し応答を生成する．ここで，本論文では，以下のものを「述語」と定義し，ユーザ発話に含まれるこれら全ての表現のうち，最後に出現するものを「最終述語」として抽出する．

\begin{figure}[b]
\vspace{-1\Cvs}
\begin{center}
\includegraphics{24-1ia1f2.eps}
\end{center}
\caption{傾聴システムの機能構成}
\label{fig:2}
\vspace{1\Cvs}
\end{figure}
\begin{table}[b]
\caption{本論文で定義する「述語」の候補となる語}
\label{table:2}
\input{01table02.txt}
\end{table}
\begin{table}[b]
\caption{本論文で扱う過去表現}
\label{table:3}
\input{01table03.txt}
\end{table}

  \begin{enumerate}
   \item 表2に示す語のうち，表3に示す過去表現を伴っているもの．
   \item ただし，表2に示す語と，表3に示す過去表現との間にアスペクト（〜していた，〜しに行った），ムード（〜したかった，〜しなかった），ヴォイス（〜してもらった，〜された）などの表現が含まれる場合には，それらも含む．
   \end{enumerate}

過去表現を伴うものに限定するのは，2.1節でも述べたように，本論文では，対話のテーマを「過去の出来事」に設定するためである．また，アスペクトやムードなどを考慮することにより，より自然なシステム応答の生成（e.g., Usr: もっと食べたかったよ．　Sys: 食べたかったんですか．）を可能にする．

問い返し応答は，以下で述べる(A), (B)の手法により生成する．これら2つの手法により，音声認識の信頼度が高い場合のみ，繰り返し応答や問い返し応答を生成することで，ユーザの発話内容を正確に繰り返し「聴いている」ことを示すと同時に，ユーザの過去を思い出しやすくし，次の発話を促す．


\noindent\textbf{(A)最終述語の不足格判別に基づく問い返し}

ユーザ発話の最終述語が動詞，および，「サ変名詞＋する」の場合に，当該述語に対する不足格の判別を行うことにより，ユーザ発話には含まれない格を問い返す応答を生成する．図2の例では，ユーザ発話の最終述語「貰う」について，あらかじめ作成した動詞の必須格辞書を用いて，発話に必須格「誰から」が含まれていないことを判別し，『誰からもらったんですか？』を生成する．不足格判別に基づく問い返し応答の生成の詳細は4.1節で述べる． 


\noindent\textbf{(B)辞書を用いた適切性判断に基づく問い返し}

ユーザ発話の最終述語，および，格要素について，表4に示す問い返しが適切かどうかを辞書に基づき判断し，応答を生成する．図2の例では，最終述語「貰う」に対する感想，および，格要素「お花」の詳細については，問い返すことが適切であると判断され，『どうでしたか？』，および，『どんなお花ですか？』が生成されている．辞書を用いた適切性判断に基づく問い返しの詳細については4.2節で述べる．

\begin{table}[b]
\caption{辞書を用いた適切性判断に基づき生成される問い返しの種類}
\label{table:4}
\input{01table04.txt}
\end{table}

\noindent\textbf{■　共感応答の生成}

感情推定に関しては様々な研究がある\cite{no33}．Balahurらは感情が非明示的に表現された文から感情を推定することを目的として，感情生起のトリガーとなる事態を記述したEmotiNetの構築を提案している\cite{no31}．また，長谷川らは，聞き手にターゲットとなる感情を生起させるための応答生成手法を考案している\cite{no35}．この中で長谷川らは，Twitterから構築した感情タグ付き対話コーパスを利用することで，「一緒に夕食に行かない？」という入力に対して「38度の熱があるのでいけません」と応答し，聞き手に「悲しみ」を喚起するような応答生成を実現している．

これに対して我々は，話し手であるユーザの発話内容に対するユーザ自身の感情を推定し，その結果を利用することにより，ユーザへの共感応答を生成する．図2の例では，「誕生日にお花を貰う」に対するユーザ自身の感情が「嬉しい」であると推定した結果，共感応答『それは嬉しいですね』が生成されている．本論文では，この例のように，ユーザ発話中に明示的な感情表現（e.g., 嬉しい）が含まれていない場合であっても，音声認識誤りが含まれるユーザ発話からデータ駆動型で感情推定を行い，共感応答を生成する．詳細は5章で述べる．
            

\noindent\textbf{■　相槌応答の生成}

認識信頼度が低いと判定された場合は，相槌応答を生成する．ここでは，相槌応答として，以下の2種類を生成する．

\begin{enumerate}
 \item システムの直前発話として，「感情・形容表現に対する理由を尋ねる」問い返し応答が生成されていた場合は，システムが「理解」あるいは「納得」したことをより強くユーザに示した方が，対話の自然性が向上するため，相槌『なるほど』を生成する．
 \item それ以外の発話が生成されていた場合は，相槌『そうですか』を生成する．
\end{enumerate}


\noindent\textbf{■　応答選択}

認識信頼度が高いと判定され，繰り返し応答，問い返し応答，共感応答のいずれかの応答が生成された場合は，以下の考えに基づき，繰り返し／問い返し応答を優先的に選択する．

\begin{itemize}
   \item 繰り返し応答により，「聴いている」ことを効果的にユーザに伝えることができる
   \item 問い返し応答により，ユーザが過去の記憶を思い出しやすくなると同時に，対話をより継続することができる
   \item 共感応答は，繰り返し応答と同時に出力することで，「共感している」ことをより効果的に伝えることができる
\end{itemize}

具体的には，以下のように応答選択を行う．

\begin{enumerate}
  \item 繰り返し／問い返し応答のいずれかが生成されている場合は，それらの中からランダムに選択する．なお，ランダムに選択した結果が繰り返し応答の場合は，繰り返し応答の後に続けて出力する応答を，以下のように選択する．

\begin{itemize}
 \item 問い返し応答が生成されている場合は，それらの中からランダムに選択し，繰り返し応答に続けて出力する（e.g., お花を貰ったんですか．誰から貰ったんですか？）．
 \item 問い返し応答は生成されていないが，共感応答が生成されている場合は，共感応答を繰り返し応答に続けて出力する（e.g., お花を貰ったんですか．それは嬉しいですね．）．
 \item 問い返し応答，共感応答のいずれも生成されていない場合は，繰り返し応答のみを出力する．
\end{itemize}
  
\item 繰り返し／問い返し応答が一切生成されていない場合は，共感応答を選択する．
\end{enumerate}


\section{音声認識，および，認識信頼度アルゴリズム}

本章では，音声認識，および，認識信頼度判定アルゴリズムについて述べる．
 

\subsection{音声認識}

まず，音声認識については，音声認識エンジンとしてJulius \cite{no36}を使用した．ここで，音響モデルは，不特定話者PTMモデル\cite{no37}を利用した．言語モデルについては，想定する対話の特性を踏まえ，次の2点を考慮して作成した．なお，作成した言語モデルの語彙数は6万語である．


\noindent\textbf{(1)ユーザ発話の多くは，過去の行動や感情に関する発話である}

システムは回想法によりユーザに過去の出来事に関する発話を促すため，ユーザ発話には行動や感情に関する単語が含まれることが予想される．表5に試作版の傾聴システムへの入力例を示す．

\begin{table}[b]
\caption{試作版の対話システムへの入力例}
\label{table:5}
\input{01table05.txt}
\end{table}


\noindent\textbf{(2)ユーザ発話中に，名詞単独の発話が含まれる}

我々の傾聴システムは，問い返し応答の1つとして，不足格を問い返す応答を生成する．この問い返しに対し，ユーザが名詞単独で発話することが予想される（e.g., Sys: どこで食べたんですか？　Usr: お店）．

以上2点を踏まえ，言語モデルは以下のように作成した．

\paragraph{\underline{手順[1]}：}Web上のテキストデータ\cite{no38}において，行動や感情が記述されやすいWebページを選別し，学習コーパスとした．学習コーパスの総量は，約215万ページ，3350万文であった．これまでに，行動や感情が記述されたコーパス作成手法として，大規模ブログデータから，人間の経験（時間と空間，動作とその対象，感情）を，適切な動詞と121個の感情語を用いて抽出する手法\cite{no39}や，過去時制動詞を主とした特徴語と，未来と現在時制動詞を主とした特徴語により，個人的な話題をブログデータから抽出する手法\cite{no40}などが提案されている．ここでは，言語モデル作成のためであり，コーパス内容をそれほど限定する必要がないことから，以下に示す方法でWebページを選別した．

\begin{enumerate}
  \item 行動や感情が記述されやすい日記のWebページを学習データとする．具体的には，URLに「BLOG, Blog, blog, DIARY, Diary, diary」のいずれかを含むWebページを採用した．
  \item 試作版の傾聴システムを用いて，開発者数名で予備実験したところ，対話ログに述語691語が含まれていた．この述語のうち，30語以上を1ページ内に含むWebページを採用した．これは，日記や物語などに関して記述されたWebページが中心である．
\end{enumerate}
 

\paragraph{\underline{手順[2]}：}上記コーパスに出現した名詞を対象に，それらの名詞単独からなる文（e.g., 映画）を，その出現頻度に従い学習コーパスに追加した．なお，追加した名詞は40,239語である．



\subsection{認識信頼度アルゴリズム}

次に，認識信頼度判定アルゴリズムについて述べる．認識信頼度判定の目的は，繰り返し／問い返し応答生成，および，共感応答生成を行う前に，認識結果に含まれる認識誤りした単語を棄却し，信頼できると判定された認識結果のみを用いて，応答生成を行うことである．ここで，繰り返し／問い返し応答を生成する場合と，共感応答を生成する場合では，以下に述べるように，ユーザ発話中の着目すべき要素，つまり，信頼できるかどうかを判定すべき要素が異なると考えられる．

まず，繰り返し／問い返し応答については，2.2節で述べたように，ユーザ発話中の最終述語，および，その述語が持つ格から生成される．つまり，繰り返し／問い返し応答の生成において，ユーザ発話中で着目すべき要素は〈格要素，格助詞，最終述語〉である．

一方，共感応答を適切に生成するためには，〈格要素，格助詞，最終述語〉といったようにユーザ発話の一部分のみに着目することはできない．例えば，ユーザ発話『会社の飲み会で，すごく美味しいお酒を飲んだ』に対する共感応答（e.g., それは楽しかったですね）や，『会社の飲み会で，我慢してお酒を飲んだ』に対する共感応答（e.g., それは大変でしたね）を適切に生成するためには，「お酒 を 飲んだ」のみに着目するのではなく，「すごく美味しい」や「我慢して」といった情報も考慮した上で，それに対するユーザの感情を推定する必要がある．そのため，共感応答生成においては，生成に必要な要素をあらかじめ特定しておくことは難しい．つまり，共感応答を生成する場合には，認識結果全体に対する信頼度判定が必要となる．

以上の考察に基づき，認識信頼度判定は，以下のように，繰り返し／問い返し応答を目的とした場合と，共感応答を目的とした場合とで，異なる手法により行う．なお，「相槌応答」は，以下のいずれの認識信頼度判定においても「信頼度が低い」と判定された場合に生成される．


\noindent■　{\bfseries 繰り返し／問い返し応答の生成を目的とした場合}

ここでの目標は，認識結果中の最終述語，および，当該述語に付随する格助詞，および，格要素（具体的には，最終述語とその一つ前の述語との間に出現する格助詞，および，格要素．以降，このようにして得られた結果を〈格要素，格助詞，最終述語〉と記述する．）について，以下のような繰り返し／問い返し応答生成のために，信頼度が高いもののみを高精度に抽出すること，である．

\begin{verbatim}
●繰り返し応答：お花を貰ったんですか／お花をですか／お花ですか／貰ったんですか
●不足格の問い返し応答：誰に貰ったんですか？
\end{verbatim}


本論文では，「Juliusから得られる認識結果の候補10Bestにおいて，多くの候補に出現するほど信頼度は高い」という考え方をベースに，〈格要素，格助詞，最終述語〉のそれぞれに対する認識信頼度を判定する．Hazenら\cite{no41}は，単語の認識信頼度を10種類の特徴量を用いて算出し，それらの単独使用と複合使用の時のエラー率の比較結果を示しており，ここで用いた手法は，その単独特徴量中でもっとも性能の良かった特徴量(N-best Purity)の考え方と近い．例として，ユーザ発話『東京に行った』を考える．認識候補10Bestにおいて，「東京　に　行った」や「東京　に　行って」以外に，例えば「故郷　に　行った」や「遠く　に　行った」などの誤った候補が得られていた場合，格助詞「に」の格要素については曖昧であるが，格助詞「に」，および，述語「行く」は多くの候補に出現していることから，少なくとも「〜に行った」という部分については，信頼度が高いと判定することができる．同様に，ユーザ発話『ボールを投げた』に対する認識候補10Bestにおいて，認識結果が「ボール　を」「ボール　と」「ボール　で」の場合には，どのような格助詞に対する格要素かは曖昧だが，格要素「ボール」については信頼度が高いと判定することができる． 

このように，〈格要素，格助詞，最終述語〉のそれぞれの項目に対する個別の信頼度については，10Bestにおけるそれぞれの項目の出現頻度をベースとした手法により信頼度判定が可能である．しかし，ここでは，〈格要素，格助詞，最終述語〉の組み合わせとして信頼度が高いかどうかを判定する必要があるため，以下の方法をとる．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f3.eps}
\end{center}
\caption{繰り返し／問い返し応答生成を目的とした認識信頼度判定の処理フロー}
\label{fig:3}
\end{figure}

提案手法の処理のフローを図3に，手続きを以下に示す．


\paragraph{\underline{手順[1]}：}Juliusより得られる音声認識結果の10Bestそれぞれに対し，「（文頭）　格助詞　最終述語」や「動詞の連用形　最終述語」などのように，着目すべき最終述語の周辺の品詞の並びが不適切な候補を棄却する．


\paragraph{\underline{手順[2]}：}手順[1]で残った認識結果の候補について，まず，最終述語，格助詞，および，格要素を，それぞれの単語認識信頼度\cite{no42}と共に抽出する．また，最終述語が持つ格（格要素＋格助詞）の認識信頼度を，格助詞と格要素の単語認識信頼度の平均により算出する．なお，格要素を抽出する際，連続する名詞は複合名詞と判断し，それぞれの名詞の単語認識信頼度の平均を，当該複合名詞の認識信頼度とする．


\paragraph{\underline{手順[3]}：}10Bestそれぞれについて得られた手順[2]の結果を，格要素，格助詞，格，および，最終述語ごとに合算する．この結果を，ユーザ発話に含まれる格要素，格助詞，格，および，最終述語の候補とする．得られる結果の例を図4に示す．なお，この例では，手順[1]により，残り5つの認識候補が棄却されたとする．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f4.eps}
\end{center}
\caption{手順[3]までの処理で得られる結果の具体例}
\label{fig:4}
\end{figure}
\begin{table}[b]
\caption{本論文で設定した認識信頼度判定のための閾値}
\label{table:6}
\input{01table06.txt}
\end{table}


\paragraph{\underline{手順[4]}：}ここまでの結果を用いて，ユーザ発話中の着目すべき要素のうち，どの認識結果が信頼できるのかを判定する．具体的には，以下のように判定する．
 
\begin{enumerate}
\item 　格要素，格助詞，格，最終述語のそれぞれについて，最大，かつ，閾値以上の信頼度を持つ候補を抽出する．なお，格助詞，および，格については，それぞれの格ごとに判定を行う．また，信頼度判定の閾値は，格要素，格助詞，格，最終述語のそれぞれについて，個別に設定する．本論文で設定した閾値を表6に示す．表6の値は，開発者2名が実験的に，「積極的な繰り返し／問い返し応答の生成」と「相槌応答の生成」とのバランスを鑑みた上で決定した値である．この値に従うと，図4の例では，以下のものが信頼できる認識結果として抽出される．

\begin{itemize}
 \item 格要素：彼，ボール
 \item 格助詞：に，を
 \item 格：彼に
 \item 最終述語：渡す
\end{itemize}
   
なお，これら4つの閾値のうち，「格要素」「格」「最終述語」に関しては，「より積極的に認識結果を利用して応答生成する」のか「誤認識を用いた応答生成を防ぐために相槌を生成するのか」を判断する値である．具体的には，閾値を低く設定すると，より積極的にそれらの認識結果を利用して応答生成するようになり，反対に，閾値を高く設定すると，認識結果は信頼できないと判定されて相槌を生成する可能性が高くなる．一方，「格助詞」に関しては，「より積極的に，不足格の問い返し応答を生成する」かどうかを判断する値である．具体的には，閾値を低く設定すると，「当該格助詞はユーザ発話に含まれている」と判断しやすくなり，不足格の問い返し応答の生成数は減少する．反対に，閾値を高く設定すると，「当該格助詞はユーザ発話に含まれていない」と判断しやすくなり，不足格の問い返し応答の生成数は増加する．なお，格助詞についての閾値は，他と比べ低く設定した．これは，格助詞は誤認識が起こりやすく\cite{no43}，格要素や最終述語と比べ認識信頼度の判断が難しいため，格助詞認識に対するRecallを高くし，「ユーザ発話に含まれているにも関わらず不足格として問い返してしまうエラーによる満足度低下」を防ぐことを目的としたためである．

また，本論文では認識候補の10Bestを利用したが，ある閾値以上の認識結果を利用するなど，利用する認識候補の数を一定にしない方法も考えられる．このような場合には，単語信頼度の合算値を，利用した認識候補の数で正規化した上で閾値判定を行う必要がある．
   
\item 　格要素，格助詞，および，最終述語の個別の項目については，(1)で抽出された結果を信頼できる要素と判定する．一方，〈格要素，格助詞，最終述語〉の共起の信頼度については，格（e.g., 彼に）と最終述語（e.g., 渡す）の共起が日本語として適切かどうかを判定する必要がある．なぜなら，個別の認識候補については言語モデルにより共起の適切性が考慮されているが，提案手法では，〈格要素，格助詞，最終述語〉を一旦独立したものとして扱うため，例えば「格（格要素＋格助詞）については10Best中の上位4候補にのみ含まれる（下位6候補には含まれない）結果が信頼できると判定されるが，最終述語については下位6候補にのみ含まれる（上位4候補には含まれない）結果が信頼できると判定される」という可能性があるためである．

日本語として適切かどうかの判定にはWeb5億文コーパス\cite{no38}を用いる．今回は，Webテキストに〈格要素，格助詞，最終述語〉の組み合わせが10回以上出現した場合に，日本語として適切であるとみなした．
\end{enumerate}

以上の手順で，信頼できると判定された「格要素」「格助詞」「格」「最終述語」を用いて繰り返し／問い返し応答を生成する．なお，信頼できると判定された「格要素」「格助詞」「格」「最終述語」が全く存在しない場合は，繰り返し／問い返し応答は生成されない．


\noindent\textbf{■　共感応答の生成を目的とした場合}

共感応答の生成では，ユーザ発話の音声認識結果に対し，1単語単位ではなく，1発話単位の信頼性を評価し，信頼できる発話候補のみ共感応答生成への入力とする．しかし，Juliusから得られる単語単位の信頼度は，音響モデル尤度，および，3-gram言語モデル尤度に基づき算出された値であるため，後段で，この値を用いて1発話全体の信頼性を判定することは容易ではない．

そこで，「発話全体が信頼できる認識候補かどうか」ではなく，「感情推定がロバストに行える認識結果の候補であるかどうか」という観点で認識結果を精査することとした．具体的には，名詞や動詞，形容詞などの自立語が一語の場合には，発話の曖昧性が高く正確な感情推定できない場合が多いが，「プレゼントを貰った」や「足をぶつけた」のように自立語を2語以上含む場合には，発話の曖昧性が下がり「それは良かったですね」や「それは大変でしたね」といった共感応答の生成が期待できる．そこで，10Bestそれぞれに含まれる「名詞」「動詞」「形容詞」「副詞」，および，「否定表現」の総数が2以上の候補を，感情推定がロバストに行える認識候補と判定し，5章で述べる共感応答生成への入力とする．
  
  

\subsection{音声認識性能，および，認識信頼度判定アルゴリズムの有効性評価}

本節では，提案システムの音声認識性能，および，認識信頼度判定アルゴリズムの有効性評価についての予備実験結果を示す．なお，テストセットとして，被験者39名による1,042発話を用いた．

まず，音声認識性能についての結果について述べる．テストセットに対する単語認識率は，recall: 70.1\%, precision: 66.7\% であった．提案システムのように項構造を用いる場合は，ユーザ発話に含まれる格要素，格助詞，最終述語をどの程度適切に認識できるかでシステムの応答精度が大きく変わってくる．一般的に，格助詞は誤認識されやすく，藤原らの調査\cite{no43}によると，「認識信頼度が0.5以上の範囲で，助詞は動詞より約13\%程度認識率が低下する」というデータがある．彼らの試算に従うと，提案システムにおいて，ユーザ発話に含まれる格助詞の認識精度は約50\%程度になると考えられる．

次に，このように多くの誤認識を含むユーザ発話に対して，提案手法により，高精度な応答生成が可能かどうかを検証した結果について述べる．自然な話し言葉においては，省略，音声認識器の誤認識，文境界の不明確さなどにより，項構造を誤って理解する可能性があり，これまでに，タスク依存型モデルにおける部分的な構文解析，多数の音声認識候補(N-Best)の利用，1単語単位の信頼度と1発話単位の信頼度の組み合わせ，会話内容全体を考慮した信頼度尺度の使用等により，意味解釈の精度を向上させる多くの手法が検討されてきた\cite{no44}．今回のシステムでは，応答生成の種類に応じて，N-Best利用による1単語単位の信頼度と，ロバストに感情推定できるかという尺度での
\linebreak
1発話単位の信頼度を使い分けることにより，適切な応答を引き出している．また，いずれの認識信頼度判定においても信頼度が低いと判定された場合には「相槌応答」を生成することで，誤認識による不適切な応答生成を最小限にしている．

\begin{figure}[t]
\begin{center}
\includegraphics{24-1ia1f5.eps}
\end{center}
\caption{認識信頼度アルゴリズムの有効性検証結果}
\label{fig:5}
\end{figure}

3.2節で述べた認識信頼度アルゴリズムの有効性を，上記テストセットを用いて検証した結果を図5に示す．図5の「1Bsetのみ利用」は，Juliusから得られる認識結果の1bestのみを用い全ての認識結果が信頼できるとして応答生成した場合で，「認識信頼度判定有り」は，我々の提案アルゴリズムにより信頼度が高い候補を抽出して応答生成した場合を示す．なお，ここでは，応答正解率 = 適切な応答数／(適切な応答数 + 誤応答数)とし，提案アルゴリズムにより相槌が生成された場合（452発話）については，評価の対象外とした．図5が示す通り，Juliusから得られる認識結果の1bestを用いて応答生成した場合には，応答正解率は55.8\%だが，我々が提案する認識信頼度判定を用いた場合には，応答生成の正解率は74.7\%であった．このことから，音声認識誤りにロバストな認識信頼度判定アルゴリズムが構築できたと考える．

音声認識器の誤認識に関しては，今後さらに低減されていくと考えられるが，周囲騒音の大きい環境や高齢者の小声発話などに対しては認識が難しく，誤認識の問題は依然として残ると予想される．今回採用したような認識信頼度の利用手法は，今後のシステムにおいても必須であると考えることができる．


\section{問い返し応答の生成アルゴリズム}

本章では，問い返し応答の生成アルゴリズムについて述べる．2.2節で述べたように，問い返し応答には，「最終述語の不足格の問い返し」と「辞書を用いた適切性判別に基づく問い返し」の2種類がある．以下，それぞれについて述べる．


\subsection{最終述語の不足格判別に基づく問い返し応答の生成アルゴリズム}

本節では，最終述語の不足格判別に基づく問い返し応答の生成アルゴリズムについて述べる．提案システムでは，最終述語が「動詞」および「サ変名詞＋する」の場合のみ不足格判別に基づく問い返し応答を生成し，他の最終述語に関しては不足格の問い返し応答は生成しないものとした．なぜなら，ユーザの行動を表す「動詞」および「サ変名詞＋する」に関しては，不足格（e.g., 誰と，どこに，何を）を問い返すことがユーザの次発話を促す効果があると期待されるが，ユーザの感情や形容表現を表す「形容詞」「形容詞＋なる」「形容動詞」「名詞＋だ」に関しては，不足格判別に基づく問い返し応答（e.g., いつより嬉しかったんですか？，何より美味しかったんですか）は不自然な応答となる場合が多いためである．なお，ユーザの感情や形容表現を表すこれらの述語に関しては，4.2.3節で述べる理由を問い返す表現により次発話の生成を促す．
 

\subsubsection{問い返し応答生成アルゴリズムの概要}

図6に，問い返し応答生成アルゴリズムの概要を示す．3.2節で述べた信頼度判定アルゴリズムにより，信頼度が高いと判定された動詞，および，格助詞を用いて，以下の手順により問い返し応答を生成する．
 
\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f6.eps}
\end{center}
\caption{最終述語の不足格の問い返し応答生成アルゴリズムの概要}
\label{fig:6}
\end{figure}

\paragraph{\underline{手順[1]}：}当該動詞をキーとして，予め作成された必須格辞書を検索する．ここで，必須格辞書には，図6に示すように，ある動詞についての必須格が深層格レベルで登録されていると同時に，当該格を尋ねる際に最適な疑問詞と表層格がペアで登録された辞書である．ここで，図6中の「ヲ(object)」などの表記は，「表層に現れた格助詞（深層格）」を意味する．なお，想定している対話の性質上，ユーザ発話内の「ガ(agent)」は省略されることが多いため，ここでは，必須格としては登録しない．必須格辞書の作成手法の詳細は，4.1.2節で述べる．

\paragraph{\underline{手順[2]}：}信頼度が高いと判定された格助詞と，手順[1]で検索された必須格との照合を行うことで，当該動詞の不足格を判別し応答を生成する．例えば，ユーザ発話中の動詞「貰う」の不足格が「カラ格(source)」と判別された場合，問い返し応答として『誰から貰ったんですか？』を生成する．不足格判別手法の詳細は，4.1.3節で述べる．


\subsubsection{必須格辞書の作成}

本節では，必須格辞書の作成について述べる．


\noindent\textbf{(ア)　「不足格の問い返し応答」に適した深層格の定義}

前述したように，必須格は深層格レベルで登録する．なぜなら，表層的には同じ「二格」であっても，それが「goal格」なのか「time格」なのかで尋ね方が異なる上に，深層格レベルで考慮しないと，どちらが必須格なのかを適切に判定できないためである．

一般的に，表層格は「ガ」「ヲ」「二」「デ」「ト」「ヘ」「カラ」「ヨリ」「マデ」の9種類とする定義が広く用いられているのに対し，深層格については，どのような種類をどのような基準で認定するかの共通見解がない．そこで，我々は，EDR日本語共起辞書\cite{no45}において定められている意味的関係の定義をベースに深層格を定義した．具体的には，EDR日本語共起辞書において，名詞と動詞の間に付与されている「概念関係子」をベースに深層格を定義する．表7に，概念関係子の例を示す．

\begin{table}[b]
\caption{EDRにおける概念関係子の付与例}
\label{table:7}
\input{01table07.txt}
\end{table}

本論文では，「動詞の不足格を問い返す」という目的を鑑み，以下の考察に基づいて深層格を定義した．


\begin{table}[b]
\caption{表層格「ヲ」に付与された概念関係子objectの例}
\label{table:8}
\input{01table08.txt}
\end{table}



\noindent\textbf{　\underline{1. 概念関係子の細分化が必要}}

例として，EDRで定義されている概念関係子objectに着目する．表層格「ヲ」に付与されたobject，および，表層格「ト」に付与されたobjectの例を，表8と表9に示す．EDRにおけるobjectの定義は「動作・変化の影響を受ける対象」であり，どちらもその定義に従っているが，意味的には，「ヲ」が示すobjectは動作の「対象」，一方，「ト」が示すobjectは動作の「相手」と考えられ，全く異なるものである．仮に，動詞「競い合った」を考えた際，「ヲ」が示すobject（＝「対象」）が不足格であった場合，それを問い返す適切な応答は「何を競い合ったの？」であるのに対し，「ト」が示すobject（＝「相手」）が不足格であった場合の適切な問い返し応答は「誰と競い合ったの？」となる．つまり，動詞の不足格を問い返すことを目的とした場合，動詞「競い合う」にとっての概念関係子objectを2種類の深層格に細分化する必要がある．

このような細分化は，上記の例のように，異なる表層格に付与された概念関係子を対象とした場合だけではなく，同一の表層格に付与された概念関係子も対象となる．例えば，表10に示すような，表層格「ト」に付与された概念関係子goalに着目すると，上2つの動詞（一致する，関係する）では，不足格を尋ねる際に「〜と……？」と尋ねるのが自然なのに対し，下2つの動詞（なる，考える）では，「どう……？」と尋ねるのが自然である．

\begin{table}[t]
\caption{表層格「ト」に付与された概念関係子objectの例}
\label{table:9}
\input{01table09.txt}
\end{table}
\begin{table}[t]
\caption{表層格「ト」に付与された概念関係子goalの例}
\label{table:10}
\input{01table10.txt}
\end{table}
\begin{table}[t]
\caption{表層格「ヲ」に付与された概念関係子objectおよびbasisの例}
\label{table:11}
\input{01table11.txt}
\end{table}


\noindent\textbf{　\underline{2. 概念関係子の統合が可能}}

また，格の尋ね方が同一かどうかの観点で考えると，異なる概念関係子を統合できる場合もある．例えば，表11に示すような，表層格「ヲ」に付与されている概念関係子objectおよびbasisの場合，どちらも「対象」を示しているが，動詞の意味が「過不足・優劣」などの場合はbasis，それ以外の場合にはobjectが付与されている．ここで，これらの格を尋ねる際には，いずれも「〜を……？」と尋ねるのが自然である．つまり，上記の観点では，これらの概念関係子は全て「〜を……？」と尋ねるobjectに統合可能と言える．

以上の考察に基づき，本論文で定義した深層格の一部を表12に示す．

\begin{table}[t]
\caption{本研究で再定義した深層格（抜粋）}
\label{table:12}
\input{01table12.txt}
\end{table}


\noindent\textbf{（イ）必須格辞書の作成}

（ア）で述べた定義に従い，動詞の必須格辞書を作成する．具体的には，以下の手順で作成した．


\subparagraph{\underline{手順[1]}：}毎日新聞記事5年分 (毎日新聞社 1991--1995)\nocite{no46} を対象として，全ての文に対し係り受け解析を行い，〈格要素，格助詞，動詞〉を抽出する．


\subparagraph{\underline{手順[2]}：}手順[1]の抽出結果に対し「格助詞置換分析法」\cite{no47}を用いて深層格の判別を行う．この手法は，格要素や動詞の意味属性情報に加え，当該動詞がどのような表層格のパターンを持っているか，別の表層格に置換可能であるかどうか，などの情報を統計的に獲得し，これらの情報を利用して，ルールベースにより深層格の判別を行うものである．具体的な処理を図7に示す．例として，「飛行機が成田空港を出発する」の「ヲ」格の深層格を判別する．


\subparagraph{　A)}まず，図7(A)に示す通り，上記の毎日新聞記事5年分から，「出発する」が持つ表層格パターンを抽出する．


\subparagraph{　B)}次に，「ガ−ヲ」の格パターンの「ヲ」が，別の表層格に置換されたパターンが存在するかどうかを検索する．その結果，「出発する」は「ガ−カラ」という「ヲ」が「カラ」に置換されたパターン，あるいは，「ガ−二」という「ヲ」が「二」に置換されたパターンを持つことが分かる．ここで，置換されたパターンが存在するかどうかは，シソーラス\cite{no48}から得られる格要素の意味属性を利用して判断する．

\subparagraph{　C)}最後に，図7(C)に示す通り，あらかじめ作成した深層格判別ルールに従い，「ヲ」の深層格が「source」であると判別する．  

\begin{figure}[t]
\begin{center}
\includegraphics{24-1ia1f7.eps}
\end{center}
\caption{格助詞置換分析法\protect\cite{no47}の概要}
\label{fig:7}
\end{figure}

なお，EDR日本語共起辞書内で付与されている概念関係子を，本研究で再定義した深層格体系（表12）に人手で変換したデータ685事例（e.g., 変換前：「群衆と握手する （ト＝object）」⇒変換後：「群衆と握手する（ト=partner）」）を深層格の正解データとし，上記提案手法の深層格判別精度を評価した結果，判別精度は75.7\%であった．


\subparagraph{\underline{手順[3]}：}手順[2]の結果を動詞ごとにまとめ，それぞれの深層格について頻度が一定以上あるものを当該述語の必須格とする．


\subparagraph{\underline{手順[4]}：}手順[3]で必須格と判断された深層格それぞれについて，シソーラスを用いて，出現した全ての格要素の意味属性を【人／場所／人工物／…】といったレベルで判別する．


\subparagraph{\underline{手順[5]}：}手順[4]で得られたそれぞれの意味属性を【人⇒誰／場所⇒どこ／物⇒何／…】のように，尋ねる際に最適な疑問詞に置換し，最頻出の疑問詞を，当該深層格を尋ねる際に最適な疑問詞として登録する．

なお，受動態や使役態の場合は，能動態とは必須格が異なる．しかし，本論文で作成した深層格判別ルールは能動態のみにしか対応していない．したがって，例えば，ユーザ発話「ずいぶんと怒られたよ」に対し，「誰に怒られたんですか？」といったような不足格の問い返し応答は生成できない（2.2節で述べたように，「怒られたんですか．」という繰り返し応答の生成は可能）．この点については，今後の課題とする．
 
 
 
 
\subsubsection{不足格の判別手法}

本節では不足格の判別手法について述べる．音声認識誤りがない場合には，入力された 〈格要素，格助詞，動詞〉を用いて4.1.2節と同様の方法で深層格解析をし，不足格を尋ねる応答を生成する方法をとることができるが，我々のタスクでは〈格要素，格助詞，動詞〉の全てが閾値以上の信頼度で認識できるとは限らない．特に，格要素の信頼度が低いと判定され抽出されなかった場合には，深層格解析を行うことができない．しかし，このような場合であっても，格助詞と動詞の信頼度が高いと判定された場合には，表層格レベルでの不足格判別は可能である．したがって，ここでは，格要素も含めて信頼度が高いと判定されたかどうかに関わらず，格助詞と動詞のみを用いて，表層格の情報に基づいた不足格の判別を行う．具体的には，以下の手順で行う．例として，ユーザ発話「北海道に行ったよ」に対し，認識信頼度判定の結果，格助詞「二」，および，動詞「行く」のみが，信頼度が高いと判定されて抽出された場合を考える．
 

\paragraph{\underline{手順[1]}：}信頼度が高いと判定された動詞について，4.1.2節で述べた手法により作成された必須格辞書を検索し，それぞれの必須格について，当該深層格を表現し得る全ての表層格に置き換える．上記の例では，動詞「行く」の必須格として登録されている深層格「goal」および「partner」を，対応する全ての表層格「二・ヘ」および「ト」に置き換える．
 

 \paragraph{\underline{手順[2]}：}手順[1]で置き換えた表層格のいずれもがユーザ発話に含まれていない深層格に限り，当該必須格を不足格と判別する．上記の例では，表層格「二」が含まれているため，深層格「goal」はユーザ発話に含まれており，深層格「partner」が不足格であると判断して，不足格を問い返す応答「誰と行ったんですか？」を生成する．

前述したように，音声認識において，格助詞は他の単語に比べて誤認識されやすい．また，話し言葉においては格助詞の省略も頻繁に起こる．これらに対する提案手法の有効性に関して考察する．

まず，音声認識誤りに関して，ユーザ発話「北海道に行ったよ」の認識が難しく，認識候補の上位に格助詞「に」が認識されなかった場合を考える．仮に，単純に1bestの認識結果に対して，上記の不足格判別手法を適用したとすると，「goal」は不足格であると判別され，「どこに行ったんですか？」という誤応答が生成されてしまう．しかし，提案手法では，3.2節でも述べたように，認識結果の10bestを利用し，格助詞については，認識信頼度判定の閾値を低い値に，つまり，「当該格助詞がユーザ発話に含まれている」と判定しやすい値に設定してある．したがって，上位の認識結果では格助詞「二」が認識されていなかったとしても，10best内の下位の認識結果では認識されており，単語認識信頼度の合計が閾値以上であれば，格助詞「二」は認識信頼度が高いと判定され抽出される．これにより，「goal」は不足格ではないと判別され，「どこに行ったんですか？」という誤応答の生成を防ぐことが可能となる．

次に，格助詞の省略に関しては，例えば，「北海道行ったよ」といった発話の場合，提案手法で手がかりとする格助詞（この例では「二」）が，信頼度が高い結果として抽出されることは考えにくいため，実際には「goal」が含まれているにも関わらず誤って不足格であると判別される．この発話に対して，「goal」が含まれていることを正しく判別するためには，格要素（北海道）の意味属性から深層格を理解するような手法や，省略された格助詞を補完するような技術の開発が必要となる．この点については今後の課題とする．

 
 
\subsection{辞書を用いた適切性判別に基づく問い返し応答の生成アルゴリズム}

本節では，辞書を用いた適切性判別に基づく問い返し応答の生成アルゴリズムについて述べる．前述したように，この応答には，「格要素の詳細」「感想」「感情・形容表現に対する理由」をユーザに尋ねる3種類の応答がある．以下，それぞれについて述べる．
 

\subsubsection{格要素の詳細を尋ねる問い返し応答の生成アルゴリズム}

まず，ユーザ発話「お花を貰った」に対するシステム応答「どんなお花ですか？」といったような，格要素の詳細を尋ねる問い返し応答の生成アルゴリズムについて述べる．


\paragraph{\underline{手順[1]}：}Webテキスト\cite{no38}において，格要素の詳細を尋ねる際の疑問詞（「どんな」「何の」「どこの」の3種類）と係り受け関係にある名詞の頻度をカウントする．


\paragraph{\underline{手順[2]}：}手順[1]で各疑問詞との係り受け関係が頻度閾値以上の名詞については，当該疑問詞で詳細を尋ねることが適切であると判定する．

\begin{table}[b]
\caption{詳細を尋ねることが適切であると判定された格要素の例}
\label{table:13}
\input{01table13.txt}
\end{table}


表13に，登録されている名詞の例を示す．表13の(a)は疑問詞「どんな」との係り受け関係が閾値以上で出現した名詞で，例えば『どんな動物なの？』『どんなドラマなの？』などの応答を生成する．しかし，当該名詞がユーザ発話に含まれたとしても，ユーザ発話には既にその詳細についての情報が含まれている可能性がある．そこで，ここでは，信頼度が高いと判定された格要素を含む認識候補について，当該格要素の直前に「形容詞」「形容動詞」または「〜の」が存在する認識候補が1つでも存在すれば，ユーザ発話には既に格要素の詳細についての情報が含まれていると判断し，格要素の詳細を尋ねる問い返しの生成は行わない．
 

\subsubsection{感想を尋ねる問い返し応答の生成アルゴリズム}

次に，ユーザ発話「お花を貰った」に対してシステム応答「どうでしたか？」というユーザ発話の感想を尋ねる問い返し応答の生成アルゴリズムについて述べる．我々のシステムでは，言語モデルに含まれる述語を対象に，感想を尋ねることが自然であるかどうかを人手により判断してもらい，「感想を尋ねることが不自然な述語の辞書」を構築した．辞書の一部を表14に示す．我々のシステムは，ユーザ発話の最終述語がこの辞書に登録されていない場合に，感想を尋ねる問い返し応答を生成する．例えば，ユーザ発話が「お花を貰ったの」の場合には「貰った」は辞書に登録されていないため「どうでしたか？」という発話を生成するが，ユーザ発話が「ムキになったの」の場合には表14に示す辞書に「ムキになる」が登録されているため「どうでしたか？」というシステム発話は生成しない．

\begin{table}[b]
\caption{感想を尋ねることが不自然であると人手により判断された述語の例（エントリ数：422）}
\label{table:14}
\input{01table14.txt}
\end{table}

ただし，「ディズニーランドに行った」の場合は「どうでしたか？」と尋ねることが適切だが，「食堂に行った」のように日常的な事態に関しては「どうでしたか？」と尋ねることは適切でないというように，感想を尋ねることが適切かどうかの判断は，述語のみではなく格要素などの情報も考慮した上で行う必要がある．この点に関しては今後の課題である．


\subsubsection{感情・形容表現に対する理由を尋ねる問い返し応答の生成アルゴリズム}

最後に，ユーザ発話「楽しかったよ」に対するシステム応答「どうして楽しかったんですか？」のような，感情・形容表現に対する理由を尋ねる問い返し応答の生成アルゴリズムについて述べる．提案手法では，「人手により，理由を尋ねることが適切であると判定された感情・形容表現」が登録された辞書に基づき，当該応答の適切性を判定する．登録されている感情・形容表現の例を表15に示す．

\begin{table}[b]
\caption{理由を尋ねることが適切であると人手により判断された感情・形容表現の例（エントリ数：130）}
\label{table:15}
\input{01table15.txt}
\end{table}

ただし，ユーザ発話に，既に当該感情・形容表現に対する理由が含まれている可能性があるため，単純に辞書に登録されているかどうかのみで応答生成の適切性を判定することはできない．そこで，ここでは，信頼度が高いと判定された感情・形容表現を含む認識候補について，当該感情・形容表現の直前に，「ので」「から」などの接続詞が存在する認識候補が1つでも存在すれば，ユーザ発話には既に理由が含まれると判断し，当該応答の生成は行わないこととした．


\section{共感応答の生成アルゴリズム}

本章では，共感応答の生成アルゴリズムについて述べる．


\subsection{応答生成アルゴリズムの概要}

図8に共感応答の生成アルゴリズムの概要を示す．3.2節で述べたように，本論文では，前段で認識誤りを含む認識結果を棄却するのではなく，「誤認識結果が含まれる場合でも適切に感情推定を行う」手法を提案する．具体的には，「感情推定の際に重要となるキーワードが正しく認識されていれば，複数の認識候補に共通して出現し，それらの認識候補に対する感情推定結果は同一となる」という仮説に基づき，前段の認識信頼度判定アルゴリズムにより得られた3つの認識候補に対して感情推定を行い，多数決，および，閾値判定に基づき，得られた感情推定結果が適切であるかどうかを判断する．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f8.eps}
\end{center}
\caption{共感応答の生成アルゴリズムの概要}
\label{fig:8}
\end{figure}


\paragraph{\underline{手順[1]}：}認識信頼度判定により得られた3つの各認識結果に対して，5.2節で述べる手法によりユーザの感情を推定する．その際，それぞれの感情推定結果には信頼度(0〜1)が付与される．また，具体的な感情のレベル（e.g., 嬉しい／恐い）での推定結果が高信頼度で得られた場合は当該結果が出力されるが，推定信頼度が低い場合には，感情極性のレベル（ポジティブ／ネガティブ／ニュートラル）で出力される．


\paragraph{\underline{手順[2]}：}3つの認識候補毎に得られた推定結果について，感情と感情極性ごとに信頼度の和を算出し，値が最大，かつ，閾値以上の信頼度を持つ結果を，ユーザ発話に対する感情推定結果とする．もし閾値を以上の信頼度を持つ結果がなければ，感情極性はニュートラルとする．


\paragraph{\underline{手順[3]}：}手順[2]で得られた最終的な推定結果を用いて共感応答を生成する．具体的には，最終的な推定結果が「嬉しい」であれば，「それは嬉しいですね」という応答が生成され，最終的な推定結果が「ポジティブ」であれば，「それはいいですね」という応答が生成される．一方，最終的な推定結果が「ニュートラル」の場合は，共感応答は生成しない．これにより，大きな感情の変化が起きない内容のユーザ発話（e.g., 電話をした）や，誤認識により信頼できる感情推定結果が得られなった場合に，不適切な共感応答を生成することを防ぐことができる．


\subsection{感情推定アルゴリズム}

ここでは，感情推定アルゴリズムについて説明する．本論文では，徳久らの手法\cite{no12}により感情推定を行う．具体的には，感情推定を「ユーザ発話をある感情クラスに分類する問題」ととらえ，大量の学習データに基づく機械学習によりこの問題を解く手法である．ここで，我々は，システムがユーザに共感していることをより明確に示すために，単に感情極性（ポジティブ，ネガティブ，ニュートラル）を推定するだけではなく，より具体的なレベルでの感情（「嬉しい，楽しい，安心，怖い，悲しい，残念，嫌，寂しい，不安，腹立たしい」の10クラス）を推定する．感情推定は，次の3つの処理により実現する．


\noindent\textbf{\underline{処理1：感情生起要因コーパスの作成}}

機械学習を行う際の学習データとなる感情生起要因コーパスを作成する．感情生起要因コーパスとは，ある事態に対してどのような感情が生起するかが記述されたコーパスであり，\textbf{｛}感情が生起する要因となる事態\textbf{｝}と〈感情〉とで構成される．

まず，獲得対象とする感情表現を定義する．寺村\cite{no51}は，感情表現に関して，『X＝感情主，Y＝対象，Z＝当該語のとき，「XはYをZ」「XはYにZ」「XはYがZ」のいずれかの表現ができれば，Zは感情表現である．』と定義している．この定義を参考にして，小林らの評価値表現辞書\cite{no52}から感情表現を抽出した結果，349語の感情表現を得た．表16に，感情ごとの感情表現の数と例を示す．

\begin{table}[b]
\begin{center}
\caption{感情ごとの感情表現の数と例}
\input{01table16.txt}
\end{table}

次に，図9に示す言語パターンを用いてWebコーパスから自動的に感情生起要因を獲得する．獲得の手がかりとする感情表現には表16の349語を，接続表現には右記の8種類（ので，から，ため，て，のは，のが，ことは，ことが）を用いる．例えば，「突然雨が降り出したのはがっかりだ」という文からは，〈がっかり〉が生起する要因として\textbf{｛}突然雨が降り出した\textbf{｝}を獲得する．

この方法で，河原らのWeb 5億文コーパス\cite{no38}から感情生起の要因を獲得した結果，約130万件の感情生起要因が獲得された．表17に10種類の感情ごとの感情生起要因の獲得数を示す．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f9.eps}
\end{center}
\caption{感情生起要因を獲得するための言語パターン}
\label{fig:9}
\end{figure}
\begin{table}[b]
\caption{感情生起要因コーパスの規模}
\label{table:17}
\input{01table17.txt}
\end{table}


\noindent\textbf{\underline{処理2：感情極性のレベルでの推定}}

上記で作成した感情生起要因コーパスを学習データとして，感情生起要因コーパスに含まれるポジティブの事例とネガティブの事例を用いて感情極性推定モデルを構築し，ユーザ発話の感情極性推定結果が感情極性推定モデルの分離面に近い場合にニュートラルと推定する．

感情極性の推定に関しては，さまざまな手法が提案されている\cite{no53,no33,no54}．これらを参考にして，我々は単語を特徴量として文の感情極性を推定する．図10に「福祉の費用の負担が増えてしまう」という感情極性がネガティブである文を形態素単位で記述した例を示す．図10の例について3-gram以下の列を展開すると，「福祉，福祉の，福祉の費用，の，の費用，…」などが得られる．これらを素性としてSVMで学習し感情極性推定モデルを構築する．判別した結果，SVMのスコアが正，かつ，閾値以上ならば感情極性はポジティブ，スコアが負，かつ，閾値以下ならば感情極性はネガティブ，それ以外ならばニュートラルを出力する．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f10.eps}
\end{center}
\caption{形態素列の例}
\label{fig:10}
\end{figure}


\noindent\textbf{\underline{処理3：具体的な感情のレベルでの推定}}

ここでは，ポジティブ，および，ネガティブのそれぞれを細分類化し，処理2と同様に機械学習によりユーザ発話に対する感情を推定する．表16に示すように，我々は先行研究\cite{no55,no56}による知見を考慮し，ポジティブな感情として\textbf{｛}嬉しい，楽しい，安心\textbf{｝}の3種類，ネガティブな感情として\textbf{｛}恐い，悲しい，残念，嫌，寂しい，心配，腹立たしい\textbf{｝}の 7 種類の感情を対象として感情推定を行う． 

SVMは2クラス判別器が，多クラスへの分類を行うため，図11に示す2種類の方式を試す．一般に，大量のデータから少量の事例を識別することは難しい．図11の〈方式1〉は，表17に示す感情生起要因の獲得数を考慮して事例の多い順に識別モデルを配置した方式である．まず入力文が\textbf{｛}嫌\textbf{｝}か\textbf{｛}嬉しい，残念，楽しい，恐い，不安，寂しい，腹立たしい，悲しい，安心\textbf{｝}かを判別し，続いて\textbf{｛}嬉しい\textbf{｝}か\textbf{｛}残念，楽しい，恐い，不安，寂しい，腹立たしい，悲しい，安心\textbf{｝}かを判別し，さらに\textbf{｛}残念\textbf{｝}か\textbf{｛}楽しい，恐い，不安，寂しい，腹立たしい，悲しい，安心\textbf{｝}かを判別する．このような方法で判別を繰り返し，最後に\textbf{｛}悲しい\textbf{｝}か\textbf{｛}安心\textbf{｝}かを判別する．一方，図11の〈方式2〉は，感情極性（ポジティブまたはネガティブ）を判別した上で，感情生起要因の獲得数を考慮して判別モデルを配置した方式である．感情極性の推定には処理2で構築したモデルを用いる．方式1と方式2のどちらの方法を採用するかについては，5.3節で評価実験を行い，その結果を踏まえて決定する．

\begin{figure}[t]
\begin{center}
\includegraphics{24-1ia1f11.eps}
\end{center}
\caption{感情推定の判別モデル}
\label{fig:11}
\end{figure}


\subsection{感情推定アルゴリズムの評価}

本節では，5.2節で述べた感情推定アルゴリズムのそれぞれのモジュールを評価する．


\noindent\textbf{\underline{評価1：感情生起要因コーパスの構築精度の評価}}

感情生起要因コーパスの評価のため，ランダムに2,000事例を抽出し，獲得した感情生起要因の精度を調べた．評価は，感情生起要因コーパスの獲得に関わっていない評価者1名で行った．表18に評価結果を，表19に具体例を示す．表18および表19の「感情極性」は獲得した事態が実際にその感情極性であったかどうかを評価した結果を，「感情」は獲得した事態が実際にその感情を表すかどうかを評価した結果である．また，「正例」は“正例”，「文脈依存」は“文脈によっては正例”，「負例」は“負例”を示す．

\begin{table}[t]
\caption{感情生起要因コーパスの評価}
\label{table:18}
\input{01table18.txt}
\end{table}
\begin{table}[t]
\caption{感情生起要因コーパスの評価の例}
\label{table:19}
\input{01table19.txt}
\vspace{-0.5\Cvs}
\end{table}

表18に示す通り，感情極性については，57.0\%が正例，文脈によって正例となる事例も加えると90.9\%の事態が正例であった．また，感情に関しては，49.4\%が正例，文脈によって正例となる事例を加えると73.9\%が正例であった．負例について分析したところ，表19の「ジュースが飲みたい」と「大変だ」のように，本来は係り受け関係にない従属節と感情表現が係り受け解析誤りにより獲得されることが原因であることが分かった．感情生起要因コーパスの精度が十分かどうかは，感情生起要因コーパスを用いた感情推定精度を評価して初めて言及できるが，大規模で比較的信頼性の高いコーパスが構築できたと考えている．


\noindent\textbf{\underline{評価2：感情極性推定の評価}}

感情極性推定の精度を評価するため，以下の2つのテストセットを構築した．


\subparagraph{　TestSet1: }1つ目は，システムの開発者以外の弊所所員6名がキーボード対話によるプロトタイプ対話システムに入力した発話に対して話者自身が感情極性を付与した65発話である．これらには，ポジティブ31発話，ネガティブ34発話が含まれる．


\subparagraph{　TestSet2: }2つ目は，表18で感情極性が正例の1,140事例（ポジティブ491事例，ネガティブ649事例）事例である．なお，実験の際は，感情極性推定モデルはこれらを除いた事例で学習する．


上記のテストセットで評価した結果を表20に示す．数値はF値を算出した結果である．感情極性推定精度に関しても，この精度で十分かどうかは言及しにくいが，特徴量は単語n-gramという非常にシンプルなものであるものの，1) 大規模な学習コーパスを利用したことで比較的高精度であること，2) 音声認識による対話システムへの実用化を想定した場合には，単語n-gramのようなシンプルな特徴量の方が利用しやすいという2つの理由から，実用的な感情極性推定モデルが構築できたと考えている．

\begin{table}[b]
\vspace{-0.5\Cvs}
\caption{感情極性推定結果（F値）}
\label{table:20}
\input{01table20.txt}
\end{table}


\noindent\textbf{\underline{評価3：感情推定の評価}}

以下の3つのテストセットを用いて感情推定の評価実験を行う．


\subparagraph{　TestSet1: }1つ目は，感情極性の評価実験のTestSet1（65発話）に対して，作業者2名が10種類の感情クラスを独立に付与したものである．なお，ある発話に対して複数の感情が該当する場合には，もっとも適切な感情クラスをひとつ選択した．作業者の付与した感情の一致率は$\kappa = 0.76$ であった．評価では，作業者のひとり以上が付与した感情が出力されれば正解とした．表21に例を示す．

\begin{table}[b]
\caption{2名の作業者による感情クラス付与の例}
\label{table:21}
\input{01table21.txt}
\end{table}


\subparagraph{　TestSet2: }2つ目は，感情極性の評価実験のTestSet1（65発話）に対して，作業者1名が10種類の感情クラスを付与したものである．ある発話に対して複数の感情が該当する場合には，該当する感情クラスをすべて付与した．その結果，ポジティブの発話に対しては平均1.48個，ネガティブの発話に対しては平均2.47個の感情クラスが付与された．表22に例を示す．


\subparagraph{　TestSet3: }3つ目は，表18で感情が正例の988事例である．実験の際は，感情推定モデルはこれらを除いた事例で学習する．


評価結果を表23に示す．表23の「感情推定」は図11の方式1の結果を，表23の「感情極性＋感情推定」は図11の方式2の結果を示す．表23の結果から，どのテストセットにおいても感情極性を推定した上で感情クラスを推定するという図11の方式2の精度が高かった．したがって，次章以降の評価実験では，方式2の方法により感情推定するモデルを採用し，共感応答を生成する．

\begin{table}[t]
\caption{1名の作業者による感情クラス付与の例}
\label{table:22}
\input{01table22.txt}
\end{table}
\begin{table}[t]
\caption{感情推定の評価実験結果(Accuracy)}
\label{table:23}
\input{01table23.txt}
\end{table}


\section{評価実験}

提案した傾聴システムの評価するため，20〜70代の男女110名の一般被験者に対する評価実験を行った．本章では，評価実験結果について述べる．


\subsection{実験条件}

まず，表24に，実験に参加した110名の内訳を示す．

\begin{table}[b]
\caption{実験参加者の性別・年代別の内訳}
\label{table:24}
\input{01table24.txt}
\end{table}

次に，実験設定について説明する．対話ロボットとしては犬型ロボットAIBO（ソニー製，型番：ERS-210）を用いた．対話実験は防音室内で行い，実験進行と対話システムの開始・終了作業は，オペレータが防音室外で行った．防音室内には椅子とテーブル，オペレータが被験者に実験開始終了を伝えるためのスピーカを設置し，テーブル上に，ロボット，および，ロボットの声を出すためのスピーカを設置した．被験者は椅子に座り，単一指向性のヘッドセットマイク（オーディオテクニカ製，型番：ATM75）を装着して，ロボットに向かって発話した．また，話しかけやすさを考慮し，常時，ロボットのしっぽを左右に動かした．さらに，ロボットが話を聴いていると被験者が感じるように，相槌を生成する際には，ロボットの耳が動くようにした．なお，これらのロボットの動作音，および，音声合成音は，ヘッドセットマイクに入り込まない十分小さな音であった．

本実験では，回想法におけるテーマとして「1: 印象深い旅行」と「2: 子どもの頃の遊び」の2種類の話題を用意し，それぞれの話題について1回ロボットと対話をしてもらった．各話題において，対話は，以下の2つのシステム発話でスタートする．

\begin{enumerate}
\item 「これまでの印象深い旅行についてお聞かせ下さい．これまでにどこに行きましたか？」

\item 「子どもの頃の遊びについてお聞かせ下さい．子どもの頃，何をして遊びましたか？」
\end{enumerate}

被験者への教示としては，「各話題について，対話を終了したくなったら『バイバイ』という発話でいつでも対話の終了が可能である」ことを示したのみで，事前に練習しなかった．これは，事前練習が評価に影響することを避けるためである．

以上の実験設定のもと，被験者には5章までに述べた方法で構築した傾聴システムとの対話を体験してもらい，実験終了後，アンケートによる主観評価や意見を収集した．


\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f12.eps}
\end{center}
\caption{継続対話時間に関するヒストグラム}
\label{fig:12}
\end{figure}

\subsection{継続対話時間}

はじめに，継続対話時間に関する評価結果について述べる．対話が長く継続するということは，「より多くのことを話せるように助ける」という傾聴の本質的な点であり，システムの重要な客観的評価基準の一つと考えられる．なお，ここでの継続対話時間とは，上記2種類の各話題において，システム側からのスタートの発話からユーザが対話を終了させる（＝「バイバイ」と発話）までの時間のことである．継続対話時間に関する結果を図12に，また，継続対話時間毎の平均発話数，および，平均発話単語数を表25，表26に示す．

話題が「印象深い旅行」の場合は，45.5\% (50/110)の被験者が2分以上（ユーザ発話数の平均12.40）対話を継続していた．一方，話題が「子どもの頃の遊び」の場合，95.5\% (105/110)の被験者が2分以内（ユーザ発話数の平均4.76）に対話を終了していた．対話継続時間の平均はそれぞれ，1分46秒，1分8秒であり，「印象深い旅行」の方が対話が継続しやすいことがわかった．これは，話題が「印象深い旅行」の場合，旅先で自分がとった行動を思い出すことにより，話す内容がスムーズに思い浮かびやすいのに対し，話題が「子どもの頃の遊び」の場合，「何をして遊んだか？」を答えた後，何を話して良いのかなかなか思い浮かばないことが原因の一つとして考えられる．継続時間について何分以上なら良いというような絶対評価を行うことは難しいが，旅行の話題では3分以上対話が継続した被験者が観察されるなど，ロボットでも比較的長い時間傾聴を行えることが分かった．

\begin{table}[t]
\caption{継続対話時間毎の平均発話数，および，平均発話単語数（印象深い旅行）}
\label{table:25}
\input{01table25.txt}
\end{table} 
\begin{table}[t]
\caption{継続対話時間毎の平均発話数，および，平均発話単語数（子どもの頃の遊び）}
\label{table:26}
\input{01table26.txt}
\end{table} 

なお，1分以内に対話が終了してしまった事例を分析したところ，主に，次の2つの現象が見られた．

\begin{description}
\item[(1)　最初のユーザ発話に対して，誤認識により不適切な応答を生成している]\mbox{}\\
例1　Usr: 公園でよく遊びました． ⇒ Sys: いつを過ぎたんですか？\\
例2　Usr: 鬼ごっこをして． ⇒ Sys: 子猫ですか．\\
例3　Usr: え？っと，留学と旅行ですね． ⇒ Sys: 遊学ですか．

\item[(2)　システムから問い返し応答がないため，ユーザが次に何を話して良いか分からない]\mbox{}\\
例1　Usr: ショッピングです．⇒ Sys: ショッピングですか．\\
例2　Usr: かくれんぼ．⇒ Sys: かくれんぼですか．
\end{description}

いずれの場合も，ユーザが早々に「対話がつまらない」と感じて対話を終了させた（『バイバイ』と発話した）と考えられる．ここで，(1)については，6.1節で述べたように，システムから「これまでにどこに行きましたか？」や「何をして遊びましたか？」と話し始め，最初のユーザ発話の認識が高精度で行えるようにユーザ発話を誘導したにも関わらず，誤認識した事例である．誤認識を防ぐ手段として，認識信頼度判定の閾値を高くすることも考えられるが，その場合のシステム応答は相槌となり，ユーザに最初に与える印象が改善されるとは考えにくい．したがって，音声認識性能の向上が重要な課題となる．一方，(2)については，音声認識精度ではなく，対話を継続させるための応答生成の課題である．(2)の例にあるように，名詞（格要素）のみが発話された場合，提案手法では，問い返し応答として，適切と判断された場合にのみ，その詳細を尋ねる応答しか生成されない．したがって，この例のように，「どんな」や「どこの」などの疑問詞で問い返すことが不適切だと判定された場合には，その名詞について話題を広げることができない．このような事例の対策としては，例えば，(2)例2で，「かくれんぼ」と「鬼ごっこ」は関連が深い，という知識を利用して，「かくれんぼですか．鬼ごっこもしましたか？」といった問い返し応答を生成することなどが考えられる．また，本論文では，ユーザの1発話のみを利用して応答を生成しているが，過去のユーザ発話を利用することにより，さらに多様な応答生成が可能になると考えられる．その際には，ゼロ代名詞などの省略された情報の補完が重要な課題となる．今後は，例えば，今村らの手法\cite{no49}を用いてゼロ代名詞照応解析により項を補完した上で応答生成を行うことなども検討していきたい．


\subsection{応答正解率}

次に，応答正解率に関する評価結果について述べる．110名の被験者以外の2名の評価者が，ユーザ発話とそれに対するシステム応答の全ペアに対し，応答の適切性を主観で判断し，両名が共に「適切」と判定したシステム応答のみを正解とした．なお，相槌が生成されている場合は，「相槌応答」として分類した．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f13.eps}
\end{center}
\caption{生成されたシステム応答の分類結果}
\label{fig:13}
\end{figure}

まず，図13に，生成されたシステム応答の「正解応答」「誤応答」「相槌応答」の割合を示す．なお，後述するように，相槌応答についても「適切」「不適切」の分類を行っている．図13から，実験における相槌応答は全体の38.0\% ($34.9 + 3.1$)，また，相槌応答を除く応答を対象にした応答正解率は68.06\% (42.2/62.0)であった．以降では，まず，相槌を除く応答を対象に考察を行い，次に，相槌も含めた応答全体についての考察を行う．

図14に，相槌を除く応答を対象にした，年代別／男女別の応答正解率の結果を示す．この結果から，男女別では女性に対する応答正解率が，年代別では20代〜40代に対する応答正解率が相対的に高いことが分かる．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f14.eps}
\end{center}
\caption{相槌を除く応答を対象にした応答正解率（男女別／年代別）}
\label{fig:14}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f15.eps}
\end{center}
\caption{生成されたシステム応答種別毎の割合}
\label{fig:15}
\end{figure}


次に，図15に，生成されたシステム応答種別毎の割合，および，図16に，システム応答種別毎の正解率を示す．図16から，共感応答（e.g., それは良かったですね．），および，感情・形容表現の理由を尋ねる問い返し（e.g., どういう所がおもしろかったんですか？）については約80\%程度と高い精度が得られているが，不足格判別に基づく問い返し（e.g., どこで遊んだんですか？）については，他の応答種別と比べ著しく精度が低いことが分かる．ここで，共感応答，および，感情・形容表現の理由を尋ねる問い返しの精度が高い理由としては，次のことが考えられる．

\begin{figure}[t]
\begin{center}
\includegraphics{24-1ia1f16.eps}
\end{center}
\caption{生成されたシステム応答種別毎の応答正解率}
\label{fig:16}
\end{figure}

\begin{itemize}
\item 共感応答は，認識結果を直接的に用いて応答を生成するのではなく，感情推定結果を利用するため，仮に誤認識結果が含まれていたとしても，感情推定結果として正しければ適切な共感応答が可能となる．

\item 感情・形容表現の理由を尋ねる問い返しは，最終述語が「おもしろい」や「楽しい」の場合に生成されるが，このようなユーザ発話は，システムからの「感想を尋ねる応答（e.g., 〜に行ったんですか．どうでしたか？）」に対して発話されることが多く，しかも多くの場合は，「楽しかったよ」といった短い発話でユーザが返答するため，精度良く認識することが可能となる．また，当該応答の生成が適切であるかどうかを判定するための辞書は人手により作成されているため，辞書の精度も高い．
\end{itemize}

一方，不足格判別に基づく問い返しの応答精度が低い理由としては，誤認識結果を利用した応答が生成されていることに加え，次のことが挙げられる．

\begin{description}
\item[(1) 格情報が含まれているにも関わらず，当該格を不足格と判別してしまう]\mbox{}\\
例1　Usr: ご飯を食べたりしました ⇒ Sys: 何をしたんですか？\\
例2　Usr: 缶蹴りしました ⇒ Sys: 何をしたんですか？

\item[(2) 最終述語が「〜した」の場合に，「した」のみを最終述語として抽出してしまう]\mbox{}\\
例1　Usr: ご飯を食べたりしました ⇒ Sys: 何をしたんですか？\\
例2　Usr: 缶蹴りしました ⇒ Sys: 何をしたんですか？

\item[(3) 深層格解析エラーにより，必須格辞書に誤りがある]\mbox{}\\
例　Usr: 海で泳ぎました ⇒ Sys: どこを泳いだんですか？
\end{description}

ここで，(1)の例1は，ユーザ発話中の格助詞「二」が，認識信頼度判定アルゴリズムによって「信頼できない」と判定され，結果として不足格と判別された例である．4.1.3節で述べた通り，我々の提案手法では，格助詞の音声認識誤りが極力少なくなるような対策をしているが，(1)の例1のような事例も観察された．誤応答を減らすためのシステム改良は今後も続けていきたい．また，(1)の例2は，ユーザ発話において格助詞が省略されたことにより，不足格判別を誤った例である．4.1.3節でも述べたように，このような場合の不足格判別については今後の課題である．

一方，(2)の例については，2つとも，最終述語が適切に抽出できなかった例である．2.2節で述べた通り，「最終述語の不足格判別に基づく問い返し」はユーザ発話の最終述語が動詞，もしくは，「サ変名詞＋する」の場合に生成されるが，上述の事例のように，「する」はサ変名詞以外の品詞と接続する場合も多い．最終述語の抽出精度の向上については今後の課題である．

最後に，(3)の例については，深層格解析エラーにより，必須格辞書に誤りがある例である．具体的には，動詞「泳ぐ」について，深層格解析の段階で，「〜で泳ぐ」の格助詞「デ」を深層格「place (act)」として，一方，「〜を泳ぐ」の格助詞「ヲ」を深層格「object」として解析し，双方ともが必須格として登録されたため，既に泳いだ「場所」が発話されたにも関わらず，その情報を誤って不足格として問い返している．この例については，「デ」「ヲ」共に「動作の場所」を表す深層格であることを適切に解析する，というように，深層格解析の精度向上が必要である．

ここまでで，「相槌応答」を除いた応答を対象に述べてきた．次に，「相槌応答」も含めた応答全体について述べる．我々は，誤認識を含む場合でもロバストに応答を生成する手法として，認識信頼度を判定し，信頼度が低い場合には相槌を生成することで，誤認識結果を用いた応答生成を防ぐ手法を提案した．しかし，ユーザが発話を終える前に生成された相槌（e.g., Usr: 子供のころは，す…… ⇒ Sys: そうですか），あるいは，システム応答が聞き取れずユーザがシステムに問い返した際に生成された相槌（e.g., Usr: はい？ ⇒ Sys: そうですか）などは，誤認識結果を用いた応答ではないものの，応答として不適切であると考えられる．今回の実験で生成された相槌応答（応答全体の38.0\%）の中に，このような不適切な相槌が8.04\%（応答全体の3.1\%）含まれていた．前者については，発話の区切りを検出する性能の向上，後者については，ユーザ発話が問い返しであるかどうかを判定する機能の構築が必要である．

以上を踏まえて，適切な相槌も含めた応答正解率は77.1\%であった．また，図17に，適切な相槌も含めた年代別／男女別の応答正解率を示す．男女別，年代別で，応答正解率に極端に大きな差はないが，男性では50, 70代，女性では40代の応答正解率がやや低いことがわかる．最後に，図18に，年代別／男女別の相槌応答の割合を示す．これより，20, 30代，および，50, 60代の女性については，相槌応答の割合が低く，一方，70代については，男女ともに相槌応答の割合が高いことが分かる．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f17.eps}
\end{center}
\caption{適切な相槌も含めた応答正解率（男女別／年代別）}
\label{fig:17}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f18.eps}
\end{center}
\caption{相槌応答の割合（男女別／年代別）}
\label{fig:18}
\end{figure}


\subsection{アンケートによる主観評価結果}

『システムと話してみて，満足度はどのくらいでしたか？』という質問に対する，年代別／男女別の結果を図19に示す．全体的に女性の評価が高かったことがわかる．特に50代以上の女性と70代の男性の満足度は相対的に高く，高齢者に対して有効なシステムとなる可能性が示唆された．その中でも70代については，相槌応答の割合が高く（図18），単調な対話であったにも関わらず，満足度が顕著に低下していないことから，単調な対話でも受容性が高いことも示唆された．40代女性の評価が低いのは，50, 60代の女性と比べて応答正解率が低い（図17），および，相槌応答の割合が高い（図18）ことが原因と考えられる．一方，男性については，30, 40代の被験者の評価が他の年代に比べて相対的に低く，満足感は与えられていないことがわかった．ただし，女性の結果とは異なり，30, 40代の男性に対する応答正解率が低い，あるいは，相槌応答の割合が高い，といった傾向は見られない．この点についての要因の解明は，今後の課題とする．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f19.eps}
\end{center}
\hangcaption{設問『システムと話して，満足度はどのくらいでしたか？』に対する主観評価結果（男女別／年代別）}
\label{fig:19}
\end{figure}

\begin{table}[b]
\centering
\caption{ユーザから得られた自由記述の感想（抜粋）}
\label{table:27}
\input{01table27.txt}
\end{table}

また，実験後，ユーザから得られた自由記述の感想の抜粋を，表27に示す．表27のネガティブな意見や対話ロボットへの要望については，今後の開発に生かしたい．

\begin{figure}[b]
\begin{center}
\includegraphics{24-1ia1f20.eps}
\end{center}
\caption{実際の対話例}
\label{fig:20}
\end{figure}


\subsection{実際の対話例}

最後に，実際の対話例\cite{no50}を図20に示す．なお，図中のシステム応答「そこで何をしたんですか」「そこで他になにをしましたか？」「他には何をしましたか？」については，本実験で対象とした2つの話題に合わせて，問い返し応答として用意した定型応答であり，ユーザが沈黙した場合などに発話を促すために生成される．この結果より，対話が大きな破綻なく継続していることがわかる．


\section{まとめ}

本稿では，回想法の効果による高齢者の認知症予防や，独居高齢者の孤独感の軽減，あるいは，若い世代のストレス軽減，などへの貢献を目的として，音声対話ロボットのための傾聴システムの開発について述べた．ユーザ発話中の述語の不足格判別などによる「繰り返し／問い返し応答」，ユーザ発話に対する感情推定による「共感応答」の生成アルゴリズム，および，それらの応答と「相槌応答」とを，音声認識信頼度を考慮した上で適切に生成するアルゴリズムを提案した．110名の一般被験者に対する評価実験の結果，「印象深い旅行」を話題とした場合で，45.5\%の被験者が2分以上（ユーザ発話数平均12.40）対話を継続していた．また，システムの応答を主観的に評価した結果，相槌を除いた場合で約68\%，適切な相槌も含めた場合で約77\%のユーザ発話に対して対話を破綻させることなく応答生成ができていた．また，生成された応答種別毎では，共感応答や感情・形容表現の理由を尋ねる問い返しについては高い応答正解率が得られていたが，一方で，特に不足格判別に基づく問い返しについては応答正解率が低かった．さらに，被験者へのアンケートの結果，特に高齢の被験者から肯定的な主観評価結果が得られた．

今後の課題としては，主に，下記の事項が挙げられる．これらの問題を解決することにより，高齢者のみならず，若い世代に対する満足度向上につながると期待される．
\begin{enumerate}
\item 深層格解析精度の向上（格助詞の省略，および，動詞の受動態・使役態への対応）

\item より多様な応答の生成（名詞の関連語知識の利用や，過去のユーザ発話の利用など）

\item 発話区切り検出精度の向上（ユーザ発話を遮って応答生成を行わない）

\item ユーザ発話の談話行為推定（ユーザの問い返しなどに対して相槌を生成しない）

\item 音声認識精度の向上
\end{enumerate}

また，実際のユーザへの効果の評価として，本傾聴システムを体験したことによる，ユーザの話し方や顔表情などの状態変化に関する評価を行い，システムの改良を進める予定である．


\acknowledgment

Web上の5億文のテキストを提供して頂いた京都大学の河原大輔氏に深く感謝致します．




\bibliographystyle{jnlpbbl_1.5}
\nocite{*}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Balahur \BBA\ Hristo}{Balahur \BBA\ Hristo}{2016}]{no31}
Balahur, A.\BBACOMMA\ \BBA\ Hristo, T. \BBOP 2016\BBCP.
\newblock \BBOQ Detecting Implicit Expressions of Affect from Text using
  Semantic Knowledge on Common Concept Properties.\BBCQ\
\newblock In {\Bem the 10th International Conference on Language Resources and
  Evaluation (LREC 2016)}, \mbox{\BPGS\ 1165--1170}.

\bibitem[\protect\BCAY{Banchs \BBA\ Li}{Banchs \BBA\ Li}{2012}]{no13}
Banchs, R.\BBACOMMA\ \BBA\ Li, H. \BBOP 2012\BBCP.
\newblock \BBOQ IRIS: A Chat-oriented Dialogue System based on the Vector Space
  Model.\BBCQ\
\newblock In {\Bem the 50th Annual Meeting of the Association for Computational
  Linguistics (ACL)}, \mbox{\BPGS\ 37--42}.

\bibitem[\protect\BCAY{Bellegarda}{Bellegarda}{2013}]{no8}
Bellegarda, J. \BBOP 2013\BBCP.
\newblock \BBOQ Large-Scale Personal Assistant Technology Deployment: The Siri
  Experience.\BBCQ\
\newblock In {\Bem INTERSPEECH}, \mbox{\BPGS\ 2029--2033}.

\bibitem[\protect\BCAY{Butler}{Butler}{1963}]{no6}
Butler, R. \BBOP 1963\BBCP.
\newblock \BBOQ The Life Review: An Interpretation of Reminiscence in the
  Aged.\BBCQ\
\newblock {\Bem Psychiatry}, {\Bbf 26}, \mbox{\BPGS\ 65--76}.

\bibitem[\protect\BCAY{De~Mori, Bechet, Hakkani-Tur, McTear, Riccardi, \BBA\
  Tur}{De~Mori et~al.}{2008}]{no44}
De~Mori, R., Bechet, F., Hakkani-Tur, D., McTear, M., Riccardi, G., \BBA\ Tur,
  G. \BBOP 2008\BBCP.
\newblock \BBOQ Spoken Language Understanding.\BBCQ\
\newblock {\Bem IEEE Signal Processing Magazine}, {\Bbf 25}  (3), \mbox{\BPGS\
  50--58}.

\bibitem[\protect\BCAY{DeVault, Artstein, Benn, Dey, Fast, Gainer, Georgila,
  Gratch, Hartholt, Lhommet, Lucas, Marsella, Morbini, Nazarian, Scherer,
  Stratou, Suri, Traum, Wood, Xu, Rizzo, \BBA\ Morency}{DeVault
  et~al.}{2014}]{no29}
DeVault, D., Artstein, R., Benn, G., Dey, T., Fast, E., Gainer, A., Georgila,
  K., Gratch, J., Hartholt, A., Lhommet, M., Lucas, G., Marsella, S., Morbini,
  F., Nazarian, A., Scherer, S., Stratou, G., Suri, A., Traum, D., Wood, R.,
  Xu, Y., Rizzo, A., \BBA\ Morency, L. \BBOP 2014\BBCP.
\newblock \BBOQ SimSensei Kiosk: A Virtual Human Interviewer for Healthcare
  Decision Support.\BBCQ\
\newblock In {\Bem the 2014 International Conference on Autonomous Agents and
  Multi-agent Systems}, \mbox{\BPGS\ 137--139}.

\bibitem[\protect\BCAY{藤原\JBA 伊藤\JBA 荒木}{藤原 \Jetal }{2005}]{no43}
藤原敬記\JBA 伊藤敏彦\JBA 荒木健治 \BBOP 2005\BBCP.
\newblock 音声言語理解のための助詞・付属語の信頼度利用に関する調査.\
\newblock \Jem{日本音響学会 2006 年春季研究発表会講演論文集}, {\Bbf 1-P-28},
  \mbox{\BPGS\ 199--200}.

\bibitem[\protect\BCAY{Gordon \BBA\ Swanson}{Gordon \BBA\ Swanson}{2009}]{no40}
Gordon, A.\BBACOMMA\ \BBA\ Swanson, R. \BBOP 2009\BBCP.
\newblock \BBOQ Identifying Personal Stories in Millions of Weblog
  Entries.\BBCQ\
\newblock In {\Bem the 3rd International Conference on Weblogs and Social
  Media, Data Challenge Workshop}, \mbox{\BPGS\ 16--23}.

\bibitem[\protect\BCAY{Han, Bang, Ryu, \BBA\ Lee}{Han et~al.}{2015}]{no17}
Han, S., Bang, J., Ryu, S., \BBA\ Lee, G.~G. \BBOP 2015\BBCP.
\newblock \BBOQ Exploiting Knowledge Base to Generate Responses for Natural
  Language Dialog Listening Agents.\BBCQ\
\newblock In {\Bem the 16th Annual Meeting of the Special Interest Group on
  Discourse and Dialogue (SIGDIAL)}, \mbox{\BPGS\ 129--133}.

\bibitem[\protect\BCAY{Han, Lee, Lee, \BBA\ Lee}{Han et~al.}{2013}]{no16}
Han, S., Lee, K., Lee, D., \BBA\ Lee, G.~G. \BBOP 2013\BBCP.
\newblock \BBOQ Counseling Dialog System with 5W1H Extraction.\BBCQ\
\newblock In {\Bem the 14th Annual Meeting of the Special Interest Group on
  Discourse and Dialogue (SIGDIAL)}, \mbox{\BPGS\ 349--353}.

\bibitem[\protect\BCAY{長谷川\JBA 鍛冶\JBA 吉永\JBA 豊田}{長谷川 \Jetal
  }{2014}]{no35}
長谷川貴之\JBA 鍛冶伸裕\JBA 吉永直樹\JBA 豊田正史 \BBOP 2014\BBCP.
\newblock オンライン上の対話における聞き手の感情の予測と喚起.\
\newblock \Jem{人工知能学会論文誌}, {\Bbf 29}  (1), \mbox{\BPGS\ 90--99}.

\bibitem[\protect\BCAY{Hazen, Seneff, \BBA\ Polifroni}{Hazen
  et~al.}{2002}]{no41}
Hazen, T.~J., Seneff, S., \BBA\ Polifroni, J. \BBOP 2002\BBCP.
\newblock \BBOQ Recognition Confidence Scoring and its Use in Speech
  Understanding Systems.\BBCQ\
\newblock {\Bem Computer Speech \& Language}, {\Bbf 16}  (1), \mbox{\BPGS\
  49--67}.

\bibitem[\protect\BCAY{東中\JBA 貞光\JBA 内田\JBA 吉村}{東中 \Jetal
  }{2013}]{no10}
東中竜一郎\JBA 貞光九月\JBA 内田渉\JBA 吉村健 \BBOP 2013\BBCP.
\newblock しゃべってコンシェルにおける質問応答技術.\
\newblock \Jem{NTT 技術ジャーナル}, {\Bbf 25}  (2), \mbox{\BPGS\ 56--59}.

\bibitem[\protect\BCAY{Higashinaka, \mbox{Funakoshi}, Araki, Tsukahara,
  Kobayashi, \BBA\ Mizukami}{Higashinaka et~al.}{2015}]{no15}
Higashinaka, R., \mbox{Funakoshi}, K., Araki, M., Tsukahara, H., Kobayashi, Y.,
  \BBA\ Mizukami, M. \BBOP 2015\BBCP.
\newblock \BBOQ Towards Taxonomy of Errors in Chat-oriented Dialogue
  Systems.\BBCQ\
\newblock In {\Bem the 16th Annual Meeting of the Special Interest Group on
  Discourse and Dialogue (SIGDIAL)}, \mbox{\BPGS\ 97--95}.

\bibitem[\protect\BCAY{Higashinaka, \mbox{Imamura}, Meguro, Miyazaki,
  Kobayashi, Sugiyama, \mbox{Hirano}, Makino, \BBA\ Matsuo}{Higashinaka
  et~al.}{2014}]{no14}
Higashinaka, R., \mbox{Imamura}, K., Meguro, T., Miyazaki, C., Kobayashi, N.,
  Sugiyama, H., \mbox{Hirano}, T., Makino, T., \BBA\ Matsuo, Y. \BBOP
  2014\BBCP.
\newblock \BBOQ Towards an Open-domain Conversational System Fully Based on
  Natural Language Processing.\BBCQ\
\newblock In {\Bem the 25th International Conference on Computational
  Linguistics (COLING)}, \mbox{\BPGS\ 928--939}.

\bibitem[\protect\BCAY{池見}{池見}{1996}]{no2}
池見陽 \BBOP 1996\BBCP.
\newblock 傾聴とフォーカシングの臨床心理学.\
\newblock \Jem{聴能言語学研究}, {\Bbf 13}  (3), \mbox{\BPGS\ 213--220}.

\bibitem[\protect\BCAY{今村\JBA 東中\JBA 泉}{今村 \Jetal }{2015}]{no49}
今村賢治\JBA 東中竜一郎\JBA 泉朋子 \BBOP 2015\BBCP.
\newblock 対話解析のためのゼロ代名詞照応解析付き述語項構造解析.\
\newblock \Jem{自然言語処理}, {\Bbf 22}  (1), \mbox{\BPGS\ 3--26}.

\bibitem[\protect\BCAY{乾\JBA 奥村}{乾\JBA 奥村}{2006}]{no33}
乾孝司\JBA 奥村学 \BBOP 2006\BBCP.
\newblock テキストを対象とした評価情報の分析に関する研究動向.\
\newblock \Jem{自然言語処理}, {\Bbf 13}  (3), \mbox{\BPGS\ 201--241}.

\bibitem[\protect\BCAY{磯\JBA 颯々野}{磯\JBA 颯々野}{2013}]{no9}
磯健一\JBA 颯々野学 \BBOP 2013\BBCP.
\newblock 「音声アシスト」の音声認識と自然言語処理の開発.\
\newblock \Jem{情報処理学会研究報告}, {\Bbf 2013-SLP-98}  (4), \mbox{\BPGS\
  1--6}.

\bibitem[\protect\BCAY{河原}{河原}{2013}]{no11}
河原達也 \BBOP 2013\BBCP.
\newblock 音声対話システムの進化と淘汰—歴史と最近の技術動向—.\
\newblock \Jem{人工知能学会誌}, {\Bbf 28}  (1), \mbox{\BPGS\ 45--51}.

\bibitem[\protect\BCAY{Kawahara \BBA\ Kurohashi}{Kawahara \BBA\
  Kurohashi}{2006}]{no38}
Kawahara, D.\BBACOMMA\ \BBA\ Kurohashi, S. \BBOP 2006\BBCP.
\newblock \BBOQ Case Frame Compilation from the Web using High-Performance
  Computing.\BBCQ\
\newblock In {\Bem the 5th International Conference on Language Resources and
  Evaluation}, \mbox{\BPGS\ 1344--1347}.

\bibitem[\protect\BCAY{河原\JBA 李}{河原\JBA 李}{2005}]{no42}
河原達也\JBA 李晃伸 \BBOP 2005\BBCP.
\newblock 連続音声認識ソフトウェア Julius.\
\newblock \Jem{人工知能学会誌}, {\Bbf 20}  (1), \mbox{\BPGS\ 41--49}.

\bibitem[\protect\BCAY{Kawahara, Uesato, Yoshino, \BBA\ Takanashi}{Kawahara
  et~al.}{2016}]{no34}
Kawahara, T., Uesato, M., Yoshino, K., \BBA\ Takanashi, K. \BBOP 2016\BBCP.
\newblock \BBOQ Toward Adaptive Generation of Backchannels for Attentive
  Listening Agents.\BBCQ\
\newblock In {\Bem International Workshop Spoken Dialogue Systems (IWSDS)},
  \mbox{\BPGS\ 1--10}.

\bibitem[\protect\BCAY{小林\JBA 乾\JBA 松本\JBA 立石\JBA 福島}{小林 \Jetal
  }{2005}]{no52}
小林のぞみ\JBA 乾健太郎\JBA 松本裕治\JBA 立石健二\JBA 福島俊一 \BBOP 2005\BBCP.
\newblock 意見抽出のための評価表現の収集.\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (2), \mbox{\BPGS\ 203--222}.

\bibitem[\protect\BCAY{小林\JBA 山本\JBA 横山\JBA 土井}{小林 \Jetal
  }{2010}]{no25}
小林優佳\JBA 山本大介\JBA 横山祥恵\JBA 土井美和子 \BBOP 2010\BBCP.
\newblock
  高齢者向け対話インタフェース—雑談時における関心度検出方法とそれを利用した対話システム—.\
\newblock \Jem{人工知能学会言語・音声理解と対話処理研究会}, {\Bbf
  SIG-SLUD-B001-01}, \mbox{\BPGS\ 1--6}.

\bibitem[\protect\BCAY{小林\JBA 山本\JBA 土井}{小林 \Jetal }{2011}]{no26}
小林優佳\JBA 山本大介\JBA 土井美和子 \BBOP 2011\BBCP.
\newblock
  高齢者向け対話インタフェース—発話間の共起性を利用した傾聴対話の基礎検討—.\
\newblock \Jem{情報科学技術フォーラム FIT2011（第 2 分冊）}, \mbox{\BPGS\
  253--256}.

\bibitem[\protect\BCAY{小林\JBA 山本\JBA 土井}{小林 \Jetal }{2012}]{no27}
小林優佳\JBA 山本大介\JBA 土井美和子 \BBOP 2012\BBCP.
\newblock
  高齢者向け対話インタフェース—病院スタッフ・患者間の対話モデルを使用したコミュニケーションロボツト—.\
\newblock \Jem{人工知能学会言語・音声理解と対話処理研究会}, {\Bbf
  SIG-SLUD-B103-12}, \mbox{\BPGS\ 253--256}.

\bibitem[\protect\BCAY{国立国語研究所}{国立国語研究所}{2004}]{no48}
国立国語研究所 \BBOP 2004\BBCP.
\newblock \Jem{分類語彙表—増補改定版—}.
\newblock 秀英出版.

\bibitem[\protect\BCAY{工藤\JBA 松本}{工藤\JBA 松本}{2004}]{no54}
工藤拓\JBA 松本裕治 \BBOP 2004\BBCP.
\newblock 半構造化テキスト分類のためのブースティングアルゴリズム.\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 45}  (9), \mbox{\BPGS\ 2146--2156}.

\bibitem[\protect\BCAY{倉島\JBA 藤村\JBA 奥田}{倉島 \Jetal }{2009}]{no39}
倉島健\JBA 藤村考\JBA 奥田英範 \BBOP 2009\BBCP.
\newblock 大規模テキストからの経験マイニング.\
\newblock \Jem{電子情報通信学会論文誌}, {\Bbf J92-D}  (3), \mbox{\BPGS\
  301--310}.

\bibitem[\protect\BCAY{黒川}{黒川}{2005}]{no7}
黒川由紀子 \BBOP 2005\BBCP.
\newblock \Jem{高齢者の心理療法—回想法}.
\newblock 誠信書房.

\bibitem[\protect\BCAY{Lee, Kawahara, \BBA\ Shikano}{Lee et~al.}{2001}]{no36}
Lee, A., Kawahara, T., \BBA\ Shikano, K. \BBOP 2001\BBCP.
\newblock \BBOQ Julius---An Open Source Real-time Large Vocabulary Recognition
  Engine.\BBCQ\
\newblock In {\Bem European Conference on Speech Communication and Technology
  (EUROSPEECH2001)}, \mbox{\BPGS\ 1692--1694}.

\bibitem[\protect\BCAY{李}{李}{2000}]{no37}
李晃伸 \BBOP 2000\BBCP.
\newblock Phonetic Tied-Mixture モデルを用いた大語彙連続音声認識.\
\newblock \Jem{電子情報通信学会論文誌}, {\Bbf J83-DII}  (12), \mbox{\BPGS\
  2517--2525}.

\bibitem[\protect\BCAY{毎日新聞社}{毎日新聞社}{1991  1995}]{no46}
毎日新聞社 \BBOP 1991--1995\BBCP.
\newblock CD—毎日新聞データ集91版〜95版.\
\newblock 日外アソシエーツ.

\bibitem[\protect\BCAY{目黒\JBA 東中\JBA 堂坂\JBA 南}{目黒 \Jetal
  }{2012}]{no22}
目黒豊美\JBA 東中竜一郎\JBA 堂坂浩二\JBA 南泰浩 \BBOP 2012\BBCP.
\newblock 聞き役対話の分析および分析に基づいた対話制御部の構築.\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 53}  (12), \mbox{\BPGS\ 2728--2801}.

\bibitem[\protect\BCAY{目黒\JBA 東中\JBA 堂坂\JBA 南\JBA 磯崎}{目黒 \Jetal
  }{2009}]{no20}
目黒豊美\JBA 東中竜一郎\JBA 堂坂浩二\JBA 南泰浩\JBA 磯崎秀樹 \BBOP 2009\BBCP.
\newblock 聞き役対話システムの構築を目的とした聞き役対話の分析.\
\newblock \Jem{情報処理学会研究報告}, \mbox{\BPGS\ 1--7}.

\bibitem[\protect\BCAY{目黒\JBA 東中\JBA 南\JBA 堂坂}{目黒 \Jetal
  }{2011}]{no21}
目黒豊美\JBA 東中竜一郎\JBA 南泰浩\JBA 堂坂浩二 \BBOP 2011\BBCP.
\newblock POMDP を用いた聞き役対話システムの対話制御.\
\newblock \Jem{言語処理学会第 17 回年次大会発表論文集（2011 年 3 月）},
  \mbox{\BPGS\ 912--915}.

\bibitem[\protect\BCAY{三島\JBA 久保田}{三島\JBA 久保田}{2003}]{no4}
三島徳雄\JBA 久保田進也 \BBOP 2003\BBCP.
\newblock \Jem{積極傾聴を学ぶ—発見的体験学習法の実際—}.
\newblock 中央労働災害防止協会.

\bibitem[\protect\BCAY{Morbini, Forbell, DeVault, Sagae, Traum, \BBA\
  Rizzo}{Morbini et~al.}{2012}]{no28}
Morbini, F., Forbell, E., DeVault, D., Sagae, K., Traum, D.~R., \BBA\ Rizzo, A.
  \BBOP 2012\BBCP.
\newblock \BBOQ A Mixed-Initiative Conversational Dialogue System for
  Healthcare.\BBCQ\
\newblock In {\Bem the 13th Annual Meeting of the Special Interest Group on
  Discourse and Dialogue (SIGDIAL)}, \mbox{\BPGS\ 137--139}.

\bibitem[\protect\BCAY{中村}{中村}{1993}]{no56}
中村明 \BBOP 1993\BBCP.
\newblock \Jem{感情表現辞書}.
\newblock 東京堂出版.

\bibitem[\protect\BCAY{日本電子化辞書研究所}{日本電子化辞書研究所}{2001}]{no45}
日本電子化辞書研究所 \BBOP 2001\BBCP.
\newblock \Jem{EDR 電子化辞書 2.0 版　使用説明書}.

\bibitem[\protect\BCAY{楡木}{楡木}{1989}]{no5}
楡木満生 \BBOP 1989\BBCP.
\newblock 積極的傾聴法.\
\newblock \Jem{医学教育}, {\Bbf 20}  (5), \mbox{\BPGS\ 341--346}.

\bibitem[\protect\BCAY{大石\JBA 松本}{大石\JBA 松本}{1995}]{no47}
大石亨\JBA 松本裕治 \BBOP 1995\BBCP.
\newblock 格パターン分析に基づく動詞の語彙知識獲得.\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 36}  (11), \mbox{\BPGS\ 2597--2610}.

\bibitem[\protect\BCAY{大竹\JBA 萩原}{大竹\JBA 萩原}{2012}]{no18}
大竹裕也\JBA 萩原将文 \BBOP 2012\BBCP.
\newblock 高齢者のための発話意図を考慮した対話システム.\
\newblock \Jem{日本感性工学会論文誌}, {\Bbf 11}  (2), \mbox{\BPGS\ 207--214}.

\bibitem[\protect\BCAY{大竹\JBA 萩原}{大竹\JBA 萩原}{2014}]{no19}
大竹裕也\JBA 萩原将文 \BBOP 2014\BBCP.
\newblock 評価表現による印象推定と傾聴型対話システムへの応用.\
\newblock \Jem{日本知能情報ファジィ学会誌}, {\Bbf 26}  (2), \mbox{\BPGS\
  617--626}.

\bibitem[\protect\BCAY{Plutchik}{Plutchik}{1980}]{no55}
Plutchik, R. \BBOP 1980\BBCP.
\newblock \BBOQ A General Psycho-evolutionary Theory of Emotion.\BBCQ\
\newblock In {\Bem Theories of Emotion}. Academic Press.

\bibitem[\protect\BCAY{下岡\JBA 徳久\JBA 吉村\JBA 星野\JBA 渡部}{下岡 \Jetal
  }{2010}]{no50}
下岡和也\JBA 徳久良子\JBA 吉村貴克\JBA 星野博之\JBA 渡部生聖 \BBOP 2010\BBCP.
\newblock 音声対話ロボットのための傾聴システムの開発.\
\newblock \Jem{人工知能学会言語・音声理解と対話処理研究会}, {\Bbf SIG-SLUD-58},
  \mbox{\BPGS\ 61--66}.

\bibitem[\protect\BCAY{総務省統計局}{総務省統計局}{2013}]{no1}
総務省統計局 \BBOP 2013\BBCP.
\newblock 高齢者の人口.\
\newblock http://www.stat.go.jp/data/topics/topi721.htm/.

\bibitem[\protect\BCAY{須田}{須田}{2013}]{no32}
須田行雄 \BBOP 2013\BBCP.
\newblock \Jem{回想法実施マニュアル}.
\newblock 第1回公募研究,一般社団法人日本産業カウンセラー協会.

\bibitem[\protect\BCAY{寺村}{寺村}{1982}]{no51}
寺村秀夫 \BBOP 1982\BBCP.
\newblock \Jem{日本語のシンタクスと意味}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{Tokuhisa, Inui, \BBA\ Matsumoto}{Tokuhisa
  et~al.}{2008}]{no12}
Tokuhisa, R., Inui, K., \BBA\ Matsumoto, Y. \BBOP 2008\BBCP.
\newblock \BBOQ Emotion Classification Using Massive Examples Extracted from
  the Web.\BBCQ\
\newblock In {\Bem the 22th International Conference on Computational
  Linguistics (COLING)}, \mbox{\BPGS\ 881--888}.

\bibitem[\protect\BCAY{Turney}{Turney}{2002}]{no53}
Turney, P. \BBOP 2002\BBCP.
\newblock \BBOQ Thumbs Up? Thumbs Down? Semantic Orientation Applied to
  Unsupervised Classification of Reviews.\BBCQ\
\newblock In {\Bem the 40th Annual Meeting of the Association for Computational
  Linguistics (ACL)}, \mbox{\BPGS\ 417--424}.

\bibitem[\protect\BCAY{ホールファミリーケア協会}{ホールファミリーケア協会}{2004}]{no3}
ホールファミリーケア協会 \BBOP 2004\BBCP.
\newblock \Jem{傾聴ボランティアのすすめ}.
\newblock 三省堂.

\bibitem[\protect\BCAY{Yamaguchi, Inoue, Yoshino, Takanashi, Ward, \BBA\
  Kawahara}{Yamaguchi et~al.}{2016}]{no30}
Yamaguchi, T., Inoue, K., Yoshino, K., Takanashi, K., Ward, N., \BBA\ Kawahara,
  T. \BBOP 2016\BBCP.
\newblock \BBOQ Analysis and Prediction of Morphological Patterns of
  Backchannels for Attentive Listening Agents.\BBCQ\
\newblock In {\Bem International Workshop Spoken Dialogue Systems (IWSDS)},
  \mbox{\BPGS\ 1--12}.

\bibitem[\protect\BCAY{山本\JBA 小林\JBA 横山\JBA 土井}{山本 \Jetal
  }{2009}]{no23}
山本大介\JBA 小林優佳\JBA 横山祥恵\JBA 土井美和子 \BBOP 2009\BBCP.
\newblock 高齢者対話インタフェース〜
  『話し相手』となって，お年寄りの生活を豊かに〜.\
\newblock \Jem{ヒューマンコミュニケーション基礎研究会}, {\Bbf 109}  (224),
  \mbox{\BPGS\ 47--51}.

\bibitem[\protect\BCAY{横山\JBA 山本\JBA 小林\JBA 土井}{横山 \Jetal
  }{2010}]{no24}
横山祥恵\JBA 山本大介\JBA 小林優佳\JBA 土井美和子 \BBOP 2010\BBCP.
\newblock
  高齢者向け対話インタフェース—雑談継続を目的とした話題提示・傾聴の切替式対話法—.\
\newblock \Jem{情報処理学会研究報告音声言語情報処理}, {\Bbf 2010-SLP-80}  (4),
  \mbox{\BPGS\ 1--6}.

\end{thebibliography}


\begin{biography}
\bioauthor{下岡　和也}{
2002年京都大学工学部情報学科卒業．2005年京都大学大学院知能情報学専攻修士課程修了．同年（株）豊田中央研究所入社．現在，空間情報処理とその応用に関する研究，開発に従事．
}
\bioauthor{徳久　良子}{
2001年九州工業大学大学院情報科学専攻修士課程修了．同年（株）豊田中央研究所入社．2009年奈良先端大学大学院博士後期課程修了．博士（工学）．感情や対話研究に従事．人工知能学会，情報処理学会，言語処理学会会員．
}
\bioauthor{吉村　貴克}{
1997年名古屋工業大学知能情報システム学科卒．2002年同大学大学院博士後期課程修了．博士（工学）．現在，（株）豊田中央研究所にて，車両の走行データのデータ処理とその応用に関する研究に従事．IEEE会員．
}
\bioauthor{星野　博之}{
1988年名古屋大学大学院工学研究科修士課程修了．同年（株）豊田中央研究入社，現在に至る．音声認識，ヒューマンインタフェース等の研究に従事．電子情報通信学会，日本音響学会他．博士（情報科学）．
}
\bioauthor{渡辺　生聖}{
2000年筑波大学第三学群情報学類卒業．2002年同大学院修士課程修了．現在，トヨタ自動車（株）パートナーロボット部にて，シニアライフ支援のための対話ロボットの開発に従事．
}

\end{biography}


\biodate



\end{document}
