<?xml version="1.0" ?>
<root>
  <jtitle>音声対話ロボットのための傾聴システムの開発</jtitle>
  <jauthor>下岡和也徳久良子吉村貴克星野博之渡部生聖</jauthor>
  <jabstract>高齢者の認知症や孤独感の軽減に貢献できる対話ロボット開発のため，回想法に基づく傾聴を行う音声対話システムの開発を行った．本システムは，ユーザ発話の音声認識結果に基づき，相槌をうったり，ユーザ発話を繰り返したり，ユーザ発話中の述語の不足格を尋ねたりする応答を生成する．さらに，感情推定結果に基づき，ユーザ発話に対して共感する応答を生成する．本システムの特徴は，音声認識結果に誤りが含まれることを前提とし，音声認識信頼度を考慮して応答を生成する点である．110名の一般被験者に対する評価実験の結果，「印象深い旅行」を話題とした場合で，45.5%の被験者が2分以上対話を継続できた．また，システムの応答を主観的に評価した結果，約77%のユーザ発話に対して対話を破綻させることなく応答生成ができた．さらに，被験者へのアンケートの結果，特に高齢の被験者から肯定的な主観評価結果が得られた．</jabstract>
  <jkeywords>音声対話ロボット，傾聴，回想法，高齢者</jkeywords>
  <section title="はじめに">日本は，2007年に高齢化率が21.5%となり「超高齢社会」になった．世界的に見ても，高齢者人口は今後も増加すると予想されており，認知症治療や独居高齢者の孤独死が大きな問題となっている．また，若い世代においても，学校でのいじめや会社でのストレスなどにより精神状態を崩すといった問題が起きている．このような問題を防ぐ手段として，カウンセリングや傾聴が有効であると言われている．しかし，高齢者の介護職は人手不足であり，また，家庭内においても，身近に，かつ，気軽に傾聴してもらえる人がいるとは限らない．このような背景のもと，本論文では，音声対話ロボットのための傾聴対話システムを提案する．我々は，介護施設や病院，あるいは，家庭に存在する音声対話ロボットが傾聴機能を有することにより，上記の問題の解決に貢献できると考えている．傾聴とは，話を聴いていることを伝え，相手の気持ちになって共感を示しつつ，より多くのことを話せるように支援する行為であり，聴き手は，表1に挙げる話し方をすることが重要であるとされる．また，傾聴行為の一つとして回想法が普及している．回想法とは，アメリカの精神科医Butlerによって1963年に提唱されたものであり，過去の思い出に，受容的共感的に聞き入ることで高齢者が自分自身の人生を再評価し，心理的な安定や記憶力の改善をはかるための心理療法である．本論文は，この回想法による傾聴を行う音声対話システムの実現を目指す．音声対話システムとして，音声認識率の向上やスマートフォンの普及などを背景に，AppleのSiriやYahoo!の音声アシスト，NTTドコモのしゃべってコンシェルといった様々な音声アプリケーションが登場し，一般のユーザにも身近なものになってきた．単語単位の音声入力や一問一答型の音声対話によって情報検索を行うタスク指向型対話システムに関しては，ある一定の性能に達したと考えられる．しかしながら，これらの音声対話システムは，音声認識率を高く保つために，ユーザが話す内容や発声の仕方（単語に区切るなど）を制限している．一方で，雑談対話のような達成すべきタスクを設定しない非タスク指向型対話システムも多く提案されており(Tokuhisa,Inui,andMatsumoto2008;BanchsandLi2012;Higashinaka,,Meguro,Miyazaki,Kobayashi,Sugiyama,Hirano,Makino,andMatsuo2014;,Funakoshi,Araki,Tsukahara,Kobayashi,andMizukami2015)no12,no13,no14,no15，傾聴対話システムも提案されている．傾聴対話システムの先行研究として，Hanらの研究，および，大竹らの研究がある．これらの研究は，いずれも対話システムによる傾聴の実現を目的としており，5W1H型の疑問文による問い返し（e.g.,Usr:とっても美味しかったよ．⇒Sys:何が美味しかったの？）や，固有名詞に関する知識ベースに基づく問い返し(e.g.,Usr:ILikeMessi.⇒Sys:WhatisMessi'sPosition?)，あるいは，評価表現辞書を用いた印象推定法による共感応答（e.g.,Usr:寒いしあまり炬燵から出たくないね．⇒Sys:炬燵は暖かいよね．）などの生成手法が提案されている．Hanら，大竹らの研究は傾聴対話システムの実現を目的としている点において，我々と同様である．しかしながら，これらの研究はテキスト入力を前提としているため，音声入力による対話システムへ適用する際には，音声認識誤りへの対応という課題が残る．傾聴のような聞き役対話システムの先行研究としては，目黒らの研究がある．この研究では，人同士の聞き役対話と雑談を収集し，それぞれの対話における対話行為の頻度を比較・分析し，さらに，聞き役対話の流れをユーザ満足度に基づいて制御する手法を提案している．ただし，この研究の目的は，人と同様の対話制御の実現であり，また，カウンセリングの側面を持つ傾聴ではなく，日常会話においてユーザが話しやすいシステムの実現を目指している点で，我々と異なる．また，山本，横山，小林らの研究は，対話相手の画像や音声から会話への関心度を推定し，関心度が低い場合は話題提示に，関心度が高い場合は傾聴に切り替えることで雑談を継続させる．発話間の共起性を用いて，音声の誤認識による不適切な応答を低減する工夫も導入している．さらに，病院のスタッフと患者間の対話から対話モデル（隣接ペア）を用いた病院での実証実験を行っており，ロボットとの対話の一定の有効性を示している．しかしながら，傾聴時において生成される応答は「単純相槌」「反復相槌」「質問」の3種類であり，ユーザ発話中のキーワードを抽出して生成されるため，ユーザ発話中に感情表現がない場合に（e.g.,Usr:混雑していたよ），傾聴において重要とされる「共感応答」（e.g.,Sys:それは残念でしたね）は扱っていない．同様に，戦場の兵士らの心のケアを目的とした傾聴対話システムSimCoachや，意思決定のサポートをするSimSenseiという対話システムも構築されている．SimCoachやSimSenseiはCGによるAgent対話システムで，発話内容に合わせた豊かな表情や頷きを表現することで，人間とのより自然な対話を実現している点も特徴である．我々は，対話システムの機能を，回想法をベースとした傾聴に特化することにより，音声認識や応答生成のアルゴリズムをシンプル化し，対話が破綻することなく継続し，高齢者から若者まで満足感を感じさせるシステムの実現を目指す．Yamaguchiら，Kawaharaらは，傾聴対話システムがユーザ発話に対して傾聴に適した相槌を生成する手法とその有効性について報告している．具体的には，人同士の傾聴時の対話で生じる相槌を対象として相槌が持つ先行発話との関係を分析し，それに基づいて相槌生成の形態，韻律を決定する手法を検討した．結果として，先行発話の境界のタイプや構文の複雑さに応じて相槌を変えることや，先行発話の韻律的特徴と同調するように韻律的特徴を制御することの有効性を述べている．相槌の生成ではタイミング，形態，韻律が重要であるが，今回のシステムでは，適切な内容の応答生成による対話の継続と満足感の評価を目的としている．本論文の貢献は，音声認識誤りを考慮した上で，傾聴時に重要な応答の生成を可能にする手法の提案，および，提案手法が実装されたシステムの有効性を，応答正解率の観点と，100人規模の被験者実験による対話継続時間と主観評価による満足度の観点で評価した点である．本論文の構成は，次のようになっている．第2章で本傾聴対話システムの概要を述べる．第3,4,5章は，本対話システムの機能である音声認識，および，認識信頼度判定部，問い返し応答生成部，共感応答生成部に関する実装に関して，第6章で評価実験と結果について説明し，第7章でまとめる</section>
  <section title="傾聴システムの概要">本章では，提案する傾聴システムの概要について述べる．</section>
  <subsection title="目指す対話例">図に，回想法の実施事例を示す．聞き手(S)は，話し手(A)が自身の過去を思い出しやすいように「問い返し」を重ね，それに対して話し手が答える，というスタイルがベースとなって対話が進行している．また，聞き手は，適切なタイミングで，「言い換え」「要約」「相槌」「共感」「繰り返し」といった，傾聴に重要とされる応答を行っていることが分かる．我々は，図1に示すような回想法による傾聴対話を実現するため，対話のテーマを「過去の出来事」に設定し，ユーザが語る過去の行動や感情に対して，音声認識誤りを考慮した上で，システムが傾聴に重要とされる応答を生成するための手法を提案する．なお，本論文では，上記の応答のうち，「繰り返し」「問い返し」「共感」「相槌」の4種類の応答を対象とする．なぜなら，「言い換え」および「要約」については「繰り返し」により粗い近似が可能である，と考えたためである．次節では，このような対話を実現するための傾聴システムの機能構成について述べる</subsection>
  <subsection title="傾聴システムの機能構成">提案する傾聴システムの機能構成を図2に示す．大きく分けて，「音声認識・信頼度判定」「繰り返し／問い返し応答の生成」「共感応答の生成」「相槌応答の生成」「応答選択」の5つの機能で構成されている．以下で，それぞれの機能の概要を述べる．■音声認識・信頼度判定入力されたユーザ発話を音声認識し，音声認識結果の信頼度を算出する．認識結果が信頼できると判定された場合は，当該認識結果を用いて，繰り返し／問い返し応答，および，共感応答を生成する．一方，信頼できないと判定された場合には，当該認識結果を用いた応答を行うのではなく，予め用意された相槌応答を生成する．これにより，誤認識結果を用いた応答生成を低減し，対話の破綻を防ぐ．詳細は3章で述べる．■繰り返し／問い返し応答の生成ユーザ発話の最終述語に着目し，認識信頼度が高いと判定された当該述語，および，当該述語が持つ格に基づき，繰り返し／問い返し応答を生成する．ここで，本論文では，以下のものを「述語」と定義し，ユーザ発話に含まれるこれら全ての表現のうち，最後に出現するものを「最終述語」として抽出する．表2に示す語のうち，表3に示す過去表現を伴っているもの．ただし，表2に示す語と，表3に示す過去表現との間にアスペクト（〜していた，〜しに行った），ムード（〜したかった，〜しなかった），ヴォイス（〜してもらった，〜された）などの表現が含まれる場合には，それらも含む．過去表現を伴うものに限定するのは，2.1節でも述べたように，本論文では，対話のテーマを「過去の出来事」に設定するためである．また，アスペクトやムードなどを考慮することにより，より自然なシステム応答の生成（e.g.,Usr:もっと食べたかったよ．Sys:食べたかったんですか．）を可能にする．問い返し応答は，以下で述べる(A),(B)の手法により生成する．これら2つの手法により，音声認識の信頼度が高い場合のみ，繰り返し応答や問い返し応答を生成することで，ユーザの発話内容を正確に繰り返し「聴いている」ことを示すと同時に，ユーザの過去を思い出しやすくし，次の発話を促す．(A)最終述語の不足格判別に基づく問い返しユーザ発話の最終述語が動詞，および，「サ変名詞＋する」の場合に，当該述語に対する不足格の判別を行うことにより，ユーザ発話には含まれない格を問い返す応答を生成する．図2の例では，ユーザ発話の最終述語「貰う」について，あらかじめ作成した動詞の必須格辞書を用いて，発話に必須格「誰から」が含まれていないことを判別し，『誰からもらったんですか？』を生成する．不足格判別に基づく問い返し応答の生成の詳細は4.1節で述べる．(B)辞書を用いた適切性判断に基づく問い返しユーザ発話の最終述語，および，格要素について，表4に示す問い返しが適切かどうかを辞書に基づき判断し，応答を生成する．図2の例では，最終述語「貰う」に対する感想，および，格要素「お花」の詳細については，問い返すことが適切であると判断され，『どうでしたか？』，および，『どんなお花ですか？』が生成されている．辞書を用いた適切性判断に基づく問い返しの詳細については4.2節で述べる．■共感応答の生成感情推定に関しては様々な研究がある．Balahurらは感情が非明示的に表現された文から感情を推定することを目的として，感情生起のトリガーとなる事態を記述したEmotiNetの構築を提案している．また，長谷川らは，聞き手にターゲットとなる感情を生起させるための応答生成手法を考案している．この中で長谷川らは，Twitterから構築した感情タグ付き対話コーパスを利用することで，「一緒に夕食に行かない？」という入力に対して「38度の熱があるのでいけません」と応答し，聞き手に「悲しみ」を喚起するような応答生成を実現している．これに対して我々は，話し手であるユーザの発話内容に対するユーザ自身の感情を推定し，その結果を利用することにより，ユーザへの共感応答を生成する．図2の例では，「誕生日にお花を貰う」に対するユーザ自身の感情が「嬉しい」であると推定した結果，共感応答『それは嬉しいですね』が生成されている．本論文では，この例のように，ユーザ発話中に明示的な感情表現（e.g.,嬉しい）が含まれていない場合であっても，音声認識誤りが含まれるユーザ発話からデータ駆動型で感情推定を行い，共感応答を生成する．詳細は5章で述べる．■相槌応答の生成認識信頼度が低いと判定された場合は，相槌応答を生成する．ここでは，相槌応答として，以下の2種類を生成する．システムの直前発話として，「感情・形容表現に対する理由を尋ねる」問い返し応答が生成されていた場合は，システムが「理解」あるいは「納得」したことをより強くユーザに示した方が，対話の自然性が向上するため，相槌『なるほど』を生成する．それ以外の発話が生成されていた場合は，相槌『そうですか』を生成する．■応答選択認識信頼度が高いと判定され，繰り返し応答，問い返し応答，共感応答のいずれかの応答が生成された場合は，以下の考えに基づき，繰り返し／問い返し応答を優先的に選択する．繰り返し応答により，「聴いている」ことを効果的にユーザに伝えることができる問い返し応答により，ユーザが過去の記憶を思い出しやすくなると同時に，対話をより継続することができる共感応答は，繰り返し応答と同時に出力することで，「共感している」ことをより効果的に伝えることができる具体的には，以下のように応答選択を行う．繰り返し／問い返し応答のいずれかが生成されている場合は，それらの中からランダムに選択する．なお，ランダムに選択した結果が繰り返し応答の場合は，繰り返し応答の後に続けて出力する応答を，以下のように選択する．問い返し応答が生成されている場合は，それらの中からランダムに選択し，繰り返し応答に続けて出力する（e.g.,お花を貰ったんですか．誰から貰ったんですか？）．問い返し応答は生成されていないが，共感応答が生成されている場合は，共感応答を繰り返し応答に続けて出力する（e.g.,お花を貰ったんですか．それは嬉しいですね．）．問い返し応答，共感応答のいずれも生成されていない場合は，繰り返し応答のみを出力する．繰り返し／問い返し応答が一切生成されていない場合は，共感応答を選択する</subsection>
  <section title="音声認識，および，認識信頼度アルゴリズム">本章では，音声認識，および，認識信頼度判定アルゴリズムについて述べる．</section>
  <subsection title="音声認識">まず，音声認識については，音声認識エンジンとしてJuliusを使用した．ここで，音響モデルは，不特定話者PTMモデルを利用した．言語モデルについては，想定する対話の特性を踏まえ，次の2点を考慮して作成した．なお，作成した言語モデルの語彙数は6万語である．(1)ユーザ発話の多くは，過去の行動や感情に関する発話であるシステムは回想法によりユーザに過去の出来事に関する発話を促すため，ユーザ発話には行動や感情に関する単語が含まれることが予想される．表5に試作版の傾聴システムへの入力例を示す．(2)ユーザ発話中に，名詞単独の発話が含まれる我々の傾聴システムは，問い返し応答の1つとして，不足格を問い返す応答を生成する．この問い返しに対し，ユーザが名詞単独で発話することが予想される（e.g.,Sys:どこで食べたんですか？Usr:お店）．以上2点を踏まえ，言語モデルは以下のように作成した．手順[1]：Web上のテキストデータにおいて，行動や感情が記述されやすいWebページを選別し，学習コーパスとした．学習コーパスの総量は，約215万ページ，3350万文であった．これまでに，行動や感情が記述されたコーパス作成手法として，大規模ブログデータから，人間の経験（時間と空間，動作とその対象，感情）を，適切な動詞と121個の感情語を用いて抽出する手法や，過去時制動詞を主とした特徴語と，未来と現在時制動詞を主とした特徴語により，個人的な話題をブログデータから抽出する手法などが提案されている．ここでは，言語モデル作成のためであり，コーパス内容をそれほど限定する必要がないことから，以下に示す方法でWebページを選別した．行動や感情が記述されやすい日記のWebページを学習データとする．具体的には，URLに「BLOG,Blog,blog,DIARY,Diary,diary」のいずれかを含むWebページを採用した．試作版の傾聴システムを用いて，開発者数名で予備実験したところ，対話ログに述語691語が含まれていた．この述語のうち，30語以上を1ページ内に含むWebページを採用した．これは，日記や物語などに関して記述されたWebページが中心である．手順[2]：上記コーパスに出現した名詞を対象に，それらの名詞単独からなる文（e.g.,映画）を，その出現頻度に従い学習コーパスに追加した．なお，追加した名詞は40,239語である</subsection>
  <subsection title="認識信頼度アルゴリズム">次に，認識信頼度判定アルゴリズムについて述べる．認識信頼度判定の目的は，繰り返し／問い返し応答生成，および，共感応答生成を行う前に，認識結果に含まれる認識誤りした単語を棄却し，信頼できると判定された認識結果のみを用いて，応答生成を行うことである．ここで，繰り返し／問い返し応答を生成する場合と，共感応答を生成する場合では，以下に述べるように，ユーザ発話中の着目すべき要素，つまり，信頼できるかどうかを判定すべき要素が異なると考えられる．まず，繰り返し／問い返し応答については，2.2節で述べたように，ユーザ発話中の最終述語，および，その述語が持つ格から生成される．つまり，繰り返し／問い返し応答の生成において，ユーザ発話中で着目すべき要素は〈格要素，格助詞，最終述語〉である．一方，共感応答を適切に生成するためには，〈格要素，格助詞，最終述語〉といったようにユーザ発話の一部分のみに着目することはできない．例えば，ユーザ発話『会社の飲み会で，すごく美味しいお酒を飲んだ』に対する共感応答（e.g.,それは楽しかったですね）や，『会社の飲み会で，我慢してお酒を飲んだ』に対する共感応答（e.g.,それは大変でしたね）を適切に生成するためには，「お酒を飲んだ」のみに着目するのではなく，「すごく美味しい」や「我慢して」といった情報も考慮した上で，それに対するユーザの感情を推定する必要がある．そのため，共感応答生成においては，生成に必要な要素をあらかじめ特定しておくことは難しい．つまり，共感応答を生成する場合には，認識結果全体に対する信頼度判定が必要となる．以上の考察に基づき，認識信頼度判定は，以下のように，繰り返し／問い返し応答を目的とした場合と，共感応答を目的とした場合とで，異なる手法により行う．なお，「相槌応答」は，以下のいずれの認識信頼度判定においても「信頼度が低い」と判定された場合に生成される．■繰り返し／問い返し応答の生成を目的とした場合ここでの目標は，認識結果中の最終述語，および，当該述語に付随する格助詞，および，格要素（具体的には，最終述語とその一つ前の述語との間に出現する格助詞，および，格要素．以降，このようにして得られた結果を〈格要素，格助詞，最終述語〉と記述する．）について，以下のような繰り返し／問い返し応答生成のために，信頼度が高いもののみを高精度に抽出すること，である．●繰り返し応答：お花を貰ったんですか／お花をですか／お花ですか／貰ったんですか●不足格の問い返し応答：誰に貰ったんですか？verbatim本論文では，「Juliusから得られる認識結果の候補10Bestにおいて，多くの候補に出現するほど信頼度は高い」という考え方をベースに，〈格要素，格助詞，最終述語〉のそれぞれに対する認識信頼度を判定する．Hazenらは，単語の認識信頼度を10種類の特徴量を用いて算出し，それらの単独使用と複合使用の時のエラー率の比較結果を示しており，ここで用いた手法は，その単独特徴量中でもっとも性能の良かった特徴量(N-bestPurity)の考え方と近い．例として，ユーザ発話『東京に行った』を考える．認識候補10Bestにおいて，「東京に行った」や「東京に行って」以外に，例えば「故郷に行った」や「遠くに行った」などの誤った候補が得られていた場合，格助詞「に」の格要素については曖昧であるが，格助詞「に」，および，述語「行く」は多くの候補に出現していることから，少なくとも「〜に行った」という部分については，信頼度が高いと判定することができる．同様に，ユーザ発話『ボールを投げた』に対する認識候補10Bestにおいて，認識結果が「ボールを」「ボールと」「ボールで」の場合には，どのような格助詞に対する格要素かは曖昧だが，格要素「ボール」については信頼度が高いと判定することができる．このように，〈格要素，格助詞，最終述語〉のそれぞれの項目に対する個別の信頼度については，10Bestにおけるそれぞれの項目の出現頻度をベースとした手法により信頼度判定が可能である．しかし，ここでは，〈格要素，格助詞，最終述語〉の組み合わせとして信頼度が高いかどうかを判定する必要があるため，以下の方法をとる．提案手法の処理のフローを図3に，手続きを以下に示す．手順[1]：Juliusより得られる音声認識結果の10Bestそれぞれに対し，「（文頭）格助詞最終述語」や「動詞の連用形最終述語」などのように，着目すべき最終述語の周辺の品詞の並びが不適切な候補を棄却する．手順[2]：手順[1]で残った認識結果の候補について，まず，最終述語，格助詞，および，格要素を，それぞれの単語認識信頼度と共に抽出する．また，最終述語が持つ格（格要素＋格助詞）の認識信頼度を，格助詞と格要素の単語認識信頼度の平均により算出する．なお，格要素を抽出する際，連続する名詞は複合名詞と判断し，それぞれの名詞の単語認識信頼度の平均を，当該複合名詞の認識信頼度とする．手順[3]：10Bestそれぞれについて得られた手順[2]の結果を，格要素，格助詞，格，および，最終述語ごとに合算する．この結果を，ユーザ発話に含まれる格要素，格助詞，格，および，最終述語の候補とする．得られる結果の例を図4に示す．なお，この例では，手順[1]により，残り5つの認識候補が棄却されたとする．手順[4]：ここまでの結果を用いて，ユーザ発話中の着目すべき要素のうち，どの認識結果が信頼できるのかを判定する．具体的には，以下のように判定する．格要素，格助詞，格，最終述語のそれぞれについて，最大，かつ，閾値以上の信頼度を持つ候補を抽出する．なお，格助詞，および，格については，それぞれの格ごとに判定を行う．また，信頼度判定の閾値は，格要素，格助詞，格，最終述語のそれぞれについて，個別に設定する．本論文で設定した閾値を表6に示す．表6の値は，開発者2名が実験的に，「積極的な繰り返し／問い返し応答の生成」と「相槌応答の生成」とのバランスを鑑みた上で決定した値である．この値に従うと，図4の例では，以下のものが信頼できる認識結果として抽出される．格要素：彼，ボール格助詞：に，を格：彼に最終述語：渡すなお，これら4つの閾値のうち，「格要素」「格」「最終述語」に関しては，「より積極的に認識結果を利用して応答生成する」のか「誤認識を用いた応答生成を防ぐために相槌を生成するのか」を判断する値である．具体的には，閾値を低く設定すると，より積極的にそれらの認識結果を利用して応答生成するようになり，反対に，閾値を高く設定すると，認識結果は信頼できないと判定されて相槌を生成する可能性が高くなる．一方，「格助詞」に関しては，「より積極的に，不足格の問い返し応答を生成する」かどうかを判断する値である．具体的には，閾値を低く設定すると，「当該格助詞はユーザ発話に含まれている」と判断しやすくなり，不足格の問い返し応答の生成数は減少する．反対に，閾値を高く設定すると，「当該格助詞はユーザ発話に含まれていない」と判断しやすくなり，不足格の問い返し応答の生成数は増加する．なお，格助詞についての閾値は，他と比べ低く設定した．これは，格助詞は誤認識が起こりやすく，格要素や最終述語と比べ認識信頼度の判断が難しいため，格助詞認識に対するRecallを高くし，「ユーザ発話に含まれているにも関わらず不足格として問い返してしまうエラーによる満足度低下」を防ぐことを目的としたためである．また，本論文では認識候補の10Bestを利用したが，ある閾値以上の認識結果を利用するなど，利用する認識候補の数を一定にしない方法も考えられる．このような場合には，単語信頼度の合算値を，利用した認識候補の数で正規化した上で閾値判定を行う必要がある．格要素，格助詞，および，最終述語の個別の項目については，(1)で抽出された結果を信頼できる要素と判定する．一方，〈格要素，格助詞，最終述語〉の共起の信頼度については，格（e.g.,彼に）と最終述語（e.g.,渡す）の共起が日本語として適切かどうかを判定する必要がある．なぜなら，個別の認識候補については言語モデルにより共起の適切性が考慮されているが，提案手法では，〈格要素，格助詞，最終述語〉を一旦独立したものとして扱うため，例えば「格（格要素＋格助詞）については10Best中の上位4候補にのみ含まれる（下位6候補には含まれない）結果が信頼できると判定されるが，最終述語については下位6候補にのみ含まれる（上位4候補には含まれない）結果が信頼できると判定される」という可能性があるためである．日本語として適切かどうかの判定にはWeb5億文コーパスを用いる．今回は，Webテキストに〈格要素，格助詞，最終述語〉の組み合わせが10回以上出現した場合に，日本語として適切であるとみなした．以上の手順で，信頼できると判定された「格要素」「格助詞」「格」「最終述語」を用いて繰り返し／問い返し応答を生成する．なお，信頼できると判定された「格要素」「格助詞」「格」「最終述語」が全く存在しない場合は，繰り返し／問い返し応答は生成されない．■共感応答の生成を目的とした場合共感応答の生成では，ユーザ発話の音声認識結果に対し，1単語単位ではなく，1発話単位の信頼性を評価し，信頼できる発話候補のみ共感応答生成への入力とする．しかし，Juliusから得られる単語単位の信頼度は，音響モデル尤度，および，3-gram言語モデル尤度に基づき算出された値であるため，後段で，この値を用いて1発話全体の信頼性を判定することは容易ではない．そこで，「発話全体が信頼できる認識候補かどうか」ではなく，「感情推定がロバストに行える認識結果の候補であるかどうか」という観点で認識結果を精査することとした．具体的には，名詞や動詞，形容詞などの自立語が一語の場合には，発話の曖昧性が高く正確な感情推定できない場合が多いが，「プレゼントを貰った」や「足をぶつけた」のように自立語を2語以上含む場合には，発話の曖昧性が下がり「それは良かったですね」や「それは大変でしたね」といった共感応答の生成が期待できる．そこで，10Bestそれぞれに含まれる「名詞」「動詞」「形容詞」「副詞」，および，「否定表現」の総数が2以上の候補を，感情推定がロバストに行える認識候補と判定し，5章で述べる共感応答生成への入力とする．</subsection>
  <subsection title="音声認識性能，および，認識信頼度判定アルゴリズムの有効性評価">本節では，提案システムの音声認識性能，および，認識信頼度判定アルゴリズムの有効性評価についての予備実験結果を示す．なお，テストセットとして，被験者39名による1,042発話を用いた．まず，音声認識性能についての結果について述べる．テストセットに対する単語認識率は，recall:70.1%,precision:66.7%であった．提案システムのように項構造を用いる場合は，ユーザ発話に含まれる格要素，格助詞，最終述語をどの程度適切に認識できるかでシステムの応答精度が大きく変わってくる．一般的に，格助詞は誤認識されやすく，藤原らの調査によると，「認識信頼度が0.5以上の範囲で，助詞は動詞より約13%程度認識率が低下する」というデータがある．彼らの試算に従うと，提案システムにおいて，ユーザ発話に含まれる格助詞の認識精度は約50%程度になると考えられる．次に，このように多くの誤認識を含むユーザ発話に対して，提案手法により，高精度な応答生成が可能かどうかを検証した結果について述べる．自然な話し言葉においては，省略，音声認識器の誤認識，文境界の不明確さなどにより，項構造を誤って理解する可能性があり，これまでに，タスク依存型モデルにおける部分的な構文解析，多数の音声認識候補(N-Best)の利用，1単語単位の信頼度と1発話単位の信頼度の組み合わせ，会話内容全体を考慮した信頼度尺度の使用等により，意味解釈の精度を向上させる多くの手法が検討されてきた．今回のシステムでは，応答生成の種類に応じて，N-Best利用による1単語単位の信頼度と，ロバストに感情推定できるかという尺度での1発話単位の信頼度を使い分けることにより，適切な応答を引き出している．また，いずれの認識信頼度判定においても信頼度が低いと判定された場合には「相槌応答」を生成することで，誤認識による不適切な応答生成を最小限にしている．3.2節で述べた認識信頼度アルゴリズムの有効性を，上記テストセットを用いて検証した結果を図5に示す．図5の「1Bsetのみ利用」は，Juliusから得られる認識結果の1bestのみを用い全ての認識結果が信頼できるとして応答生成した場合で，「認識信頼度判定有り」は，我々の提案アルゴリズムにより信頼度が高い候補を抽出して応答生成した場合を示す．なお，ここでは，応答正解率=適切な応答数／(適切な応答数+誤応答数)とし，提案アルゴリズムにより相槌が生成された場合（452発話）については，評価の対象外とした．図5が示す通り，Juliusから得られる認識結果の1bestを用いて応答生成した場合には，応答正解率は55.8%だが，我々が提案する認識信頼度判定を用いた場合には，応答生成の正解率は74.7%であった．このことから，音声認識誤りにロバストな認識信頼度判定アルゴリズムが構築できたと考える．音声認識器の誤認識に関しては，今後さらに低減されていくと考えられるが，周囲騒音の大きい環境や高齢者の小声発話などに対しては認識が難しく，誤認識の問題は依然として残ると予想される．今回採用したような認識信頼度の利用手法は，今後のシステムにおいても必須であると考えることができる</subsection>
  <section title="問い返し応答の生成アルゴリズム">本章では，問い返し応答の生成アルゴリズムについて述べる．2.2節で述べたように，問い返し応答には，「最終述語の不足格の問い返し」と「辞書を用いた適切性判別に基づく問い返し」の2種類がある．以下，それぞれについて述べる</section>
  <subsection title="最終述語の不足格判別に基づく問い返し応答の生成アルゴリズム">本節では，最終述語の不足格判別に基づく問い返し応答の生成アルゴリズムについて述べる．提案システムでは，最終述語が「動詞」および「サ変名詞＋する」の場合のみ不足格判別に基づく問い返し応答を生成し，他の最終述語に関しては不足格の問い返し応答は生成しないものとした．なぜなら，ユーザの行動を表す「動詞」および「サ変名詞＋する」に関しては，不足格（e.g.,誰と，どこに，何を）を問い返すことがユーザの次発話を促す効果があると期待されるが，ユーザの感情や形容表現を表す「形容詞」「形容詞＋なる」「形容動詞」「名詞＋だ」に関しては，不足格判別に基づく問い返し応答（e.g.,いつより嬉しかったんですか？，何より美味しかったんですか）は不自然な応答となる場合が多いためである．なお，ユーザの感情や形容表現を表すこれらの述語に関しては，4.2.3節で述べる理由を問い返す表現により次発話の生成を促す．</subsection>
  <subsubsection title="問い返し応答生成アルゴリズムの概要">図6に，問い返し応答生成アルゴリズムの概要を示す．3.2節で述べた信頼度判定アルゴリズムにより，信頼度が高いと判定された動詞，および，格助詞を用いて，以下の手順により問い返し応答を生成する．手順[1]：当該動詞をキーとして，予め作成された必須格辞書を検索する．ここで，必須格辞書には，図6に示すように，ある動詞についての必須格が深層格レベルで登録されていると同時に，当該格を尋ねる際に最適な疑問詞と表層格がペアで登録された辞書である．ここで，図6中の「ヲ(object)」などの表記は，「表層に現れた格助詞（深層格）」を意味する．なお，想定している対話の性質上，ユーザ発話内の「ガ(agent)」は省略されることが多いため，ここでは，必須格としては登録しない．必須格辞書の作成手法の詳細は，4.1.2節で述べる．手順[2]：信頼度が高いと判定された格助詞と，手順[1]で検索された必須格との照合を行うことで，当該動詞の不足格を判別し応答を生成する．例えば，ユーザ発話中の動詞「貰う」の不足格が「カラ格(source)」と判別された場合，問い返し応答として『誰から貰ったんですか？』を生成する．不足格判別手法の詳細は，4.1.3節で述べる</subsubsection>
  <subsubsection title="必須格辞書の作成">本節では，必須格辞書の作成について述べる．(ア)「不足格の問い返し応答」に適した深層格の定義前述したように，必須格は深層格レベルで登録する．なぜなら，表層的には同じ「二格」であっても，それが「goal格」なのか「time格」なのかで尋ね方が異なる上に，深層格レベルで考慮しないと，どちらが必須格なのかを適切に判定できないためである．一般的に，表層格は「ガ」「ヲ」「二」「デ」「ト」「ヘ」「カラ」「ヨリ」「マデ」の9種類とする定義が広く用いられているのに対し，深層格については，どのような種類をどのような基準で認定するかの共通見解がない．そこで，我々は，EDR日本語共起辞書において定められている意味的関係の定義をベースに深層格を定義した．具体的には，EDR日本語共起辞書において，名詞と動詞の間に付与されている「概念関係子」をベースに深層格を定義する．表7に，概念関係子の例を示す．本論文では，「動詞の不足格を問い返す」という目的を鑑み，以下の考察に基づいて深層格を定義した．1.概念関係子の細分化が必要例として，EDRで定義されている概念関係子objectに着目する．表層格「ヲ」に付与されたobject，および，表層格「ト」に付与されたobjectの例を，表8と表9に示す．EDRにおけるobjectの定義は「動作・変化の影響を受ける対象」であり，どちらもその定義に従っているが，意味的には，「ヲ」が示すobjectは動作の「対象」，一方，「ト」が示すobjectは動作の「相手」と考えられ，全く異なるものである．仮に，動詞「競い合った」を考えた際，「ヲ」が示すobject（＝「対象」）が不足格であった場合，それを問い返す適切な応答は「何を競い合ったの？」であるのに対し，「ト」が示すobject（＝「相手」）が不足格であった場合の適切な問い返し応答は「誰と競い合ったの？」となる．つまり，動詞の不足格を問い返すことを目的とした場合，動詞「競い合う」にとっての概念関係子objectを2種類の深層格に細分化する必要がある．このような細分化は，上記の例のように，異なる表層格に付与された概念関係子を対象とした場合だけではなく，同一の表層格に付与された概念関係子も対象となる．例えば，表10に示すような，表層格「ト」に付与された概念関係子goalに着目すると，上2つの動詞（一致する，関係する）では，不足格を尋ねる際に「〜と……？」と尋ねるのが自然なのに対し，下2つの動詞（なる，考える）では，「どう……？」と尋ねるのが自然である．2.概念関係子の統合が可能また，格の尋ね方が同一かどうかの観点で考えると，異なる概念関係子を統合できる場合もある．例えば，表11に示すような，表層格「ヲ」に付与されている概念関係子objectおよびbasisの場合，どちらも「対象」を示しているが，動詞の意味が「過不足・優劣」などの場合はbasis，それ以外の場合にはobjectが付与されている．ここで，これらの格を尋ねる際には，いずれも「〜を……？」と尋ねるのが自然である．つまり，上記の観点では，これらの概念関係子は全て「〜を……？」と尋ねるobjectに統合可能と言える．以上の考察に基づき，本論文で定義した深層格の一部を表12に示す．（イ）必須格辞書の作成（ア）で述べた定義に従い，動詞の必須格辞書を作成する．具体的には，以下の手順で作成した．手順[1]：毎日新聞記事5年分(毎日新聞社1991--1995)no46を対象として，全ての文に対し係り受け解析を行い，〈格要素，格助詞，動詞〉を抽出する．手順[2]：手順[1]の抽出結果に対し「格助詞置換分析法」を用いて深層格の判別を行う．この手法は，格要素や動詞の意味属性情報に加え，当該動詞がどのような表層格のパターンを持っているか，別の表層格に置換可能であるかどうか，などの情報を統計的に獲得し，これらの情報を利用して，ルールベースにより深層格の判別を行うものである．具体的な処理を図7に示す．例として，「飛行機が成田空港を出発する」の「ヲ」格の深層格を判別する．A)まず，図7(A)に示す通り，上記の毎日新聞記事5年分から，「出発する」が持つ表層格パターンを抽出する．B)次に，「ガ−ヲ」の格パターンの「ヲ」が，別の表層格に置換されたパターンが存在するかどうかを検索する．その結果，「出発する」は「ガ−カラ」という「ヲ」が「カラ」に置換されたパターン，あるいは，「ガ−二」という「ヲ」が「二」に置換されたパターンを持つことが分かる．ここで，置換されたパターンが存在するかどうかは，シソーラスから得られる格要素の意味属性を利用して判断する．C)最後に，図7(C)に示す通り，あらかじめ作成した深層格判別ルールに従い，「ヲ」の深層格が「source」であると判別する．なお，EDR日本語共起辞書内で付与されている概念関係子を，本研究で再定義した深層格体系（表12）に人手で変換したデータ685事例（e.g.,変換前：「群衆と握手する（ト＝object）」⇒変換後：「群衆と握手する（ト=partner）」）を深層格の正解データとし，上記提案手法の深層格判別精度を評価した結果，判別精度は75.7%であった．手順[3]：手順[2]の結果を動詞ごとにまとめ，それぞれの深層格について頻度が一定以上あるものを当該述語の必須格とする．手順[4]：手順[3]で必須格と判断された深層格それぞれについて，シソーラスを用いて，出現した全ての格要素の意味属性を【人／場所／人工物／…】といったレベルで判別する．手順[5]：手順[4]で得られたそれぞれの意味属性を【人⇒誰／場所⇒どこ／物⇒何／…】のように，尋ねる際に最適な疑問詞に置換し，最頻出の疑問詞を，当該深層格を尋ねる際に最適な疑問詞として登録する．なお，受動態や使役態の場合は，能動態とは必須格が異なる．しかし，本論文で作成した深層格判別ルールは能動態のみにしか対応していない．したがって，例えば，ユーザ発話「ずいぶんと怒られたよ」に対し，「誰に怒られたんですか？」といったような不足格の問い返し応答は生成できない（2.2節で述べたように，「怒られたんですか．」という繰り返し応答の生成は可能）．この点については，今後の課題とする．</subsubsection>
  <subsubsection title="不足格の判別手法">本節では不足格の判別手法について述べる．音声認識誤りがない場合には，入力された〈格要素，格助詞，動詞〉を用いて4.1.2節と同様の方法で深層格解析をし，不足格を尋ねる応答を生成する方法をとることができるが，我々のタスクでは〈格要素，格助詞，動詞〉の全てが閾値以上の信頼度で認識できるとは限らない．特に，格要素の信頼度が低いと判定され抽出されなかった場合には，深層格解析を行うことができない．しかし，このような場合であっても，格助詞と動詞の信頼度が高いと判定された場合には，表層格レベルでの不足格判別は可能である．したがって，ここでは，格要素も含めて信頼度が高いと判定されたかどうかに関わらず，格助詞と動詞のみを用いて，表層格の情報に基づいた不足格の判別を行う．具体的には，以下の手順で行う．例として，ユーザ発話「北海道に行ったよ」に対し，認識信頼度判定の結果，格助詞「二」，および，動詞「行く」のみが，信頼度が高いと判定されて抽出された場合を考える．手順[1]：信頼度が高いと判定された動詞について，4.1.2節で述べた手法により作成された必須格辞書を検索し，それぞれの必須格について，当該深層格を表現し得る全ての表層格に置き換える．上記の例では，動詞「行く」の必須格として登録されている深層格「goal」および「partner」を，対応する全ての表層格「二・ヘ」および「ト」に置き換える．手順[2]：手順[1]で置き換えた表層格のいずれもがユーザ発話に含まれていない深層格に限り，当該必須格を不足格と判別する．上記の例では，表層格「二」が含まれているため，深層格「goal」はユーザ発話に含まれており，深層格「partner」が不足格であると判断して，不足格を問い返す応答「誰と行ったんですか？」を生成する．前述したように，音声認識において，格助詞は他の単語に比べて誤認識されやすい．また，話し言葉においては格助詞の省略も頻繁に起こる．これらに対する提案手法の有効性に関して考察する．まず，音声認識誤りに関して，ユーザ発話「北海道に行ったよ」の認識が難しく，認識候補の上位に格助詞「に」が認識されなかった場合を考える．仮に，単純に1bestの認識結果に対して，上記の不足格判別手法を適用したとすると，「goal」は不足格であると判別され，「どこに行ったんですか？」という誤応答が生成されてしまう．しかし，提案手法では，3.2節でも述べたように，認識結果の10bestを利用し，格助詞については，認識信頼度判定の閾値を低い値に，つまり，「当該格助詞がユーザ発話に含まれている」と判定しやすい値に設定してある．したがって，上位の認識結果では格助詞「二」が認識されていなかったとしても，10best内の下位の認識結果では認識されており，単語認識信頼度の合計が閾値以上であれば，格助詞「二」は認識信頼度が高いと判定され抽出される．これにより，「goal」は不足格ではないと判別され，「どこに行ったんですか？」という誤応答の生成を防ぐことが可能となる．次に，格助詞の省略に関しては，例えば，「北海道行ったよ」といった発話の場合，提案手法で手がかりとする格助詞（この例では「二」）が，信頼度が高い結果として抽出されることは考えにくいため，実際には「goal」が含まれているにも関わらず誤って不足格であると判別される．この発話に対して，「goal」が含まれていることを正しく判別するためには，格要素（北海道）の意味属性から深層格を理解するような手法や，省略された格助詞を補完するような技術の開発が必要となる．この点については今後の課題とする．</subsubsection>
  <subsection title="辞書を用いた適切性判別に基づく問い返し応答の生成アルゴリズム">本節では，辞書を用いた適切性判別に基づく問い返し応答の生成アルゴリズムについて述べる．前述したように，この応答には，「格要素の詳細」「感想」「感情・形容表現に対する理由」をユーザに尋ねる3種類の応答がある．以下，それぞれについて述べる．</subsection>
  <subsubsection title="格要素の詳細を尋ねる問い返し応答の生成アルゴリズム">まず，ユーザ発話「お花を貰った」に対するシステム応答「どんなお花ですか？」といったような，格要素の詳細を尋ねる問い返し応答の生成アルゴリズムについて述べる．手順[1]：Webテキストにおいて，格要素の詳細を尋ねる際の疑問詞（「どんな」「何の」「どこの」の3種類）と係り受け関係にある名詞の頻度をカウントする．手順[2]：手順[1]で各疑問詞との係り受け関係が頻度閾値以上の名詞については，当該疑問詞で詳細を尋ねることが適切であると判定する．表13に，登録されている名詞の例を示す．表13の(a)は疑問詞「どんな」との係り受け関係が閾値以上で出現した名詞で，例えば『どんな動物なの？』『どんなドラマなの？』などの応答を生成する．しかし，当該名詞がユーザ発話に含まれたとしても，ユーザ発話には既にその詳細についての情報が含まれている可能性がある．そこで，ここでは，信頼度が高いと判定された格要素を含む認識候補について，当該格要素の直前に「形容詞」「形容動詞」または「〜の」が存在する認識候補が1つでも存在すれば，ユーザ発話には既に格要素の詳細についての情報が含まれていると判断し，格要素の詳細を尋ねる問い返しの生成は行わない．</subsubsection>
  <subsubsection title="感想を尋ねる問い返し応答の生成アルゴリズム">次に，ユーザ発話「お花を貰った」に対してシステム応答「どうでしたか？」というユーザ発話の感想を尋ねる問い返し応答の生成アルゴリズムについて述べる．我々のシステムでは，言語モデルに含まれる述語を対象に，感想を尋ねることが自然であるかどうかを人手により判断してもらい，「感想を尋ねることが不自然な述語の辞書」を構築した．辞書の一部を表14に示す．我々のシステムは，ユーザ発話の最終述語がこの辞書に登録されていない場合に，感想を尋ねる問い返し応答を生成する．例えば，ユーザ発話が「お花を貰ったの」の場合には「貰った」は辞書に登録されていないため「どうでしたか？」という発話を生成するが，ユーザ発話が「ムキになったの」の場合には表14に示す辞書に「ムキになる」が登録されているため「どうでしたか？」というシステム発話は生成しない．ただし，「ディズニーランドに行った」の場合は「どうでしたか？」と尋ねることが適切だが，「食堂に行った」のように日常的な事態に関しては「どうでしたか？」と尋ねることは適切でないというように，感想を尋ねることが適切かどうかの判断は，述語のみではなく格要素などの情報も考慮した上で行う必要がある．この点に関しては今後の課題である</subsubsection>
  <subsubsection title="感情・形容表現に対する理由を尋ねる問い返し応答の生成アルゴリズム">最後に，ユーザ発話「楽しかったよ」に対するシステム応答「どうして楽しかったんですか？」のような，感情・形容表現に対する理由を尋ねる問い返し応答の生成アルゴリズムについて述べる．提案手法では，「人手により，理由を尋ねることが適切であると判定された感情・形容表現」が登録された辞書に基づき，当該応答の適切性を判定する．登録されている感情・形容表現の例を表15に示す．ただし，ユーザ発話に，既に当該感情・形容表現に対する理由が含まれている可能性があるため，単純に辞書に登録されているかどうかのみで応答生成の適切性を判定することはできない．そこで，ここでは，信頼度が高いと判定された感情・形容表現を含む認識候補について，当該感情・形容表現の直前に，「ので」「から」などの接続詞が存在する認識候補が1つでも存在すれば，ユーザ発話には既に理由が含まれると判断し，当該応答の生成は行わないこととした</subsubsection>
  <section title="共感応答の生成アルゴリズム">本章では，共感応答の生成アルゴリズムについて述べる</section>
  <subsection title="応答生成アルゴリズムの概要">図8に共感応答の生成アルゴリズムの概要を示す．3.2節で述べたように，本論文では，前段で認識誤りを含む認識結果を棄却するのではなく，「誤認識結果が含まれる場合でも適切に感情推定を行う」手法を提案する．具体的には，「感情推定の際に重要となるキーワードが正しく認識されていれば，複数の認識候補に共通して出現し，それらの認識候補に対する感情推定結果は同一となる」という仮説に基づき，前段の認識信頼度判定アルゴリズムにより得られた3つの認識候補に対して感情推定を行い，多数決，および，閾値判定に基づき，得られた感情推定結果が適切であるかどうかを判断する．手順[1]：認識信頼度判定により得られた3つの各認識結果に対して，5.2節で述べる手法によりユーザの感情を推定する．その際，それぞれの感情推定結果には信頼度(0〜1)が付与される．また，具体的な感情のレベル（e.g.,嬉しい／恐い）での推定結果が高信頼度で得られた場合は当該結果が出力されるが，推定信頼度が低い場合には，感情極性のレベル（ポジティブ／ネガティブ／ニュートラル）で出力される．手順[2]：3つの認識候補毎に得られた推定結果について，感情と感情極性ごとに信頼度の和を算出し，値が最大，かつ，閾値以上の信頼度を持つ結果を，ユーザ発話に対する感情推定結果とする．もし閾値を以上の信頼度を持つ結果がなければ，感情極性はニュートラルとする．手順[3]：手順[2]で得られた最終的な推定結果を用いて共感応答を生成する．具体的には，最終的な推定結果が「嬉しい」であれば，「それは嬉しいですね」という応答が生成され，最終的な推定結果が「ポジティブ」であれば，「それはいいですね」という応答が生成される．一方，最終的な推定結果が「ニュートラル」の場合は，共感応答は生成しない．これにより，大きな感情の変化が起きない内容のユーザ発話（e.g.,電話をした）や，誤認識により信頼できる感情推定結果が得られなった場合に，不適切な共感応答を生成することを防ぐことができる</subsection>
  <subsection title="感情推定アルゴリズム">ここでは，感情推定アルゴリズムについて説明する．本論文では，徳久らの手法により感情推定を行う．具体的には，感情推定を「ユーザ発話をある感情クラスに分類する問題」ととらえ，大量の学習データに基づく機械学習によりこの問題を解く手法である．ここで，我々は，システムがユーザに共感していることをより明確に示すために，単に感情極性（ポジティブ，ネガティブ，ニュートラル）を推定するだけではなく，より具体的なレベルでの感情（「嬉しい，楽しい，安心，怖い，悲しい，残念，嫌，寂しい，不安，腹立たしい」の10クラス）を推定する．感情推定は，次の3つの処理により実現する．処理1：感情生起要因コーパスの作成機械学習を行う際の学習データとなる感情生起要因コーパスを作成する．感情生起要因コーパスとは，ある事態に対してどのような感情が生起するかが記述されたコーパスであり，｛感情が生起する要因となる事態｝と〈感情〉とで構成される．まず，獲得対象とする感情表現を定義する．寺村は，感情表現に関して，『X＝感情主，Y＝対象，Z＝当該語のとき，「XはYをZ」「XはYにZ」「XはYがZ」のいずれかの表現ができれば，Zは感情表現である．』と定義している．この定義を参考にして，小林らの評価値表現辞書から感情表現を抽出した結果，349語の感情表現を得た．表16に，感情ごとの感情表現の数と例を示す</subsection>
</root>
