<?xml version="1.0" ?>
<root>
  <jtitle>仕事文推敲支援に向けた連体修飾部不足に対する受容性判定法</jtitle>
  <jauthor>梅村祥之増山繁</jauthor>
  <jabstract>文章推敲に関する従来研究では，主に，タイプミス，構文構造の複雑さ，表記の揺れを指摘する手法など，表記レベルと統語レベルの手法に重点がおかれていた．それに対して，本研究では，読みやすさを向上させるために，説明が不足していて論理展開が読み取りにくいと感じられる箇所を検出する技術を扱う．文章としては情報を正確に伝達するための仕事文（仕事用の文）を対象として，文単位での情報不足を推敲対象とする．この課題は意味処理に踏み込むため，これまで十分研究が行われてこなかった．なお，語用論の「協調の原理」によれば，量の格率と呼ばれる情報不足と情報過多に関する遵守すべき原則がある．このうち情報過多を扱わない理由は，情報過多が，冗長な情報を無視するのに基づく読者の負担を増やすだけであるのに対し，情報不足は理解困難という深刻な事態を招き，重要性が高いためである．実験準備から解析に至る流れは，次の通りである．まず，原文から連体修飾部を欠落させた課題文を生成し，次に，被験者にその箇所に情報不足を感じるかどうかを判定させ正解判定データを作成した．その後，正解判定データの一部から機械学習を行い，残りのデータを機械判定させる．機械判定に用いる主な素性として，修飾部の欠落箇所におけるつながりの滑らかさに関係した語の連鎖に関する統計量を取り上げた．約1,000箇所の判定課題に対し，SVMによる機械学習アルゴリズムを用いた自動判定により正解率を測定した結果，機械判定の正解率として，ベースライン500pt</jabstract>
  <jkeywords>文章推敲，n-gram，SVM，連体修飾，情報不足</jkeywords>
  <subsubsection title="n-gramに基づく素性">n-gramに基づく素性として次の5つを用いる（図参照）．この中の「評価文節の確率」以外は，欠落箇所におけるつながりの滑らかさに関する特性を表現している．</subsubsection>
  <section title="はじめに">言語処理技術を利用した文章の推敲や校正の支援に関する研究が行われている．この研究分野を次の5段階に分けて考える．まず，「表記レベル」に関しては，自然言語処理の教科書に詳しく解説されているように，研究開発が完成段階に達し，コンピュータのアプリケーションソフトとして実装されている．次の「統語レベル」に関しても，係り受けの複雑さに起因する読みづらさを指摘し，書き換え候補を生成する研究が行われ，応用段階に到達している．以上の「表記レベル」と「統語レベル」の課題に対しては，文を言語解析し，その際の解析困難性の程度を誤りや読みづらさの指標にするという手法が広く用いられている．この手法が使われる理由は，表記レベルと統語レベルに対応した言語解析である形態素解析および係り受け解析の現状の解析精度が十分に高いためであると考えられる．それに対し，次の「意味レベル1」では欠落した格要素の推定や照応詞の照応先の特定の困難さを算出する必要がある．しかしながら，それに対応した格解析や照応解析といった意味解析技術の精度が現状では不十分なため，解析困難の理由が，解析技術の精度不足に起因するのか，原文側の問題に起因するのか区別がつかず，指摘の要否判定ができない．さらに，「意味レベル2」に含まれる情報不足や情報過多の指摘に関しては，対応する言語解析技術も定まっておらず，今後の技術と考えられている．このように，「意味レベル1，2」やその先の「文脈・構成レベル」の検出・支援の技術は研究が進展していないのが現状である．本論文は，「意味レベル2」に含まれる情報不足と情報過多の指摘のうち情報不足の指摘を扱う．以下，文章作成の理論の中で，この課題の位置付けを考える．言語表現とそれを用いる使用者や文脈との関係を研究する分野である語用論と会話における意志疎通の原理を扱ったGriceの理論がある．これはコミュニケーションが成り立つための原理と条件を与える協調の原理についての内容であり，仕事文（仕事に用いる文を仕事文と称する．）が満たすべき条件を与える基礎理論である．協調の原理に従うために，いくつかの特定の条件（格率という）に従わなければならない．格率は量，質，関係，様態の4カテゴリにまとめられる．そのうちの量に関して，次の2つの格率に従う必要がある．要求に見合うだけの情報を与える発言を行う．要求されている以上の情報を与えるような発言を行ってはならない．(1)の格率を満たさなければ，情報不足の問題が生じ，(2)の格率を満たさなければ，情報過多の問題を生じる．このうち，本論文で扱う課題は，量に関する１つ目の格率を満たさないために生じる情報不足の課題である．文章講座に関する一般書籍にも情報不足に関する解説が見られる．例えば書籍「仕事文の書き方」では，仕事文において正確な文章を書くために，情報不足に注意することを述べている．この書籍では情報不足による論理の飛躍の例として，次に示す入学用ランドセルの広告文を取り上げている．第1文と第2文の間に論理の飛躍があって読みづらいため，間に言葉を補い，次のように修正すべきと述べている．量の格率の2条件を満足しないために生じる情報不足と情報過多の問題の中で，本研究では情報不足の問題のみを扱い，情報過多の問題は扱わない．その理由について述べる．本研究では，ビジネス分野の文章作成支援を目指して，仕事文を対象とする．そのため，情報不足の場合には，文が難解になることに加え，論理の飛躍によって誤解を生じさせると言う深刻な事態を招くのに対し，情報過多の場合には，冗長な情報を無視するのに読解の負担がかかるものの，誤解を生じる可能性は低いため，深刻さの程度は低い．したがって，コンピュータによる文章推敲支援の課題として，情報不足の検出と指摘の課題を扱うことが有用であると考える．本研究では，この課題を情報不足が読者に受容されるかどうかを判定する問題として扱い，コーパスベースの統計的言語処理に基づくアプローチを用いた手法を開発する．</section>
  <section title="全体概要">詳細説明に入る前に，本章では，実験に用いる文を準備する段階から，機械学習アルゴリズムを用いた自動判定に至る流れの概略を説明する（図）．原文として，新聞記事を基にして作られた京大コーパスを用いる．京大コーパスは，文に，形態素情報と係り受け情報が付与されているので，係り受け構造を利用して連体修飾節あるいは連体修飾句の場所を認定する．その部分を欠落させた文を作成し，被験者判定用の文とする．この文を被験者に提示して，欠落箇所に情報不足を感じるかどうか判定してもらう．被験者数は4名である．判定対象とする文の数は約1,800文である．全員が各々これら約1,800文を判定する．通常，被験者毎の判定結果は異なる．そのため，OK判定（情報不足なし）とNG判定（情報不足あり）の比率は1対1にならない．本研究は，機械判定の要素技術を確立する段階の研究であるため，手法の性能を評価する際の容易さから，次のように，OKとNG判定が1対1になるようなデータセットを作成する．すなわち，評価データから，各被験者毎に，OK判定とNG判定の比率が同じになるように文を抜き取り，データセットを作成する．そのように作成された被験者毎のデータセットは，判定の正解値に関するベースラインが500pt％である．次の段階は，機械判定に用いる素性値の算出である．素性は全部で11素性である．その中の１つは，例えば，各文の情報不足評価位置での文の滑らかさ等に関する素性情報である．それらの素性値を使って，10-foldcrossvalidation法に基づく学習と判定を行う．機械学習アルゴリズムを用いた自動判定の手法としてSVM(SupportVectorMachines)を用いる．なお，4名の被験者による判定を各々の正解値としたため，正解率も4通りが得られる．一方，被験者の判定の一致率によって手法の精度の上限を推定し，それを基に正解率を評価する．</section>
  <section title="課題文と正解データの作成"/>
  <subsection title="課題文の作成手順">本研究では毎日新聞の記事に形態素・構文情報などの各種言語情報を人手で付与したテキストコーパスである京大コーパスを用いて課題文の作成を行った．京大コーパスを利用するのは次の理由による．自動的に付与した形態素，構文解析に関して人手修正を行っているため，解析誤りが少ない．京大コーパスの素材となった毎日新聞記事は新聞記事であり，本研究が対象とする仕事文に相当する．また，文の品質が高く，機械処理向きの優れた素材である．次に，京大コーパスから機械処理で課題文を作成する方法について説明する．本研究では原文のある部分を削除する加工を行って情報不足を生じさせた文を生成する．削除する部分の選定基準を以下のように設定する．以上の処理により，京大コーパスの初めの600記事から，１文に1箇所の評価箇所を含む課題文を作成した結果1,792文が得られた．評価は１文毎の評価で行う．被験者への文の提示と評価も1文単位で行い，機械判定も1文内の情報を基に行う．主観評価において，文脈上の影響を除外するために，文の提示順をランダムにした．</subsection>
  <subsection title="主観評価">機械学習アルゴリズムに基づく自動判定に用いる正解値を与えるために，被験者による主観評価を行う．成人男性4名によって評価を行った．評価にあたって，被験者に与えた教示は次の通りである．被験者に，初めの10問は練習用と断って評価してもらい，以降のデータ処理で使用していない．評価の際に，評価時間に制限は設けていない．総計1,792文を評価するのにおおよそ10数時間を要するため，被験者の判断で，数日に分けて評価した．</subsection>
  <subsection title="被験者間での主観評価の一致率">被験者間での主観評価の一致率を計算する．一致率を次のように定義する．ただし，計算は文単位で行う．4名の被験者から2名を選んだ6通りの組に対しての一致率は，表に示す通りである．全て，ほぼ，800pt％の一致率が得られた．また，主観評価の一致の程度を係数で検証した．係数について簡単に説明する．2名の被験者がカテゴリ判定したデータのクロス集計結果を表とするとき，係数は，=(P_o-P_e)/(1-P_e)で定義される．ここで，P_oは実際の一致割合（被験者A，BともにNGあるいは，ともにOK）であり，P_o=(a+d)/Nである．P_eは被験者AとBの間に関連がない場合の各セルの期待値を足して全数で割った値であり，P_e=(n_1m_1/N+n_2m_2/N)/Nである．係数の値により，一致の度合は表のように評価される．今回の実験において，6通り全ての組に関し，表に示すように，``moderate''な一致の範囲であった．</subsection>
  <section title="機械判定で用いる素性の定義">文の受容性に関する機械判定を行うための識別器としてSVMを用いる．SVMは最大マージン原理を利用した2クラスの分類問題を解くための識別器であり，SVMは言語処理分野の他にも様々な分野に利用されている．SVMの一般的な教科書としてはがある．また，高い性能を持つSVMの性能に関係する汎化誤差の議論については，例えば「パターン認識と学習の統計学」6.4節等を参照されたい．素性として，以下で定義する11個の素性を用いる．11個のうちの3個は語彙表記と語の意味クラスに関する素性である．その他の8個は，大規模な生コーパスから計算した言語統計量を用いて計算した素性である．以上の枠組を模式図の形式で図に示す．</section>
  <subsection title="語彙素性">はじめに，語彙に関する3つの素性について図を参照しながら説明する．</subsection>
  <subsection title="語彙素性以外の素性">以下に示す8個の素性は，大規模な生コーパスから計算した統計量を用いて計算した素性である．大規模な生コーパスとして，2000年の毎日新聞記事を収めた「CD-毎日新聞2000」1年分を用いる．形態素の分割には標準的な形態素解析ソフトであり，また，京大コーパスとの親和性がよいためJUMANを用いる．</subsection>
  <subsubsection title="Noisy Channel Modelに基づく素性">誤字の修正の問題にNoisyChannelModelに基づく手法が用いられている．本素性はNoisyChannelModelの考え方にヒントを得たものである（図参照）．図(a)に示すように，形態素の並び,W_-2,x,W_0,を観測したとする．ここで，xはどんな形態素でも良い．W_0が与えられたという条件の下で，2つ前の形態素がW_-2である条件付き確率をp(W_-2W_0)で表す．全ての語Wに対して,W,x,W_0,となる確率をp(WW_0)で表す．次に，p(WW_0)が降順になるようにWの並び順を定める．このときの並び順をW^(1),W^(2),,W^(n)とする．すると，W_-2はW^(1),,W^(n)のいづれかに位置する．次に，p(WW_0)から累積分布P(WW_0)を次式で計算する．累積分布の説明図を同図(a)中の右図に示す．この中でW_-2に対応する累積確率P(W_-2W_0)が本素性（NoisyChannelModelに基づく素性）である．以下，本指標の性質について図と例を用いて説明する．同図(b)のイラストに示す．例として，W_0が「今日」でW_-2が「日」と「直径」の2つについて説明する．各々の文脈は「…日○今日…」と「…直径○今日…」である．ここで，「○」はこの位置を何か1文節が占めていることを示している．W_0が定まると，それに従って累積分布P(WW_0)のカーブも固定される．上記の例の場合，W_0=「今日」に対して，共起しやすい語であるW_-2=「日」はx軸で左端（上位14位）に位置し，共起しにくい語であるW_-2=「直径」はx軸の右端（上位362位）に位置する．累積分布のカーブであるため，W_-2がx軸上の上位（左側）に位置すると，指標は小さな値になる．ここの例で「…日○今日…」という自然な文脈に対応する．一方，W_-2がx軸上の下位（右側）に位置すると，指標は大きな値になる．ここの例で「…直径○今日…」という不自然な文脈に対応する．</subsubsection>
  <subsubsection title="エントロピーに基づく素性">ここで扱うエントロピーでも，他の素性同様，欠落評価位置を挟んだ前後の連結性を扱う．具体的には，連続した2形態素についての条件付き確率に基づくエントロピーとして，文頭から文末に向かう順方向エントロピーと文末から文頭に向かう逆方向エントロピーの2つを扱う（図参照）．いくつかの語でエントロピーを計算した例を表に示す．特定の文脈で使われる語はエントロピーが小さく，いろいろな文脈で使われる語はエントロピーが大きい．例えば，「記事」は「関連記事」，「この記事」という文脈で使われることが多いためエントロピーが小さいのに対し，「ニュース」ではそのような文脈上のつながりがなく，エントロピーが少し大きくなる．「電池」は，「太陽電池」，「燃料電池」という文脈が非常に多いため，ここで示した6語の中で最小の値となっている．一方，「教育」，「文化」はいろいろな文脈で使われるため，エントロピーが大きい．「首相」は村上首相（人名＋首相）のような特定の文脈で使われる場合と，そうでない場合が半々程度出現し，エントロピーは中程度の大きさになる．本節で導入するエントロピー指標は，文脈による次の語（順方向エントロピーの場合には次の語で，逆方向エントロピーの場合には前の語）の予測が容易か困難かの指標であり，連体修飾部の欠落の受容性と次の関係を持つ．</subsubsection>
  <section title="機械判定の正解率測定結果">機械判定を行うにあたり，データセットに含まれる「補う必要なし」（以下，正例と表記する）と「補う必要あり」（以下，負例と表記する）の数が等しくなるようにサンプルの抜き取りを行って調整する．具体的には，全被験者とも，負例が少なかったので，正例の中からランダムに，負例の数のサンプルを抽出して，正例と負例のサンプル数が等しくなるようにデータセットを調整する．そのようにして得られた被験者毎のサンプル数を図および表に示す．この操作により，サンプル数800弱の被験者2名と，サンプル数1,100弱の被験者2名の2グループに分けた．以下の機械判定では，調整後のデータセットを基に，学習と判定を行う．前章で述べた素性を用い，分類器として自然言語処理で広く使われるSVMを使って判定を行った．SVMのパラメータとして線形カーネルを用い，ソフトマージンでコストC=1を用いた．機械学習アルゴリズムを用いた自動判定の評価にあたり10-foldcrossvalidationを行った．学習コーパスの量と正解値の関係，すなわち学習曲線を図に示す．課題の正解値は，4名の主観評価中の1名に関するデータを用いる．前述のようにデータセット中の正例と負例の比率を等しくすることによって，ベースラインを0.5に設定してある．ベースラインの値は，正例と負例の2値判定をランダムに行った場合の正解率に相当する．各被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線で示す％になるようにデータ抽出したデータセットに対する一致率であり，僅かに異なる．．学習量に対する正解率のグラフを調べたところ，素性を語彙素性のみにすると，学習サンプル数の増加に伴って正解率が増加しており，ここで調べたサンプル数の範囲では，まだ飽和していない．素性を統計量に関する素性のみにすると学習サンプル数に依存せず，同じ値となり，語彙素性と統計量の双方を用いた場合の正解率は，語彙素性のみの正解率および統計量のみの正解率を上回った（図）．次に，被験者毎の正解率を図，表に示す．図中に，ベースラインおよび各主観被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線で示す．被験者間での正解率に大きな違いはない．4名の正解率の平均値はベースライン0.5，上限0.76に対し，0.67であった．</section>
  <section title="機械判定のパラメータ検討">本論文では，機械学習アルゴリズムとして正解率の高さから定評のあるSVMを用いた．しかし，SVMだけを対象としたのでは，達成される正解率の内訳が，選択された素性に基づく性能によるのか機械学習アルゴリズムの性能によるのか区別がつかない．そこで，機械学習アルゴリズムの中で基本的な手法であるKNN法(k-nearestneighbormethod)を使用した場合の正解率を求めてSVMの正解率と比較し，同じ素性でも，機械学習の違いによる性能向上分の程度を調べる．その結果，ベースライン0.5に対し，KNN法で0.65，SVMで0.67となった．したがって，性能のうちの大部分は素性によって実現されたものと考えられる．なお，KNN法はパラメータKを含むので，網羅的に調べるため，Kを1.5の冪乗(1,2,3,5,7,11,...,437)で変化させて正解率の最大を求めた．次に，SVMを使う場合の，素性選択による影響を調べるために，素性を1つずつ削除した場合の正解率を調べる．それによって，素性選択の改良による性能向上の余地がどの程度あるのかを調べる．その結果，逆方向バイグラム素性を削減したときに最高値を示し，正解率0.69であった．なお，正解率が最も低下したのは，順方向エントロピーを削除したときで，正解率0.65であった（表）．最後に，本論文で導入した11素性を各々単一に用いた場合の正解率を調べる．単体性能の最高を示す素性が「語の表記」で0.66であり，全体を使った性能が0.67である．今回新規な素性としてNoisyChannelModelに基づく素性を導入しているが，単体での正解率は0.52であり，全体中，中間的な性能であった（表）．先の「素性を1つずつ削除」する実験でこの素性を削除した場合に，正解率の低下は中程度であり，補助的な役割は果たしている．主要な素性を補助するために導入した素性の場合，主要な素性無しで，補助的な素性のみを使っても，本来，高い性能は得られない．例えば，順方向エントロピーがこれに該当する．先の「素性を1つずつ削除した場合の正解率」では，削除による正解率低下が最も大きく，重要であるが，それに対して，単一で用いた場合，性能の低い順に2位である．以上の結果，素性選択の方法による正解率への影響を調べた結果，本実験で用いる素性に対して，素性選択を調整すると正解率は多少向上するが，その程度は大きくないことが判明した．</section>
  <section title="考察">機械判定の正解率として，ベースライン500pt％，人間の評価のバラツキから定義した上限760pt％に対し，670pt％の正解率を得た．上限に近い700pt％前半が正解率の最終目標になるであろうから，今回の正解率670pt％は，それと比べ，ある程度近い値に達していると思われる．なお，素性の削減実験で全素性から「逆方向バイグラム」の素性を削減したときに，正解率の最高値690pt％を記録したが，今回のデータに限って偶然高い値になった可能性もあり，また，素性選択の組合せは膨大で正解率の最大値を網羅的に調べるのは困難なため，パラーメータ検討前の正解率を本手法の正解率として代表させた．以下では，実験に用いた素性について，語彙素性とそれ以外の素性の2種類に分けて考察する．まず，語彙素性における機械判定による正解率について図の学習曲線を参照すると，学習サンプル数が少ないときにベースライン手法とほぼ同一であり，十分多いサンプル数を機械学習に与えた場合に全素性とほぼ同等の正解率で判定できることが確認できた．これは語彙素性として使用したものが主に形態素の表記であったため，素性の異なり数が非常に多く，少ない学習サンプル数では十分学習できなかったためと考える．次に，語彙素性以外の素性について考察する．語彙素性以外の素性は8種類ある．これらは主に，n-gramに基づく素性など，語のつながりの滑らかさを反映した統計量であり，新聞記事１年分の生コーパスから求めたものである．図の学習サンプル数は，被験者判定による学習サンプル数であり，統計量を求める際の生コーパスの量とは異なる．そのため，学習により，判定に用いられる素性に対する重み係数が調整されるものの，学習サンプル数による効果は小さい．本研究のように，被験者の主観評価に基づいて正解判定データを整備し，機械学習ベースの判定処理を行うという研究スタイルの場合，主観評価に関わる実験デザインの善し悪しが研究の成否に大きく影響する．本研究では，被験者評価用の文を作成する際に，で述べたように，１文毎の評価に限定したり，1文内の連体修飾部を1箇所に限定するなど，様々な条件設定を工夫して，被験者間の一致度が高くなるよう配慮した．結果的に，被験者間の一致率が約8割で係数がmoderateという十分高い一致率となり機械判定処理に成功した．近年研究の盛んなテキスト自動要約の研究では，主観評価結果のバラツキの問題が大きいため，評価法に関して様々な研究が行われ，評価型ワークショップNTCIRのTSCにおいて，評価法をいかにすべきかの議論がなされている．本研究での被験者間の一致率を，従来研究における別のタスクの場合と比較してみる．Maniらの要約の研究では，4名の被験者で，要約文（もしくは原文）がトピックスに適合する検索結果かどうかを判定してもらう適合性判定（二者択一）を行い，被験者間の一致率を調べている．その結果，2名1組での一致率は690pt％で，=0.38であった．また，要約文もしくは原文が，5カテゴリまたはその他のどれに該当するかを答える被験者実験の結果，2名1組での一致率は560pt％で=0.29であった．平尾らの重要文抽出の研究では，要約率を300pt％に設定したときの被験者間の重要文の一致に関し，2名1組の=0.3程度となっている．なお，この研究では，231記事，4,013文からなる文書データに対し，6名の被験者で，重要文の人手判定を行い，大規模な機械学習用の正解値データセットを作成している．また，小林らの音声要約における重要文抽出の研究では，学会講演の音声に対する，人間による重要文抽出（要約率330pt％）の一致率を調べている．2名の評価者間の係数について，10組の平均値は=0.286である．重要文抽出に関しては，=0.3程度(Fair)である．以上の要約に関連した様々なタスクでの被験者間の一致率と比較して，本研究のタスクにおける被験者間の一致率は，が0.46〜0.56（全てmoderate）であり，一致率が高いと言える．要約文の品質評価法に関して，外的評価という方法がある．例えば，適合性判定のタスクを設定して，様々な品質の要約文で，タスクの達成時間を計測し，達成時間を短縮できた要約文の品質が高いと判定する方法である．この評価方法は競技型ワークショップSUMMACで用いられたが，評価の実施が高価だったことに加えて，時間の制限から原文書を比較的短いものに限定しており，評価の妥当性の疑問が問題点として挙げられている．本研究では，被験者間のばらつきの少ない実験条件を整備することに留意し，被験者間の一致率約8割で係数がmoderateになる高い一致率を得た．その結果，機械判定の処理が成功した．次に，今回の課題設定に関する特殊性を吟味する．本研究で扱った連体修飾部の追加の要否判定（換言すると欠落に対する受容性判定）の課題には，意味レベルと表層レベルとが混在している．これらのレベルの構成比率についてはデータセット中にある課題文を分析することで算出することが可能である．同様に，それらの分析を行った上で，各レベルに属する課題文の中で正解率が特に低いものに照準を合わせて，素性の選定を行うという対策も考えることが出来る．しかし，そのような個別対策に基づくアプローチは，コーパスベースの統計的言語処理と機械学習による枠組に合致せず，オープンテストによる正解率評価の公正性にも反する恐れもある．以上の観点から個別対策は行っていない．本研究の意義を一言で言えば，文章推敲支援の分野において，これまであまり研究が進んでいなかった「意味レベル2」（節で定義）の課題を扱い，広く行われている統計的言語処理のアプローチで機械判定を行い，ある程度高い正解率を達成した点である．成功のポイントは，意味処理の課題を扱うに際して，主観評価の安定性を向上させるよう，実験デザインを工夫することによって，学習量の圧縮や，機械判定の正解値評価の部分を容易にした点である．</section>
  <section title="関連研究">酒井らはテキスト自動要約における文内要約の要素技術として動詞連体修飾節の省略可能性に関する知識をコーパスから獲得する手法を提案している．この研究は，本研究とも関連が深いので，両者の枠組の違いを図に図示する．両者の似ている点は，文中のある部分の削除に対して，その受容性に関する評価指標を構築することが中心課題である点である．そのため，n-gram素性やエントロピー素性など，語の統計量に基づく素性を構築する上で，酒井らの手法を参考にした．一方，最も異なる点は，省略可能性評価の場合に，省略のない完全な文と省略のある文を生成できるのに対し，本研究の場合には，与えられた文は，全て連体修飾部を欠落させた文であり，原文は与えられず，復元出来ない点である．そのため，省略可能性評価の場合，完全な文と省略のある文を対比して指標を構築するというアプローチを取ることが出来るのに対し，本研究の場合，欠落のある文のみから評価指標を構築しなければならないという難しさがある．</section>
  <section title="まとめ">文章校正，推敲の支援に関する従来研究では，主に，タイプミス，構文構造の複雑さ，表記の揺れを指摘する手法など，表記レベルと統語レベルの手法に重点がおかれていた．一方，人間による文章の推敲の作業では，読みやすさを向上させるために，説明が不足していて論理展開が読み取りにくいと感じられる箇所を指摘する場面が多く見られ，コンピュータ支援に対するニーズは高い．しかし，これまで，このような課題は，意味処理レベルの困難な課題と考えられ，機械判定の対象として十分に研究されていなかった．本研究では，原文から連体修飾部を欠落させた文を生成し，被験者がその箇所に何か言葉を補った方が良いか，その必要はないかを評価してもらい，そのようにして作成した正解判定データを使って機械判定する．この課題設定に関して，人間の判定結果の一致率を調べた．その結果，4名の評定者による各1,792箇所の判定に関し，４名中2名ずつ，6通りの組合せについて，いずれもほぼ８割の高い一致率を示した．機械判定の主な素性として，語彙素性に関する素性3種，コーパスからの統計量に関する素性8種を用い，機械学習アルゴリズムに基づく自動判定の手法として，SVMを用いた．その際，ベースラインを500pt％にすべく，正例数と負例数が等しくなるようにサンプルの抽出を行い，928サンプル（4名の被験者の平均値）からなるデータセットを作成した．機械判定の正解率として，ベースライン500pt％，上限（人間の評価のバラツキから上限を定義）760pt％に対し，670pt％の正解率を得た．今回の実験上の制約の中で，1文毎で評価している点が最も大きな制約であろう．この制約を外し，文脈を含めて検討することが今後の課題である．その際，照応技術の進展に合わせて研究開発することが鍵となろう．また同様に，今回用いなかった技術として，格解析の技術がある．格要素の有無に関する情報は，情報不足の推定に有力な情報を与えることが期待できるため，格解析技術の進展に合わせて利用を検討すべきである．</section>
</root>
