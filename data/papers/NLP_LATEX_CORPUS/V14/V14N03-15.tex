    \documentclass[japanese]{jnlp_1.3c}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}

\Volume{14}
\Number{3}
\Month{Apr.}
\Year{2007}

\received{2006}{4}{20}
\revised{2006}{9}{4}
\rerevised{2006}{11}{13}
\accepted{2006}{12}{1}

\setcounter{page}{297}

\jtitle{評判情報のレベルを考慮した評価文書の分類と\\
	評価情報の信頼性評価への応用}
\jauthor{安村　禎明\affiref{KOBE} \and 坂野　大作\affiref{KOBE} 
	\and  上原　邦昭\affiref{KOBE}}
\jabstract{
本論文では，Web上の評判情報を有益に活用するために，レビューなどの評価
文書をポジティブ（おすすめ）とネガティブ（おすすめしない）という極性値に分類
する手法を
提案する．本手法では，全体評判情報と部分評判情報という2つの
レベルで評判情報を捉える．全体評判情報とは評価文書の対象全般に関わる評
価表現のことを指し，部分評判情報とは対象の一属性に関する評価表現のこと
を指す．全体評判情報の極性値は評価文書の極性値と一致すると考えられるため，まず
全体評判情報を用いて評価文書を分類し，全体評判情報がない場合は部分評判情報を用
いて分類する．これら2つのレベルの評判情報を考慮することで分類精度の向
上が期待できる．
さらに，これら2つのレベルの評判情報を用いることで，評
判情報の信頼性評価の一手法を提案する．ここでは，評価文書の極性値とその中
の部分評判情報の極性値が異なる場合にその部分評判情報は信頼性が高いと評価する．
映画のレビューを用いた評価実験の結果，ナイーブベイズを用いた分類手法よ
りも本手法の方が良い結果が得られた．また，提案した評価指標が評価文書の信頼性評価の1つと
なりうることを示唆した．
}
\jkeywords{評判情報，テキスト分類，信頼性，情報抽出}

\etitle{Classification of Feedback Documents Considering a Level of Reputations 
	and Reliability Evaluation of Reputations}
\eauthor{Yoshiaki Yasumura\affiref{KOBE} \and Daisaku Sakano\affiref{KOBE} 
	\and Kuniaki Uehara\affiref{KOBE}} 
\eabstract{
This paper describes a method for classifying feedback documents into
two polarities: positive and negative.
In this method, we classify reputations into ``Object Level
Reputations'' and ``Attribute Level Reputations''.
Object level reputations are the reputations concerning the object of the
feedback document. Attribute level reputations are the reputations
concerning one attribute of the object. Since we asuume that the polarity of the object
level reputation corresponds to the polarity of the feedback document,
feedback documents are first classified using the object level reputation.
The feedback documents that do not contain object level reputations
are classified using the attribute level reputations. In addition,
this paper proposes a method for reliability evaluation of
reputations considering two levels of reputations. In this method,
we regard the attribute level reputations that has the opposite polarity of the
feedback document as reliable reputations.
The experimental results using movie reviews showed that the proposed method could 
classify feedback documents more correctly than the previous method,
and that the proposed measure can be one of the reliability measures for reputations.
}
\ekeywords{Reputation, Text Classification, Reliability, Information Extraction}

\headauthor{安村，坂野，上原}
\headtitle{評判情報のレベルを考慮した評価文書の分類と評価情報の信頼性評価への応用}

\affilabel{KOBE}{神戸大学大学院工学研究科情報知能学専攻}{
	Department of Computer and Systems Engineering, Kobe University}



\begin{document}
\maketitle




\section{はじめに}

近年，Webが爆発的に普及し，掲示板等のコミュニティにおいて誰もが容易に情報交換をすることが可能になった．
このようなコミュニティには様々な人の多様な評判情報（意見）が多く存在している．これ
らの情報は企業のマーケティングや個人が商品を購入する際の意思決定などに
利用されている．

このため，このような製品などに対する評判情報を，Web上に存在するレビュー
あるいはブログなどから，
自動的に収集・解析する技術への期待が高まっている．
このため，従来このよう
な評判情報の抽出に関して研究されてきた\cite{morinaga,iida,dave,kaji,yano,suzuki}．
これらの研究では，製品などに関する評価文書から自然言語処理技術を用いて
評判情報を抽出する．また，評判情報を含む評価文書を，ポジティヴ
（おすすめ）とネガティヴ（おすすめしない）という2つの極性値に分類し，その結
果をユーザに提示する．提示された情報を基にユーザは様々な意思決定を行う．

評価文書を2つの極性値に分類する手法に関して，これまで多くの研究が行われ
てきた．
\cite{turney}では，フレーズの極性値に基づく教師なし学習によって評価文書
を分類している．\cite{chaovalit}では，映画のレビューを対象に教師なし学
習\cite{turney}と教師あり学習を比較している．ここでは，教師あり学習と
してN-gramを用いている．実験の結果，分類精度は教師あり学習の方が高かっ
たと報告している．教師あり学習を用いたものとして
\cite{dave}では，ナイーブベイズを用いて評判情報の分類学習を行っている．

これらの研究では，文書中に含まれている単語や評判情報をすべて同等に扱っている．
しかし，評価文書には，全体評判情報と部分評判情報とい
う2つのレベルの評判情報が含まれていると考えられる．
全体評判情報とは，評価文書の対象全般に関わる評価表現のことを指す．
例えば，映画のレビューにおいて「この映画はおもしろい」という評価表現は対象
全般に関わる評価表現であり，この表現がある場合はその極性値が評価文書の極
値にほぼ一致する．一方，部分評判情報とは，対象の一属性に関わる評価表現
のことを指す．例えば，映画のレビューにおいて「映像がきれい」という評価
表現は映画の一属性である映像に関する評価表現であり，この表現があったと
してもその極性値が評価文書の極性値と一致するわけではない．
したがって，これら2つのレベルを考慮することで評価文書の分類精度の向上
が期待できる．

そこで本論文では，評判情報を全体評判情報と部分評判情報という2つのレベ
ルに分け，その極性値を基に評価文書を分類する手法を提案する．本手法では，
まず評価文書から全体評判情報を抽出し，その極性値を判定する．この極性値は評価文
書の極性値とほぼ一致するため，この極性値を評価文書の極性値とする．評価文書に
全体評判情報が含まれない場合は，部分評判情報の極性値の割合から評価文書の
極性値を決定する．


さらに，この2つのレベルの評判情報を用いて，評判情報の信頼性を評価する
ための一手
法を提案する．評判情報は主観的な情報のため，信頼性が低いという問題点が
ある．このため，その信頼性を評価できれば有益な情報となる．信頼性を評価
する手法は多くのことが考えられるが，ここではその1つとして，評価文書の極
値と異なる極性値を持つ部分評判情報は信頼性の高い情報と捉えることを提案する．
例えば，
「すごく面白い映画だった．映像も素晴らしかった」と
「はっきりいって最低の映画でした．でも映像だけは良かったです」という評
価文書があるとする．
前者のように，映画全体をポジティブに評価している人が映像に関してもポジ
ティブに評価することはあまり情報としての価値はない．悪意のある見方をす
ると宣伝ともとれる．一方，後者は映画全体としてはネガティブな評価である
が，映像に関してはポジティブに評価している．このような評価は客観的でフェ
アである可能性が高いため，信頼性が高い評価情報であるとする．このような
信頼性は，評判情報の2つのレベルを用いることで評価できる．



\section{評判情報}
評判情報と評価文書を定義し，その表現法について述べる．
また，全体評判情報と部分評判情報という評判情報の2つのレベルに関して述べる．

\subsection{評判情報と評価文書}

Web上ではブログや掲示板あるいはレビュー等で映画の感想やある製品に関する評価が多く存在する．
例えば「映像に迫力がなかった」というような文がある．
このような評価を含む情報を本研究では評判情報と呼ぶ．また，評判情報を含む文書を評
価文書と呼ぶ．レビューで考えれば，1投稿が1つの評価文書に対応する（図\ref{fig:2.1}）．

\begin{figure}[t]
 \begin{center}
      \includegraphics{14-3ia15f1.eps}
  \caption{評価文書と評判情報}
  \label{fig:2.1}
 \end{center}
\end{figure}


また，「こんにちは，私は原作は見てないので比較はできませんが，この映画はとても面
白かったです．」という文章では，評判に関わる部分は「この映画は
面白い」ということである．
必要な部分だけを抽出すると，評判情報は（対象，属性，評価表現）という3つ組の形で表すことができる
\cite{iida,tateishi}．対象とは評価対象の名前や評価対象全体を表
す言葉である．属性とは評価対象の一部分を表す言葉であり，評価表現とはそ
の評価対象や属性の評価である．映
画を例にした評判情報の表現として，（映画，映像，迫力—ない），（$\phi$, 演技，すご
い），（映画，$\phi$, 面白い）など
が挙げられる．$\phi$は，実際のデータでは対象や属性が必要ない場
合や，文章中で省略されている場合を表す．
本研究では，この3つ組みは文単位で抽出する．

評判情報には，大別して全体評判情報と
部分評判情報という2つのレベルが存
在すると考えられる．
全体評判情報とは評価対象全般に関する評価表現であり，部分評判情
報とは評価対象の一属性に関する評価表現である．
例えば，（映画，$\phi$, おもしろい）は評価対象全般である映画に関する評価表現で
あるため，全体評判情報である．一方，（$\phi$, 映像，きれい）は映画の
一部である映像に関する評価であるため，部分評判情報である．
また，（映画，映像，きれい）のようなすべての属性がある場合でも，映像に関する
評判情報であるため，部分評判情報と捉える．
全体評判情報は対象全般に関する評価であるため，その極性値は評価文書の極性値
と一致すると考えられる．一方，部分評判情報は一属性に関する評価であるため，その
極性値は評価文書の極性値と一致するとは限らない．
したがって，全体評判情報を重視して評価文書を分類すると，その分類精度の
向上が期待できる．

本研究において上記の3つ組の表現を用いることで全体評判情報と部分評判情報を明
確に区別することが可能となる．また，本研究では，レビュー内のテキスト情報以外の情報は用い
ていない．例えば，投稿者の情報や投稿の返信関係，
文を超えた範囲からの抽出などは行っていない．これらの情報を考慮すること
で評価文書の分類精度が上がることが期待できるが，本論文では評判情報の
2つのレベルに焦点をあてているため，これらの情報を考慮しなかった．


\section{評価文書の分類}
ここでは，評価文書をポジティブとネガティブに分類する手法を説明する．
\pagebreak
まず，本手法での基本モデルとして用いるナイーブベイズ(NB)モデルつい
て述べる\cite{dave}．
次に，2つのレベルの評判情報を用いた評価文書の分類手法を提案する．

\subsection{ナイーブベイズモデル}

文書分類では単語の順序は必ずしも必要ではなく，
文書中にどのような単語がどのような頻度で出現するかの情報で十分な場合が多い．
そこで，単語の順序を無視し，文書を単語の集合として捉えるBOW (bag-of--words)モデル
が用いられる．
BOWモデルでは，1つの文書は形態素解析によって抜き出された単語リスト$d\{w_1,w_2,\cdots,w_M\}$と表現され，
単語リスト$d$は文書と同一視される．$w_m$は文書に含まれる単語で，各々は異なる単語と
は限らない．
この考えに基づき，分類する文書（実際には単語リスト）を$d$とし，分類するための手がかりとなる
学習コーパス（N個の学習用文書）$D=\{d_1,\cdots,d_N\}$から形態素解析等の処理によって得られる単語リストを単語集合Wとする．単語集合は$W=\{t_1,t_2,\cdots,t_V\}$
と表現する．$t_i$は第$i$番目の単語でVは単語の総数を表す．

NBモデルではBOWモデルに従う．NBでは，あるトピック$c$を持つ文書$d$の各単語$w_m$の生起を統計
的に独立と仮定しているため，独立性の定義から次の式が成り立つ，
\begin{equation}
p(d|c)=P(w_1,\cdots,w_m|c)=\Pi_{m=1}^MP(w_m|c)
\end{equation}
これはあるクラスを与えたときに文書$d$が生成される確率は，$w_M\in W$の
生成確率である$P(w_m|c)$の乗算で算出できることを意味する．


次に単語頻度ベクトル$x=(x_1,\cdots,x_V)$を導入する．$x_i$は$t_i\in W$が文書$d$に出
現する回数を表す．
単語$t_i$ごとに整理すると，$P(w_1|c)\times \cdots \times P(w_M|c)=P(t_1|c)^{x_1}\times \cdots \times P(t_V|c)^{x_V}$
が成り立つため，$P(t_i|c)=\theta_iとすると，$式(1)は次のようになる．
\begin{equation}
p(d|c)=\Pi_{i=1}^V\theta_i^{x_i}
\end{equation}
これがBOWモデルに基づく，文書のNBモデルである．
$\theta=(\theta_1,\cdots,\theta_V)$は未知のパラメータであるために学習する必要があ
る．
本研究では，NBのパラメータ学習に，事後分布最大化学習（MAP学習）を用いる．
MAP学習では，与えられた学習用コーパス$D$に対して，$\theta$の事後分布$p(\theta|D)$を最大化するパラメータを最適としている．MAP学習による$\theta$の推定値は次の式で表現できる．
\begin{equation}
\hat{\theta}=\frac{\sum_{n=1}^Nx_{n,i}+\alpha-1}{\sum_{i=1}^V\sum_{n=1}^N x_{n,i}+V(\alpha -1)}
\end{equation}
ここで，$x_{n,i}$は$t_i$が$D_i$中に出現する頻度ベクトルである．推定パ
ラメータ$\alpha$は一種の平滑化（スムージング）パラメータである．
$\hat{\theta_i}$はW中の全ての単語が$D$中に出現する総回数に対する，$t_i$が$D$中
に出現する数の割合となっている（図\ref{fig:3.2}）．

\begin{figure}[t]
 \begin{center}
      \includegraphics{14-3ia15f2.eps}
  \caption{ナイーブベイズモデル}
  \label{fig:3.2}
 \end{center}
\end{figure}


NBモデルを用いて文書をポジティブとネガティブの2つのクラス$(c_1=P,c_2=N)$に分類する．
各クラス毎に学習データ$D$から式(3)を利用して$P(d|c_1)とP(d|c_2)$が得られる．
クラスが未知の文書$d*$に対して，クラス事後確率$P(c_i|d*)$を最大化するクラス$c_i$がベイズ誤り確率最小化の観点で最適なクラス分類となる．
ここで，$P(c_i|d*)\propto P(c_i)P(d*|c_i)$なので，$P(c_i)P(d*|c_i)$の最大化となる．


\subsection{NB分類器の作成}
単語素性のNB分類器は次の手順で作られる．
\begin{enumerate}
\item 学習データから評価表現候補単語リストの作成
\item NBモデルの作成
\end{enumerate}
学習データ$D$には，極性値がラベル付けされた
レビュー集合を用いる．
$D$から，評価表現の単語リストを抽出する．このとき，評価表現候補は，形容詞—自立，動
詞—自立，名詞—形容動詞語幹，名詞—サ変接続，副詞—一般，副詞—助詞類接続
という品詞で絞り込んだ単語集合を抽出する．これは評価表現をこれらの品詞
にほぼ限定できるためである．この段階では明らかに評価表現
でない名詞を多く含んでいる．
そこで，評価対象を特徴づける対象名や属性名（映画ならば“映画”や“映
像”など）と助詞—連体化や助詞—並立助詞，つまり“の”や“と”で繋がる名詞
を$D$から抽出し，評価表現ではない可能性が高いので評価表現候補からは除
外する（図\ref{fig:3.3}）．また，明らかに評価表現にならない動詞も候補から外す．これには“する”などのstop-word
と呼ばれるものが含まれる．次に，評価表現候補をTF-IDFで得点づけする．TF-IDFは単語を得
点づけするアルゴリズムで，ポジティブである評価文書だけに頻出するような単語はTF-IDF値が大きくなる．
逆に，ポジティブにもネガティブにも出現するような評判情報はTF-IDF値が押さえられる．
この段階で，ポジティブとネガティブそれぞれに対して特徴的な語が数値として得られる（表\ref{fig:3.4}）．

ポジティブ，ネガティブそれぞれに特徴的な語を数値順でソートしたものの中
で上位の単語だけを用いる．
これは，あまり数値が低いものは特徴的な単語でない可能性があるためである．
また，候補数に差があると，分類に偏りが出易くなるので，ポジティブとネガ
ティブ，それぞれの候補数を合
わせる．本研究では，ポジティブとネガティブで候補数が少ない方の数に合わせた．このように
して単語集合$W$が完成する．さらに単語集合Wの$D$中における頻度ベクトル$X$を作成し，
式(3)に基づき$P(d|N)$と$P(d|P)$を作成する．

\begin{figure}[t]
 \begin{center}
       \includegraphics{14-3ia15f3.eps}
  \caption{属性と属性評価表現の抽出}
  \label{fig:3.3}
 \end{center}
\end{figure}


\begin{table}[t]
  \caption{TF-IDFによるスコアリング}
  \label{fig:3.4}
\begin{center}
\begin{tabular}{|c|r|c|r|}
\hline
Positive word & tf-idf  & Negative word & tf-idf \\ \hline
楽しめる& 963 & 悪い&786 \\ \hline
最高& 920 & 良い&634 \\ \hline
面白い& 873 & ない&617 \\ \hline
楽しい& 845 & 面白い&377 \\ \hline
いい& 625 & 飽きる&371 \\ \hline
良い& 598 & 面白い—ない&361 \\ \hline
とても& 563 & つまらない&332 \\ \hline
すごい& 484 & 感じる&318 \\ \hline
ない& 435 & もっと&302 \\ \hline
すき& 434 & 拾う&300 \\ \hline
おもしろい& 433 & ちょっと&298 \\ \hline
よい& 387 & わかる—ない&298 \\ \hline
演技& 345 & 好き&258 \\ \hline
監督& 345 & がっかり&251 \\ \hline
笑う& 344 & 無い&248 \\ \hline
感じる& 326 & どう&243 \\ \hline
楽しむ& 323 & 正直&242 \\ \hline
ちょっと& 310 & 変&236 \\ \hline
もう一度& 300 & 残念&223 \\ \hline
\end{tabular}
\end{center}
\end{table}



\subsection{評価文書分類の提案モデル}
ここでは，評価文書を分類するための提案モデルについて述べる．
NBモデルによる分類には，分類対象を評価文書にした場合に
は以下のような問題点がある．
問題点の1つは係り受けを扱えないことである．例えば，「車がはやい」と
「電池切れがはやい」のよ
うに，評価表現だけでなく，対象と評価表現，あるいは属性と評価表現の組で
なければ，ポジティブとネガティブに正確に分類できない．
このため，係り受けを扱うことで分類精度が高められると期待できる．
もう1つの問題点は，全体評判情報と部分評判情報を同等に扱っていることである．
単なる多数決ではなく，レベルの違いを利用した分類手法が必要である．例えば，
（映画，$\phi$, おもしろい）が1回，（$\phi$, 映像，荒い）が2回出現するような評価文書
は一般的にはポジティブに分類される．なぜならば，全体評判情報の極性値は評価
文書の極性値とほぼ一致するため，これを重視すると，この評価文書の極性値はポ
ジティブであると予想されるからである．
しかし，評判情報の単純な多数決ではこの評価文書はネガティブに分類される．
したがって，全体評判情報を重視すれば，評価文書の分類精度は向上すると期
待できる．



評価文書を分類するための提案モデルには次の2つの新しい点がある．
\begin{itemize}
\item 全体評判情報と部分評判情報に分けて文書分類すること
\item 係り受けの関係を扱うこと
\end{itemize}

提案モデルでは，次の2つの分類器を作成する．1つは全体評判情報の分類器，もう1つ
はNB分類器である．最初に全体評判情報
分類器で分類を試みる．この分類器では全体評判情報を抽出し，その極性値を求
める．全体評判情報の極性値は評価文書の極性値とほぼ一致するため，評価文書を
全体評判情報の極性値に基づき分類する．
全体評判情報を含まない評価文書はこの分類噐では分類不可能であるため，
このような評価文書は，単語素性のNB分類器を用いて分類する．この手順により
本手法では優先的に全体評判情報を用いて評価文書を分類する．実際に全体評判情報
として使われる素性は評判情報の3つ組の種類のうち（対象，$\phi$, 評価表現）となる．

\subsection{2つのレベルを考慮した評価文書の分類手法}

全体評判情報の分類器の作成手順を以下に示す．
\begin{enumerate}
\item 学習データ$D$から対象候補単語リストの作成\\
 対象候補単語はその対象の特徴的な言葉に限定し，人手で設定する．例えば，映画な
らば``映画''，``作品''を用いる．
\item $D$から評価表現候補単語リストの作成\\
単語素性に基づくNB分類器の評価候補単語リストの作成と同様に行う．
\item $D$から対象候補と評価表現候補の組み合わせとのマッチングによる全体評判情報候補を作成\\
$D$から係り受けの関係にある2文節をすべて抽出し，対象候補と評価表現候補の組み合わせとマッチングしていく．
このようにして抜き出されたものを同じ組み合わせであるもの毎に
集めて単語集合Wと単語集合の頻度ベクトルXを得る（図\ref{fig:3.5}）．
\item NBモデルの作成\\
$W$と$X$と式(3)から$P(d|N)$と$P(d|P)$を作成する．
\end{enumerate}


\begin{figure}[t]
 \begin{center}
    \includegraphics{14-3ia15f4.eps}
  \caption{属性と評価表現の抽出}
  \label{fig:3.5}
 \end{center}
\end{figure}



\section{評価情報の信頼性評価}

ここでは，評価情報の信頼性を評価する一手法について述べる．
評判情報は主観的な意見であるために，その客観性は乏しく信頼性は低いとい
う問題点がある．
このような信頼性の低い情報の中から比較的信頼性の高い情報を抽出できれば有益な情報
となる．

人間は主に2つの信頼性評価方法を用いていると考えられる
．1つは，サイト名などの情報発信者や組織名などの情報を用いる方法である．
このような情報を元に情報の信頼性を評価する研究\cite{mui,takehara}があるが，
サイトの信頼性が低いからといって全ての評判情報の信頼性が低いわけではな
い．
また，投稿者情報を用いることは匿名性の高さのために困難であることが多い．
もう1つの信頼性評価手法は，複数の情報の整合性から評価するものである．
これを利用した研究は単純に
多数決をとることで客観性を与えるということ\cite{tateishi}しかなされていない．

本論文では，信頼性評価の一要素として評価文書と評判情報の極性値に基づく手
法を提案する．ここでは，
評価文書の極性値とその中
の部分評判情報の極性値が異なる場合にその部分評判情報は信頼性が高いと評価する．
例えば，「すごく面白い映画だった．映像も素晴らしかった」と
「はっきりいって最低の映画でした．でも映像だけは良かったです」という評
価文書について考える．
前者のように，ポジティブな極性値を持つ評価文書において，ポジティブな部分評判
情報はあまり情報としての価値はない．悪意のある見方をすれば，前者の評判
情報は映画の宣伝とも捉えられる．
しかし，後者は映画そのものはネガティブと捉えているが，映像に関してはポ
ジティブに評価している
ため，客観的でフェアな評判情報と考えられる．このように，評価文書の極性値
とは逆の評価を持つ部分評判情報は，他のものよりもフェアであると考えられる．
この理由は以下の通りである．
\begin{itemize}
\item 対象全般に対する評価と属性に対する評価が同じになることが一般的で
あるが，あえて異なる極性値を持つ評価情報を書き込むことは情報としての価
値が高い．
\item 対象に関してポジティブな面とネガティブな面の両方が評価できている
ため，客観性が高い．
\item 宣伝や熱狂的なファン，アンチファンの投稿は信頼性が低いが，このよ
うな情報を排除できる．
\end{itemize}
本論文では，このような情報をフェアな評判情報と呼ぶ．

このフェアな評判情報を抽出するためには，評価文書と評判情報の極性値も調べ
ることが必要である．
つまり，評価文書を分類するタスクと，評価文書から評判情報を抜き出した後，各評判情
報を分類するタスクの2つのタスクが必要である（図\ref{fig:3.1}）．

\begin{figure}[t]
 \begin{center}
      \includegraphics{14-3ia15f5.eps}
  \caption{信頼性評価手法の概要}
  \label{fig:3.1}
 \end{center}
\end{figure}


この2つのタスクの結果，部分評判情報は以下の4種類に分類される．
\begin{itemize}
\item 評価文書としてはポジティブ，部分評判情報としてはポジティブなもの(Pp)
\item 評価文書としてはポジティブ，部分評判情報としてはネガティブなもの(Pn)
\item 評価文書としてはネガティブ，部分評判情報としてはポジティブなもの(Np)
\item 評価文書としてはネガティブ，部分評判情報としてはネガティブなもの(Nn)
\end{itemize}

フェアな評判情報はPnとNpということになる．
本論文では，このように評価文書を分類し，その中の評判情報を分類すること
でフェアな評判情報とそれ以外の評判情報を区別する．
このようにしてフェアな評判情報を抽出する．

\subsection{フェアな評判情報の抽出}
本節では，フェアな評判情報の抽出法について述べる．
フェアな評判情報を抽出するためには，評価文書の分類と，それに含まれてい
る評判情報の抽出およびその分類が必要である．評価文書の分類に関しては，
前章で提案した手法を用いる．以下では
評判情報の抽出とその分類について述べる\cite{iida}．

このタスクにおける評判情報とは部分評判情報を指すため，（$\phi$, 属性，評価表
現）を抽出し，分類するタスクである．
このタスクのために，まず，評判情報辞書を作成する．基本的な考え方は辞書にマッチす
る評判情報候補は評判情報であるというものである．
この手法を用いる理由は，既存の研究では様々な条件付けで評判情報候補を絞ることはで
きても，それが実際に評判情報であるかという分類は難しいとされているためである．

辞書の作成には，まず学習データ$D$から属性候補と評価表現候補を抽出することから始める．
属性候補に関しては，初期値として属性であると考えられる単語を10程度与え
る．学習データ$D$中でそれらと助詞—連体化や助詞—並立助詞，つまり「の」や「と」で繋がる名詞を抽出する．
このように抜き出された名詞は，対象の属性である可能性が高いため
初期値にこれを加え属性候補とする．評価表現候補は，形容詞—自立，動詞—自
立，名詞—形容動詞語幹，名詞—サ変接続，副詞—一般，副詞—助詞類接続という
品詞で絞り込めるため，これらの品詞を候補とする．このように抽出された属性候補と評
価集合の全組み合わせに対して手動でポジティブとネガティブをラベル付けして，正事例として辞書に加える．
評価表現でないと判断した組み合わせは負事例として学習していく．
このように作成された評判情報辞書を用いることで，分類対象の評価文書から評判情報を
抜き出す．

\subsection{フェアな評判情報の利用}
本手法によって得られた部分評判情
報を評価対象毎，カテゴリ毎，ラベル（PpやNn）毎にカウントすることによって，表\ref{class}のような
分類結果が得られる．
カテゴリとは属性のグループであり，映画のカテゴリでは映像・音楽・ストーリなどである．
このカテゴリと属性を一対多で対応させることで，カテゴリ毎，ラベル毎に
集計する．

この表をユーザに提示することで評判情報が評価できる．
例えば，この表でのカテゴリ1，カテゴリ2はともに単なるポジティブと
ネガティブの多数決をとると，それぞれ100対100と145対145で
同じとなる．しかし，フェアな評判情報であるPnとNpを考慮することで，
カテゴリ1はポジティブが優勢であり，カテゴリ2はネガティブが優勢である
と判断できる．

\begin{table}[t]
\caption{評判情報の分類}
\label{class}
\begin{center}
\begin{tabular}{|c|c|c|c|c|} \hline
  & Pp & Pn & Np & Nn \\ \hline
カテゴリ1 & 14 & 0 & 86 & 100 \\ \hline
カテゴリ2  & 145 & 22 & 0 & 123 \\ \hline
\end{tabular}
\end{center}
\end{table}




\section{評価実験}

評価文書分類においてNBモデルと提案手法の比較実験を行った．また，
抽出されたフェアな評判情報の有用性について評価する．

\subsection{実験設定}

実験に用いたデータはポータルサイト``Yahoo Japan''の``Yahoo Movie''
から収集した．
収集したデータは，最近公開されたメジャーな10タイトルにおいてそれぞれ最
新の1000レ
ビューを収集したものであり，合計10000レビューである．
これらのタイトルを選択したのは，レビュー数が十分であることと，実際に本
手法を用いる際には比較的新しい情報を対象とすることが多いと考えたためで
ある．
``Yahoo Movie''のレビューには，投稿者によって点数が5段階で付与されている．
本実験では得点が5点あるいは4点のレビューをポジティブとし，2点あるいは1点のものをネガティブと
した．3点または“得点なし”は中立とした．表\ref{train}にデータの詳細な内訳を示す．

10回交差検定でNBモデルと提案手法の結果を比較した．
データの中から，1000レビュー，つまり1タイトル毎に評価データとし，残りのデー
タである9000レビューを訓練データとした．比較の指標には精度と再現率を用いた．
また，評判情報に関する語は自立語に絞られるため，両手法共に素性には自立語のみを利用した．
また，否定語である“ない”に関しては，“自立語—ない”の形で扱っている．
全体評判情報の最初の対象候補単語リストとしては，映画，作品，ムービーを用いた．
部分評判情報の最初の候補単語リストは，映像，CG，画面，音楽，ミュージッ
ク，曲，演出，ステージング，脚色，配役，キャスティング，キャスト，物語，
ストーリー，話を用いた．

\begin{table}[t]
\caption{実験データ}
\label{train}
\begin{center}
\begin{tabular}{|c|c|c|c|} \hline
 データ & ポジティブ & ネガティブ & 合計 \\ \hline
タイトル1 & 647 & 242 & 889 \\ \hline
タイトル2 & 426 & 356 & 782 \\ \hline
タイトル3 & 592 & 207 & 799 \\ \hline
タイトル4 & 750 & 149 & 899 \\ \hline
タイトル5 & 812 & 122 & 934 \\ \hline
タイトル6 & 790 & 131 & 921 \\ \hline
タイトル7 & 547 & 261 & 808 \\ \hline
タイトル8 & 426 & 396 & 822 \\ \hline
タイトル9 & 654 & 283 & 937 \\ \hline
タイトル10 & 542 & 298 & 840 \\ \hline
合計 & 6186 & 2445 & 8631 \\ \hline
\end{tabular}
\end{center}
\end{table}



\subsection{全体評判情報による分類評価}
ここでは，全体評判情報が実際に評価文書分類に有用であるかの評価のために，
全体評判情報を人手で抽出し，全体評判情報と評価文書の評価がどの程度一致するかを調べた．
ここでの人手による全体評判情報の抽出は，「良かった」，「最悪」などの一単語で
明確に評価が分かるものに限定し，「ちょっと．．．」，「心に残る」などの
分かりにくい表現は抽出に用いなかった．

500のレビューを人手で評価した結果，全体評判情報は178のレビューに含まれており，
そのうち162のレビューでは全体評判情報と評価文書の極性値が一致した．また，一致しなかった
16のレビューに関しても，評価文書の評価値はすべて3点となっており，
中立の評価となった．したがって，全体評判情報によって逆の極性値を取るものはなかった．
全体評判情報が含まれている文書は全体の1/3以上であり，全体評判情報が一般的な情報であることが
わかった．以上のことから，全体評判情報が評価文書分類に有用であることが示唆された．
更に，提案手法において全体評判情報がNBよりも高い精度で抽出できれば評価文書の分類精度が
向上することが予測される．

\subsection{評価文書分類の実験結果}
評価文書分類の実験結果を表\ref{result}に示す．値は10回交差検定の平均値である．
P精度，P再現率とは，それぞれポジティブな評価文書に対する精度，再現率を
表しており，N精度，N再現率，全体精度，全体再現率は
それぞれネガティブな評価文書と全評価文書に対する精度と再現率を表す．
人間がこの分類を行った場合，9割強の精度で分類できるが，
完全には分類できないと思われる．この理由は内容に関して述べているだけで
評価につながる表現がないレビューやポジティブとネガティブの両方の評価が
書いてあるが，結局全体としてどちらに評価したのかがわからない場合が挙げ
られる．

\begin{table}[b]
\caption{評価文書の分類結果}
\label{result}
\begin{center}
\begin{tabular}{|c|c|c|c|c||c|c|} \hline
  & P精度 & P再現率 & N精度 & N再現率 &全体精度 & 全体再現率\\ \hline
NBモデル & 0.832 & 0.7943 & 0.538 & 0.578 & 0.741 & 0.733\\ \hline
提案モデル  & 0.848 & 0.799 & 0.570 & 0.639 & 0.771 & 0.760\\ \hline
\end{tabular}
\end{center}
\end{table}


実験結果としては，提案モデルがNBモデルをすべての精度，再現率において上回った．
これは全体評判情報を用いて分類したためと考えられる．
本手法の方が正確に分類した例として「先日，見てきました．とても面白かっ
たです．ですが，レンのお腹…．あれはないかと…．ちょっと失笑して
しまいました．もう少し役作りして欲しかったです．」というレビューがある．
このレビューでは，「とても面白かった」という全体評判情報によってポジティ
ブな投稿であると本手法では判定しているが，NBモデルでは，それ以外の単語
も考慮しているため，この影響でネガティブに分類された．

しかしながら，全体の精度と再現率に関してはNBモデルと提案手法のt検定に
よる有意差はなかった．
この原因は，明らかに全体情報でない候補に対して強い特徴づけを
していることが主として挙げられる．本手法による全体評判情報の抽出精度は82\%であり，
全体評判情報をさらに高い精度で抽出する必要がある．
全体評判情報の抽出精度を上げるには辞書の拡充があげられるが，
人手によるコストが大きくなる．

また，ネガティブな評価文書に関する性能の低さは，ポジティブと比べて，学習データが少ないこと
が原因として考えられる．これは，学習データ数を揃えることで解決できそうであるが，ネガ
ティブな評価文書数は表\ref{train}からもわかるように少なく，揃えることが容易
ではない．また，日本人の特徴である“否定的な事ははっきり言わない”ということを考えると，
数を揃えるだけでは対処できない場合もある．例えば「ちょっと…」のような表現がある．

分類誤りは，Yahooの得点とは逆の内容を書いている，ということを除けば以下のような例がある．
\begin{itemize}
\item  全体評判情報の候補リストに誤っているものが含まれている場合\\
例えば，（映画，$\phi$, 聞く）（映画，$\phi$, 感じる）などがネガティブな候
補として上位となった．これらの全体評判情報は極性値を決定するものではな
いが，分布の偏りによってはこのように全体評判情報の候補となる．
このリストを基に分類器を作成するため，分類精度を下げることになった．
\item 他人のレビューを引用して否定している場合\\
``「最高の映画」なんて書いている人がいるけど''のように逆の見地をとる投
稿者の評判情報部分を引用していることがある．
この問題に対処するためには，引用部分を見分ける必要がある．
\end{itemize}


\subsection{フェアな評判情報の評価}
ここでは，フェアな評判情報を評価する．
映画の評判を多数決を用いて評価した場合とフェアな評判情報のみを
用いて多数決を用いて評価した場合を比較し，どちらが世間的な評価に近いか
を確認する．世間的な評価を完全に把握することは困難であるが，ここでは
著者の1名が多くのレビューを読むことで世間的な評価を判断した．

\begin{table}[b]
\begin{minipage}{0.45\textwidth}
\caption{NANAの評判情報の分類結果}
\label{result2}
\begin{center}
\begin{tabular}{|c|c|c|c|c|} \hline
  & Pp & Pn & Np & Nn \\ \hline
映像 & 9 & 0 & 0 & 0 \\ \hline
音楽  & 98 & 2 & 24 & 2 \\ \hline
キャスト  & 143 & 15 & 25 & 34 \\ \hline
ストーリ  & 163 & 72 & 61 & 42 \\ \hline
\end{tabular}  
\end{center}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
\caption{オペラ座の怪人の評判情報の分類結果}
\label{result3}
\begin{center}
\begin{tabular}{|c|c|c|c|c|} \hline
オペラ座の怪人  & Pp & Pn & Np & Nn \\ \hline
映像 & 65 & 1 & 7 & 0 \\ \hline
音楽  & 172 & 7 & 25 & 10 \\ \hline
キャスト  & 71 & 8 & 11 & 7 \\ \hline
ストーリ  & 147 & 3 & 18 & 2 \\ \hline
\end{tabular}
\end{center}
\end{minipage}
\end{table}

実際のデータに対して本手法を適用し，評判情報を分類した．
評価データとしてどのように世間的に評価されているか
がよく知られているため，``NANA''と``オペラ座の怪人''の2つの映画の
レビューを用いた．
表\ref{result2}，表\ref{result3}にその分類結果を示す．
表中の数値はデータ中に含まれていた
それぞれのカテゴリの評判情報の数である．

NANAの分類結果を見てみると，音楽カテゴリにおいてPnに対して
Npが多く，ポジティブである可能性が高いと考えられる．
オペラ座の怪人の音楽カテゴリにおいても同様のことが言える．
実際にこの両作品に関しては音楽的な評価が高かったと
考えられるため，世間的な評価と一致している．
しかし，これらの結果は単純な多数決でも同様の結果が得られる．

NANAのストーリに注目すると，単純な多数決をとった場合，
224対114となりポジティブの方が多い．
しかし，フェアな評判情報であるPnとNpを比較すると
61対72となりネガティブの方が多くなる．
NANAのストーリは世間的には原作とのギャップから
評価が低かったことを考えると，ネガティブとする方が妥当である．
これはフェアな評判情報のみを用いた場合と一致している．
このようにフェアな評判情報を用いることで，世間的な評価を
抽出できる可能性を示唆した．
このように評判情報の分類結果を用いることで，評判情報の多様な解析が可能となる．


\section{おわりに}
本論文では，評判情報の2つのレベルを考慮した評価文書の分類手法を提案し
た．全体評判情報を用いて評価文書を分類し，その後に部分評判情報を用いて
分類することによって，分類精度の向上を試みた．映画のレビューを用いた実
験の結果，ナイーブベイズによる手法よりも分類精度が向上することを確認し
た．

また，評価文書の極性値と評判情報の極性値を利用することで，信頼性の高い情報
を抽出するための一手法を提案した．評価文書の極性値とその中の評判情報の極
値が異なる場合，その評判情報をフェアな評判情報であるとし，信頼性の高い
情報とした．実験により，フェアな評判情報が評判情報を評価する際に1つの指標と
なる可能性を示した．今後の課題としては，フェアな評判情報および，
評判情報の分類結果から読み取れる情報の利用法があげられる．



\bibliographystyle{jnlpbbl_1.2}
\begin{thebibliography}{}
\bibitem[\protect\BCAY{Chaovalit}{Chaovalit}{2005}]{chaovalit}
Chaovalit, P. and  Zhou, L. 
 \BBOP 2005\BBCP.
\newblock \BBOQ Movie Review Mining: a Comparison between Supervised
and Unsupervised Classification Approaches\BBCQ\
\newblock In {\Bem Proceedings of the 38th Hawaii Internatioanl Conference on System Sciences}.

\bibitem[\protect\BCAY{Dave, Lawrence, Pennock}{Dave\Jetal}{2003}]{dave}
Dave, K., Lawrence, S., and Pennock, D. M.
 \BBOP 2003\BBCP.
\newblock \BBOQ Mining the peanut gallery: Opinion extraction and semantic classification of product revews\BBCQ\
\newblock In {\Bem Proceedings of WWW}, \BPGS\ 519--528.

\bibitem[\protect\BCAY{飯田, 小林, 乾, 松本, 立石, 福島}{飯田\Jetal}{2005}]{iida}
飯田龍, 小林のぞみ, 乾健太郎, 松本裕治, 立石健二, 福島俊一 \BBOP 2005\BBCP.
\newblock \JBOQ 意見抽出を目的とした機械学習による属性—評価値の同定\JBCQ\
\newblock 自然言語処理研究会, 情報処理学会, \textbf{165}, \BPGS\ 21--28.

\bibitem[\protect\BCAY{鍛冶, 喜連川}{鍛冶 \JBA 喜連川}{2005}]{kaji}
鍛冶伸裕, 喜連川優 \BBOP 2005\BBCP.
\newblock \JBOQ 依存構造を考慮した評価文書の分類\JBCQ\
\newblock 自然言語処理研究会, 情報処理学会, \textbf{170}, \BPGS\ 15--20.

\bibitem[\protect\BCAY{Morinaga}{Morinaga\Jetal}{2002}]{morinaga}
Morinaga, S., Ymamanishi, K., Tateishi, K., and Fukushima, T., \BBOP 2002\BBCP.
\newblock \BBOQ Mining Product Reputations on the Web\BBCQ\
\newblock In {\Bem Proceedings of SIGKDD 02}.

\bibitem[\protect\BCAY{Mui}{Mui}{2002}]{mui}
Mui, L., Halberstadt, A., and  Mohtashemi, M. 
 \BBOP 2002\BBCP.
\newblock \BBOQ A Computational Model of Trust and Reputaion\BBCQ\
\newblock In {\Bem Proceedings of the 35th Hawaii Internatioanl Conference on System Sciences}.

\bibitem[\protect\BCAY{鈴木, 高村, 奥村}{鈴木\Jetal}{2004}]{suzuki}
鈴木泰裕, 高村大也,  奥村学 \BBOP 2004\BBCP.
\newblock \JBOQ Weblogを対象とした評価表現抽出\JBCQ\
\newblock  人工知能学会, SIGSW\&ONT-A401-2.

\bibitem[\protect\BCAY{竹原, 中島, 角谷, 田中}{竹原\Jetal}{2004}]{takehara}
竹原幹人, 中島伸介, 角谷和俊, 田中克己 \BBOP 2004\BBCP.
\newblock \JBOQ Web情報検索の為のBlog情報に基づくトラスト値の算出方法\JBCQ\
\newblock 日本データベース学会Letters, \textbf{3} (1), \BPGS\ 101--104.

\bibitem[\protect\BCAY{立石, 石黒, 福島}{立石\Jetal}{2001}]{tateishi}
立石健二, 石黒義英, 福島俊一 \BBOP 2001\BBCP.
\newblock \JBOQ インターネットからの評判情報検索\JBCQ\
\newblock 自然言語処理研究会, 情報処理学会, \textbf{144}, \BPGS\ 75--82.

\bibitem[\protect\BCAY{Turney}{Turney}{2002}]{turney}
Turney, P. D. 
 \BBOP 2002\BBCP.
\newblock \BBOQ Thumbs Up or Thumbs Down? Semantic Orientation Applied
to Unsupervised Classification of Reviews\BBCQ\
\newblock In {\Bem Proceedings of the 40th Annual Meeting of the
  Association for Computational Linguistics}, \BPGS\ 417--424.

\bibitem[\protect\BCAY{矢野, 目良, 相沢}{矢野\Jetal}{2004}]{yano}
矢野宏実, 目良和也, 相沢輝昭 \BBOP 2004\BBCP.
\newblock \JBOQ 趣向を考慮した評判情報検索手法\JBCQ\
\newblock 自然言語処理研究会, 情報処理学会, \textbf{164}, \BPGS\ 165--170.


\end{thebibliography}


\begin{biography}

\bioauthor{安村　禎明}{
1993年大阪大学基礎工学部卒業．1998年同大学院基礎工学研究科博士後期課程修了．
同年東京工業大学大学院助手．2004年神戸大学工学部助教授．現在，同大学大学院工学研究科准教授．
博士（工学）．機械学習，テキストマイニング，エージェントに関する研究に従事．人工知能学会，
電子情報通信学会，情報処理学会，IEEE各会員．
}
\bioauthor{坂野　大作}{
2004年岡山県立大学情報工学部卒業．2006年神戸大学大学院自然科学研究科情報知能工学専攻修了．
現在，NTTコミュニケーションズ株式会社に勤務．在学中，テキストマイニングの研究に従事．
}
\bioauthor{上原　邦昭}{
1978年大阪大学基礎工学部情報工学科卒業．
1983年同大学院博士後期課程単位取得退学．
大阪大学産業科学研究所助手，講師，神戸大学工学部情報知能工学科助教授，同都市安全研究センター教授，
同大学大学院自然科学研究科教授を経て，
同大学院工学研究科教授．
工学博士．人工知能，特に機械学習，マルチメディア処理の研究に従事．
情報処理学会，人工知能学会，電子情報通信学会，計量国語学会，日本ソフトウェア科学会，AAAI各会員．
}

\end{biography}






\biodate

\end{document}
