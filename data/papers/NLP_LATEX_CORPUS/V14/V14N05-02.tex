    \documentclass[japanese]{jnlp_1.3e}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}
\usepackage{amsmath}

\Volume{14}
\Number{5}
\Month{Oct.}
\Year{2007}
\received{2006}{12}{27}
\revised{2007}{5}{14}
\accepted{2007}{6}{18}

\setcounter{page}{41}

\jtitle{概念間の関連度計算のための大規模概念ベースの構築}
\jauthor{奥村　紀之\affiref{KUEE} \and 土屋　誠司\affiref{tokushima} \and 渡部　広一\affiref{KUEE} \and 河岡　　司\affiref{KUEE}}
\jabstract{
人間は日常会話において，様々な連想を行っている．例えば，「車」という語から「タイヤ」，
「エンジン」，「事故」，…，といった語を自然に思い浮かべ，連想によって会話の内容を柔軟に
拡大させている．コンピュータ上での連想機能の実現には，概念ベースが重要な役割を果たす．
概念ベースでは，言葉の意味（概念）を属性とその重みで定義している．概念ベースの構築方式として，
概念（約4万語）とその属性を，電子化国語辞書の語義説明文から抽出する方法が提案されている．
しかしながら，定義的な国語辞書から取得される概念や属性の数が少数であり，連想の精度に
問題がある．

本論文では，電子化国語辞書の語義説明文から構築した概念ベースを核に，電子化新聞等の
一般的な記事文から共起情報を基に概念ベースを拡大し，約12万語規模の概念ベースを構築する
手法を提案している．概念ベースの拡張においては，まず，国語辞書の各見出し語に対する語義
説明文から基本的な概念に対し，信頼性の高い属性を取得する．それらを基に，新聞記事等から
抽出した各概念に対する共起語を属性候補として追加する．その後，属性関連度（概念と属性の
関連の強さ）により不適切な属性（雑音属性）を除去し，属性の質を向上させている．また，各属性に
付与する重み（属性重み）は，概念を属性集合により構成される仮想文書と捉え，文書処理における
キーワードの重み付与方法（$\mathit{tf}\cdot\mathit{idf}$法）の考え方に準拠する方法により求めている．
提案手法で構築した概念ベースと国語辞書のみで構築した概念ベースを関連度評価実験により
比較評価し，提案手法で構築した概念ベースが精度的に優れていることを示した．
}
\jkeywords{連想機能，概念ベース，関連度計算方式，属性信頼度，概念価値，属性重み}

\etitle{A Construction of Large-scale Concept-base for Calculation of Degree of Association between Concepts}
\eauthor{Noriyuki Okumura\affiref{KUEE} \and Seiji Tsuchiya\affiref{tokushima} \and Hirokazu Watabe \affiref{KUEE} \and Tsukasa Kawaoka \affiref{KUEE}} 
\eabstract{
We human beings associate various words in daily conversation. For example, we naturally associate `Tire', `Engine', `Accident', and so on with `Automobile', and expand contents of conversation by association. Concept-base is the key role for achievement of association mechanism on computers. The meanings of words (concepts) are defined by attributes and weights in Concept-base. As construction method of Concept-base, it is suggested that concepts (about 40000 words) and attributes are picked up from descriptive texts on electronic dictionaries. However, the number of concepts and attributes picked up from dictionaries are small, and Concept-base has some problems about accuracy of association.

In this paper, Concept-base is expanded by coincidence information of general texts such as electronic newspapers based on Concept-base which is constructed from descriptive texts on electronic dictionaries, and it is suggested that a construction method of 120,000 words scale Concept-base. In extension of Concept-base, first, basic concepts are gotten from descriptive texts on electronic dictionaries about each words which are mentioned in dictionaries and get attributes which have high reliability. Co-occurring words are gotten based on Concept-base which is made from electronic dictionaries as nomination of attributes from electronic newspapers. After this manipulation, improper attributes (noise attributes) are cut off using Degree of Association of attributes, and attributes' quality is made higher. In addition, weights (attributes' weights) of each attributes are given as weights often used in information retrieval and text mining by ascribing Concept-base to virtual documents. At the last, it is shown that accuracy of Concept-base made by suggested method is higher than accuracy of Concept-base made by only dictionaries using experiment of Degree of Association.
}
\ekeywords{Association Mechanism, Concept-base, Calculation method of Degree of Association, Degree of Reliability, Value of Concept in Concept-base, Attributes' Weight}

\headauthor{奥村，土屋，渡部，河岡}
\headtitle{概念間の関連度計算のための大規模概念ベースの構築}

\affilabel{KUEE}{同志社大学大学院工学研究科}{Graduate School of Engineering, Doshisha University}
\affilabel{tokushima}{徳島大学大学院ソシオテクノサイエンス研究部}{Institute of Technology and Science, The University of Tokushima}



\begin{document}
\maketitle


\section{はじめに}
我々人間は，日常生活において様々な会話の中から必要に応じて情報を取捨選択している．
さらに，会話の流れに即して語の意味を適宜解釈し，適切な応答を行っている．人間は語の
情報から適切な応答を行うために，様々な連想を行っている\cite{yoshimura2006}．例えば，「車」という語から
「タイヤ」，「エンジン」，「事故」，…，といった語を自然に連想する．連想によって，
会話の内容を柔軟に拡大させている．このように，柔軟な会話ができる背景には，語の意味や，
語と語の関係についての膨大な知識を有しているため，種々の知識から語と語の関連性を判断し，
新たな語を連想することができることが挙げられる．実生活における会話では，「車と自動車」，
「自動車と自転車」のように，同義性や類似性の高い語と語の関係のみならず，「車と運転」，
「赤ちゃんと玩具」，「雨と傘」のように，広い意味での語と語の関連性の評価が必要となる
場合が多い．

人間とコンピュータ，あるいはコンピュータ同士の会話においても，人間のような柔軟で
常識的な応答を行うためには連想機能が重要となる．そのためには，コンピュータに語と
語に関する知識を付与し，同義性や類義性のみならず，多様な観点において語と語の関連の
強さを定量的に評価する手法が必要となる．

これまで，コンピュータにおける会話処理の重要な要素の一つとして，語と語の類似度に
関する研究がなされてきた．類似度の研究では，シソーラスなどの知識を用いて，語と語が
意味的にどの程度似ているかを評価することを目的としている\cite{kasahara1997}．そのため，会話において
未知の語が出現した場合には，既知の知識との類似度を算出し，同義語や類義語に置換する
ことによって語の意味を理解することが可能となる．

一方，本論文では，コンピュータとの会話において，「雨が降っていますよ」という文に対し，
「雪」，「霧」，…などの「雨」に対する同義語や類義語だけではなく，「雨」や「降る」という語から，
人間が自然に想起するような，「傘」，「濡れる」，「天気予報」，…などの語を幅広く
想起させ，自然な会話を行うための連想機能を実現することを目的としている．コンピュータが
このような連想をできるならば，「雨が降っていますよ」という文に対して，「それでは傘を
持っていきます」という応答を生成することが可能となる．

コンピュータの連想機能を実現するために，概念ベースとそれを用いた関連度計算方式が提案
されている\cite{kojima2004,watabe2001,watabe2006}．概念ベースでは，語の意味（概念）が，電子化国語辞書から抽出した特徴語
（直接意味語・間接意味語）と重みの集合で定義されている．各特徴語（属性）の重みは，概念と概念の
関連の強さを定量的に評価するための基本量として定義している．すなわち，概念ベースの
構築においては，概念に対する属性をどのように抽出し，各属性に付与する重みを
どのように決定するかが重要となる．

本論文では，電子化辞書から構築された4万語規模の概念ベースを，電子化された新聞記事等を
用いて12万語規模の概念ベースへ拡張する手法について述べている．概念ベースの構築手法に
ついては，電子化辞書から見出し語に対する語義説明文から属性を抽出し，属性信頼度に基づく
精錬を行う手法が提案されている．しかしながら，この手法には大きく2つの問題点が存在する．

第一には，辞書の語義説明文から取得される大部分の属性は，語の狭義の意味を説明する語
（直接意味語）であり，間接的に見出し語と関連を持つ広義の意味語（間接意味語）を獲得することが
困難である点である．これは，コンピュータに柔軟な連想機能を実現する上で，同義や類義の語
以外の連想語を取得する際に大きく影響する．直接意味語と間接意味語について，「自動車」の
例を挙げる．

\noindent
例．自動車
\begin{description}
\item[直接意味語] 車，車輪，原動機，回転，装置，ブレーキ，…
\item[間接意味語] 渋滞，免許証，事故，便利，交通，信号，保険，レース，…
\end{description}

第二には，4万語規模の概念ベースでは，幅広い連想を行い，語と語の関連性を定量化する上で
語彙が不十分である点である．概念を定義するための属性は，全て概念ベースに定義されている
語でなければならないという制約があるため，4万語規模の概念ベースに定義されていない語を，
新たな属性として概念に付与するためには，概念ベースの拡張が必須となる．

概念ベースの拡張においては，概念に付与すべき属性の抽出手法，並びに，獲得した属性に対する
重みの付与手法が必要となる．まず，国語辞書からの概念ベース構築の際に適切に属性を取得することが
できなかった概念を抽出し，不適切な概念を削除する．属性の抽出手法として，電子化された新聞記事等における共起に
基づく手法を提案する．また，重みの付与手法として，属性関連度と概念価値に基づく手法を
提案する．このように拡張した概念ベースの有用性を，関連度計算方式を用いた評価実験によって
示している．


\section{概念ベース}

概念ベース\cite{kojima2004,hirose2002}は，概念（見出し語）とその特徴を表す複数の語（属性）を対の組として集めた語の知識
ベースである．任意の概念$A$は，見出し語$A$と属性$a_i$，重み$w_i$により以下のように定義する．
\begin{equation}
A=\{(a_1,w_1),(a_2,w_2),(a_3,w_3),\cdots,(a_k,w_k)\}
\end{equation}
なお，属性となる全ての語は概念ベースの概念として定義されていなければならない．このことから，
各概念は$n$次元の属性連鎖集合として定義されることとなる（図\ref{fig:concept-base}）．
すなわち，概念$A$の属性$a_i$を一次元の属性（一次属性）と呼ぶ．さらに，属性$a_i$を概念として見た
場合，$a_i$の属性$a_{i_j}$を概念$A$の二次元の属性（二次属性）として導出することが可能である．

\begin{figure}[b]
	\begin{center}
	\includegraphics{14-5ia2f1.eps}
	\caption{概念ベース}
	\label{fig:concept-base}
	\end{center}
\end{figure}

概念とは，$n$次元の属性連鎖集合で定義される属性空間である．概念は，無限連鎖による属性集合で
あるため，起点となる概念を識別するために「見出し語」と言う表現を用いる．すなわち，見出し語とは，
$n$次元の属性連鎖集合によって定義された属性空間を識別するためのラベルである．さらに，単に
「属性」と表記する場合は，各概念の一次属性を表すものとする．

各属性の重みは，概念と他の概念との関連の強さを定量的に評価するための基本量として付与している．
すなわち，概念間の関連の強さは概念を構成する（属性，重み）の対の集合の総合的な一致度合いに
基づき定量化される．このため，概念間の関連の強さを定量化するためには，属性とその重みを具体的に
どのように付与するかが重要となる．

なお，本論文で対象とする概念ベースでは，各概念の属性はシソーラス等を用いて意味的に圧縮していない．
その理由として，各概念が持つ微妙な特徴が意味的な圧縮を行うことによって失われること，また，概念を
意味的に適切に圧縮することが困難であることが挙げられる．


\section{関連度計算方式}

関連度計算方式\cite{watabe2006}は，概念ベースに定義された語と語の関連の強さを，同義性，類似性のみに関わらず
定量化する手法である．本論文では，概念を構成する属性集合間の一致の度合いを定量化する
関連度計算方式を前提に，この方式に適した概念ベースの構築法を論じている．

また，語と語の類似性評価手法として，シソーラスなどを用いて属性の意味的な圧縮を行った
概念ベースを前提に各概念をベクトルと見なし，余弦を用いて定量化するベクトル空間モデルが
広く利用されている\cite{Kawashima2005}．この方式は，「赤ちゃんと子ども」や「自動車と車」といった，類似性の
高い語と語の類似性評価には適しているが，「赤ちゃんと玩具」や「自動車と事故」といった語と
語の関連性は，類似性という観点からは関連性評価が困難であると考えられる．そのため，本論文に
使用する概念ベースは，より柔軟に語と語の関連の強さを定量化するために関連度計算方式を
前提としている．

以下，概念間の属性一致度，並びに属性一致度に基づき概念関連度を求める関連度計算方式について
述べる． 


\subsection{属性一致度}

概念$A$, $B$の属性を$a_i$, $b_j$，対応する重みを$u_i$, $v_j$とし，それぞれ属性が$L$個，$M$個あるとする．
($L\leq M$)．また，各概念の属性の重みを，その総和が$1.0$となるよう正規化している．
\begin{gather*}
A=\{(a_i,u_i)|i=1\sim L\} \\
B=\{(b_j,v_j)|j=1\sim M\}
\end{gather*}
このとき，概念$A$と概念$B$の属性一致度$\mathit{MatchWR}(A,B)$を以下のように定義する．
\begin{gather}
 \mathit{MatchWR}(A,B)=\sum_{a_i=b_j}\mathit{min}(u_i,v_j)\\
 \mathit{min}(u_i,v_j)=
  \begin{cases}
	u_i(u_i\leq v_j)\\
	v_j(v_j<u_i)
  \end{cases}
\end{gather} 
ただし，$a_i=b_j$は属性同士が一致した場合を示している．すなわち，一致した属性の重みのうち，
小さい方の重みの和が属性一致度となる．属性一致度は$0.0\sim 1.0$の値をとる．

\subsection{概念関連度}

概念関連度$\mathit{MR}$は，対象となる二つの概念において，一次属性の組み合わせについて属性一致度を求め，
これを基に概念を構成する属性集合全体としての一致度合いを計算することで算出される．

具体的には，まず，見出し語として一致する属性同士($a_i=b_j$)について，優先的に対応を決定する．
他の属性については，全ての一次属性の組み合わせにおいて属性一致度を算出し，属性一致度の和が
最大となるように組み合わせを決定する．属性一致度を考慮することにより，属性同士の見出し語としての
一致だけではなく，一致度合いの近い属性を有効に対応づけることが可能となる．

また，概念$A$, $B$間の見出し語として一致する属性($a_i=b_j$)については，以下の処理により別扱いとする．
$a_i=b_j$なる属性があった場合，それらの属性の重みを参照し，$u_i>v_j$となる場合は，$a_i$の重み$u_i$を
$u_i-v_j$とし，属性$b_j$を概念$B$から除外する．逆の場合は，同様に$b_j$の重み$v_j$を$v_j-u_i$とし，
属性$a_i$を概念$A$から除外する．見出し語として一致する属性が$T$組あった場合，概念$A$, $B$はそれぞれ
$A' $, $B' $として以下のように再定義され，これらの属性間には見出し語として一致する属性は
存在しなくなる．

見出し語として一致した属性の概念関連度を$\mathit{MR}_{\mathit{com}}(A,B)$とし，以下の式で定義する．
\begin{gather}
 \mathit{MR}_{\mathit{com}}(A,B)=\sum_{a_i=b_j}\mathit{min}(u_i,v_j) \\
 A' =\{(a_i' ,u_i' )|i=1\sim L-T\} \nonumber\\
 B' =\{(b_j' ,v_j' )|j=1\sim M-T\} \nonumber \\
 \mathit{min}(u_i,v_j)=
  \begin{cases}
   u_i(u_i\leq v_j)\\
   v_j(v_j<u_i)
  \end{cases}
\end{gather} 
次に，見出し語として一致する属性を除外した$A'$, $B'$の概念関連度を$\mathit{MR}_{\mathit{def}}(A',B')$とする．
$\mathit{MR}_{\mathit{def}}(A',B')$を算出するために，属性数の少ない方の概念$A'$の並びを固定し，属性間の属性一致度の和が
最大になるように概念$B'$の属性を並べ替える．この時，対応にあふれた属性は無視する．概念$A'$の属性
$a_i'$と概念$B'$の属性$b_{x_i}$が対応したとすると，概念$B'$は以下のように並び換えられる．
\begin{equation}
B' =\{(b_{x_1},v_{x_1}),(b_{x_2},v_{x_2}),\cdots,(b_{x_{L-T}},v_{x_{L-T}})\}
\end{equation}
この結果，見出し語として一致する属性を除去した属性間の概念関連度$\mathit{MR}_{\mathit{def}}(A',B')$を
以下の式によって定義する．$\mathit{MR}_{\mathit{def}}(A',B')$は対応が決定した属性間の重みの比率と，
重みの平均値を属性一致度に乗じることで，属性一致度を補正する．
\begin{gather}
 \mathit{MR}_{\mathit{def}}(A',B')=\sum_{s=1}^{L-T}\mathit{MatchWR}(a_s',b_s')\times 
	\frac{\mathit{min}(u_s',v_s')}{\mathit{max}(u_s',v_s')}\times \frac{u_s'+v_s'}{2}\\
 \mathit{max}(u_i,v_j)=
  \begin{cases}
   u_i(u_i\geq v_j)\\
   v_j(v_j>u_i)
  \end{cases}
\end{gather} 
このように，見出し語として一致する属性間の概念関連度$\mathit{MR}_{\mathit{com}}(A,B)$と，見出し語として一致しない
属性間の概念関連度$\mathit{MR}_{\mathit{def}}(A',B')$をそれぞれ算出し，合計を概念$A$, $B$の概念関連度$\mathit{MR}(A,B)$とする．
\begin{equation}
 \mathit{MR}(A,B)=\mathit{MR}_{\mathit{com}}(A,B)+\mathit{MR}_{\mathit{def}}(A',B')
\end{equation}
概念関連度もまた，属性一致度と同様$0.0\sim 1.0$の値をとる．



\section{関連度計算方式を用いた概念ベース評価法} \label{hyouka}

構築した概念ベースの性能評価は，概念ベースに定義されている概念$X$と概念$Y$の関連の強さに対して，
人間の評価と関連度計算の比較により行う．任意の概念$X$と概念$Y$に対し出来るだけ人間の
判断結果に近い結果が得られる概念ベースが，連想機能を実現する上で有効であると考えられる．



\subsection{評価用データ}

任意の概念を基準概念$X$とし，人間が判断して非常に高い関連があると考えられる概念$A$，
概念$A$ほどではないが，概念$X$に対して関連があると考えられる概念$B$，そして，概念$X$に
対して無関連だと考えられる概念$C$を一組とするデータを準備する．このような4つの見出し語が
一組となり構成されるデータセットを$X$-$\mathit{ABC}$評価用データと呼ぶ（表\ref{Table:X-ABC}）．

\begin{table}[t]
\input{02t1.txt}
\end{table}



\subsection{X-ABC関連度評価法}

基準概念$X$に対して，概念$A$，概念$B$，概念$C$の概念関連度$\mathit{MR}(X,A)$，$\mathit{MR}(X,B)$，$\mathit{MR}(X,C)$を
算出する．

このとき，それぞれの概念関連度の間に以下の式が成立するならば，判断は正しいとする．また，
全$X$-$\mathit{ABC}$評価用データに対し，以下の式を満たす$X$-$\mathit{ABC}$評価用データの比率を$C$平均順序正解率と呼ぶ．$set_{num}$は$X$-$\mathit{ABC}$評価用データの総数である．
\begin{gather}
\mathit{MR}(X，A) - \mathit{MR}(X，B) > \mathit{AveMR}(X，C) \\
\mathit{MR}(X，B) - \mathit{MR}(X，C) > \mathit{AveMR}(X，C) \\
\mathit{AveMR}(X，C) = \frac{\sum_{i=1}^{\mathit{set}_{\mathit{num}}}\mathit{MR}(X_i，C_i)}{\mathit{set}_{\mathit{num}}}
\end{gather}
なお，$\mathit{AveMR}(X，C)$は$X$-$\mathit{ABC}$評価用データ全体における$MR(X,C)$の平均値である．基準概念$X$に
対して無関連である概念$C$との概念関連度$\mathit{MR}(X,C)$は，0となるのが理想であるが，一つでも一致する
属性があった場合，$\mathit{MR}(X,C)$は$0$とならない．そのため，$\mathit{AveMR}(X，C)$を概念関連度の誤差とみなし，
各概念関連度($\mathit{MR}(X,A)$，$\mathit{MR}(X,B)$，$\mathit{MR}(X,C)$)間に誤差以上の有意差があった場合を正解し，
概念ベースの性能評価を行う．



\section{国語辞書を用いた基本概念ベース構築法} \label{kihon-make}

本節では，電子化国語辞書から概念ベースを構築する手法について述べる．

この手法では，電子化国語辞書から各見出し語に対して，語義説明文に含まれる自立語を属性候補として
抽出し，それらを，属性信頼度（語に関する種々の知識から属性としての確からしさを定量化した値）により
精錬し不適切な語を削除する\cite{kojima2004}．その後，手作業で作成した重み学習データを用いた最適化実験により属性の
重みを付与することにより概念ベース（基本概念ベース）を構築している．また，属性の取得数が少数で
あった見出し語に関しては，基本概念ベースには定義していない．



\subsection{電子化辞書からの属性抽出}

電子化国語辞書の見出し語の語義説明文中に含まれる自立語を構文解析により機械的に
抽出する．次に，見出し語の意味には関係なくどの説明文にも形式的に含まれる自立語は削除し
属性候補を得る（Ex. する，なる，…）．このようにして，概念総数約3万4千，属性総数約150万，
各概念につき平均約40の属性を持つ初期概念ベースが得られる．初期概念ベースは，厳密には
関連度計算のための基本量として重みが付与された概念ベースではなく，「概念—属性」の対の
集合が取得され，各属性の語義説明文内での出現頻度を重みとして保持している．



\subsection{学習による重み付与手法} \label{sec:gakushu}

初期概念ベースについて説明文中の出現頻度と語に関する種々の知識（シソーラスや同義語辞書等）を
用いて属性らしさを表す属性信頼度を求める\cite{kojima2004}．さらに属性信頼度の値により属性のクラス分けを行い，
学習実験によりクラス毎の最適な属性の重みを得る．初期概念ベースを用いて属性信頼度を算出し，
実験により各属性の重みを算出する重み学習による属性重み付与手法について述べる．

各属性の重みが属性の確からしさを表す属性信頼度に関係することは明らかであるが，各属性信頼度に
対してどのような重みを付与すればよいのかは極めて難しい課題である．そこで，手作業で用意した
学習データを用いて，評価結果が最適となる属性の重みを実験的に求める手法が提案されている．
学習実験により属性の重みを決定する際に，各属性の重みを連続値として最適化を行うのは不可能である．
したがって，属性信頼度を基準とし，6つのクラスに分割し，クラスごとに重みを最適化する．以下，
属性信頼度と属性信頼度を算出するための手がかり，学習データ，実験的に決定したクラス別の重みに
ついて述べる．

\subsubsection{属性信頼度と信頼度クラス}

属性信頼度は複数の手がかりを用いて算出され，各手がかりに合致する属性の確からしさは
手作業によるサンプルの目視評価によって求められている．属性信頼度を算出するための手がかりは
以下の6項目である．
\begin{enumerate}
\item 概念と属性の一致
\item 関係データに定義されている
\item 初期概念ベースの頻度重み
\item 初期概念ベースを用いた概念関連度
\item 概念と属性の表記の部分一致
\item 概念と属性が相互属性関係にある
\end{enumerate} 
\noindent
関係データとは電子化辞書を解析した際に取得された語と語の関係を
示すデータであり，同義・類義・反意などの関係が定義されている．また，相互属性関係とは，
概念$A$の属性$a_i$に対し，概念$a_i$の属性として概念$A$が付与されている場合，概念$A$と
属性$a_i$は相互属性関係にあると定義する．

また，複数の手がかりに該当する属性の属性信頼度は，独立事象の確率合成によって算出する．
独立事象$P_1$, $P_2$の起こりうる確率が$p_1$, $p_2$であった場合，$P_1$, $P_2$が同時に起こりうる
確率$P$は以下の式\ref{eq:gousei}によって算出する．
\begin{equation}
  P = \frac{p_1 p_2}{p_1 p_2 + (1-p_1)(1-p_2) }
  \label{eq:gousei}
\end{equation}
算出された各属性の属性信頼度を表\ref{Table:shinraido-class}に示すように信頼度クラスに
分類する．
\begin{table}[b]
\input{02t2.txt}
\end{table}

\subsubsection{各信頼度クラスの属性の重み}

重み学習データ（表\ref{Table:gakushu-data}）を用いてC平均順序正解率が最高となる各属性
信頼度クラスの重みは表\ref{Table:gakushu-kekka}のように得られる．

\begin{table}[b]
\input{02t3.txt}
\end{table}

重みが$0$となる信頼度クラス$5$，$6$に関しては，属性として採用されず，概念ベースから
削除される．信頼度クラス$1$に関しては，同義・類義・反意をさらに細分化して重みを算出しており，
同義が$8$，類義が$4$，反意が$1$となっている．このとき，概念ベースの概念総数は約3万4千，
属性総数は約53万，平均属性数は各概念につき約16個となる．このように構築された概念ベースを
基本概念ベースと呼ぶ．

\begin{table}[b]
\input{02t4.txt}
\end{table}



\subsubsection{特徴と問題点} \label{special}

学習による重み付与手法は，概念ベースの属性を選別し，適切な重みを付与する手法としては
十分評価できるものである．しかし，同じ信頼度クラスに属する属性には
同じ重みを付与することになるため，信頼度クラスの設定が曖昧であると適切な重みを算出することが
困難になる．

また，この方式は，学習データに大きく依存するため一般性に問題が残る（図\ref{fig:270-590}）．
図\ref{fig:270-590}では，重みを最適化するために使用した590組の学習データによるC平均順序
正解率と，590組の学習データと重複しない500組の評価データによるC平均順序正解率を示している．
\begin{figure}[t]
	\begin{center}
	\includegraphics{14-5ia2f2.eps}
		\caption{基本概念ベースの性能評価}
		\label{fig:270-590}
	\end{center}
\end{figure}

最適化実験に使用した学習データによるC平均順序正解率と，最適化実験に使用しなかった
評価データによるC平均順序正解率では，およそ10\%の差違が生じており，学習対象となる
学習データに大きく依存する重みが算出されていることが分かる．
さらに，語彙数の拡大された概念ベースの構築に際しては，信頼度クラスの
分割数の設定と，それに伴う最適化学習時間などに多くの課題が発生する．



\section{新聞記事を用いた概念ベース構築法}

本節では，基本概念ベースの構築において，電子化辞書から適切な属性を抽出することができなかった
見出し語について，新聞記事などを用いて属性を取得し，概念ベースを大規模なものへ拡張し
構築する手法について述べる．また，基本概念ベースに定義されている概念についても，属性を
追加している．なお，基本概念ベースへの属性追加手法として，語間の論理関係を用いた属性拡張\cite{kojima2004a}が
提案されているが，基本概念ベースに定義される概念のみを対象としており，本論文で目的とする
概念ベースの拡張とは本質的に異なる．

基本概念ベースに定義されている約4万語の概念では，日常会話に出現する語に幅広く対応することが
困難であり，少なくとも国語辞書の見出し語として記載される概念については，概念ベースとして
構築することが望ましい．しかし，電子化辞書に記載される語義説明文からは適切に属性を取得できない
概念が多数存在するため，新聞記事やWEB文書など，一般の文書から属性を獲得することが必要となる．

新聞記事など一般の記事から取得した属性候補の確からしさは，電子化辞書に記載される語義説明文から取得した
属性候補に対して低下する．そのため，概念に対して不適切な属性（雑音属性）の除去を行い，適切な
重みを付与する必要がある．これには，\ref{sec:gakushu}節に述べたように，属性信頼度の考え方に
基づく概念ベースの精錬手法が有効であると考えられるが，概念数の増大により，適切な学習データを
作成することや，学習データに基づく重みの最適化を行うために時間がかかることなど，種々の問題が発生する．
したがって，大規模な概念ベースを構築する際には，概念ベースの規模に即した精錬手法が必要となる．

本論文では，大規模に拡張した概念ベースの精錬手法として，情報検索やテキストマイニングなどの
分野において広く利用されるキーワード重み付け手法である$\mathit{tf}\cdot\mathit{idf}$法\cite{tokunaga1999}に基づき各概念に付与
された属性に対し初期属性重みを付与する．さらに，その初期属性重みを用いることにより，拡張した概念
ベースに定義される任意の概念と概念の概念関連度を算出することが可能となる．そのため，各概念と
属性の概念関連度を特に属性関連度と呼び，属性関連度を用いて雑音属性の除去を行う．また，
$\mathit{idf}$の考え方に基づく概念価値を算出し再度重みを付与することにより，概念ベースの質の向上を
図っている．



\subsection{電子化辞書からの見出し語抽出}

一般的な国語辞書にはおよそ20万語の語彙が収録されている．電子化国語辞書を用いた基本概念ベースの
構築においては，見出し語の説明文から取得された自立語数（属性数）が少数である場合には，その見出し語は
概念として採用されていなかった．しかし，4万語程度の概念では，自然な会話を行うために語と語の
関連性を定量化する上で語彙が不十分である．そこで，電子化新聞の記事を用いることにより，国語辞書からは
属性の取得が困難であった見出し語（概念）について，属性を抽出する手法を提案する．

国語辞書に掲載されている20万語のうち，見出し語（概念）として不適切な表記を除去した約12万語の
概念について，電子化新聞（毎日新聞，日本経済新聞）より属性を取得する．すなわち，
基本概念ベースに定義されている概念についても，同様に属性を取得する．表\ref{Table:get-word}に電子化辞書に
記載されており，且つ基本概念ベースでは定義されなかった見出し語（概念）の例，および，見出し語として
不適切な表記の例を示す．

\begin{table}[t]
\input{02t5.txt}
\end{table}

基本概念ベースにはカタカナ語や固有名詞が定義されていなかった場合が多い．また，一般的に会話文中に
出現するような「飲食店」などの語も定義されていない．見出し語として不適切であるとしたものは，「…」
による表記の省略，「〈〉」による表記の使用例，「・」による表記の並列等である．



\subsection{電子化新聞からの属性抽出} \label{get-attribute}

電子化新聞には，電子化辞書のように「語—説明文」という明確な関係がない．このため，
電子化新聞から「概念—属性」の関係を抽出するためには，新聞記事内での語と語の共起を
手がかりとする手法が有効であると考える\cite{hirose2002}．本論文における共起とは，句読点によって区切られた
領域において，単語$A$と単語$B$が同時に出現している場合，単語$A$と単語$B$は共起していると
定義する．例えば，図\ref{fig:news-kyouki}に示すように，新聞記事内に「…，大学が国立研究所など
外部の研究機関に大学院の研究室を置く，…」という文があった場合，語「大学，国立，研究所，外部，…」
など，文中に出現する単語は共起していると定義する．このように，電子化新聞中の記事を句読点に
区切られた領域に分割し，領域ごとに約12万語に拡張された概念ベースに定義される概念および属性候補を
自立語として抽出する．

\begin{figure}[b]
	\begin{center}
	\includegraphics{14-5ia2f3.eps}
		\caption{共起の例}
		\label{fig:news-kyouki}
	\end{center}
\end{figure}

また，抽出された領域内の単語$A$，単語$B$，単語$C$，…の間には，単語$A$を概念とした場合，
その属性として共起している単語$B$，単語$C$，…が付与されるという関係にある．「…，大学が
国立研究所など外部の研究機関に大学院の研究室を置く，…」の例では，表\ref{Table:kyouki-zokusei}
のように「概念—属性」の関係を取得する．

\begin{table}[t]
\input{02t6.txt}
\end{table}

このようにして，各概念に対して取得された属性数は平均で100属性ほどである．



\subsection{初期属性重みの付与}

本論文では，最終的な属性重みとして属性関連度と概念価値を用いる．しかし，前節までの手順により
「概念—属性」の関係を抽出した段階では，各概念に対する属性に適切な重みが付与されていないため，
属性関連度を算出することができない．そこで，$\mathit{tf}\cdot\mathit{idf}$法の考え方に基づく初期重みを付与する
ことにより，属性関連度を算出する．

\subsubsection{疑似$\mathit{tf}$の算出}

$\mathit{tf}$とは，対象文書内に同一の単語が出現する頻度である．すなわち，限られた領域内で頻繁に
出現する単語は重要であるという指標となる．しかし，本論文で構築する概念ベースでは，各概念に
対して，重複する属性は付与していない．したがって，各概念に対して付与される属性の出現頻度は
全て1回のみである．そのため，概念ベースからは定量的な$\mathit{tf}$の算出が困難である．

そこで，本論文では，概念ベースの初期属性重み算出のために，基本概念ベースと属性抽出の際の
共起情報を基に，以下の手順により，3段階の疑似$\mathit{tf}$値を各属性に付与する（図\ref{fig:shoki-shinraido}）．
$\mathit{tf}(A,a)$は，概念（見出し語）$A$に対する属性候補$a$の疑似$\mathit{tf}$値を示している．

\begin{figure}[t]
	\begin{center}
	\includegraphics{14-5ia2f4.eps}
		\caption{初期属性重み算出のための疑似$\mathit{tf}$導出}
		\label{fig:shoki-shinraido}
	\end{center}
\end{figure}

新聞記事を用いた概念ベースの拡張では，前提として基本概念ベースを使用している．基本概念ベースに
定義される概念に対し，付与されている属性の質は高い．そのため，基本概念ベースに定義されている
「概念—属性」の関係は信頼性が高いと考えられるため，疑似$\mathit{tf}$を1.0としている．

また，基本概念ベースには定義されていない「概念—属性」の関係は，新聞記事内での共起情報に
基づいて収集している．しかし，新聞記事内での共起情報のみでは，「概念—属性」の関係が
どの程度確からしいかを判定することは困難である．したがって，新聞記事内の共起情報のみによって
関係が示される属性に関しては疑似$\mathit{tf}$を0.0とし，属性候補として保留する．$\mathit{tf}\cdot\mathit{idf}$法では，
単語の出現頻度と，全文書における対数文書頻度を乗じることによりキーワードの重みを算出している．
そのため，疑似$\mathit{tf}$を0.0とした場合，$\mathit{tf}\cdot\mathit{idf}$法に基づいた重み付けを行うと，重みは0.0となる．
しかしながら，新聞記事内での共起情報以外に「概念—属性」の関係を明確にすることができないために，
属性候補を雑音属性として除去すると，大半の属性候補は概念ベースから除去されてしまう．そこで，
疑似$\mathit{tf}$を0.0とし属性候補を保留しておき，後述の属性関連度を算出し，属性としての採否を
決定することで，最終的な属性として付与することとする．

本論文では，直接意味語のみならず，間接意味語も含めて，概念の属性とすることを目的としている．
複合語を形成する語と語の間には間接意味語の関係となる場合が多いと考えられる．ここで，複合語とは，
「携帯電話」などのように，複数の自立語（名詞）が複合することによって，新たな意味を持つ語のことである．
新聞記事内に出現する語のうち，本論文では，特に隣接する語と語の間には
関係があると考え，記事内で隣接して出現する語と語を複合語として定義した．新聞記事から
取得された複合語はおよそ46万語ある． 概念と属性候補が複合語の関係にある場合，共起の条件のみを
満たす「概念—属性」の関係よりも信頼性があるものとし疑似$\mathit{tf}$値を0.5としている．

同様に，概念と属性候補の見出し語の表記が部分的に一致している場合，たとえば，「車と自動車」のように，
「車」という表記が一致しており，これらの語と語の間には関連があると考えられる．そのため，疑似$\mathit{tf}$値を0.5と
している．

さらに，国語辞書における自立語とその語義説明文の間には，語と語がどのような論理関係を持っているかが
記されている場合が多い．そこで，図\ref{fig:kankei}に示す関係を用いて，語と語の明確な論理関係を抽出し，
「概念—属性」の関係が国語辞書において論理関係を取得できる場合，疑似$\mathit{tf}$値を1.0としている．これは，
複合語や表記の部分的な一致とは異なり，国語辞書の情報から関係が明確となるため，概念に対して確からしい
属性であると判断し，疑似$\mathit{tf}$値を付与している．また，国語辞書の記載情報については，
「対」と記されている見出し語との関係は反意語，
「類」と記されている見出し語との関係は類義語，また，体言止めとなっている場合は見出し語と同義語，
「〜の略」と記されている場合は，見出し語と同義であるとした．

\begin{figure}[t]
	\begin{center}
	\includegraphics{14-5ia2f5.eps}
		\caption{同義・類義・反意の語彙説明文}
		\label{fig:kankei}
	\end{center}
\end{figure}

国語辞書の記載情報と同様に，シソーラスにおいて上位・下位・仲間（親ノードが同じ）（図\ref{fig:shoki-shinraido}）
関係にある「概念—属性」の関係も，人手で作成された信頼できる情報であるとし，疑似$\mathit{tf}$値を1.0としている．



\subsubsection{$\mathit{idf}$の考え方に基づく概念価値}

概念価値とは，概念ベースに定義されている各概念の概念ベース内における重要性を示す値である．
各概念は，$n$次の属性連鎖集合によって定義されている．各概念を特徴づける属性は，
各概念の語義説明文や同一の新聞記事に共に出現する語である．それら属性はすべて概念ベースにおいて
定義されているため，さらにそれらの属性の語義説明文や新聞記事に共出現する語を取得することが
可能である．したがって，$n$次の属性集合を仮想的な文書集合として捉えることができる．

本論文では，概念ベースを仮想的な文書空間と捉え概念価値を算出し，概念ベースに定義される
各概念に対する属性の重みとして付与する手法を提案する．概念ベースの特性上，多数の概念の
属性として付与されているような概念は参照頻度が高く，各概念を特徴づける上で価値が低いと
考えられる．そのため，対数文書頻度である$\mathit{idf}$の考え方に基づき，少数の概念にしか属性として
付与されていない概念の価値を重要視することを目的としている．


概念ベースにおける概念価値として，情報検索などの分野で広く利用されている$\mathit{tf}\cdot\mathit{idf}$に
基づく概念価値算出手法について述べる．本論文では特に，$\mathit{idf}$の考え方を基に概念価値の算出を
行う．

$\mathit{idf}$とは，稀に出現する語は重要であるという観点に基づいた情報価値である．一般に$\mathit{idf}$は
以下の式によって算出される．
\begin{equation}
 \mathit{idf}(t)=\log \frac{N}{\mathit{df}(t)}
\end{equation}

ここで，$N$は検索対象となる文書集合中の全文書数，$\mathit{df}(t)$は語$t$が出現する文書数である．
$\mathit{idf}$は，ある語が少数の文書にしか出現しない場合において大きな値となり，全ての文書に
出現するような語は最小の値となる．一般に検索対象となる文書数は膨大であり，対数をとることで
その分布を抑制している．

本論文で対象としている概念ベースは，$n$次元の属性連鎖集合で定義されており，見出し語を
起点とし，$n$次元までの属性集合を取得することが可能である．したがって，概念ベースに
定義される全見出し語数（約12万語）を仮想的な全文書数とし，ある概念$A$が12万語の概念の中で
属性として参照されている見出し語数を，仮想的な概念$A$の出現文書数とみなすことができる．
したがって，概念ベースにおける擬似的な$\mathit{idf}$を以下の式によって定義する．
\begin{equation}
 V\_ \mathit{CB}_{(n)}(t)=\log_2\frac{N_{\mathit{all}}}{\mathit{df}(t)} \label{idf-base}
\end{equation}

このとき，$N_{\mathit{all}}$は概念ベースに定義される全概念数である約12万，$\mathit{df}(t)$は，語$t$を$n$次属性内に
属性として保持している概念数である．
なお，一般に$\mathit{idf}$を算出する際の抑制関数として常用対数が用いられている．これは，情報検索や
テキストマイニングなどで対象とする文書数が数億から数十億といった巨大な規模の文書をソースとしているためである．
一方，本論文で扱う概念ベースは約12万語の仮想的な文書集合であり，常用対数を用いることによって抑制幅が大きくなり
各値の分布が高密度に圧縮されるため，対数の底は2としている．

このように，$\mathit{idf}$の考え方に基づき，$n$次の属性集合を用いて擬似的に算出する概念価値を$V\_\mathit{CB}_{(n)}$と定義する．

\subsubsection{初期属性重みの付与} \label{shoki-omomi}

本論文では，属性関連度を用いて各概念に付与された属性に重みを算出する手法を提案する．そのため，
属性関連度を算出するために，各概念に付与される属性には属性重みが付与されている必要がある．
属性関連度を算出するための初期属性重みとして，疑似$\mathit{tf}$と$V\_\mathit{CB}_{(1)}$による重み付けを行う（式\ref{shoki-zokuseiomomi}）．
\begin{equation}
 w(A,a)=p\_ \mathit{tf}(A,a)\times V\_\mathit{CB}_{(1)}(a) \label{shoki-zokuseiomomi}
\end{equation}

$w(A,a)$は概念$A$に対する属性候補$a$の属性重み，$p\_\mathit{tf}(A,a)$は概念$A$に対する属性候補$a$の
疑似$\mathit{tf}$値，$V\_\mathit{CB}_{(1)}(a)$は属性候補を新聞記事から収集し，疑似$\mathit{tf}$を各概念に対する属性候補に
付与した後に，疑似$\mathit{tf}$値が0.0となった属性候補を除去した概念ベースでの一次属性を用いた$a$の
概念価値である．

\subsection{属性関連度} \label{kinji-shinraido}

概念ベースに定義される任意の概念と概念の関連度を概念関連度と呼ぶことに対し，
「概念—属性」の関係にある概念同士の概念関連度を特に属性関連度($\mathit{AR}$)と呼ぶ．属性関連度は
概念関連度と同様に，各概念に付与される属性に対して属性重みが付与されることにより算出される．
各属性に重みが付与されていない限りは属性関連度を算出できないため，\ref{shoki-omomi}節に
述べた手法により重みを付与し，概念$A$に対する属性$a_i$の属性関連度を算出している（式\ref{zokusei-kanrendo}）．
\begin{equation}
\mathit{AR}(A,a_i) = \mathit{MR}(A,a_i) \label{zokusei-kanrendo}
\end{equation}

また，属性関連度を用いて新聞記事から拡張した概念ベースの属性の精錬を行う．新聞記事から「概念—属性」の
関係を抽出した場合，国語辞書など定義的な情報源から抽出する場合と比較すると，属性としての信頼性が低下する．
そのため，初期属性重みを基に，属性を精錬する必要がある．新聞記事からの属性拡張を行っているが，前提条件として
基本概念ベースを使用しているため，精錬に際しては，図\ref{fig:270-590}に示した500組の$X$-$\mathit{ABC}$評価用データを
用いて，基準概念$X$に対し無関連の概念である概念$C$の平均値，すなわち基本概念ベースにおける$\mathit{MR}(X,C)$の
平均値(0.02)を閾値とし，属性を選別している．このとき，拡張した概念ベースは，概念総数約12万，属性総数約250万，
各概念に対し平均約30属性が付与された．



\subsection{属性関連度と概念価値に基づく重み付与手法} \label{shin-omomi}

$\mathit{tf}\cdot\mathit{idf}$法では，ある限られた領域内に頻出する語は重要であるという考え方に基づく$\mathit{tf}$と，
全文書集合において稀に出現する語は重要であるという考え方に基づく$\mathit{idf}$を乗じることによって
各キーワードの重みを算出している．一方，本論文では，$\mathit{idf}$の考え方に基づく概念価値を定量的に
算出することは可能であるが，出現頻度の情報に基づく$\mathit{tf}$を算出することができない．そのため，
疑似$\mathit{tf}$を付与することにより，$\mathit{tf}\cdot\mathit{idf}$法に準拠した手法による重み付けを行っている．

しかし，疑似$\mathit{tf}$は3段階の値であり，詳細な重みを算出できているとは言い難い．そこで，疑似$\mathit{tf}$と
概念価値によって重みを付与した概念ベースを用いて属性関連度を算出し，「概念—属性」の関連の強さが
大きいほどその属性は概念にとって重要な属性であると考え，属性関連度($\mathit{AR}$)と概念価値($V\_\mathit{CB}_{(n)}$)を
乗じた値を重みとして付与する．

具体的には，概念$A$の属性$a_i$の重み$u_i$を以下の式で定義する．
\begin{equation}
 u_i=\mathit{AR}(A,a_i)\times V\_\mathit{CB}_{(n)}(a_i)
\end{equation}

本論文で提案する属性関連度と概念価値による重み付与手法では，\ref{kihon-make}節で作成された概念ベースへの
実験による重み付与手法とは異なり，各属性の重みが離散値ではなく連続値をとることに特徴がある．



\section{$X$-$\mathit{ABC}$関連度評価法を用いた評価実験}

\ref{hyouka}節に述べた$X$-$\mathit{ABC}$関連度評価法を用いて，拡張した概念ベースの性能評価を行った．
評価用データとして，多数の$X$-$\mathit{ABC}$評価用データを準備し，3名の被験者により目視評価を行い，
3名全員が正しいと判定した1780組の$X$-$\mathit{ABC}$評価用データを採用した．実験に際しては，
初期属性重みを付与した概念ベースに対し，属性関連度と概念価値を$V\_\mathit{CB}_{(1)}\sim V\_\mathit{CB}_{(4)}$まで展開した
値をそれぞれ重みとして付与した概念ベースの性能比較を行った．また，本論文では属性関連度と概念価値を乗じ，
重みを付与するため，再帰的に重みを算出することが可能であり，再帰的に重みを付与した場合の
C平均順序正解率の動向を調査した．最後に，基本概念ベースと拡張した概念ベースの性能比較として，
500組の$X$-$\mathit{ABC}$評価用データと1780組の$X$-$\mathit{ABC}$評価用データを用いて性能評価を行った．



\subsection{属性関連度と概念価値による重み付与手法の検証}

\ref{shoki-omomi}節において作成した初期属性重みを付与した概念ベースと，\ref{shin-omomi}節において
作成した概念ベースの性能比較を行った．初期属性重みに関しては，疑似$\mathit{tf}$が0.0となった属性候補を
除去し，残った属性候補のみを用いて概念価値を算出し，重みとして付与している（式\ref{idf-base}）．
また，属性関連度と概念価値による
重み付与手法では，初期属性重みを用いて算出した属性関連度を基に，属性関連度が$0.02$に満たない属性候補を除去し，
1次属性から算出した概念価値から4次属性まで概念ベースを属性連鎖によって展開し算出した概念価値を用いて重みを
付与した概念ベースを構築した．図\ref{fig:shoki-kanrendo-comp}にそれぞれのC平均順序正解率を示す．

\begin{figure}[t]
	\begin{center}
	\includegraphics{14-5ia2f6.eps}
		\caption{初期属性重みと属性関連度$\times$概念価値}
		\label{fig:shoki-kanrendo-comp}
	\end{center}
\end{figure}

図\ref{fig:shoki-kanrendo-comp}から，雑音属性の除去を行った後に，2次属性まで各概念を属性連鎖によって
展開した際に取得される概念価値$V\_\mathit{CB}_{(2)}$と属性関連度を乗じ，重みを付与した場合が最高となり，
71.2\%となった．以降の検証では，属性関連度と概念価値$V\_\mathit{CB}_{(2)}$を乗じた重みを付与した概念ベースを
拡張概念ベースと定義し，拡張概念ベースを用いて実験を行った．



\subsection{属性関連度を繰り返し算出した重み付与手法の検証}

属性関連度と概念価値に基づく重み付与手法は，算出された重みを基に再度属性関連度を算出することによって
再帰的に重みを付与することが可能である．すなわち，拡張概念ベースに付与された重みを基に属性関連度を算出し，
概念価値を乗じた重みを付与することができる．このような操作を繰り返すことによってC平均順序正解率にどのような
変動が見られるかを調査した．図\ref{reverse}に結果を示す．

\begin{figure}[b]
	\begin{center}
	\includegraphics{14-5ia2f7.eps}
		\caption{再帰的に重みを付与した場合のC平均順序正解率}
		\label{reverse}
	\end{center}
\end{figure}

図\ref{reverse}では左から順に拡張概念ベースを用いて属性関連度を算出し概念価値を乗じた重みを付与した
概念ベース(first)，firstを用いて属性関連度を算出し概念価値を乗じた重みを付与した概念ベース(second)…，と
順に4回目の繰り返しまで示している．図\ref{reverse}から，再帰的に重みを付与することは可能であるが，
徐々にC平均順序正解率が低下することが分かる．すなわち，再帰的に重みを付与しても，C平均順序正解率の向上は
見込めないことが分かる．



\subsection{基本概念ベースと拡張概念ベースの性能比較}

本論文では，新聞記事から概念ベースを拡張する手法について論じているが，拡張のベースとなる
基本概念ベースに定義される概念について，拡張することによって基本概念ベース部分の性能にどのような
変化が見られるかを検証した．検証には基本概念ベースに定義されている概念のみで構成された$X$-$\mathit{ABC}$評価用データ500組と
基本概念ベースに未定義の概念も含む1780組の$X$-$\mathit{ABC}$評価用データを用いた．実験結果を図\ref{kihon-kakucho}に示す．

\begin{figure}[b]
	\begin{center}
	\includegraphics{14-5ia2f8.eps}
		\caption{基本概念ベースと拡張概念ベースの性能比較}
		\label{kihon-kakucho}
	\end{center}
\end{figure}

図\ref{kihon-kakucho}から，基本概念ベースに定義されている概念について54.8\%から73.2\%へC平均順序正解率を
向上させたことが分かる．また，基本概念ベースに定義されていない概念も含む$X$-$\mathit{ABC}$評価用データについては，
基本概念ベースでは概念関連度を正しく算出することができない概念について，拡張概念ベースによって
対応を可能としたため，対応語彙数の拡張に成功していることが分かる．基本概念ベースでは，1780組の
$X$-$\mathit{ABC}$評価用データに対応できずC平均順序正解率が7.4\%となり，拡張によって対応語彙数が拡大したことによる
有効性が示されている．



\subsection{考察}

検証実験により，基本概念ベースの性能を大幅に向上し，対応できる語彙数を拡張しても，
拡張概念ベースの基本概念ベース相当部分における性能もまた，元々基本概念ベースに定義されていた概念と
同等の性能で概念関連度を算出することが可能となったと言える．

すなわち，本論文で提案した手法を用いて基本概念ベースを新聞記事によって拡張し，属性関連度と
概念価値を用いた重み付与手法によって構築した拡張概念ベースは有効であることが示されたと言える．


\section{おわりに}

人間とコンピュータの自然な会話を実現するにはコンピュータに大規模の語について，
類義語のみならず幅広い関連語を連想できる機能を持たせることが必須となる．この連想機能により，
会話において，知らない語を知っている語に置き換え，文の意味を理解し，さらに入力文に含まれる
語から応答にふさわしい語を想起することにより，自然な応答文を作り出すことが可能となる． 

本論文では，12万語を超える大規模概念ベースを構築するため，電子化辞書の語義説明文から
だけではなく，電子化新聞等，対象語（概念）を含む一般的な情報文から多数の属性候補語を収集し，
それらを属性関連度と概念価値に基づく属性重み付与法により精錬し適切な属性語を選出する
方式を提案した．この方式では，流行語など，電子化国語辞書にも掲載されていない新概念についても
WEBのホームページを使い逐次拡張が可能となる．また，提案方式で構築した大規模概念ベース（12万語）を
用いた関連度評価実験により，拡張された概念に関しても4万語規模概念ベース以上の性能が得られることを
示した．

ただし，提案手法では固有名詞と用言に関しては十分な属性を獲得することが出来ず，今後の課題として対応が必要である．固有名詞については，概念ベースとは別に，人名辞典，企業名辞典，地名辞典などの辞典類の知識ベース化による対処，また，用言については，大規模な格フレーム辞書\cite{kawahara2005,kawahara2006}の利用による対処を考えている．

\acknowledgment
本研究は文部科学省からの補助を受けた同志社大学の学術フロンティア研究プロジェクトにおけ
る研究の一環として行った．




\bibliographystyle{jnlpbbl_1.3}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{広瀬\JBA 渡部\JBA 河岡}{広瀬\Jetal }{2002}]{hirose2002}
広瀬幹規\JBA 渡部広一\JBA 河岡司 \BBOP 2002\BBCP.
\newblock \JBOQ
  概念間ルールと属性としての出現頻度を考慮した概念ベースの自動精錬手法\JBCQ\
\newblock 信学技報, 電子情報通信学会,NLC2001-93,109--116.

\bibitem[\protect\BCAY{笠原\JBA 松澤\JBA 石川}{笠原\Jetal
  }{1997}]{kasahara1997}
笠原要\JBA 松澤和光\JBA 石川勉 \BBOP 1997\BBCP.
\newblock \JBOQ 国語辞書を利用した日常語の類似性判別\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 38}  (7), \mbox{\BPGS\ 1272--1283}.

\bibitem[\protect\BCAY{河原\JBA 黒橋}{河原\JBA 黒橋}{2005}]{kawahara2005}
河原大輔\JBA 黒橋禎夫 \BBOP 2005\BBCP.
\newblock \JBOQ 格フレーム辞書の漸次的自動構築\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (2), \mbox{\BPGS\ 109--131}.

\bibitem[\protect\BCAY{河原\JBA 黒橋}{河原\JBA 黒橋}{2006}]{kawahara2006}
河原大輔\JBA 黒橋禎夫 \BBOP 2006\BBCP.
\newblock \JBOQ 高性能計算環境を用いたWebからの大規模格フレーム構築\JBCQ\
\newblock 自然言語処理研究会, 情報処理学会.

\bibitem[\protect\BCAY{川島\JBA 石川}{川島\JBA 石川}{2005}]{Kawashima2005}
川島貴広\JBA 石川勉 \BBOP 2005\BBCP.
\newblock \JBOQ
  言葉の意味の類似性判別に関するシソーラスと概念ベースの性能評価\JBCQ\
\newblock \Jem{人工知能学会論文誌，20巻5号B}, \mbox{\BPGS\ 326--336}.

\bibitem[\protect\BCAY{小島\JBA 渡部\JBA 河岡}{小島\Jetal }{2002}]{kojima2004}
小島一秀\JBA 渡部広一\JBA 河岡司 \BBOP 2002\BBCP.
\newblock \JBOQ
  連想システムのための概念ベース構成法-属性信頼度の考え方に基づく属性重みの決
定\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 9}  (5), \mbox{\BPGS\ 93--110}.

\bibitem[\protect\BCAY{小島\JBA 渡部\JBA 河岡}{小島\Jetal }{2004}]{kojima2004a}
小島一秀\JBA 渡部広一\JBA 河岡司 \BBOP 2004\BBCP.
\newblock \JBOQ
  連想システムのための概念ベース構成法-語間の論理関係を用いた属性拡張\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 11}  (3), \mbox{\BPGS\ 21--38}.

\bibitem[\protect\BCAY{徳永}{徳永}{1999}]{tokunaga1999}
徳永健伸\JED\ \BBOP 1999\BBCP.
\newblock \Jem{情報検索と言語処理}.
\newblock 東京大学出版会.

\bibitem[\protect\BCAY{渡部\JBA 河岡}{渡部\JBA 河岡}{2001}]{watabe2001}
渡部広一\JBA 河岡司 \BBOP 2001\BBCP.
\newblock \JBOQ 常識的判断のための概念間の関連度評価モデル\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 8}  (2), \mbox{\BPGS\ 39--54}.

\bibitem[\protect\BCAY{渡部\JBA 奥村\JBA 河岡}{渡部\Jetal }{2006}]{watabe2006}
渡部広一\JBA 奥村紀之\JBA 河岡司 \BBOP 2006\BBCP.
\newblock \JBOQ 概念の意味属性と共起情報を用いた関連度計算方式\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 13}  (1), \mbox{\BPGS\ 53--74}.

\bibitem[\protect\BCAY{吉村\JBA 土屋\JBA 渡部\JBA 河岡}{吉村\Jetal
  }{2006}]{yoshimura2006}
吉村枝里子\JBA 土屋誠司\JBA 渡部広一\JBA 河岡司 \BBOP 2006\BBCP.
\newblock \JBOQ 連想知識メカニズムを用いた挨拶文の自動拡張方式\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 13}  (1), \mbox{\BPGS\ 117--141}.

\end{thebibliography}

\begin{biography}

\bioauthor{奥村　紀之}{
2003年同志社大学工学部知識工学科卒業．
2005年同志社大学大学院工学研究科知識工学専攻博士前期課程修了．
同大学院工学研究科知識工学専攻博士後期課程在学．
知識情報処理の研究に従事．
言語処理学会会員．}

\bioauthor{土屋　誠司}{
2000年同志社大学工学部知識工学科卒業．
2002年同志社大学大学院工学研究科知識工学専攻博士前期課程修了．
同年，三洋電機株式会社入社．
2007年同志社大学大学院工学研究科知識工学専攻博士後期課程修了．
同年，徳島大学大学院ソシオテクノサイエンス研究部助教．
工学博士．
主に，知識処理，概念処理，意味解釈の研究に従事．
言語処理学会，人工知能学会，情報処理学会，電子情報通信学会各会員．}

\bioauthor{渡部　広一}{
1983年北海道大学工学部精密工学科卒業．
1985年同大学院工学研究科情報工学専攻修士課程修了．        
1987年同精密工学専攻博士後期課程中途退学．
同年，京都大学工学部助手．
1994年同志社大学工学部専任講師．
1998年同助教授．工学博士．
主に，進化的計算法，コンピュータビジョン，概念処理などの研究に従事．
言語処理学会，人工知能学会，情報処理学会，電子情報通信学会，システム制御情報学会，精密工学会各会員．}

\bioauthor{河岡　　司}{
1966年大阪大学工学部通信工学科卒業．
1968年同大学院修士課程修了．
同年，日本電信電話公社入社，情報通信網研究所知識処理研究部長，
NTTコミュニケーション科学研究所所長を経て，現在同志社大学工学部教授．
工学博士．
主にコンピュータネットワーク，知識情報処理の研究に従事．
言語処理学会，人工知能学会，情報処理学会，電子情報通信学会，IEEE (CS)各会員．
}

\end{biography}

\biodate


\end{document}
