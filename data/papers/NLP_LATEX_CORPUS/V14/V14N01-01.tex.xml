<?xml version="1.0" ?>
<root>
  <jtitle>日本語係り受け解析の線形時間アルゴリズム</jtitle>
  <jauthor>颯々野学</jauthor>
  <jabstract>日本語係り受け解析を行なう新しいアルゴリズムを述べる．このアルゴリズムによれば，トップレベルの精度を落とすことなく線形時間で係り受け解析が行なえる．本論文では，アルゴリズムの形式的な記述を行ない，その時間計算量を理論的に議論する．加えて，その効率と精度を京大コーパスVersion2を使って実験的にも評価する．改良された係り関係のモデルと提案手法を組み合わせると，京大コーパスVersion2に対して従来手法よりもよい精度が得られた．</jabstract>
  <jkeywords>日本語係り受け解析，構文解析，依存構造解析</jkeywords>
  <section title="はじめに">構文解析において，精度と同様，計算効率も，自然言語処理の重要な問題の一つである．構文解析の研究では，精度に議論の重点を置くことが多いが，効率についての研究もまた重要である．特に実用的な自然言語処理のアプリケーションにとっては，そうである．精度を落とすことなく効率を改善することは，とても大きな課題である．本研究の目的は，日本語の係り受け解析(依存構造解析)を行なう効率のよいアルゴリズムを提案し，その効率の良さを理論的，実験的の両面から示すことである．本論文では，日本語係り受け解析の線形時間アルゴリズムを示す．このアルゴリズムの形式的な記述を示し，その時間計算量(timecomplexity)を理論的に論じる．加えて，その効率と精度を京大コーパスVersion2を使って実験的に評価する．本論文の構成は以下の通りである．第~2節では，日本語の構文的な特徴と典型的な日本語文の解析処理について述べる．第~3節では，英語や日本語の依存構造解析の従来研究について簡単に述べる．その後，第~4節で我々の提案手法を述べる．次に，第~5節で，二つの文節の依存関係を推定するための改良したモデルを述べる．第~6節では実験結果とその考察を記す．最後に，第~7節で本論文での我々の貢献をまとめる．</section>
  <section title="日本語文の解析">本節では，日本語の構文的特徴と典型的な日本語文の解析の手順について整理する．</section>
  <subsection title="日本語の構文的特徴">日本語は基本的にはSOV言語である．語順は比較的自由である．英語では，文中の語の構文的機能は語順で表される．一方，日本語では，後置詞(postpositions)によって表される．この点では，名詞の後に置かれる日本語の格助詞はドイツ語名詞の格変化と類似の役割を持っている．ドイツ語名詞は格変化することによって，文法的な格を表している．文節の概念も日本語の文節と似た概念である．文献で定義される英語のチャンク(chunk)も文節に近いといえる．は上記の日本語の性質と親和性があり，日本語文を構文的に分析するときに使われてきた．文節は，1~個以上の内容語(contentwords)とそれに続く0~個以上の機能語(functionwords)から構成される．文節をこのように定義することによって，ドイツ語のような屈折言語において文中の語の文法的役割を分析するときと似た手法を日本語文を分析するときにも使うことができる．それゆえ，厳密なことを言えば，日本語の場合，語順が自由なのではなく，文節の順序が自由である．ただし，文の主動詞を含む文節は文の末尾に置かれなければならない．例えば，以下の2文は同じ意味を持つ:(1)健が彼女に本をあげた．(2)健が本を彼女にあげた．この2例文で，最も右の文節「あげた」(動詞の語幹と，過去や完了を表すマーカで構成されている)は文の末尾に置かれていることに注意されたい．ここで，上に述べたものも含めて，通常の書き言葉の日本語で仮定される係り受けの制約条件をまとめておく．これらの特徴は，基本的には韓国語やモンゴル語でも共通である．</subsection>
  <subsection title="日本語文解析の典型的な手順">日本語には前節のような特徴があるので，日本語文の解析では次のような手順が非常に一般的である:文を形態素に分割する(つまり形態素解析する)それらを文節にまとめ上げる文節間の係り関係を解析するそれぞれの係り関係にagent，object，locationなどの意味的役割のラベルを付ける我々は(3)における係り受け解析に焦点を置く．</subsection>
  <section title="関連研究">ここでは，主に時間計算量に重点を置いて関連研究を述べる．日本語はもちろん英語でも依存構造解析(dependencyanalysis)は研究されている．これらの論文の解析アルゴリズムでは，O(n^3)の時間がかかる．ここでnは単語数であるは，projectivedependencyparsingの決定的なアルゴリズムを提案している．このアルゴリズムの時間計算量の上限はO(n)である．このアルゴリズムをスウェーデン語のテキストで評価している．^,．日本語の係り受け解析では，文中の二つの文節の係り受けの確率を使うことが非常に多かった．HarunoらHaruno1998は，決定木を用いて係り受けの確率を推定した．FujioとMatsumotoFujio1998はCollinsのモデルの修正版を日本語の係り受け解析に適用した．Harunoらと，FujioとMatsumotoの両グループともCYK法を用いている．これはO(n^3)の時間がかかる．ここでnは文の長さ，つまり文節数を表している．SekineらSekine2000Backwardは最大エントロピー法(MaximumEntropyModeling;ME)を係り受けの確率の推定に使い，後方ビームサーチ(文末から文頭に向かうビームサーチ)で最もよい解析結果を見つける．このビームサーチのアルゴリズムはO(n^2)の時間がかかる．KudoとMatsumotoKudo2000Japaneseらも同じ後方ビームサーチをMEではなくサポートベクタマシン(SVMs)とともに用いている．二つの文節間の係り受けの確率を使わない統計的手法も少ないながらある．一つはSekineの決定的有限状態変換器を用いる手法である．Sekineは，の場所の97%は文中の五つの候補でカバーされると報告している．似た現象はMaruyamaとOginoも観測している．これらの調査にもとづき，Sekineは，決定的有限状態変換器を用いる効率のよい解析アルゴリズムを提案している．このアルゴリズムは，考慮する係り先の文節数を制限することでしらみつぶしに探索することを避け，O(n)の時間計算量となっている．しかしながら，彼のパーザは京大コーパスに対して77.97%の係り受け正解率(定義は第~節で述べる)しか得られていない．これは，89%を超える現在の最高精度よりもかなり低い．2文節間の係り受けの確率を用いない別の興味深い手法は，KudoとMatsumotoKudo2002によるCascadedChunkingModelである．このモデルはのアイデアにもとづく．彼らはこのモデルとSVMsを用いて，89.29%を得ている．彼らの手法では，解析時に評価される係り関係の数はCYK法や後方ビームサーチよりも相当少ないが，それでも時間計算量の上限はO(n^2)である．以上見たように，高い精度を保ちつつ線形時間の処理を保証して，どのように日本語係り受け解析を行なうかは，まだ解決されていない問題である．以下に記述するアルゴリズムがこの問題に対する答えとなろう．</section>
  <section title="アルゴリズム">本節では，提案アルゴリズムを解析時に使うものと，学習時に使うものとに分けて記す．解析時のアルゴリズム，その時間計算量，学習時のアルゴリズムを順に述べ，最後に提案アルゴリズムの特徴のまとめと関連研究との理論的な比較を述べる．</section>
  <subsection title="文を解析するアルゴリズム">我々の提案する係り受け解析のアルゴリズムの擬似コードを図~に示す．このアルゴリズムは，ある文節が別の文節に係るかどうかを決定する推定器(estimator)とともに用いる．推定器の典型的なものとして，SVMや決定木などの訓練できる分類器が考えられる．ここでは，文中の二つの文節の係り関係を推定できる，つまり係るか否かを決定できる何らかの分類器があり，その分類器の時間計算量は文の長さに影響されないと仮定しておく．係り関係の推定器を別にすれば，このアルゴリズムで使うデータ構造はわずか二つである．一つは入力に関するもので，もう一つは出力に関するものである．前者は，チェックすべき係り元の文節のIDを保持するためのスタックである．後者は，既に解析された係り先文節のIDを保持する整数の配列である．以下では，例を使いながら先に示したアルゴリズムの動作を説明する．図~の擬似コードに沿って，図~にある例文を解析してみよう．説明のため，図~のestimate_dependency()として完璧な分類器があるとする．この分類器は図~の例文に対して必ず正しい結果を返すとする．まず始めに0(健が)をスタックに積む．0は文の先頭の文節のIDである．この初期化の後，forループの各繰り返し(iteration)の中で解析がどのように進むかを見る．最初のiterationでは，0番目の文節と1番目の文節(彼女に)の係り関係をチェックする．0番目の文節は1番目の文節に係らないから，0をスタックに積み，次に1を積む．ここで，スタックの底は0であって1ではないことに注意されたい．より小さいIDが必ずスタックの底のほうに保持される．この性質のおかげで，非交差の制約(第~のC3)を破らずに解析を進めることができる．2回目のiterationでは，1をスタックから降ろし，1番目の文節と2番目の文節(あの)の係り関係をチェックする．1番目の文節は2番目には係らないので，再び1と2をスタックに積む．3回目のiterationでは，2をスタックから降ろし，2番目の文節と3番目の文節(本を)の係り関係をチェックする．2番目の文節は3番目に係るので，その関係をoutdep[]に格納する．outdep[j]の値は，第~j番目の文節の係り先を表す．例えばoutdep[2]=3は2番目の文節の係り先は3番目の文節であることを意味している．次に，1をスタックから降ろし，1番目の文節と3番目の文節の係り関係をチェックする．1番目の文節は3番目に係らないので1を再びスタックに積む．その後，3をスタックに積む．この段階で，スタックには頭から底に向けて3，1，0が格納されている．3回目のiterationでは，3をスタックから降ろす．3番目の文節と4番目の係り関係はチェックする必要がない．4番目の文節は文中の最も末尾の文節であり，3番目の文節は必ず4番目にかかるからである．そこでoutdep[3]=4とする．次に1をスタックから降ろす．この場合も，1番目の文節と4番目との係り関係のチェックはする必要がない．同様に，0番目の文節も4番目に係る．結果としてoutdep[1]=4とoutdep[0]=4となる．この時点でスタックは空となり，この解析の関数analyze()は終了する．解析結果である係り受け関係は，配列outdep[]に得られている．</subsection>
  <subsection title="時間計算量">一見したところ，提案したアルゴリズムの時間計算量の上限は，2重ループを含むためO(n^2)と思える．しかしそうではない．時間計算量の上限がO(n)であることを，図~におけるwhileループの条件部が何回実行されるかを考えることによって示す．条件部が失敗する回数と成功する回数とに分けて考える．whileループの条件部はN-2回失敗する．何故なら外側のforループが1からN-1へ，つまりN-2回実行されるからである．もちろん，whileループが無限ループになることはない．whileループの内部でstackに値を新たに積むことなく降ろしているので，いつかj==EMPTYになる．つまりj!=EMPTYを満たさず，whileループを抜けることになる．一方，この条件部はN-1回成功する．何故ならoutdep[j]=iがN-1回実行されるからである．文節jそれぞれについて，outdep[j]=iは必ず一度だけ実行される．j=stack.pop()を実行すると，jに格納されている値は失われ，その値は二度と再びスタックに積まれることはないからである．つまり，whileループは，高々N-1回実行される．これは末尾の文節を除く文節数に等しい．結局，whileループの条件部の実行回数は，失敗回数N-2と成功回数N-1を合計し2N-3となる．これは時間計算量の上限がO(n)となることを意味している．</subsection>
  <subsection title="訓練事例を作り出すアルゴリズム">前節のアルゴリズムで用いる分類器のための訓練事例を作り出すには，図~に示すアルゴリズムを使う．図~にある解析用のアルゴリズムと殆ど同じである．違いは，indep[]を使ってestimate_dependency()が正しい係り関係の判定を返す点と，outdep[]に係り先のIDを格納する必要がない点である．</subsection>
  <subsection title="特徴のまとめと関連研究との理論的な比較">我々の提案アルゴリズムは次のような特徴を持つ:特定の機械学習の方法に依存しない．訓練できる分類器ならどれでも使える．左から右へ文を一度だけスキャンする．時間計算量の上限はO(n)である．アルゴリズム中，最も時間を消費する部分である分類器の呼び出しの回数は，高々2N-3回である．アルゴリズムの流れとデータ構造は非常に簡単である．そのため，実装も易しい．我々のアルゴリズムと最も関連が深いモデルの一つは，のChunkingModelである．彼らのモデルと我々のアルゴリズムはF1を始め多くの共通点がある．彼らのモデルと我々のアルゴリズムの大きな違いは，入力文を何回スキャンするかにある(F2)．彼らのモデルでは，入力文を何回かスキャンする必要があり，これは計算上の非効率につながっている．最悪の場合ではO(n^2)の計算が必要になる．我々の解析アルゴリズムは，左から右に一度だけしかスキャンせず，実時間の音声認識などのような実用的なアプリケーションに対しても，より好適であろう．それに加えて，アルゴリズムの流れと利用するデータ構造は，CascadedChunkingModelで使われるものよりもずっと簡単である(F4)．彼らのモデルでは，チャンクタグを保持する配列が必要となり，入力文を何度もスキャンする間，この配列は正しく更新されなければならない．NivreによるProjectiveDependencyParsingの手法も，我々のアルゴリズムと深い関係がある．彼のアルゴリズムも，スタックを用いており，時間計算量の上限もO(n)である．ただし，我々のアルゴリズムが日本語を対象とし，係り先が必ず右にあることを前提にしているのに対し，Nivreのアルゴリズムは依存関係の向きはどちらでもよい．その点では，彼のアルゴリズムは我々の手法をより一般的にしたものと考えることができる．一方，では，単語間の依存関係を決めるルールを用意しておき，ある一定の優先度で選ぶとしている．我々は，依存関係が一方向である日本語に対して，機械学習を用いる方法を提示し，実際に検証している．我々の解析アルゴリズムは，shift-reduce法の最も簡単な形の一つと考えられる．典型的なshift-reduce法との違いは，アクションの型を複数持つ必要がなく，スタックの先頭のみ調べればよいという点である．これらの簡潔さの理由は，日本語が制約C2(第~節参照)を仮定できること，文脈自由文法の解析ではなく，係り受け関係のみの解析であることの二つによる．</subsection>
  <section title="係り関係を推定するためのモデル">2文節間の係り関係を推定するために，2文節に関係する形態的，文法的情報を素性のベクタとして表現し，それを入力として分類器に係るか否かを判断させる．その分類器として，サポートベクタマシン(SVMs)を用いた．SVMsは優れた特徴を持っている．その一つは，多項式カーネルを用いると，ある事例の持つ素性の組合せが自動的に考慮される点である．現在まで多数の分類タスクに対して，非常に優れた性能が報告されている．SVMsの形式的な記述については，文献を参照されたい．素性として，第~節以降で述べるものを用いた．実際には2文節間の係り関係の推定の処理は，図~のestimate_dependency()の中で行なう．推定しようとする2文節の形態的，文法的情報を素性のベクタとして表現し，SVMsに係るか否かを判定させることになる．以下では，まず基本となる標準素性を述べ，次にそれに追加して用いる付加的な素性について述べる．</section>
  <subsection title="標準素性">ここで「標準素性」といっているものは，でほぼ共通に使われている素性セットを指す．それぞれの文節について以下の素性を使った:主辞品詞，主辞品詞細分類，主辞活用型，主辞活用形，主辞表層形語形品詞，語形品詞細分類，語形活用型，語形活用形，語形表層形句読点開き括弧，閉じ括弧位置—文の先頭か文の末尾かここで主辞とは，概ね文節内の最も右の内容語に相当する．品詞が特殊，助詞，接尾辞を除き，最も文末に近い形態素を指す．語形とは，概ね文節内の最も右の機能語に相当する．品詞が特殊となるものを除き，最も文末に近い形態素を指す．これらに加えて，2文節間のギャップに関する素性も用いた．距離(1，2--5，6以上)と，助詞，括弧，句読点である．</subsection>
  <subsection title="注目文節の前後の文節">注目している係り元文節，係り先文節の前後の文節も有用である．それらが固定的な表現や格フレーム，その他の連語を表すことがあるからである．第~j番目の文節が係り元文節で，第~i番目の文節が係り先文節の候補だとする．j番目の文節とi番目の文節の前後にある文節のうち，次の三つを素性として考慮する:j-1番目の文節(jに係るときのみ)と，i-1番目の文節，i+1番目の文節の三つである．我々のアルゴリズムでは，j&lt;i-1を満たしj番目の文節がi番目の文節に係るかチェックしているとき，i-1番目の文節は必ずi番目の文節に係っていることに注意されたい．提案手法におけるデータ構造を簡単にしておくために，j番目，i番目の文節からさらに遠い文節については考慮しなかった．なお，j-1番目の文節がj番目の文節に係るかどうかはoutdep[]を見れば簡単にチェックできる．注目している文節の前後を使うのは，における動的素性と似ている．</subsection>
  <subsection title="文節内の追加素性">「標準素性」では，文節内に二つ以上の機能語を含むとき格助詞の情報を見落とすことがある．ある文節が格助詞と提題助詞を持つとする．このとき格助詞の後ろに提題助詞が来る．それゆえ，格助詞の情報を見落としてしまう．「標準素性」では文節内の最も右の機能語しか素性として扱われないからである．こういった情報を見落とさないように，文節内の全ての格助詞を素性として扱う．「標準素性」で見落とされる重要な情報は他にもある．それは，係り先候補の文節の最も左の語の情報である．この語は係り元の文節の最も右の語と慣用表現のような強い相関関係を持つことも多い．これに加えて，係り先候補文節の直後の文節の表層形も素性として使う．これは，第~節の素性とともに用いる．</subsection>
  <subsection title="並列句のための素性">並列構造を正しく認識することは，長い文を正しく解析する際に最も難しいことの一つである．KurohashiとNagaoは，二つの文節列の類似度を計算することによって並列句を認識する手法を提案している．現在までのところ，機械学習を使うシステムの中で並列構造を認識するための素性はあまり研究されていない．我々は最初のステップとして，並列構造を認識するための基本的な二つの素性を試した．注目している文節がキー文節(distinctivekeybunsetsu)であるとき，この二つの素性は使われる．一つ目の素性は，係り元文節がキー文節であるときアクティブになるものである．もう一つの素性は，係り元文節がキー文節で，その係り元文節と係り先候補の文節の主辞表層形が一致していればアクティブになるものである．単純さを保つため，対象とする主辞品詞は名詞のみとした．</subsection>
  <section title="実験と考察">提案アルゴリズムを利用したパーザをC++で実装し，その時間計算量の振る舞いや解析精度を実験的に評価した．</section>
  <subsection title="コーパス">提案アルゴリズムを評価するために，京大コーパスVersion2を使った．新聞記事の1月1日から1月8日分(7,958文)を訓練事例とし，1月9日分(1,246文)をテスト事例とした．1月10日分を開発用に用いた．これらの記事の使い方はと同じである．</subsection>
  <subsection title="SVM の設定">独自にC++で実装したSVMsのツールを用いた．カーネルとして，3次の多項式カーネルを用いた．特に記述がない限り誤分類のコストは1に設定した．</subsection>
  <subsection title="実験結果">解析精度テスト事例に対する我々のパーザの性能を表~に示す．従来研究との比較のために，性能評価には京大コーパスで標準的に使われる尺度である係り受け正解率と文正解率の二つを用いる．係り受け正解率とは，正しく解析された係り受けの割合であり(他の多くの文献と同様，文末の一文節を除く)，文正解率とは，全ての係り関係が正しく解析された文の割合である．「標準素性」を用いた場合の精度は比較的よい．実際，この係り受け正解率は動的素性を用いないときのCascadedChunkingModelとほぼ同じである．第~節で述べた全ての素性を用いた場合，我々のパーザは89.56%の係り受け正解率を得た．これは京大コーパスVersion2に対して公表されている精度の中で最もよいものである．時間計算量の漸近的な振る舞い図~に，我々のパーザのテスト事例に対する実行時間を示す．これはワークステーション(UltraSPARCII450MHz,1GBメモリ)を用いて計測した．図~より実行時間の上限が文の長さに比例しているのが分かる．これは，第~節で行なった理論的な分析と一致している．この実験結果を見て，確かに従来研究よりも時間計算量の上限は低く抑えられているが，我々のパーザの実際の処理時間はそれほど速くないと思われるかもしれない．パーザのこの遅さの主たる原因は，SVMsにおけるカーネル評価での膨大な計算のせいである．我々の実験では，SVMの分類器は4万個以上のサポートベクタを持っている．それゆえ，係り関係を判定するたびに膨大な内積計算が必要となる．幸い，この問題に対する解決策は既にKudoとMatsumotoKudo2003によって与えられている．彼らは高次の多項式カーネルを線形カーネルに変換する手法を提案し，変換された線形カーネルでは，精度を保ったまま元の多項式カーネルよりもおよそ30から300倍高速だったと報告している．彼らの手法を我々のパーザに適用すれば，処理時間も十分高速化されるだろう．彼らの手法を用いればどのくらい我々のパーザの速度が改善されるか粗く見積もるために，線形カーネルを用い，同じテスト事例に対してパーザを走らせてみた．図~に，線形カーネルを用いたパーザの処理時間を示す．なお計測には多項式カーネルを用いた場合と同じマシンを使った．3次の多項式カーネルを使う場合に比べて相当に高速である．非常に長い文であっても0.02秒以内で解析が行なえている．加えて，このパーザのスピードばかりでなく精度も我々が期待した以上だった．係り受け正解率は87.36%，文正解率は40.60%に達した．これらの精度は，素性の組合せを人手で選択して追加しているパーザよりもわずかに良い．</subsection>
  <subsection title="関連研究との比較">我々のパーザと関連研究におけるパーザとを時間計算量と精度の点から比較する．比較のサマリを表~に示す．我々のアルゴリズムとSVMsと組み合わせたものが時間計算量の点から優れた性質を持ち，加えてトップレベルの精度が得られている．文献との比較は，第~の記述にゆずる．UchimotoらUchimoto1999は最大エントロピー法と後方ビームサーチを用いている．文献によれば，解析時間はn^2に比例するとのことである．これに対し，我々のパーザは線形時間で文を解析し，精度もよい．工藤と松本の「相対モデル」のパーザも，後方ビームサーチを用いているので，時間計算量という点ではUchimotoらのパーザと同様である．文献では，「相対モデル」のパーザは，京大コーパスVersion3.0に対して，係り受け正解率91.37%を得，CascadedChunkingModelは91.23%を得たと報告されている．我々のパーザは，京大コーパスVersion2において，CascadedChunkingModelの精度を0.27ポイント上回っていることを考えると，我々のパーザと「相対モデル」パーザとの差も大きなものではないと判断できる．また，我々と同様SekineSekine2000Japaneseも線形時間で処理が進む非常に高速なパーザを提案している．彼の手法は，後方から係り先を決定していく．係り元の文節の語形の情報と，係り先候補(5つまで)の主辞の情報から，係り先を一つに決める決定的有限状態変換器を用いている．係り元の語形や5つの係り先候補の主辞の情報を細かく区別すると，状態(state)の数が多くなりすぎ，大量のメモリを消費するため，係り元の語形の状態を40に，係り先の主辞の状態を18に限定している．品詞や活用形の情報のみ利用している．このため，精度が大きく犠牲になっている．</subsection>
  <section title="おわりに">我々は線形時間で処理を行なう日本語係り受け解析のアルゴリズムを提案した．京大コーパスVersion2に対して実験を行ない，時間計算量と解析精度を調べた．時間計算量の上限はO(n)であることが確認でき，解析精度も従来報告されているものを上回った．精度の差は従来研究で報告されているものと大きくないため，精度面からの優位性は結論できないが，本研究で(1)提案アルゴリズムが理論的にも実験的にも時間計算量の上限がO(n)で抑えられていることと，(2)時間計算量を抑え，左から右へ一度しかスキャンしないにも関わらずトップレベルの精度が得られることの二つを示せた意義は大きいと考える．後方の文節を直接考慮しない提案アルゴリズムに一定の限界があることは明らかであるが，係り先として考慮する文節の数を増やしても精度が向上するとは限らず，その解決は単純ではない．我々はスタッキングにより精度が向上しないか検討したいと考えている．また，並列構造の認識についてもよりよいモデルを提案したい．document</section>
</root>
