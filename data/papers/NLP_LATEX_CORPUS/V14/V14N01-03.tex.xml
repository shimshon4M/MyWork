<?xml version="1.0" ?>
<root>
  <jtitle>日本語フレームネットに基づく意味役割推定</jtitle>
  <jauthor>肥塚真輔岡本紘幸	斎藤博昭小原京子</jauthor>
  <jabstract>本稿では，日本語フレームネットを背景に，述語項構造における項の意味役割を推定する統計モデルの定義，および獲得手法を提案する．本モデルの目的は，表層格では区別できない意味の区別である．本モデルは文と述語から述語項構造を同定して意味役割を付与すべき項を抽出し，それらに適切な意味役割を付与する．評価実験の結果，尤度が閾値を超える意味役割のみを付与する条件の下，意味役割を付与すべき項がわかっている文に対して精度77％，再現率68％，また，意味役割を付与すべき項がわかっていない文に対して精度63％，再現率43％で意味役割推定を実現し，本手法の有効性を示した．また，同一の表層格をもつ項に対して，複数の異なる意味役割の付与を実現した．</jabstract>
  <jkeywords>意味役割推定，最大エントロピー法，サポートベクタマシン</jkeywords>
  <subsubsection title="">*断片候補生成本稿で提案した項候補獲得手法では，項候補となるための要件を過不足なく満たす最適な断片候補を獲得するため，述語と直接係り受け関係にある文節から複数の断片候補を生成し，それらを確率モデルを用いて順位付けする．断片候補生成手法は以下の通りである．述語と直接係り受け関係にある文節を獲得する獲得した文節から，それが1つ以上の内容語を含むという前提の下，以下に適合する形態素の列を獲得する獲得した各形態素列に対して，それが1つ以上の内容語を含むという前提の下，以下の各ル−ルに基づいて断片候補を生成する</subsubsection>
  <section title="はじめに">コンピュータに自然言語の意味を理解させるためには，文の述語とその項の意味的な関係を表現する必要がある．竹内は，述語と項の深層関係を表現する手法としての語彙概念構造に着目，これに基づく辞書を提案している．語彙概念構造は述語と項の深層関係を抽象化するため，言い換えの分野で有効性が示されている．河原らは，用言とその直前の格要素の組を単位とした用例ベースの辞書，格フレーム辞書を提案し，それに基づく格解析モデルを提案している．照応や省略の解析に格フレーム辞書の有効性が示されている．格フレーム辞書は表層格を表現・区別し，語彙概念構造は表層格および深層関係を抽象化するものであり，表層格で区別できない述語と項の意味関係を個々の項について詳細に表現することはできない．これに対し，述語と項との詳細な意味関係を典型的場面についての構造化された知識である意味フレームに即して表現した体系として，日本語フレームネットが提案されている．日本語フレームネットは英語語彙情報資源FrameNetと同様にフレーム意味論に基づく日本語語彙情報資源で，意味フレーム別に，その意味要素である詳細な意味役割を定義し，その意味フレームに関与する述語項構造の述語となる語彙項目をリストアップしている．格フレーム辞書，語彙概念構造辞書および日本語フレームネットによる，述語「払う」に対する記述を図に示す．FrameNetは機械翻訳や語義曖昧性解消の分野で有効と考えられており，将来の適用に向けて，FrameNet意味役割を自動推定するタスクのコンテストも開催されているsrlconll/home.htmlならびにhttp://www.senseval.org/．FrameNetに基づく意味役割自動推定は，述語の各項に対し，詳細な意味役割に相当する，フレーム意味論における「フレーム要素(FrameElement)」を付与する試みである．この研究はGildeaらの提案に端を発する．Gildeaらは，条件付き確率モデルを用いた意味役割推定に加え，確率モデルの学習に必要な訓練事例の自動生成手法も提案した．Gildeaらの提案は，形式意味論の枠組みに沿って述語と項の意味的な関係を表現するPropBankを背景とした意味役割推定手法においても参照され，その改良として，確率モデルの獲得手法に最大エントロピー(ME)法やサポートベクタマシン(SVM)を用いた意味役割推定が複数提案された．また，文中のどの部分が項であるかを同定するため，形態素の品詞や句の文法機能を用いて項を抽象化し，頻出するものを項とする手法も提案された．日本語フレームネットではFrameNetの枠組や方法論をふまえ，日英の比較対照を考慮した日本語語義記述が実践されているが，日本語フレームネットを用いた，日本語を対象とした意味役割の自動推定に関する研究は行われていない．そこで本稿では，日本語フレームネットに基づき，述語項構造における項の意味役割を推定するモデルを提案する．日本語フレームネットは現在作成中であり，現時点では語彙資源の規模が非常に小さい．そのため，日本語の意味役割推定にはある程度規模の大きい英語FrameNetを対象とした既存の手法をそのまま適用できず，小規模の語彙資源でも十分な精度で推定可能な手法を新たに考える必要がある．本稿では以上を踏まえ，日本語フレームネットの注釈付き事例に基づく機械学習を用いて，意味役割を推定するモデルの獲得手法を提案する．意味役割推定モデルは，文と述語から述語項構造を同定，意味役割を付与すべき項を抽出し，それらに適切な意味役割を付与するという3つのタスクを担う．モデルの獲得には最大エントロピー法ならびにサポートベクタマシンを用い，項候補の獲得には構文情報を利用する．同時に，モデルの学習に必要な訓練事例の自動生成も行う．</section>
  <section title="モデルの定義">本稿で提案する意味役割推定モデルは，与えられた文と述語に対して取り得る全ての意味役割注釈パタンについての尤度を計算し，尤度が最も高い注釈パタンを出力するモデルである．すなわち，入力文Tと述語tが与えられた時の意味役割注釈パタンLの確率P(L|t,T)を最大にする意味役割注釈パタンL_bestが最終的な出力となる．L_best&amp;=&amp;L:P(L|t,T)eqnarray注釈パタンLはフレームf，項候補集合S，項候補-意味役割対応関係Cにより一意に決定されるため，式()右辺P(L|t,T)を以下のように定義した．P(L|t,T)&amp;&amp;P(C,S,f|t,T)*-2mm&amp;=&amp;P(C|S,f,t,T)P(S|f,t,T)P(f|t,T)eqnarray本稿では式()右辺を第1項からそれぞれ，対応付けモデル，項候補獲得モデル，フレーム選択モデルと呼ぶ．図に，これらのモデルの概要を示す．図中の各モデルについては以下で詳説する．ただし，項候補獲得モデル中の項候補同定モデル，および対応付けモデル中の自項独立/他項依存意味役割同定モデルの詳細は節で述べる．</section>
  <subsection title="フレーム選択モデル">フレーム選択モデルは与えられた文と述語から，項に付けられる注釈となるべき意味役割が定義された意味フレームを獲得するモデルである．我々はフレーム選択モデルを，tがfの見出し語に含まれる場合に1を，それ以外で0を返す関数R(f,t)を用い，以下のように定義した．P(f|t,T)&amp;&amp;R(f,t)eqnarrayフレーム選択モデルの例を図に示す．</subsection>
  <subsection title="項候補獲得モデル">項候補獲得モデルは与えられた文と述語およびフレームから，意味役割を注釈付けする項（断片）を獲得するモデルである．項候補の獲得手法を以下に示す．Tを構文解析し，tと直接係り受け関係にある部分木の集合S'''を得る．S'''の各要素s'''_iについて，形態素ならびに文節の単位で前後に短縮伸長し，項候補の候補（断片候補）s''_ijを生成，断片候補集合S''_iを得る（断片候補生成）．S''_iの各要素s''_ijに関し，P(s''_ij|f,t,T)がを越える要素をs'_ijとして集め，断片候補集合S'_iを得る．尤度P(s''_ij|f,t,T)は項候補同定モデル（節）により得られる．S'_iの各要素s'_ijについて，()の尤度P(s''_ij|f,t,T)=P(s'_ij|f,t,T)が最大となるs'_ijをs_iとし，項候補集合Sを得る．以上より，我々は項候補獲得モデルを以下のように定義した．P(S|f,t,T)&amp;&amp;_s_iSP(s_i|f,t,T)eqnarray項候補獲得モデルの例を図に示す．我々は，述語項構造における項が文節を基本に構成された語句であると仮定し，構文解析結果に基づいた項候補獲得手法を提案する．一方，河原らの格フレーム辞書構築の取り組みは，項の意味が表層格で抽象化されて表現されることを根拠とする．また，Baldeweinらは構文情報を用いた項の抽象化手法を提案している．我々の仮定はそれらと同様，項が構文情報によって抽象化できることを前提としている．</subsection>
  <subsection title="対応付けモデル">対応付けモデルは，与えられた文，述語，フレームならびに項候補から，項候補と意味役割の対応付けを行うモデルである．項と意味役割の対応付け手法は以下の通りである．項候補集合Sの各要素s_iについて，fに定義された意味役割r_kR_f（R_fはfに定義された意味役割の集合）が対応付けられる確率P(r_k|s_i,S,f,t,T)を算出する．P(r_k|s_i,S,f,t,T)は自項独立意味役割同定モデル（節）により得られる．Sの各要素s_iについて，()の尤度P(r_k|s_i,S,f,t,T)をP(c'_ik|S,f,t,T)とし，iについて重複のないようにc'_ikを集めたものを項候補-意味役割対応関係C'とする．C'の各要素c'_ikについて，()の尤度P(c'_ik|S,f,t,T)の積が最大となる意味役割対応付けC'_bestを得る．Sの各要素s_iについて，C'_bestを考慮した上で意味役割r_kが対応付けられる確率	P(r_k|s_i,C'_best,S,f,t,T)を算出する．P(r_k|s_i,C'_best,S,f,t,T)は他項依存意味役割同定モデル（節）により得られる．Sの各要素s_iについて，()の尤度P(r_k|s_i,C'_best,S,f,t,T)をP(c_ik|C'_best,S,f,t,T)とし，iについて重複のないようにc_ikを集めたものをCとする．以上より，我々は対応付けモデルを以下のように定義した．P(C'|S,f,t,T)&amp;=&amp;_s_iSP(c'_ik|S,f,t,T)&amp;=&amp;_s_iSP(r_k|s_i,S,f,t,T)C'_best&amp;=&amp;C'P(C'|S,f,t,T)P(C|S,f,t,T)&amp;=&amp;_s_iSP(c_ik|C'_best,S,f,t,T)&amp;=&amp;_s_iSP(r_k|s_i,C'_best,S,f,		t,T)eqnarray対応付けモデルの例を図に示す．</subsection>
  <section title="モデルの獲得">次に，節で定義した意味役割推定モデルを構築する手法について述べる．本稿で提案する手法は，大きく6つのステップで構成されている．日本語フレームネットから，意味フレーム定義，意味役割定義，品詞定義，見出し語，ならびに意味役割注釈付き事例を抽出する．フレーム意味論に反しない2つの仮定の下，抽出した事例から新しい事例を作成する．以下の仮定は，いかなる事例に適用しても言語的に不自然にならないものとして設定したもので，我々はこれらの仮定を妥当なものと考える．	述語に直接係る主語句（ガ格を末尾に持つ文節の全部分木）を削	除しても，他の項の意味役割は変化しない．		文の主辞となる述語の項は削除しても，他の全ての項の意味役割	が変化しない解釈が可能．	事例から確率モデルを学習する．意味役割推定モデルに基づくシステムを構築する．日本語フレームネットに定義された見出し語が述語の文をコーパスから抽出する．抽出した文の項の意味役割を推定する．本手法では，節で定義した意味役割推定モデルのうち，以下の3つのモデルを機械学習により獲得する．項候補同定モデル（式()条件P(s''_ij|f,t,T)):項候補獲得モデルにおいて断片候補が項候補となるかどうかを判定する．自項独立意味役割同定モデル（式()右辺P(r_k|s_i,S,f,t,T)):対応付けモデルにおいて，ある項候補にある意味役割が割り当てられるかを，他項の意味役割を考慮せずに判定する．他項依存意味役割同定モデル（式()右辺P(r_k|s_i,C'_best,S,f,t,T)):対応付けモデルにおいて，ある項候補にある意味役割が割り当てられるかを，他項の意味役割を考慮した上で判定する．我々は機械学習に，最大エントロピー法とサポートベクタマシンを用いた．最大エントロピー法の実装にはツールmaxentを用い，サポートベクタマシンの実装にはTinySVMtaku-ku/software/TinySVM/を用いた．サポートベクタマシンの出力は，シグモイド関数に代入することで確率値とみなした．なお，構文解析器にはCaboChaを用いた．以下に，各モデルの詳細を述べる．</section>
  <subsection title="項候補同定モデル">項候補同定モデルは，断片候補s''_ijが断片すなわち項候補となるかを判定するモデルであり，項候補獲得モデルに定義されている．項候補同定モデルが定義された式()には，断片候補が項候補となるための閾値が定義されており，最大エントロピー法およびサポートベクタマシンの出力に対する正当性から，今回はそれを0.5とした．学習に必要な正事例には日本語フレームネットから抽出した注釈付き事例を用い，負事例は抽出した事例と正事例を基に以下の2通りの方法を用いて準備した．また，学習には以下の素性を用いた．</subsection>
  <subsection title="自項独立意味役割同定モデル">自項独立意味役割推定モデルは，ある項候補にある意味役割が注釈付けられるかを判定するモデルであり，対応付けモデルに定義されている．対応付けモデルの定義式()()より明らかなように，本モデルは複数の意味役割候補から一つを選択する多値分類タスクと考えることができる．我々は機械学習に最大エントロピー法とサポートベクタマシンを用いたが，このうちサポートベクタマシンでは，多値分類にonevs.rest法を用いた．学習の素性には，項候補同定モデルの学習に用いた素性に加え，以下を利用した．</subsection>
  <subsection title="他項依存意味役割同定モデル">他項依存意味役割同定モデルは，他項に注釈付けられた意味役割を考慮した上で，項候補にある意味役割が注釈付けされるかを判定するモデルであり，対応付けモデルに定義されている．対応付けモデルの定義式()ならびに意味役割推定モデルの定義式()より明らかなように，本モデルも複数の意味役割候補から一つを選択する多値分類タスクと見なすことができ，自項独立意味役割同定モデル同様，サポートベクタマシンではonevs.rest法を適用した．学習の素性には，自項独立意味役割同定モデルの学習に用いた素性に加え，以下を利用した．</subsection>
  <section title="評価">定義した意味役割推定モデルの有効性を確認するために，獲得したモデルを用いて意味役割推定を行った．評価に際し，モデルへの入出力にそれぞれ3通りの条件を設定した．入力条件とその目的は以下の通りである．文と述語システム全体を評価文と述語，正しい断片候補（項候補の候補）項候補獲得モデルを評価文と述語，正しい項候補対応付けモデルを評価また，出力条件は以下の通りである．獲得した断片集合Sについての正誤判定を行う．獲得した項候補-意味役割対応関係Cについての正誤判定を行う．獲得したc_ikのうちで，尤度P(c_k|C'_best,S,f,t,T)が0.5を越えるものを出力し正誤判定を行う．出力条件()は，出力条件()において出力される意味役割注釈パタンのうち，この注釈パタンに含まれるものの意味役割が付与される確率が低い項候補については「項でない」とみなして出力することを意味する．我々は，以上の9通りの組合せ（入力3条件出力3条件）について，機械学習に用いた最大エントロピー法を用いた場合とサポートベクタマシンを用いた場合の2通りで，交差検定法により評価した．評価実験の対象フレームを表に，実験時に設定した各種パラメータを表に示す．また，評価実験の結果を表,に示す．評価実験の結果，本手法は(1)意味役割が付与されるべき項が分かっている文に対して精度77％，再現率68％，(2)意味役割が付与されるべき項がわかっていない文に対して精度63％，再現率43％の意味役割推定を実現した．計490文という少ない注釈付き事例を用いて，大規模な学習事例を用いた英語の意味役割手法に迫る精度を得ることができており，本手法の有効性を示した．また本手法は，図〜のような，表層格では区別できない意味の区別を実現した．なお，図〜は，同一の表層格を持つ項に対する本手法の意味役割推定を評価するために用意した入力に対する結果である．</section>
  <section title="おわりに">本稿では，日本語フレームネットを背景とし，項の意味役割を推定する統計モデルの定義，ならびに獲得手法を提案した．結果，提案した意味役割推定モデルの尤度が0.5を超えるもののみを付与する条件の下，意味役割が付与されるべき項が分かっていない文に対して精度63％，再現率43％の意味役割推定を，意味役割が付与されるべき項が分かっている文に対して精度77％，再現率68％の意味役割推定を実現し，本手法の有効性を示した．また，日本語フレームネットを背景としたことにより，表層格では区別できない意味の区別を実現した．今後は，語義曖昧性解消問題や機械翻訳の要素技術として本稿の提案手法を適用すると共に，現在進行中の日本語フレームネットの新たな事例について，再度本手法の検証を行っていく予定である．mainichi:_cddocument</section>
</root>
