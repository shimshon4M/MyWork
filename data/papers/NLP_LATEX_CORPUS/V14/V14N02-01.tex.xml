<?xml version="1.0" ?>
<root>
  <jtitle>Web上の情報を用いた関連語のシソーラス構築について</jtitle>
  <jauthor>榊剛史松尾豊	内山幸樹石塚満</jauthor>
  <jabstract>本論文ではWeb上の情報を利用し，自動的に関連語のシソーラスを構築する手法を提案する．検索エンジンを利用し，^2値による語の関連度の指標を用い，従来のWebを用いた関連度の指標の問題点を解決する．また，新しいクラスタリング手法であるNewman法を用いて語のネットワークをクラスタリングすることで，従来手法より適切に関連語を同定する．コーパスおよび既存のシソーラスから生成した関連語正解セットを用い，提案手法の効果についての検証を行う．</jabstract>
  <jkeywords>シソーラス，クラスタリング，共起情報，Webマイニング</jkeywords>
  <subsection title="^2値を用いた関連度の指標">本論文では，^2値を使った関連度の指標を用いる．^2値は，あるデータ集合内での統計的な偏りを表す指標であり，機械翻訳やコロケーション処理など，多くの手法で用いられている．語の関連度としてはCurranらが用いている．^2値を関連度に用いるのは，語の出現頻度のばらつきによる影響を排除するためである．相互情報量やJaccard係数を関連度に用いる場合の問題点は，語の出現確率に大きな影響を受ける点である．この問題の解決策として，出現確率を適切に正規化するというアプローチが考えられる．^2値では，語群を構成する語の出現頻度を正規化要素とし，値の正規化を行ったうえで，共起の偏りを算出するので，出現確率のばらつきによる影響を抑えることができる．このため，値のばらつきが大きい検索エンジンのヒット件数を用いて関連度を算出する場合，^2値を計算指標として用いることが適切であると考えられる．対象とする語群の中で，共起の偏りを統計的に調べるために，1つ1つの語について，語群内の他の語との共起頻度を標本値とし，「w_i,w_jGが共起する確率は，語w_iと語群G内の語が共起する確率と等しい」という帰無仮説をおいて検定を行う．語w_iと語w_jの実際の共起頻度をn(w_i,w_j)，語w_iと語群Gの語との共起頻度の和をS_w_i=_kn(w_i,w_k)，全ての共起頻度の和をS_G=_w_iGS_w_iとするとき，語w_iと語w_jに関する^2値は次式で表される．^2(w_i,w_j)&amp;=n(w_i,w_j)-E(w_i,w_j)E(w_i,w_j)E(w_i,w_j)&amp;=S_w_iS_w_jS_GalignE(w_i,w_j)は語w_i,w_jの共起頻度の期待値を表している．例えば，語w_iを「プリンタ」，語w_jを「インターレーザー」とすると，n(w_i,w_j)は273，S_w_i=20601273，S_w_j/S_G=839/166552478となる．表は，表から計算された^2値行列である．表では，「プリンタ」は「印刷」や「インク」と偏って共起している．また，「インターレーザー」は「プリンタ」との共起が，「Aquos」は「Sharp」との共起が強いなど，良好な結果となっている．また，表のような，「プリンタ」「液晶」との関連が低いと考えられる4語と「プリンタ」「液晶」の2語で構成される計6語の語群を与えた場合を考える．この語群では，表の語群と違い，「プリンタ」と「液晶」の関連性が強いと考えられる．「プリンタ」の行に注目すると，確かに「プリンタ」と「液晶」の^2値が大きくなっており，語群に基づいた適切な結果が得られている．</subsection>
  <section title="はじめに">シソーラスは，機械翻訳や情報検索のクエリー拡張，語の曖昧性の解消など，言語処理のさまざまな場面で用いられる．シソーラスは，WordNetやEDR電子化辞書，日本語語彙大系など，人手で長い年月をかけて作られたものがよく用いられている．しかし，こういったシソーラスを作成するのは手間がかかり，また日々現れる新しい語に対応するのも大変である．一方で，シソーラスを自動的に構築する研究が以前から行われている．Webページをはじめとする大規模で多様な文書を扱うには，シソーラスを自動で構築する，もしくは既存のシソーラスを自動で追加修正する手段が有効である．シソーラスの自動構築は，語の関連度の算出と，その関連度を使った関連語の同定という段階に分けられる．2語の関連度は，コーパス中の共起頻度を用いて求めることができる．これまでの研究では，コーパスとして新聞記事や学術文書が用いられることが多かった．それに対し，近年ではWebをコーパスとして用いる手法が提案されている．Kilgarriffらは，Webをコーパスとして用いるための手法やそれに当たっての調査を詳細に行っている．佐々木らはWebを用いた関連度の指標を提案している．Webには，新聞記事や論文といった従来からある整形された文書のみならず，日記や掲示板，ブログなど，よりユーザの日常生活に関連したテキストも数多く存在している．世界全体で80億ページを超えるWebは，間違いなく現時点で手に入る最大のコーパスであり，今後も増え続けるだろう．Kilgarriffらが議論しているように，Webの文書が代表性を持つのかといった議論はこれからも重要になるが，Webはコーパスとしての大きな可能性を秘めていると著者らは考えている．Webをコーパスとして扱う際にひとつの重要な手段になるのが，検索エンジンである．これまでに多くの研究が検索エンジンを用いて，Web上の文書を収集したり，Webにおける語の頻度情報を得ている．しかし検索エンジンを用いる手法とコーパスを直接解析する手法には違いがあるため，従来使われてきた計算指標がそのまま有効に働くとは限らない．本論文では，Webを対象とし，検索エンジンを用いて関連語のシソーラスを構築する手法を提案する．特に，検索エンジンを大量に使用すること，統計的な処理を行うこと，スケーラブルなクラスタリング手法を用いていることが特徴である．ただし，類義・同義語に加え，上位・下位語や連想語など，より広い意味である語に関連した語を関連語とする．まず，2章で関連研究について述べる．そして，3章で検索エンジンを用いた関連度の指標を提案し，さらに4章では関連語ネットワークをクラスタリングする手法について紹介する．そして，5章では評価実験を行い，この手法の効果について議論を行う．</section>
  <section title="関連研究">語の関連性を自動的に得る方法は，これまでにさまざまな研究が行われている．コーパス中での語の共起情報をもとに語の関連度を測る指標として，様々なものが提案され用いられており，それらは大きく2つに分けられる．1つは単語ベクトルを用いたベクトル空間手法である．これは，単語を多次元ベクトル空間の単語ベクトルで表現し，それぞれの単語ベクトルを比較することで関連度を測る手法である．ベクトル空間手法では，表のようにベクトルの内積をもとにした計算指標が用いられている．表において，x_i,y_iはそれぞれ単語ベクトルx,yのi番目の要素を表す．なお，overlap係数はバイナリベクトルにしか用いることはできない．単語ベクトルの要素の取り方は研究によって様々であり，各文書への出現頻度を要素とするベクトルや各単語との共起頻度を要素とするベクトルなどが考えられる．ただし，独立な事象の確率は足し合わせることができないため，内積を用いる関連度では，語の出現確率を単語ベクトルの要素とすることは不適切と考えられる．もう1つはコーパス中での確率を用いる確率手法である．この手法では，2語がコーパス中で共起する確率をもとに関連度を算出している．確率手法で用いられている計算指標を表に示す．表において，p(ww')は語w,w'の共起確率を表し，p(ww')は語w,w'のどちらかが出現する確率を表す．またfはで定義されている関数であり，f(w,r,w')は語w,w'がrの関係を持って出現する頻度を，f(*,r,w')は語w'がいずれかの語とrの関係を持って出現する頻度を表す．これらの計算指標は，ベクトル空間手法で用いられている指標を書き換えたものが多い．また，単語同士の共起確率ではなく，各単語が他の語と共起する確率の確率分布関数の類似性を用いて関連度を算出する研究も数多く行われている．確率分布関数を用いた類似度は，確率分布類似度(DistributionalSimilarity)と呼ばれる．類似した名詞は共通した動詞と共起すると仮定し，動詞との共起分布の類似性から関連度を算出している．語の関連度が得られれば，関連度に基づいて語をクラスタリングすることで関連語が得られる．実際には，同じクラスタに分類された語同士を関連語や同義語であるとしている．語のクラスタリングには分布クラスタリング(DistributionalClustering)が用いられることが多い．分布クラスタリングとは，類似した名詞は共通した動詞と共起すると仮定し，各語の動詞との確率分布の類似度に基づいて，データを結合もしくは分割していくクラスタリング手法である．これらコーパスから関連度を自動的に算出する手法では，コーパス内に出現する語しか扱えないという欠点がある．そのため，広範囲の語をカバーするためには，広範囲の内容をカバーするコーパスが必要となる．近年では，より広範囲の語をカバーするためにWebをコーパスとして用いることが提案されている．しかしWeb上の文書は莫大であり，直接収集し，解析するためには非常に大きな時間コストと設備コストがかかる．そのため，Web全体での語の出現頻度や2語の共起頻度を獲得するためには従来のコーパスを用いたシソーラス構築とは異なる工夫が必要である．そのような工夫の一つとしてKilgarriffらは検索エンジンを用いた手法を紹介している．「語w_a」をクエリーとして検索エンジンを利用すると，語w_aのWeb上でのヒット件数が得られる．検索エンジンは非常に多くのページをクローリングしているため，このヒット件数を語w_aのWeb全体での出現頻度と近似できる．同様にして，「語w_aand語w_b」をクエリーとすれば，Web上での語w_aと語w_bの共起頻度を獲得することができる．検索エンジンから獲得できる頻度情報を用いて関連度を算出する手法としては，次のようなものがある．Heylighenは検索エンジンのヒット件数を用いた語の関連度の尺度により，語の分類や語の曖昧性解消，より優れた検索エンジンの開発の可能性を示唆している．BaroniやTuerneyは，類義語を同定するために，検索エンジンを用いた語の関連性の尺度を提案している．Turneyはその結果を用いることでTOEFLのシソーラスの問題で平均的な学生よりもよい得点を挙げたことを報告している．佐々木らは検索エンジンの上位ページとヒット件数を利用した専門用語集の自動構築を行っている．Szpektorは名詞ではなく動詞の関連度を検索エンジンを用いて定義している．これら検索エンジンを用いて関連度の計算を行っている研究では，条件付き確率や表の確率手法で定義されているような相互情報量，Jaccard係数が計算指標として用いられている．</section>
  <section title="検索エンジンを用いた関連性の測定">本章では，Web上の情報を用いて語の関連度を測る手法を提案する．</section>
  <subsection title="検索エンジンのヒット件数の利用と従来手法の問題点">検索エンジンのヒット件数を用いて2語の関連度を計算する手法について説明する．ここでは，従来研究で用いられている相互情報量を計算指標として関連度を算出する．そして，その関連度を検証し，従来手法の問題点について述べる．具体的な例を使って説明しよう．ここで用いられている手法は，のものと同一である．関連度を測りたい語を，例えば「インク」「インターレーザー」「プリンタ」「印刷」「液晶」「Aquos」「テレビ」「Sharp」の8語とする．これらの語群は，Epsonのプリンタであるインターレーザーに関する語と，Sharpの液晶TVであるAquosに関する語であり，各語の関連度を得ることで，2つのグループを適切に分けたいと仮定する．表に示しているのは，語群の各語に対して，検索エンジンによって得られたヒット件数である．表には，語群中の2語を検索エンジンのクエリーとしたときのヒット件数を行列形式にしたものを示す．例えば，「インク」と「プリンタ」であれば，をクエリーとして検索エンジンに入力し，そのヒット件数を調べる．8語に対してこの行列を得るには，_8C_2=28回のクエリーが必要となる．Baroniらは，この2つの情報を使って求めた相互情報量の値が，語の関連度を示すよい指標になると述べている．相互情報量は，語w_aの出現確率をp(w_a)，語w_bの出現確率をp(w_b)，語w_aと語w_bの同時出現確率をp(w_aw_b)とすると，MI(w_a,w_b)&amp;=p(w_aw_b)p(w_a)p(w_b)&amp;=Nn(w_a,w_b)n(w_a)n(w_b)alignと表される．ここでn(w_a)は語w_aをクエリーとしたときのヒット数，n(w_a,w_b)は「語w_a語w_b」をクエリーとしたときのヒット数であり，また，Nは検索エンジンのクロールした全ページ数である．BaroniらはNを3億5千万ページとしているが，2006年末現在では，Googleは約150億ページ，AltaVistaは約120億のページである．ここではN=10010^8とした．表に相互情報量を示す．「液晶」の行に注目すると，「液晶」と関連が強いとあらかじめ想定している語は「テレビ」「Aquos」「Sharp」であるが，「プリンタ」や「インターレーザー」との相互情報量が大きく，「テレビ」や「Sharp」との値は小さくなっており，適切な関連度が算出されていない．この原因は，相互情報量が「出現確率の影響を受ける」という特徴を持つためである．この特徴は式()を次式のように書き換えるとわかりやすい．p(w_a|w_b)は語w_bが出現するときに語w_aと語w_bが共起する条件付き確率を表す．p(w_a|w_b)が等しい場合は，p(w_a)の出現確率が小さいほど相互情報量は大きい値になる．この特徴自体は「共起する確率が同じなら，出現確率の低い語と共起する方が関連性が強い」と考えられるので，問題がない．しかし，検索エンジンにおいては語によって出現頻度に大きなばらつきがあり，また全事象を表すNが非常に大きいために出現確率の違いによる影響が大きくなり過ぎてしまう．例えば，「テレビ」のように出現確率の極端に大きい語と他の語の相互情報量が小さくなる．表の「テレビ」の列に注目すると，いずれの語においても「テレビ」との相互情報量が小さくなっていることが分かる．実際に表の語のヒット件数と表の各行との相関係数（式）は-0.35となり，相互情報量と語の出現確率にやや強い負の相関があることが分かる．それに対し，表の共起ヒット件数と表の相互情報量のとの相関係数は0.06となり，ほとんど相関がないことが分かる．このように，従来用いられてきた相互情報量は語の出現確率に影響を受けるため，関連度を測る際に各語の出現確率に数千倍，数万倍といった開きがある場合，値の信頼性は低くなるという問題がある．これは，Jaccard係数やdice係数など他の類似度の指標についても当てはまる．</subsection>
  <section title="関連度を用いたネットワークに基づくクラスタリング">従来は，確率分布の類似度に基づいた分布クラスタリングの方法を用いて，関連語をクラスタに分けることが多かった．本研究では，語の関連度からネットワークを構築し，ネットワークに基づく新しいクラスタリングの方法を適用する．関連語ネットワーク上でNewman法によりクラスタリングを行い，その結果，同じクラスタに分類されたもの同士を関連語として取り出す．このクラスタリング法は，語の数が大規模になったときにでも適用でき，対象によってはよいクラスタを生成するので近年注目を集めている．</section>
  <subsection title="関連語ネットワークの構築">まず，語の関連性を用いて，語のネットワークを構築する．ノードが語，エッジが強い関連を表す．本論文では，これを関連語ネットワークと呼ぶ．関連語ネットワークは次のように構成される．語群Gを与える．次式により2語w_i，w_jGの関連度^2_w_i,w_jを計算する．^2_w_i,w_j&amp;=n(w_i,w_j)-E(w_i,w_j)E(w_i,w_j)E(w_i,w_j)&amp;=S_w_iS_w_jS_GS_w_i&amp;=_kn(w_i,w_k)S_G&amp;=_w_iGS_w_ialign各語w_iGをノードとして配置する．^2_w_i,w_j&gt;0のとき，ノードw_i，w_j間にエッジを張る．例を図に示す．これは，Webから獲得したコーパス中に高頻度に出現する計90語をこのネットワークの構成語として用い，ヒット件数を得る検索エンジンとしてGoogleを用いた関連語ネットワークである．この関連語ネットワーク上では，関連の強い語同士が近く配置されている．例えば，図の左下には「疾患」「患者」などの医学関連の語が密集している．また，上部では「アプリケーション」「ファイル」などのコンピュータ関連の語が密集している．このように関連語ネットワーク上では，関連の強い語同士が密集して存在している．</subsection>
  <subsection title="ネットワークに基づくクラスタリング">従来のシソーラス構築における語のクラスタリングには確率分布を用いた分布クラスタリング手法が一般的に用いられている．．また情報検索の分野では，語を属性とする高次元のベクトルを用いた語のクラスタリング手法も多く，LSAやrandomprojectionといった次元を圧縮する手法も有効である．一方で，近年ではデータをネットワークとして表した上で，それを分析する手法が提案され，着目を集めており，語の関係性の分析にも用いられている．SigmanはWordNetがネットワーク構造としての性質を持っていることを示し，WordNetにネットワーク分析の手法を適用できることを示している．ネットワークのクラスタリングには，従来，表のように距離関数D(c_i,c_j)を定義し（n_iはクラスタc_iに含まれる語の数，Sim(w_k,w_l)は語w_k,w_lの類似度を表す），距離の近い順に各クラスタをマージしていく階層的クラスタリング手法や，EMアルゴリズム，NaiveBayesといった機械学習の手法を用いたクラスタリング手法が一般的に用いられてきた．しかし，ここ数年で新たなクラスタリング手法がいくつも提案されている．代表例としては，betweennessクラスタリングがあげられる．betweennessクラスタリングは，グラフのbetweennessというエッジの媒介性を表す指標（あるエッジが他のエッジの最短パスにどの程度の割合で含まれているか）に注目し，できるだけ部分グラフをつなぐようなbetweennessの高いエッジを削除していくことにより，密度の濃いサブグラフを同定する手法である．これらの手法は高次元のベクトルに対しても有効であり，以前の手法と比べて高い精度で現実のクラスタ構造を再現することができる．その反面，時間計算量が大きく，大規模なネットワークに適用することは難しい．例えば，ネットワークのノード数をn，エッジ数をmとするとき，betweennessクラスタリングの時間計算量はO(n^3)またはO(m^2n)であり，ノード数が多いネットワーク上でbetweennessクラスタリングを行うことは困難である．そこで，本研究では大規模なネットワークにも適用可能なクラスタリング手法であるNewman法を用いる．Newman法は，階層的クラスタリング手法の一つであるが，クラスタリングを評価関数Qの最大値導出問題に置き換えた手法である．評価関数Qとは，各クラスタの結合度を表す関数であり，Qが大きいほど各クラスタ内の結合が強いことを表している．Newman法では，Qの高い状態がより適切にクラスタリングされた状態であると定義している．そして，Qの最大値を求めることで，そのネットワークに最適なクラスタリング結果を得ることを目標としている．評価関数Qは次式で表される．k_vは頂点vが持っているエッジの本数，mは全エッジ本数の合計，c_vは頂点vが属しているクラスタを表している．(c_v,c_w)はクロネッカーのである．式()の第1項において，A_vwは頂点v,w間のエッジの有無を表しており，また頂点v,wが同じクラスタのときのみ，(c_v,c_w)=1となる．つまり，第1項は各クラスタ内に含まれるエッジの本数の合計を表している．同様に第2項においては，k_vk_w2mは頂点v,w間にエッジが引かれる確率を表しているため，第2項は，各クラスタ内に含まれるエッジの本数の合計の期待値を表している．すなわち，評価関数Qとは，クラスター内に存在するエッジの本数の合計が期待値からどの程度ずれているかを相対的に表した値である．クラスター内のエッジ本数の和が期待値と同じならQ=0，それより強いクラスターならQ&gt;0であり，弱いクラスターならQ&lt;0となる．Qが最大であるとき，各クラスター内での結合度が最大であるので，ネットワーク全体として最も良くクラスタリングされた状態であると考えられる．しかしQの最大値を求める場合，エッジ数m，ノード数nのとき，計算量がO(n^3)もしくはO(m^2n)となり，大きくなってしまう．そこでNewman法ではGreedyアルゴリズムを用いてQの値が極大値をとるようにクラスタリングを行う．Greedyアルゴリズムなので，「Qの変化量Qが最大になるようにクラスタ，もしくはノードをマージする」という手順を繰り返していく．そして「Qの最大値&lt;0」となった時点でクラスタリングを終了とする．このようにしてQの極大値を求めている．この際，常に「Qが最大になるような2つのクラスタを選んでマージ」するため，クラスタがマージされていく順序は一意であり，初期条件によってクラスタリングの結果は変化しない．また，クラスタ数を任意に制御したい場合は，終了条件をQ&lt;0ではなくクラスタ数にすることも可能である．Newman法とbetweennessクラスタリングを比較すると，NewmanらによりNewman法はbetweennessクラスタリングとほぼ同じ精度のクラスタリング結果が得られることが示されている．また，Newman法の時間計算量はO((m+n)n)もしくはO(n^2)であり，時間計算量がO(m^2n)あるいはO(n^3)であるbetweennessクラスタリングと比べ，計算量が少なく，高速な手法となっている．そのため，Newman法はノード数やエッジ数が大きい大規模ネットワークに適用可能である．</subsection>
  <subsection title="Newman法による関連語の獲得">語群Gを用いてシソーラスを構築する場合，Newman法を用いて関連語を同定する手順は次のようになる．検索エンジンのヒット件数と^2値を用いて語群Gの語の関連度を算出する．関連度をもとに語群Gを構成語とする関連語ネットワークを構築する．1つの語を1つのクラスタとする．ある2つのクラスタが1つのクラスタになったと仮定して，Qの変化量Q（式）を計算する．(4)を全てのクラスタの組み合わせについて行う．Qが最大となるような2つのクラスタをマージし，1つのクラスタとする．ただし，最大のQ&lt;0なら(8)へ．マージしたクラスタのe_ij,a_iを再計算し，(4)に戻る．同じクラスタに属している語を関連語とみなす．Q_ij&amp;=2(e_ij-a_ia_j)e_ij&amp;=クラスタi，j間のエッジの本数（割合）a_i&amp;=_ie_iialign</subsection>
  <section title="評価"/>
  <subsection title="評価実験の概要と正解セットの作成">シソーラスを評価する手法として，WordNetやEDRなど人手で構築された既存のシソーラスと比較する方法，綿密に作られたアンケートや語の分類タスクを人が行い，その結果と比較することでシソーラスの適切さを評価する方法がある．前者の手法はWordNetに出現する語しか評価できないため語の範囲が限られてしまい，後者はコストがかかるのが問題である．本研究では，提案手法で構築されたシソーラスと，2種類のシソーラスを比較することで，提案手法の評価を行う．1つ目はWebより収集したコーパスから作成したシソーラスであり，これを関連語の正解セット作成用のデータとして用いることで提案手法と従来のコーパスを用いた手法との比較を行う．2つ目は既存のシソーラスであり，これから作成した関連語の正解セットを用いて，人手によって構築されたシソーラスと提案手法との比較を行う．また，1つ目の正解セットにはWebに特徴的な語が多く含まれるのに対し，2つ目の正解セットでは，既存のシソーラスに含まれるような，いわゆる汎用的な語が多く含まれる．そのため，それぞれの正解セットを評価実験に用いることで，Webに特徴的な語に対する提案手法の有効性，汎用的な語に対する提案手法の有効性を検証することにもなる．</subsection>
  <subsubsection title="OpenDirectoryを用いた正解セットの作成">シソーラスを作成するコーパスとしてOpenDirectoryを用い，あらかじめ各カテゴリに特徴的な語を抽出することで，正解となるシソーラスを模擬的に作成する．OpenDirectoryは，ボランティア方式で運営される世界最大のウェブディレクトリであり，各カテゴリは，担当のエディタによって管理されている．Webディレクトリの中では，カテゴリ分類の信頼性が高いもののひとつである．各カテゴリに特徴的に出現する語は互いに関連しているという仮定のもとで，提案手法および比較手法による語の関連性の適切さを評価する．OpenDirectoryの14個のカテゴリの中から，「アート」，「スポーツ」，「コンピュータ」，「ゲーム」，「社会」，「家族」，「科学」，「健康」，「レクリエーション」の9つのカテゴリを用いた．各カテゴリ内に含まれるWebページを用い，次のようにカテゴリに特徴的な語を抽出する．各カテゴリC_i(i=1...9)ごとに登録順に1000ページの文書を取得する．全ての文書に形態素解析を行う．そして連接する名詞5-gramまでを単語として取り出す．カテゴリC_i内で，単語w_aが含まれる文書の数をf^i_w_aとする．また，全てのカテゴリで語w_aが含まれる文書数をf^all_w_aとする．カテゴリC_iにおける語w_aの重みを次のように計算する．ただし，Nは全文書数である．カテゴリC_iごとにscoreの高い語w_aを取り出し，それらをそのカテゴリに特徴的な語群R_C_iとする．すなわち，R_C_i=w_k|rank_i(w_k)10である（rank_i(w_k)は，カテゴリC_i内での語w_kのscoreの順位を表す）．また，A=w|wR_C_i,i=1...9とする．ここでは，各カテゴリごとに特徴的に現れる語を，tfidfの考え方を用いて重み付けしている．また上記説明の(1)において「登録順に」とあるが，これはOpenDirectoryのサイトから文書データを収集する際に，データが得られる順番を意味している．この順番は，文書の内容に関係なく無作為に並んでおり，特定のルールはないと考えられるため，ランダムな順番と考えても問題ないと言える．得られた語の一部を表に示す．例えば「アート」カテゴリから取り出された語に注目すれば，「画廊」「作品」「個展」は絵画関連の語，「サックス」「ライブ」「ギター」は音楽関連の語，「バレエ」「披露」「劇場」はパフォーミングアート関連の語，「短歌」は文芸関連の語となっており，いずれも「アート」に関連した語が取り出されている．こうして得られたカテゴリごとの特徴的な語を用いて，ある2語が同一カテゴリ内に含まれれば，関連しているある2語が異なるカテゴリであれば，関連していないと見なす．ここでの評価法は，カテゴリごとの特徴語の抽出に基づいている．各カテゴリに特徴的に現れる語を重み付けする方法は，やで用いられている．後者では，各カテゴリに特徴的な語をtfidfで重み付けし，tfidf値の高い語をカテゴリに特徴的な語として抽出している．さらにでは，OpenDirectoryのカテゴリ分類を用いて各カテゴリに特徴的な語を取得し，その結果，人手による評価で平均65%，最大で81%の正解率を得ている．もちろん，ここでの関連語の正解セットは完全ではなく，異なるカテゴリに含まれていても関連している場合もあるかもしれないし，同一カテゴリ内であっても，その関連の度合いは程度の差が大きいかもしれない．しかし，本研究では，このデータを手法の比較を行うための目安として用いており，比較手法の優劣を示すには十分であると考えている．図に全体の概要を図示する．OpenDirectoryから獲得したカテゴリ分類されたコーパスを用いて関連語の正解セットを作成する．その正解セットの語を用いて提案手法および比較手法によって関連語を出力する．その際，比較手法はコーパス内の共起情報を用いて関連度の算出を行う．そして出力結果と正解セットを比較し，手法の評価を行う．図に示すとおり，本評価実験では正解セット作成用コーパス，比較手法で用いる関連度学習用コーパスの2種類のコーパスが必要となる．そこで，全部で各カテゴリから5000ページずつ計4万5千ページの文書をコーパスとして用意し，1/5を正解セット作成用に，4/5を関連度の学習用に用いて5分割交差検定を行った．正解セット作成用のコーパスを変えたそれぞれの正解セットをAo_i(i=1,2,3,4,5)とする．関連度の評価は，適合率，再現率，InverseRankScoreによって測る．InverseRankScoreとは正解とマッチした語の順位の逆数の合計値であり，正解となる語が上位にランクされる程大きい値となる．この値を用いることで，順位を考慮した比較を行うことができる．簡単な算出例を表に示す．この場合，手法1による出力は4語中2語が正解であるので適合率=24=0.50，正解セット4語のうち2語が手法1により出力に含まれているので，再現率=24=0.50となる．同様に手法2では適合率=35=0.60，再現率=34=0.75となり，手法2の方が優位となる．しかし，正解の語が上位にランクされている手法1の方が手法としての実用性が高い，とも考えられる．このような場合に各手法のInverseRankScoreを求めると手法1では，11+12=1.50，手法2では13+14+15=0.78となり，手法1の方が優位となる．このように適合率，再現率に加え，InverseRankScoreを用いることで，順位を加味した評価を行うことができる．．</subsubsection>
  <subsubsection title="既存シソーラスを用いた正解セットの作成">本論文では，Curranらの手法を元にして，提案手法と既存のシソーラスを比較を行う．そのために，正解セット作成用シソーラスと比較用シソーラス，2種類のシソーラスを用意する．まず，正解セット作成用シソーラスから関連語を取り出し，正解セットを作成する．この正解セットの語群に対して提案手法と比較用シソーラスを適用して関連語の分類を行う．その結果，どの程度正しく語群が関連語群に分類されるかによって提案手法と既存シソーラスとの比較を行う．本論文では，Curranらが用いたRoget'sThesaurusの最新版であるRoget'sMilleniumThesaurus~を正解セット作成用のシソーラスとして用い，WordNet及びMobyThesaurus~を比較用のシソーラスとして用いる．Roget'sMilleniumThesaurusは見出語を持ち，その見出語がそれぞれ関連語群を持つ，という2層構造をしたシソーラスである．本実験においては，1つの見出語から取り出される関連語群をそのまま正解の関連語群とした．ただし，比較用シソーラスに含まれない語は除くものとする．関連語の例は表のようになる．今回，見出語としてはTOEIC最頻出英単語リストに含まれる名詞の計220語を用いる．これらの見出語から無作為に10語選び，その10語からそれぞれ関連語群を取り出し，1組の関連語正解セットとする．本実験では，計10組の正解セットAw_i(i=1,2,...,10)を作成した．また比較用のシソーラスを用いた関連語群の分類では，算出した関連度に基づいて行うのではなく，各2語が比較用シソーラスで関連語とされているか，いないかの2値的な判定によって行うものとする．この際，どの2語を関連語とみなすかは，シソーラスの構造によって違う方法を用いた．Roget'sThesaurusと同様に見出語と関連語群の2層構造を持つMobyThesaurusにおいては，見出語とその関連語群同士，及び同じ見出語を持つ語同士を関連語とみなす．木構造を持つWordNetにおいては，見出語とHyponyms（下位語），見出語とHypernyms（上位語）及び見出語とCoordinateTerms（共通の上位語を持つ語）同士を関連語とみなす．関連度の評価指標としては，OpenDirectoryを用いる場合と同様に，適合率とInverseRankScoreを用いる．</subsubsection>
  <subsection title="関連度の指標の評価">関連度の指標に関する評価を行う．提案手法では，関連度の計算に^2値を用いているが，この有効性を示すため，相互情報量，Jaccard係数を用いた関連度と比較する．検索エンジンを利用する際，日本語のみを扱うOpenDirectoryによる正解セットでは，検索時のオプションとして「日本語のページを検索」を選択した値を用い，英語のみを扱う既存のシソーラスによる正解セットでは検索時のオプションとして「ウェブ全体から検索」を選択した値を用いる．また，コーパスを用いて学習する手法との比較も行う．コーパスを用いる手法では，tfidf値を要素とする単語ベクトルを用い，計算指標としてはcosineを用いた．実験の手順を以下に示す．正解セットA_iに含まれる全ての語について，各指標ごとに2語の関連度を計算する（比較用シソーラスを用いる際はこの手順は省略）．各指標ごとに語w_iと関連度の高い上位9語をA_iから選び，それを語wの関連語群G_wとする（比較用のシソーラスを用いる場合は，比較用シソーラスにおいて語w_iの関連語とされる語を全て取り出し，G_wとする）．G_wと正解セットを比較し，適合率を計算する．(2)を語w_iA_i全てについて行い，指標ごとに適合率の平均値を算出する．(1)から(3)を正解セットA_i(i=1〜n)について行う．OpenDirectoryから作成した正解セットの適合率の平均値を表に，InverseRankScoreの平均値を表に示す．まず，検索エンジンを用いた手法同士で比較すると，どの正解セットにおいても^2値が他の2つの計算指標よりもよい適合率，InverseRankScoreを示している．これより，^2値が検索エンジンを用いる手法の関連度の指標として有効であることが分かる．また，コーパスを用いて学習した手法であるcosineと検索エンジンを用いた手法を比較するとJaccard係数，相互情報量はcosineよりも低い適合率，InverseRankScoreである．cosineと^2値を比較すると正解セットによって2つの評価指標の優劣が変化している．しかし，平均ではほとんど差がないことから，^2値とcosineはほぼ同じ適合率であると考えられる．ただし，コーパスから学習する手法ではコーパス中に出現する語しか扱えないという欠点を持つのに対し，検索エンジンを用いる手法ではWeb上に出現するほとんどの語を扱うことができる．そのため同じ適合率ならば，^2値を計算指標として検索エンジンを用いる手法の方が優れていると言える．また，表,において，5つの正解セットにおける標準偏差（式）を求める．すると適合率の標準偏差は0.014，InverseRankScoreの標準偏差は0.12であり，いずれも標準偏差は10%以内に収まっている．このことから，正解セットによるばらつきによる影響はあまり大きくないと考えられる．次にRoget'sThesaurusから作成した正解セットを用いた既存シソーラスと提案手法の比較実験の結果を表とに示す．ただし，比較用シソーラスにおいては，全ての関連語が等価に扱われており順位が存在しないため，InverseRankScoreの算出は省略する．まず，Webを用いる手法同士を比較すると，OpenDirectoryを用いた正解セットと比べて適合率の差が小さくなってはいるが，シソーラスを用いた正解セットにおいても，^2値が他の計算指標よりよい数値を示している．これより，提案手法の優位性は小さくなるものの，Web上での出現頻度にばらつきの少ない汎用的な語に対しても，提案手法が有効であることがわかる．次に^2値と既存のシソーラスを比較すると，既存のシソーラスの精度の方が若干高い数値を出してはいるものの，ほぼ同程度の精度・適合率が得られている．これより，関連語を同定するタスクにおいて，提案手法を用いることで既存シソーラスと同程度の効果が得られると言える．以上より，提案手法を用いることで，検索エンジンを用いた既存手法やコーパスから学習する手法よりも適切に関連度を算出することができていると考えられる．ただし，コーパスから学習する手法ではcosine以外の計算指標を用いた手法があるため，今後それらの指標とも比較する必要がある．</subsection>
  <subsection title="クラスタリングの評価">次に，クラスタリングの評価を行う．提案手法ではNewton法を用いているが，比較手法としては，群平均法を距離関数とする階層的クラスタリングを用いる．クラスタリング手法の評価手法を以下に示す．正解セットA_iに含まれる全ての語について，2語の関連度を計算する．関連度をもとに関連語ネットワークを構築する．その際，ネットワークの密度が0.3になるように関連度の低いエッジを切る．ネットワークの密度とは，エッジ数を存在し得る最大のエッジ数（ノード数をnとすると_nC_2）で割ったものである．提案手法及び比較手法により，クラスタリングを行う．今回は，使用したカテゴリ数が9であるため，群平均法はクラスタ数が9になった時点でクラスタリングを終了とする．また，本実験では条件を均一化するためにNewman法においても終了条件をQ&lt;0ではなくクラスタ数9とする．同一クラスタに属する2語は関連語，異なるクラスタに属する2語は非関連語とする．この結果を正解セットと比較し，適合率・再現率・F値を求める．(1)から(4)を正解セットA_i(i=1〜n)について行う．OpenDirectoryによる正解セットを用いた評価結果を表に，Roget'sThesaurusによる正解セットを用いた評価結果を表に示す．示されている値はそれぞれ，5個のOpenDirectory正解セットAo_i(i=1〜5)と10個のRoget'sThesaurus正解セットAw_i(i=1〜10)について実験を行った結果の平均値である．各計算指標の群平均法とNewman法の結果を比較すると，いずれも群平均法では適合率が高く，再現率が低い．クラスタリングの評価では一般的なことであるが，これは1つのクラスタにほとんどの語が含まれ，残り8つのクラスタにそれぞれ1〜3語程度の語が含まれている状態と考えられる．例えば，極端な例ではクラスタ内の語数が1であれば適合率が11=1.0になる．そのため，含まれている語数の少ないクラスタが多数できる手法の方が精度が上がりやすい．しかし，再現率やF値で見ると，各クラスタに含まれる語数が均等に近くなるようなクラスタリング手法の評価が高くなる．表,表から群平均法の代わりにNewman法を用いることで，いずれの指標においてもF値が高くなっている．このことから，提案手法を用いることでより適切に語がクラスタリングされていると言える．ただし，群平均法がこの実験に適していない可能性も考えられるので，今後他の手法との比較を行う必要がある．Newman法を用いた場合の各指標を比較すると，表,表いずれにおいても，^2値が最も良いF値を示している．これより，語のクラスタリングを行う関連語ネットワークの構築には^2値による関連度を用いることが適切であると言える．次に評価手法(3)におけるNewman法の終了条件を「クラスタ数9」とした場合と「Q&lt;0」とした場合の評価実験結果を表に示す．またその際の正解セットごとのクラスタ数のグラフを図に示す．表より，終了条件を「Q&lt;0」とした方が「クラスタ数指定」とした場合よりも高いF値を示している．しかし，その差は4ポイント程度であり，精度に大きな違いはないといえる．これより，提案手法においては，条件としてクラスタ数を与えない場合でも，与えた場合とほぼ同程度の精度で関連語のクラスタリングを行うことができることがわかる．ただし，今回の実験ではそれぞれの終了条件によって違う傾向を持っている．「クラスタ数指定」では，適合率&gt;再現率となっているが，「Q&lt;0」では，適合率&lt;再現率となっている．これは，終了条件によるクラスタ数の違いとWebを用いて関連度を算出する際に必ずしも目的とする語の関連性が得られないためである，これに関して，クラスタリング結果の具体例を表に示す．ここに用いられている語は表に示されている語である．本実験では，表より，表の正解セットでは「科学」及び「コンピュータ」という関連性によってクラスタリングされることが想定されている．しかし，実際には「クラスタ数指定」のクラスタA_1に含まれる語は，「情報科学」及び「プログラミング」という共通の関連性を持っていると考えられる．クラスタA_2に含まれる語は「Web掲示板」という共通の関連性を持っていると考えられる．また「Q&lt;0」では，クラスタA_1,A_2が1つにマージされクラスタBを構成している．このように提案手法では，正解セットで目的としている関連性とは異なる関連性に基づいてクラスタリングされる場合が多い．これはクラスタリング手法によるものではなく，主に算出された関連度によるものである．実際には，クラスタA_1のように2つ以上のカテゴリの語で構成されるクラスタやクラスタA_2のように1つのカテゴリの語の一部のみで構成されるクラスタなど，正解セットのカテゴリ分けとは異なるクラスタができてしまっている．今回の実験においては，「クラスタ数指定」ではクラスタA_2のようなクラスタが多かったために適合率&gt;再現率となっている．また，クラスタ数の少なかった「Q&lt;0」ではクラスタBのようなクラスタが多かったために適合率&lt;再現率となっている．以上より，提案手法の精度を高めていくためには，目的にあわせた関連度を取得する手法とより適切にクラスタ数を自動取得する手法が必要となってくる．また，ネットワークのノード数とクラスタリングの実行時間の関係を図に示す．基準線は，xをノード数，zをエッジ数とするとき，式y=1.810^-8x(z+x)のあらわす曲線である（1.810^-8は比例定数）．図で実測値と基準線を比較するとほぼ一致しており，確かにNewman法の計算量がO(n(m+n))に比例している．そして，n=4029,m=7146169のとき実行時間は532秒であり，n,mが大きい大規模ネットワークにも提案手法が適用可能であると考えられる．以上の評価実験の結果より，提案手法について以下の3点を述べることができる．既存手法よりも適切に関連語のクラスタリングを行うことができるクラスタ数が未知の場合でも，クラスタ数が既知の場合と同程度の精度で関連語のクラスタリングを行うことができる大規模なネットワークにも適用可能である</subsection>
  <section title="議論">語の関連は，相対的なものである．候補となる語群によって，あるときは関連した語同士でも，他の場合には関連していないこともあり得る．ある語群において全ての語同士の関連度が分かっているとき，どの語とどの語を関連語と見なすかは，関連度によって規定される語の関係性によると考えられる．語の関連性を図のようなネットワーク図（ノード間の距離を（1/語の関連度）とおく）で可視化すると，図-aのような時は部分集合A,B,Cそれぞれが，関連語の集まった関連語群であると言える．同様に図-bであれば，部分集合A,B,C,Dそれぞれが関連語群であると言える．このように語のネットワーク上で周囲と比べて密度が高くなっている部分を抽出することで，各語の関連語を同定することができる．Webは非常に多様性に富んだテキストから構成されている．したがって，目的に合わせた語の関連性を得るには，Webから適切な文書集合を切り出した上で，その文書集合内での関連度を求めるという方法が考えられる．これには，検索クエリーに特定の検索語(keywordspice)を加える方法が有効であろう．本論文では，関連語ネットワーク上のエッジには重みを与えていないが，語の関連性が多値的であることを考えると，重みを考慮する必要がある．ただし，既存のNewman法は重みのあるネットワークに対応していない．そこで，重みを扱えるようにNewman法を改良することで，重みつきのネットワーク上でクラスタリングを行うことが考えられる．語の関連性を「関連がある，ない」の2値ではなく，重みという多値で扱うことで，クラスタ数の自動取得も含めて，より適切なクラスタリング結果が得られることが予想される．加えて，Newman法では1語が1つのクラスタリングにしか所属できないハードクラスタリングであるため，語の持つ多義性を解消することができない，という問題点がある．しかし，Newman法をもとにしたソフトクラスタリングの手法も提案されており，この手法を関連語ネットワークに適用することで語の多義性を解消できると考えられる．また本研究では，同義・類義，上位語・下位語，連想語をすべて関連語としたが，こういった語を関係性を分類していくことも重要であろう．こういった研究には，前置詞を手がかりとして語の関係性を同定するの手法があるが，これを検索エンジンを利用していかに効率的に行うかは今後の検討課題のひとつである．</section>
  <section title="結論">本論文では，自動的に関連語のシソーラスを構築する手法について提案した．提案手法では，検索エンジンを利用し，Webをコーパスとして用いる．Newman法をクラスタリング法として用いる部分が大きな特徴のひとつである．検索エンジンを用いて語の関連度を取得する研究においては，コーパスを直接解析する手法と比べ，共起頻度以外の文法的な情報が得られないため，クラスタリングによって関連語を同定し，高い精度を得られている研究はなかった．本論文では，共起頻度のみを用いたクラスタリングで精度の高い関連語の同定に成功しており，そのような点で非常に有意義な研究だと考えられる．また，語の関係の相対性に着目し，相対性を考慮した手法を用いた．^2値は語群内での相対的な偏りを示す統計的指標であり，またNewman法はネットワーク全体で相対的に結合度の強いノードをマージするクラスタリング手法である．これらの手法を用いることにより，より適合率が高く，適用範囲の広いシソーラスの構築手法を提案することができた．Webは重要な言語資源であり，その利用のためには検索エンジンの利用や大規模な処理への対応など，Webならではのアルゴリズムの工夫が必要になる．今後，検索エンジンを利用した言語処理の可能性をさらに追求していきたい．</section>
</root>
