<?xml version="1.0" ?>
<root>
  <jtitle>機械学習を用いた日本語機能表現のチャンキング</jtitle>
  <jauthor>土屋雅稔注連隆夫高木俊宏	内元清貴松吉俊	宇津呂武仁佐藤理史中川聖一</jauthor>
  <jabstract>日本語には，複数の語がひとかたまりとなって，全体として1つの機能的な意味を持つ表現が多数存在する．このような表現は機能表現と呼ばれ，日本語文の構造を理解するために非常に重要である．本論文では，形態素を単位とするチャンク同定問題として機能表現検出タスクを定式化し，機械学習手法を適用することにより，機能表現の検出を実現する方法を提案する．SupportVectorMachine(SVM)を用いたチャンカーYamChaを利用して，機能表現の検出器を実装し，実際のタグ付きデータを用いて性能評価を行った．機能表現を構成している形態素の数の情報，機能表現中における形態素の位置情報を素性として参照することにより，F値で約92という高精度の検出器を実現できることを示す．</jabstract>
  <jkeywords>機能表現，チャンキング，機械学習</jkeywords>
  <section title="はじめに">機能表現とは，「にあたって」や「をめぐって」のように，2つ以上の語から構成され，全体として1つの機能的な意味をもつ表現である．一方，この機能表現に対して，それと同一表記をとり，内容的な意味をもつ表現が存在することがある．例えば，ex:niatatte-Fとex:niatatte-Cには，「にあたって」という表記の表現が共通して現れている．出発する0ptにあたって，荷物をチェックしたボールは，壁0ptにあたって跳ね返ったexampleex:niatatte-Fでは，下線部はひとかたまりとなって，「機会が来たのに当面して」という機能的な意味で用いられている．それに対して，ex:niatatte-Cでは，下線部に含まれている動詞「あたる」は，動詞「あたる」本来の内容的な意味で用いられている．このような表現においては，機能的な意味で用いられている場合と，内容的な意味で用いられている場合とを識別する必要がある．以下，文~(),()の下線部のように，表記のみに基づいて判断すると，機能的に用いられている可能性がある部分を機能表現候補と呼ぶ．機能表現の数については，いくつかの先行研究が存在する．は，450種類の表現を，意味的に52種類に分類し，機能的に7種類に分類している．は，森田らが分類した表現の内，格助詞，接続助詞および助動詞に相当する表現について，階層的かつ網羅的な整理を行い，390種類の意味的・機能的に異なる表現が存在し，その異形は13690種類に上ると報告している．土屋らは，森田らが分類した表現の内，特に一般性が高いと判断される337種類の表現について，新聞記事から機能表現候補を含む用例を無作為に収集し，人手によって用法を判定したデータベースを作成している．このデータベースによると，機能表現候補が新聞記事（1年間）に50回以上出現し，かつ，機能的な意味で用いられている場合と，それ以外の意味で用いられている場合の両方が適度な割合で出現する表現は，52種類である．本論文では，この52種類の表現を当面の検討対象として，機能表現の取り扱い状況を検討する．まず，既存の解析系について，この52種類の表現に対する取り扱い状況を調査したところ，52種類の表現全てに対して十分な取り扱いがされているわけではないことが分かった．52種類の表現の内，形態素解析器JUMAN~と構文解析器KNPの組合わせによって，機能的な意味で用いられている場合と内容的な意味で用いられている場合とが識別される可能性がある表現は31種類である．また，形態素解析器ChaSen~と構文解析器CaboCha~の組合わせを用いた場合には，識別される可能性がある表現は26種類である．このような現状を改善するには，機能表現候補の用法を正しく識別する検出器が必要である．そのような検出器を実現する方法として，検出対象である機能表現を形態素解析用辞書に登録し，形態素解析と同時に機能表現を検出する方法と，形態素解析結果を利用して機能表現を検出する方法が考えられる．現在，広く用いられている形態素解析器は，機械学習的なアプローチで接続制約や連接コストを推定した辞書に基づいて動作する．そのため，形態素解析と同時に機能表現を検出するには，既存の形態素に加えて各機能表現の接続制約や連接コストを推定するための，機能表現がラベル付けされた大規模なコーパスが必要になる．しかし，検出対象の機能表現が多数になる場合は，作成コストの点から見て，そのような条件を満たす大規模コーパスを準備することは非現実的である．形態素解析と機能表現検出が独立に実行可能であると仮定し，形態素解析結果を利用して機能表現を検出することにすると，前述のような問題を避けられる．そこで，機能表現の構成要素である可能性がある形態素が，機能表現の一部として現れる場合と，機能表現とは関係なく現れる場合で，接続制約が変化しないという仮定を置いた上で，人手で作成した検出規則を形態素解析結果に対して適用することにより機能表現を検出する手法が提案されてきた．しかし，これらの手法では，検出規則を人手で作成するのに多大なコストが必要となり，検出対象とする機能表現集合の規模の拡大に対して追従が困難である．そこで，本論文では，機能表現検出と形態素解析は独立に実行可能であると仮定した上で，機能表現検出を形態素を単位とするチャンク同定問題として定式化し，形態素解析結果から機械学習によって機能表現を検出する方法を提案する．機械学習手法としては，入力次元数に依存しない高い汎化能力を持ち，Kernel関数を導入することによって効率良く素性の組合わせを考慮しながら分類問題を学習することが可能なSupportVectorMachine(SVM)を用いる．具体的には，SVMを用いたチャンカーYamCha~を利用して，形態素解析器ChaSenによる形態素解析結果を入力とする機能表現検出器を実装した．ただし，形態素解析用辞書に「助詞・格助詞・連語」や「接続詞」として登録されている複合語が，形態素解析結果中に含まれていた場合は，その複合語を，構成要素である形態素の列に置き換えた形態素列を入力とする．また，訓練データとしては，先に述べた52表現について人手で用法を判定したデータを用いる．更に，このようにして実装した機能表現検出器は，既存の解析系およびが提案した人手で作成した規則に基づく手法と比べて，機能表現を高精度に検出できることを示す．本論文の構成は以下の通りである．最初に，本論文の対象とする機能表現と，その機能表現候補の用法を表現するための判定ラベルについて述べた上で，機能表現検出をチャンク同定問題として定式化する（章）．次に，SVMを用いて機能表現検出器を実装するための詳細を説明する（章）．章では，人手で判定規則を作成して機能表現を検出する手法について説明する．章では，作成した機能表現検出器の検出性能を評価し，この検出器は，既存の解析系および人手によって規則を作成した手法と比べ，機能表現を高精度に検出できることを示す．加えて，機械学習時に必要となる訓練データを削減する方法を検討する．章では，関連研究について述べ，最後に結論を述べる（章）．</section>
  <section title="日本語機能表現の検出"/>
  <subsection title="日本語複合辞用例データベース">森田らは，機能表現の中でも特に「単なる語の連接ではなく，表現形式全体として，個々の構成要素のプラス以上の独自の意味が生じている」表現を複合辞と呼び，個々の構成要素の意味から構成的に表現形式全体の意味を説明できるような表現とは区別している．現代語複合辞用例集（以下，複合辞用例集と呼ぶ）は，主要な125種類の複合辞について，用例を集成し，説明を加えたものである．日本語複合辞用例データベース（以下，用例データベースと呼ぶ）は，機能表現の機械処理を研究するための基礎データを提供することを目的として設計・編纂されたデータベースである．用例データベースは，複合辞用例集に収録されている125種類の複合辞および，その異形（合計337種類の機能表現）を対象として，機能表現候補と一致する表記のリストと，個々の機能表現候補に対して最大50個の用例を収録している．そして，各機能表現候補が文中において果たしている働きを，tbl:判定ラベル体系に示す6種類の判定ラベルのうちから人手で判定し，付与している．機能表現に対して付与される判定ラベルは，F,A,Mのいずれかであり，これらが本論文における検出対象となる．</subsection>
  <subsection title="判定ラベル体系">判定ラベルとは，機能表現候補が文中でどのような働きをしているかを表すラベルであり，用例データベースではtbl:判定ラベル体系の通り，6種類のラベルが設定されている．以下，個々の判定ラベルについて説明する．用例データベースでは，IPA品詞体系(THiMCO97)の形態素解析用辞書に登録されている語から，「助詞・格助詞・連語」として登録されている語を取り除いた残りの語を，語としている．そして，ある機能表現候補が，1個以上の語，複合辞または慣用表現からなる列である場合，その候補は判定単位として適切であるが，それ以外の場合は，その候補は判定単位として不適切であるとして，判定ラベルBを付与している．例えば，tbl:判定ラベル体系中のex:A43-2000:Bに含まれる機能表現候補「にかけて」は，「心配する」という意味の慣用表現「気にかける」の一部が活用した形であり，先に述べた条件を満たしていない．したがって，ex:A43-2000:Bには，判定ラベルBが付与される．判定ラベルYは，機能表現候補の読みが，判定対象となっている機能表現の読みと一致していないことを表す．例えば，「AうえでB」という形で，「Aした後でB」という出来事の継起関係を表す機能表現「うえで」の用例としてtbl:判定ラベル体系中のex:A12-1000:Yを判定する場合を考える．この場合，機能表現候補の読み「じょうで」と，判定対象となっている機能表現の読み「うえで」が一致していないので．判定ラベルYを付与する．判定ラベルCは，機能表現候補に内容的に働いている語が含まれていることを表す．例えば，tbl:判定ラベル体系中のex:A56-1000:Cの機能表現候補に含まれる動詞「とる」は本来の意味で内容的に働いているので，判定ラベルとしてCを付与する．判定ラベルF,A,Mは，機能表現候補が機能的に働いているとき，その機能を区別するためのラベルである．判定ラベルFは，機能表現候補が複合辞用例集で説明されている用法で働いていることを表し，判定ラベルAは，機能表現候補が接続詞的に働いていることを表す．判定ラベルMは，これら以外の機能的な働きをしていることを表す．例として，「ところで」の用例としてtbl:判定ラベル体系中のex:A22-1000:F()を判定する場合を考える．ex:A22-1000:Fのターゲット文字列は，複合辞用例集で説明されている通りに逆接の働きをしているので，判定ラベルFを付与する．ex:A22-1000:Aのターゲット文字列は，文頭で接続詞的に働いているので，判定ラベルAを付与する．ex:A22-1000:Mのターゲット文字列は，形式名詞「ところ」を含めて機能的に働いているので，判定ラベルMを付与する．本論文では，判定ラベルF,A,Mが付与される機能表現候補を検出対象とする．</subsection>
  <subsection title="チャンキングによる定式化">*-2pt本節では，最初に，機能表現検出タスクに対して機械学習的手法を適用する場合に，考慮しておくべき2つの問題点について述べる．第1の問題点は，学習データの分量とモデルの複雑さの間に存在するトレードオフの関係であり，第2の問題点は，機能表現候補が部分的に重複して現れた場合の取り扱いである．その上で，機能表現を検出する手順として，以下の2通りの手順を検討する．1つまたは複数の形態素からなる機能表現候補を単位として，判定ラベ	ルを付与する手順（以下，手順1と呼ぶ）．形態素を単位として，機能表現の一部であることを表すチャンクタグを付与する手順（以下，手順2と呼ぶ）．手順2については，検出対象とする機能表現の取り扱い方によって，更に2通りに細分化することができる．第1は，検出対象とする全ての機能表現に同一のチャンクタグを用いる手順（以下，手順2-aと呼ぶ）であり，第2は，機能表現毎に異なるチャンクタグを用いる手順（以下，手順2-bと呼ぶ）である．機能表現検出タスクに対して機械学習的手法を適用する場合には，まず，学習データの分量とモデルの複雑さの間に存在するトレードオフの関係を考慮する必要がある．一般に，あるタスクに対して機械学習手法を適用する時，そのタスクの対象をどの程度に細分化してモデルで表現するかは，非常に重要な問題である．十分な分量の学習データが利用可能である場合には，タスクの対象を細かく分類した複雑なモデルを採用することによって，モデルの予測精度は改善する．しかし，不十分な分量の学習データしか利用できない場合に，過度に複雑なモデルを採用すると，モデルの予測精度は悪化する．つまり，機能表現検出タスクに対して機械学習的手法を適用する場合には，利用できる学習データの量を考慮しながら，適当な複雑さのモデルを選択する必要がある．機能表現検出タスクに対して機械学習的手法を適用する場合には，第2の問題点として，機能表現候補が部分的に重複して現れる場合を考慮する必要がある．例えば，ex:toiu-Fとex:toiumonono-Fには，「という」および「というものの」という2つの機能表現候補が，部分的に重複して現れている．それが試合0ptという0ptものの0pt難しさだ．	勝った0ptというものの，スコアは悪い．	exampleex:toiu-Fでは，「AというB」という形で用いられてBの具体的な内容を示しているので，2つの機能表現候補の内，「という」という機能表現候補に対して，機能的であるという判定を行う必要がある．それに対して，ex:toiumonono-Fでは，「AというもののB」の形で，前件Aの成立・存在を認めた上で，それにもかかわらず後件Bのようなことがあるという関係を述べているので，2つの機能表現候補の内，「というものの」という機能表現候補に対して，機能的であるという判定を行う必要がある．実際に予備調査を行った結果から，機能表現候補の出現箇所の約20%において，このように複数の機能表現候補の一部が重複した形で現れることが分かった．したがって，機能表現検出において，複数の機能表現候補が部分的に重複して現れる場合を無視することは適当ではなく，その複数の候補を適切に扱う必要がある．以上の問題点を踏まえて，手順1について検討する．ある1つの機能表現候補に適切な判定ラベルを付与するには，その候補に付与される可能性がある複数の判定ラベル間に優先順位を与えるモデルが必要である．つまり，判定ラベルの数をUとすると，Uに比例した複雑さのモデルが必要である．手順1では，機能表現毎に個別に判定ラベルを付与するため，機能表現の種類数をVとすると，判定ラベルの総数は，候補毎の判定ラベルの数Uと機能表現の種類数Vの積UVとなる．したがって，手順1のモデルの複雑さは，UVに比例する．また，第2の問題点に対応するには，部分的に重複している複数の機能表現候補と判定ラベルの対から，適当なものを選択する必要がある．手順1のモデルでは，機能表現候補と判定ラベルのUV通りの対を全て区別しているので，それらを比較することにより，適当な対を選択する．次に，手順2について検討する．手順2では，形態素を単位として判定を行い，それぞれの形態素に，機能表現の一部であることを表すチャンクタグを付与する．ある形態素に適切なチャンクタグを付与するには，その形態素に付与される可能性がある全てのチャンクタグに優先順位を与えるモデルが必要である．このようなモデルの複雑さは，その形態素に付与される可能性があるチャンクタグの種類数に比例する．さらに，チャンクタグcを形態素m_1に付与する場合と形態素m_2に付与する場合の2通りの状況を考える．また，機能表現に含まれる全ての形態素の異なり数Mとする．この時，同一のチャンクタグcを付与する場合であっても，付与対象となる形態素が異なる場合には異なるモデルが必要という立場に立つと，手順2のモデルの複雑さは，チャンクタグの種類数と，形態素の異なり数Mの積に比例すると考えられる．この分析を踏まえて，手順2-aと手順2-bのモデルの複雑さを検討する．手順2-aでは，検出対象とする全ての機能表現に同一のチャンクタグを用いる．このチャンクタグは，その形態素が含まれるチャンクの用法を表す判定ラベルと，その形態素がチャンクの中で占める位置を表す部分からなり，チャンクタグの種類数はUに比例する．よって，手順2-aのモデルの複雑さはUMに比例する．一方，手順2-bでは，機能表現毎に異なるチャンクタグを用いる．このチャンクタグは，その形態素がどの機能表現の一部であるかを表す部分，その形態素が含まれるチャンクの用法を表す判定ラベル，および，その形態素がチャンクの中で占める位置を表す部分からなり，チャンクタグの種類数はUVに比例する．よって，手順2-bのモデルの複雑さは，UVMに比例する．また，手順2では，形態素を単位としてチャンクタグを付与することによって，部分的に重複している複数の機能表現候補の選択も同時に行っている．例えば，ex:toiu-F，（）の場合，形態素「もの」に対してチャンクタグを付与すると，機能表現候補「という」と機能表現候補「というものの」のどちらが適切かという選択も同時に行われる．先に述べた通り，モデルの複雑さと，モデルの推定に必要となる学習データの量にはトレードオフの関係が存在する．手順1のモデルの複雑さはUVに比例し，手順2-aのモデルの複雑さはUMに比例し，手順2-bのモデルの複雑さはUVMに比例する．章で述べたように，異形を考慮すると，機能表現の種類数Vは1万種類以上となる．それに対して，機能表現中に現れる形態素は，助詞・助動詞などの付属語と限られた自立語のみであり，機能表現中に現れる形態素の異なり数Mは，機能表現の種類数Vよりもはるかに少なく，多くても数百程度と予想される．したがって，検討した手順の中で，もっとも簡単なモデルを使っている手順は，手順2-aである．本論文では，利用できる学習データの量が十分ではない可能性を考慮して，複雑なモデルの採用を避け，できるだけ簡単なモデルの手順を採用することにする．よって，本論文における機能表現検出タスクの定式化においては，手順2-aを採用する．すなわち，形態素を単位として，機能表現の一部であることを表すチャンクタグを付与し，機能表現をチャンキングするという方式を採用する．そのチャンクタグとしては，検出対象とする全ての機能表現に同一のチャンクタグを用いる．</subsection>
  <section title="SVMを用いたチャンキングによる機能表現検出"/>
  <subsection title="Support Vector Machines">サポートベクトルマシンは，素性空間を超平面で分割することによりデータを2つのクラスに分類する二値分類器である．2つのクラスを正例，負例とすると，学習データにおける正例と負例の間隔（マージン）を最大にする超平面を求め，それを用いて分類を行う．すなわち，以下の識別関数f(x)の値によってクラスを判別することと等価である．f(x)&amp;=sgn(^l_i=1_iy_iK(x_i,x)	+b)b&amp;=-max_i,y_i=-1b_i	+min_i,y_i=1b_i2b_i&amp;=^l_j=1_jy_jK(x_j,x_i)alignここでxは識別したい事例の文脈（素性の集合），x_iとy_i(i=1,...,l,y_i1,-1)は学習データの文脈とクラスである．また，関数sgn(x)は，x0のときに1，x&lt;0のときに-1となる二値関数である．各_iは，式()と式()の制約のもとで式()のL()を最大にするものである．L()&amp;=^l_i=1_i-12^l_i,j=1_i_jy_iy_jK(x_i,x_j)&amp;0_iC,,(i=1,...,l)&amp;^l_i=1_iy_i=0align関数Kはカーネル関数と呼ばれ，様々なものが提案されているが，本論文では次式で定義される多項式カーネルを用いる．ここで，C,dは実験的に設定される定数である．予備実験を行い，次数dの値として1,2,3の3通りを検討した．d=2,3とした場合はF値に大きな差はなかったが，d=1とするとF値がかなり悪化した．ただし，d=3とした場合は，d=2とした場合に比べて，学習時間がかなり増加したため，本論文では，次数dの値として2を用いる．また，予備実験において，マージンCの値として1,0.1,0.01,0.001,0.0001の5通りを検討したところ，F値に大きな差が見られなかったため，本論文ではマージンCの値として1を用いる．</subsection>
  <subsection title="チャンクタグの表現法">節で述べたように，本論文では，検出対象とする機能表現全てに共通のチャンクタグを，形態素を単位として付与するという手順で，機能表現検出を行う．チャンクタグは，そのチャンクタグが付与された形態素が，検出対象とする機能表現のいずれかに含まれるか否かを表し，チャンクの範囲を示す要素とチャンクの用法を示す要素という2つの要素からなる．以下，本論文で用いたチャンクタグについて詳細を述べる．チャンクの範囲を示す要素の表現法としては，以下で示すようなIOB2フォーマットが広く利用されている．本論文でも，このIOB2フォーマットを使用する．チャンクの用法を示す要素の表現法としては，tab:tagのように様々なものが考えられる．例えば，体系5(CHK5)は，6種類の判定ラベルF,A,M,C,Y,Bのうち，ラベルA,MとラベルC,Y,Bをそれぞれ区別せずに1つの分類とみなす表現法である．そして，各機能表現候補は，チャンクであることを表す要素(B/I)と，用法を示す要素(F/AM/CYB)を組み合わせた6種類のチャンクタグによって表現される．実際には，この6種類に，チャンクに含まれないことを表すチャンクタグOを加えて，fig:chunktagのように7種類のチャンクタグを付与する．また，体系11(CHK11)は，判定ラベルF,A,Mの機能表現候補に対しては体系5と同様にチャンクタグを付与するが，判定ラベルC,Y,Bの機能表現候補に対しては，チャンクとして区別せずに，チャンクタグOを付与する体系である．予備実験の結果，いずれの表現法を用いても大きな性能の差は見られなかったため，本論文では，最も性能が良かった体系5(CHK5)を用いる．本論文では，用例データベースで設定されている判定ラベルのうち，ラベルFが付与された表現を検出する検出器（これを，検出器Fと呼ぶ）と，ラベルF,A,Mのいずれかが付与された表現（機能表現）を検出する検出器（これを，検出器FAMと呼ぶ）を作成する．検出器FAMの評価時には，判定ラベルF,A,Mを区別しない．判定ラベルFは，複合辞用例集で説明されている用法で用いられていることを表す判定ラベルであり，機能表現候補がひとかたまりとなって非構成的な意味を持っている場合にのみ付与される．それに対して，判定ラベルA,Mは，機能表現候補が非構成的な意味を持っているか否かに関わらず，その機能表現候補が機能的な働きをしていることを表すラベルである．したがって，検出器Fは，非構成的な意味を持つ機能表現（の一部）のみを検出する検出器となり，検出器FAMは機能表現全体を検出する検出器となる．SVMは二値分類器であるため，そのままでは，2クラスの分類しか扱えない．本論文のようにクラス数が3以上の場合には，複数の二値分類器を組み合わせて拡張する必要がある．本論文では，拡張手法としては，広く利用されているペアワイズ法を用いる．ペアワイズ法とは，N個のクラスに属するデータを分類する時，異なる2つのクラスのあらゆる組み合わせに対する二値分類器を作り，得られたN(N-1)/2個の二値分類器の多数決により，クラスを決定する方法である．</subsection>
  <subsection title="素性">学習・解析に用いる素性について説明する．文頭からi番目の形態素m_iに対して与えられる素性F_iは，形態素素性MF(m_i)，チャンク素性CF(i)，チャンク文脈素性OF(i)の3つ組として，次式によって定義される．形態素素性MF(m_i)は，形態素解析器によって形態素m_iに付与される情報である．本論文では，IPA品詞体系(THiMCO97)の形態素解析用辞書に基づいて動作する形態素解析器ChaSenによる形態素解析結果を入力としているため，以下の10種類の情報（表層形，品詞，品詞細分類13，活用型，活用形，原形，読み，発音）を形態素素性として用いた．チャンク素性CF(i)とチャンク文脈素性OF(i)は，i番目の位置に出現している機能表現候補に基づいて定まる素性である．今，下図のような形態素列m_jm_im_kからなる機能表現候補Eが存在したとする．チャンク素性CF(i)は，i番目の位置に出現している機能表現候補Eを構成している形態素の数（機能表現候補の長さ）と，機能表現候補中における形態素m_iの相対的位置の情報の2つ組である．チャンク文脈素性OF(i)は，i番目の位置に出現している機能表現候補の直前2形態素および直後2形態素の形態素素性とチャンク素性の組である．すなわち，i番目の位置に対するCF(i)およびOF(i)は次式で表される．CF(i)&amp;=k-j+1,;;i-j+1(i)&amp;=MF(m_j-2),CF(m_j-2),MF(m_j-1),CF(m_j-1),&amp;;MF(m_k+1),CF(m_k+1),MF(m_k+2),CF(m_k+2)align*節で述べたように，機能表現検出においては，1つの文中に，複数の機能表現候補が部分的に重複して現れる場合を考慮する必要がある．ここでは，そのような場合のチャンク素性とチャンク文脈素性の付与方法について考える．複数の機能表現候補が部分的に重複して現れている場合，それらの候補全てに基づいてチャンク素性とチャンク文脈素性を付与するという方法と，それらの候補から何らかの基準を用いて1つの候補を選択し，選択された候補に基づいてチャンク素性とチャンク文脈素性を付与するという方法が考えられる．前者の方法で付与された素性を参照して機械学習を行うには，重複する可能性がある機能表現の全ての組み合わせに対して十分な量の学習事例が必要であるが，そのような学習事例を準備することは現実的ではない．そのため，本論文では，後者の方法を採り，次の優先順序に従って選ばれた1つの機能表現候補に基づいて，チャンク素性とチャンク文脈素性を付与することにする．例えば，ex:nakutehaikemasenには，「なくてはいけません」および「てはいけません」という2つの機能表現候補が，部分的に重複して現れている．慎重にし0ptなくてはいけません．					exampleこの場合，「なくてはいけません」という機能表現候補が，「てはいけません」という機能表現候補に比べて，より左の形態素から始まっているので，「なくてはいけません」という機能表現候補に基づいて，チャンク素性とチャンク文脈素性を付与する．また，ex:toiumononoには，「という」および「というものの」という2つの機能表現候補が，部分的に重複して現れている．それが試合0ptというものの0pt難しさだ．	exampleこの場合，2つの機能表現候補の先頭の形態素は同一であるため，より形態素数が多い候補「というものの」に基づいて，チャンク素性とチャンク文脈素性を付与する．i番目の形態素に対するチャンクタグをc_iとすると，チャンクタグc_iの学習・解析を行う場合に用いる素性として，i番目の形態素および前後2形態素に付与された素性F_i-2,F_i-1,F_i,F_i+1,F_i+2と，直前2形態素に付与されたチャンクタグc_i-2,c_i-1を用いる（yamcha）．解析時には，解析によって得られたチャンクタグを，直前2形態素に付与されたチャンクタグとして順に利用して，解析を行う．前後3形態素の素性と直前3形態素のチャンクタグを用いて学習・解析を行う予備実験も行ったが，前後2形態素の素性と直前2形態素のチャンクタグを用いた場合に比べて，殆んど性能が変わらなかったため，前後2形態素の素性と直前2形態素のチャンクタグを用いる．</subsection>
  <section title="人手による規則を用いた検出">この節では，形態素解析結果に基づいて，人手で作成した規則によって機能表現候補の用法を識別する検出器の概略について述べる．形式的には，ある機能表現候補Eの用法を判定する規則T(E)は，形態素列パターンP(E)と，判定規則リストR(E)の2つ組として，次のように定義される．[T(E)P(E),:R(E)]機能表現候補Eに一致する形態素列パターンP(E)は，1つの形態素に一致する形態素パターンpの列である．P(E)&amp;p_1p_2p_lp&amp;Lex,:POS,:FORMalign*形態素パターンpは，形態素の基本形の表記Lex，品詞POSおよび活用形FORMの3つ組として定義される．例えば，「として」に対する形態素列パターンP()は，以下のように3つの形態素パターンからなる．[P()=0pt,~,*0pt,~,~0pt0pt,~,*]なお，本論文では，IPA品詞体系の形態素解析用辞書に基づいて動作する形態素解析器ChaSenによる形態素解析結果を入力としているため，品詞と活用形はIPA品詞体系で指定する．また，判定規則リストR(E)は，機能表現候補の直前の形態素列に一致する左接続制約LC，直後の形態素列に一致する右接続制約RC，および，これらの制約を満たした場合の判定ラベルLからなる3つ組として定義される判定規則rの順序付き集合である．R(E)&amp;r_1,r_2,,r_kr&amp;LC,:RC,:Lalign*左接続制約LCおよび右接続制約RCは，論理関数and,~or,~notと，左接続素性LFまたは右接続素性RFの組み合わせである．LC&amp;LF|and(LC',LC'')|or(LC',LC'')|not(LC')RC&amp;RF|and(RC',RC'')|or(RC',RC'')|not(RC')align*ここで，LC',LC''は任意の左接続制約を表し，RC',RC''は任意の右接続制約を表す．例えば，「として」に対する判定規則リストR()は，以下のような2つの判定規則の順序付き集合である．[R()=,and(,~not(0pt,~,*)),,0pt,:,]最初の判定規則は，左接続制約なし，右接続制約「and(,not(,,*))」，判定ラベルCという3つ組である．これは，機能表現候補の右側が「だ」以外の助動詞であれば，機能表現候補の左側がどのような表現であっても，判定ラベルCを付与するという判定規則を意味する．接続素性としては，複合辞用例集で説明されている接続制約を参考にして，tbl:左接続素性とtbl:右接続素性のような素性を用意した．このような規則T(E)に基づく判定は，以下の2段階からなる．最初に，形態素列パターンP(E)によって機能表現候補を発見し，次に，判定規則リストR(E)に含まれる判定規則を先頭から順に検査して，最初に一致した判定規則r_iの判定ラベルを出力する．例えば，ex:toshite-Fの形態素解析結果を対象として判定を行う場合を考える．たくさんの若者たちが，ボランティア0ptとして，頑張っている．	example最初に形態素列パターンP()によって下線部が機能表現候補として発見される．次に，判定規則リストR()に含まれている判定規則を順に適用していく．1番目の規則,and(,not(,~,*)),は，右接続制約が「だ」以外の助動詞となっているが，ex:toshite-Fでは，機能表現候補の直後は読点になっているから，成り立たない．2番目の規則,:,は，左接続制約が「体言」になっており，ex:toshite-Fでも成り立っているので，判定ラベルとしてFを出力する．なお，全ての判定規則が成り立たなかった場合は，判定ラベルを付与しない．人手で作成した判定規則の数を，tbl:human_crafted_rulesに示す．1つの機能表現候補を判定するための判定規則リストは，平均して2.7個の判定規則からなっている．なお，使用した接続素性は186個である．1つの文に対して，全ての可能な機能表現候補に対する規則を適用すると，複数の機能表現候補が照合されることがある．この時，節で述べた場合と同様に，複数の機能表現候補が部分的に重なって出現して，それらの候補に対する判定ラベルが相互に競合し，複数の判定ラベル付与結果を同時に採用できない場合がある．その場合は，以下の優先順序に従って機能表現候補を採用する．まず，形態素列長で比較して，より長い機能表現候補を採用する．機能表現候補の形態素列長が等しい場合は，先頭の形態素が最も左側の機能表現候補を採用する．既に採用されている機能表現候補と，競合する機能表現候補は，全て棄却するこの優先順序は，チャンク素性・チャンク文脈素性を付与する際に，部分的に重複する複数の機能表現候補を取捨選択するための優先順序とは異なっている（節）．ここでは，形態素列長として長い機能表現候補は，短い機能表現候補と比べて，判定の際の制約条件が多くなるから，より信頼できるというヒューリスティックスに基づいて，形態素列長として長い機能表現候補を優先している．．</section>
  <section title="実験と考察">本論文で提案する2つの検出器，検出器Fと検出器FAMに対して，学習および解析を行い，各ベースラインと性能を比較した．また，用いる素性の違いによって，性能がどのように変化するかを調査した．さらに，訓練時のデータサイズの違いと検出性能の関係を明らかにし，最後に，訓練データの作成コストの削減が可能であるかを調査した．</section>
  <subsection title="データセット">文を単位として学習を行うには，文中に現れる全ての機能表現候補に対して判定ラベルが付与されたデータが必要である．そのため，本論文の対象とする52表現に対する用例として用例データベースに収録されている2600例文（1つの表現につき50例文）について，これらの例文に含まれている全ての機能表現候補に判定ラベルを付与した．以下，この2600例文をまとめて，全データセットと呼ぶ．ただし，用例データベースでは，機能表現候補の先頭と末尾が形態素境界と一致しない候補にも判定ラベルが付与されているが，本論文では，形態素解析結果に基づいて機能表現を検出する立場をとるため，そのような機能表現候補に対する判定ラベルは取り除くことにする．具体的には，以下のような処理を行った．最初に，用例データベースに収録されている用例を，IPA品詞体系の形態素解析用辞書に基づいて動作する形態素解析器ChaSenを用いて形態素解析した．次に，形態素解析結果中に，形態素解析用辞書に「助詞・格助詞・連語」や「接続詞」として登録されている複合語が含まれていた場合は，その複合語を，構成要素である形態素の列に置き換えた．このようにして得られた形態素解析結果と機能表現候補を照合し，先頭と末尾が形態素境界と一致しなかった176個の候補に対する判定ラベルを取り除いた．取り除いた判定ラベルの内，175個は，人手によってラベルBと判定されている．また，取り除いた手順より明らかに，この175個の判定ラベルに対応する機能表現候補は，形態素解析結果のみに基づいてラベルBと判定することができる．したがって，これらの判定ラベルを取り除いても，機能表現検出の評価としては問題はない．取り除いた判定ラベルの内，残る1個は，人手によってラベルMと判定されている．この判定ラベルは，形態素解析誤りによって取り除かれてしまったが，数が僅かであり，無視することができる．全データセットに含まれる各ラベルの数と，全形態素数をtab:datasetに示す．1つの例文に，複数の機能表現候補が出現する場合があるため，機能表現候補の総数は，例文の総数よりも多くなっている．</subsection>
  <subsection title="評価尺度">実験を評価する際の尺度には，以下の式で表される精度，再現率，F値，および判別率を用いた．&amp;=[0.5zh]&amp;=[0.5zh]&amp;=2+[0.5zh]&amp;=align*また，実験は，10分割交差検定を用いて行った．</subsection>
  <subsection title="既存の解析系に対する評価基準">既存の解析系(JUMAN/KNPおよびChaSen/CaboCha)は，形態素解析および構文解析段階で処理が必要となる機能表現を，部分的に処理の対象としている．しかし，明示的に機能表現を取り扱うという立場は取っていないため，機能表現のチャンキングというタスクに対する既存の解析系の性能を評価するには，その出力をどのように解釈するかを定めておく必要がある．形態素解析器JUMANと構文解析器KNPの組み合わせでは，機能表現は以下のように処理される．最初に，接続詞として形態素解析用辞書に登録されている機能表現は，形態素解析時に検出される．次に，構文解析時に，解析規則に記述された特定の形態素列が現れると，直前の文節の一部としてまとめたり，直前の文節からの係り受けのみを受けるように制約を加えて，機能表現である可能性を考慮した解析を行う．一方，IPA品詞体系(THiMCO97)の形態素解析用辞書を用いた形態素解析器ChaSenと，京都テキストコーパスから機械学習したモデルを用いた構文解析器CaboChaの組合わせでは，機能表現は以下のように処理される．最初に，形態素解析用辞書に「助詞・格助詞・連語」や「接続詞」として登録されている機能表現は，形態素解析時に検出される．また，「ざるを得ない」などの表現は直前の文節の一部としてまとめられ，機能的な表現として解析される．本論文では，機能表現候補部分が，機能表現である可能性を考慮した解析の対象となっている場合は，判定ラベルF,A,Mのいずれかが付与されているとみなし，それ以外の場合は，判定ラベルC,Y,Bのいずれかが付与されているとみなすことにする．既存の解析系でも，一部の機能表現については，機能的な働きをしていることを考慮した解析が行われているが，その対応状況は不十分である．判定ラベルF,A,Mのいずれかが付与されている用例の内，少なくとも1つの用例が，機能的に働いている可能性を考慮して解析され，かつ，判定ラベルC,Y,Bのいずれかが付与された用例の内，少なくとも1つの用例が，機能的に働いている可能性を考慮せずに解析されている場合，その機能表現は，用法が正しく区別される可能性があるとする．用例データベースに50用例が収録されている表現で，かつ，機能的な意味で用いられている場合と，それ以外の意味で用いられている場合の両方が適度な割合で出現する表現は，52種類ある．本論文では，この52種類を対象とするが，その内，JUMAN/KNPによって用法が正しく区別される可能性がある表現は，31種類である．一方，ChaSen/CaboChaによって用法が正しく区別される可能性がある表現は26種類である．また，用例データベースに収録されている337表現全体では，新聞上の実際の用法の割合に関係なく識別が必要と思われる表現は，111種類である．その内，JUMAN/KNPによって用法が正しく区別される可能性がある表現は43種類，ChaSen/CaboChaによって用法が正しく区別される可能性がある表現は40種類である．</subsection>
  <subsection title="評価結果"/>
  <subsubsection title="概要">検出器Fおよび検出器FAMと，各ベースラインの検出性能をtab:kekka_gaiyouに示す．tab:kekka_gaiyouにおいて，「頻度最大の判定ラベル」とは，全ての候補部分に対して頻度最大の判定ラベル（ラベルF）を付与した場合の検出性能である．「JUMAN/KNP」および「ChaSen/CaboCha」といった既存の解析系は，機能表現の用法の区別を意識した検出は行わないため，ラベルF，A，Mを正解とする評価のみを行った．「人手作成の規則による検出器」は，節で記述した手法による検出性能である．tab:kekka_gaiyou中の「CRFを用いた検出器」は，ConditionalRandomFileds(CRF)によって学習・解析を行った場合の検出性能である．CRFとは，系列ラベリング問題のために設計された識別モデルであり，正しい系列ラベリングを他の全ラベリング候補と弁別するような学習を行う．本論文では，CRFによる学習・解析用ツールとしてCRF++を利用した．素性としては，前後2形態素の形態素素性，チャンク素性，チャンク文脈素性と，直前2形態素のチャンクタグを用いた．学習時には，事前分布としてGaussianPriorを用いて事後確率を最大化することにより，パラメータを正則化した．その際のハイパーパラメータとしては，1,2,3,4,5の5通りの値について予備実験を行い，最も良い性能を示した1を採用した．tab:kekka_gaiyou中の「SVMを用いた検出器」は，本論文の提案するSVMによるチャンキング手法による検出性能である．表より，提案手法は，学習・解析に用いた素性に関わらず，ベースラインおよび人手作成の規則による検出よりも，高いF値を示した．また，提案手法は，CRFを用いた検出器よりも，高いF値を示した．学習・解析に用いた素性の違いによる性能の違いを検討すると，形態素素性のみを用いた場合に比べて，形態素素性とチャンク素性を併用した場合の方が，F値で2ポイント以上上回った．このことから，チャンク素性は，機能表現を検出するための素性として有効であったと言える．それに対して，形態素素性とチャンク素性を併用した場合と，形態素素性・チャンク素性・チャンク文脈素性と全ての素性を使った場合に，性能の差は殆んど見られなかった．全ての素性を用いて学習と解析を行った検出器Fおよび検出器FAMにおいて，他の表現と比較して極端に検出性能が悪く，F値が50に達しなかった表現は，「としては」と「にあたり」の2表現である．例えば，ex:niatari-Fに含まれる「にあたり」は，「（新規参入という）時が来たのに当面して」という機能的な意味で用いられているため，判定ラベルFが付与されるべき文である．それに対して，ex:niatari-Cおよびex:niatari-C2に含まれる「にあたり」は，内容的に用いられているため，判定ラベルCが付与されるべき文である．新規参入0ptにあたり，潜在的なニーズを掘り起こそうと，転勤族	を主な対象にした．お神酒の瓶が女性0ptにあたり，けがをする事故があった．	米国の最先端の科学者が知恵を結集して原爆の開発0ptにあたり，	一九四五年八月に広島・長崎に原爆が投下された．	exampleしかし，SVMを用いた検出器Fおよび検出器FAMは，ex:niatari-Fとex:niatari-Cに対しては判定ラベルCを，ex:niatari-C2に対しては判定ラベルFを付与してしまい，用法を正しく判定できたのはex:niatari-Cのみだった．仮に，ex:niatari-Fとex:niatari-Cを区別することだけが必要ならば，直前がサ変名詞であることが有効な素性として働く可能性があるが，ex:niatari-C2は，そのような素性だけではうまく判定できない．このように，提案手法によっては適切に検出できない表現もごく少数ながら存在するが，他の表現については，tab:kekka_gaiyouに示したように適切に検出することができた．</subsubsection>
  <subsubsection title="素性の比較">前述の通り，形態素素性とチャンク素性を併用した場合と，形態素素性・チャンク素性・チャンク文脈素性と全ての素性を使った場合に，性能の差は殆んど見られなかった．しかし，表現によっては，チャンク文脈素性が，検出の際に決定的な効果をもつ表現も存在するはずである．そこで，実際にそのような効果が現れている表現が存在するか，検出器FAMについて，形態素素性とチャンク素性のみ用いた場合の検出性能と，チャンク文脈素性を含む全ての素性を用いた場合の検出性能を，表現毎に比較した．F値で比較したとき，全ての素性を用いた場合の検出性能が，形態素素性とチャンク素性のみを用いた場合の検出性能を3ポイント以上上回っている表現は，以下の8表現である．この8表現に対して，チャンク文脈素性を含めて全ての素性を用いた場合には検出に成功した用例と，形態素素性とチャンク素性のみを用いた場合には検出に失敗した用例を，比較・分析した．例えば，「にあたって」の検出性能は，形態素素性とチャンク素性のみを用いた場合にはF値で0.79だったのに対して，チャンク文脈素性を含めて全ての素性を用いた場合にはF値で1.00となり，大きな改善が見られた．「にあたって」の用例を分析したところ，機能表現候補の直後に，形態素解析用辞書において「動詞・非自立」と分類されている語が現れていると，内容的に働いていると判定できることが分かった．チャンク文脈素性を用いると，機能表現候補に後続する2形態素分の情報を検出時に利用することができるので，この手がかりを機械学習することができ，検出性能が大きく向上したものと考えられる．「にあたって」以外の7表現の用例についても，「にあたって」と同様の特徴的なチャンク文脈素性が確認できた用例がいくつかあった．しかし，この7表現の用例については，検出性能の改善に寄与したチャンク文脈素性は，それぞれの用例に個別的で，全ての用例に共通するような素性は見い出されなかった．逆に，F値で比較したとき，全ての素性を用いた場合の検出性能が，形態素素性とチャンク素性のみを用いた場合の検出性能を3ポイント以上下回っている表現は，以下の7表現である．この7表現についても，検出に成功した用例と失敗した用例とを比較したが，失敗の原因は，それぞれの用例に個別的で，全ての用例に共通する原因は見い出されなかった．そのため，これらの表現は，チャンク文脈素性がスパースであるために，チャンク文脈素性を参照することによって性能が悪化したと考えられる．このように，素性によって検出性能が良くなる表現と，検出性能が悪くなる表現があることを考慮すると，素性の異なる複数の検出器を組み合わせて検出するという方法が考えられる．この方法を採用した場合，章で述べた場合と同様に，複数の機能表現候補に対する判定ラベルが相互に競合し，複数の検出器による検出結果を同時に採用できない可能性がある．このような場合に対応するには，複数の検出器による検出結果を統合するための枠組みが必要となるため，本論文では，そのような複雑な手法は用いない（節）．</subsubsection>
  <subsubsection title="SVMを用いたチャンキングと人手で作成した規則を用いた検出器の比較">形態素素性とチャンク素性のみを用いた検出器FAMと，人手により作成した検出規則を用いた手法による検出器FAMに対して，前節と同様に，表現毎に性能を比較した．表現毎に見た場合，人手規則を用いた検出器FAMのF値が，SVMを用いた検出器FAMのF値に比べて3ポイント以上高い表現は，52表現中14表現存在した．14表現の内，「にあたり」などの4表現は，SVMを用いた検出器FAMの精度が，人手規則を用いた検出器FAMの精度を上回っているが，再現率は，人手規則を用いた検出器FAMの方が上回っている．人手規則を用いた検出器FAMでは，再現率を重視して判定規則が作成されているため，検出が困難な表現に対しても，高い再現率を維持できる．そのため，このような表現については，SVMを用いた検出器FAMに比べて，F値が高くなると考えられる．「に従い」などの10表現については，人手規則を用いた検出器FAMが，精度と再現率の両方の尺度で，SVMを用いた検出器FAMを上回っていた．例えば，ex:nishitagai-Fとex:nishitagai-F2に含まれる「にしたがい」はいずれも機能的な意味で用いられており，判定ラベルFが付与されるべきである．それに対して，ex:nishitagai-Cに含まれる「にしたがい」は内容的に用いられているので，判定ラベルCが付与されるべきである．年齢を経る0ptにしたがい，体内の水分は減る．晩年に向かう0ptにしたがい0pt仕事の質が上がっている．二十年ごとに古い伝統の型0ptにしたがい0pt社を建てかえる．exampleSVMを用いた検出器FAMは，ex:nishitagai-Fとex:nishitagai-Cは正しく判定できたが，ex:nishitagai-F2には判定ラベルCを誤って付与した．これは直後の文脈を用いて誤った判定を行っているのではないかと考えられる．それに対して，人手規則を用いた検出器FAMは，機能的に働いている機能表現候補の直前は用言であるという規則に基づいて，3つの文を正しく判定した．このように，表現毎に個別に見ると，人手によって作成された規則が，SVMよりも良い性能を示す場合はあるが，対象とする表現全体としては，SVMを用いた検出器FAMの性能が，人手規則による検出器FAMの性能を上回っている．</subsubsection>
  <subsection title="訓練データサイズの違いによる比較">ここまでの実験では，用例データベースに基づいて作成した全データセットを訓練データとして実験を行った．本節では，このデータサイズが，機能表現検出の学習に十分であるか検討する．そのため，訓練データとして用いる判定ラベル数を減少させた時，検出性能がどのように変化するかを調査した．結果をfig:learning_curveに示す．fig:learning_curveより，全データセットの約10分の1の判定ラベルのみを訓練データとして用いた時は，検出性能が大きく低下しているが，判定ラベル数の増加にともなって検出性能も向上し，全データセットに相当する判定ラベル数付近では，対象とする表現全体に対する検出性能はほぼ飽和していることがわかる．したがって，チャンク文脈素性を参照することによって検出性能が悪化する7表現を除いた残る45表現については，全データセットの分量で，機能表現検出の学習に十分であると言える．また，チャンク文脈素性を参照することによって検出性能が悪化する7表現についても，形態素素性とチャンク素性を用いた検出器を学習するには，全データセットの分量で十分であると言える．</subsection>
  <subsection title="訓練データの作成コストの削減">ここまでの実験では，文を単位として機械学習を行うため，文中に現れる全ての機能表現候補に対して判定ラベルを付与した全データセットを，訓練データとして用いた．しかし，このようにして訓練データを作成する方法には，以下のような問題が考えられる．「という」などのように出現頻度の高い機能表現と，出現頻度の低い機	能表現の収集数に差が生じ，学習に偏りが生じる恐れがある．検出対象とする機能表現の種類を増やすと，たとえ例文数が一定であっ	ても，機能表現候補の出現数が増加し，訓練データの作成コストが増大	する．これらの問題を解決するため，例文中に含まれる全ての機能表現候補に判定ラベルを付与するのではなく，必要な一部の機能表現候補に限って判定ラベルを付与する方法を検討する．前者の問題を解決するためには，各機能表現に対する学習事例の数を一定にすることが考えられる．そのため，1表現に対して50用例が収録されている用例データベースにおいて判定ラベルが付与されている機能表現候補と，その前後2形態素のみを学習データとして用いるという方法を考えた．しかし，この方法では，前後2形態素の範囲内に，判定ラベルがまだ付与されていない別の機能表現候補が含まれている場合，誤った判定ラベルを用いて学習してしまうことがあり，予備実験でも性能がかなり低下した．この問題を避けるには，判定ラベルが付与されている機能表現候補の前後2形態素の範囲内に，別の機能表現候補が出現していた場合は，その機能表現候補にも判定ラベルを付与し，その候補の前後2形態素を範囲に加えるという操作を繰り返し，判定ラベルが付与された機能表現候補とその前後2形態素のみを残すという方法が考えられる．しかし，この方法でも，チャンクタグOに対する学習事例の数が不十分なために，性能が低下した．そのため，ここまでの操作によって判定ラベルが付与されなかった機能表現候補を取り除き，それらによって分断された部分を，それぞれ1文とみなして学習を行う方法を採用した．例として，「ばかりだ」という機能表現の例文として，用例データベースに収録されているex:bakaridaを考える（``/''は形態素区切りを表す）．/セミナー/開催/に/あたり/，/最初/は/戸惑う/こと/ばかり/だっ/た/と/いう/．/	example「ばかりだ」の前後2形態素の範囲内には，「という」という機能表現候補が含まれている．そのため，この機能表現候補にも判定ラベルを付与し，この機能表現候補の前後2形態素の範囲を判定ラベル付与の対象に加える．/戸惑う/こと/ばかり/だっ/た/と/いう/．/example「にあたり」という機能表現候補には，この操作によっては，判定ラベルが付与されない．この機能表現候補を取り除き，それによって分断された部分を，ex:divided_sentence_1とex:divided_sentence_2のようにそれぞれ1文とみなして学習を行う．/セミナー/開催//，/最初/は/戸惑う/こと/ばかり/だっ/た/と/いう/．/	exampleこの手続きによって得られたデータセットを，以下では部分データセットと呼ぶ．部分データセットに含まれる各ラベル数と，全形態素数をtab:datasetに示す．データセットの作成に必要な人手コストは，機能表現候補の出現数にほぼ比例すると考えられる．したがって，tab:datasetより，部分データセットの作成に必要な人手コストは，全データセットの作成に必要な人手コストと比較して，かなり小さくなっていることが分かる．この部分データセットを訓練データとして機能表現検出器を作成した場合の検出性能をtab:cost_Fに示す．学習・解析の素性としては，検出器Fについては，形態素素性とチャンク素性を，検出器FAMについては，形態素素性，チャンク素性およびチャンク文脈素性を用いた．部分データセットを訓練データとした場合の検出性能は，全データセットを訓練データとした場合の検出性能と比較して，検出器Fについて約1.0ポイント，検出器FAMについて約0.8ポイント低下している．しかし，この検出性能の低下は，データセットの作成に必要な人手コストの削減に対して，十分に小さい．したがって，上で述べた方法によって訓練データの作成コストの削減ができているといえる．</subsection>
  <section title="関連研究">は，話し言葉コーパスを対象コーパスとして，半自動で精度良く短単位・長単位の2種類の粒度の形態論的情報を付与する枠組みを提案している．この枠組みでは，なるべく少ない人的コストで話し言葉コーパス全体に2種類の粒度の形態素情報を付与するため，最初に短単位の解析を行い，次に，短単位の形態素情報を素性として，短単位をチャンキングすることによって長単位の形態素情報を付与するという手順を採っている．例えば，「という」という機能表現は，短単位列としては助詞「と」および動詞「いう」の連体形の2短単位に分割され，長単位としては助詞「という」という1長単位にチャンキングされる．短単位から長単位をチャンキングするための機械学習手法としては，最大エントロピー法(ME)とSVMを比較し，SVMがより優れていると報告している．内元らの研究は，話し言葉コーパス全体を対象としているのに対して，本論文では，機能表現に焦点をあてて検討を行っている点で異なる．そのため，内元らは話し言葉コーパス中の長単位全体に対する形態素解析精度の評価は行っているが，機能表現に特化した評価は行っていない．一方，本論文では，既存の解析系における機能表現の取り扱い状況を整理した上で，機能表現に特化した性能評価を行っている．また，本論文では，対象となる機能表現のリストを事前に用意しているため，形態素列のどの部分が機能表現として検出される可能性があるかという情報（チャンク素性およびチャンク文脈素性）を利用して，チャンキングを行うことができる．機械学習手法としては，CRFとSVMを比較し，SVMの方が検出性能が高いことを示している．は，機能表現や慣用表現を含む複数の形態素からなる定型的表現をできるだけ網羅的に収集し，機能表現間に類似度を定義して，機能表現の言い換えや機械翻訳に利用することを提案している．とは，日本語の文構造の解析を容易にするため，通常よりかなり長い文節を単位として解析を行うことを提案し，機能表現を含む大規模な長単位機能語辞書を作成している．しかし，これらの先行研究における日本語処理系においては，機能表現と同一の形態素列が内容的に振る舞う可能性が考慮されていない．</section>
  <section title="おわりに">本論文では，機能表現検出と形態素解析は独立に実行可能であると仮定した上で，形態素を単位とするチャンク同定問題として機能表現検出タスクを定式化し，機械学習手法を適用して機能表現の検出を実現した．実際に，SVMを用いたチャンカーYamChaを利用して，形態素解析器ChaSenによる形態素解析結果を入力とする機能表現検出器を実装し，52種類の機能表現を対象として性能評価を行った．その結果，機械学習によって作成した機能表現検出器は，既存の解析系および人手で作成した規則を用いた検出器よりも，高精度に機能表現を検出できることを示した．更に，訓練データの作成コストを削減する方法について検討し，訓練データを作成するコストを大幅に削減しつつ，同時に，検出性能がほぼ同等の検出器を実現できることを示した．今後の研究課題として，検出対象とする機能表現の種類を増やし，その性能を評価することを計画している．また，係り受け解析と機能表現検出を組み合わせることにより，両者をより高精度に行う方法についても検討していきたい．document</section>
</root>
