    \documentclass[japanese]{jnlp_1.3e}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}

\Volume{14}
\Number{4}
\Month{July}
\Year{2007}
\received{2006}{10}{9}
\revised{2007}{4}{15}
\accepted{2007}{4}{16}

\setcounter{page}{43}

\jtitle{仕事文推敲支援に向けた連体修飾部不足に対する受容性判定法}
\jauthor{梅村　祥之\affiref{KUEE} \and 増山　　繁\affiref{KUEE}}
\jabstract{
文章推敲に関する従来研究では，主に，タイプミス，構文構造の複雑さ，表記の揺
れを指摘する手法など，表記レベルと統語レベルの手法に重点がおかれていた．
それに対して，本研究では，読みやすさを向上させるために，
説明が不足していて論理展開が読み取りにくいと感じられる箇所を検出する技術
を扱う．文章としては情報を正確に伝達するための仕事文（仕事用の文）を対象とし
て，文単位での情報不足を推敲対象とする．この課題は意味処理に踏み込むため，
これまで十分研究が行われてこなかった．なお，語用論の「協調の原理」によれ
ば，量の格率と呼ばれる情報不足と情報過多に関する遵守すべき原則がある．
このうち情報過多を扱わない理由は，情報過多が，冗長な情報を無視するのに基づく
読者の負担を増やすだけであるのに対し，情報不足は理解困難という深刻
な事態を招き，重要性が高いためである．
実験準備から解析に至る流れは，次の通りである．
まず，原文から連体修飾部を欠落させた課題文を
生成し，次に，被験者にその箇所に情報不足を感じるかどうかを判定させ
正解判定データを作成した．その後，正解判定データの一部から機械学習を行い，
残りのデータを機械判定させる．機械判定に用いる主な素性として，
修飾部の欠落箇所におけるつながりの滑らかさに関係した
語の連鎖に関する統計量を取り上げた．約1,000箇所の判定課題に対し，
SVMによる機械学習アルゴリズムを用いた自動判定により正解率を測定した結果，
機械判定の正解率として，ベースライン50{\kern0pt}％，
上限（人間の評価のバラツキから上限を定義）76{\kern0pt}％に対し，
10-fold cross validationで67{\kern0pt}％の正解率を得た．
}
\jkeywords{文章推敲，$n$-gram，\textit{SVM}，連体修飾，情報不足}

\etitle{Decision Method for Acceptability of Defection of Adnominal Clause or Phrase for Elaboration}
\eauthor{Yoshiyuki Umemura\affiref{KUEE} \and Shigeru Masuyama\affiref{KUEE}} 
\eabstract{
Previous work on elaboration mainly focuses on
expression-level and/or structure-level technologies
such as correction of typing errors, detection and indications of
the complexity of syntactic structures, fluctuations of expressions and so on.
In contrast, this paper deals with technologies to detect portions
in each sentence, 
where readers feel difficult in reasoning contexts because of information
defection.
We constrain sentences in business writings used as communication media to
transfer information correctly.
This problem is placed in a semantic-level elaboration that has not
been studied sufficiently.
According to ``cooperative principle'' in pragmatics,
there are principles for information defection or information overload
that are called ``maxims of quantity''.
This paper only deals with information defection.
The reason why this paper does not deal with information overload is
that information overload only imposes burden on readers 
not to take account of redundant information. On the other hand, information defection
leads to serious problems that make readers difficult to understand.
The process from preparation of experiments to analyses is as follows.
Firstly, we generate sentences 
where adnominal regions are eliminated. Secondly, we prepare correct
data sets by subjective judgements whether examinees feel explanations
are insufficient or not. Finally, we apply machine learning and automatic
decision on this data. We used $n$-gram statistics and others to
evaluate smoothness of connections between regions crossing missing
portion of adnominal clause of a phrase.
We obtain correct decision rate 67\% in the result of about 1,000 decision tasks
used with SVMs,
against base-line rate 50\% and upper limit of correct decision rate
76\% (determined by dispersion of decisions by human subjects).
}
\ekeywords{Elaboration, $n$-gram, SVM, Adnominal, Defection}

\headauthor{梅村，増山}
\headtitle{仕事文推敲における修飾部判定法}

\affilabel{KUEE}{
	豊橋技術科学大学 知識情報工学系}{
	Department of Knowledge Engineering, Toyohashi University of Technology}


\begin{document}
\maketitle





\section{はじめに}
\label{はじめに}

言語処理技術を利用した文章の推敲や校正の支援に関する研究が行われている．
この研究分野を次の5段階に分けて考える．
 \begin{description}
  \item[表記レベル]
	     誤字の検出と修正，表記揺れの指摘など．
  \item[統語レベル]
	     統語構造の複雑さに起因する読みづらさの指摘など．
  \item[意味レベル1]
	     欠落した格要素の推定や，照応先の特定が困難な場合の指摘．
  \item[意味レベル2]
	     情報不足（論理の飛躍や説明が不足しているもの），
	     情報過多（表現が冗長）の指摘．
  \item[文脈・構成レベル]
	     文間のつながりに関する理解しづらさの指摘．
	     文の構成による論旨の展開についての指摘など．
 \end{description}

まず，「表記レベル」に関しては，自然言語処理の教科書\cite{tanaka}に詳しく解説され
ているように，研究開発が完成段階に達し\cite{ibuki}，
コンピュータのアプリケーションソフトとして実装されている\cite{kasahara}．
次の「統語レベル」に関しても，係り受けの複雑さに起因する読みづらさを指摘し，
書き換え候補を生成する研究が行われ，応用段階に到達している
\cite{yokobayashi}\cite{suganuma2006}
．
以上の「表記レベル」と「統語レベル」の課題に対しては，
文を言語解析し，その際の解析困難性の程度を誤りや読みづらさの指標にすると
いう手法が広く用いられている．
この手法が使われる理由は，表記レベルと統語レベルに対応した言語解析である
形態素解析および係り受け解析の現状の解析精度が十分に高いためであると考え
られる．
それに対し，次の「意味レベル1」では欠落した格要素の推定や照応詞の照応先
の特定の困難さを算出する必要がある．しかしながら，
それに対応した格解析や照応解析といった意味解析技術の精度が現状では不十分なため，
解析困難の理由が，解析技術の精度不足に起因するのか，
原文側の問題に起因するのか区別がつかず，指摘の要否判定ができない．
さらに，「意味レベル2」に含まれる情報不足や情報過多の指摘に関しては，
対応する言語解析技術も定まっておらず，今後の技術と考えられている．
このように，「意味レベル1，2」やその先の「文脈・構成レベル」の検出・支援の技術は
研究が進展していないのが現状である．

本論文は，「意味レベル2」に含まれる情報不足と情報過多の指摘のうち
情報不足の指摘を扱う．以下，文章作成の理論の中で，この課題の位
置付けを考える．

言語表現とそれを用いる使用者や文脈との関係を研究する分野である語用論
\cite{Green}と会話における意志疎通の原理を扱ったGriceの理論\cite{Grice}
がある．これはコミュニケーションが成り立つための原理と条件を
与える協調の原理についての内容であり，仕事文（仕事に用いる文を仕事文と称する
\footnote{本論文では，岩波新書「仕事文の書き方」\cite{高橋昭男}にならい，
仕事の場面で用いる文を仕事文と呼ぶ．これに近い概念の「論説文」は，
仕事目的以外の，例えば教育用の論説文もあるため，
仕事文と完全には一致しない．}．）が満たすべき条件を与える基礎理論である．
協調の原理に従うために，いくつかの特定の条件（格率という）に従わなければならない．
格率は量，質，関係，様態の4カテゴリにまとめられる．そのうちの
量に関して，次の2つの格率に従う必要がある．
\begin{enumerate}
 \item 要求に見合うだけの情報を与える発言を行う．
 \item 要求されている以上の情報を与えるような発言を行ってはならない．
\end{enumerate}
(1)の格率を満たさなければ，情報不足の問題が生じ，
(2)の格率を満たさなければ，情報過多の問題を生じる．
このうち，本論文で扱う課題は，量に関する１つ目の格率を満たさないために生じる
情報不足の課題である．

文章講座に関する一般書籍にも情報不足に関する解説が見られる．
例えば書籍「仕事文の書き方」\cite{高橋昭男}では，
仕事文において正確な文章を書くために，
情報不足に注意することを述べている．
この書籍では情報不足による論理の飛躍の例として，
次に示す入学用ランドセルの広告文を取り上げている．

    \vspace{10.5pt}\begin{center}
    \fbox{\parbox{38zw}{
 ここ数年，児童の数が急激に減っています．そのため，品不足になる恐れがあ
 りますので，お早めにお求めください．}}
    \end{center}\vspace{10.5pt}

\noindent
第1文と第2文の間に論理の飛躍があって読みづらいため，間に言葉を補い，
次のように修正すべきと述べている．
    \vspace{10.5pt}\begin{center}
    \fbox{\parbox{38zw}{
 ここ数年，児童の数が急激に減っており，{\bf それに対応して，メーカーでは，
 製造数を大幅に減らしています．このような事情から，人気商品については，}
 品不足になる恐れがありますので，お早めにお求めください．（文字強調筆者）}}\\
    \end{center}\vspace{10.5pt}

量の格率の2条件を満足しないために生じる情報不足と情報過多の問題の中で，
本研究では情報不足の問題のみを扱い，情報過多の問題は扱わない．
その理由について述べる．
本研究では，ビジネス分野の文章作成支援を目指して，仕事文を対象とする．
そのため，情報不足の場合には，文が難解になることに加え，
論理の飛躍によって誤解を生じさせると言う深刻な事態を招くのに対し，
情報過多の場合には，冗長な情報を無視するのに読解の負担が
かかるものの，誤解を生じる可能性は低いため，深刻さの程度は低い．
したがって，コンピュータによる文章推敲支援の課題として，
情報不足の検出と指摘の課題を扱うことが有用であると考える．
本研究では，この課題を情報不足が読者に受容されるかどうかを判定する問題として扱い，
コーパスベースの統計的言語処理に基づくアプローチを用いた手法を開発する．



\section{全体概要}

詳細説明に入る前に，本章では，実験に用いる文を準備する段階から，
機械学習アルゴリズムを用いた自動判定に至る流れ
の概略を説明する（図\ref{fig:全体概要}）．

\begin{figure}[b]
    \includegraphics[width=\textwidth]{14-4ia3f1.eps}
  \caption{全体概要}
  \label{fig:全体概要}
\end{figure}

原文として，新聞記事を基にして作られた京大コーパス
\footnote{http://nlp.kuee.kyoto-u.ac.jp/nl-resource/corpus.html} 
を用いる．
京大コーパスは，文に，形態素情報と係り受け情報が付与されているので，
係り受け構造を利用して連体修飾節あるいは連体修飾句の場所を認定する．
その部分を欠落させた文を作成し，被験者判定用の文とする．
この文を被験者に提示して，欠落箇所に情報不足を感じるかどうか判定してもらう．
被験者数は4名である．判定対象とする文の数は約1,800文である．
全員が各々これら約1,800文を判定する．
通常，被験者毎の判定結果は異なる．そのため，OK判定（情報不足なし）とNG判定
（情報不足あり）の比率は1対1にならない．
本研究は，機械判定の要素技術を確立する段階の研究であるため，
手法の性能を評価する際の容易さから，次のように，OKとNG判定が1対1に
なるようなデータセットを作成する．
すなわち，評価データから，各被験者毎に，
OK判定とNG判定の比率が同じになるように文を抜き取り，データセットを作成す
る．そのように作成された被験者毎のデータセットは，判定の正解値に関するベースライン
が50{\kern0pt}％である．
次の段階は，機械判定に用いる素性値の算出である．
素性は全部で11素性である．その中の１つは，例えば，
各文の情報不足評価位置での文の滑らかさ等に関する素性情報である．
それらの素性値を使って，10-fold cross validation法に基づく
学習と判定を行う．
機械学習アルゴリズムを用いた自動判定の手法として
SVM (Support Vector Machines)を用いる．
なお，4名の被験者による判定を各々の正解値としたため，
正解率も4通りが得られる．
一方，被験者の判定の一致率によって手法の精度の上限を推定し，
それを基に正解率を評価する．


\section{課題文と正解データの作成}


\subsection{課題文の作成手順}
\label{課題文の作成手順}

本研究では毎日新聞の記事に形態素・構文情報などの各種言語情報
を人手で付与したテキストコーパスである京大コーパス
を用いて課題文の作成を行った．
京大コーパスを利用するのは次の理由による．
\begin{itemize}
 \item
      自動的に付与した形態素，構文解析に関して人手修正を行ってい
      るため，解析誤りが少ない．
 \item      
      京大コーパスの素材となった毎日新聞記事は新聞記事であり，
      本研究が対象とする仕事文に相当する．また，
      文の品質が高く，機械処理向きの優れた素材である．
\end{itemize}

次に，京大コーパスから機械処理で課題文を作成する方法について説明する．
本研究では原文のある部分を削除する加工を行って情報不足を生じさせた文を生
成する\footnote{場合によっては，曖昧な部分が削除されることによって，文が
明確になる可能性もある．しかし，文意には立ち入らず機械処理によって文を生
成する．}． 
削除する部分の選定基準を以下のように設定する．
\begin{description}
 \item [連続した文字列]
	     削除する部分は文中で連続した文字列部分である．
 \item [1文につき1箇所]
	     削除する部分の数は1文につき最大1箇所に限定する．
	     この条件を満たさない文は採用しない．
	     削除する部分の候補が1文につき複数存在する場合，文頭に近い方
	     1箇所を採用する．
	     理由は，１文中に複数箇所ある場合に，
	     後続の評価が，前の評価結果に影響される可能性を否定できない
	     ため，その影響を避けるためである．
 \item [連体修飾部]
	     削除対象を連体修飾部（本論文では連体修飾句と連体修飾節を合わ
	     せて連体修飾部と称する）に限定する．
	     連用修飾を扱わない理由について述べる．
	     連体修飾と連用修飾では機械判定に使う素性が少し異なる．
	     そのため，判定の正解率を高めるには，
	     素性のセットを入れ換えて個々に処理することになる．
	     しかし，解析の流れが煩雑になるだけで，
	     判定手法の基本的な枠組は同一であるため，
	     今回の研究では連体修飾部に限定して検討する．
	     機械処理で連体修飾部を求め
	     るには，係り受け解析結果から認定する（図\ref{fig:連体修飾部}
	     参照）．同図(b)は連体修飾部が再帰的な修飾状態（以下，再帰修飾と呼ぶ）
	     になっている例を示す．
	     再帰修飾の場合は，最も外側の修飾部を採用する．
 \item [係り先の品詞制限]
	     連体修飾の係り先である名詞の種類を一般名詞に限定する．
	     その理由を述べる．名詞は一般名詞，固有名詞，形式名詞，
	     その他（数詞，時相名詞，副詞的名詞）に分かれる．
	     情報不足判定のアルゴリズムを構築するにあたって，
	     これらの種類によってアルゴリズムが異なる．
	     このうち，出現頻度は一般名詞が非常に多く
	     \footnote{京大コーパスの600記事中に，名詞が54,061個含ま
	     れ，そのうちの70{\kern0pt}％が一般名詞，14{\kern0pt}％が固有名詞，2％が形式名詞，
	     その他（数詞，時相名詞，副詞的名詞）が4％である．}，
	     実用上の観点からも一般名詞を扱うのが有利である．
	     次に判定処理を考えると，固有名詞では，
	     初めに出現した固有名詞には説明が必要で，
	     次回以降は不要であるといった判定法が有効であると予想される．
	     また，形式名詞は指示照応の問題が深く関係し，先行文脈に
	     関する文脈処理の判定問題となる．
	     後述する通り，本研究では文脈の要素を除外して
	     1文内で完結した主観評価と機械判定を行うため，固有名詞と
	     形式名詞を扱うと，この基準を超えることになる．
	     以上の理由から一般名詞に限定する．
 \item[直前文節が存在]
	     連体修飾部を削除したとき，その位置の前に文節が存在するとい
	     う条件を課す．
	     このようにした理由は，本研究で扱う素性が文節間のつながりに
	     関する情報を利用するためである．
\end{description}

\begin{figure}[b]
  \begin{center}
    \includegraphics{14-4ia3f2.eps}
  \end{center}
  \caption{連体修飾部の認定}
  \label{fig:連体修飾部}
\end{figure}

以上の処理により，京大コーパスの初めの600記事から，
１文に1箇所の評価箇所を含む課題文を作成した結果1,792文が得られた．
評価は１文毎の評価で行う．被験者への文の提示と評価も1文単位で行い，
機械判定も1文内の情報を基に行う．
主観評価において，文脈上の影響を除外するために，
文の提示順をランダムにした．


\subsection{主観評価}

機械学習アルゴリズムに基づく自動判定に用いる正解値を与えるた
めに，被験者による主観評価を行う．成人男性4名によって評価を行った．
評価にあたって，被験者に与えた教示は次の通りである．
\begin{quote}
 新聞記事（毎日新聞1995年版）の文を素材として，加工を加えた文を読んでもらい
 主観評価して頂きます．
 1文ずつ文が表示され，評価してもらいますが，文毎に独立しており，文脈は
 ありません．
 1文につき1箇所の評価箇所があり，「★」印がついています．
 この部分に，原文ではなんらかの文字が挿入されていましたが，
 それを欠落させています．
 この文を読み，ここに何か言葉を補った方が良いか，その必要はないかを評価して
 いただきます．
 なお，文字を欠落させるにあたり，言語解析を行うことにより，文法的な誤りは
 生じないようになっています．従いまして，ここに何か言葉を補わないと
 文を理解する上で読み辛いかどうかの観点で評価して下さい．
\end{quote}
被験者に，初めの10問は練習用と断って評価してもらい，
以降のデータ処理で使用していない．
評価の際に，評価時間に制限は設けていない．総計1,792文を評価するのにおお
よそ10数時間を要するため，被験者の判断で，数日に分けて評価した．


\subsection{被験者間での主観評価の一致率} 
\label{label:主観評価の一致率}


被験者間での主観評価の一致率を計算する．
一致率を次のように定義する．
\begin{equation}
 一致率 = 一致した数 / 全評価数
\end{equation}
ただし，計算は文単位で行う．
4名の被験者から2名を選んだ6通りの組に対しての一致率は，表
\ref{table:一致率}に示す通りである．全て，ほぼ，80{\kern0pt}％の一致率が得られた．
また，主観評価の一致の程度を$\kappa$係数
\cite{kappa}\cite{kappa2}で検証した．
$\kappa$係数について簡単に説明する．
2名の被験者がカテゴリ判定した
データのクロス集計結果を表\ref{table:行列定義}とするとき，
$\kappa$係数は，$\kappa=(P_o - P_e)/(1 - P_e)$で定義される．
ここで，$P_o$は実際の一致割合（被験者A，BともにNGあるいは，ともにOK）であ
り，
$P_o=(a + d)/N$である．
$P_e$は被験者AとBの間に関連がない場合の各セルの期待値を足して全数で割っ
た値であり，
$P_e = (n_1 m_1 / N + n_2 m_2 / N)/N$である．
$\kappa$係数の値により，一致の度合は表\ref{table:カッパ係数}のように評価される．
今回の実験において，6通り全ての組に関し，表\ref{table:一致率κ}に
示すように，``moderate''な一致の範囲であった．

\begin{table}[t]
\input{table1-2.txt}
\end{table}

\begin{table}[t]
\input{table3-4.txt}
\end{table}

\section{機械判定で用いる素性の定義}
\label{label:機械判定用の素性定義}

文の受容性に関する機械判定を行うための識別器としてSVMを用いる．
SVMは最大マージン原理を利用した2クラスの分類問題を解くための
識別器であり，SVMは言語処理分野の他にも様々な分野に利用されている
\cite{SVMapplication}．
SVMの一般的な教科書としては
\cite{Cristianini}\cite{Vapnik}
がある．
また，高い性能を持つSVMの性能に関係する汎化誤差の議論については，例えば
「パターン認識と学習の統計学」6.4節\cite{Aso}等を参照されたい．

素性として，以下で定義する11個の素性を用いる．11個のうちの3個は
語彙表記と語の意味クラスに関する素性である．
その他の8個は，大規模な生コーパスから計算した言語統計量を用いて計算した
素性である．以上の枠組を模式図の形式で図\ref{fig:機械判定の枠組}に示す．

\begin{figure}[t]
  \begin{center}
    \includegraphics{14-4ia3f3.eps}
  \end{center}
  \caption{機械学習アルゴリズムに基づく自動判定の枠組を示す模式図}
  \label{fig:機械判定の枠組}
\end{figure}


\subsection{語彙素性}

はじめに，語彙に関する3つの素性について図\ref{fig:素性1}を参照しながら説
明する．

\begin{figure}[t]
  \begin{center}
    \includegraphics{14-4ia3f4.eps}
  \end{center}
  \caption{語彙素性の説明図}
  \label{fig:素性1}
 \end{figure}

 \begin{description}
  \item [評価文節先頭形態素の表記]
	      本論文では図\ref{fig:素性1}に示すように，文中に存在する複数の文節の
	      うち，評価位置の直後に来る文節を「評価文節」と呼ぶ．
	      評価文節に含まれる複数の形態素のうち，先頭に位置する形態素の
	      表記が本素性である．
  \item [評価文節先頭形態素の意味クラス]
	      「評価文節先頭形態素の表記」と同じ形態素に対して，
	      日本語語彙大系\cite{語彙大系}の意味クラスをツリー構造を持
	      たない単なるカテゴリとみなして素性に割り当てたものである．
	      複数の意味クラスを持つ場合，第1語義に対する意味クラスを用
	      いる．
  \item [直前文節末形態素の表記]
	      本論文では図\ref{fig:素性1}の中で示すように，文を構成する
	      複数の文節のうち，評価位置の直前に来る文節を「直前文節」と呼
	      ぶ．本素性は，直前文節に含まれる複数の形態素のうち，最後の形
	      態素の表記である．
 \end{description}


\subsection{語彙素性以外の素性}

以下に示す8個の素性は，大規模な生コーパスから計算した統計量を用いて計算
した素性である．大規模な生コーパスとして，2000年の毎日新聞記事を収めた
「CD-毎日新聞2000\cite{mainichi}」1年分を用いる．
形態素の分割には標準的な形態素解析ソフトであり，また，京大コーパスとの親和性が
よいためJUMANを用いる．

\subsubsection{$n$-gramに基づく素性}

$n$-gramに基づく素性として次の5つを用いる（図\ref{fig:素性2}参照）．
この中の「評価文節の確率」以外は，欠落箇所におけるつながりの滑らかさに
関する特性を表現している．

\begin{figure}[b]
    \includegraphics[width=\textwidth]{14-4ia3f5.eps}
  \caption{$n$-gramに基づく素性の説明図}
  \label{fig:素性2}
\end{figure}

 \begin{description}
  \item [トライグラムの同時確率]
	      直前文節の最後の2つの形態素表記と評価文節先頭形態素表記の同時確
	      率の底を10とする対数（以下，同様）である．
  \item [トライグラムの条件付確率]
	      直前文節の最後の2つの形態素表記が出現したという条件の下で，
	      評価文節先頭形態素表記の出現する条件付き確率の対数である．
  \item [スキップバイグラム]
	      評価文節先頭形態素とそこから2形態素前の形態素の
	      出現する同時確率の対数である．
	      通常，評価文節先頭形態素の直前形態素に助詞が来る確率が高い．
	      そのため，評価文節先頭形態素と意味的な共起関係を表現する
	      特徴量になりにくい．
	      そこで，評価文節先頭形態素の直前の形態素の代わりに，2形態素
	      前の形態素を扱う．
  \item [評価文節の確率]
	      評価文節を構成する形態素列の出現確率（形態素の同時確率
	      の対数）である．
	      ただし，形態素数の上限を3形態素（トライグラム）までとする．
  \item [逆方向バイグラム] 
	      評価文節先頭形態素表記が出現したという条件の下で直前文節の最後の
	      形態素表記の出現する条件付き確率の対数である．
 \end{description}


\subsubsection{Noisy Channel Modelに基づく素性} 

誤字の修正の問題にNoisy Channel Model に基づく手法が用いられている
\cite{Kerninghan}．
本素性はNoisy Channel Modelの考え方にヒントを得たものである
（図\ref{fig:noisy}参照）．
図\ref{fig:素性3}(a)に示すように，形態素の並び$\ldots, W_{-2}, x, W_0, \ldots$
を観測したとする．
ここで，$x$はどんな形態素でも良い．
$W_0$が与えられたという条件の下で，2つ前の形態素が$W_{-2}$である条件付き確率を
$p(W_{-2} \vert W_0)$ で表す．
全ての語$\tilde W$に対して$\ldots, \tilde W, x, W_0, \ldots$ となる確率を
$p(\tilde W \vert W_0)$で表す．
次に，$p(\tilde W \vert W_0)$が降順になるように$\tilde W$の並び順を定める．
このときの並び順を
${\tilde W}^{(1)}, {\tilde W}^{(2)}, \ldots, {\tilde W}^{(n)}$
とする．
すると，$W_{-2}$は$\tilde W^{(1)}, \ldots, \tilde W^{(n)}$のいづれかに位置する．
次に，$p(\tilde W \vert W_0)$から累積分布$P(\tilde W \vert W_0)$を次式で計算する．
\begin{equation}
 P(\tilde W \vert W_0)=\sum_{W=\tilde W^{(1)}}^{\tilde W} p(W \vert W_0)
\end{equation}
累積分布の説明図を同図(a)中の右図に示す．この中で$W_{-2}$に対応する
累積確率$P(W_{-2} \vert W_0)$が本素性（Noisy Channel Modelに基づく素性）である．

\begin{figure}[b]
\begin{center}
    \includegraphics{14-4ia3f6.eps}
  \end{center}
  \caption{Noisy Channel Modelに基づく素性}
  \label{fig:noisy}
\end{figure}

\begin{figure}[t]
\begin{center}
    \includegraphics{14-4ia3f7.eps}
  \end{center}
  \caption{Noisy Channel Modelに基づく素性計算}
  \label{fig:素性3}
\end{figure}

以下，本指標の性質について図と例を用いて説明する．
同図(b)のイラストに示す．
例として，$W_0$が「今日」で$W_{-2}$が「日」と「直径」の2つについて
説明する．各々の文脈は「… 日 ○ 今日 …」と「… 直径 ○ 今日 …」で
ある．ここで，「○」はこの位置を何か1文節が占めていることを示している．
$W_0$が定まると，それに従って累積分布$P(\tilde W \vert W_0)$のカーブも
固定される．
上記の例の場合，$W_0 = 「今日」$に対して，共起しやすい語である
$W_{-2} = 「日」$ は$x$軸で左端（上位14位）に位置し，
共起しにくい語である$W_{-2} = 「直径」$ は$x$軸の右端（上位362位）に位置する．
累積分布のカーブであるため，$W_{-2}$が$x$軸上の上位（左側）に位置すると，
指標は小さな値になる．
ここの例で「… 日 ○ 今日 …」という自然な文脈に対応する．
一方，$W_{-2}$が$x$軸上の下位（右側）に位置すると，指標は大きな値になる．
ここの例で「… 直径 ○ 今日 …」という不自然な文脈に対応する．



\subsubsection{エントロピーに基づく素性} 

ここで扱うエントロピーでも，他の素性同様，
欠落評価位置を挟んだ前後の連結性を扱う．
具体的には，連続した2形態素についての条件付き確率に基づくエントロピーと
して，文頭から文末に向かう順方向エントロピーと文末から文頭に向かう逆方向
エントロピーの2つを扱う（図\ref{fig:素性4}参照）．

\begin{figure}[t]
    \includegraphics[width=\textwidth]{14-4ia3f8.eps}
  \caption{エントロピーに基づく素性の説明図}
  \label{fig:素性4}
\end{figure}

 \begin{description}
  \item [順方向エントロピー]
	      直前文節の最後の形態素$W_{-1}$が与えられたという条件
	      の下で，
	      評価文節先頭形態素$W_0$の出現確率に基づくエントロピー
	      （ただし，対数の底は10）である．
	      \[
	       H_f = - \sum_{W_0 \in \Omega(W_{-1})}p(W_0 \vert
	      W_{-1})\log_{10}p(W_0 \vert W_{-1})
	      \]
	      ただし，\\
	      $\Omega(W)$： 形態素$W$の直後に出現する形態素の集合
  \item [逆方向エントロピー]
	      評価文節の先頭の形態素$W_0$が与えられたという条件の下で，
	      直前文節の最後の形態素$W_{-1}$が出現する確率に基づくエントロピー
	      （ただし，対数の底は10）である．
	      \[
	       H_b = - \sum_{W_{-1} \in \Omega'(W_{0})}p(W_{-1} \vert
	      W_{0})\log_{10}p(W_{-1} \vert W_{0})
	      \]
	      ただし，\\
	      $\Omega'(W)$： 形態素$W$の直前に出現する形態素の集合
 \end{description}

\begin{table}[b]
\input{table5.txt}
\end{table}

いくつかの語でエントロピーを計算した例を表\ref{table:entropy}に示す．
特定の文脈で使われる語はエントロピーが小さく，いろいろな文脈で使われる語
はエントロピーが大きい．
例えば，「記事」は「関連記事」，「この記事」という文脈で使われることが
多いためエントロピーが小さいのに対し\footnote{本論文においてエントロピーの計算に使われるバイグラム，すなわち2形態素の
つながりにおける条件付き確率の計算では，2000年１年分の毎日新聞記事データ
を使っているため，新聞記事特有の文脈の影響を受けている．} ，「ニュース」では
そのような文脈上のつながりがなく，エントロピーが少し大きくなる．
「電池」は，「太陽電池」，「燃料電池」という文脈が非常に多いため，
ここで示した6語の中で最小の値となっている．一方，「教育」，「文化」は
いろいろな文脈で使われるため，エントロピーが大きい．「首相」は
村上首相（人名＋首相）のような特定の文脈で使われる場合と，そうでない場合が
半々程度出現し，エントロピーは中程度の大きさになる．

本節で導入するエントロピー指標は，文脈による次の語（順方向エントロピーの
場合には次の語で，逆方向エントロピーの場合には前の語）の予測が
容易か困難かの指標であり，連体修飾部の欠落の受容性と次の関係を持つ．
 \begin{description}
  \item [予測が容易]
	      説明がなくても分かる（連体修飾部不要）．エントロピー小．
  \item [予測が困難]
	      十分に説明してほしい（連体修飾部が必要）．エントロピー大．
 \end{description}



\section{機械判定の正解率測定結果}

機械判定を行うにあたり，データセットに含まれる「補う必要なし」（以下，正
例と表記する）と「補う必要あり」（以下，負例と表記
する）の数が等しくなるように
サンプルの抜き取りを行って調整する．具体的には，
全被験者とも，負例が少なかったので，正例の中からランダムに，負例の数のサ
ンプルを抽出して，正例と負例のサンプル数が等しくなるようにデータセットを
調整する．そのようにして得られた被験者毎のサンプル数を
図\ref{fig:サンプル数}および表\ref{table:サンプル数}に示す．この操作により，サンプル数
800弱の被験者2名と，サンプル数1,100弱の被験者2名の2グループに分けた．
以下の機械判定では，調整後のデータセットを基に，学習と判定を行う．

\begin{table}[b]
\input{table6.txt}
\end{table}

\begin{figure}[b]
 \begin{center}
    \includegraphics{14-4ia3f9.eps}
 \end{center}
 \caption{機械判定用のデータセットのサンプル数}
 \label{fig:サンプル数}
\end{figure}

\begin{figure}[t]
\begin{minipage}{199pt}
  \begin{center}
    \includegraphics{14-4ia3f10.eps}
  \end{center}
  \caption{機械判定の学習曲線}
  \label{fig:学習曲線}
\end{minipage}
\hfill
\begin{minipage}{171pt}
\vspace{13pt}
 \begin{center}
    \includegraphics{14-4ia3f11.eps}
  \end{center}
  \caption{機械判定の正解率}
  \label{fig:正解率}
 \end{minipage}
\end{figure}
\begin{table}[t]
\input{table7.txt}
\end{table}

前章で述べた素性を用い，分類器として自然言語処理で広く使われる
SVMを使って判定を行った．
SVMのパラメータとして線形カーネルを用い，
ソフトマージンでコスト$C=1$を用いた\footnote{ソフトウェアパッケージとしてkernlab
\cite{kernlab}を用いた．}．
機械学習アルゴリズムを用いた自動判定の評価にあたり10-fold cross validation
を行った．
学習コーパスの量と正解値の関係，すなわち学習曲線を図\ref{fig:学習曲線}に示
す．課題の正解値は，4名の主観評価中の1名に関するデータを用いる．
前述のようにデータセット中の正例と負例の比率を等しくすることによって，
ベースラインを0.5に設定してある．ベースラインの値は，
正例と負例の2値判定をランダムに行った場合の正解率に相当する．
各被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横線
で示す\footnote{\ref{label:主観評価の一致率}で計算した一致率は全データ
に対するものであるが，ここの一致率はベースラインが50{\kern0pt}％になるようにデータ抽出
したデータセットに対する一致率であり，僅かに異なる．} ．
学習量に対する正解率のグラフを調べたところ，素性を語彙素性のみにすると，
学習サンプル数の増加に伴って正解率が増加しており，
ここで調べたサンプル数の範囲では，まだ飽和していない．
素性を統計量に関する素性のみにすると学習サンプル数に依存せず，
同じ値となり，語彙素性と統計量の双方を用いた
場合の正解率は，語彙素性のみの正解率および統計量のみの正解率を上回った（図\ref{fig:学習曲線}）．

次に，被験者毎の正解率を図\ref{fig:正解率}，表\ref{table:正解率}に示す．
図中に，ベースラインおよび
各主観被験者に対し，他の3名との一致率の相乗平均値を上限値の目安として横
線で示す．
被験者間での正解率に大きな違いはない．4名の正解率の平均値は
ベースライン0.5，上限0.76に対し，0.67であった．






\section{機械判定のパラメータ検討}

本論文では，機械学習アルゴリズムとして正解率の高さから定評のあるSVMを用
いた．しかし，SVMだけを対象としたのでは，達成される正解率の内訳が，
選択された素性に基づく性能によるのか
機械学習アルゴリズムの性能によるのか区別がつかない．
そこで，機械学習アルゴリズムの中で基本的な手法であるKNN法
(k-nearest neighbor method)を使用した場合の正解率を求めてSVMの正解率と比
較し，同じ素性でも，機械学習の違いによる性能向上分の程度を調べる\footnote{ソフトウェアパッケージとしてWeka
\cite{Weka}の中のIBkを用いた．}．
その結果，ベースライン0.5に対し，KNN法で0.65，SVMで0.67となった．
したがって，性能のうちの大部分は素性によって実現されたものと考えられる．
なお，KNN法はパラメータKを含むので，網羅的に調べるため，
Kを1.5の冪乗 (1, 2, 3, 5, 7, 11, ..., 437) で変化させて正解率の最大を求めた．

次に，SVMを使う場合の，素性選択による影響を調べるために，
素性を1つずつ削除した場合の正解率を調べる．それによって，
素性選択の改良による性能向上の余地がどの程度あるのかを調べる．
その結果，逆方向バイグラム素性を削減したときに最高値を示し，正解率0.69であった．
なお，正解率が最も低下したのは，順方向エントロピーを削除したときで，
正解率0.65であった（表\ref{table:素性削減}）．

\begin{table}[t]
\input{table8-9.txt}
\end{table}

最後に，本論文で導入した11素性を各々単一に用いた場合の正解率を調べる．
単体性能の最高を示す素性が「語の表記」で0.66 であり，
全体を使った性能が 0.67 である．
今回新規な素性としてNoisy Channel Modelに基づく素性を導入しているが，
単体での正解率は0.52 であり，全体中，中間的な性能であった
（表\ref{table:単一素性}）．
先の「素性を1つずつ削除」する実験でこの素性を削除した場合に，
正解率の低下は中程度であり，補助的な役割は果たしている．
主要な素性を補助するために導入した素性の場合，主要な素性無
しで，補助的な素性のみを使っても，本来，高い性能は得られない．
例えば，順方向エントロピーがこれに該当する．先の「素性を1つずつ削除した場合の正解
率」では，削除による正解率低下が最も大きく，重要であるが，
それに対して，単一で用いた場合，性能の低い順に2位である．

以上の結果，
素性選択の方法による正解率への影響を調べた結果，
本実験で用いる素性に対して，素性選択を調整すると正解率は多少向上する
が，その程度は大きくないことが判明した．



\section{考察}

機械判定の正解率として，ベースライン50{\kern0pt}％，
人間の評価のバラツキから定義した上限
\footnote{人間の評価のバラツキの観点から，各被験者に対し，他の3名との一致率の
相乗平均値で定義} 76{\kern0pt}％に対し，67{\kern0pt}％の正解率を得た．
上限に近い70{\kern0pt}％前半が正解率の最終目標になるであろうから，
今回の正解率67{\kern0pt}％は，それと比べ，ある程度近い値に達していると思われる．
なお，素性の削減実験で全素性から「逆方向バイグラム」の素性を削減
したときに，正解率の最高値69{\kern0pt}％を記録したが，今回のデータに限って偶然
高い値になった可能性もあり，また，素性選択の組合せは膨大で
正解率の最大値を網羅的に調べるのは困難なため，パラーメータ検討前の正解率を
本手法の正解率として代表させた．

以下では，実験に用いた素性について，語彙素性とそれ以外の素性の2種類
に分けて考察する．まず，語彙素性における
機械判定による正解率について図\ref{fig:学習曲線}の学習曲線を参照すると，
学習サンプル数が少ないときにベースライン手法とほぼ同一であり，
十分多いサンプル数を機械学習に与えた場合に全素性とほぼ同等の
正解率で判定できることが確認できた．
これは語彙素性として使用したものが主に形態素の表記であったため，
素性の異なり数が非常に多く，少ない学習サンプル数では
十分学習できなかったためと考える．
次に，語彙素性以外の素性について考察する．語彙素性以外の素性は8種類ある．
これらは主に，$n$-gramに基づく素性など，語のつながりの滑らかさを反映した
統計量であり，新聞記事１年分の生コーパスから求めたものである．
図\ref{fig:学習曲線}の学習サンプル数は，被験者判定による学習サンプル数で
あり，統計量を求める際の生コーパスの量とは異なる．
そのため，学習により，判定に用いられる素性に対する重み係数が調整されるものの，
学習サンプル数による効果は小さい．

本研究のように，被験者の主観評価に基づいて正解判定データを整備し，
機械学習ベースの判定処理を行うという研究スタイルの場合，
主観評価に関わる実験デザインの善し悪しが研究の成否に大きく影響する．
本研究では，被験者評価用の文を作成する際に，\ref{課題文の作成手順}で
述べたように，１文毎の評価に限定したり，1文内の連体修飾部を1箇所に
限定するなど，様々な条件設定を工夫して，被験者間の一致度が高くなるよう
配慮した．
結果的に，被験者間の一致率が約8割で$\kappa$係数がmoderateという十分高い
一致率となり機械判定処理に成功した．

近年研究の盛んなテキスト自動要約の研究では，
主観評価結果のバラツキの問題が大きいため，評価法に関して様々な研究が行わ
れ\cite{難波}，評価型ワークショップNTCIRのTSCにおいて，
評価法をいかにすべきかの議論がなされている\cite{NTCIR}．
本研究での被験者間の一致率を，従来研究における別のタスクの場合と比較してみる．
Maniらの要約の研究\cite{Mani99}では，4名の被験者で，
要約文（もしくは原文）がトピックスに適合する検索結果かどうかを判定してもら
う適合性判定（二者択一）を行い，被験者間の一致率を調べている．
その結果，2名1組での一致率は69{\kern0pt}％で，$\kappa=0.38$であった．
また，要約文もしくは原文が，5カテゴリまたはその他のどれに該当するかを
答える被験者実験の結果，2名1組での一致率は56{\kern0pt}％で$\kappa=0.29$であった．
平尾らの重要文抽出の研究\cite{平尾}では，要約率を30{\kern0pt}％に設定したときの
被験者間の重要文の一致に関し，2名1組の$\kappa=0.3$程度となっている．
なお，この研究では，231記事，4,013文からなる文書データに対し，6名の被験者で，
重要文の人手判定を行い，大規模な機械学習用の正解値データセットを作成している．
また，小林らの音声要約における重要文抽出の研究\cite{小林}では，
学会講演の音声に対する，人間による重要文抽出（要約率33{\kern0pt}％）の一致率を調べている．
2名の評価者間の$\kappa$係数について，10組の平均値は$\kappa=0.286$である．
重要文抽出に関しては，$\kappa=0.3$程度(Fair)である．
以上の要約に関連した様々なタスクでの被験者間の一致率と比較して，
本研究のタスクにおける被験者間の一致率は，$\kappa$が0.46〜0.56（全て
moderate）であり，一致率が高いと言える．

要約文の品質評価法に関して，外的評価という方法がある．例えば，
適合性判定のタスクを設定して，様々な品質の要約文で，タスクの達成時間を
計測し，達成時間を短縮できた要約文の品質が高いと判定する方法である．
この評価方法は競技型ワークショップSUMMACで用いられたが，評価
の実施が高価だったことに加えて，時間の制限から原文書を比較的短いものに
限定しており，評価の妥当性の疑問が問題点として挙げられている
\cite{自動要約}．
本研究では，被験者間のばらつきの少ない実験条件を整備することに留意し，
被験者間の一致率約8割で$\kappa$係数がmoderateになる高い一致率を得た．
その結果，機械判定の処理が成功した．



次に，今回の課題設定に関する特殊性を吟味する．
本研究で扱った連体修飾部の追加の要否判定（換言すると欠落に対する受容性判
定）の課題には，意味レベルと表層レベルとが混在している．
これらのレベルの構成比率についてはデータセット中にある
課題文を分析することで算出することが可能である．
同様に，それらの分析を行った上で，各レベルに属する課題文の中で
正解率が特に低いものに照準を合わせて，素性の選定を行うという対策も考える
ことが出来る．
しかし，
そのような個別対策に基づくアプローチは，コーパスベースの統計的言語処理と
機械学習による枠組に合致せず，
オープンテストによる正解率評価の公正性にも反する恐れもある．
以上の観点から個別対策は行っていない．

本研究の意義を一言で言えば，文章推敲支援の分野において，
これまであまり研究が進んでいなかった「意味レベル2」（\ref{はじめに}節で定義）
の課題を扱い，
広く行われている統計的言語処理のアプローチで機械判定を行い，
ある程度高い正解率を達成した点である．
成功のポイントは，意味処理の課題を扱うに際して，主観評価の安定性を向上させるよう，
実験デザインを工夫することによって，学習量の圧縮や，
機械判定の正解値評価の部分を容易にした点である．


\section{関連研究}

\begin{figure}[b]
    \includegraphics[width=\textwidth]{14-4ia3f12.eps}
  \caption{酒井らの連体修飾節省略可能性評価の課題との比較}
  \label{fig:酒井}
\end{figure}

酒井らはテキスト自動要約における文内要約の要素技術として動詞連体修飾節の省略
可能性に関する知識をコーパスから獲得する手法を提案している
\cite{sakai}\cite{sakai2}．
この研究は，本研究とも関連が深いので，両者の枠組の違いを図\ref{fig:酒井}
に図示する．
両者の似ている点は，文中のある部分の削除に対して，
その受容性に関する評価指標を構築することが中心課題である点である．
そのため，$n$-gram素性やエントロピー素性など，語の統計量に基づく素性を
構築する上で，酒井らの手法を参考にした．

一方，最も異なる点は，省略可能性評価の場合に，省略のない完全な文と
省略のある文を生成できるのに対し，
本研究の場合には，与えられた文は，全て連体修飾部を欠落させた文であり，
原文は与えられず，復元出来ない点である．
そのため，省略可能性評価の場合，完全な文と省略のある文を対比して指標を
構築するというアプローチを取ることが出来るのに対し，
本研究の場合，欠落のある文のみから評価指標を構築しなければならないという
難しさがある．



\section{まとめ}

文章校正，推敲の支援に関する従来研究では，主に，タイプミス，構文構造の複
雑さ，表記の揺れを指摘する手法など，表記レベルと統語レベルの手法に重点が
おかれていた．
一方，人間による文章の推敲の作業では，
読みやすさを向上させるために，説明が不足していて論理展開が読み取りにくい
と感じられる箇所を指摘する場面が多く見られ，コンピュータ支援に対する
ニーズは高い．
しかし，これまで，このような課題は，意味処理レベルの困難な課題と考えられ，
機械判定の対象として十分に研究されていなかった．
本研究では，原文から連体修飾部を欠落させた文を生成し，
被験者がその箇所に何か言葉を補った方が良いか，その必要はな
いかを評価してもらい，そのようにして作成した正解判定データを使って機械判定する．
この課題設定に関して，人間の判定結果の一致率を調べた．その結果，
4名の評定者による各1,792箇所の判定に関し，４名中2名ずつ，6通りの組合せについて，
いずれもほぼ８割の高い一致率を示した．
機械判定の主な素性として，語彙素性に関する素性3種，コーパスからの統計
量に関する素性8種を用い，機械学習アルゴリズムに基づく自動判定の
手法として，SVMを用いた．
その際，ベースラインを50{\kern0pt}％にすべく，正例数と負例数が等しくなるように
サンプルの抽出を行い，928サンプル（4名の被験者の平均値）からなるデータセットを作成した．
機械判定の正解率として，ベースライン50{\kern0pt}％，
上限（人間の評価のバラツキから上限を定義）76{\kern0pt}％に対し，67{\kern0pt}％の正解率を得た．

今回の実験上の制約の中で，1文毎で評価している点が最も大きな制約であろう．
この制約を外し，文脈を含めて検討することが今後の課題である．
その際，照応技術の進展に合わせて研究開発することが鍵となろう．
また同様に，今回用いなかった技術として，格解析の技術がある．
格要素の有無に関する情報は，情報不足の推定に有力な情報を与えることが
期待できるため，格解析技術の進展に合わせて利用を検討すべきである．









\acknowledgment

  本研究の一部は，文部科学省科学研究費特定領域研究(B)(2)16092213，および，
  21世紀COEプログラム「インテリジェントヒューマンセンシング」
  （豊橋技術科学大学）の援助により行われた．
  京大コーパス利用に関し，京都大学黒橋研究室と毎日新聞社に感謝い
  たします．日本語語彙大系使用に関して日本電信電話株式会社に感謝い
  たします．
  また，研究遂行に御協力いただきました豊橋技術科学大学増山研究室の
  助教酒井浩之氏，修士課程山本悠二氏他の方々，および実験被験者に感謝
  いたします．貴重な御指摘をいただきました査読者に感謝いたします．




\bibliographystyle{jnlpbbl_1.3}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{麻生\JBA 津田\JBA 村田}{麻生\Jetal }{2003}]{Aso}
麻生英樹\JBA 津田宏治\JBA 村田昇 \BBOP 2003\BBCP.
\newblock \Jem{パターン認識と学習の統計学}, 6.3 \JCH, \mbox{\BPGS\ 77--80}.
\newblock 統計科学のフロンティア6. 岩波書店.

\bibitem[\protect\BCAY{Carletta, Isard, Isard, Kowtko, Doherty-Sneddon, \BBA\
  Anderson}{Carletta et~al.}{1997}]{kappa2}
Carletta, J., Isard, A., Isard, S., Kowtko, J.~C., Doherty-Sneddon, G., \BBA\
  Anderson, A.~H. \BBOP 1997\BBCP.
\newblock \BBOQ The Reliability of a Dialogue Structure Coding Scheme\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 23}  (1), \mbox{\BPGS\
  13--31}.

\bibitem[\protect\BCAY{Cristianini \BBA\ Shawe-Taylor}{Cristianini \BBA\
  Shawe-Taylor}{2000}]{Cristianini}
Cristianini, N.\BBACOMMA\ \BBA\ Shawe-Taylor, J. \BBOP 2000\BBCP.
\newblock {\Bem An Introduction to Support Vector Machines and other
  kernel-based learning methods}.
\newblock Cambridge University Press.
\newblock (大北剛訳 \BBOP2005\BBCP. \Jem{サポートベクターマシン入門}.
  共立出版.).

\bibitem[\protect\BCAY{Green}{Green}{1989}]{Green}
Green, G.~M. \BBOP 1989\BBCP.
\newblock {\Bem Pragmatics and Natural Language Understanding}.
\newblock Lawrence Erlbaum Associates.
\newblock (深田淳訳 \BBOP1990\BBCP. \Jem{プラグマティックスとは何か}.
  産業図書.).

\bibitem[\protect\BCAY{Grice}{Grice}{1989}]{Grice}
Grice, P. \BBOP 1989\BBCP.
\newblock {\Bem Studies in the Way of Words}.
\newblock Harvard University Press.
\newblock (清塚邦彦, 飯田隆訳 \BBOP1998\BBCP. \Jem{論理と会話}. 勁草書房.).

\bibitem[\protect\BCAY{平尾\JBA 賀沢\JBA 磯崎\JBA 前田\JBA 松本}{平尾\Jetal
  }{2003}]{平尾}
平尾努\JBA 賀沢秀人\JBA 磯崎秀樹\JBA 前田英作\JBA 松本裕治 \BBOP 2003\BBCP.
\newblock \JBOQ 機械学習による複数文書からの重要文抽出\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 10}  (1), \mbox{\BPGS\ 81--108}.

\bibitem[\protect\BCAY{伊吹}{伊吹}{1998}]{ibuki}
伊吹潤 \BBOP 1998\BBCP.
\newblock \JBOQ
  同音異義語誤りの校正における各種の共起制約データの有効性の評価\JBCQ\
\newblock \Jem{言語処理学会第4回年次大会発表論文集}, \mbox{\BPGS\ 626--629}.

\bibitem[\protect\BCAY{池原\JBA 宮崎\JBA 白井\JBA 横尾\JBA 中岩\JBA 小倉\JBA
  大山\JBA 林}{池原\Jetal }{1997}]{語彙大系}
池原悟\JBA 宮崎正弘\JBA 白井諭\JBA 横尾昭男\JBA 中岩浩巳\JBA 小倉健太郎\JBA
  大山芳史\JBA 林良彦 \BBOP 1997\BBCP.
\newblock \Jem{日本語語彙大系}.
\newblock 岩波書店.

\bibitem[\protect\BCAY{Karatzoglou, Smola, Hornik, \BBA\ Zeileis}{Karatzoglou
  et~al.}{2004}]{kernlab}
Karatzoglou, A., Smola, A., Hornik, K., \BBA\ Zeileis, A. \BBOP 2004\BBCP.
\newblock \BBOQ kernlab---An S4 Package for Kernel Methods in R\BBCQ\
\newblock {\Bem Journal of Statistical Software}, {\Bbf 11}  (9), \mbox{\BPGS\
  1--20}.

\bibitem[\protect\BCAY{笠原\JBA 小林\JBA 荒井\JBA 絹川}{笠原\Jetal
  }{2001}]{kasahara}
笠原健成\JBA 小林栄一\JBA 荒井真人\JBA 絹川博之 \BBOP 2001\BBCP.
\newblock \JBOQ
  マニュアルの校閲作業における文書推敲支援ツールの実適用評価\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 42}  (5), \mbox{\BPGS\ 1242--1253}.

\bibitem[\protect\BCAY{Kernighan, Church, \BBA\ Gale}{Kernighan
  et~al.}{1990}]{Kerninghan}
Kernighan, M.~D., Church, K.~W., \BBA\ Gale, W.~A. \BBOP 1990\BBCP.
\newblock \BBOQ A spelling correction program based on a noisy channel
  model\BBCQ\
\newblock In {\Bem COLING-90}, \mbox{\BPGS\ 205--210}.

\bibitem[\protect\BCAY{小林\JBA 山口\JBA 中川}{小林\Jetal }{2005}]{小林}
小林聡\JBA 山口優\JBA 中川聖一 \BBOP 2005\BBCP.
\newblock \JBOQ 表層的言語表現と韻律情報を用いた講演音声の重要文抽出\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (6), \mbox{\BPGS\ 3--24}.

\bibitem[\protect\BCAY{Landis \BBA\ Koch}{Landis \BBA\ Koch}{1977}]{kappa}
Landis, J.~R.\BBACOMMA\ \BBA\ Koch, G.~G. \BBOP 1977\BBCP.
\newblock \BBOQ The measurement of observer agreement for categorical
  data\BBCQ\
\newblock {\Bem Biometrics}, {\Bbf 33}, \mbox{\BPGS\ 159--174}.

\bibitem[\protect\BCAY{毎日新聞社}{毎日新聞社}{2001}]{mainichi}
毎日新聞社 \BBOP 2001\BBCP.
\newblock \Jem{CD-毎日新聞2000}.
\newblock 日外アソシエーツ.

\bibitem[\protect\BCAY{Mani}{Mani}{2001}]{自動要約}
Mani, I. \BBOP 2001\BBCP.
\newblock {\Bem Automatic Summarization}.
\newblock John Benjamins Publishing Company.
\newblock (奥村学, 難波英嗣, 植田禎子\BBOP2003\BBCP. \Jem{自動要約}.
  共立出版.).

\bibitem[\protect\BCAY{Mani, House, Klein, Hirschman, Firmin, \BBA\
  Sundheim}{Mani et~al.}{1999}]{Mani99}
Mani, I., House, D., Klein, G., Hirschman, L., Firmin, T., \BBA\ Sundheim, B.
  \BBOP 1999\BBCP.
\newblock \BBOQ The TIPSTER SUMMAC Text Summarization Evaluation\BBCQ\
\newblock In {\Bem Proceedings of the ninth conference on European chapter of
  the Association for Computational Linguistics}, \mbox{\BPGS\ 77--85}.

\bibitem[\protect\BCAY{難波\JBA 奥村}{難波\JBA 奥村}{2002}]{難波}
難波英嗣\JBA 奥村学 \BBOP 2002\BBCP.
\newblock \JBOQ
  要約の内的(intrinsic)な評価法に関するいくつかの考察—第2回NTCIRワークショッ
プ自動要約タスク(TSC)を基に—\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 9}  (3), \mbox{\BPGS\ 129--146}.

\bibitem[\protect\BCAY{小野\JBA 菅沼\JBA 谷口}{小野\Jetal
  }{2006}]{suganuma2006}
小野貴博\JBA 菅沼明\JBA 谷口倫一郎 \BBOP 2006\BBCP.
\newblock \JBOQ 日本語文章推敲支援における係り受けを誤解される文の抽出\JBCQ\
\newblock \Jem{情報処理学会研究報告}, ``2006-NL-175''\JVOL, \mbox{\BPGS\
  99--104}.

\bibitem[\protect\BCAY{酒井\JBA 増山}{酒井\JBA 増山}{2004}]{sakai}
酒井浩之\JBA 増山繁 \BBOP 2004\BBCP.
\newblock \JBOQ 動詞連体修飾節の省略可能性に関するコーパスからの知識獲得\JBCQ\
\newblock \Jem{電子情報通信学会論文誌}, {\Bbf J87-D-II}  (8), \mbox{\BPGS\
  1641--1652}.

\bibitem[\protect\BCAY{Sakai \BBA\ Masuyama}{Sakai \BBA\
  Masuyama}{2006}]{sakai2}
Sakai, H.\BBACOMMA\ \BBA\ Masuyama, S. \BBOP 2006\BBCP.
\newblock \BBOQ Knowledge Acquisition about the Deletion Possibility of
  Adnominal Verb Phrases\BBCQ\
\newblock {\Bem SYSTEMS and COMPUTERS in JAPAN}, {\Bbf 37}  (2), \mbox{\BPGS\
  25--36}.

\bibitem[\protect\BCAY{高橋}{高橋}{1997}]{高橋昭男}
高橋昭男 \BBOP 1997\BBCP.
\newblock \Jem{仕事文の書き方}, 4 \JCH, \mbox{\BPGS\ 77--85}.
\newblock 岩波新書. 岩波書店.

\bibitem[\protect\BCAY{田中}{田中}{1999}]{tanaka}
田中穂積\JED\ \BBOP 1999\BBCP.
\newblock \Jem{自然言語処理—基礎と応用}, 7 \JCH.
\newblock 電子情報通信学会.

\bibitem[\protect\BCAY{Vapnik}{Vapnik}{1998}]{Vapnik}
Vapnik, V.~N. \BBOP 1998\BBCP.
\newblock {\Bem Statistical Learning Theory}.
\newblock John Wiley \& Sons, Inc.

\bibitem[\protect\BCAY{Wang}{Wang}{2005}]{SVMapplication}
Wang, L. \BBOP 2005\BBCP.
\newblock {\Bem Support Vector Machines: Theory And Applications}.
\newblock Springer-Verlag.

\bibitem[\protect\BCAY{Witten \BBA\ Frank}{Witten \BBA\ Frank}{1999}]{Weka}
Witten, I.~H.\BBACOMMA\ \BBA\ Frank, E. \BBOP 1999\BBCP.
\newblock {\Bem Data Mining}.
\newblock Morgan Kaufmann Publishers.

\bibitem[\protect\BCAY{横林\JBA 菅沼\JBA 谷口}{横林\Jetal }{2004}]{yokobayashi}
横林博\JBA 菅沼明\JBA 谷口倫一郎 \BBOP 2004\BBCP.
\newblock \JBOQ
  係り受けの複雑さの指標に基づく文の書き換え候補の生成と推敲支援への応用\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 45}  (5), \mbox{\BPGS\ 1451--1459}.

\bibitem[\protect\BCAY{福島\JBA 奥村\JBA 難波}{福島\Jetal }{2002}]{NTCIR}
福島孝博\JBA 奥村学\JBA 難波英嗣 \BBOP 2002\BBCP.
\newblock \JBOQ Text Summarization
  Challenge—自動要約の評価型ワークショップ—\JBCQ\
\newblock \Jem{情報処理}, {\Bbf 43}  (12), \mbox{\BPGS\ 1295--1299}.

\end{thebibliography}



\begin{biography}
   \bioauthor{梅村　祥之}{
   1981年名古屋大学大学院修士課程工学研究科修了．同年，
   東京芝浦電気株式会社入社．1988年株式会社豊田中央研究所入社．
   現在に至る．同社走行安全研究センターに所属．
   主に，自動車に関わる人間特性の研究に従事．
   2003年豊橋技術科学大学博士後期課程社会人コース入学．
   ヒューマンインタフェース学会，情報処理学会，日本音響学会，言語処理学会，
   自動車技術会会員．
   }
   \bioauthor{増山　　繁}{
   1977年 京大・工・数理卒．1982年 同大学院博士後期課程単位取得退学．
   1983年 同了（工博）．1982年 日本学術振興会奨励研究員．1984年 
   京大・工・数理助手．1989年 豊橋技術科学大学知識情報工学系講師，
   1990年 同助教授，1997年 同教授，2005年 同大学インテリジェント
   センシングシステムリサーチセンター教授併任．アルゴリズム工学，特に，
   グラフ・ネットワークのアルゴリズム等，及び，自然言語処理，
   特に，テキスト自動要約等，情報アクセス支援への応用の研究に従事．
   }

\end{biography}


\biodate



\end{document}
