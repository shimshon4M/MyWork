    \documentclass[japanese]{jnlp_1.2d}

\usepackage[dvips]{graphicx}
\usepackage{url}
\usepackage{amsmath}

\makeatletter
\setlength{\fboxsep}{2pt}
\newlength{\NearBaselineskip}
\setlength{\NearBaselineskip}{17pt \@plus\z@ \@minus16\p@}
\makeatother

\Volume{14}
\Number{1}
\Month{Jan.}
\Year{2007}
\received{2006}{6}{21}
\revised{2006}{9}{9}
\accepted{2006}{10}{3}

\setcounter{page}{111}

\jtitle{機械学習を用いた日本語機能表現のチャンキング}
\jauthor{土屋　雅稔\affiref{tutimc} \and 注連　隆夫\affiref{pine} \and 高木　俊宏\affiref{pine} 
	\and 内元　清貴\affiref{nict} \and 松吉　　俊\affiref{pine} \and \\
	宇津呂武仁\affiref{tsukuba} \and 佐藤　理史\affiref{nuee} \and 中川　聖一\affiref{tutics}}
\jabstract{
  日本語には，複数の語がひとかたまりとなって，全体として1つの機能的な意
  味を持つ表現が多数存在する．このような表現は機能表現と呼ばれ，日本語文
  の構造を理解するために非常に重要である．
  本論文では，形態素を単位とするチャンク同定問題として機能表現検出タスク
  を定式化し，機械学習手法を適用することにより，機能表現の検出を実現する
  方法を提案する．
  Support Vector Machine (SVM)を用いたチャンカーYamChaを利用して，機能表
  現の検出器を実装し，実際のタグ付きデータを用いて性能評価を行った．機能
  表現を構成している形態素の数の情報，機能表現中における形態素の位置情報
  を素性として参照することにより，F値で約92という高精度の検出器を実現で
  きることを示す．}
\jkeywords{機能表現，チャンキング，機械学習}

\etitle{Chunking Japanese Compound Functional Expressions\\ by Machine Learning}
\eauthor{Masatoshi Tsuchiya\affiref{tutimc} \and Takao Shime\affiref{pine} \and 
	Toshihiro Takagi\affiref{pine} \and \\
	Kiyotaka Uchimoto\affiref{nict} \and Suguru Matsuyoshi\affiref{pine} \and 
	Takehito Utsuro\affiref{tsukuba} \and \\
	Satoshi Sato\affiref{nuee} \and Seiichi Nakagawa\affiref{tutics}} 
\eabstract{
  The Japanese language has many compound functional expressions which
  consist of more than one word including both content words and
  functional words.  They are very important for recognizing the
  syntactic structures of Japanese sentences and for understanding their
  semantic contents.
  We formalize detection of Japanese compound functional expressions as
  a chunking problem against a morpheme sequence, and propose to learn a
  detector of them using a machine learning method.
  The chunker YamCha based on Support Vector Machines (SVMs) is applied
  to this task.  Through experimental evaluation, we achieve the
  cross validation result of the F-measure as 92, when the number of
  morphemes constituting a compound functional expression, and the
  position of each morpheme within a functional expression are
  considered as features of SVM.
}
\ekeywords{Japanese Compound Fuctional Expression, Chunking, Machine Learning}

\headauthor{土屋，注連，高木，内元，松吉，宇津呂，佐藤，中川}
\headtitle{機械学習を用いた日本語機能表現のチャンキング}

\affilabel{tutimc}{豊橋技術科学大学情報メディア基盤センター}
  {Information and Media Center, Toyohashi University of Technology}
\affilabel{pine}{京都大学大学院情報学研究科}
  {Graduate School of Informatics, Kyoto University}
\affilabel{nict}{情報通信研究機構}
  {National Institute of Information and Communications Technology}
\affilabel{tsukuba}{筑波大学大学院システム情報工学研究科}
  {Graduate School of Systems and Information Engineering, University of Tsukuba}
\affilabel{nuee}{名古屋大学大学院工学研究科}
  {Graduate School of Engineering, Nagoya University}
\affilabel{tutics}{豊橋技術科学大学情報工学系}
  {Department of Information and Computer Sciences, Toyohashi University}


\newcommand{\uline}[1]{}

\newcounter{example}
\makeatletter
\newenvironment{example}{}{}
\makeatother
\newcommand{\strref}[1]{}
\newcommand{\tabref}[1]{}
\newcommand{\figref}[1]{}
\newcommand{\eqnref}[1]{}

\begin{document}
\maketitle





\section{はじめに}
\label{sec:intro}
{\bfseries 機能表現}とは，「にあたって」や「をめぐって」のように，2つ以
上の語から構成され，全体として1つの機能的な意味をもつ表現である．一方，
この機能表現に対して，それと同一表記をとり，内容的な意味をもつ表現が存在
することがある．
例えば，\strref{ex:niatatte-F}と\strref{ex:niatatte-C}には，「にあたって」
という表記の表現が共通して現れている．
\begin{example}
  \item 出発する\kern0pt\uline{にあたって}，荷物をチェックした\label{ex:niatatte-F}
  \item ボールは，壁\kern0pt\uline{にあたって}跳ね返った\label{ex:niatatte-C}
\end{example}
\strref{ex:niatatte-F}では，下線部はひとかたまりとなって，「機会が来たの
に当面して」という機能的な意味で用いられている．それに対して，
\strref{ex:niatatte-C}では，下線部に含まれている動詞「あたる」は，動詞
「あたる」本来の内容的な意味で用いられている．
このような表現においては，機能的な意味で用いられている場合と，内容的な意
    味で用いられている場合とを識別する必要がある\cite{日本語複合辞用例データベースの作成と分析}．
以下，文~(\ref{ex:niatatte-F}), (\ref{ex:niatatte-C})の下線
部のように，表記のみに基づいて判断すると，機能的に用いられている可能性が
ある部分を{\bf 機能表現候補}と呼ぶ．

機能表現の数については，いくつかの先行研究が存在する．
\cite{日本語表現文型}は，450種類の表現を，意味的に52種類に分類し，機能的
に7種類に分類している．
\cite{階層構造による日本語機能表現の分類}は，森田らが分類した表現の内，
格助詞，接続助詞および助動詞に相当する表現について，階層的かつ網羅的な整
理を行い，390種類の意味的・機能的に異なる表現が存在し，その異形は13690種
類に上ると報告している．
土屋らは，森田らが分類した表現の内，特に一般性が高いと判断される337種類
の表現について，新聞記事から機能表現候補を含む用例を無作為に収集し，人手
によって用法を判定したデータベースを作成している．このデータベースによる
と，機能表現候補が新聞記事（1年間）に50回以上出現し，かつ，機能的な意味で
用いられている場合と，それ以外の意味で用いられている場合の両方が適度な割
合で出現する表現は，52種類である．
本論文では，この52種類の表現を当面の検討対象として，機能表現の取り扱い状
況を検討する．

まず，既存の解析系について，この52種類の表現に対する取り扱い状況を調査し
たところ，52種類の表現全てに対して十分な取り扱いがされているわけではない
ことが分かった\footnote{詳しくは，\ref{subsec:既存の解析系}節を参照}．
52種類の表現の内，形態素解析器JUMAN~\cite{juman-5.1}と
構文解析器KNP\cite{knp-2.0}の組合わせによって，機能的な意味で用いられて
いる場合と内容的な意味で用いられている場合とが識別される可能性がある表現
は31種類である．
また，形態素解析器ChaSen~\cite{chasen-2.3.3}と
構文解析器CaboCha~\cite{cabocha}の組合わせを用いた場合には，識別される可
能性がある表現は26種類である．

このような現状を改善するには，機能表現候補の用法を正しく識別する検出器が
必要である．そのような検出器を実現する方法として，検出対象である機能表現
を形態素解析用辞書に登録し，形態素解析と同時に機能表現を検出する方法と，
形態素解析結果を利用して機能表現を検出する方法が考えられる．現在，広く用
いられている形態素解析器は，機械学習的なアプローチで接続制約や連接コスト
を推定した辞書に基づいて動作する．そのため，形態素解析と同時に機能表現を
検出するには，既存の形態素に加えて各機能表現の接続制約や連接コストを推定
するための，機能表現がラベル付けされた大規模なコーパスが必要になる．しか
し，検出対象の機能表現が多数になる場合は，作成コストの点から見て，そのよ
うな条件を満たす大規模コーパスを準備することは非現実的である．

形態素解析と機能表現検出が独立に実行可能であると仮定し，形態素解析結果を
利用して機能表現を検出することにすると，前述のような問題を避けられる．
そこで，機能表現の構成要素である可能性がある形態素が，機能表現の一部とし
て現れる場合と，機能表現とは関係なく現れる場合で，接続制約が変化しないと
いう仮定を置いた上で，人手で作成した検出規則を形態素解析結果に対して適用
することにより機能表現を検出する手法が提案されてきた\cite{接続情報にもと
づく助詞型機能表現の自動検出,助動詞型機能表現の形態・接続情報と自動検出,
形態素情報を用いた日本語機能表現の検出}．しかし，これらの手法では，検出
規則を人手で作成するのに多大なコストが必要となり，検出対象とする機能表現
集合の規模の拡大に対して追従が困難である．

そこで，本論文では，機能表現検出と形態素解析は独立に実行可能であると仮定
した上で，機能表現検出を形態素を単位とするチャンク同定問題として定式化し，
形態素解析結果から機械学習によって機能表現を検出する方法を提案する．
機械学習手法としては，入力次元数に依存しない高い汎化能力を持ち，Kernel関
数を導入することによって効率良く素性の組合わせを考慮しながら分類問題を学
習することが可能なSupport Vector Machine (SVM)\cite{Vapnik98a}を用いる．
具体的には，SVMを用いたチャンカーYamCha~\cite{yamcha}を利用して，形態素解
析器ChaSenによる形態素解析結果を入力とする機能表現検出器を実装した．ただ
し，形態素解析用辞書に「助詞・格助詞・連語」や「接続詞」として登録されて
いる複合語が，形態素解析結果中に含まれていた場合は，その複合語を，構成要
素である形態素の列に置き換えた形態素列を入力とする．また，訓練データとし
ては，先に述べた52表現について人手で用法を判定したデータを用いる．
更に，このようにして実装した機能表現検出器は，既存の解析系および\cite
{形態素情報を用いた日本語機能表現の検出}が提案した人手で作成した規則に基
づく手法と比べて，機能表現を高精度に検出できることを示す．


本論文の構成は以下の通りである．最初に，本論文の対象とする機能表現と，そ
の機能表現候補の用法を表現するための判定ラベルについて述べた上で，機能表
現検出をチャンク同定問題として定式化する（\ref{sec:detection}章）．次に，
SVMを用いて機能表現検出器を実装するための詳細を説明する
（\ref{sec:chunking_using_svm}章）．\ref{sec:human_rule}章では，人手で判定
規則を作成して機能表現を検出する手法について説明する．\ref{sec:実験と考
察}章では，作成した機能表現検出器の検出性能を評価し，この検出器は，既存
の解析系および人手によって規則を作成した手法と比べ，機能表現を高精度に検
出できることを示す．加えて，機械学習時に必要となる訓練データを削減する方
法を検討する．\ref{sec:関連研究}章では，関連研究について述べ，最後に結論
を述べる（\ref{sec:おわりに}章）．


\section{日本語機能表現の検出}
\label{sec:detection}

\subsection{日本語複合辞用例データベース}

森田ら\cite{日本語表現文型}は，機能表現の中でも特に「単なる語の連接では
なく，表現形式全体として，個々の構成要素のプラス以上の独自の意味が生じて
いる」表現を{\bfseries 複合辞}と呼び，個々の構成要素の意味から構成的に表
現形式全体の意味を説明できるような表現とは区別している．現代語複合辞用例
集\cite{複合辞用例集}（以下，{\bfseries 複合辞用例集}と呼ぶ）は，主要な125
種類の複合辞について，用例を集成し，説明を加えたものである．

日本語複合辞用例データベース\cite{日本語複合辞用例データベースの作成と分
析}（以下，{\bfseries 用例データベース}と呼ぶ）は，機能表現の機械処理を研
究するための基礎データを提供することを目的として設計・編纂されたデータベー
スである．用例データベースは，複合辞用例集に収録されている125種類の複合
辞および，その異形（合計337種類の機能表現）を対象として，機能表現候補と一
致する表記のリストと，個々の機能表現候補に対して最大50個の用例を収録して
いる．そして，各機能表現候補が文中において果たしている働きを，
\tabref{tbl:判定ラベル体系}に示す6種類の判定ラベルのうちから人手で判定
し，付与している．機能表現に対して付与される判定ラベルは，F, A, Mのいずれ
かであり，これらが本論文における検出対象となる．

\begin{table}[tb]
  \caption{判定ラベル体系}
  
  \label{tbl:判定ラベル体系}
  \newcommand{\exlabel}[1]{}
  \begin{center}
    \footnotesize
    \def\arraystretch{}
    \begin{tabular}{c|c|c|c|c|p{184pt}}
\hline\hline
      判定 & 判定 & & 内容 & & \\[-1pt]
      ラベル & 単位 & 読み & vs 機能 & 用法 & \multicolumn{1}{c}{例文} \\ \hline
      B & 不適切
	& \multicolumn{3}{c|}{} 
	& \exlabel{ex:A43-2000:B}
	  …と谷川王将は気\kern0pt\uline{にかけて}\kern0ptいる．
	  \\ \hline
      Y & 適切
	& 不一致
	& \multicolumn{2}{c|}{}
	& \hangafter=1\hangindent=13.7pt\exlabel{ex:A12-1000:Y}~
	  地球\kern0pt\uline{上では}，人口の増加，異常気象が心配されている．
	  \\ \hline
      C & 適切
	& 一致
	& 内容的
	& 内容的用法
	& \hangafter=1\hangindent=13.7pt\exlabel{ex:A56-1000:C}~
	  まな板\kern0pt\uline{にとって}\kern0ptていねいに…
	  みそ汁の実にするのである．
	  \\ \hline
      F & 適切
	& 一致
	& 機能的
	& 複合辞用例集の用法
	& \hangafter=1\hangindent=13.7pt\exlabel{ex:A22-1000:F}~
	  受験などでは倍率が上がった\kern0pt\uline{ところで}\kern0pt入学金があがることはない． \\
      A & 適切
	& 一致
	& 機能的
	& 接続詞的用法
	& \hangafter=1\hangindent=13.7pt\exlabel{ex:A22-1000:A}~
	  \uline{ところで}，全国の桜の名所では近年，樹勢の衰えが目立ち，…
	  \\
      M & 適切
	& 一致
	& 機能的
	& 他の機能的用法
	& \hangafter=1\hangindent=13.7pt\exlabel{ex:A22-1000:M}~
	  浜ノ島はあと一歩の\kern0pt\uline{ところで}\kern0pt勝ち星に結び付かず負け越した．\\ \hline
    \end{tabular}
  \end{center}
\end{table}

\subsection{判定ラベル体系}
\label{subsec:label}

判定ラベルとは，機能表現候補が文中でどのような働きをしているかを表すラベ
ルであり，用例データベースでは\tabref{tbl:判定ラベル体系}の通り，6種類の
ラベルが設定されている．以下，個々の判定ラベルについて説明する．

用例データベースでは，IPA品詞体系(THiMCO97)の
形態素解析用辞書\cite{ipadic-2.6.1}に登録されている語から，「助詞・格助
詞・連語」として登録されている語を取り除いた残りの語を，語としている．
そして，ある機能表現候補が，1個以上の語，複合辞または慣用表現からなる列
である場合，その候補は判定単位として適切であるが，それ以外の場合は，その
候補は判定単位として不適切であるとして，判定ラベルBを付与している．
例えば，\tabref{tbl:判定ラベル体系}中の\strref{ex:A43-2000:B}に含まれる
機能表現候補「にかけて」は，「心配する」という意味の慣用表現「気にかける」
の一部が活用した形であり，先に述べた条件を満たしていない．したがって，
\strref{ex:A43-2000:B}には，判定ラベルB が付与される．

判定ラベルYは，機能表現候補の読みが，判定対象となっている機能表現の読み
と一致していないことを表す．例えば，「AうえでB」という形で，「Aした後でB」
という出来事の継起関係を表す機能表現「うえで」の用例として\tabref{tbl:判
定ラベル体系}中の\strref{ex:A12-1000:Y}を判定する場合を考える．この場合，
機能表現候補の読み「じょうで」と，判定対象となっている機能表現の読み「う
えで」が一致していないので．判定ラベルYを付与する．

判定ラベルCは，機能表現候補に内容的に働いている語が含まれていることを表
す．例えば，\tabref{tbl:判定ラベル体系}中の\strref{ex:A56-1000:C}の機能
表現候補に含まれる動詞「とる」は本来の意味で内容的に働いているので，判定
ラベルとしてCを付与する．

判定ラベルF, A, Mは，機能表現候補が機能的に働いているとき，その機能を区別
するためのラベルである．判定ラベルFは，機能表現候補が複合辞用例集で説明
されている用法で働いていることを表し，判定ラベルAは，機能表現候補が接続
詞的に働いていることを表す．判定ラベルMは，これら以外の機能的な働きをし
ていることを表す．
例として，「ところで」の用例として\tabref{tbl:判定ラベル体系}中の
\strref{ex:A22-1000:F}$\sim$(\ref{ex:A22-1000:M})を判定する場合を考え
る．\strref{ex:A22-1000:F}のターゲット文字列は，複合辞用例集で説明されて
いる通りに逆接の働きをしているので，判定ラベルFを付与する．
\strref{ex:A22-1000:A}のターゲット文字列は，文頭で接続詞的に働いているの
で，判定ラベルAを付与する．\strref{ex:A22-1000:M}のターゲット文字列は，
形式名詞「ところ」を含めて機能的に働いているので，判定ラベルMを付与する．
本論文では，判定ラベルF, A, Mが付与される機能表現候補を検出対象とする．



\subsection{チャンキングによる定式化}
\label{subsec:formalization}

\vspace*{-2pt}
本節では，最初に，機能表現検出タスクに対して機械学習的手法を適用する場合
に，考慮しておくべき2つの問題点について述べる．第1の問題点は，学習データ
の分量とモデルの複雑さの間に存在するトレードオフの関係であり，第2の問題
点は，機能表現候補が部分的に重複して現れた場合の取り扱いである．
その上で，機能表現を検出する手順として，以下の2通りの手順を検討する．
\begin{itemize}
  \item 1つまたは複数の形態素からなる機能表現候補を単位として，判定ラベ
	ルを付与する手順（以下，{\bfseries 手順1}と呼ぶ）．
  \item 形態素を単位として，機能表現の一部であることを表すチャンクタグを
        付与する手順（以下，{\bfseries 手順2} と呼ぶ）．
\end{itemize}
手順2については，検出対象とする機能表現の取り扱い方によって，更に2通りに
細分化することができる．第1は，検出対象とする全ての機能表現に同一のチャ
ンクタグを用いる手順（以下，{\bfseries 手順2-a}と呼ぶ）であり，第2は，機能
表現毎に異なるチャンクタグを用いる手順（以下，{\bfseries 手順2-b}と呼ぶ）
である．

機能表現検出タスクに対して機械学習的手法を適用する場合には，まず，学習デー
タの分量とモデルの複雑さの間に存在するトレードオフの関係を考慮する必要が
ある．
一般に，あるタスクに対して機械学習手法を適用する時，そのタスクの対象をど
の程度に細分化してモデルで表現するかは，非常に重要な問題である．十分な分
量の学習データが利用可能である場合には，タスクの対象を細かく分類した複雑
なモデルを採用することによって，モデルの予測精度は改善する．しかし，不十
分な分量の学習データしか利用できない場合に，過度に複雑なモデルを採用する
と，モデルの予測精度は悪化する．
つまり，機能表現検出タスクに対して機械学習的手法を適用する場合には，利用
できる学習データの量を考慮しながら，適当な複雑さのモデルを選択する必要が
ある．

機能表現検出タスクに対して機械学習的手法を適用する場合には，第2の問題点
として，機能表現候補が部分的に重複して現れる場合を考慮する必要がある．
例えば，\strref{ex:toiu-F}と\strref{ex:toiumonono-F}には，「という」およ
び「というものの」という2つの機能表現候補が，部分的に重複して現れている．
\begin{example}
  \item それが試合\kern0pt\uline{\uline{という}{\kern0pt}ものの}{\kern0pt}難しさだ．
	\label{ex:toiu-F}
  \item 勝った{\kern0pt}\uline{\uline{という}}\uline{ものの}，スコアは悪い．
	\label{ex:toiumonono-F}
\end{example}
\strref{ex:toiu-F}では，「AというB」という形で用いられてBの具体的な内容
を示しているので，2つの機能表現候補の内，「という」という機能表現候補に
対して，機能的であるという判定を行う必要がある．それに対して，
\strref{ex:toiumonono-F}では，「AというもののB」の形で，前件Aの成立・存
在を認めた上で，それにもかかわらず後件Bのようなことがあるという関係を述
べているので，2つの機能表現候補の内，「というものの」という機能表現候補
に対して，機能的であるという判定を行う必要がある．
実際に予備調査を行った結果から，機能表現候補の出現箇所の約20\%において，
このように複数の機能表現候補の一部が重複した形で現れることが分かった．し
たがって，機能表現検出において，複数の機能表現候補が部分的に重複して現れ
る場合を無視することは適当ではなく，その複数の候補を適切に扱う必要がある．


以上の問題点を踏まえて，手順1について検討する．
ある1つの機能表現候補に適切な判定ラベルを付与するには，その候補に付与さ
れる可能性がある複数の判定ラベル間に優先順位を与えるモデルが必要である．
つまり，判定ラベルの数を$U$とすると，$U$に比例した複雑さのモデルが必要で
ある．
手順1では，機能表現毎に個別に判定ラベルを付与するため，機能表現の種類数
を$V$とすると，判定ラベルの総数は，候補毎の判定ラベルの数$U$と機能表現の
種類数$V$の積$U\cdot V$となる．したがって，手順1のモデルの複雑さは，
$U\cdot V$に比例する．
また，第2の問題点に対応するには，部分的に重複している複数の機能表現候補
と判定ラベルの対から，適当なものを選択する必要がある．手順1のモデルでは，
機能表現候補と判定ラベルの$U\cdot V$通りの対を全て区別しているので，それ
らを比較することにより，適当な対を選択する．

次に，手順2について検討する．
手順2では，形態素を単位として判定を行い，それぞれの形態素に，機能表現の
一部であることを表すチャンクタグを付与する．ある形態素に適切なチャンクタ
グを付与するには，その形態素に付与される可能性がある全てのチャンクタグに
優先順位を与えるモデルが必要である．このようなモデルの複雑さは，その形態
素に付与される可能性があるチャンクタグの種類数に比例する．
さらに，チャンクタグ$c$を形態素$m_{1}$に付与する場合と形態素$m_{2}$に付
与する場合の2通りの状況を考える．また，機能表現に含まれる全ての形態素の
異なり数$M$とする．この時，同一のチャンクタグ$c$を付与する場合であっても，
付与対象となる形態素が異なる場合には異なるモデルが必要という立場に立つと，
手順2のモデルの複雑さは，チャンクタグの種類数と，形態素の異なり数$M$の積
に比例すると考えられる．
この分析を踏まえて，手順2-aと手順2-bのモデルの複雑さを検討する．
手順2-aでは，検出対象とする全ての機能表現に同一のチャンクタグを用いる．
このチャンクタグは，その形態素が含まれるチャンクの用法を表す判定ラベルと，
その形態素がチャンクの中で占める位置を表す部分からなり，チャンクタグの種
類数は$U$に比例する．よって，手順2-aのモデルの複雑さは$U\cdot M$に比例す
る．
一方，手順2-bでは，機能表現毎に異なるチャンクタグを用いる．このチャンク
タグは，その形態素がどの機能表現の一部であるかを表す部分，その形態素が含
まれるチャンクの用法を表す判定ラベル，および，その形態素がチャンクの中で
占める位置を表す部分からなり，チャンクタグの種類数は$U\cdot V$に比例する．
よって，手順2-bのモデルの複雑さは，$U\cdot V\cdot M$に比例する．
また，手順2では，形態素を単位としてチャンクタグを付与することによって，
部分的に重複している複数の機能表現候補の選択も同時に行っている．例えば，
\strref{ex:toiu-F}，（\ref{ex:toiumonono-F}）の場合，形態素「もの」に対
してチャンクタグを付与すると，機能表現候補「という」と機能表現候補「とい
うものの」のどちらが適切かという選択も同時に行われる．

先に述べた通り，モデルの複雑さと，モデルの推定に必要となる学習データの量
にはトレードオフの関係が存在する．
手順1のモデルの複雑さは$U\cdot V$に比例し，手順2-aのモデルの複雑さは
$U\cdot M$に比例し，手順2-bのモデルの複雑さは$U\cdot V\cdot M$に比例する．
\ref{sec:intro}章で述べたように，異形を考慮すると，機能表現の種類数$V$は
1万種類以上となる．それに対して，機能表現中に現れる形態素は，助詞・助動
詞などの付属語と限られた自立語のみであり，機能表現中に現れる形態素の異な
り数$M$は，機能表現の種類数$V$よりもはるかに少なく，多くても数百程度と予
想される．したがって，検討した手順の中で，もっとも簡単なモデルを使ってい
る手順は，手順2-aである．
本論文では，利用できる学習データの量が十分ではない可能性を考慮して，複雑
なモデルの採用を避け，できるだけ簡単なモデルの手順を採用することにする．
よって，本論文における機能表現検出タスクの定式化においては，手順2-aを採
用する．すなわち，形態素を単位として，機能表現の一部であることを表すチャ
ンクタグを付与し，機能表現をチャンキングするという方式を採用する．そのチャ
ンクタグとしては，検出対象とする全ての機能表現に同一のチャンクタグを用い
る．


\section{SVMを用いたチャンキングによる機能表現検出}
\label{sec:chunking_using_svm}

\subsection{Support Vector Machines}
サポートベクトルマシンは，素性空間を超平面で分割することによりデータを2 
つのクラスに分類する二値分類器である\cite{SVM,tinysvm}．2つのクラスを正
例，負例とすると，学習データにおける正例と負例の間隔（マージン）を最大にす
る超平面を求め，それを用いて分類を行う．すなわち，以下の識別関数$f(x)$の
値によってクラスを判別することと等価である．
\begin{align}
  \label{eq:svm1}
    f({\bf x}) & = \operatorname{sgn} \left( \sum^{l}_{i=1} \alpha_i y_i K({\bf x}_i,{\bf x}) 
	+ b \right)\\
    b & = -\frac{\operatorname{max}_{i,y_i=-1}b_i 
	+ \operatorname{min}_{i,y_i=1}b_i}{2}\nonumber\\
    b_i & = \sum^l_{j=1} \alpha_j y_j K({\bf x}_j,{\bf x}_i) \nonumber
\end{align}
ここで${\bf x}$は識別したい事例の文脈（素性の集合），${\bf x}_{i}$と
$y_i(i=1,...,l, y_i\in\{1,-1\})$は学習データの文脈とクラスである．また，
関数$sgn(x)$は，$x \geq 0$のときに1，$x < 0$のときに$-1$となる二値関数で
ある．\pagebreak
各$\alpha_i$は，式(\ref{eq:svm5})と式(\ref{eq:svm6})の制約のもとで
式(\ref{eq:svm4})の$L(\alpha)$を最大にするものである．
{\allowdisplaybreaks
\begin{align}
  L({\alpha}) & = \sum^l_{i=1} \alpha_i - \frac{1}{2} \sum^l_{i,j=1} \alpha_i \alpha_j y_i y_j K({\bf x_i},{\bf x_j})
  \label{eq:svm4}\\
  & 0 \leq \alpha_i \leq C \, \, (i=1,...,l)
  \label{eq:svm5}\\
  & \sum^l_{i=1} \alpha_i y_i = 0 
  \label{eq:svm6}
\end{align}
}
関数$K$はカーネル関数と呼ばれ，様々なものが提案されているが，本論文では
次式で定義される多項式カーネルを用いる．
\begin{equation}
  \label{eq:svm3}
  K({\bf x},{\bf y}) = ({\bf x}\cdot{\bf y} + 1)^d
\end{equation}
ここで，$C,d$は実験的に設定される定数である．

予備実験を行い，次数$d$の値として$1,2,3$の3通りを検討した．$d=2,3$とした
場合はF値に大きな差はなかったが，$d=1$とするとF値がかなり悪化した
\footnote{評価尺度（F値）については\ref{subsec:評価尺度}節を参照}．ただし，
$d=3$とした場合は，$d=2$とした場合に比べて，学習時間がかなり増加したため，
本論文では，次数$d$の値として2を用いる．また，予備実験において，マージン
$C$の値として$1,0.1,0.01,0.001,0.0001$の5通りを検討したところ，F値に大き
な差が見られなかったため，本論文ではマージン$C$の値として1を用いる．


\subsection{チャンクタグの表現法}

\ref{subsec:formalization}節で述べたように，本論文では，検出対象とする機
能表現全てに共通のチャンクタグを，形態素を単位として付与するという手順で，
機能表現検出を行う．チャンクタグは，そのチャンクタグが付与された形態素が，
検出対象とする機能表現のいずれかに含まれるか否かを表し，チャンクの範囲を
示す要素とチャンクの用法を示す要素という2つの要素からなる．以下，本論文
で用いたチャンクタグについて詳細を述べる．

チャンクの範囲を示す要素の表現法としては，以下で示すようなIOB2フォーマッ
ト\cite{Sang00a}が広く利用されている．本論文でも，このIOB2フォーマットを
使用する．
\begin{quote}
  \begin{tabular}{cl}
    \textbf{I} & チャンクに含まれる形態素（先頭以外） \\
    \textbf{O} & チャンクに含まれない形態素 \\
    \textbf{B} & チャンクの先頭の形態素 \\
  \end{tabular}
\end{quote}

\begin{table}
  \begin{center}
    \caption{チャンクの用法を示す要素の体系}
    \label{tab:tag}
    \begin{tabular}{c||c|c|c|c|c|c}
      \hline
      体系1 (CHK1) & F & A & M & C & Y & B \\
      \hline
      体系2 (CHK2) & \multicolumn{1}{c}{F} & \multicolumn{1}{c}{A} & \multicolumn{1}{c|}{M}
		  & C & Y & B \\
      \hline
      体系3 (CHK3) & \multicolumn{1}{c}{F} & \multicolumn{1}{c}{A} & \multicolumn{1}{c|}{M} &
		      \multicolumn{1}{c}{C} &\multicolumn{1}{c}{Y} & \multicolumn{1}{c}{B} \\
      \hline
      体系4 (CHK4) & F & \multicolumn{1}{c}{A} & \multicolumn{1}{c}{M}
		  & \multicolumn{1}{c}{C} & \multicolumn{1}{c}{Y} & \multicolumn{1}{c}{B} \\
      \hline
      体系5 (CHK5) & F & \multicolumn{1}{c}{A} & \multicolumn{1}{c|}{M}
		  & \multicolumn{1}{c}{C} & \multicolumn{1}{c}{Y} & \multicolumn{1}{c}{B} \\
      \hline
      体系6 (CHK6) & F & \multicolumn{1}{c}{A} & \multicolumn{1}{c|}{M} & C & Y & B \\
      \hline
      体系7 (CHK7) & F & A & M & \multicolumn{1}{|c}{C} & \multicolumn{1}{c}{Y} & B \\
      \hline
      体系8 (CHK8) & \multicolumn{1}{c}{F} & M & A & \multicolumn{1}{|c}{C} & \multicolumn{1}{c}{Y} & B \\
      \hline
      体系9 (CHK9) & \multicolumn{1}{c}{F} & M & A & C & Y & B \\
      \hline
      体系10 (CHK10) & F & A & M & \multicolumn{3}{c}{---} \\
      \hline
      体系11 (CHK11) & F & \multicolumn{1}{c}{A} & M & \multicolumn{3}{c}{---} \\
      \hline
      体系12 (CHK12) & \multicolumn{1}{c}{F} & \multicolumn{1}{c}{A} & M & \multicolumn{3}{c}{---} \\
      \hline
      体系13 (CHK13) & \multicolumn{1}{c}{F} & M & A & \multicolumn{3}{c}{---} \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

チャンクの用法を示す要素の表現法としては，\tabref{tab:tag}のように様々な
ものが考えられる．例えば，体系5 (CHK5)は，6種類の判定ラベルF, A, M, C, Y, Bの
うち，ラベルA, MとラベルC, Y, Bをそれぞれ区別せずに1つの分類とみなす表現法
である．そして，各機能表現候補は，チャンクであることを表す要素(B/I)と，
用法を示す要素(F/AM/CYB)を組み合わせた6種類のチャンクタグによって表現さ
れる．実際には，この6種類に，チャンクに含まれないことを表すチャンクタグ
{\bfseries O}を加えて，\figref{fig:chunktag}のように7種類のチャンクタグ
を付与する．
また，体系11 (CHK11)は，判定ラベルF, A, Mの機能表現候補に対しては体系5と同
様にチャンクタグを付与するが，判定ラベルC, Y, Bの機能表現候補に対しては，
チャンクとして区別せずに，チャンクタグ{\bfseries O}を付与する体系である．
予備実験の結果，いずれの表現法を用いても大きな性能の差は見られなかったた
め，本論文では，最も性能が良かった体系5 (CHK5)を用いる．

\begin{figure}
  \begin{center}
    \begin{tabular}{l|c||c|c|c|c}\hline
      \multicolumn{2}{c||}{} & \multicolumn{3}{c|}{機能表現候補の形態素} & それ以外の形態素 \\ \cline{3-5}
      \multicolumn{2}{c||}{} & F & A, M & C, Y, B & \\ \hline\hline
      チャンクに含まれる & 先頭 & {\bfseries B-F} & {\bfseries B-AM} & {\bfseries B-CYB} & \\ \cline{2-5}
      & 先頭以外 & {\bfseries I-F} & {\bfseries I-AM} & {\bfseries I-CYB} & \\ \hline
      \multicolumn{2}{l||}{チャンクに含まれない} & \multicolumn{3}{c|}{} & {\bfseries O} \\ \hline
    \end{tabular}
  \end{center}
    \vspace{8pt}
  \caption{体系5 (CHK5)におけるチャンクタグ}
  \label{fig:chunktag}
\vspace{-2pt}
\end{figure}

本論文では，用例データベースで設定されている判定ラベルのうち，ラベルFが
付与された表現を検出する検出器（これを，検出器Fと呼ぶ）と，ラベルF, A, Mのい
ずれかが付与された表現（機能表現）を検出する検出器（これを，検出器FAMと呼ぶ）
を作成する．検出器FAMの評価時には，判定ラベルF, A, Mを区別しない．
判定ラベルFは，複合辞用例集で説明されている用法で用いられていることを表
す判定ラベルであり，機能表現候補がひとかたまりとなって非構成的な意味を持っ
ている場合にのみ付与される．それに対して，判定ラベルA, Mは，機能表現候補
が非構成的な意味を持っているか否かに関わらず，その機能表現候補が機能的な
働きをしていることを表すラベルである．したがって，検出器Fは，非構成的な
意味を持つ機能表現（の一部）のみを検出する検出器となり，検出器FAMは機能表
現全体を検出する検出器となる．

SVMは二値分類器であるため，そのままでは，2クラスの分類しか扱えない．本論
文のようにクラス数が3以上の場合には，複数の二値分類器を組み合わせて拡張
する必要がある．本論文では，拡張手法としては，広く利用されているペアワイ
ズ法を用いる．ペアワイズ法とは，$N$個のクラスに属するデータを分類する時，
異なる2つのクラスのあらゆる組み合わせに対する二値分類器を作り，得られた
$N(N-1)/2$個の二値分類器の多数決により，クラスを決定する方法である．

\subsection{素性}
\label{subsec:feature}

学習・解析に用いる素性について説明する．文頭から$i$番目の形態素
$m_{i}$に対して与えられる素性$F_{i}$は，形態素素性$MF(m_{i})$，チャンク
素性$CF(i)$，チャンク文脈素性$OF(i)$の3つ組として，次式によって定義され
る．
\begin{equation}
  F_{i} = \langle MF(m_{i}), CF(i), OF(i) \rangle
\end{equation}
形態素素性$MF(m_{i})$は，形態素解析器によって形態素$m_{i}$に付与される情
報である．
本論文では，IPA品詞体系(THiMCO97)の形態素解析用辞書\cite{ipadic-2.6.1}
に基づいて動作する形態素解析器ChaSenによる形態素解析結果を入力としている
ため，以下の10種類の情報（表層形，品詞，品詞細分類$1\sim 3$，活用型，活
用形，原形，読み，発音）を形態素素性として用いた．

チャンク素性$CF(i)$とチャンク文脈素性$OF(i)$は，$i$番目の位置に出現して
いる機能表現候補に基づいて定まる素性である．今，下図のような形態素列
$m_j\ldots m_i \ldots m_k$からなる機能表現候補$E$が存在したとする．
\begin{center}
  \begin{tabular}[tb]{ccccc}
    $m_{j-2}$ & $m_{j-1}$ &\fbox{$m_j\ldots m_i \ldots m_k$} & $m_{k+1}$ & $m_{k+2}$\\
    & & 機能表現候補$E$ & & 
  \end{tabular}
\end{center}
チャンク素性$CF(i)$は，$i$番目の位置に出現している機能表現候補$E$を構成
している形態素の数（機能表現候補の長さ）と，機能表現候補中における形態素
$m_{i}$の相対的位置の情報の2つ組である．チャンク文脈素性$OF(i)$は，$i$番
目の位置に出現している機能表現候補の直前2形態素および直後2形態素の形態素
素性とチャンク素性の組である．すなわち，$i$番目の位置に対する$CF(i)$およ
び$OF(i)$は次式で表される．
\begin{align*} 
CF(i) &=\langle k-j+1 ,\;\; i-j+1 \rangle\\
OF(i) &=\langle MF(m_{j-2}), CF(m_{j-2}), MF(m_{j-1}), CF(m_{j-1}), \\
& \quad \;\phantom{\langle}MF(m_{k+1}), CF(m_{k+1}), MF(m_{k+2}), CF(m_{k+2})\rangle
\end{align*}

\begin{figure}[b]
  \begin{center}
    \includegraphics[width=.6\textwidth]{06f2.eps}
    \caption{YamChaの学習・解析}
    \label{yamcha}
  \end{center}
\end{figure}

\ref{subsec:formalization}節で述べたように，機能表現検出においては，1つ
の文中に，複数の機能表現候補が部分的に重複して現れる場合を考慮する必要が
ある．ここでは，そのような場合のチャンク素性とチャンク文脈素性の付与方法
について考える．
複数の機能表現候補が部分的に重複して現れている場合，それらの候補全てに基
づいてチャンク素性とチャンク文脈素性を付与するという方法と，それらの候補
から何らかの基準を用いて1つの候補を選択し，選択された候補に基づいてチャ
ンク素性とチャンク文脈素性を付与するという方法が考えられる．
前者の方法で付与された素性を参照して機械学習を行うには，重複する可能性が
ある機能表現の全ての組み合わせに対して十分な量の学習事例が必要であるが，
そのような学習事例を準備することは現実的ではない．
そのため，本論文では，後者の方法を採り，次の優先順序に従って選ばれた1つ
の機能表現候補に基づいて，チャンク素性とチャンク文脈素性を付与することに
する\footnote{この優先順序は，人手で作成した判定規則に基づく手法
（\ref{sec:human_rule}章）において，複数の機能表現候補が部分的に重なって出
現し，それらに対する判定ラベルが競合した場合に，適切な判定ラベル付与結果
を取捨選択する場合の優先順序とは異なっている．ここでは，学習・解析方向が
左から右であることを考慮して，最も左側の機能表現候補を優先している．}．
\begin{description}
 \item[1] 先頭の形態素が，最も左側の機能表現候補を用いる．
 \item[2] 1を満たす候補が複数存在する場合は，その中で最も形態素数が多い
	    候補を用いる．
\end{description}
例えば，\strref{ex:nakutehaikemasen}には，「なくてはいけません」および
「てはいけません」という2つの機能表現候補が，部分的に重複して現れている．
\begin{example}
  \item 慎重にし{\kern0pt}\uline{なく}\uline{\uline{てはいけません}}．
	\label{ex:nakutehaikemasen}
	
	
	
	
\end{example}
この場合，「なくてはいけません」という機能表現候補が，「てはいけません」
という機能表現候補に比べて，より左の形態素から始まっているので，「なくて
はいけません」という機能表現候補に基づいて，チャンク素性とチャンク文脈素
性を付与する．
また，\strref{ex:toiumonono}には，「という」および「というものの」という
2つの機能表現候補が，部分的に重複して現れている．
\begin{example}
  \item それが試合{\kern0pt}\uline{\uline{という}}\uline{ものの}{\kern0pt}難しさだ．
	\label{ex:toiumonono}
\end{example}
この場合，2つの機能表現候補の先頭の形態素は同一であるため，より形態素数
が多い候補「というものの」に基づいて，チャンク素性とチャンク文脈素性を付
与する．

$i$番目の形態素に対するチャンクタグを$c_{i}$とすると，チャンクタグ
$c_{i}$の学習・解析を行う場合に用いる素性として，$i$番目の形態素および前
後2形態素に付与された素性$F_{i-2},F_{i-1},F_{i},F_{i+1},F_{i+2}$と，直前
2形態素に付与されたチャンクタグ$c_{i-2},c_{i-1}$を用いる
（\figref{yamcha}）．解析時には，解析によって得られたチャンクタグを，直前2 
形態素に付与されたチャンクタグとして順に利用して，解析を行う．前後3形態
素の素性と直前3形態素のチャンクタグを用いて学習・解析を行う予備実験も行っ
たが，前後2形態素の素性と直前2形態素のチャンクタグを用いた場合に比べて，
殆んど性能が変わらなかったため，前後2形態素の素性と直前2形態素のチャンク
タグを用いる．


\section{人手による規則を用いた検出}
\label{sec:human_rule}

この節では，形態素解析結果に基づいて，人手で作成した規則によって機能表現
候補の用法を識別する検出器の概略について述べる．

形式的には，ある機能表現候補$E$の用法を判定する規則$T(E)$は，形態素列パ
ターン$P(E)$と，判定規則リスト$R(E)$の2つ組として，次のように定義される．
\[
  T(E) \equiv \langle P(E),\: R(E)\rangle
\]

機能表現候補$E$に一致する形態素列パターン$P(E)$は，1つの形態素に一致する
形態素パターン$p$の列である．
\begin{align*} 
  P(E) & \equiv p_{1}p_{2}\cdots p_{l} \\
  p & \equiv \langle Lex,\: POS,\: FORM\rangle
\end{align*}
形態素パターン$p$は，形態素の基本形の表記$Lex$，品詞$POS$および活用形
$FORM$の3つ組として定義される．
例えば，「として」に対する形態素列パターン$P(\mbox{として})$は，以下のよ
うに3つの形態素パターンからなる．
\[
  P(\mbox{として}) =
    \langle\kern0pt\mbox{と},~\mbox{助詞},*\rangle\
    \langle\kern0pt\mbox{する},~\mbox{動詞},~\mbox{連用形}\kern0pt\rangle\ 
    \langle\kern0pt\mbox{て},~\mbox{助詞},*\rangle
\]
なお，本論文では，IPA品詞体系の形態素解析用辞書に基づいて動作する形態素
解析器ChaSenによる形態素解析結果を入力としているため，
品詞と活用形はIPA品詞体系で指定する．

また，判定規則リスト$R(E)$は，機能表現候補の直前の形態素列に一致する左接
続制約$LC$，直後の形態素列に一致する右接続制約$RC$，および，これらの制約
を満たした場合の判定ラベル$L$からなる3つ組として定義される判定規則$r$の
順序付き集合である．
\begin{align*} 
  R(E) & \equiv \{r_{1}, r_{2}, \ldots, r_{k}\} \\
  r & \equiv \langle LC,\:RC,\:L \rangle
\end{align*}
左接続制約$LC$および右接続制約$RC$は，
論理関数$\mathtt{and},~\mathtt{or},~\mathtt{not}$と，
\pagebreak
左接続素性$LF$または
右接続素性$RF$の
組み合わせである．
\begin{align*} 
  LC & \equiv  LF\ |\ {\tt and}(LC',LC'')\ |\ {\tt or}(LC',LC'')\ |\ {\tt not}(LC') \\
  RC & \equiv  RF\ |\ {\tt and}(RC',RC'')\ |\ {\tt or}(RC',RC'')\ |\ {\tt not}(RC')
\end{align*}
ここで，$LC',LC''$は任意の左接続制約を表し，$RC',RC''$は任意の右接続制約
を表す．例えば，「として」に対する判定規則リスト$R(\mbox{として})$は，以
下のような2つの判定規則の順序付き集合である．
\[
  R(\mbox{として}) =
  \left\{
    \langle\phi,{\tt and}(\mbox{助動詞},~{\tt not}(\langle\kern0pt\mbox{だ},~\mbox{助動詞},*\rangle)),\mbox{C}\rangle,\
    \langle\kern0pt\mbox{体言},\:\phi,\mbox{F}\rangle\
  \right\}
\]
最初の判定規則は，左接続制約なし，右接続制約「${\tt and}(\mbox{助動詞},\ 
{\tt not}(\langle\mbox{だ},\ \mbox{助動詞},*\rangle))$」，判定ラベルCとい
う3つ組である．これは，機能表現候補の右側が「だ」以外の助動詞であれば，
機能表現候補の左側がどのような表現であっても，判定ラベルCを付与するとい
う判定規則を意味する．
接続素性としては，複合辞用例集で説明されている接続制約を参考にして，
\tabref{tbl:左接続素性}と\tabref{tbl:右接続素性}のような素性を用意した．

\begin{table}[b]
  \caption{左接続素性}
  \label{tbl:左接続素性}
  \begin{center}
    \begin{tabular}{l|p{0.6\columnwidth}}\hline
      $LF$ & \multicolumn{1}{c}{意味} \\ \hline
      体言 & 直前部分が体言である場合に真 \\ 
      用言 & 直前部分が用言である場合に真 \\ 
      基本形 & 直前部分が基本形の用言である場合に真 \\ 
      過去形 & 直前部分が過去形の用言である場合に真 \\ 
      助詞「の」 & 直前部分に名詞と助詞「の」が連続して現れている場合に真 \\ 
      文頭 & 機能表現候補が文頭に現れている場合に真 \\ 
      $p$ & 直前の形態素が形態素パターン$p$に一致する場合に真 \\ 
      \hline
    \end{tabular}
  \end{center}
  \vspace*{5mm}
  \caption{右接続素性}
  \label{tbl:右接続素性}
  \begin{center}
    \begin{tabular}{l|p{0.6\columnwidth}}\hline
      $RF$ & \multicolumn{1}{c}{意味} \\ \hline
      助動詞 & 直後に助動詞が現れている場合に真 \\
      体言 & 直後に体言が現れている場合に真 \\
      文末 & 機能表現候補が文末に現れている場合に真 \\
      $p$ & 直後の形態素が形態素パターン$p$と一致する場合に真 \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

このような規則$T(E)$に基づく判定は，以下の2段階からなる．最初に，形態素
列パターン$P(E)$によって機能表現候補を発見し，次に，判定規則リスト$R(E)$ 
に含まれる判定規則を先頭から順に検査して，最初に一致した判定規則$r_{i}$ 
の判定ラベルを出力する．例えば，\strref{ex:toshite-F}の形態素解析結果を
対象として判定を行う場合を考える．
\begin{example}
  \item たくさんの若者たちが，ボランティア{\kern0pt}\uline{として}，頑張っている．
	\label{ex:toshite-F}
\end{example}
最初に形態素列パターン$P(\mbox{として})$によって下線部が機能表現候補とし
て発見される．次に，判定規則リスト$R(\mbox{として})$に含まれている判定規
則を順に適用していく．
1番目の規則$\langle\phi,{\tt and}(\mbox{助動詞}, \linebreak
{\tt not}(\langle\mbox
{だ},~\mbox{助動詞},*\rangle)),\mbox{C}\rangle$は，右接続制約が「だ」以外
の助動詞となっているが，\strref{ex:toshite-F}では，機能表現候補の直後は
読点になっているから，成り立たない．2番目の規則$\langle\mbox{体言},
\:\phi,\mbox{F}\rangle$ は，左接続制約が「体言」になっており，
\strref{ex:toshite-F}でも成り立っているので，判定ラベルとしてFを出力する．
なお，全ての判定規則が成り立たなかった場合は，判定ラベルを付与しない．
人手で作成した判定規則の数を，\tabref{tbl:human_crafted_rules}に示す．
1つの機能表現候補を判定するための判定規則リストは，平均して2.7個の判定規
則からなっている．なお，使用した接続素性は186個である．

\begin{table}[t]
  \caption{人手で作成した判定規則数}
  \label{tbl:human_crafted_rules}
  \begin{center}
    \begin{tabular}{c|r} \hline
      判定ラベル & 規則数 \\ \hline
      F & 53 \\
      A & 9 \\
      M & 11 \\
      C & 46 \\
      Y & 0 \\
      B & 26 \\ \hline
      計 & 145 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

1つの文に対して，全ての可能な機能表現候補に対する規則を適用すると，複数
の機能表現候補が照合されることがある．
この時，\ref{subsec:formalization}節で述べた場合と同様に，複数の機能表現
候補が部分的に重なって出現して，それらの候補に対する判定ラベルが相互に競
合し，複数の判定ラベル付与結果を同時に採用できない場合がある．その場合は，
以下の優先順序に従って機能表現候補を採用する．まず，形態素列長で比較して，
より長い機能表現候補を採用する．機能表現候補の形態素列長が等しい場合は，
先頭の形態素が最も左側の機能表現候補を採用する．既に採用されている機能表
現候補と，競合する機能表現候補は，全て棄却する
\footnote {この優先順序は，チャンク素性・チャンク文脈素性を付与する際に，
部分的に重複する複数の機能表現候補を取捨選択するための優先順序とは異なっ
ている（\ref{subsec:feature}節）．ここでは，形態素列長として長い機能表現候
補は，短い機能表現候補と比べて，判定の際の制約条件が多くなるから，より信
頼できるというヒューリスティックスに基づいて，形態素列長として長い機能表
現候補を優先している．}．



\section{実験と考察}
\label{sec:実験と考察}

本論文で提案する2つの検出器，検出器Fと検出器FAMに対して，
学習および解析
を行い，各ベースラインと性能を比較した．
\pagebreak
また，用いる素性の違いによって，
性能がどのように変化するかを調査した．さらに，訓練時のデータサイズの違い
と検出性能の関係を明らかにし，最後に，訓練データの作成コストの削減が可能
であるかを調査した．

\subsection{データセット}
\label{subsec:dataset}

文を単位として学習を行うには，文中に現れる全ての機能表現候補に対して判定
ラベルが付与されたデータが必要である．そのため，本論文の対象とする52表現
に対する用例として用例データベースに収録されている2600例文（1つの表現につ
き50例文）について，これらの例文に含まれている全ての機能表現候補に判定ラ
ベルを付与した．以下，この2600例文をまとめて，全データセットと呼ぶ．


\begin{table}[b]
  \caption{データセットの各統計量}
  \label{tab:dataset}
  \begin{center}
    \begin{tabular}{@{}c||c|c|c|c|c|c|c||c@{}} \hline
      & \multicolumn{7}{c||}{判定ラベル} & \\ \cline{2-7}
      & F & A & M & C & Y & B & 計 & \raisebox{1.5ex}[0pt]{全形態素数} \\ \hline
      全データセット & 1974 & 55 & 453 & 523 & 9 & 169 & 3183 & 92899 \\
      部分データセット & 1478 & 52 & 342 & 465 & 8 & 155 & 2500 & 90813 \\ \hline
    \end{tabular}
  \end{center}
\end{table}

ただし，用例データベースでは，機能表現候補の先頭と末尾が形態素境界と一致
しない候補にも判定ラベルが付与されているが，本論文では，形態素解析結果に
基づいて機能表現を検出する立場をとるため，そのような機能表現候補に対する
判定ラベルは取り除くことにする．
具体的には，以下のような処理を行った．最初に，用例データベースに収録され
ている用例を，IPA品詞体系の形態素解析用辞書に基づいて動作する形態素解析
器ChaSenを用いて形態素解析した．次に，形態素解析結果中に，形態素解析用辞
書に「助詞・格助詞・連語」や「接続詞」として登録されている複合語が含まれ
ていた場合は，その複合語を，構成要素である形態素の列に置き換えた．このよ
うにして得られた形態素解析結果と機能表現候補を照合し，先頭と末尾が形態素
境界と一致しなかった176個の候補に対する判定ラベルを取り除いた．
取り除いた判定ラベルの内，175個は，人手によってラベルBと判定されている．
また，取り除いた手順より明らかに，この175個の判定ラベルに対応する機能表
現候補は，形態素解析結果のみに基づいてラベルBと判定することができる．し
たがって，これらの判定ラベルを取り除いても，機能表現検出の評価としては問
題はない．
取り除いた判定ラベルの内，残る1個は，人手によってラベルMと判定されている．
この判定ラベルは，形態素解析誤りによって取り除かれてしまったが，数が僅か
であり，無視することができる．

全データセットに含まれる各ラベルの数と，全形態素数を\tabref{tab:dataset}
に示す．1つの例文に，複数の機能表現候補が出現する場合があるため，機能表
現候補の総数は，例文の総数よりも多くなっている．

\subsection{評価尺度}
\label{subsec:評価尺度}

実験を評価する際の尺度には，以下の式で表される精度，再現率，F値，および
判別率を用いた．
\begin{align*} 
  \mbox{精度} &= \frac{\mbox{検出に成功したチャンク数}}{\mbox{解析によって検出されたチャンク数}} 
\\[0.5zh]
  \mbox{再現率} &= \frac{\mbox{検出に成功したチャンク数}}{\mbox{評価データに存在するチャンク数}} 
\\[0.5zh]
  \mbox{Ｆ値} &= \frac{2 \times \mbox{精度} \times \mbox{再現率}}{\mbox{精度} + \mbox{再現率}} 
\\[0.5zh]
  \mbox{判別率} &= \frac{\mbox{正解した判定ラベル数}}{\mbox{全判定ラベル数}} 
\end{align*}
また，実験は，10分割交差検定を用いて行った．

\subsection{既存の解析系に対する評価基準}
\label{subsec:既存の解析系}

既存の解析系(JUMAN/KNPおよびChaSen/CaboCha)は，形態素解析および構文解析
段階で処理が必要となる機能表現を，部分的に処理の対象としている．しかし，
明示的に機能表現を取り扱うという立場は取っていないため，機能表現のチャン
キングというタスクに対する既存の解析系の性能を評価するには，その出力をど
のように解釈するかを定めておく必要がある．

形態素解析器JUMANと構文解析器KNPの組み合わせでは，機能表現は以下のように
処理される．最初に，接続詞として形態素解析用辞書に登録されている機能表現
は，形態素解析時に検出される．次に，構文解析時に，解析規則に記述された特
定の形態素列が現れると，直前の文節の一部としてまとめたり，直前の文節から
の係り受けのみを受けるように制約を加えて，機能表現である可能性を考慮した
解析を行う．
一方，IPA品詞体系(THiMCO97)の形態素解析用辞書\cite{ipadic-2.6.1}を用い
た形態素解析器ChaSenと，京都テキストコーパス\cite{京都大学テキストコーパ
ス}から機械学習したモデルを用いた構文解析器CaboChaの組合わせでは，機能表
現は以下のように処理される．最初に，形態素解析用辞書に「助詞・格助詞・連
語」や「接続詞」として登録されている機能表現は，形態素解析時に検出される．
また，「ざるを得ない」などの表現は直前の文節の一部としてまとめられ，機能
的な表現として解析される．

本論文では，機能表現候補部分が，機能表現である可能性を考慮した解析の対象
となっている場合は，判定ラベルF, A, Mのいずれかが付与されているとみなし，
それ以外の場合は，判定ラベルC, Y, Bのいずれかが付与されているとみなすこと
にする．

既存の解析系でも，一部の機能表現については，機能的な働きをしていることを
考慮した解析が行われているが，その対応状況は不十分である．
判定ラベルF, A, Mのいずれかが付与されている用例の内，少なくとも1つの用例が，
機能的に働いている可能性を考慮して解析され，かつ，判定ラベルC, Y, Bのいず
れかが付与された用例の内，少なくとも1つの用例が，機能的に働いている可能
性を考慮せずに解析されている場合，その機能表現は，用法が正しく区別される
可能性があるとする．
用例データベースに50用例が収録されている表現で，かつ，機能的な意味で用い
られている場合と，それ以外の意味で用いられている場合の両方が適度な割合で
出現する表現は，52種類ある．本論文では，この52種類を対象とするが，その内，
JUMAN/KNPによって用法が正しく区別される可能性がある表現は，31種類である．
一方，ChaSen/CaboChaによって用法が正しく区別される可能性がある表現は26種
類である．
また，用例データベースに収録されている337表現全体では，新聞上の実際の用
法の割合に関係なく識別が必要と思われる表現は，111種類である．その内，
JUMAN/KNPによって用法が正しく区別される可能性がある表現は43種類，
ChaSen/CaboChaによって用法が正しく区別される可能性がある表現は40種類であ
る．


\subsection{評価結果}

\subsubsection{概要}

検出器Fおよび検出器FAMと，各ベースラインの検出性能を
\tabref{tab:kekka_gaiyou}に示す．

\tabref{tab:kekka_gaiyou}において，「頻度最大の判定ラベル」とは，全ての
候補部分に対して頻度最大の判定ラベル（ラベルF）を付与した場合の検出性能で
ある．「JUMAN/KNP」および「ChaSen/CaboCha」といった既存の解析系は，機能
表現の用法の区別を意識した検出は行わないため，ラベルF，A，Mを正解とする
評価のみを行った．「人手作成の規則による検出器」は，\ref{sec:human_rule} 
節で記述した手法による検出性能である．

\tabref{tab:kekka_gaiyou}中の「CRFを用いた検出器」は，Conditional Random
Fileds (CRF)\cite{CRF}によって学習・解析を行った場合の検出性能である．CRF 
とは，系列ラベリング問題のために設計された識別モデルであり，正しい系列ラ
ベリングを他の全ラベリング候補と弁別するような学習を行う．
本論文では，CRFによる学習・解析用ツールとして
CRF++\footnote{\url{http://chasen.org/~taku/software/CRF++/}}を利用した．
素性としては，前後2形態素の形態素素性，チャンク素性，チャンク文脈素性と，
直前2形態素のチャンクタグを用いた．学習時には，事前分布としてGaussian
Priorを用いて事後確率を最大化することにより，パラメータを正則化した\cite{kudo.IPSJNL2004}．
その際のハイパーパラメータとしては，1,2,3,4,5の5通りの値について予備実験を
行い，最も良い性能を示した1を採用した．

\begin{table}[t]
  \caption{各検出器の検出性能(\%)}
  \label{tab:kekka_gaiyou}
  \begin{center}
    {\footnotesize
    \begin{tabular}{l|p{104pt}||rrr|r||rrr|r} 
\hline
      & & \multicolumn{4}{c||}{検出器F} & \multicolumn{4}{c}{検出器FAM} \\ \cline{3-6}\cline{7-10}
      & & 精度 & 再現率 & F値 & 判別率 & 精度 & 再現率 & F値 & 判別率  \\ \hline \hline
      & 頻度最大の判定ラベル & 72.4 & 100 & 76.6 & 62.0 & 78.0 & 100 & 87.6 & 78.0 \\
      ベース & JUMAN/KNP & --- & --- & --- & --- & 89.2 & 49.3 & 63.5 & 55.8 \\
      ライン & ChaSen/CaboCha & --- & --- & --- & --- & 89.0 & 45.6 & 60.3 & 53.2 \\ \hline
      \multicolumn{2}{l||}{人手作成の規則による検出器} & 86.8 & 83.7 & 85.2 & 82.0 & 90.7 & 81.6 & 85.9 & 79.1 \\
      \multicolumn{2}{l||}{CRF を用いた検出器} & 82.0 & 85.9 & 83.9 & 79.3 & 84.9 & 87.4 & 86.1 & 81.1 \\ \hline
      SVMを & 形態素素性 & 85.1 & 89.2 & 87.1 & 85.5 & 88.0 & 91.0 & 89.4 & 86.5 \\
      用いた & 形態素素性，チャンク素性 & 87.6 & 91.1 & 89.3 & 87.9 & 91.0 & 93.2 & 92.1 & 89.0 \\
      検出器 & 形態素素性，チャンク素性，チャンク文脈素性 & 87.1 & 91.3 & 89.1 & 87.5 & 91.1 & 93.6 & 92.3 & 89.2 \\ \hline
    \end{tabular}
    }
  \end{center}
\vspace*{-6pt}
\end{table}

\tabref{tab:kekka_gaiyou}中の「SVM を用いた検出器」は，本論文の提案する 
SVM によるチャンキング手法による検出性能である．表より，提案手法は，学習・
解析に用いた素性に関わらず，ベースラインおよび人手作成の規則による検出よ
りも，高いF値を示した．また，提案手法は，CRFを用いた検出器よりも，高いF 
値を示した．

学習・解析に用いた素性の違いによる性能の違いを検討すると，形態素素性のみ
を用いた場合に比べて，形態素素性とチャンク素性を併用した場合の方が，F値
で2ポイント以上上回った．このことから，チャンク素性は，機能表現を検出す
るための素性として有効であったと言える．それに対して，形態素素性とチャン
ク素性を併用した場合と，形態素素性・チャンク素性・チャンク文脈
素性と全ての素性を使った場合に，性能の差は殆んど見られなかった．

全ての素性を用いて学習と解析を行った検出器Fおよび検出器FAMにおいて，他の
表現と比較して極端に検出性能が悪く，F値が50に達しなかった表現は，「とし
ては」と「にあたり」の2表現である．
例えば，\strref{ex:niatari-F}に含まれる「にあたり」は，「（新規参入という） 
時が来たのに当面して」という機能的な意味で用いられているため，判定ラベル
Fが付与されるべき文である．それに対して，\strref{ex:niatari-C}および
\strref{ex:niatari-C2}に含まれる「にあたり」は，内容的に用いられているた
め，判定ラベルCが付与されるべき文である．
\begin{example}
  \item 新規参入{\kern0pt}\uline{にあたり}，潜在的なニーズを掘り起こそうと，転勤族
	を主な対象にした．\label{ex:niatari-F} 
  \item お神酒の瓶が女性{\kern0pt}\uline{にあたり}，けがをする事故があった．
	\label{ex:niatari-C} 
  \item 米国の最先端の科学者が知恵を結集して原爆の開発{\kern0pt}\uline{にあたり}，
	一九四五年八月に広島・長崎に原爆が投下された．
	\label{ex:niatari-C2} 
\end{example}
しかし，SVMを用いた検出器Fおよび検出器FAMは，\strref{ex:niatari-F}と
\strref{ex:niatari-C}に対しては判定ラベルCを，\strref{ex:niatari-C2}に対
しては判定ラベルFを付与してしまい，用法を正しく判定できたのは
\strref{ex:niatari-C}のみだった．
仮に，\strref{ex:niatari-F}と\strref{ex:niatari-C}を区別することだけが必
要ならば，直前がサ変名詞であることが有効な素性として働く可能性があるが，
\strref{ex:niatari-C2}は，そのような素性だけではうまく判定できない．
このように，提案手法によっては適切に検出できない表現もごく少数ながら存在
するが，他の表現については，\tabref{tab:kekka_gaiyou}に示したように適切
に検出することができた．


\subsubsection{素性の比較}
前述の通り，形態素素性とチャンク素性を併用した場合と，
\pagebreak
形態素素性・チャンク素性・
チャンク文脈素性と全ての素性を使った場合に，性能の差
は殆んど見られなかった．
しかし，表現によっては，チャンク文脈素性が，検出の際に決定的な効果をもつ
表現も存在するはずである．そこで，実際にそのような効果が現れている表現が
存在するか，検出器FAMについて，形態素素性とチャンク素性のみ用いた場合の
検出性能と，チャンク文脈素性を含む全ての素性を用いた場合の検出性能を，表
現毎に比較した．

F値で比較したとき，全ての素性を用いた場合の検出性能が，形態素素性とチャ
ンク素性のみを用いた場合の検出性能を3ポイント以上上回っている表現は，以
下の8表現である．
\vspace{\NearBaselineskip}
\begin{center}
  \begin{tabular}{llll}
    といっても & としても & といえば & というものの \\
    にあたって & に応じて & にとり   & ことがある
  \end{tabular}
\end{center}
\vspace{\NearBaselineskip}

この8表現に対して，チャンク文脈素性を含めて全ての素性を用いた場合には検
出に成功した用例と，形態素素性とチャンク素性のみを用いた場合には検出に失
敗した用例を，比較・分析した．
例えば，「にあたって」の検出性能は，形態素素性とチャンク素性のみを用いた
場合にはF値で0.79だったのに対して，チャンク文脈素性を含めて全ての素性を
用いた場合にはF値で1.00となり，大きな改善が見られた．「にあたって」の用
例を分析したところ，機能表現候補の直後に，形態素解析用辞書において「動詞
・非自立」と分類されている語が現れていると，内容的に働いていると判
定できることが分かった．チャンク文脈素性を用いると，機能表現候補に後続す
る2形態素分の情報を検出時に利用することができるので，この手がかりを機械
学習することができ，検出性能が大きく向上したものと考えられる．
「にあたって」以外の7表現の用例についても，「にあたって」と同様の特徴的
なチャンク文脈素性が確認できた用例がいくつかあった．しかし，この7表現の
用例については，検出性能の改善に寄与したチャンク文脈素性は，それぞれの用
例に個別的で，全ての用例に共通するような素性は見い出されなかった．

逆に，F値で比較したとき，全ての素性を用いた場合の検出性能が，形態素素性
とチャンク素性のみを用いた場合の検出性能を3ポイント以上下回っている表現
は，以下の7表現である．
\vspace{\NearBaselineskip}
\begin{center}
  \begin{tabular}{llll}
    となれば & といいながら & かと思うと & ところを \\
    にしても & にあたり     & に従い
  \end{tabular}
\end{center}
\vspace{\NearBaselineskip}
この7表現についても，検出に成功した用例と失敗した用例とを比較したが，失
敗の原因は，それぞれの用例に個別的で，全ての用例に共通する原因は見い出さ
れなかった．そのため，これらの表現は，チャンク文脈素性がスパースであるた
めに，チャンク文脈素性を参照することによって性能が悪化したと考えられる．

このように，素性によって検出性能が良くなる表現と，検出性能が悪くなる表現
があることを考慮すると，
素性の異なる複数の検出器を組み合わせて検出すると
いう方法が考えられる．
この方法を採用した場合，\ref{sec:human_rule}章で述べた場合と同様に，複数
の機能表現候補に対する判定ラベルが相互に競合し，複数の検出器による検出結
果を同時に採用できない可能性がある．このような場合に対応するには，複数の
検出器による検出結果を統合するための枠組みが必要となるため，本論文では，
そのような複雑な手法は用いない（\ref{subsec:formalization}節）．


\subsubsection{SVMを用いたチャンキングと人手で作成した規則を用いた検出器の比較}

形態素素性とチャンク素性のみを用いた検出器FAMと，人手により作成した検出
規則を用いた手法\cite{形態素情報を用いた日本語機能表現の検出}による検出
器FAMに対して，前節と同様に，表現毎に性能を比較した．表現毎に見た場合，
人手規則を用いた検出器FAMのF値が，SVMを用いた検出器FAMのF値に比べて3ポイ
ント以上高い表現は，52表現中14表現存在した．
14表現の内，「にあたり」などの4表現は，SVMを用いた検出器FAMの精度が，人
手規則を用いた検出器FAMの精度を上回っているが，再現率は，人手規則を用い
た検出器FAMの方が上回っている．
人手規則を用いた検出器FAMでは，再現率を重視して判定規則が作成されている
ため，検出が困難な表現に対しても，高い再現率を維持できる．そのため，この
ような表現については，SVMを用いた検出器FAMに比べて，F値が高くなると考え
られる．
「に従い」などの10表現については，人手規則を用いた検出器FAMが，精度と再
現率の両方の尺度で，SVMを用いた検出器FAMを上回っていた．
例えば，\strref{ex:nishitagai-F}と\strref{ex:nishitagai-F2}に含まれる
「にしたがい」はいずれも機能的な意味で用いられており，判定ラベルFが付与
されるべきである．それに対して，\strref{ex:nishitagai-C}に含まれる「にし
たがい」は内容的に用いられているので，判定ラベルCが付与されるべきである．
\begin{example}
  \item 年齢を経る{\kern0pt}\uline{にしたがい}，体内の水分は減る．\label{ex:nishitagai-F}
  \item 晩年に向かう{\kern0pt}\uline{にしたがい}{\kern0pt}仕事の質が上がっている．\label{ex:nishitagai-F2}
  \item 二十年ごとに古い伝統の型{\kern0pt}\uline{にしたがい}{\kern0pt}社を建てかえる．\label{ex:nishitagai-C}
\end{example}
SVMを用いた検出器FAMは，\strref{ex:nishitagai-F}と
\strref{ex:nishitagai-C}は正しく判定できたが，\strref{ex:nishitagai-F2} 
には判定ラベルCを誤って付与した．これは直後の文脈を用いて誤った判定を行っ
ているのではないかと考えられる．それに対して，人手規則を用いた検出器FAM 
は，機能的に働いている機能表現候補の直前は用言であるという規則に基づいて，
3つの文を正しく判定した．
このように，表現毎に個別に見ると，人手によって作成された規則が，SVMより
も良い性能を示す場合はあるが，対象とする表現全体としては，SVMを用いた検
出器FAMの性能が，人手規則による検出器FAMの性能を上回っている．


\subsection{訓練データサイズの違いによる比較}

ここまでの実験では，用例データベースに基づいて作成した全データセットを訓
練データとして実験を行った．本節では，このデータサイズが，機能表現検出の
学習に十分であるか検討する．そのため，訓練データとして用いる判定ラベル数
を減少させた時，検出性能がどのように変化するかを調査した．結果を
\figref{fig:learning_curve}に示す．


\begin{figure}[b]
  \begin{center}
    \includegraphics[width=.7\textwidth]{06f3.eps}
  \end{center}
  \caption{訓練データサイズと学習性能の関係}
  \label{fig:learning_curve}
\end{figure}

\figref{fig:learning_curve}より，全データセットの約10分の1の判定ラベルの
みを訓練データとして用いた時は，検出性能が大きく低下しているが，判定ラベ
ル数の増加にともなって検出性能も向上し，全データセットに相当する判定ラベ
ル数付近では，対象とする表現全体に対する検出性能はほぼ飽和していることが
わかる．
したがって，チャンク文脈素性を参照することによって検出性能が悪化する7表
現を除いた残る45表現については，全データセットの分量で，機能表現検出の学
習に十分であると言える．
また，チャンク文脈素性を参照することによって検出性能が悪化する7表現につ
いても，形態素素性とチャンク素性を用いた検出器を学習するには，全データセッ
トの分量で十分であると言える．

\subsection{訓練データの作成コストの削減}

ここまでの実験では，文を単位として機械学習を行うため，文中に現れる全ての
機能表現候補に対して判定ラベルを付与した全データセットを，訓練データとし
て用いた．
しかし，このようにして訓練データを作成する方法には，以下のような問題が考
えられる．
\begin{itemize}
  \item 「という」などのように出現頻度の高い機能表現と，出現頻度の低い機
	能表現の収集数に差が生じ，学習に偏りが生じる恐れがある．
  \item 検出対象とする機能表現の種類を増やすと，たとえ例文数が一定であっ
	ても，機能表現候補の出現数が増加し，訓練データの作成コストが増大
	する．
\end{itemize}

これらの問題を解決するため，例文中に含まれる全ての機能表現候補に判定ラベ
ルを付与するのではなく，必要な一部の機能表現候補に限って判定ラベルを付与
する方法を検討する．
前者の問題を解決するためには，各機能表現に対する学習事例の数を一定にする
ことが考えられる．そのため，1表現に対して50用例が収録されている用例デー
タベースにおいて判定ラベルが付与されている機能表現候補と，その前後2形態
素のみを学習データとして用いるという方法を考えた．しかし，この方法では，
前後2形態素の範囲内に，判定ラベルがまだ付与されていない別の機能表現候補
が含まれている場合，誤った判定ラベルを用いて学習してしまうことがあり，予
備実験でも性能がかなり低下した．
この問題を避けるには，判定ラベルが付与されている機能表現候補の前後2形態
素の範囲内に，別の機能表現候補が出現していた場合は，その機能表現候補にも
判定ラベルを付与し，その候補の前後2形態素を範囲に加えるという操作を繰り
返し，判定ラベルが付与された機能表現候補とその前後2形態素のみを残すとい
う方法が考えられる．しかし，この方法でも，チャンクタグ{\bfseries O}に対
する学習事例の数が不十分なために，性能が低下した．
そのため，ここまでの操作によって判定ラベルが付与されなかった機能表現候補
を取り除き，それらによって分断された部分を，それぞれ1文とみなして学習を
行う方法を採用した．

例として，「ばかりだ」という機能表現の例文として，用例データベースに収録
されている\strref{ex:bakarida}を考える（``/''は形態素区切りを表す）．
\begin{example}
  \item /セミナー/開催/\underline{に/あたり}/，/最初/は/戸惑う/こと/\fbox{ばかり/だっ}/た/\underline{と/いう}/．/
	\label{ex:bakarida}
\end{example}
「ばかりだ」の前後2形態素の範囲内には，「という」という機能表現候補が含
まれている．そのため，この機能表現候補にも判定ラベルを付与し，この機能表
現候補の前後2形態素の範囲を判定ラベル付与の対象に加える．
\begin{example}
  \item /戸惑う/こと/\underline{ばかり/だっ}/た/\underline{と/いう}/．/
\end{example}
「にあたり」という機能表現候補には，この操作によっては，判定ラベルが付与
されない．この機能表現候補を取り除き，それによって分断された部分を，
\strref{ex:divided_sentence_1}と\strref{ex:divided_sentence_2}のようにそ
れぞれ1文とみなして学習を行う．
\begin{example}
  \item /セミナー/開催/ \label{ex:divided_sentence_1}
  \item /，/最初/は/戸惑う/こと/\underline{ばかり/だっ}/た/\underline{と/いう}/．/
	\label{ex:divided_sentence_2}
\end{example}

この手続きによって得られたデータセットを，以下では部分データセットと呼ぶ．
部分データセットに含まれる各ラベル数と，全形態素数を\tabref{tab:dataset} 
に示す．データセットの作成に必要な人手コストは，機能表現候補の出現数にほ
ぼ比例すると考えられる．したがって，\tabref{tab:dataset}より，部分データ
セットの作成に必要な人手コストは，全データセットの作成に必要な人手コスト
と比較して，かなり小さくなっていることが分かる．

この部分データセットを訓練データとして機能表現検出器を作成した場合の検出
性能を\tabref{tab:cost_F}に示す．学習・解析の素性としては，検出器Fについ
ては，形態素素性とチャンク素性を，検出器FAMについては，形態素素性，チャ
ンク素性およびチャンク文脈素性を用いた．部分データセットを訓練データとし
た場合の検出性能は，全データセットを訓練データとした場合の検出性能と比較
して，検出器Fについて約1.0ポイント，検出器FAMについて約0.8ポイント低下し
ている．しかし，この検出性能の低下は，データセットの作成に必要な人手コス
トの削減に対して，十分に小さい．したがって，上で述べた方法によって訓練デー
タの作成コストの削減ができているといえる．

\begin{table}
  \begin{center}
    \caption{訓練データの違いによる性能比較(\%)}
    \label{tab:cost_F}
    \begin{tabular}{c||c|c|c|c|c|c}
      \hline
      & \multicolumn{3}{c|}{検出器F} & \multicolumn{3}{c}{検出器FAM} \\ \cline{2-7}
      データセット & 精度 & 再現率 & F値 & 精度 & 再現率 & F値 \\
      \hline
      \hline
      全データセット & 87.6 & 91.1 & 89.3 & 91.1 & 93.6 & 92.3 \\
      部分データセット & 87.1 & 89.8 & 88.4 & 90.7 & 92.4 & 91.5 \\
      \hline
    \end{tabular}
  \end{center}
\vspace{11pt}
\end{table}


\section{関連研究}
\label{sec:関連研究}

\cite{Uchimoto04aj,Uchimoto04}は，話し言葉コーパス\cite{CSJ}を対象コーパ
スとして，半自動で精度良く短単位・長単位の2種類の粒度の形態論的情報を付
与する枠組みを提案している．
この枠組みでは，なるべく少ない人的コストで話し言葉コーパス全体に2種類の
粒度の形態素情報を付与するため，最初に短単位の解析を行い，次に，短単位の
形態素情報を素性として，短単位をチャンキングすることによって長単位の形態
素情報を付与するという手順を採っている．
例えば，「という」という機能表現は，短単位列としては助詞「と」および動詞
「いう」の連体形の2短単位に分割され，長単位としては助詞「という」という1 
長単位にチャンキングされる．
短単位から長単位をチャンキングするための機械学習手法としては，最大エント
ロピー法(ME)とSVMを比較し，SVMがより優れていると報告している．
内元らの研究は，話し言葉コーパス全体を対象としているのに対して，本論文で
は，機能表現に焦点をあてて検討を行っている点で異なる．
そのため，内元らは話し言葉コーパス中の長単位全体に対する形態素解析精度の
評価は行っているが，機能表現に特化した評価は行っていない．一方，本論文で
は，既存の解析系における機能表現の取り扱い状況を整理した上で，機能表現に
特化した性能評価を行っている．
また，本論文では，対象となる機能表現のリストを事前に用意しているため，形
態素列のどの部分が機能表現として検出される可能性があるかという情報（チャ
ンク素性およびチャンク文脈素性）を利用して，チャンキングを行うことができ
る．
機械学習手法としては，CRFとSVMを比較し，SVMの方が検出性能が高いことを示
している．

\cite{shudo.coling80,shudo.NL88,shudo.NLC98,shudo.mwe2004}は，機能表現や
慣用表現を含む複数の形態素からなる定型的表現をできるだけ網羅的に収集し，
機能表現間に類似度を定義して，機能表現の言い換えや機械翻訳に利用すること
を提案している．
\cite{hyoudo.NLC98,hyoudo.NLP99,hyoudo.NLP00}と\cite{isaji.NLP04}は，日
本語の文構造の解析を容易にするため，通常よりかなり長い文節を単位として解
析を行うことを提案し，機能表現を含む大規模な長単位機能語辞書を作成してい
る．
しかし，これらの先行研究における日本語処理系においては，機能表現と同一の
形態素列が内容的に振る舞う可能性が考慮されていない．


\section{おわりに}
\label{sec:おわりに}

本論文では，機能表現検出と形態素解析は独立に実行可能であると仮定した上で，
形態素を単位とするチャンク同定問題として機能表現検出タスクを定式化し，機
械学習手法を適用して機能表現の検出を実現した．
実際に，SVMを用いたチャンカーYamChaを利用して，形態素解析器ChaSenによる
形態素解析結果を入力とする機能表現検出器を実装し，52種類の機能表現を対象
として性能評価を行った．その結果，機械学習によって作成した機能表現検出器
は，既存の解析系および人手で作成した規則を用いた検出器よりも，高精度に機
能表現を検出できることを示した．
更に，訓練データの作成コストを削減する方法について検討し，訓練データを作
成するコストを大幅に削減しつつ，同時に，検出性能がほぼ同等の検出器を実現
できることを示した．

今後の研究課題として，検出対象とする機能表現の種類を増やし，その性能を評
価することを計画している．また，係り受け解析と機能表現検出を組み合わせる
ことにより，両者をより高精度に行う方法についても検討していきたい．


\begin{thebibliography}{}

\bibitem[\protect\BCAY{Cristianini \BBA\ Shawe-Taylor}{Cristianini \BBA\
  Shawe-Taylor}{2000}]{SVM}
Cristianini, N.\BBACOMMA\  \BBA\ Shawe-Taylor, J. \BBOP 2000\BBCP.
\newblock {\Bem An Introduction to {S}upport {V}ector {M}achines and {O}ther
  {K}ernel-based {L}earning {M}ethods}.
\newblock Cambridge University Press.

\bibitem[\protect\BCAY{Kudoh}{Kudoh}{2000}]{tinysvm}
Kudoh, T. \BBOP 2000\BBCP.
\newblock \BBOQ {TinySVM: Support Vector Machines}\BBCQ\
\newblock \url{http://cl.aist-nara.ac.jp/~taku-ku/software/TinySVM/index.html}.

\bibitem[\protect\BCAY{Lafferty, Mc{C}allum, \BBA\ Pereira}{Lafferty
  et~al.}{2001}]{CRF}
Lafferty, J., Mc{C}allum, A., \BBA\ Pereira, F. \BBOP 2001\BBCP.
\newblock \BBOQ Conditional {R}andom {F}ields: {P}robabilistic {M}odels for
  {S}egmenting and {L}abeling {S}equence {D}ata\BBCQ\
\newblock In {\Bem Proceedings of ICML}, \BPGS\ 282--289.

\bibitem[\protect\BCAY{松吉, 佐藤, 宇津呂}{松吉\Jetal
  }{2005}]{接続情報にもとづく助詞型機能表現の自動検出}
松吉俊, 佐藤理史, 宇津呂武仁 \BBOP 2005\BBCP.
\newblock \JBOQ 接続情報にもとづく助詞型機能表現の自動検出\JBCQ\
\newblock \Jem{言語処理学会第11回年次大会論文集}, \BPGS\ 1044--1047.

\bibitem[\protect\BCAY{中塚, 佐藤, 宇津呂}{中塚\Jetal
  }{2005}]{助動詞型機能表現の形態・接続情報と自動検出}
中塚裕之, 佐藤理史, 宇津呂武仁 \BBOP 2005\BBCP.
\newblock \JBOQ 助動詞型機能表現の形態・接続情報と自動検出\JBCQ\
\newblock \Jem{言語処理学会第11回年次大会論文集}, \BPGS\ 596--599.

\bibitem[\protect\BCAY{Shudo, Narahara, \BBA\ Yoshida}{Shudo
  et~al.}{1980}]{shudo.coling80}
Shudo, K., Narahara, T., \BBA\ Yoshida, S. \BBOP 1980\BBCP.
\newblock \BBOQ Morphological Aspect of Japanese Language Processing\BBCQ\
\newblock In {\Bem Proceedings of the 8th International Conference on
  Computational Linguistics (COLING'80)}, \BPGS\ 1--8.

\bibitem[\protect\BCAY{Shudo, Tanabe, Takahashi, \BBA\ Yoshimura}{Shudo
  et~al.}{2004}]{shudo.mwe2004}
Shudo, K., Tanabe, T., Takahashi, M., \BBA\ Yoshimura, K. \BBOP 2004\BBCP.
\newblock \BBOQ MWEs as Non-propositional Content Indicators\BBCQ\
\newblock In {\Bem Proceedings of the 2nd ACL Workshop on Multiword
  Expressions: Integrating Processing (MWE-2004)}, \BPGS\ 32--39.

\bibitem[\protect\BCAY{{Tjong Kim Sang}}{{Tjong Kim Sang}}{2000}]{Sang00a}
{Tjong Kim Sang}, E. \BBOP 2000\BBCP.
\newblock \BBOQ Noun Phrase Recognition by System Combination\BBCQ\
\newblock In {\Bem Proceedings of the 1st Conference of the North American
  Chapter of the Association for Computational Linguistics}, \BPGS\ 50--55.

\bibitem[\protect\BCAY{Uchimoto, Takaoka, Nobata, Yamada, Sekine, \BBA\
  Isahara}{Uchimoto et~al.}{2004}]{Uchimoto04}
Uchimoto, K., Takaoka, K., Nobata, C., Yamada, A., Sekine, S., \BBA\ Isahara,
  H. \BBOP 2004\BBCP.
\newblock \BBOQ Morphological Analysis of the Corpus of Spontaneous
  Japanese\BBCQ\
\newblock {\Bem IEEE Transactions on Speech and Audio Processing}, {\Bbf 12}
  (4).

\bibitem[\protect\BCAY{内元, 高岡, 野畑, 山田, 関根, 井佐原}{内元\Jetal
  }{2004}]{Uchimoto04aj}
内元清貴, 高岡一馬, 野畑周, 山田篤, 関根聡, 井佐原均 \BBOP 2004\BBCP.
\newblock \JBOQ 『日本語話し言葉コーパス』への形態素情報付与\JBCQ\
\newblock \Jem{第3回「話し言葉の科学と工学」ワークショップ論文集}, \BPGS\
  39--46.

\bibitem[\protect\BCAY{Vapnik}{Vapnik}{1998}]{Vapnik98a}
Vapnik, V.~N. \BBOP 1998\BBCP.
\newblock {\Bem Statistical Learning Theory (Adaptive and Learning Systems for
  Signal Processing, Communications, and Control)}.
\newblock John Wiley \& Sons Inc.

\bibitem[\protect\BCAY{兵藤, 若田, 池田}{兵藤\Jetal }{1998}]{hyoudo.NLC98}
兵藤安昭, 若田光敏, 池田尚志 \BBOP 1998\BBCP.
\newblock \JBOQ 文節ブロック間規則による浅い係り受け解析と精度評価\JBCQ\
\newblock \Jem{電子情報通信学会研究報告}, NLC98-30\JVOL.

\bibitem[\protect\BCAY{兵藤, 池田}{兵藤\JBA 池田}{1999}]{hyoudo.NLP99}
兵藤安昭, 池田尚志 \BBOP 1999\BBCP.
\newblock \JBOQ 文節単位のコストに基づく日本語文節解析システム\JBCQ\
\newblock \Jem{言語処理学会第5回年次大会発表論文集}, \BPGS\ 502--504.

\bibitem[\protect\BCAY{兵藤, 村上, 池田}{兵藤\Jetal }{2000}]{hyoudo.NLP00}
兵藤安昭, 村上裕, 池田尚志 \BBOP 2000\BBCP.
\newblock \JBOQ 文節解析のための長単位機能語辞書\JBCQ\
\newblock \Jem{言語処理学会第6回年次大会発表論文集}, \BPGS\ 407--410.


\bibitem[\protect\BCAY{土屋, 宇津呂, 松吉, 佐藤, 中川}{土屋\Jetal
      }{2006}]{日本語複合辞用例データベースの作成と分析}
    土屋雅稔, 宇津呂武仁, 松吉俊, 佐藤理史, 中川聖一 \BBOP 2006\BBCP.
\newblock \JBOQ 日本語複合辞用例データベースの作成と分析\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 47}  (6).

\bibitem[\protect\BCAY{土屋, 宇津呂, 佐藤, 中川}{土屋\Jetal
  }{2005}]{形態素情報を用いた日本語機能表現の検出}
土屋雅稔, 宇津呂武仁, 佐藤理史, 中川聖一 \BBOP 2005\BBCP.
\newblock \JBOQ 形態素情報を用いた日本語機能表現の検出\JBCQ\
\newblock \Jem{言語処理学会第11回年次大会発表論文集}, \BPGS\ 584--587.

\bibitem[\protect\BCAY{前川}{前川}{2004}]{CSJ}
前川喜久雄 \BBOP 2004\BBCP.
\newblock \Jem{『日本語話し言葉コーパス』の概観 ver.1.0}.
\newblock
  \url{http://www2.kokken.go.jp/~csj/public/members_only/manuals/overview10.pd
f}.

\bibitem[\protect\BCAY{首藤, 吉村, 武内, 津田}{首藤\Jetal }{1988}]{shudo.NL88}
首藤公昭, 吉村賢治, 武内美津乃, 津田健蔵 \BBOP 1988\BBCP.
\newblock \JBOQ 日本語の慣用的表現について
  ---語の非標準的用法からのアプローチ---\JBCQ\
\newblock \Jem{情報処理学会研究報告}, 1988-NL-66\JVOL, \BPGS\ 1--7.

\bibitem[\protect\BCAY{首藤, 小山, 高橋, 吉村}{首藤\Jetal }{1998}]{shudo.NLC98}
首藤公昭, 小山泰男, 高橋雅仁, 吉村賢治 \BBOP 1998\BBCP.
\newblock \JBOQ 依存構造に基づく言語表現の意味的類似度\JBCQ\
\newblock \Jem{電子情報通信学会研究報告}, NLC98-30\JVOL, \BPGS\ 33--40.

\bibitem[\protect\BCAY{国立国語研究所}{国立国語研究所}{2001}]{複合辞用例集}
国立国語研究所 \BBOP 2001\BBCP.
\newblock \Jem{現代語複合辞用例集}.

\bibitem[\protect\BCAY{松吉, 佐藤, 宇津呂}{松吉\Jetal
  }{2006}]{階層構造による日本語機能表現の分類}
松吉俊, 佐藤理史, 宇津呂武仁 \BBOP 2006\BBCP.
\newblock \JBOQ 階層構造による日本語機能表現の分類\JBCQ\
\newblock \Jem{言語処理学会第12回年次大会発表論文集}, \BPGS\ 408--411.

\bibitem[\protect\BCAY{浅原, 松本}{浅原\JBA 松本}{2003}]{ipadic-2.6.1}
浅原正幸, 松本裕治 \BBOP 2003\BBCP.
\newblock \JBOQ ipadic version 2.6.1 ユーザーズマニュアル\JBCQ\
\newblock \url{http://chasen.aist-nara.ac.jp/chasen/doc/ipadic-2.6.1-j.pdf}.

\bibitem[\protect\BCAY{工藤, 山本, 松本}{工藤\Jetal }{2004}]{kudo.IPSJNL2004}
工藤拓, 山本薫, 松本裕治 \BBOP 2004\BBCP.
\newblock \JBOQ Conditional Random Fields を用いた日本語形態素解析\JBCQ\
\newblock \Jem{情報処理学会研究報告}, 2004-NL-161\JVOL, \BPGS\ 89--96.

\bibitem[\protect\BCAY{工藤, 松本}{工藤\JBA 松本}{2002a}]{yamcha}
工藤拓,  松本裕治 \BBOP 2002a\BBCP.
\newblock \JBOQ {Support Vector Machine を用いた Chunk 同定}\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 9}  (5), pp.~3--21.

\bibitem[\protect\BCAY{工藤, 松本}{工藤\JBA 松本}{2002b}]{cabocha}
工藤拓, 松本裕治 \BBOP 2002b\BBCP.
\newblock \JBOQ チャンキングの段階適用による係り受け解析\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 43}  (6), pp.~1834--1842.

\bibitem[\protect\BCAY{黒橋, 河原}{黒橋\JBA 河原}{2005a}]{juman-5.1}
黒橋禎夫,  河原大輔 \BBOP 2005a\BBCP.
\newblock \Jem{日本語形態素解析システム{JUMAN} version 5.1 使用説明書}.
\newblock
  \url{http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman/juman-5.1.tar.gz}.

\bibitem[\protect\BCAY{黒橋, 河原}{黒橋\JBA 河原}{2005b}]{knp-2.0}
黒橋禎夫, 河原大輔 \BBOP 2005b\BBCP.
\newblock \Jem{日本語構文解析システム{KNP} version 2.0 使用説明書}.
\newblock \url{http://www.kc.t.u-tokyo.ac.jp/nl-resource/knp/knp-2.0.tar.gz}.

\bibitem[\protect\BCAY{黒橋 長尾}{黒橋\JBA
  長尾}{1997}]{京都大学テキストコーパス}
黒橋禎夫, 長尾眞 \BBOP 1997\BBCP.
\newblock \JBOQ 京都大学テキストコーパス・プロジェクト\JBCQ\
\newblock \Jem{言語処理学会第3回年次大会発表論文集}, \BPGS\ 115--118.

\bibitem[\protect\BCAY{松本, 北内, 山下, 平野, 松田, 高岡, 浅原}{松本\Jetal
  }{2003}]{chasen-2.3.3}
松本裕治, 北内啓, 山下達雄, 平野善隆, 松田寛, 高岡一馬, 浅原正幸 \BBOP
  2003\BBCP.
\newblock \JBOQ 形態素解析システム {C}ha{S}en version 2.3.3 使用説明書\JBCQ\
\newblock \url{http://chasen.aist-nara.ac.jp/chasen/doc/chasen-2.3.3-j.pdf}.

\bibitem[\protect\BCAY{森田, 松木}{森田\JBA 松木}{1989}]{日本語表現文型}
森田良行, 松木正恵 \BBOP 1989\BBCP.
\newblock \Jem{日本語表現文型}, \Jem{NAFL選書}, 5\JVOL.
\newblock アルク.

\bibitem[\protect\BCAY{伊佐治, 山田, 池田}{伊佐治\Jetal }{2004}]{isaji.NLP04}
伊佐治和哉, 山田将之, 池田尚志 \BBOP 2004\BBCP.
\newblock \JBOQ 長単位の機能語を辞書に持たせた文節構造解析システム ibukiC\JBCQ\
\newblock \Jem{言語処理学会第10回年次大会発表論文集}, \BPGS\ 636--639.

\end{thebibliography}

\begin{biography}
\bioauthor{土屋　雅稔}{
  1998年京都大学工学部 電気工学科第二学科 卒業．
  2004年京都大学大学院 情報学研究科 知能情報学専攻 博士課程単位認定退学．
  京都大学修士（情報学）．
  2004年より
  豊橋技術科学大学 情報メディア基盤センター 助手．
  自然言語処理に関する研究に従事．
}

\bioauthor{注連　隆夫}{
  2005年大阪府立大学工学部卒業．
  現在，京都大学大学院情報学研究科修士課程在学中．
  自然言語処理の研究に従事．
}

\bioauthor{高木　俊宏}{
  2006年京都大学工学部卒業．
  現在，同大学院情報学研究科修士課程在学中．
  通信ネットワークの研究に従事．
}

\bioauthor{内元　清貴}{
  1994年京都大学工学部電気工学第二学科卒業．
  1996年同大学院修士課程修了．博士（情報学）．
  同年郵政省通信総合研究所入所．
  現在，独立行政法人情報通信研究機構主任研究員．
  自然言語処理の研究に従事．
  言語処理学会，情報処理学会，ACL，各会員．
}

\bioauthor{松吉　　俊}{
  2003年京都大学理学部卒業．2005年同大学院情報学研究科修士課程修了．現在，
  同大学院情報学研究科博士後期課程在学中．自然言語処理の研究に従事．
}

\bioauthor{宇津呂武仁}{
  1989年京都大学工学部 電気工学第二学科 卒業．
  1994年同大学大学院工学研究科 博士課程電気工学第二専攻 修了．
  京都大学博士（工学）．
  奈良先端科学技術大学院大学 情報科学研究科 助手，
  豊橋技術科学大学 工学部 情報工学系 講師，
  京都大学 情報学研究科 知能情報学専攻 講師を経て，
  2006年より
  筑波大学 大学院システム情報工学研究科 知能機能システム専攻 助教授．
  自然言語処理の研究に従事．
}

\bioauthor{佐藤　理史}{
  1983年京都大学工学部電気工学第二学科卒業．
  1988年同大学院工学研究科博士後期課程電気工学第二専攻研究指導認定退学．
  京都大学工学部助手，北陸先端科学技術大学院大学情報科学研究科助教授，
  京都大学大学院情報学研究科助教授を経て，
  2005年より名古屋大学大学院工学研究科電子情報システム専攻教授．
  工学博士．自然言語処理，情報の自動編集等の研究に従事．
}

\bioauthor{中川　聖一}{
  1976年京都大学大学院博士課程修了．
  同年，京都大学情報工学科助手．1980年豊橋技術科学大学情報工学系講師．
  1990年教授．1985--1986年カーネギメロン大学客員研究員．
  音声情報処理，自然言語処理，人工知能の研究に従事．
  工学博士．
  1977年電子通信学会論文賞，1988年IETE最優秀論文賞，
  2001年電子情報通信学会論文賞，各受賞．
  電子情報通信学会フェロー．
  著書「確率モデルによる音声認識」（電子情報通信学会編），
  「音声聴覚と神経回路網モデル」（共著，オーム社），
  「情報理論の基礎と応用」（近代科学社），
  「パターン情報処理」（丸善），
  「Spoken Language Systems」（編著，IOS Press）など．
}

\end{biography}


\biodate

\end{document}
