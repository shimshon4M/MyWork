<?xml version="1.0" ?>
<root>
  <jtitle>レビューに対する評価指標の自動付与</jtitle>
  <jauthor>岡野原大輔	辻井潤一</jauthor>
  <jabstract>本論文では，ある対象を評価している文章（レビュー）が与えられた時，対象物に対する評価が「良い」か「悪い」かでレビューを二値分類するのではなく，どの程度「良い」か「悪い」かの指標（sentimentpolarityscore（SPscore））をレビューに与える新しいタスクを提案する．SPscoreはレビューの簡潔な要約であり，単純な「良い」か「悪い」かの二値分類より詳細な情報を与える．このタスクの難しさは連続した量であるSPscoreをどのようにしてレビューから得られるかにある．本稿ではsupportvectorregressionを用いてSPscoreを求める方法を提案する．5段階評価がついた本に対するレビューを用いた実験で，我々の手法がsupportvectormachinesを用いた多値分類より高い精度であり，人による指標の予測結果に近いことを示す．また，NaiveBayesClassifierを用いた文単位での主観性分析を用いることにより我々の手法の頑健性が増すことを示す．</jabstract>
  <jkeywords>評判分析，文章分類，機械学習</jkeywords>
  <section title="Introduction">Inrecentyears,discussiongroups,onlineshops,andblogsystemsontheInternethavegainedpopularity,andthenumberofdocuments,suchasreviews,isgrowingdramatically.Sentimentclassificationreferstoclassifyingreviewsnotbytheirtopicsbutbythepolarityoftheirsentiment(e.g,positiveornegative).Itisusefulforrecommendationsystems,fine-grainedinformationretrievalsystems,andbusinessapplicationsthatcollectopinionsaboutacommercialproduct.Recently,sentimentclassificationhasbeenactivelystudiedandexperimentalresultshaveshownthatmachinelearningapproachesperformwell.Thepresentstudyasserts,however,thatthepolarityofreviewscanbeestimatedmorepreciselythanispossiblewithexistingclassificationtechniques.Forexample,bothreviewsAandBinTablewouldbeclassifiedsimplyaspositiveinbinaryclassification,butclearlythisclassificationlosesinformationconcerningthedifferenceinthedegreeofpolaritythatisapparentinthereviewtexts.Weproposeanoveltypeofdocumentclassificationtaskwhereweevaluatereviewswithscores,suchasselectingfromascaleofonetofivestarsforexample.Wecallthisscorethesentimentpolarityscore(SPscore).If,forexample,therangeofthescoreisfromonetofive,wecouldgivefivetoreviewAandfourtoreviewB.Thistask,namely,orderedmulti-classclassification,isconsideredasanextensionofbinarysentimentclassification.Inorderedmulti-classclassification,theclassesarenotindependent,butareordered.Whileitispossibletotreatthisproblemasamulti-classclassificationtaskignoringtheorderinformation,theperformanceoftheclassifiercanbeimprovedbyincorporatingthisinformationintotheclassifier.Inthispaper,wedescribeamachinelearningmethodforthistask.Oursystemusessupportvectorregression(SVR)todeterminetheSPscoresofreviews.ThismethodenablesustoannotateSPscorestoarbitraryreviews,suchascommentsinbulletinboardsystemsorblogsystems.Weexploreseveraltypesoffeaturesbeyondabag-of-wordstocapturekeyphrasestodetermineSPscores:n-gramsandreferences(thewordsaroundthereviewedobject).Inaddition,oursystemdeterminesthesubjectivityofeachsentenceusingaNaiveBayesclassifier,sinceareviewincludesmanyirrelevantsentences.Thisapproachperformswellwhentrainingdataincludesmanyirrelevantsentences,butmayleadtoareductionintheclassifier'saccuracy.ThisisbecauseNaiveBayesclassificationcannotcorrectlyclassifysubjectivesentencescompletely,whileobjectivesentencescancontaininformationthatisusefulindeterminingSPscores.Weshowthatthisproblemcanbeovercome,however,simplybyaddingaconstantfactortotheNaiveBayesestimation.Weconductedexperimentswithbookreviewsfromamazon.com,eachofwhichhadafive-pointscaleratingalongwithtext.Wecomparedpairwisesupportvectormachines(pSVMs)andSVRandfoundthatSVRoutperformedbetterthanpSVMsbyabout30%intermsofthesquarederror,whichisclosetohumanperformance.WealsodemonstratedthatthedetectionofsentencesubjectivitybyusingaNaiveBayesclassifierimprovedtherobustnessoftheclassifier.</section>
  <section title="Related Work">Recentstudiesonsentimentclassificationfocusedonmachinelearningapproaches.PangrepresentsareviewasafeaturevectorandestimatespolarityusingSVM,whichisalmostthesamemethodasthoseusedfortopicclassification.Thispaperessentiallyfollowsthiswork,butweextendthistasktoanorderedmulti-classclassificationtask.Therehavebeenmanyattemptstoanalyzereviewstoadeeperlevelinordertoimproveaccuracy.Mullenusedfeaturesfromvariousinformationsourcessuchasreferencestothe``work''or``artist'',whichwereannotatedbyhand,andshowedthatthesefeatureshavethepotentialtoimproveaccuracy.Weusereferencefeaturesgivenbythewordsaroundthefixedreviewtargetword(``book'').Turneyusedsemanticorientation,whichmeasuresthedistancefromphrasesto``excellent''or``poor''byusingsearchengineresultsandgivesthewordpolarity.Kudouseddecisionstumpstocapturesubstructuresembeddedintext(suchasword-baseddependency),andsuggestedthatsubtreefeaturesareimportantforopinion/modalityclassification.Independentlyofandinparallelwithourwork,twootherpapersconsiderthedegreeofpolarityforthepurposesofsentimentclassification.Koppelexploitedaneutralclassandappliedaregressionmethodsimilartothatofthepresentstudy.Pangappliedametriclabelingmethodforthetaskinwhichsimilarreviewstendtohavesamepolarities.Ourworkdiffersfromthesetwostudiesinseveralrespects.Inthepresentstudyevaluationwascarriedoutbyexploitingsquareerrorsratherthanprecisionerrors,withafive-pointscoringscaleusedintheexperiments,incontrasttoKoppel,whousedthree(``good'',``bad'',``neutral''),andPang,whousedthree/fourpointscores.Thereforeweuseregressionwhichminimizenotaprecisionerrorbutasquareerror.Wearguethattheprecisionerrorsarenotenoughtocapturethetask.Becauseifweusetheprecisionerrorsmistakesofassigning5SPscoretoareviewwhosecorrectSPscoreis1canoccurmanytimes,whichbecomesunacceptableprobleminrealapplications.Wealsoexaminevariousfeaturestocapturethecharacteristicsofreviews,whicharefoundtobeeffectiveinexperiences.</section>
  <section title="Analyzing Reviews with Polarity Scores">Inthissectionwepresentanoveltasksettingwherewepredictthedegreeofsentimentpolarityofareview.WefirstdefineSPscoresandthetaskofassigningthemtoreviewdocuments.Wethendescribethepresentevaluationdataset.Usingthisdataset,weexaminedtheperformanceofhumanclassifiersonthistask,toclarifythedifficultyofquantifyingpolarity.</section>
  <subsection title="Sentiment Polarity Scores">Weextendthesentimentclassificationtasktothemorechallengingtaskofassigningratingscorestoreviews.WecallthisscoretheSPscore.ExamplesofSPscoresincludefive-starscalesandscoresoutof100.LetSPscorestakediscretevaluesinaclosedinterval[min...max].ThetaskistoassigncorrectSPscorestounseenreviewsasaccuratelyaspossible.LetybethepredictedSPscoreandybetheSPscoreassignedbythereviewer.Wemeasuretheperformanceofanestimatorwiththemeansquareerror,where(x_1,y_1),...,(x_n,y_n)isthetestsetofreviews.Incontrasttoconventionalmulti-classclassification,whichgivesequalpenaltiestoallmistakes,penaltiesforthepresentestimatorarelargerwhenthemistakeinpredictedSPscoreislarge.Ordinalregressionisanotherframeworktopredictvariablesofordinalscale.SinceourtasksettinggivesalargepenaltyforlargemistakeinSPscore,theregressionapproachismoresuitableforthetaskthanordinalregressionwhichconsidersonlymistakesfororderofSPscore.Wealsonotetheefficiencyoftraining.Inseveralmethodsofordinalregressiontheproblemsizeisaquadraticfunctionofthetrainingdatasizewhichisnotaccptablefortrininglargedata.Ourmethoduseswell-studiedformulations(SVMs,SVR)andcanemployefficientalgorithmsandsoftwares.</subsection>
  <subsection title="Evaluation Data">Weusedbookreviewsonamazon.comforevaluationdata^,.Eachreviewhasstarsassignedbythereviewer,withthenumberofstarsrangingfromonetofive,whereoneistheworstscore,whilefiveisthebest.WeconvertedthenumberofstarsintoSPscores1,2,3,4,5.Althougheachreviewmayincludeseveralparagraphs,wedidnotexploitparagraphinformation.Fromthesedata,wemadetwodatasets.ThefirstwasasetofreviewsforbooksintheHarryPotterseries(CorpusA).Thesecondwasasetofreviewsforbooksofarbitrarykinds(CorpusB).ItwaseasiertopredictSPscoresforCorpusAthanCorpusBbecauseCorpusAbookshaveasmallervocabularyandeachreviewwasabouttwiceaslarge.Tocreateadatasetwithauniformscoredistribution(theeffectofskewedclassdistributionsisoutofthescopeofthispaper),weselected330reviewsperSPscoreforCorpusAand280reviewsperSPscoreforCorpusB.Tableshowsthenumberofwordsandsentencesinthecorpora.Thereisnosignificantdifferenceintheaveragenumberofwords/sentencesamongdifferentSPscores.</subsection>
  <subsection title="Preliminary Experiments: Human Performance for Assigning SP scores">WetreattheSPscoresassignedbythereviewersascorrectanswers.However,thecontentofareviewanditsSPscoremaynotberelated.Moreover,SPscoresmayvarydependingonthereviewers.Accordingly,weexaminedtheuniversalityoftheSPscore.WeaskedtwocomputationallinguiststoindependentlyassignanSPscoretoeachreviewfromCorpusA.ThesetwolinguistsfirstlearnedtherelationshipbetweenreviewsandSPscoresusing20reviews,andwerethengiven100reviewswithauniformSPscoredistributionastestdata.Tableshowstheresultsgivenintermsofthemeansquareerror.TheRandomrowshowstheperformanceachievedbyrandomassignment,andtheAll3rowshowstheperformanceachievedbyassigning3toallthereviews.TheseresultssuggestthatSPscoreswouldbeestimatedsolelyfromthecontentsofreviewswithasquareerrorof0.78.TableshowsthedistributionoftheestimatedSPscoresandcorrectSPscores.Inthetablewecanobservethedifficultyofthistask;theprecisequantificationofSPscores.Forexample,itcanbeseenfromthetablethathumanBtendedtooverestimateSPscoresforreviewswhosecorrectscoreswereintherangebetween2and4,assigninga1or5.WeshouldnotethatifweconsiderthistaskasbinaryclassificationbytreatingthereviewswhoseSPscoresare4and5aspositiveexamplesandthosewith1and2asnegativeexamples(ignoringthereviewswhoseSPscoresare3),theclassificationprecisionsbyhumansAandBare95%and96%respectively.</subsection>
  <section title="Assigning SP scores to Reviews">ThissectiondescribesamachinelearningapproachtopredicttheSPscoresofreviewdocuments.Ourmethodconsistsofthefollowingtwosteps:extractionoffeaturevectorsfromreviews,andestimationofSPscoresfromthesefeaturevectors.Thefirststepbasicallyusesexistingtechniquesfordocumentclassification.Incontrast,thepredictionofSPscoresisdifferentfrompreviousstudiesbecauseweconsiderorderedmulti-classclassification,thatis,eachSPscorehasitsownclassandtheclassesareordered.Unlikeusualmulti-classclassification,largemistakesintermsoftheordershouldhavelargepenalties.Inthispaper,wediscusstwomethodsofestimatingSPscores:pSVMsandSVR.</section>
  <subsection title="Review Representation">Werepresentareviewasafeaturevector.Althoughthisrepresentationignoresthesyntacticstructure,wordpositions,andtheorderofwords,itisknowntoworkreasonablywellformanytaskssuchasinformationretrievalanddocumentclassification.Weusebinary,tf,andtf-idfasfeatureweightingmethods.ThefeaturevectorsarenormalizedtohaveL^2norm1.</subsection>
  <subsection title="Support Vector Regression">Supportvectorregression(SVR)isamethodofregressionthatfollowsasimilarunderlyingideatothatofSVM.SVRpredictstheSPscoreofareviewbythefollowingregression:whereyisthepredictedSPscore,xisthefeaturevectorofareview,wandbareparametersofSVR.SVRusesan-insensitivelossfunction.Thislossfunctionmeansthatallerrorsinsideancubeareignored.ThisallowsSVRtorequireonlyafewsupportvectors,andgivesageneralizationability.Givenatrainingset,(x_1,y_1),....,(x_n,y_n),parameterswandbaredeterminedbysolvingthefollowingproblem,minimize&amp;12ww+C_i=1^n(_i+_i^*)subjectto&amp;(wx_i+b)-y_i&amp;+_i&amp;y_i-(wx_i+b)&amp;+_i^*_i^(*)0&amp;i=1,...,n.eqnarrayThefactorC&gt;0isaparameterthatcontrolsthetrade-offbetweentrainingerrorminimizationandmarginmaximization.ThelossintrainingdataincreasesasCbecomessmaller,whilegeneralizationislostasCbecomeslarger.Moreover,wecanapplyakernel-tricktoSVR,asinthecaseforSVMs,byusingakernelfunction.Thisapproachcapturestheorderofclassesanddoesnotsufferfromdatasparseness.WhilewecoulduseconventionallinearregressioninsteadofSVR,inthepresentstudyweuseSVRbecauseitcanexploitthekernel-trickandavoidover-training.AnothergoodcharacteristicofSVRisthatwecanidentifythefeaturescontributingtodeterminingtheSPscoresbyexaminingthecoefficients(win()),whilepSVMsdonotgivesuchinformation,becausemultipleclassifiersareinvolvedindeterminingfinalresults.Adifficultyassociatedwiththepresentapproach,however,isthatitisdifficulttolearnnon-linearregressionbySVR.Forexample,whengiventrainingdatais(x=1,y=1),(x=2,y=2),(x=3,y=8),SVRcannotperformregressioncorrectlywithoutadjustingtheinputspace(featurevalues)sothattheoutputplanebecomeslinear-one.Notethatthisproblemdoesnotoccurinclassificationproblems,butinregressionproblems.Wecansolvethisproblembychoosinganappropriatekernelforthetask,butthisselectionisnotstraightforward.</subsection>
  <subsection title="Pairwise Support Vector Machines">Weapplyamulti-classclassificationapproachtoestimatingSPscores.pSVMsconsidereachSPscoreasauniqueclass,ignoringtheorderamongtheclasses.GivenreviewswithSPscores1,2,..,m,weconstructm(m-1)/2SVMclassifiersforallthepairsofpossiblevaluesofSPscores.TheclassifierforanSPscorepair(avsb)assignstheSPscoretoareviewwithaorb.Theclasslabelofadocumentisdeterminedbymajorityvotingoftheclassifiers.AnytiesinthevotingareresolvedbychoosingtheclassthatisclosesttotheneutralSPscore(i.e,(1+m)/2).ThisapproachignoresthefactthatSPscoresareordered,whichcausesthefollowingtwoproblems:First,itallowslargemistakes.Second,whenthenumberofpossiblevaluesoftheSPscoreislarge(e.g,n&gt;100),thisapproachsuffersfromadatasparsenessproblem.ThisisbecausepSVMscannotemployexamplesthathavecloseSPscores(e.g,SPscore=50)fortheclassificationofotherSPscores(e.g,theclassifierforaSPscorepair(51vs100)).</subsection>
  <subsection title="Features beyond Bag-of-Words">Previousstudiessuggestedthatcomplexfeaturesdonotworkasexpectedbecausedatabecomessparsewhensuchfeaturesareused,andabag-of-wordsapproachissufficienttocapturetheinformationinmostreviews.Nevertheless,weobservedthatreviewsincludemanychunksofwordssuchas``verygood''or``mustbuy''thatareusefulforestimatingthedegreeofpolarity.Weconfirmedthisobservationbyusingn-grams.SincethewordsaroundthereviewtargetmightbeexpectedtoinfluencetheoverallSPscoremorethanotherwords,weusethesewordsasfeatures.Wecallthesefeaturesreference.Weassumethereviewtargetisonlytheword``book'',andweuse``inbook''and``aroundbook''features.The``inbook''featurearethewordsappearinginthesentencewhichincludestheword``book''.The``aroundbook''featureisgivenbythewordslyingwithintwoplaceseithersideoftheword``book''.Tablesummarizesthelistoffeaturesfortheexperiments.</subsection>
  <subsection title="Identification of Subjectivity Sentences">Areviewdocumentincludesmanysentencesthatareirrelevanttosentimentpolarityofthedocument,suchasexplanationofareviewedobjectorobjectivesentences.Thereexistsomemethodsfordetectingsubjectivesentencesbyaknowledge-basedapproachormachinelearning.Here,weproposeamethodforestimatingtheprobabilitythatagivensentenceissubjectiveusingNaiveBayesclassifiers(furtherdetailsandotherNaiveBayesmodelscanbefoundin).Figureshowsanoverviewofourapproach,thatis,weassigntheprobabilitythatagivensentenceinreviewissubjective,andthenweighteachfeatureusingthisprobability.Althoughitishardtoobtainacorpusinwhichindividualsentencesareannotatedwithwhetherthesentenceisobjectiveorsubjective,wecanobtaindocumentsconsistingofsubjectiveorobjectivesentencesonly.Usingthesedocuments,weconstructaNaiveBayesclassifiertoestimatetheprobabilityofeachsentence'ssubjectivity.Weassignaclasswhichmaybeeithersubjective(sub)orobjective(obj)toeachsentence(s_i).WeuseamultinomialNaiveBayesClassiertoestimatetheprobabilitysentencesubjectivityp(sub|s_i),p(sub|s_i)&amp;=p(sub)p(s_i|sub)p(s_i)	&amp;=p(sub)p(s_i|sub)p(sub)p(s_i|sub)+p(obj)p(s_i|obj).alignWedecomposep(s_i|sub)andp(s_i|obj)intotheprobabilityofp(w_t|sub)andp(w_t|obj),w_ts_i,p(s_i|sub)&amp;=C_t=1^|s_i|p(w_t|sub),p(s_i|obj)&amp;=C_t=1^|s_i|p(w_t|obj),&amp;=P(|s_i|)|s_i|!_t=1^|V|1|w_j|w_j=w_t,w_js_i|!.alignWesubstituteexpressions()and()intoequation(),andobtainWeestimatep(w_t|sub),p(w_t|obj),p(sub),p(obj)fromtrainingdata.Thetrainingdataconsistsofsubjectivesentencess_1,s_2,..,s_mandobjectivesentencess_1,s_2,...,s_m.Letc_sub(w_t)bethefrequencyofthewordw_tinthesubjectivecorpus,andc_obj(w_t)bethefrequencyofthewordw_tintheobjectivecorpus,thentheaboveparametersaregivenbyp(w_t|sub)&amp;=p(w_t)p(sub|w_t)p(sub)&amp;=1+c_sub(w_t)|V|+_s=1^V(c_sub(w_s)),(w_t|obj)&amp;=1+c_obj(w_t)|V|+_s=1^V(c_obj(w_s)),(sub)&amp;=p(obj)=12.alignWeuseLaplaciansmoothingforestimatingp(w_t|sub),p(w_t|obj).Usingp(sub|s_i),weweighteachsentence.Usingtheprobabilityp(sub|s_i),werecalculatethevalueofeachfeature.Thedisadvantageofthisapproachisthattheinformationofthetrainingdatabecomessmallincomparisonwiththeoriginaldata,becausetheestimationofNaiveBayesclassificationtendstooverestimatetheprobability.Forexample,evenifthetrueprobabilityiscloseto0.5,theresultofNBwouldbe0or1.Futhermore,theobjectivesentencesmayhaveinformationthatcouldbeusefulindeterminingtheSPscores.Wethereforeintroduceasmoothingfactor,whichmeansthatweassignesprobabilityfromto1(byignoringthenormalizationfactor).Thefeaturevectorsforareviewarecalculatedasfollows:thefirst(x)istheoriginalfeaturevector,thesecondx_NBisafeaturevectorweightedbytheprobabilitythattheparticularsentenceissubjective,whilethethird(x_NBS)isafeaturevectorwhichissmoothedbyusingthepre-definedsmoothingfactor(),x&amp;:=_i=1^m(f(s_i)),_NB&amp;:=_i=1^m(p(sub|s_i)f(s_i)),_NBS&amp;:=_i=1^m((p(sub|s_i)+)f(s_i)),alignwheref(s_i)isthefeaturevectorforthesentences_i.Thefeaturevaluesinx_NBandx_NBScanbeconsideredtobetheexpectedfeaturevaluesinasubjectivesentence.Wecouldalternativelyadoptanapproachwherebyfirsttheobjectivesentencesareeliminated,andthenwesolvetheproblemasbefore.Thisapproachwouldbefasterthanourapproachsincethetrainingdataissmallerthantheoriginaltrainingdataset.However,theresultsofthisapproachwouldbelessaccuratethanourapproachusingthefeaturevectorsxandx_NB,sincethesevectorscanbeseenasanapproximationoffeaturevalues.However,clearlywecantradeoffthespeedandaccuracyoftheclassifierbythechoiceofapproach,andweplantoinvestigatethisfurtheraspartoffuturework.</subsection>
  <section title="Experiments">Weperformedtwoseriesofexperiments.First,wecomparedpSVMsandSVRandexaminedtheperformanceofvariousfeaturesandweightingmethods.Second,wecomparedthemethodusingsentencesubjectivitydetectionwiththemethodwhichdoesnot.ThecorporaAandBintroducedinSectionwereusedastheexperimentaldata.WefirstremovedallHTMLtagsandpunctuationmarks,andthenappliedthePorterstemmingmethodtothereviews.Wedividedthedataintotendisjointsubsets,maintainingtheuniformclassdistribution.Alltheresultsreportedbelowaretheaveragesoften-foldcross-validation.InSVMsandSVR,weusedSVMlightwiththequadraticpolynomialkernelK(x,z)=(xz+1)^2andsetthecontrolparameterCto100inalltheexperiments.Forsentencesubjectivitydetection,weusedPang'ssentencecorpusversion1.0.</section>
  <subsection title="Comparison of pSVMs and SVR">WecomparedpSVMsandSVRtoseedifferencesinthepropertiesoftheregressionapproachcomparedwiththoseoftheclassificationapproach.BothpSVMsandSVRusedunigram/tf-idftorepresentreviews.TableshowsthesquareerrorresultsforSVM,SVRandasimpleregression(leastsquareerror)methodforCorpusA/B.TheseresultsindicatethatSVRoutperformedSVMintermsofthesquareerrorandsuggeststhatregressionmethodsavoidlargemistakesbytakingaccountofthefactthatSPscoresareordered,whilepSVMsdoesnot.WealsonotethattheresultofasimpleregressionmethodisclosetotheresultofSVRwithalinearkernel.Figureshowsthedistributionofestimationresultsforhumans(topleft:humanA,topright:humanB),pSVMs(belowleft),andSVR(belowright).InalltheplotsthehorizontalaxesshowtheestimatedSPscores,theverticalaxesshowthecorrectSPscores,whileshadingindicatesthenumberofreviews.ThesefiguressuggestthatpSVMsandSVRwereabletocapturethegradualnessofSPscoresbetterthanthehumanclassifiers.TheyalsoshowthatpSVMscannotpredictneutralSPscoreswell,whereasSVRaccuratelypredictsthesescores.</subsection>
  <subsection title="Comparison of Different Features">WecomparedthedifferentfeaturespresentedinSectionandfeatureweightingmethods.Firstwecompareddifferentweightingmethods,usingonlyunigramfeaturesforthiscomparison.Wethencompareddifferentfeatures,usingonlytf-idfweightingmethodsforthiscomparison.Tablesummarizesthecomparisonresultsofdifferentfeatureweightingmethods.Theresultsshowthattf-idfperformedwellonbothtestcorpora.Weshouldnotethatsimplerepresentationmethods,suchasbinaryortf,givecomparableresultstotf-idf,whichindicatesthatwecanaddmorecomplexfeatureswithoutconsideringthescaleoffeaturevalues.Forexample,whenweaddword-baseddependencyfeatures,wehavesomedifficultyinadjustingthesefeaturevaluestothoseofunigrams.However,wecouldusethesefeaturestogetherinbinaryweightingmethods.Tablesummarizesthecomparisonresultsfordifferentfeatures.ForCorpusA,unigram+bigramandunigram+trigramachievedhighperformance.Theperformanceofunigram+inbookdoesnotachieveasgoodaperformanceasexpected,contrarytoourintuitivebeliefthatthewordsaroundthetargetobjectaremoreimportantthanothers.However,forCorpusB,theresultsarelessaccurate,thatis,n-gramfeatureswerelessabletoaccuratelypredicttheSPscores.Thisisbecausethevarietyofwords/phraseswasmuchlargerthaninCorpusA,andn-gramfeaturesmayhavesufferedfromadatasparsenessproblem.Weshouldnotethatthesefeaturesettingsaretoosimple,andwecannotaccepttheresultofreferenceortargetobject(inbook/aroundbook)directly.NotethatthedatausedinthepreliminaryexperimentsdescribedinSectionareapartofCorpusA,andsowecancomparetheresultsobtainedfromthehumanclassifierswiththoseforCorpusAinthisexperiment.Thebestresultbythemachinelearningapproach(0.89)wasclosetothehumanresults(0.78).Toanalyzetheinfluenceofn-gramfeatures,weusedthelinearkernelk(x,z):=xzinSVRtraining.Weusedtf-idfasfeatureweighting,andexaminedeachcoefficientofregression.Sinceweusedthelinearkernel,thecoefficientvalueofSVRshowedthepolarityofasinglefeature,thatis,thisvalueexpressedhowmuchtheoccurrenceofaparticularfeatureaffectedtheSPscore.Tables,,,,andshowthecoefficientsresultingfromthetrainingofSVR.Theseresultsshowthatphrasessuchas``allag(age)'',``can'twait''``on(one)star''and``notinterest''havestrongpolarityevenifthewordwhichconstitutesthesephrasesdoesnothavestrongpolarity.</subsection>
  <subsection title="Using Naive Bayes Classifier to Subjectivity Detection">WeexaminedtheeffectivenessofsubjectivitydetectionusingtheNaiveBayesclassifier(NB)proposedinSection.First,weexaminedtheperformanceofNBitselfbyusingPang'ssentencecorpusversion1.0.Theresultoften-foldcross-validationwas90.5%accuracy.Areview,however,includesbothsubjectiveandobjectivesentences.Moreover,wehavetoexaminewhethertheinformationofsubjectivitycontributestothepolaritydetection.WeaskedtwocomputerlinguiststoselectthesentencewhichismostinfluentialontheSPscoreineachreview.ThetestdataisthesameasthetestdatausedinSection.WethenassignedsubjectivityforeachsentenceusingtheNB.Tableshowstheaveragesubjectivityofallsentencesandalsoofthemostinfluentialsentencesasselectedbythehumanclassifiers.ItisalmostcertainthatsubjectivityiscorrelatedwiththesentencethatismostinfluentialontheSPscore.FigureshowsexamplesoftheresultsofsentencesubjectivitydetectionbytheNB.TheresultssuggestthattheNBanalyzesthesubjectivityofsentenceswell.Forinstance,explanationsoftheplotofthenovel(lines2inreview1)areassigned0.00subjectivity.Second,weevaluatedtheperformanceofclassificationusingNBsentencesubjectivitydetection.Tableshowstheresultsbybaseline(SVR+tfidf+unigram),NB(baseline+NBsentencesubjectivitydetection(Eq.~))andNBwithC(baseline+NBsentencesubjectivitydetectionwithaddedconstant=0.5(Eq.~)).TheresultsindicatethatNBisbetterthanbaselinewhenthetrainingdataandtestdataaredifferent,especiallywhenthetrainingdataiscorpusBandtestdataiscorpusA.Wesuspectthatwhenweusereviewstakenfromvariousthemesastrainingdata,somepropernounshavepolarityandthesewordscausetheclassifiertobemisledtothewrongpolarity.Incontrast,whenweusereviewsonaspecificthemeastrainingdata,propernounstendtooccuruniformlythroughallSPscores,andtheeffectsofpropernounsonpolarityscoresarenotoverestimated.ThedeclineofaccuracybyNBincorporaAandBisprobablycausedbytheinadequateperformanceofNaiveBayesclassifiersorlossofusefulinformationinobjectivesentences.NBwithCperformswellineachcase,suggestingthatNBwithChastheadvantagesofobjectivesentenceeliminationwithoutsufferinganysignificantdeclineduetothelossofinformationinobjectivesentences.</subsection>
  <subsection title="Learning Curve">Wegeneratedlearningcurvestoexaminetheeffectofthesizeoftrainingdataonperformance.Figureshowstheresultsofaclassificationtaskusingunigram/tf-idftorepresentreviews.Theresultssuggestthatperformancecanbeimprovedfurtherbyincreasingthetrainingdata.</subsection>
  <section title="Conclusion">Inthispaper,wedescribedanoveltasksettinginwhichwepredictedSPscores---degreeofpolarity---ofreviews.WeproposedamachinelearningmethodusingSVRtopredictSPscores.WecomparedtwomethodsforestimatingSPscores:pSVMsandSVR.ExperimentalresultsforbookreviewsshowedthatSVRperformedbetterintermsofthesquareerrorthanpSVMsbyabout30%.ThisresultagreeswithourintuitionthatpSVMsdonotconsidertheorderofSPscores,whileSVRcapturestheorderofSPscoresandavoidshighpenaltymistakes.WithSVR,SPscorescanbeestimatedwithasquareerrorof0.89,whichisveryclosetothesquareerrorachievedbyhumanclassifiers(0.78).Weexaminedtheeffectivenessoffeaturesbeyondabag-of-wordsandreferencefeatures(thewordsaroundthereviewedobjects.)Theresultssuggestthatn-gramfeaturesandreferencefeaturescontributetoimproveaccuracy.TheexperimentalresultsforsentencesubjectivitydetectionusingNaiveBayesclassifiersshowedthatthisapproachcanimprovetherobustnessofaclassifier,whichmaybeimprovedfurtherbyaddingaconstanttotheresultofNaiveBayesclassifiers.Thisisbecausethenoisefromobjectivesentencesiseliminated.Asthenextstepinourresearch,weplantoexploitparsingresultssuchaspredicateargumentstructuresfordetectingprecisereferenceinformation.Aswellasattitude,wewillalsocaptureothertypesofpolarity,suchasmodalityandwritingposition,andwewillconsidertheestimationofthesetypesofpolarity.Weplantodevelopaclassifierspecializedfororderedmulti-classclassificationusingrecentstudiesonmachinelearningforstructuredoutputspacesorordinalregression,sinceourexperimentssuggestthatpSVMsandSVRhavebothadvantagesanddisadvantages.WewilldevelopamoreefficientclassifierthatoutperformspSVMsandSVRbycombiningtheseideas.Wealsoexaminewhetherornotourtasksettingisappropriatetosummarizethereview.authorswouldliketoacknowledgethelargecontributionsofourlaboratorymemberstogiveusvaluablecommentsandannotatereviews.document</section>
</root>
