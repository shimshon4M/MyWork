    \documentclass[japanese]{jnlp_1.3c}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}

\Volume{14}
\Number{3}
\Month{Apr.}
\Year{2007}
\received{2006}{4}{20}
\revised{2006}{8}{11}
\accepted{2006}{9}{15}

\setcounter{page}{147}

\jtitle{「怒り」の発話を対象とした話者の感情の程度推定法}
\jauthor{有本　泰子\affiref{TUTBCM} \and 大野　澄雄\affiref{TUTCS} \and 飯田　　仁\affiref{TUTMS}}
\jabstract{
音声認識の精度の向上にともなって，コールセンターなどへの自動音声応答システムの導入の要求が高まり，人間がコンピュータと対話する機会も増加する傾向にある．これまでの対話システムは言語情報のみを扱い，そのパラ言語情報を扱うことは少ないため，人間同士の対話と比較すると，コンピュータとの対話ではコンピュータが得る人間の情報は小さい．
本研究では音声の音響的特徴と言語表現の特徴から推定可能な「怒り」の感情を検出するために，感情の程度による音響的・言語的変化を分析し，コンピュータと人間とのインタラクションにおける人間の感情を捉えることを目指す．非対面の擬似対話により，認識性能に対する不満からくる「苛立ち」や，クレーム対応時におけるユーザの「腹立ち」の内的感情を表現した怒りの音声を収録し，主観評価により感情の程度を付与した音声データを作成した．
本論では，怒りの感情を含むと判定された発話について，つぎの3種の特性，声の高さや強さ等の音響的特徴，
言語形態上の語彙使用の特徴，語用論的な特徴である文末表現の特徴に着目し，発話者の感情表現とその言語表現・音響的特徴との定量的な関係を分析し，怒り表現の音声言語の特徴付けを試みた．
とくに，接続助詞「けど」，「ので」の主節が現れずに発話が中止する接続助詞中止型に
おいて，怒りの程度が高いことを明らかにした．
}
\jkeywords{感情音声，韻律，話し言葉，言語表現}

\etitle{An Estimation Method of Degree of Speaker's Anger Emotion 
	with Acoustic and Linguistic Features}
\eauthor{Yoshiko Arimoto\affiref{TUTBCM} \and Sumio Ohno\affiref{TUTCS} 
	\and Hitoshi Iida\affiref{TUTMS}} 
\eabstract{
This report describes a study on an estimation method of degree of speaker's 
emotion by using acoustic and linguistic features expressed in their anger utterances 
during a natural dialogue. We set two types of pseudo dialogues, 
the human-computer and the human-human, to induce anger utterances from 10 speakers. 
To make an emotional speech corpus with degree of emotion, 
a 5-scale subjective evaluation was conducted to grade each utterance 
on its emotional degree. The emotional speech corpus was examined to find acoustic and linguistic features 
which estimate the emotional degree of each utterance. 
Decision trees were adopted as classifiers for our estimation examination to find optimal sets of the acoustic and linguistic features for an anger degree estimation. 
As a result, we find specific tendencies of the tree acousitc features in strong anger utterances, the linguistic parameters' potential to estimate degree of anger emotion, and the capability of decision tree to estimate utterances with two kinds of acoustic features as the strong anger. 
}
\ekeywords{Emotional speech, Prosody, Spoken language, Linguistic representation}

\headauthor{有本，大野，飯田}
\headtitle{「怒り」の発話を対象とした話者の感情の程度推定法}

\affilabel{TUTBCM}{東京工科大学大学院バイオ・情報メディア研究科}{
	Graduate School of Bionics, Computer and Media Sciences, Tokyo University of Technology}
\affilabel{TUTCS}{東京工科大学コンピュータサイエンス学部}{
	School of Computer Science, Tokyo University of Technology}
\affilabel{TUTMS}{東京工科大学メディア学部}{
	School of Media Science, Tokyo University of Technology}



\begin{document}
\maketitle





\section{はじめに}

インターネットが普及し，ユビキタス社会が浸透するなか，人間がコンピュータと対話する機会も増加する傾向にある．これまでの対話システムは言語情報のみを扱い，そのパラ言語情報を扱うことは少ないため，人間同士の対話と比較すると，コンピュータとの対話ではコンピュータが得る人間の情報は少ない．

本研究では音声の言語表現の特徴と音響的特徴から推定可能な感情を検出するために，感情の程度による言語表現の特徴および音響的変化を分析し，コンピュータと人間とのインタラクションにおける人間の感情および態度表出を捉えることを目指す．それにより，両者の円滑なコミュニケーションを図ることを目的としている．将来の具体的応用対象として考えられる対話を想定し，コールセンターなどへの自動音声応答システムにおける認識性能に対する不満からくる「苛立ち」や，真意が伝わらないことに対する「腹立ち」の表現などに着目して，ユーザの内的状態をその発話の言語表現および音響的な特徴から推定する可能性について検討する．

本報告では，感情表現を含む音声データの収録方法および感情情報を付与する主観評価法および言語表現・音響的特徴をパラメータとした決定木による「怒り」の感情の程度を推定する実験手法に関して述べ，今後の分析手法の指針について報告する．

\section{関連研究}
ここでは感情の心理学的なモデルに関する研究および音響的特徴による感情の推定および識別手法に関する研究，言語表現と心的状態および態度に関する研究について述べる．

感情の心理学的なモデルに関しては様々な研究がとり行われているものの，現状では広く使用されるモデルが確立されておらず，感情にまつわる研究でも様々なカテゴライズが独自に行われ，その独自のモデルに基づいて研究が行われている．本論文では，心理学的な尺度をもとに怒りの感情の程度を推定する手法について述べるので，ここでは各モデルがどのような尺度で構成されているかに着目したい．

心理進化論的なアプローチから基本感情を8感情 (acceptance, anger, anticipation, disgust, joy, fear, sadness, surprise) に設定し，立体構造モデルを定めたPlutchikの研究がある\cite{plutchik1980}．Plutchikは強度 (intensity) または覚醒 (arousal) という尺度で基本感情ごとに類似する感情を立体モデルの縦軸に当てはめている．

RussellはShlosbergのcircular structural modelをもとに水平軸に快 (pleasure)—不快 (displeasure)，垂直軸に覚醒 (arousal) —眠気 (sleep) の2次元で表される平面状に日常使用する一般用語で分類した感情を円環に並べたcircumplex modelを提唱している\cite{russell1989}．ここで特筆すべきは，Plutchikが同様と捉えた強度と覚醒の次元を別のものとして捉えている点である．Russellは感情の強度は円環の中心からのベクトルの長さで表されるとしている．Russellが強度と覚醒の次元を別のものと捉える理由はDalyらの理論にある．

Dalyらはpleasantnessとactivityの2軸の他に円錐状にneutralに向かって上昇するintensityの次元を設けた3次元モデルを提唱し，それまで同様に扱われていたactivityとintensityの違いを明確にしている\cite{daly1983}．

本論文は，自然な対話のなかで発声された怒りの音声の感情の強さの程度をintensityの次元で計るものとする．

音響的特徴による感情の推定および識別手法に関する研究は1つの感情を扱うのではなく，多感情を扱い，感情間の識別を行う研究が多く行われている．本論文では怒りの感情の認識に向けた検討を行うため，怒りの音声に限定した研究あるいは怒りの音声を2種類に分類して識別を行った研究について述べたい．

武田らは平板，中高，頭高の3種類のアクセント型を持つ4モーラと6モーラの有意味単語および無意味単語をNHK
アナウンサー4人および音声研究者1名の計5人により平常，軽い怒り，怒り，激怒の4段階で発声されている音声試料を用意し，音声パワー，時間構造（持続時間，発話速度）および基本周波数を韻律の特徴パラメータとして分析を行った\cite{Takeda2002}．
その結果，怒りの度合いが大きくなるにしたがって，最高音圧および最高基本周波数の増大が認められている．また，時間構造に関する特徴では，怒りの度合いが強くなるに従って早口になる傾向が見られる一方，逆に激怒時には発
話が遅くなる傾向が見られたことも確認している．

Shribergらの研究はDARPA Communicator Projectのもとで開発された電話による航空券予約システ
ムを利用して，演技ではない実際の音声の収録を行い識別実験に利用している．怒りのなかでもfrustrationとannoyanceに限定し，話速，休止，基本周波数，音圧，スペクトログラムなどの音響的特徴だけでなく，対話中の発話の位置や繰り返しや言い直しなどの情報もパラメータとして加え，怒りの音声の特徴を分析している\cite{Ang2002}．その分析の結果をもとにCART-style の決定木によって感情を識別し，すべてのパラメータを利用した識別ではfrustrationおよびannoyanceの発話とそれ以外の発話を80\%以上の正解率で識別している．ここにおいて特筆すべきは，対象の音声が従来の研究によくみられる
アナウンサーや俳優により演じられた感情音声ではないことである．実際に人間が発する自然な発話を対象とすることで，
コンピュータとの対話に生じる人間の自然な感情を識別の対象としているのである．

Banseらは多感情の識別実験を行っているが，複数の感情のうち，怒りをHot AngerとCold Angerに分け，異なる感情として扱い，人間による判断と音響パラメータを用いたジャックナイフ法および判別分析による識別実験との比較を行っている\cite{Banse1996}．その結果，Hot Angerはジャックナイフ法で69\%，判別分析で75\%の正解率を得ている．一方，Cold Angerは正解率が低く，いずれも50\%以下の成績であった．

本論文では，言語の使用を話者の心的状態および態度表出として捉え，
感情表出時にどのような話者の意図が存在しているのかを分析し，感情を捉える可能性について検討するので，
言語表現と意図との関係について検討された研究を先行研究として挙げる．

言語表現と話者の心的状態および態度に関する認知心理学的なアプローチとして横森の接続助詞ケドの文末用法に関する考察がある\cite{Yokomori2006}．横森によれば，文末のケドに符号化された意味は従属節から予期されることに対して，聞き手が認知していることが逸脱的であるという認知的評価であるとしている．心的態度表出はこの認知的評価により決定付けられる．

さらに，終助詞「よ」または「ね」の語用論的機能とイントネーションとのかかわりについても研究されている\cite[など]{Katagiri1997,Sugito2001,Inukai2001,Moriyama2001}．

\section{音声資料}
怒りを表現した発話を含むできる限り自然な対話音声を収録し，各収録発話に対し5段階の主観評価に基づいて，感情の程度の実測値を付与した．ここでは，実際に行った音声収録方法・主観評価法について述べる．

\subsection{音声収録手法}
コンピュータ対人間および人間対人間の擬似対話を設定し，収録を行った．発話内容を限定せず，(a)ユーザ役の音声提供者がコンピュータ役の人間と対話をし，コンピュータの認識ミスによる聞き返しにより怒りを誘発させる方法と，(b)あらかじめ，クレームの内容を提示し，人間のオペレータとその内容について話し合ってもらう方法の2通りの対話を実施した．その際，音声提供者には対話に必要な最低限の情報のみを与え，オペレータの指示に従って自由に発話するようにした．実際の対話例を図\ref{fig:utter}に示す．

収録は一般の大学生10名（男性5名，女性5名）がユーザ役の音声提供者となり，研究の趣旨を熟知しているオペレータ役1名が対応した．オペレータ役とユーザ役とは非対面で対話を行い，それぞれの発話をDATレコーダに左右チャネルに分けて録音した．

\begin{figure}[t]
\begin{center}
    \includegraphics[width=0.8\hsize]{sampleDialogue.eps}
\caption{「怒り」の収録対話例}
\par 注:Oはオペレータの発話，Uはユーザの発話
\label{fig:utter}
\end{center} 
\end{figure} 

収録した音声を10kHz，16bitでディジタル化し，ユーザ役の音声データを発話単位に切り出した5名（男性3名，女性2名）による発話から，159発話を音声資料として使用した．

各々の発話の長さは様々で，最短の発話は「はい」(112ms)，最長の発話は「だから，その…そのデータベースに全部残っているっていう証明はどうやってするんですか」(6.26s) であった．

\subsection{主観評価法}

\begin{table}[b] 
\caption{各クラスタのデータ数}
\label{tb:cluster}
\begin{center}
\begin{tabular}{cc}
\hline
クラスタ&データ数 \\ \hline
A&41 \\
B&52 \\
C&55 \\
D&11 \\ \hline
\end{tabular}
\end{center}
\end{table}

音声資料に対して，含まれている怒りの程度を定量化するため，主観評価実験を行った．被験者は大学生12名（男性11名，女性1名）で，ヘッドホンを通して1発話につき2回ずつランダムに提示される各発話について，怒りの程度を1（ぜんぜん）から5（すごく）までの5段階で評価させた．発話ごとに評価された値の平均値を求め，それを怒りの程度を表す実測値として各発話に付与した．

さらに，音響的な特徴を分析する際に，怒りの程度による大まかな傾向をみるため，全159発話の音声資料を主観評価値をもとに4つのクラスタにクラスタリングした．クラスタリングには距離尺度にWard法を用いた階層型分類法を利用した．以後，分類した4つのクラスタを平静から順に怒りの程度が大きくなるようA，B，C，Dと称する．各クラスタのデータ数を表\ref{tb:cluster}にまとめた．

なお，評価値，すなわち怒りの程度は連続に分布しており，このクラスタリングは以後の分析のために便宜上行ったもので，相隣り合うクラスタの境界は必ずしも明確ではない．

\section{「怒り」を含む発話の分析}
\subsection{音響的分析}
本研究では音声の音響情報を反映するようなパラメータを怒りの推定のために利用する．検討したパラメータは感情表現に関する先行研究\cite[など]{Takeda2002,Cowie2001,Nagae1997,Banse1996,Ang2002}を参考に定めた．多くのパラメータについては，発話内の代表的な値として平均値を，時間的な変動の指標として発話内での標準偏差の値を用いた．

\subsubsection{高さに関連するパラメータ}

音声の高さに関連するパラメータとして，表\ref{tb:F0}に挙げた基本周波数 ({\it F}{\tiny 0}) から求められる発話内での統計量F-1〜F-7を用いる．なお{\it F}{\tiny 0}は可変窓長の変形自己相関関数法により10ms間隔で自動抽出した後，視察により修正を施したものを用いた．また，{\it F}{\tiny 0}の絶対的な値を対象とするパラメータ (F-1，F-2，F-3) については，男女間の差の影響を除去するため，簡易的ではあるが，男女それぞれについて全データの平均値を求め，その値を差し引くことで男女差の正規化を行ったパラメータ (F-4，F-5，F-6) を用意した．

\begin{table}[b] 
\caption{高さに関連するパラメータ}
\label{tb:F0}
\begin{center}
\begin{tabular}{ll}
\hline
記号&説明 \\ \hline
F-1&{\it F}{\tiny 0}の発話内平均（対数軸） \\
F-2&{\it F}{\tiny 0}の発話内最低値 \\
F-3&{\it F}{\tiny 0}の発話内最高値 \\
F-4&男女差正規化{\it F}{\tiny 0}の発話内平均（対数軸） \\
F-5&男女差正規化{\it F}{\tiny 0}の発話内最低値 \\
F-6&男女差正規化{\it F}{\tiny 0}の発話内最高値 \\
F-7&{\it F}{\tiny 0}の発話内標準偏差（対数軸） \\ \hline
\end{tabular}
\end{center}
\end{table}

\subsubsection{強さに関連するパラメータ}
音声の強さに関連するパラメータとして，表\ref{tb:pwr}に挙げたP-1〜P-3を用いる．

P-1〜P-2のパラメータは振幅のRMS値10000を0dBVとしたdBVを単位とする．短時間平均パワーは窓長20msの矩形窓を施し，5ms間隔で求めた．P-3の変動量は，短時間平均パワーの変化の緩急を定量化するため，11フレームに渡る短時間平均パワーの回帰直線の傾きのRMSを求めたものである．

\begin{table}[b] 
\begin{minipage}{0.45\textwidth}
\caption{強さに関連するパラメータ}
\label{tb:pwr}
\begin{center}
\begin{tabular}{ll}
\hline
記号&説明 \\ \hline
P-1&短時間平均パワーの発話内標準偏差 \\
P-2&短時間平均パワーの発話内最大値 \\
P-3&短時間パワーの変動量 \\ \hline
\end{tabular}
\end{center}
\end{minipage}
    \hfill
\begin{minipage}{0.45\textwidth}
\begin{center}
\caption{速さ・長さに関連するパラメータ}
\label{tb:dur}
\begin{tabular}{ll}
\hline
記号&説明 \\ \hline
D-1&呼気段落の平均モーラ数 \\
D-2&平均発話速度 (mora/s) \\ \hline
　　\\
\end{tabular}
\end{center}
\end{minipage}
\end{table}

\subsubsection{速さ・長さに関連するパラメータ}
発話の速さ・長さに関連するパラメータとして表\ref{tb:dur}に示す2種の値を用いる．

D-1は呼気段落のモーラ数を発話内で平均したものであり，D-2は休止区間を除外して求めた平均発話速度（単位：mora/s）である．


\subsubsection{声質に関連するパラメータ}
声質に関連するパラメータとして，ここではスペクトル包絡の大局的な傾きに着目して，表\ref{tb:cep}に示すC-1〜C-2を取り上げた．スペクトル包絡の大局的な傾きに関連するパラメータとして，改良ケプストラム法により求めたケプストラムの第1次係数の値を使用した．

\begin{table}[b] 
\caption{声質に関連するパラメータ}
\label{tb:cep}
\begin{center}
\begin{tabular}{ll}
\hline
記号&説明 \\ \hline
C-1&第1次ケプストラム係数の発話内平均 \\
C-2&第1次ケプストラム係数の発話内標準偏差 \\ \hline
\end{tabular}
\end{center}
\end{table}
 
\subsubsection{各パラメータに対する実測値の分布}
上述の計14種のパラメータがそれぞれ単独でどの程度怒りの推定能力を有するかについて検討する．

図\ref{fig:graph}はいくつかのパラメータについて，怒りの程度に関する4つのクラスタ内での平均値，標準誤差，標準偏差を示したものである．個別のパラメータに関する詳細については割愛するが，クラスタ間での傾向は以下の2つに大別できる．1つは怒りの程度が大きくなるに従って，ほぼ単調に値が増加あるいは減少するもの（図2中D-2およびF-2）で，もう1つは怒りの程度が最大のクラスタDについてAからCまでの傾向と反する変化を呈するもの（図2中P-2およびF-3）である．

\begin{figure}[t]
\begin{center}
    \includegraphics[width=0.4\hsize]{D-2.eps}
    \includegraphics[width=0.4\hsize]{F-2.eps}
    \includegraphics[width=0.42\hsize]{P-2.eps}
    \includegraphics[width=0.4\hsize]{F-3.eps}
\caption{クラスタごとのパラメータの平均値，標準誤差，標準偏差}
\label{fig:graph}
\end{center} 
\end{figure} 

\subsubsection{パラメータ間の相関}
複数のパラメータを組み合わせて怒りの推定に用いる際に相互に相関の高いパラメータ対を把握する必要がある．上述の14種のパラメータに関して相関係数を求めたところ，いずれのパラメータも同種のカテゴリを超えて，高い相関が見られたものはなかった．

同一のカテゴリ内で特に正の相関が大きいもの (r≧0.75) は，高さに関連するパラメータでは，{\it F}{\tiny 0}対数平均，{\it F}{\tiny 0}最高値，{\it F}{\tiny 0}最低値のそれぞれの組み合わせであった．
 
\subsection{言語的分析}
収録した音声データのうち怒りの強いクラスタ内に疑問表現，終助詞「よ・ね」や接続助詞中止型「ので・けど」が見られた\cite[など]{Arimoto2006a,Arimoto2006b}．ここでは，こうした言語特徴を利用し，怒りの推定に貢献するパラメータを用意するため，語用論的機能の観点から見た怒りとの関係や音響的特徴による機能の変化などに着目し，分析を行う．

\subsubsection{文構成に関するパラメータ}
怒りの強いクラスタであるCとDにおいては，「それはどうやって証明するんですか？」
「でも全部残っているって証明はされてないじゃないですか？」などの疑問文が多く見られた．

疑問表現は一般的に未知の部分の情報を相手に求める質問型と自分自身に問いかける自問型に分類される\cite{Masuoka1992}．質問型では上昇調のイントネーションが使われ，自問型では下降調のイントネーションが使われる．本研究では対話を取り扱っているので，主に質問型の疑問文を対象とする．

疑問の形式としては，「昨日，花子に会いましたか？」などの事柄の真偽に関わる「真偽疑問文」，「昨日，誰に会ったのですか？」などの「疑問語疑問文」，「文法は，好きですか，嫌いですか？」などの「選択疑問文」がある．

言語の表層的な構文としては「真偽疑問文」は疑問の終助詞「か／の」で終了することが認識されているが，「か／の」を付けず，文末の音響的な上昇イントネーションにするだけでも真偽疑問文になることも確認されている．「疑問語疑問文」では「何」や「誰」などの疑問語を文中に含み，普通体では文末には「か」が原則使用できない（丁寧体では「か」は使用できる）\cite{Masuoka1992}．文末の言語表層的な表現が制限される一方で，「疑問語疑問文」でも文末の音響的な上昇イントネーションは保たれている．こうしたことから，疑問表現と音響的特徴との関連は深いものと考えることができる．

疑問表現は既定の部分を前提として，未定の部分を質問する用法で用いられるが，ここでは相手の主張の正当性に対する強い反意を疑問文として表現していると捉えられる．

\subsubsection{文末表現を捉えたパラメータ}
話し言葉の1つの典型発話タイプである「予約したんですけど／予約したんで／残ってるんスけど」などの接続助詞中止型は，一般的に主節部分を明示せずに，聞き手にその解釈を委ねる用法であると捉えられる．こうした表現は，その主節に含まれると考えられる，対話相手の対応の悪さに対する「怒り」の内容を，聴き手に想起・自覚させ，強く印象つける役目を果たすものと考察できる．その例として，想定される主節の「怒り」の内容例を表\ref{tb:sample}にまとめる．

\begin{table}[b] 
\caption{接続助詞中止型に想定される「怒り」の内容例}
\label{tb:sample}
\begin{center}
\begin{tabular}{ll}
\hline
従属節&想定される主節 \\ \hline
え，でも（予約番号は発行）されてるんで．&(1) 予約はしてるんだよ．\\
 &(2) 会議室は使えるのが当たり前だろ．\\ \hline
(履歴が)残ってるんスけど&(1) ちゃんと確認しろ．\\
 &(2) もっと調べろよ．\\ \hline
\end{tabular}
\end{center}
\end{table}

さらに，横森は感情の認知的モデルにおける感情状態に遷移する前の認知的評価のみを接続助詞の意味とみなし，主体の心的態度は従属節における入力に対する主体の価値的関係によって決定されるとしている\cite{Yokomori2006}．その上で，文末における「けど」の符号化された意味を従属節から「予期されることに対して，聞き手が認知していることが逸脱的である」と定めている．
収録した対話においても，怒りを誘発するために，話し手（ユーザ）が予期していることに対して，聞き手（オペレータ）が認知していることが逸脱している対話が多い．そのため，接続助詞中止型で終わる発話が収録されたと考えられる．

終助詞「ね・よ」で終止する発話は，いずれも表面上は同意要求あるいは確認としての使用と見なせるが，言語運用的には話者が納得できない条件，事態について同意させられていることに対する話者の「怒り」の内的感情を表していると捉えることができる．

終助詞「ね・よ」に関しては多くの研究者\cite[など]{Katagiri1997,Sugito2001,Inukai2001,Moriyama2001}がその意味・機能やイントネーションとのかかわりについて研究を行っている．片桐\cite{Katagiri1997}によれば，「ね」で終止する発話は文末に上昇調のイントネーションが加わると確認要求，下降調のイントネーションが加わると情報提供の機能を果たす．また，「よ」についても上昇調のイントネーションが付随した場合は将来の聞き手の行動に対する純粋な依頼であるのに対し，下降調イントネーションが付随すると，この聞き手の行動に対する異議申し立てと捉えられるとしている．また，イントネーションの位置によって不満・強調・強引な押し付けなどさまざまな含みを持たせることが可能であるとしている．

収録音声に見られる「ね」で終止する発話についても，イントネーションとの関わりにより，その言語機能に変化があった可能性を探るため，やや怒りの強いクラスタCで見られる発話に限定して，文末30フレームの{\it F}{\tiny 0}の傾きと手前30フレームの{\it F}{\tiny 0}の傾きの差分を求めた（図\ref{fig:diff}）．

一般に句末の{\it F}{\tiny 0}は下降調になるといわれるが，終助詞「ね」で終わる発話はその他の発話に比べ，緩やかな変化ではあるものの上昇傾向を示していると考えられる．ここでの発話の機能としては確認要求とみなすことができる．

\begin{figure}[b]
\begin{center}
    \includegraphics[width=0.4\hsize]{graph3_1.eps}
    \includegraphics[width=0.4\hsize]{graph3_2.eps}
\caption{文末30フレームの{\it F}{\tiny 0}の傾きと手前30フレームの{\it F}{\tiny 0}の傾きの差分とクラスタとの分布}
\label{fig:diff}
\end{center} 
\end{figure} 

\subsubsection{言語表現のパラメータ化}
言語パラメータとして，各発話を平叙文，疑問文に分類し，表\ref{tb:ling_param}中のL-1文構成として挙げた．この際，平叙文でも語尾のイントネーションを上げることで疑問となる表現は疑問文として扱った．さらに，接続助詞中止型「ので・けど」と終助詞「ね・よ」を表\ref{tb:ling_param}中のL-2文末表現として，パラメータに加えた．各発話が接続助詞中止型「ので・けど」／終助詞「ね，よ」で終わっていることを分類の基準とした．ただし，文末に接続詞中止型の「ので・けど」が来る場合，「したいんですけど」という発話と「したんですけど」という2種類の発話が現れていたが，言語表層からもその使用の違いが明らかであるため，「したいんですけど」という発話は接続助詞中止型の分類とはしなかった．
  
\begin{table}[t] 
\caption{言語表現を利用したパラメータ}
\label{tb:ling_param}
\begin{center}
\begin{tabular}{ll}
\hline
記号&説明 \\ \hline
L-1&文構成（平叙文，疑問文）\\
L-2&文末表現（終助詞，接続助詞，その他）\\ \hline
\end{tabular}
\end{center}
\end{table}
\begin{figure}[t]
\begin{minipage}{0.45\textwidth}
\begin{center}
    \includegraphics[width=168pt]{bunkousei.eps}
\caption{文構成のパラメータに対する実測値の分布}
\label{fig:bunkousei}
\end{center} 
\end{minipage}
    \hfill
\begin{minipage}{0.45\textwidth}
\vspace{7.2pt}
\begin{center}
    \includegraphics[width=168pt]{bunmatu.eps}
\caption{文末表現に対する実測値の分布}
\label{fig:bunmatu}
\end{center} 
\end{minipage}
\end{figure} 


\subsubsection{言語パラメータに対する実測値の分布}
言語パラメータに対する実測値の分布を図\ref{fig:bunkousei}・\ref{fig:bunmatu}に示す．図\ref{fig:bunkousei}の文構成の分布をみると，疑問文のほうが怒りの程度の高い発話に多く見られ，平叙文との差も明らかである．文末表現の分布では，すべての項目でバラツキが大きくなっているが，平均値をみるとその他・終助詞・接続助詞の順に値が上昇している．


\section{推定実験}
収録した音声データを用い，音響パラメータと言語パラメータを使用して，決定木による怒りの程度を推定する実験を行った．ここではその実験手法とその結果について述べる．

\subsection{音声データとパラメータの組み合わせ}
収録した音声データにはデータ数に男女の偏りがあることが分かっている\cite[など]{Arimoto2004,Arimoto2005a,Arimoto2005b}ため，全159発話を含むdata set Aの他に男性の発話のみ（141発話）を含むdata set Bを用意した．
各data set に対し，{\it F}{\tiny 0}の絶対的な値を用いるパラメータ (F-1〜3) を除いた11種の音響パラメータを用いた実験と言語パラメータを加えた13種のパラメータによる実験を行った．さらに，data set Aには女性の発話が含まれていることから，男女差の影響の程度を比較するため，14種のすべてのパラメータを用いることにした．data set Aによる14種のパラメータを用いた実験を実験I，11種のパラメータを用いた実験を実験II，言語パラメータを加えた13種のパラメータを用いた実験を実験IIIとする．data set Bによる11種のパラメータを用いた実験を実験IV，言語パラメータを加えた13種のパラメータを用いた実験を実験Vとする．各data setに使用するパラメータ数とその実験名称を表\ref{tb:experiment}にまとめた．

\begin{table}[b] 
\caption{実験ごとに使用するdata setとパラメータ}
\label{tb:experiment}
\begin{center}
\begin{tabular}{lll}
\hline
実験&data set&パラメータ数 \\ \hline 
実験I&A（男女混合）&14種（すべての音響パラメータ）\\
実験II&&11種（男女差正規化音響パラメータ）\\
実験III&&13種（男女差正規化音響パラメータ＋言語パラメータ）\\ 
実験IV&B（男性のみ）&11種（男女差正規化音響パラメータ）\\
実験V&&13種（男女差正規化音響パラメータ＋言語パラメータ）\\ \hline 
\end{tabular}
\end{center}
\end{table}

\subsection{実験手法}
推定実験は決定木を用いて行った．交差検定を行うため，各data setの発話を3つのグループに分割した．各data setは発話数が限られているため，ランダムに三分割を行うと，グループ間に怒りの程度の偏りが生じてしまう．そのため，1発話ずつを主観評価値の高いデータから順に3つのグループに振り分け，グループ間の怒りの程度の偏りを排除し，実験の信頼性の確保に努めた．決定木のための学習用データとして2グループを，評価用データとして1グループを使用する．データに依存しない最適な木を求めるため，学習用・評価用データに使用するグループを入れ替えて{\it n}-fold交差検証法 ({\it n}=3) を行う．

学習用・評価用データに含まれる怒りの種類に影響されない木を求めるため，評価用データの分岐回ごとの予測値と主観評価による実測値の標準誤差が最小になる分岐回で木の生成を停止した．
実験の評価方法として主観評価により付与された怒りの実測値と決定木による予測値との標準誤差を求め，推定性能の指標とした．

\subsection{結果と考察}
実験の結果，音響パラメータのみを用いた実験I・II・IVでは8回目，7回目，6回目が最適な分岐回となり，その際の平均推定誤差は0.54，0.60，0.53となった．音響パラメータに言語パラメータを加えた実験III・Vでは5回目，4回目が最適な分岐回となり，その際の平均推定誤差はともに0.50となった．各実験での分岐停止回と平均推定誤差を表\ref{tb:result}に，各分岐回で選択されたパラメータを表\ref{tb:selected_param_acous}・\ref{tb:selected_param_ling}
にまとめる．

\begin{table}[b] 
\caption{実験ごとの分岐停止回と平均推定誤差}
\label{tb:result}
\begin{center}
\begin{tabular}{ccc}
\hline
&分岐停止回&平均誤差 \\ \hline
実験I&8回目&0.54 \\
実験II&7回目&0.60 \\
実験III&5回目&0.50 \\
実験IV&6回目&0.53 \\
実験V&4回目&0.50 \\ \hline
\end{tabular}
\end{center}
\end{table}

音響パラメータのみの実験と言語パラメータを加えた実験の結果を比べると，男女混合のdata set Aでは平均推定誤差に0.10差，男性のみのdata set Bで0.03差となり，音響的特徴のみの実験よりも言語的特徴を含めた実験のほうが推定精度が若干向上している．


\begin{table}[b] 
\caption{各分岐回で選択されたパラメータ（音響パラメータのみの実験）}
\label{tb:selected_param_acous}
\footnotesize
\begin{tabular}{cccccccccc}
\hline
\scalebox{0.75}[1]{分岐回}&&実験I&&&実験II&&&実験IV& \\
&group 1&group 2&group 3&group 1&group 2&group 3&group 1&group 2&group 3 \\ \hline
1&F-2（低）&F-7（大）&P-2（強）&F-7（大）&F-7（大）&P-2（強）&F-7（大）&P-2（強）&F-7（大）\\
2&F-7（大）&F-2（低）&D-2（速）&P-2（強）&C-1（大）&D-2（速）&P-2（強）&D-2（速）&P-2（強）\\
3&P-2（強）&P-1（大）&F-7（大）&D-2（速）&D-2（速）&F-7（大）&F-5（低）&F-5（低）&D-2（速）\\
4&D-2（速）&D-2（速）&F-2（低）&F-6（低）&F-7（大）&F-7（大）&D-2（速）&F-7（大）&F-7（大）\\
5&F-3（低）&C-2（大）&F-3（低）&F-7（大）&D-1（短）&D-2（速）&F-6（高）&F-7（大）&F-6（低）\\
6&F-7（大）&F-2（低）&D-2（速）&F-7（大）&P-2（強）&P-2（弱）&F-6（低）&F-6（低）&F-5（低）\\
7&P-2（弱）&P-2（強）&P-2（弱）&P-2（強）&F-4（小）&F-6（低）&-&-&- \\
8&F-2（低）&F-3（高）&P-1（大）&-&-&-&-&-&- \\ \hline
\end{tabular}
\end{table}

\begin{table}[b—] 
\caption{各分岐回で選択されたパラメータ（音響+言語パラメータの実験）}
\label{tb:selected_param_ling}
\begin{center}
\footnotesize
\begin{tabular}{ccccccc}
\hline
分岐回&&実験III&&&実験V& \\
&group 1&group 2&group 3&group 1&group 2&group 3 \\ \hline
1&F-7（大）&P-2（大）&L-1（疑問文）&L-1（疑問文）&P-2（大）&F-7（大）\\
2&P-2（大）&L-1（疑問文）&P-2（大）&P-2（大）&L-1（疑問文）&L-1（疑問文）\\
3&F-6（低）&D-2（速）&L-2（終助詞，接続助詞）&F-5（低）&D-2（速）&P-2（大）\\
4&D-2（速）&F-7（大）&P-3（小）&D-2（速）&F-7（大）&D-2（速）\\
5&F-7（大）&F-6（高）&P-2（大）&-&-&- \\ \hline
\end{tabular}
\end{center}
\end{table}

音響パラメータのみを使用した実験I・II・IVにより選択されたパラメータをみると，共通に選択されたパラメータ (F-7，P-2，D-2) があることが分かる．男女の発話が混合するdata setと男性の発話のみのdata setの間で怒りの発話に共通する音響的特徴（発話内での声の高さに大きな変化がある，声が大きい，速い）があることが分かる．実験IVにより選択されたパラメータをみると，すべてのグループで同じパラメータが選択されていることが分かり，学習用・評価用データに依存することなく，男性の怒りの発話の特徴をより正確に捉えることができたといえる．
実験IV group1による決定木（図\ref{fig:tree}参照）の最後の3回の分岐ではD-2で速くとゆっくりに分かれた発話がその後，同じF-6のパラメータで分岐し，声の低い発話と声の高い発話のそれぞれが怒りの程度が高いと推定されていることが分かる．これは音声データに2種の怒りの発話（はやく・声の高い発話，ゆっくり・声の低い発話）が存在していることを示唆する．ひとつは対人間の対話で納得できない相手の主張に対し感情的になっている発話であり，もう1つは対コンピュータの対話で誤認識に対し同一内容を丁寧に繰り返している発話と認識内容を確認する際に念を押すようにゆっくりと話す発話である．

\begin{figure}[t]
\begin{center}
    \includegraphics[width=0.8\hsize]{tree1.eps}
\caption{実験IV group1による決定木}
\label{fig:tree}
\end{center} 
\end{figure} 



表\ref{tb:selected_param_ling}をみると，言語パラメータL-1がほぼすべてのgroupで1回目・2回目という早い分岐回で選択され，疑問文である発話が怒りが強いと判断されている．これは疑問文の文構成が怒りの程度の推定に大きく寄与したと言える．音響パラメータも音響パラメータのみの実験とほぼ同じパラメータが選択され，怒りの発話の音響的な特徴も捉えられているといえる．

一方で，L-2文末表現はdata set Aのgroup3で3回目の分岐で選択されている．文末表現も怒りを推定するパラメータとなりえる可能性を確認することが出来た．今回の分類では3で述べた用途以外の接続助詞中止型および終助詞「ね・よ」が含まれていた可能性があるため，そうした2種の用途を区別することが出来れば，さらにパラメータとしての精度を向上させることが出来ると考えられる．

\section{おわりに}
コンピュータと人間とのインタラクションにおいて人間が表出するパラ言語情報・非言語情報を捉えることを目指し，音声の音響的特徴と言語表現の特徴から推定可能な感情を検出するために，感情の程度による音響的特徴・言語使用の特徴を分析した．

感情を「怒り」に限定し，非対面の擬似対話により，認識性能に対する不満からくる「苛立ち」や，クレーム対応時におけるユーザの「腹立ち」の内的感情を表現した怒りの音声を収録，主観評価により感情の程度を付与した音声データを作成した．また，決定木により「怒り」の程度の推定実験を行い，データに依存しない「怒り」の音響的な特徴を捉えた．

感情を含む音声に「それはどうやって証明するんですか？」「でも全部残っているって証明は，されてないじゃないですか？」などの疑問文の文構成，「したんですけど／したんで／してるんスけど」などの接続助詞中止型で終止する発話，終助詞「よ，ね」で終止する発話が頻出していることから，発話者の感情表現とその言語表現との定量的な関係を分析し，怒りを推定するパラメータとして適用した．その結果，文構成・文末表現などの言語表現も「怒り」の感情の推定に貢献することを明らかにした．

今後は，自然な対話の中でのユーザの感情をその発話の音響的・言語的特徴から推定するために，データの量的・質的拡充を図りながら，より推定性能の優れた音響パラメータ・言語パラメータを追究し，詳細な分析と特徴抽出を行う．

\acknowledgment

本研究を進めるにあたって有意義なコメントを戴いた飯田研究室および大野研究室の学生諸君に
感謝いたします．


\bibliographystyle{jnlpbbl_1.2}
    \newcommand{\SPhy}{}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Ang, Dhillon, Krupski, Shriberg, \BBA\ Stolcke.}{Ang
  et~al.}{2002}]{Ang2002}
Ang, J., Dhillon, R., Krupski, A., Shriberg, E., \BBA\ Stolcke., A. \BBOP
  2002\BBCP.
\newblock \BBOQ Prosody-Based Automatic Detection of Annoyance and Frustration
  in Human-Computer Dialog\BBCQ\
\newblock In {\Bem Proc. Intl. Conf. on Spoken Language Processing},
  \lowercase{\BVOL}~3, \mbox{\BPGS\ 2037--2040}.

\bibitem[\protect\BCAY{Arimoto, Ohno, \BBA\ Iida}{Arimoto
  et~al.}{2005}]{Arimoto2005b}
Arimoto, Y., Ohno, S., \BBA\ Iida, H. \BBOP 2005\BBCP.
\newblock \BBOQ A Method for Discriminating Anger Utterances from Other
  Utterances using Suitable Acoustic Features\BBCQ\
\newblock In {\Bem Proceedings of SPECOM2005}, \mbox{\BPGS\ 613--616}.

\bibitem[\protect\BCAY{Banse \BBA\ Scherer}{Banse \BBA\
  Scherer}{1996}]{Banse1996}
Banse, R.\BBACOMMA\ \BBA\ Scherer, K.~R. \BBOP 1996\BBCP.
\newblock \BBOQ Acoustic Profiles in Vocal Emotion Expression\BBCQ\
\newblock {\Bem Journal of Personality and Social Psychology}, {\Bbf 70}  (3),
  \mbox{\BPGS\ 614--636}.

\bibitem[\protect\BCAY{Cowie, Douglas-Cowie, Tsapatsoulis, Votsis, Kollias,
  Fellenz, \BBA\ Taylor}{Cowie et~al.}{2001}]{Cowie2001}
Cowie, R., Douglas-Cowie, E., Tsapatsoulis, N., Votsis, G., Kollias, S.,
  Fellenz, W., \BBA\ Taylor, J.~G. \BBOP 2001\BBCP.
\newblock \BBOQ Emotion Recognition in Human-Computer Interaction\BBCQ\
\newblock {\Bem IEEE Signal Processing Magazine}, {\Bbf 18}  (1), \mbox{\BPGS\
  32--80}.

\bibitem[\protect\BCAY{Daly, Lancee, \BBA\ Polivy}{Daly
  et~al.}{1983}]{daly1983}
Daly, E.~M., Lancee, W.~J., \BBA\ Polivy, J. \BBOP 1983\BBCP.
\newblock \BBOQ A Conical Model for the Taxonomy of Emotional Experience\BBCQ\
\newblock {\Bem Journal of Personality and Social Psychology}, {\Bbf 45}  (2),
  \mbox{\BPGS\ 443--457}.

\bibitem[\protect\BCAY{Plutchik}{Plutchik}{1980}]{plutchik1980}
Plutchik, R. \BBOP 1980\BBCP.
\newblock {\Bem Chapter 11: A structural model of the emotions in Emotions: A
  psychoevolutionary synthesis}.
\newblock Harper and Row, N.Y.

\bibitem[\protect\BCAY{Russell}{Russell}{1989}]{russell1989}
Russell, J.~A. \BBOP 1989\BBCP.
\newblock {\Bem Chapter 4: Measures of emotion. in Emotion Theory, Research,
  and Experience}.
\newblock Academic Press, Inc.

\bibitem[\protect\BCAY{片桐}{片桐}{1997}]{Katagiri1997}
片桐恭弘 \BBOP 1997\BBCP.
\newblock \Jem{文法と音声　12．終助詞とイントネーション}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{長江}{長江}{1997}]{Nagae1997}
長江功広 \BBOP 1997\BBCP.
\newblock \Jem{音声に含まれる話者の感情の分析と認識に関する研究}.
\newblock 宇都宮大学学士論文.

\bibitem[\protect\BCAY{武田\JBA 大山\JBA 杤谷\JBA 西澤}{武田\Jetal
  }{2002}]{Takeda2002}
武田昌一\JBA 大山玄\JBA 杤谷綾香\JBA 西澤良博 \BBOP 2002\BBCP.
\newblock \JBOQ 日本語音声における「怒り」を表現する韻律的特徴の解析\JBCQ\
\newblock \Jem{日本音響学会誌}, {\Bbf 58}  (9), \mbox{\BPGS\ 561--568}.

\bibitem[\protect\BCAY{有本\JBA 大野\JBA 飯田}{有本\Jetal }{2004}]{Arimoto2004}
有本泰子\JBA 大野澄雄\JBA 飯田仁 \BBOP 2004\BBCP.
\newblock \JBOQ {\kern-0.5zw}「怒り」識別のための音声の特徴量の検討\JBCQ\
\newblock \Jem{人工知能学会研究会資料}, SIG-SLUD-A303\JVOL, \mbox{\BPGS\
  13--19}.

\bibitem[\protect\BCAY{有本\JBA 大野\JBA 飯田}{有本\Jetal
  }{2005}]{Arimoto2005a}
有本泰子\JBA 大野澄雄\JBA 飯田仁 \BBOP 2005\BBCP.
\newblock \JBOQ 決定木による「怒り」識別のための音響的特徴の検討と評価\JBCQ\
\newblock \Jem{日本音響学会2005年秋季研究発表会講演論文集}, 1-6-2\JVOL,
  \mbox{\BPGS\ 225--226}.

\bibitem[\protect\BCAY{有本\JBA 大野\JBA 飯田}{有本\Jetal
  }{2006a}]{Arimoto2006a}
有本泰子\JBA 大野澄雄\JBA 飯田仁 \BBOP 2006a\BBCP.
\newblock \JBOQ
  {\kern-0.5zw}「怒り」の感情表現とその言語表現—音響的特徴の関係\JBCQ\
\newblock
  \Jem{言語処理学会第12回年次大会ワークショップ「感情・評価・態度と言語」論文
集}, 1\JVOL, \mbox{\BPGS\ 53--56}.

\bibitem[\protect\BCAY{有本\JBA 大野\JBA 飯田}{有本\Jetal
  }{2006b}]{Arimoto2006b}
有本泰子\JBA 大野澄雄\JBA 飯田仁 \BBOP 2006b\BBCP.
\newblock \JBOQ 感情音声の収録と言語表現に現れる感情表現の分析\JBCQ\
\newblock \Jem{電子情報通信学会 2006年総合大会 講演論文集}, \mbox{\BPGS\
  {\SPhy}42--43}.

\bibitem[\protect\BCAY{横森}{横森}{2006}]{Yokomori2006}
横森大輔 \BBOP 2006\BBCP.
\newblock \JBOQ 接続助詞ケドの文末用法と話し手の態度\JBCQ\
\newblock
  \Jem{言語処理学会第12回年次大会ワークショップ「感情・評価・態度と言語」論文
集}, \mbox{\BPGS\ 37--40}.

\bibitem[\protect\BCAY{森山}{森山}{2001}]{Moriyama2001}
森山卓郎 \BBOP 2001\BBCP.
\newblock
  \Jem{文法と音声III　3．終助詞「ね」のイントネーション—修正イントネーション
制約の試み—}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{杉藤}{杉藤}{2001}]{Sugito2001}
杉藤美代子 \BBOP 2001\BBCP.
\newblock \Jem{文法と音声III　1．終助詞「ね」の意味・機能とイントネーション}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{犬飼}{犬飼}{2001}]{Inukai2001}
犬飼隆 \BBOP 2001\BBCP.
\newblock \Jem{文法と音声III　2．低く短く付く終助詞「ね」{\unskip}}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{益岡\JBA 田窪}{益岡\JBA 田窪}{1992}]{Masuoka1992}
益岡隆志\JBA 田窪行則 \BBOP 1992\BBCP.
\newblock \Jem{基礎日本語文法—改訂版—}.
\newblock くろしお出版.

\end{thebibliography}


\begin{biography}

\bioauthor{有本　泰子}{
1996年青山学院大学文学部英米文学科卒業．
2004年東京工科大学メディア学部メディア学科卒業．
2005年，東京工科大学バイオ・情報メディア研究科に入学，現在に至る．日本音響学会学生会員．}

\bioauthor{大野　澄雄}{
1988年東京大学工学部電気工学科卒．1993年同大大学院工学系研究科電子
工学専攻博士課程了．同年，東京理科大学基礎工学部助手．1999年東京工科大学工学
部講師．現在，同大コンピュータサイエンス学部助教授．音声言語処理，特に音声の
韻律の分析・合成・認識処理の研究に従事．博士（工学）．電子情報通信学会，日本音
響学会各会員．}

\bioauthor{飯田　　仁}{
1974年早稲田大学大学院理工学研究科数学専攻修了．NTT基礎研究所，
ATR自動翻訳電話研究所，ATR音声翻訳通信研究所等を経て，2003年4月より
東京工科大学メディア学部教授．2006年4月より同大学片柳研究所長．
言語処理学会元会長．博士（工学）．音声対話理解，マルチモーダル・
インタラクション等の教育・研究に従事．科学技術庁長官賞等受賞．}


\end{biography}






\biodate

\end{document}
