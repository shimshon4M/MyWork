<?xml version="1.0" ?>
<root>
  <jtitle>「怒り」の発話を対象とした話者の感情の程度推定法</jtitle>
  <jauthor>有本泰子大野澄雄飯田仁</jauthor>
  <jabstract>音声認識の精度の向上にともなって，コールセンターなどへの自動音声応答システムの導入の要求が高まり，人間がコンピュータと対話する機会も増加する傾向にある．これまでの対話システムは言語情報のみを扱い，そのパラ言語情報を扱うことは少ないため，人間同士の対話と比較すると，コンピュータとの対話ではコンピュータが得る人間の情報は小さい．本研究では音声の音響的特徴と言語表現の特徴から推定可能な「怒り」の感情を検出するために，感情の程度による音響的・言語的変化を分析し，コンピュータと人間とのインタラクションにおける人間の感情を捉えることを目指す．非対面の擬似対話により，認識性能に対する不満からくる「苛立ち」や，クレーム対応時におけるユーザの「腹立ち」の内的感情を表現した怒りの音声を収録し，主観評価により感情の程度を付与した音声データを作成した．本論では，怒りの感情を含むと判定された発話について，つぎの3種の特性，声の高さや強さ等の音響的特徴，言語形態上の語彙使用の特徴，語用論的な特徴である文末表現の特徴に着目し，発話者の感情表現とその言語表現・音響的特徴との定量的な関係を分析し，怒り表現の音声言語の特徴付けを試みた．とくに，接続助詞「けど」，「ので」の主節が現れずに発話が中止する接続助詞中止型において，怒りの程度が高いことを明らかにした．</jabstract>
  <jkeywords>感情音声，韻律，話し言葉，言語表現</jkeywords>
  <section title="はじめに">インターネットが普及し，ユビキタス社会が浸透するなか，人間がコンピュータと対話する機会も増加する傾向にある．これまでの対話システムは言語情報のみを扱い，そのパラ言語情報を扱うことは少ないため，人間同士の対話と比較すると，コンピュータとの対話ではコンピュータが得る人間の情報は少ない．本研究では音声の言語表現の特徴と音響的特徴から推定可能な感情を検出するために，感情の程度による言語表現の特徴および音響的変化を分析し，コンピュータと人間とのインタラクションにおける人間の感情および態度表出を捉えることを目指す．それにより，両者の円滑なコミュニケーションを図ることを目的としている．将来の具体的応用対象として考えられる対話を想定し，コールセンターなどへの自動音声応答システムにおける認識性能に対する不満からくる「苛立ち」や，真意が伝わらないことに対する「腹立ち」の表現などに着目して，ユーザの内的状態をその発話の言語表現および音響的な特徴から推定する可能性について検討する．本報告では，感情表現を含む音声データの収録方法および感情情報を付与する主観評価法および言語表現・音響的特徴をパラメータとした決定木による「怒り」の感情の程度を推定する実験手法に関して述べ，今後の分析手法の指針について報告する．</section>
  <section title="関連研究">ここでは感情の心理学的なモデルに関する研究および音響的特徴による感情の推定および識別手法に関する研究，言語表現と心的状態および態度に関する研究について述べる．感情の心理学的なモデルに関しては様々な研究がとり行われているものの，現状では広く使用されるモデルが確立されておらず，感情にまつわる研究でも様々なカテゴライズが独自に行われ，その独自のモデルに基づいて研究が行われている．本論文では，心理学的な尺度をもとに怒りの感情の程度を推定する手法について述べるので，ここでは各モデルがどのような尺度で構成されているかに着目したい．心理進化論的なアプローチから基本感情を8感情(acceptance,anger,anticipation,disgust,joy,fear,sadness,surprise)に設定し，立体構造モデルを定めたPlutchikの研究がある．Plutchikは強度(intensity)または覚醒(arousal)という尺度で基本感情ごとに類似する感情を立体モデルの縦軸に当てはめている．RussellはShlosbergのcircularstructuralmodelをもとに水平軸に快(pleasure)—不快(displeasure)，垂直軸に覚醒(arousal)—眠気(sleep)の2次元で表される平面状に日常使用する一般用語で分類した感情を円環に並べたcircumplexmodelを提唱している．ここで特筆すべきは，Plutchikが同様と捉えた強度と覚醒の次元を別のものとして捉えている点である．Russellは感情の強度は円環の中心からのベクトルの長さで表されるとしている．Russellが強度と覚醒の次元を別のものと捉える理由はDalyらの理論にある．Dalyらはpleasantnessとactivityの2軸の他に円錐状にneutralに向かって上昇するintensityの次元を設けた3次元モデルを提唱し，それまで同様に扱われていたactivityとintensityの違いを明確にしている．本論文は，自然な対話のなかで発声された怒りの音声の感情の強さの程度をintensityの次元で計るものとする．音響的特徴による感情の推定および識別手法に関する研究は1つの感情を扱うのではなく，多感情を扱い，感情間の識別を行う研究が多く行われている．本論文では怒りの感情の認識に向けた検討を行うため，怒りの音声に限定した研究あるいは怒りの音声を2種類に分類して識別を行った研究について述べたい．武田らは平板，中高，頭高の3種類のアクセント型を持つ4モーラと6モーラの有意味単語および無意味単語をNHKアナウンサー4人および音声研究者1名の計5人により平常，軽い怒り，怒り，激怒の4段階で発声されている音声試料を用意し，音声パワー，時間構造（持続時間，発話速度）および基本周波数を韻律の特徴パラメータとして分析を行った．その結果，怒りの度合いが大きくなるにしたがって，最高音圧および最高基本周波数の増大が認められている．また，時間構造に関する特徴では，怒りの度合いが強くなるに従って早口になる傾向が見られる一方，逆に激怒時には発話が遅くなる傾向が見られたことも確認している．Shribergらの研究はDARPACommunicatorProjectのもとで開発された電話による航空券予約システムを利用して，演技ではない実際の音声の収録を行い識別実験に利用している．怒りのなかでもfrustrationとannoyanceに限定し，話速，休止，基本周波数，音圧，スペクトログラムなどの音響的特徴だけでなく，対話中の発話の位置や繰り返しや言い直しなどの情報もパラメータとして加え，怒りの音声の特徴を分析している．その分析の結果をもとにCART-styleの決定木によって感情を識別し，すべてのパラメータを利用した識別ではfrustrationおよびannoyanceの発話とそれ以外の発話を80%以上の正解率で識別している．ここにおいて特筆すべきは，対象の音声が従来の研究によくみられるアナウンサーや俳優により演じられた感情音声ではないことである．実際に人間が発する自然な発話を対象とすることで，コンピュータとの対話に生じる人間の自然な感情を識別の対象としているのである．Banseらは多感情の識別実験を行っているが，複数の感情のうち，怒りをHotAngerとColdAngerに分け，異なる感情として扱い，人間による判断と音響パラメータを用いたジャックナイフ法および判別分析による識別実験との比較を行っている．その結果，HotAngerはジャックナイフ法で69%，判別分析で75%の正解率を得ている．一方，ColdAngerは正解率が低く，いずれも50%以下の成績であった．本論文では，言語の使用を話者の心的状態および態度表出として捉え，感情表出時にどのような話者の意図が存在しているのかを分析し，感情を捉える可能性について検討するので，言語表現と意図との関係について検討された研究を先行研究として挙げる．言語表現と話者の心的状態および態度に関する認知心理学的なアプローチとして横森の接続助詞ケドの文末用法に関する考察がある．横森によれば，文末のケドに符号化された意味は従属節から予期されることに対して，聞き手が認知していることが逸脱的であるという認知的評価であるとしている．心的態度表出はこの認知的評価により決定付けられる．さらに，終助詞「よ」または「ね」の語用論的機能とイントネーションとのかかわりについても研究されている．</section>
  <section title="音声資料">怒りを表現した発話を含むできる限り自然な対話音声を収録し，各収録発話に対し5段階の主観評価に基づいて，感情の程度の実測値を付与した．ここでは，実際に行った音声収録方法・主観評価法について述べる．</section>
  <subsection title="音声収録手法">コンピュータ対人間および人間対人間の擬似対話を設定し，収録を行った．発話内容を限定せず，(a)ユーザ役の音声提供者がコンピュータ役の人間と対話をし，コンピュータの認識ミスによる聞き返しにより怒りを誘発させる方法と，(b)あらかじめ，クレームの内容を提示し，人間のオペレータとその内容について話し合ってもらう方法の2通りの対話を実施した．その際，音声提供者には対話に必要な最低限の情報のみを与え，オペレータの指示に従って自由に発話するようにした．実際の対話例を図に示す．収録は一般の大学生10名（男性5名，女性5名）がユーザ役の音声提供者となり，研究の趣旨を熟知しているオペレータ役1名が対応した．オペレータ役とユーザ役とは非対面で対話を行い，それぞれの発話をDATレコーダに左右チャネルに分けて録音した．収録した音声を10kHz，16bitでディジタル化し，ユーザ役の音声データを発話単位に切り出した5名（男性3名，女性2名）による発話から，159発話を音声資料として使用した．各々の発話の長さは様々で，最短の発話は「はい」(112ms)，最長の発話は「だから，その…そのデータベースに全部残っているっていう証明はどうやってするんですか」(6.26s)であった．</subsection>
  <subsection title="主観評価法">音声資料に対して，含まれている怒りの程度を定量化するため，主観評価実験を行った．被験者は大学生12名（男性11名，女性1名）で，ヘッドホンを通して1発話につき2回ずつランダムに提示される各発話について，怒りの程度を1（ぜんぜん）から5（すごく）までの5段階で評価させた．発話ごとに評価された値の平均値を求め，それを怒りの程度を表す実測値として各発話に付与した．さらに，音響的な特徴を分析する際に，怒りの程度による大まかな傾向をみるため，全159発話の音声資料を主観評価値をもとに4つのクラスタにクラスタリングした．クラスタリングには距離尺度にWard法を用いた階層型分類法を利用した．以後，分類した4つのクラスタを平静から順に怒りの程度が大きくなるようA，B，C，Dと称する．各クラスタのデータ数を表にまとめた．なお，評価値，すなわち怒りの程度は連続に分布しており，このクラスタリングは以後の分析のために便宜上行ったもので，相隣り合うクラスタの境界は必ずしも明確ではない．</subsection>
  <section title="「怒り」を含む発話の分析"/>
  <subsection title="音響的分析">本研究では音声の音響情報を反映するようなパラメータを怒りの推定のために利用する．検討したパラメータは感情表現に関する先行研究を参考に定めた．多くのパラメータについては，発話内の代表的な値として平均値を，時間的な変動の指標として発話内での標準偏差の値を用いた．</subsection>
  <subsubsection title="高さに関連するパラメータ">音声の高さに関連するパラメータとして，表に挙げた基本周波数(F0)から求められる発話内での統計量F-1〜F-7を用いる．なおF0は可変窓長の変形自己相関関数法により10ms間隔で自動抽出した後，視察により修正を施したものを用いた．また，F0の絶対的な値を対象とするパラメータ(F-1，F-2，F-3)については，男女間の差の影響を除去するため，簡易的ではあるが，男女それぞれについて全データの平均値を求め，その値を差し引くことで男女差の正規化を行ったパラメータ(F-4，F-5，F-6)を用意した．</subsubsection>
  <subsubsection title="強さに関連するパラメータ">音声の強さに関連するパラメータとして，表に挙げたP-1〜P-3を用いる．P-1〜P-2のパラメータは振幅のRMS値10000を0dBVとしたdBVを単位とする．短時間平均パワーは窓長20msの矩形窓を施し，5ms間隔で求めた．P-3の変動量は，短時間平均パワーの変化の緩急を定量化するため，11フレームに渡る短時間平均パワーの回帰直線の傾きのRMSを求めたものである．</subsubsection>
  <subsubsection title="速さ・長さに関連するパラメータ">発話の速さ・長さに関連するパラメータとして表に示す2種の値を用いる．D-1は呼気段落のモーラ数を発話内で平均したものであり，D-2は休止区間を除外して求めた平均発話速度（単位：mora/s）である．</subsubsection>
  <subsubsection title="声質に関連するパラメータ">声質に関連するパラメータとして，ここではスペクトル包絡の大局的な傾きに着目して，表に示すC-1〜C-2を取り上げた．スペクトル包絡の大局的な傾きに関連するパラメータとして，改良ケプストラム法により求めたケプストラムの第1次係数の値を使用した．</subsubsection>
  <subsubsection title="各パラメータに対する実測値の分布">上述の計14種のパラメータがそれぞれ単独でどの程度怒りの推定能力を有するかについて検討する．図はいくつかのパラメータについて，怒りの程度に関する4つのクラスタ内での平均値，標準誤差，標準偏差を示したものである．個別のパラメータに関する詳細については割愛するが，クラスタ間での傾向は以下の2つに大別できる．1つは怒りの程度が大きくなるに従って，ほぼ単調に値が増加あるいは減少するもの（図2中D-2およびF-2）で，もう1つは怒りの程度が最大のクラスタDについてAからCまでの傾向と反する変化を呈するもの（図2中P-2およびF-3）である．</subsubsection>
  <subsubsection title="パラメータ間の相関">複数のパラメータを組み合わせて怒りの推定に用いる際に相互に相関の高いパラメータ対を把握する必要がある．上述の14種のパラメータに関して相関係数を求めたところ，いずれのパラメータも同種のカテゴリを超えて，高い相関が見られたものはなかった．同一のカテゴリ内で特に正の相関が大きいもの(r≧0.75)は，高さに関連するパラメータでは，F0対数平均，F0最高値，F0最低値のそれぞれの組み合わせであった．</subsubsection>
  <subsection title="言語的分析">収録した音声データのうち怒りの強いクラスタ内に疑問表現，終助詞「よ・ね」や接続助詞中止型「ので・けど」が見られた．ここでは，こうした言語特徴を利用し，怒りの推定に貢献するパラメータを用意するため，語用論的機能の観点から見た怒りとの関係や音響的特徴による機能の変化などに着目し，分析を行う．</subsection>
  <subsubsection title="文構成に関するパラメータ">怒りの強いクラスタであるCとDにおいては，「それはどうやって証明するんですか？」「でも全部残っているって証明はされてないじゃないですか？」などの疑問文が多く見られた．疑問表現は一般的に未知の部分の情報を相手に求める質問型と自分自身に問いかける自問型に分類される．質問型では上昇調のイントネーションが使われ，自問型では下降調のイントネーションが使われる．本研究では対話を取り扱っているので，主に質問型の疑問文を対象とする．疑問の形式としては，「昨日，花子に会いましたか？」などの事柄の真偽に関わる「真偽疑問文」，「昨日，誰に会ったのですか？」などの「疑問語疑問文」，「文法は，好きですか，嫌いですか？」などの「選択疑問文」がある．言語の表層的な構文としては「真偽疑問文」は疑問の終助詞「か／の」で終了することが認識されているが，「か／の」を付けず，文末の音響的な上昇イントネーションにするだけでも真偽疑問文になることも確認されている．「疑問語疑問文」では「何」や「誰」などの疑問語を文中に含み，普通体では文末には「か」が原則使用できない（丁寧体では「か」は使用できる）．文末の言語表層的な表現が制限される一方で，「疑問語疑問文」でも文末の音響的な上昇イントネーションは保たれている．こうしたことから，疑問表現と音響的特徴との関連は深いものと考えることができる．疑問表現は既定の部分を前提として，未定の部分を質問する用法で用いられるが，ここでは相手の主張の正当性に対する強い反意を疑問文として表現していると捉えられる．</subsubsection>
  <subsubsection title="文末表現を捉えたパラメータ">話し言葉の1つの典型発話タイプである「予約したんですけど／予約したんで／残ってるんスけど」などの接続助詞中止型は，一般的に主節部分を明示せずに，聞き手にその解釈を委ねる用法であると捉えられる．こうした表現は，その主節に含まれると考えられる，対話相手の対応の悪さに対する「怒り」の内容を，聴き手に想起・自覚させ，強く印象つける役目を果たすものと考察できる．その例として，想定される主節の「怒り」の内容例を表にまとめる．さらに，横森は感情の認知的モデルにおける感情状態に遷移する前の認知的評価のみを接続助詞の意味とみなし，主体の心的態度は従属節における入力に対する主体の価値的関係によって決定されるとしている．その上で，文末における「けど」の符号化された意味を従属節から「予期されることに対して，聞き手が認知していることが逸脱的である」と定めている．収録した対話においても，怒りを誘発するために，話し手（ユーザ）が予期していることに対して，聞き手（オペレータ）が認知していることが逸脱している対話が多い．そのため，接続助詞中止型で終わる発話が収録されたと考えられる．終助詞「ね・よ」で終止する発話は，いずれも表面上は同意要求あるいは確認としての使用と見なせるが，言語運用的には話者が納得できない条件，事態について同意させられていることに対する話者の「怒り」の内的感情を表していると捉えることができる．終助詞「ね・よ」に関しては多くの研究者がその意味・機能やイントネーションとのかかわりについて研究を行っている．片桐によれば，「ね」で終止する発話は文末に上昇調のイントネーションが加わると確認要求，下降調のイントネーションが加わると情報提供の機能を果たす．また，「よ」についても上昇調のイントネーションが付随した場合は将来の聞き手の行動に対する純粋な依頼であるのに対し，下降調イントネーションが付随すると，この聞き手の行動に対する異議申し立てと捉えられるとしている．また，イントネーションの位置によって不満・強調・強引な押し付けなどさまざまな含みを持たせることが可能であるとしている．収録音声に見られる「ね」で終止する発話についても，イントネーションとの関わりにより，その言語機能に変化があった可能性を探るため，やや怒りの強いクラスタCで見られる発話に限定して，文末30フレームのF0の傾きと手前30フレームのF0の傾きの差分を求めた（図）．一般に句末のF0は下降調になるといわれるが，終助詞「ね」で終わる発話はその他の発話に比べ，緩やかな変化ではあるものの上昇傾向を示していると考えられる．ここでの発話の機能としては確認要求とみなすことができる．</subsubsection>
  <subsubsection title="言語表現のパラメータ化">言語パラメータとして，各発話を平叙文，疑問文に分類し，表中のL-1文構成として挙げた．この際，平叙文でも語尾のイントネーションを上げることで疑問となる表現は疑問文として扱った．さらに，接続助詞中止型「ので・けど」と終助詞「ね・よ」を表中のL-2文末表現として，パラメータに加えた．各発話が接続助詞中止型「ので・けど」／終助詞「ね，よ」で終わっていることを分類の基準とした．ただし，文末に接続詞中止型の「ので・けど」が来る場合，「したいんですけど」という発話と「したんですけど」という2種類の発話が現れていたが，言語表層からもその使用の違いが明らかであるため，「したいんですけど」という発話は接続助詞中止型の分類とはしなかった．</subsubsection>
  <subsubsection title="言語パラメータに対する実測値の分布">言語パラメータに対する実測値の分布を図・に示す．図の文構成の分布をみると，疑問文のほうが怒りの程度の高い発話に多く見られ，平叙文との差も明らかである．文末表現の分布では，すべての項目でバラツキが大きくなっているが，平均値をみるとその他・終助詞・接続助詞の順に値が上昇している．</subsubsection>
  <section title="推定実験">収録した音声データを用い，音響パラメータと言語パラメータを使用して，決定木による怒りの程度を推定する実験を行った．ここではその実験手法とその結果について述べる．</section>
  <subsection title="音声データとパラメータの組み合わせ">収録した音声データにはデータ数に男女の偏りがあることが分かっているため，全159発話を含むdatasetAの他に男性の発話のみ（141発話）を含むdatasetBを用意した．各datasetに対し，F0の絶対的な値を用いるパラメータ(F-1〜3)を除いた11種の音響パラメータを用いた実験と言語パラメータを加えた13種のパラメータによる実験を行った．さらに，datasetAには女性の発話が含まれていることから，男女差の影響の程度を比較するため，14種のすべてのパラメータを用いることにした．datasetAによる14種のパラメータを用いた実験を実験I，11種のパラメータを用いた実験を実験II，言語パラメータを加えた13種のパラメータを用いた実験を実験IIIとする．datasetBによる11種のパラメータを用いた実験を実験IV，言語パラメータを加えた13種のパラメータを用いた実験を実験Vとする．各datasetに使用するパラメータ数とその実験名称を表にまとめた．</subsection>
  <subsection title="実験手法">推定実験は決定木を用いて行った．交差検定を行うため，各datasetの発話を3つのグループに分割した．各datasetは発話数が限られているため，ランダムに三分割を行うと，グループ間に怒りの程度の偏りが生じてしまう．そのため，1発話ずつを主観評価値の高いデータから順に3つのグループに振り分け，グループ間の怒りの程度の偏りを排除し，実験の信頼性の確保に努めた．決定木のための学習用データとして2グループを，評価用データとして1グループを使用する．データに依存しない最適な木を求めるため，学習用・評価用データに使用するグループを入れ替えてn-fold交差検証法(n=3)を行う．学習用・評価用データに含まれる怒りの種類に影響されない木を求めるため，評価用データの分岐回ごとの予測値と主観評価による実測値の標準誤差が最小になる分岐回で木の生成を停止した．実験の評価方法として主観評価により付与された怒りの実測値と決定木による予測値との標準誤差を求め，推定性能の指標とした．</subsection>
  <subsection title="結果と考察">実験の結果，音響パラメータのみを用いた実験I・II・IVでは8回目，7回目，6回目が最適な分岐回となり，その際の平均推定誤差は0.54，0.60，0.53となった．音響パラメータに言語パラメータを加えた実験III・Vでは5回目，4回目が最適な分岐回となり，その際の平均推定誤差はともに0.50となった．各実験での分岐停止回と平均推定誤差を表に，各分岐回で選択されたパラメータを表・にまとめる．音響パラメータのみの実験と言語パラメータを加えた実験の結果を比べると，男女混合のdatasetAでは平均推定誤差に0.10差，男性のみのdatasetBで0.03差となり，音響的特徴のみの実験よりも言語的特徴を含めた実験のほうが推定精度が若干向上している．音響パラメータのみを使用した実験I・II・IVにより選択されたパラメータをみると，共通に選択されたパラメータ(F-7，P-2，D-2)があることが分かる．男女の発話が混合するdatasetと男性の発話のみのdatasetの間で怒りの発話に共通する音響的特徴（発話内での声の高さに大きな変化がある，声が大きい，速い）があることが分かる．実験IVにより選択されたパラメータをみると，すべてのグループで同じパラメータが選択されていることが分かり，学習用・評価用データに依存することなく，男性の怒りの発話の特徴をより正確に捉えることができたといえる．実験IVgroup1による決定木（図参照）の最後の3回の分岐ではD-2で速くとゆっくりに分かれた発話がその後，同じF-6のパラメータで分岐し，声の低い発話と声の高い発話のそれぞれが怒りの程度が高いと推定されていることが分かる．これは音声データに2種の怒りの発話（はやく・声の高い発話，ゆっくり・声の低い発話）が存在していることを示唆する．ひとつは対人間の対話で納得できない相手の主張に対し感情的になっている発話であり，もう1つは対コンピュータの対話で誤認識に対し同一内容を丁寧に繰り返している発話と認識内容を確認する際に念を押すようにゆっくりと話す発話である．表をみると，言語パラメータL-1がほぼすべてのgroupで1回目・2回目という早い分岐回で選択され，疑問文である発話が怒りが強いと判断されている．これは疑問文の文構成が怒りの程度の推定に大きく寄与したと言える．音響パラメータも音響パラメータのみの実験とほぼ同じパラメータが選択され，怒りの発話の音響的な特徴も捉えられているといえる．一方で，L-2文末表現はdatasetAのgroup3で3回目の分岐で選択されている．文末表現も怒りを推定するパラメータとなりえる可能性を確認することが出来た．今回の分類では3で述べた用途以外の接続助詞中止型および終助詞「ね・よ」が含まれていた可能性があるため，そうした2種の用途を区別することが出来れば，さらにパラメータとしての精度を向上させることが出来ると考えられる．</subsection>
  <section title="おわりに">コンピュータと人間とのインタラクションにおいて人間が表出するパラ言語情報・非言語情報を捉えることを目指し，音声の音響的特徴と言語表現の特徴から推定可能な感情を検出するために，感情の程度による音響的特徴・言語使用の特徴を分析した．感情を「怒り」に限定し，非対面の擬似対話により，認識性能に対する不満からくる「苛立ち」や，クレーム対応時におけるユーザの「腹立ち」の内的感情を表現した怒りの音声を収録，主観評価により感情の程度を付与した音声データを作成した．また，決定木により「怒り」の程度の推定実験を行い，データに依存しない「怒り」の音響的な特徴を捉えた．感情を含む音声に「それはどうやって証明するんですか？」「でも全部残っているって証明は，されてないじゃないですか？」などの疑問文の文構成，「したんですけど／したんで／してるんスけど」などの接続助詞中止型で終止する発話，終助詞「よ，ね」で終止する発話が頻出していることから，発話者の感情表現とその言語表現との定量的な関係を分析し，怒りを推定するパラメータとして適用した．その結果，文構成・文末表現などの言語表現も「怒り」の感情の推定に貢献することを明らかにした．今後は，自然な対話の中でのユーザの感情をその発話の音響的・言語的特徴から推定するために，データの量的・質的拡充を図りながら，より推定性能の優れた音響パラメータ・言語パラメータを追究し，詳細な分析と特徴抽出を行う．</section>
</root>
