<?xml version="1.0" ?>
<root>
  <jtitle>NMFによる重み付きハイパーグラフを用いた	アンサンブル文書クラスタリング</jtitle>
  <jauthor>新納浩幸佐々木稔</jauthor>
  <jabstract>	本論文ではNon-negativeMatrixFactorization(NMF)を利用したアンサンブル文書クラスタリングを提案する．NMFは次元縮約を利用したクラスタリング手法であり，文書クラスタリングのようにデータが高次元かつスパースとなる場合に効果を発揮する．ただしNMFは初期値によって得られるクラスタリング結果が異なるという問題がある．そのために通常は初期値を様々に変えて，複数個得られたクラスタリング結果から，NMFの分解の精度の最もよい結果を選択する．しかしNMFの分解の精度はクラスタリング結果の精度を直接表しているわけではないので，最適な選択が行える保証はない．ここではNMFによるクラスタリングの精度を高めるために，複数個得られたクラスタリング結果をアンサンブルすることを試みる．アンサンブルは，複数個のクラスタリング結果からハイパーグラフを作成し，そのハイパーグラフで表現されたデータをクラスタリングすることで行える．従来，そのハイパーグラフは0か1のバイナリ値が用いられていたが，ここではNMFの結果を用いて，適切な実数値の重みを与えることで改良する．実験ではk-means，NMF，通常のハイパーグラフを用いたアンサンブル手法および重み付きハイパーグラフを用いたアンサンブル手法（本手法）のクラスタリング結果を比較し，本手法の有効性を示す．</jabstract>
  <jkeywords>アンサンブルクラスタリング，NMF，ハイパーグラフ，局所解，アンサンブル学習</jkeywords>
  <section title="はじめに">本論文では，ランダムな初期値を使ってNon-negativeMatrixFactorization(NMF)による文書クラスタリングを複数回行い，それらの結果をアンサンブルすることで，より精度の高い文書クラスタリングの実現を目指す．複数のクラスタリング結果を統合する部分で，従来のハイパーグラフの代わりに重み付きハイパーグラフを用いることが特徴である．文書クラスタリングは，文書の集合に対して，知的な処理を行う基本的な処理であり，その重要性は明らかである．例えばテキストマイニングの分野では，文書クラスタリングは基本的な構成要素であるし，情報検索の分野では，検索結果の概観を視覚化するために検索された文書の集合をクラスタリングする研究が盛んに行われている．文書クラスタリングでは，まずデータとなる文書をベクトルで表現する．通常，bagofwordsのモデルを用い，次にTF-IDFなどによって次元の重みを調整する．このようにして作成されたベクトルは高次元かつスパースになるために，文書クラスタリングではクラスタリング処理を行う前に主成分分析や特異値分解などの次元縮約の手法を用いることが行われる．次元縮約により高次元のベクトルが構造を保った状態で低次元で表現されるため，クラスタリング処理の速度や精度が向上する．NMFは次元縮約の手法を応用したクラスタリング手法である．今，クラスタリング対象の(m)次元で表現された(n)個の文書を(m)行(n)列の索引語文書行列(X)で表す．目的とするクラスタの数が(k)である場合，NMFでは(X)を以下のような行列(U)と(V^T)に分解する．そして行列(V)がクラスタリング結果に対応する．[X=UV^T]ここで(U)は(m)行(k)列，(V)は(n)行(k)列である．(V^T)は(V)の転置を表す．また(U)と(V)の要素は非負である．与えられた(X)と(k)から，ある繰り返し処理により(U)と(V)を得ることができる．しかしこの繰り返し処理は局所最適解にしか収束しない．つまりNMFでは，与える初期値によって得られるクラスタリング結果が異なるという問題がある．通常は適当な初期値を与える実験を複数回行い，それらから得た複数個のクラスタリング結果の中で(X)と(UV^T)の差||_F)により測定する．が最小のもの，つまり(X)の分解の精度が最も高いものを選ぶ．しかし分解の精度は，直接的にはクラスタリングの精度を意味してはいないため，最も精度の高いクラスタリング結果を選択できる保証がない．ここではNMFの分解の精度を用いて，複数個のクラスタリング結果から最終的なクラスタリング結果を選ぶのではなく，複数個のクラスタリング結果をアンサンブルさせて，より精度の高いクラスタリング結果を導くアンサンブルクラスタリングを試みる．一般にアンサンブルクラスタリングの処理は2段階に分けられる．まず第1段で複数個のクラスタリング結果を生成し，次の第2段でそれらを組み合わせ，最終的なクラスタリング結果を導く．複数個のクラスタリング結果を生成する手法としては，k-meansの初期値を変化させたり，ランダムプロジェクションにより利用する特徴を変化させたり，``weakpartition''を生成する研究などがある．また複数個のクラスタリング結果を組み合わせる手法としては，データ間の類似度を新たに構築する手法や，データの表すベクトルを新たに構築する手法などがある．ここでは後者の手法を改良して用いる．論文では，データの表すベクトルを新たに構築するために，複数個のクラスタリング結果から，データセットに対するハイパーグラフを作成する．このハイパーグラフは，データセットが表す行列に相当する．このハイパーグラフで表現されたデータに対してクラスタリングを行い，最終的なクラスタリング結果を得る．ただしこのハイパーグラフではエッジの重みが0か1のバイナリ値である．ハイパーグラフが行列に相当すると考えると，エッジの重みの意味は同じクラスタに属する度合いとなり，バイナリ値で表すよりも非負の実数で表す方がより適切と考えられる．そこで本論文ではハイパーグラフのエッジの重みに非負の実数値を与える．具体的には，NMFのクラスタリング結果が行列(V)で得られ，同じクラスタに属する度合いが(V)から直接求められることを利用する．またここでは，この実数値の重みを付けたハイパーグラフを重み付きハイパーグラフと呼ぶことにする．実験ではk-means，NMF，通常のハイパーグラフを用いたアンサンブル手法および重み付きハイパーグラフを用いたアンサンブル手法（本手法）の各クラスタリング結果を比較し，本手法の有効性を示す．</section>
  <section title="NMF と初期値の問題"/>
  <subsection title="NMF とその特徴">NMFは(mn)の索引語文書行列(X)を，(mk)の行列(U)と(nk)の行列(V)の転置行列(V^T)の積に分解する．ただし(k)はクラスタ数である．[X=UV^T]NMFはクラスタに対応したトピックの次元を(k)個想定し，その基底ベクトルの線形和によって，文書ベクトル及び索引語ベクトルを表現することに対応する．つまり基底ベクトルの係数が，そのトピックとの関連度を表しているので，行列(V)自体がクラスタリング結果と見なせる．具体的には，(i)番目の文書(d_i)は，行列(X)の第(i)列のベクトルで表現され，その次元圧縮された結果が，行列(V)の第(i)行のベクトルとなる．このとき，(V)の第(i)行のベクトルは[(v_i1,v_i2,,v_ik)]と表せ，文書(d_i)のクラスタの番号は[_j1:kv_ij]となる．</subsection>
  <subsection title="NMF のアルゴリズム">与えられた索引語文書行列(X)から，(U)と(V)は以下の繰り返しで得ることができる．u'_iju_ij(XV)_ij(UV^TV)_ijv'_ijv_ij(X^TU)_ij(VU^TU)_ijgatherここで(u_ij)と(v_ij)はそれぞれ(U)と(V)の(i)行(j)列の要素を表す．また((X)_ij)により行列(X)の(i)行(j)列の要素を表す．上記の式により，現在の(U)と(V)から，(u'_ij)と(v'_ij)が得られる，つまり新たな(U')と(V')が得られるので，それを(U)と(V)と見なして，上記の式を繰り返し適用する．また各繰り返しの後に(U)を以下のように正規化する．繰り返しの終了は，繰り返しの最大回数を決めておくか，(UV^T)と(X)との距離(J)の変化量から判定する．(J)の値はNMFの分解の精度を表現している．NMFではこの分解の精度がクラスタリングの目的関数となっており，この分解の精度が高い，つまり(J)の値が小さいほど，良好なクラスタリングであると推定する．また(||||_F)はFrobeniusノルムを表し，(mn)の行列(A)のFrobeniusノルムは以下で定義される．[||A||_F=_i=1^m_j=1^na_ij^2]</subsection>
  <subsection title="NMF の解の多様性">通常，行列(V)と(U)の初期値にはランダムな値を与える．しかしによる繰り返しは局所最適解にしか収束しないために，(V)と(U)の初期値の与え方によって，最終的に得られる(V)と(U)は大きく異なり，結果としてクラスタリングの精度も大きく異なる．例えば，は本論文の実験で用いた文書データセットtr45に対して，NMFによるクラスタリングの実験を20回行った結果である．ただし各実験でのNMFの初期値にはランダムな値を与えており，各実験の初期値は異なる．の横軸は実験の番号を示し，縦軸はクラスタリングの精度を表している．から初期値によって得られる精度が大きく異なることが確認できる．つまり，NMFは初期値によって得られるクラスタリング結果が異なる．通常は適当な初期値を与える実験を複数回行い，それらから得た複数個の解の中で(X)の分解の精度が最も高いものを選ぶ．しかし分解の精度は，直接的にはクラスタリングの精度を意味していないため，最も精度の高いクラスタリング結果を選択できる保証がない．ここでは複数個のクラスタリング結果から1つを選択するのではなく，それらをアンサンブルするアンサンブルクラスタリングを試みる．</subsection>
  <section title="アンサンブルクラスタリング"/>
  <subsection title="ハイパーグラフによるデータの再表現">本手法のアンサンブルクラスタリングでは，NMFの初期値を様々に変化させて，複数個のクラスタリング結果を生成する．次に複数個得られたクラスタリング結果から各データに対するベクトル表現を新たに作成し，その新たにベクトル表現されたデータに対してクラスタリングを行うことで，アンサンブルクラスタリングを実現する．ここでは複数個得られたクラスタリング結果からデータに対する新たなベクトル表現を作る方法を説明する．基本的には論文で提案されたハイパーグラフを用いる．クラスタの数が(k)個であり，得られているクラスタリング結果が(m)種類の場合，各データは(km)次元のベクトルで表現される．データ(d)の(k(i-1)+c)次元の値は，(i)番目のクラスタリング結果として，データ(d)がクラスタ番号(c)のクラスタに属していれば1を，属していなければ0を与える．この結果，データ(d)の(km)次元のベクトル表現が得られる．例を示す．(k=3)，(m=4)とする．またデータは(d_1,d_2,,d_7)の7つとする．4種類のクラスタリング結果が以下のようになっていたとする．第1のクラスタリング結果：[d_1,d_2,d_5,d_3,d_4,d_6,d_7]この結果から目的の行列の1列目から3列目が得られる．[[]]第2のクラスタリング結果：[d_1,d_5,d_2,d_3,d_4,d_6,d_7]この結果から目的の行列の4列目から6列目が得られる．[[]]第3のクラスタリング結果：[d_2,d_5,d_1,d_4,d_3,d_6,d_7]この結果から目的の行列の7列目から9列目が得られる．[[]]第4のクラスタリング結果：[d_1,d_5,d_7,d_3,d_4,d_2,d_6]この結果から目的の行列の10列目から12列目が得られる．[[]]以上の4つの行列を結合させ，以下の(712)の行列を得る．これがハイパーグラフである．このハイパーグラフにおける行ベクトルが，各データ（本論文の場合，文書）の新たなベクトル表現に対応している．このベクトルの類似度に基づいて，データをクラスタリングする．[[]]</subsection>
  <subsection title="重み付きハイパーグラフ">ハイパーグラフが表す行列の各要素の値は0か1のバイナリ値である．しかし値の意味を考えれば，その次元に対応するあるクラスタリング結果のあるクラスタに属する度合いと捉えられる．そのため0か1のバイナリ値ではなく，非負の実数値を与える方が適切である．しかもNMFの場合，各クラスタリング結果では各クラスタに属する度合いに対応する値が行列(V)に記載されている．そこでここではハイパーグラフの要素が1である部分を，行列(V)の値から得ることで，非負の実数値を与えることにした．このようにして作成したハイパーグラフを，ここでは重み付きハイパーグラフと呼ぶ．に重み付きハイパーグラフの作成例を示す．これは先の第1のクラスタリング結果に対応する部分である．(d_1)から(d_7)の7個の文書データセットをNMFにより3グループにクラスタリングする．結果は行列(V)で表される．次に行列(V)を正規化する．(V)の各行に注目し，最大値の部分を1に，それ以外を0に変換したものが通常のハイパーグラフである．(V)の各行に注目し，最大値の部分はそのままに，それ以外を0に変換したものが本論文で提案する重み付きハイパーグラフである．</subsection>
  <section title="実験">本手法の有効性を示すために，k-means，NMF，通常のハイパーグラフを使うアンサンブル手法および重み付きハイパーグラフを使うアンサンブル手法（本手法）の4種のクラスタリング結果を比較する．利用するデータセットは以下のサイトで提供されている18種類である（）．http://glaros.dtc.umn.edu/gkhome/cluto/cluto/downloadverbatimデータセットは通常の索引語文書行列で表現されており，正規化されていない．ここではTF-IDFによって正規化を行った．実験結果をに示す．表の値はクラスタリング結果のエントロピーを表し，低い値ほどクラスタリングが良好であることを意味する．なお，ハイパーグラフのデータからのクラスタリングには，簡単のために，クラスタリングtoolkitのCLUTOを利用した．CLUTOはクラスタリング手法や類似度関数を様々に設定できるが，ここではdefaultの設定であるk-wayclusteringと呼ばれる手法とcosineの類似度を用いた．またハイパーグラフのデータからのクラスタリング手法には任意のものが利用可能であり，高機能なクラスタリング手法を用いて，更に高い精度を得ることも可能である．ただしここではアンサンブルすることの効果と，ハイパーグラフに重みを付ける効果を明確に確認するために，簡易なものを用いた．また，エントロピーについても注記しておく．エントロピーはクラスタリング結果を評価するための1つの尺度である．データセットのクラスタリングの正解が(K_h_h=1^k)であり，得られたクラスタリングが(C_j_j=1^k)となっているとき，クラスタ(C_i)に対するエントロピー(E_i)は以下で定義される．[E_i=-_h=1^kP(K_h|C_i)P(K_h|C_i)]各クラスタに対して(E_i)を求め，クラスタのデータ数による重み付き平均をとることで全体のエントロピーが定義される．すなわち以下の式となる．[_i=1^k|C_i|NE_i]ここで(N)は全データ数を表す．また定義中に確率(P(K_h|C_i))が出ているが，これは(K_h)と(C_i)に共通に存在するデータの数を(n_hi)と置き，(n_hi/|C_i|)によって推定する．またクラスタリングの精度は，クラスタリング結果の各クラスタを正解のクラスタに対応つけ，(n_hi)の合計を(N)で割った値により求まる．つまりエントロピーの値の低さとクラスタリングの精度はほぼ対応していると見なせる．本実験の場合，クラスタリングの精度を求めて，評価を行うことも可能ではあるが，クラスタリングの精度を求めるには，クラスタリング結果の各クラスタを正解のクラスタに対応させなくてはならない．この処理は組み合わせ最適化問題になっているために，単純には最適解が求まらない．そのために，ここではエントロピーによる評価を行っている．NMFの実験では初期値を20個用意し，得られた20個のクラスタリング結果において，NMFの分解の精度（の値）が最も高いものを選び，それをNMFのクラスタリング結果とした．NMFmeanとあるのは，20個のクラスタリング結果の平均のエントロピーである．表のstandardhypergraphが通常のハイパーグラフを使うアンサンブル手法，weightedhypergraphが重み付きハイパーグラフを使うアンサンブル手法（本手法）を意味する．NMFとNMFmeanを比較すると，NMFの方が若干エントロピーが大きい．つまりクラスタリング結果を評価するのに，を使うのは最良ではないことがわかる．またNMFmeanとweightedhypergraphを比較すると，18個のデータセット中17個で本手法の方がエントロピーが小さい．つまりこの点からアンサンブルすることの効果が確認できる．またstandardhypergraphとweightedhypergraphを比較すると，18個のデータセット中13個で本手法の方がエントロピーが小さく，ハイパーグラフに重みを与える効果も確認できる．なお18個中13個の改善は，統計的には以下のような観点から有意とみなした．standardhypergraphとweightedhypergraphのパフォーマンスが同程度である場合，standardhypergraphのエントロピーからweightedhypergraphのエントロピーを引いた値（値が大きいほど改善の度合いが高い）は平均0の正規分布と考えられる．そこで有意水準0.05としてt-検定の片側検定を用いると，棄却域は自由度が17であることに注意すると(1.74)以上となる．実際の値はstandardhypergraphのエントロピーからweightedhypergraphのエントロピーを引いた値の標本平均が0.03706，標本分散が0.007389なので，[0.03706-00.007389/17=1.78&gt;1.74]となり，パフォーマンスが同程度という仮説が棄却できる．</section>
  <section title="考察と関連研究">一般に複数の解をアンサンブルすると，複数の解の平均よりも良い値が得られると考えられる．本実験でも18個のデータセット中17個でアンサンブルの効果が得られているが，データセットtr23に関しては，本手法のエントロピーの値の方が高い．これは解の分散の影響と考えられる．実験で得られた各データセットに対するNMFによる20個のクラスタリング結果のエントロピーの分散と，におけるNMFmeanとweightedhypergarphとの差（つまりアンサンブルによる改善の度合い）をプロットした図をに示す．図の横軸が分散を示し，縦軸がweightedhypergarphとNMFmeanとの差（改善の度合い）を示している．をみると，分散が大きい2つ（cranmadとreviews）は，アンサンブルによる改善の度合いも大きいことが分かる．そして3番目に分散が大きなデータセットがtr23である．つまり分散の大きな解をアンサンブルすると，非常に良い結果を得ることもあるが，逆に悪い結果を得ることもあり得ると考えられる．データセットtr23に対するNMFの結果を見ると，1つだけ非常にエントロピーの低いクラスタリング結果が得られていた．この解を取り除いて，19個のクラスタリング結果で本手法によるアンサンブルを試したところ，NMFmeanのエントロピーは0.493，weightedhypergarphのエントロピーは0.492となり，アンサンブルの効果が現れた．また，ここではNMFで複数個のクラスタリング結果を生成する際に，個々のクラスタリング結果のクラスタ数は，最終的なクラスタ数と一致させている．しかしハイパーグラフの考え方を用いれば，生成される個々のクラスタリング結果のクラスタ数は任意でかまわない．実際にk-meansでは少ないクラスタ数に直接クラスタリングするよりも，多数のクラスタに分割してから，目的のクラスタ数にまとめた方が効果があることが経験的にわかっている．論文ではこのヒューリスティクスを利用して，多数のクラスタに分割してから，アンサンブルを行っている．本手法においても，そのような工夫を取り入れることも可能である．本手法ではハイパーグラフの値として，1に当たる部分を行列(V)の値を用いることで，実数値に変換した．この効果は実験で確認できている．この工夫を更に進めると，0に当たる部分にも行列(V)の値を用いることで，実数値に変換することが考えられる．この場合，ハイパーグラフは単純に各クラスタリング結果に対応する行列(V)を結合させたものになる．実際にこのようにして作ったハイパーグラフに対して，クラスタリングを行ってみた．結果を表に示す．ここでhypergraphVが行列(V)を結合させてハイパーグラフを作成する手法を示す．通常のハイパーグラフを使うよりも結果は良好であるが，1に当たる部分だけを精密化する方が効果があることがわかる．また0の値はそのままにしている方が，ハイパーグラフがスパースになり，データ間の類似度が0であるケースが生じやすくなる．そのためグラフスペクトル理論を用いたクラスタリング手法なども使えるようになるために好ましい．最後にアンサンブル学習との関連について述べる．アンサンブル学習とアンサンブルクラスタリングの違いは，クラスタにラベルがつくかどうかである．アンサンブル学習ではデータにラベルが付くので，そのラベルをもつデータがラベル付きのクラスタと見なせる．アンサンブルクラスタリングの場合は，クラスタにラベルがついていない．もしもクラスタにラベルをつけることができれば，アンサンブル学習の手法を直接利用できるために，さらなる改良や発展が可能である．クラスタにラベルをつける処理は，クラスタ数が2や3などの小さい場合はそれほど大きな問題ではないので，今後はクラスタにラベルをつけるという戦略で，アンサンブルを行う手法を開発したい．</section>
  <section title="おわりに">本論文では，NMFを用いたアンサンブルクラスタリングの手法を提案した．NMFの初期値を変化させて，複数個のクラスタリング結果を得る．次に得られた複数個のクラスタリング結果をハイパーグラフで表現し，それをクラスタリングすることで最終的なクラスタリング結果を得る．ハイパーグラフを作成する際に，NMFより得られた行列(V)を利用して，1の部分に実数値の重み付けする工夫を取り入れた．実験では18個のデータセットを用いて，k-means，NMF，通常のハイパーグラフを使うアンサンブル手法および重み付きハイパーグラフを使うアンサンブル手法（本手法）の比較を行った．エントロピーで評価を行い，本手法の有効性を確認できた．個々のクラスタリングで生成させるクラスタ数を変化させること，クラスタ数が小さい場合は，クラスタにラベルを与えて，アンサンブル学習の手法を利用することなどを今後の課題とする．document</section>
</root>
