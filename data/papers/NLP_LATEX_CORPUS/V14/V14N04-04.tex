    \documentclass[japanese]{jnlp_1.3e}
\usepackage{jnlpbbl_1.1}
\usepackage[dvips]{graphicx}
\usepackage{lingexample}
\usepackage{juline}
\usepackage{amsmath}

\setlength{\fboxsep}{2pt}
\setlength{\fboxrule}{0.25pt}

\Volume{14}
\Number{4}
\Month{July}
\Year{2007}
\received{2006}{11}{12}
\revised{2007}{3}{12}
\accepted{2007}{4}{13}

\setcounter{page}{67}

\jtitle{自動構築した大規模格フレームに基づく\\
	構文・格解析の統合的確率モデル}
\jauthor{河原　大輔\affiref{NICT} \and 黒橋　禎夫\affiref{Kurohashi-Lab}}
\jabstract{
 本稿では，格フレームに基づき構文・格解析を統合的に行う確率モデルを提案す
 る．格フレームは，ウェブテキスト約5億文から自動的に構築した大規模なもの
 を用いる．確率モデルは，述語項構造を基本単位とし，それを生成する確率であ
 り，格フレームによる語彙的な選好を利用するものである．ウェブのテキストを
 用いて実験を行い，特に述語項構造に関連する係り受けの精度が向上することを
 確認した．また，語彙的選好がどの程度用いられているかを調査したところ，
 60.7\%という高い割合で使われていることがわかり，カバレージの高さを確認す
 ることができた．
}
\jkeywords{格フレーム，コーパス，ウェブ，構文解析，格解析}

\etitle{A Fully-Lexicalized Probabilistic Model for Japanese Syntactic and Case Structure Analysis}
\eauthor{Daisuke Kawahara\affiref{NICT} \and Sadao Kurohashi\affiref{Kurohashi-Lab}} 
\eabstract{
 This paper presents an integrated probabilistic model for Japanese
 syntactic and case structure analysis. Syntactic and case structure are
 simultaneously analyzed based on wide-coverage case frames that are
 constructed from a huge raw corpus in an unsupervised manner. This
 model selects the syntactic and case structure that has the highest
 generative probability. We evaluate both syntactic structure and case
 structure. In particular, the experimental results for syntactic
 analysis on web sentences show that the proposed model significantly
 outperforms known syntactic analyzers.
}
\ekeywords{case frame, corpus, web, syntactic analysis, case structure analysis}

\headauthor{河原，黒橋}
\headtitle{自動構築した大規模格フレームに基づく構文・格解析の統合的確率モデル}

\affilabel{NICT}{情報通信研究機構}{National Institute of Information and Communications Technology}
\affilabel{Kurohashi-Lab}{京都大学大学院情報学研究科}{Graduate School of Informatics, Kyoto University}



\begin{document}
\maketitle



\newcommand{\argmax}[2]{}
\def\qline#1#2{}



\section{はじめに}

近年，構文解析は高い精度で行うことができるようになった．構文解析手法は，
ルールベースのもの(e.g., \cite{Kurohashi1994})，統計ベースのもの
(e.g., \cite{Kudo2002})に大別することができるが，どちらの手法も基本的には，
形態素の品詞・活用，読点や機能語の情報に基づいて高精度を実現している．例
えば，

\begin{lingexample}
\single{弁当を食べて出発した}{Example::Simple}
\end{lingexample}

\noindent
という文は，「弁当を$\rightarrow$食べて」のように正しく解析できる．これ
は，「〜を」はほとんどの場合もっとも近い用言に係るという傾向を考慮してい
るからである．このような品詞や機能語などの情報に基づく係り受け制約・選好
を，ルールベースの手法は人手で記述し，統計ベースの手法はタグ付きコーパス
から学習している．しかし，どちらの手法も語彙的な選好に関してはほとんど扱
うことができない．

\begin{lingexample} \label{Example::Undoable1}
 \head{弁当を出発する前に食べた}
 \sent{弁当は食べて出発した}
\end{lingexample}

(2a)では，「弁当を」が\ref{Example::Simple}と同じように扱われ，「弁当を
$\rightarrow$出発する」のように誤って解析される．(2b)においては，「〜は」
が文末など遠くの文節に係りやすいという傾向に影響されて，やはり「弁当は
$\rightarrow$出発した」のように誤って解析されてしまう．これらの場合，
「弁当を　食べる」のような語彙的選好が学習されていれば正しく解析できると
思われる．統計的構文解析器においては多くの場合，語彙情報が素性として考慮
されているが，それらが用いている数万文程度の学習コーパスからでは，データ
スパースネスの影響を顕著に受け，語彙的選好をほとんど学習することができな
い．

さらに，2項関係の語彙的選好が十分に学習されたとしても，次のような例を解
析することは難しい．

\begin{lingexample}
 \single{太郎が食べた花子の弁当}{Example::1}
\end{lingexample}

\noindent
「弁当を　食べる」「花子が　食べる」という語彙的選好を両方とも学習している
とすると，「食べた」の係り先はこれらの情報からでは決定することができない．
この例文を正しく解析するには，「食べた」は「太郎が」というガ格をもってお
り，ヲ格の格要素は被連体修飾詞「弁当」であると認識する必要がある．このよ
うに，語彙的選好を述語項構造としてきちんと考慮できれば構文解析のさらな
る精度向上が期待できる．

述語項構造を明らかにする格解析を実用的に行うためには，語と語の関係を記述
した格フレームが不可欠であり，それもカバレージの大きいものが要求される．
そのような格フレームとして，大規模ウェブテキストから自動的に構築したもの
を利用することができる\cite{Kawahara2006}．本稿では，この大規模格フレー
ムに基づく構文・格解析の統合的確率モデルを提案する．本モデルは，格解析を
生成的確率モデルで行い，格解析の確率値の高い構文構造を選択するということ
を行う．

構文解析手法として，語彙的選好を明示的に扱うものはこれまでにいくつか提案
されてきた．白井らと藤尾らは，数十〜数百万文のコーパスから語の共起確率を
推定し利用している\cite{Shirai1998,Fujio1999}．本研究にもっとも関連してい
る研究として，阿辺川らによる構文解析手法がある\cite{Abekawa2006}．阿辺川
らは，同じ用言を係り先とする格要素間の従属関係と，格要素・用言間の共起関
係を利用した構文解析手法を提案している．これら2つの関係を新聞記事30年分か
ら収集し，PLSIを用いて確率推定を行っている．既存の構文解析器の出力する
n-bestの構文木候補に対して，確率モデルに基づくリランキングを適用し，もっ
とも確率値の高い構文木を選択している．この手法は，PLSIを用いることによっ
て潜在的な意味クラスを導入し，確率を中規模のコーパスから推定している．

本研究は，これらの研究に対して次の点で異なる．
\begin{itemize}
 \item 明示的に意味，用法が分類された格フレームを用いている．解析時に格フ
       レームを選択することにより，用言の意味的曖昧性を解消し，その意
       味，用法下において正確な格解析を行うことができる．
 \item 非常に大規模なコーパスから構築された格フレームを用いることによっ
       て，用例の出現を汎化せずに用いている．
 \item 阿辺川らの手法のようにn-best解をリランキングするのではなく，構文，
       格構造を生成する生成モデルを定義している．
\end{itemize}


\section{ウェブから獲得した大規模格フレーム}
\label{Section::格フレーム辞書の自動構築}

格フレームは，ウェブから収集した大規模コーパスを用いて，
\cite{Kawahara2006}の手法により自動構築を行う．本節では，格フレーム構築手
法の概要を述べる．

人間のもつ常識的知識の重要な部分である格フレームは，様々な言語現象をカバー
することが望ましい．そのような格フレームを構築するために，大規模コーパス
から漸進的に確からしい情報を抽出する．

\begin{table}[b]
\input{table1.txt}
\end{table}

まず最初に，大規模コーパスを構文解析し，その解析結果から第1段階の格フレー
ムを構築する．格フレームを構築する際の最大の問題は，用言の用法の曖昧性で
ある．つまり，同じ表記の用言でも複数の意味，用法をもち，とりうる格や用例
が異なる．例えば，以下の2つの例は，用言は「積む」で同じであるが用法が異
なっている．

\begin{lingexample}
 \head{トラックに荷物を積む}
 \sent{経験を積む}
\end{lingexample}

\noindent
用法が異なる格フレームを別々につくるために，我々は，格フレーム収集の単位
を用言とその直前の格要素の組とした．「積む」の例では，「荷物を積む」「経
験を積む」を単位として格フレームを収集する．さらに，「荷物を積む」「物資
を積む」などかなり類似している格フレームをマージするためにクラスタリン
グを行う．

上記の第1段階の構築手法では構文解析を用いているために，基本的に格助詞の
付属している格要素を収集している．このため，得られる格フレームは，二重主
語構文，外の関係，格変化のような複雑な言語現象には対処できないという問題
がある．この問題に対処するために，上記で得られた格フレームを用いて再度テ
キストを解析し，新たな情報を格フレームに与える．新たに得られる情報は，1
回目の格フレーム構築では扱うことができなかった係助詞句（「〜は」や「〜も」）
や被連体修飾詞に関する関係である．

\begin{lingexample}
 \single{この車はエンジンが良い}{ガ２1}
\end{lingexample}

例えば，上例において，構文解析の段階では「車は」は解釈できなかったが，格
解析では「｛エンジン｝が　よい」という格フレームを用いることによって，格
フレームにガ格以外の格がないことから「車は」は2つ目のガ格であり，「｛エ
ンジン｝が　よい」は二重主語構文をとることがわかる．

\begin{lingexample}
 \single{その問題は彼が図書館で調べている}{ガ２2}
\end{lingexample}

この例文の「問題は」は，すでに得られている格フレーム「｛問題，課題｝を 
｛図書館｝で　調べる」のヲ格の用例群に合致するため，格解析ではヲ格と解析
されるだけで，新しい情報は得られない．同様に，被連体修飾詞は構文解析では
扱われないが，格解析では，格フレームのガ格，ヲ格などの用例と類似している
かどうか調べることによって解釈される．例えば，「業務を営む免許」の「免許」
は，格フレーム「｛銀行，会社｝が｛業務，ビジネス｝を　営む」のどの格の
用例とも類似せず，外の関係と呼ばれる関係をもっていると判定され，この情報
が格フレームに加えられる．

上記の手法を用いて，ウェブから収集した約5億日本語文から格フレームを構築し
た．約350CPUの計算機グリッドを用いてこの処理を行い，約1週間で格フレームを
構築することができた．この格フレームは約90,000用言からなる．その一部を表
\ref{例::格フレーム}に示す．


\section{構文・格解析の統合的確率モデル}

本論文で提案する構文・格解析統合モデルは，入力文がとりうるすべての構文構造
に対して確率的格解析を行い，もっとも確率値の高い格解析結果をもつ構文構造
を出力する．すなわち，入力文$S$が与えられたときの構文構造$T$と述語項構造$L$ 
の同時確率$P(T,L|S)$を最大にするような構文構造$T_{best}$と述語項構造
$L_{best}$を出力する．次のように，$P(S)$は一定であるので，本モデルは
$P(T,L,S)$を最大にすることを考える．
\begin{align}
 (T_{best}, L_{best}) & = \argmax{(T, L)}{P(T,L|S)} \nonumber \\
                      & = \argmax{(T, L)}{\frac{P(T,L,S)}{P(S)}} \nonumber \\
                      & = \argmax{(T, L)}{P(T,L,S)}
\end{align}


\subsection{構文・格解析の統合的確率モデルの概略}

本論文では，依存構造に基づく確率的生成モデルを提案する．本モデルは「節」
を基本単位とし，主節（文末の節）から順次生成していく．「節」とは，用言1つと，
それと関係をもつ格要素群を意味する．$P(T,L,S)$は，文に含まれる節$c_i$を生
成する確率の積として次のように定義する．
\begin{equation} \label{Formula::Division}
 P(T,L,S)  = \prod_{c_i \in S} P(c_i|b_{h})
\end{equation}
$n$は文$S$中に存在する節の数（＝用言数）であり，ここで$b_{h}$は節$c_i$の係り先
文節である．主節は係り先をもたないが，仮想的な係り先を$\mbox{EOS}$とする．

従来研究のほとんどは，文生成の確率を，2文節間の係り受け確率の積としていた
が，本研究では式(\ref{Formula::Division})のように，節，つまり用言と格要素
群を単位として生成するモデルとしている．そのため，複数の格要素を考慮して
係り受けを決定することができ，例(3)のような文も正しく解析できるようなモデ
ルとなっている．

例えば「弁当は食べて目的地に出発した．」という文を考える．「弁当は」が
「食べて」に係る場合には，2つの節「弁当は食べて」「目的地に出発した．」
があり，次の確率を考える．
\[
 P（\mbox{目的地に出発した．}|\mbox{EOS}） \times
	P（\mbox{弁当は食べて}|\mbox{出発した．}）
\]
「弁当は」が「出発した．」に係る場合には，2つの節「食べて」「弁当は目的
地に出発した．」があり，次の確率を考える．
\[
 P（\mbox{弁当は目的地に出発した．}|\mbox{EOS}） \times
	P（\mbox{食べて}|\mbox{出発した．}）
\]
本モデルは，これらのうちもっとも確率の高い構造を採用する．

節$c_i$は，述語項構造$\mathit{CS}_i$と用言タイプ$f_i$に分解して考える．用
言タイプとは，用言の活用や付属語列を意味する．そのため，述語項構造
$\mathit{CS}_i$に含まれる用言は原型である．係り先の文節$b_{h}$も同様に，
語$w_{h}$とタイプ$f_{h}$ に分けて考える．
\begin{align}
 P(c_i|b_{h}) & = P(\mathit{CS}_i, f_i|w_{h}, f_{h})  \nonumber\\
              & = P(\mathit{CS}_i|f_i,w_{h},f_{h}) \times P(f_i|w_{h},f_{h})  \nonumber\\
              & \approx P(\mathit{CS}_i|f_i,w_{h}) \times P(f_i|f_{h}) 
	\label{Formula::FirstDecomposition}
\end{align}
この近似は，用言は係り先文節のタイプには依存しない，また用言タイプは係り
先の語には依存しないと考えられるからである．

例えば，$P（\mbox{弁当は食べて}|\mbox{出発した．}）$は次のようになる．
\[
 P（\mathit{CS}（\mbox{弁当は食べる}）|\mbox{テ形},\mbox{出発する}）
	\times P（\mbox{テ形}|\mbox{タ形．}）
\]

ただし，本モデルにおいて，副詞，連体詞，および連体修飾句は述語項構造に入
れず，考慮しない．これらは用言に対して格関係を持たないので，用言格フレー
ムにおいて扱うことができず，生成することができないためである．これらの係
り先は，読点がなければ直近の係りうる文節とするなどといったルールに基づい
て決定する\cite{Kurohashi1994}．

式(\ref{Formula::FirstDecomposition})の$P(\mathit{CS}_i|f_i,w_{h})$を述語
項構造生成確率，$P(f_i|f_{h})$を用言タイプ生成確率と呼び，これらについて
次の2つの節で説明する．


\subsection{述語項構造生成確率}
\label{Section::述語項構造生成確率}

述語項構造の生成モデルは，その述語項構造にマッチする格フレームの選択と，
入力側の各格要素の格フレームへの対応付けを同時に行うモデルである．

述語項構造$\mathit{CS}_i$は，述語$v_i$，格フレーム$\mathit{CF}_l$，格の対
応関係$\mathit{CA}_k$の3つからなると考える．格の対応関係$\mathit{CA}_k$と
は，図\ref{Figure::Correspondence} に示すように，入力側の格要素と格フレー
ムの格との対応付け全体を表す．対応関係は図示のもの以外にも，「弁当は」を
ガ格に対応付ける可能性がある．述語項構造生成確率
$P(\mathit{CS}_i|f_i,w_{h})$は次のようになる．
\begin{align}
  P(\mathit{CS}_i|f_i,w_{h}) & = P(v_i,\mathit{CF}_l,\mathit{CA}_k|f_i,w_{h}) \nonumber \\
  & = P(v_i|f_i,w_{h}) \nonumber \\
  & \times P(\mathit{CF}_l|f_i,w_{h},v_i) \nonumber \\
  & \times P(\mathit{CA}_k|f_i,w_{h},v_i,\mathit{CF}_l) \nonumber \\
  & \hbox to105pt{$\approx P(v_i|w_{h})$\hfill}\mbox{（用言生成確率）}  \label{Formula::PA}\\
  & \hbox to105pt{$\quad {} \times P(\mathit{CF}_l|v_i)$\hfill}\mbox{（格フレーム生成確率）} 
	\nonumber \\
  & \hbox to105pt{$\quad {} \times P(\mathit{CA}_k|\mathit{CF}_l,f_i)$\hfill}\mbox{（格の対応関係生成確率）} \nonumber
\end{align}
この近似は，述語$v_i$はその係り先の語$w_{h}$のみに，格フレーム$\mathit{CF}_l$は
述語$v_i$のみに，格の対応関係$\mathit{CA}_k$は格フレーム$\mathit{CF}_l$と付属語列$f_i$に依
存すると考えられることによる．

\begin{figure}[b]
 \begin{center}
      \includegraphics{14-4ia4f1.eps}
  \caption{格の対応関係$\mathit{CA}_k$の例}
  \label{Figure::Correspondence}
 \end{center}
\end{figure}

用言生成確率と格フレーム生成確率は大規模コーパスの格解析結果から推定する．\unskip$P(\mathit{CA}_k|\mathit{CF}_l,f_i)$は，格の対応関係生成確率と呼び，以下で詳説する．


\subsubsection{格の対応関係生成確率}

格の対応関係$\mathit{CA}_k$を，格フレームの格スロット$s_j$ごとに考える．格スロッ
ト$s_j$に入力側の格要素（体言$n_j$, 格要素タイプ$f_j$）が対応付けられてい
るかどうかで場合分けすると，次のように書き換えることができる．
\begin{equation}
\begin{aligned}[b]
 P(\mathit{CA}_k|\mathit{CF}_l,f_i) 
  & = \prod_{s_j: A(s_j)=1} P(A(s_j) =1,n_j,f_j|\mathit{CF}_l,f_i,s_j) \\
  & \times \prod_{s_j: A(s_j)=0} P(A(s_j)=0|\mathit{CF}_l,f_i,s_j) 
\end{aligned}
\label{Formula::CCExample}
\end{equation}
ただし，$A(s_j)$ は，格スロット$s_j$に入力側格要素が対応付けられていれば
$1$，そうでなければ$0$をとる関数である．

式(\ref{Formula::CCExample})右辺第1項の各確率は次のように分解できる．
\begin{equation}
\begin{aligned}[b]
 P(A(s_j) & =1,n_j,f_j|\mathit{CF}_l,f_i,s_j) \\
  & = P(A(s_j)=1|\mathit{CF}_l,f_i,s_j) \times P(n_j,f_j|\mathit{CF}_l,f_i,A(s_j)=1,s_j) 
\end{aligned}
\label{Formula::CaseAndExample}
\end{equation}

この式の第1項と式(\ref{Formula::CCExample})第2項の各確率は，$f_i$には依存しな
いと考えられるので，それぞれ$P(A(s_j)=1|\mathit{CF}_l,s_j)$，
$P(A(s_j)=0|\mathit{CF}_l,s_j)$となる．これらは格スロット生成確率と呼び，大規模コー
パスの格解析結果から推定する．$P(n_j,f_j|\mathit{CF}_l,f_i,A(s_j)=1,s_j)$は格要素
生成確率と呼ぶ．

例えば，$P（CS（\mbox{弁当は食べる}）|\mbox{テ形},\mbox{出発する}）$について
考える．「食べる」のある格フレーム$CF_{\mathrm{食べる1}}$がガ格とヲ格を
もっているならば，この格フレームを用いたときの述語項構造生成確率としては，
「弁当は」をガ格またはヲ格に対応付けるときの2つを考えることになる．以下
に「弁当は」をヲ格に対応付けるときの確率を示す．
\begin{align*}
 P（CS（\mbox{弁当は食べる}）|\mbox{テ形},\mbox{出発する}）
 & = P（\mathrm{食べる|出発する}）\\
 & \times P（CF_{\mathrm{食べる1}}|\mathrm{食べる}）\\
 & \times P（A（\mathrm{を}）=1|CF_{\mathrm{食べる1}},\mbox{を}）\\
 & \times P（A（\mathrm{が}）=0|CF_{\mathrm{食べる1}},\mbox{が}）\\
 & \times P（\mathrm{弁当}, \mathrm{は}|CF_{\mathrm{食べる1}},\mbox{テ形},A（\mathrm{を}） =1,\mbox{を}）
\end{align*}


\subsubsection{格要素生成確率}
\label{Section::用例生成確率}

格要素の体言$n_j$と格要素タイプ$f_j$を生成する確率は独立であり，表層格の
解釈は格フレームに依存しないと考え，格要素生成確率は以下のように近似する．
\begin{equation}
  P(n_j,f_j|\mathit{CF}_l,f_i,A(s_j)=1,s_j) \approx P(n_j|\mathit{CF}_l, A(s_j)=1,s_j) 
	\times P(f_j|s_j,f_i) 
	\label{Prob::CaseComponent}
\end{equation}
$P(n_j|\mathit{CF}_l,A(s_j)=1,s_j)$は用例生成確率と呼び，格フレーム自体から推定す
る．

格要素タイプ$f_j$としては，表層格$c_j$，読点の有無$p_j$，提題助詞「は」
の有無$t_j$の3つを考慮する．
\begin{align}
 P(f_j|s_j, f_i) & = P(c_j,t_j,p_j|s_j,f_i) \nonumber \\
  & =  P(c_j|s_j,f_i) \nonumber \\
  & \times P(p_j|s_j,f_i,c_j) \nonumber \\
  & \times P(t_j|s_j,f_i,c_j,p_j) \nonumber \\
  & \hbox to84pt{$\approx P(c_j|s_j)$\hfill}\mbox{（表層格生成確率）} \\
  & \hbox to84pt{$\quad {} \times P(p_j|f_i)$\hfill}\mbox{（読点生成確率）} \nonumber \\
  & \hbox to84pt{$\quad {} \times P(t_j|f_i,p_j)$\hfill}\mbox{（提題助詞生成確率）} \nonumber
\end{align}
この近似は，$c_j$は$s_j$のみに，$p_j$は$f_i$のみに，$t_j$は$f_i$と$p_j$
に依存すると考えられるためである．表層格生成確率は，表層格を解釈した格を
タグ付けした京都テキストコーパス\cite{Kawahara2002j}を用いて推定する．

日本語では，読点や提題助詞はそれらの属する文節が遠くに係る場合に用いられ
やすいという傾向がある．このような傾向を考慮して，読点生成確率
$P(p_j|f_i)$と提題助詞生成確率$P(t_j|f_i,p_j)$を以下のように定義する．
\begin{align}
 P(p_j|f_i)     & = P(p_j|o_i,u_i) \\
 P(t_j|f_i,p_j) & = P(t_j|o_i,u_i,p_j)
\end{align}
$o_{i}$は，対象格要素がほかの係り先候補を越えて$v_i$に係る場合に$1$をと
り，それ以外では$0$となる．$u_i$は，節の区切れとしての強さであり，強い節
ほど読点や提題助詞をもつ句を受けやすい．節の強さとしては，南による節の分
類\cite{Minami1993}を参考にして設定した5段階を考える．


\subsection{用言タイプ生成確率}
\label{Section::付属語列生成確率}

用言タイプ生成確率$P(f_i|f_{h})$は，文節$b_{h}$のタイプを条件にした
ときに，それに係っている節$c_i$の用言タイプを生成する確率である．この確
率は，節$c_i$が連用節であるか連体節であるかで次のように異なる．

節$c_i$が連用節の場合は，節間の係り受けに大きな影響を及ぼすと考えられる
読点の有無と連用節のタイプ（強さ）を考慮する．これに加えて，$c_i$がほかの
係り先候補を越えて$b_{h}$に係るかどうかを考慮する．
\begin{equation}
 P_{\mathit{VBmod}}(f_i|f_{h}) = P_{\mathit{VBmod}}(p_i,u_i|p_{h},u_{h},o_{h})
\end{equation}

節$c_i$が連体節である場合は，受側すなわち体言のタイプには依存しないと考
え，次のように定義する．
\begin{equation}
 P_{\mathit{NBmod}}(f_i|f_{h}) = P_{\mathit{NBmod}}(p_i|o_{h})
\end{equation}



\section{実験}

提案手法によって解析した構文・述語項構造の評価実験を行った．各パラメータ
は表\ref{Table::ParameterEstimation}のリソースから最尤推定によって計算し
た．これらのリソースは一度の処理で得られたものではなく，構文解析，格フレー
ム構築，格解析という順番で処理を行い，得られたものである．ここにおける格
解析は，シソーラスに基づく類似度を用いた格解析\cite{Kawahara2005}である．
格フレームはウェブテキスト約5億文から自動構築したものを用い，格解析済みデー
タはウェブテキスト約600万文を格解析することによって得たものを用いた．構
文構造の候補としては，ルールベースの構文解析器KNPが出力するすべての候補
を用いた．

\begin{table}[b]
\input{table2.txt}
\end{table}


\subsection{構文解析実験}

構文解析実験は，ウェブテキスト675文\footnote{これらの文は格フレーム構築と
モデル学習には用いていない．}を形態素解析器JUMANに通した結果を提案システ
ムに入力することによって行う．その675文には，京都テキストコーパスと同じ基
準で係り受けのタグ付けを行い，これを用いて係り受けの評価を行った．文末か
ら2つ目までの文節以外の係り受けを評価し，その評価結果を表
\ref{Table::Accuracy}に示す．表において，「CaboCha」とは，SVMに基づく統計
的構文解析器
    CaboCha\footnote{http://chasen.org/{\textasciitilde}taku/software/cabocha/ 
（形態素解析器JUMANの結果を入力できる最後のバージョンである
CaboCha 0.36を用いた．）}を表し，「KNP」とは，構文解析器KNPを表しており，い
ずれのシステムにも同じ形態素解析結果を入力している．係り受けの精度比較の
ため，「CaboCha」には「KNP」による文節区切りの結果を入力し，文節区切りも
一致させている．

\begin{table}[b]
\input{table3.txt}
\end{table}

\begin{table}[b]
\input{table4.txt}
\end{table}

表\ref{Table::Accuracy}より，提案手法は「CaboCha」や「KNP」より精度がよい
ことがわかる．マクネマー検定を行った結果，提案手法の精度は「CaboCha」と
「KNP」より有意($p < 0.05$)に上回っていることがわかった．また，表には，係
り受けのタイプごとの精度も併せて示してある．述語項構造と密接に関係してい
るのは，「体言$\rightarrow$用言」の係り受けであり，その中で中心的なのは
「係助詞句以外」である．その精度は「KNP」と比べて1.6\%向上しており，エラー
率は10.9\%減少している．これより提案手法が，述語項構造に関係する係り受け
の解析に有効であることがわかる．

表\ref{Table::GoodExamples}に，「KNP」では誤りになるが，提案手法によって
正解になった例を挙げる．四角形で囲まれた文節の係り先が×下線部から○下線
部に変化したことを示している．

また，以下に提案手法の主な誤り原因を挙げる．


\subsubsection*{係り受けの正解基準からのずれ}

提案モデルは，語彙的な選好を強く考慮して係り受けを決定する．しかし，解析
結果が，係り受けの正解基準とずれるために，誤りとなる場合がある．

\begin{itemize}
 \item \fbox{行政相談委員は，}~いつでも自宅でみなさんからのご相談に\qline{応じて
       いますが，}{×}この期間中は次のところで行政相談所を\qline{開きます．}{○}
\end{itemize}

この文において，「行政相談委員は，」の正解係り先は「開きます．」であるが，
提案手法は係り先を「応じていますが，」と解析し，誤りとなる．「開きま
す．」，「応じていますが，」のどちらも意味的には係り先として正しいと考え
られるが，基準としては文末の「開きます．」であるのでずれが生じる．このよ
うな問題を解決するには，省略関係の正解を考慮しながら評価を行う必要がある．


\subsubsection*{係り受けの制約}

KNPが出力している構文構造の候補中に，正解の構造が含まれていないことがある．

\begin{itemize}
 \item 本当に，美味い~\fbox{コーヒーを}~\qline{お探しの}{○}方にオススメの
\qline{サイトです．}{×}
\end{itemize}

この文において，「コーヒーを」の正解係り先は「お探しの」であるが，「お探
しの」は「コーヒーを」の係り先候補にはなっていないために解析が誤る．
「お探しの」のような体言の文節は，通常，連体修飾しか受けないためこのよう
な扱いになっているが，この問題を解決するためにはこのような制約を緩める，
より多くの候補を探索する必要がある．


\subsubsection*{各確率の重み付け}

提案モデルにおいて，各確率を重み付けすることは行っていない．実際には，読
点を考慮する確率と用例を生成する確率のどちらかを強く考慮するかの重みを最
適化した方がよい場合があり，機械学習手法を用いてそのような最適化を行うこ
とが考えられる．


\subsection{格解析実験}

述語項構造が正しく認識されているかを評価するために，係助詞句と被連体修飾
詞の格が正しく認識できているかどうかを調べた．ウェブテキスト215文に対して京
都コーパスと同様の基準で関係タグを付与し，それと自動解析結果を比較した．
精度を表\ref{Table::CaseAccuracy}に示す．ベースラインとは，類似度に基づ
く格解析手法\cite{Kawahara2005}である．この表より，ベースラインから大幅
に改善しており，提案手法が有効であることがわかる．

\begin{table}[b]
\input{table5.txt}
\end{table}


\subsection{格フレームのカバレージ}

解析における格フレームのカバレージを調べるために，格要素がその係り先用言
の格フレームの用例になっているかどうかを調べた．正しい係り受けのみを評価
したところ，60.7\%の格要素が格フレームの用例となっていた．比較のため，新
聞記事26年分の2,600万文から構築した格フレームで同様の実験を行ったところ，
35.1\%であった．これより，ウェブテキスト5億文から構築した格フレームは高
いカバレージをもっていることが確認された．

また，英語の統計的構文解析器において，テスト文中の2項間の依存関係が学習コー
パス中に存在する割合が約1.5\%であるという報告がある\cite{Bikel2004}．言語・
リソースの違いがあるので直接の比較はできないが，格フレームのカバレージは
非常に高いと思われる．


\section{関連研究}

これまでに，語彙的選好を明示的に扱う構文解析手法がいくつか提案されてきた．
白井らは，PGLRの枠組みに基づく統計的構文解析手法を提案している
\cite{Shirai1998}．語彙的選好として，例えば$P（パイ|を，食べる）$のような確
率を新聞記事5年分から学習している．しかし，本研究で用いたような格フレー
ムは導入しておらず，用言の意味的曖昧性を区別せずに確率推定を行っている．
京都テキストコーパス中の比較的短い500文を用いて評価を行い，84.34\%の解析
精度であったと報告している．

藤尾らは，語の共起確率に基づく構文解析手法を提案している\cite{Fujio1999}．
2つの語が係り受けをもつ確率と距離確率の積で定義した確率モデルを用いてお
り，それらの確率はEDRコーパスから学習している．EDRコーパス1万文を用いて
評価を行い，86.89\%であったと報告している\footnote{文末から2つ目の文節も
評価に入れている．}．

阿辺川らは，同じ用言を係り先とする格要素間の従属関係と，格要素・用言間の
共起関係を利用した構文解析手法を提案している\cite{Abekawa2006}．これら2
つの関係を新聞記事30年分から収集し確率モデルを学習している．既存の構文解
析器の出力するn-bestの構文木候補に対して，確率モデルに基づくリランキング
を適用し，もっとも確率値の高い構文木を選択している．京都テキストコーパス
中の約9,000文を用いて評価を行い，既存の構文解析器よりも0.26\%高い91.21\%
    の精度を実現している\kern0pt$^{3}$．さらに，阿辺川らの被連体修飾詞の解
析\cite{Abekawa2005}を統合することによって，0.04\%高い91.25\%の精度を得て
いる．

一方，語彙情報を素性として用いている様々な機械学習手法が提案されている．
その中でもっとも良い精度を実現しているのは，工藤らが提案している統計的構
文解析手法である\cite{Kudo2002}．この手法は，SVMに基いてチャンキングを段
階的に適応していくモデルであり，京都テキストコーパスから学習している．同
コーパス（約40,000文）を用いて2分割交差検定により評価を行い，90.46\%の精度
    を実現している\kern0pt$^{3}$．しかし，数万文程度のタグ付きコーパスから
では，係り先候補間の語彙的選好を十分学習するのはほとんど困難であると思わ
れる．なお，本論文の実験で比較対象とした「CaboCha」は，本手法を実装した解
析器である．

\vspace{-0.5\baselineskip}
\section{おわりに}

本論文では，ウェブから獲得した格フレームに基づく構文・格解析の統合的確率
モデルを提案した．このモデルによって，構文解析の精度が向上することを確認
した．今後は，省略・照応解析を統合することによって，格フレームに基づく構
文・格・省略・照応解析の統合的確率モデルを構築する予定である．

\vspace{-0.5\baselineskip}

\bibliographystyle{jnlpbbl_1.3}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{Bikel}{Bikel}{2004}]{Bikel2004}
Bikel, D.~M. \BBOP 2004\BBCP.
\newblock \BBOQ Intricacies of {C}ollins' Parsing Model\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 30}  (4), \mbox{\BPGS\
  479--511}.

\bibitem[\protect\BCAY{藤尾\JBA 松本}{藤尾\JBA 松本}{1999}]{Fujio1999}
藤尾正和\JBA 松本裕治 \BBOP 1999\BBCP.
\newblock \JBOQ 語の共起確率に基づく係り受け解析とその評価\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 40}  (12), \mbox{\BPGS\ 4201--4212}.

\bibitem[\protect\BCAY{白井\JBA 乾\JBA 徳永\JBA 田中}{白井\Jetal
  }{1998}]{Shirai1998}
白井清昭\JBA 乾健太郎\JBA 徳永健伸\JBA 田中穂積 \BBOP 1998\BBCP.
\newblock \JBOQ
  統計的構文解析における構文的統計情報と語彙的統計情報の統合について\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 5}  (3), \mbox{\BPGS\ 85--106}.

\bibitem[\protect\BCAY{河原\JBA 黒橋}{河原\JBA 黒橋}{2005}]{Kawahara2005}
河原大輔\JBA 黒橋禎夫 \BBOP 2005\BBCP.
\newblock \JBOQ 格フレーム辞書の漸次的自動構築\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (2), \mbox{\BPGS\ 109--132}.

\bibitem[\protect\BCAY{河原\JBA 黒橋}{河原\JBA 黒橋}{2006}]{Kawahara2006}
河原大輔\JBA 黒橋禎夫 \BBOP 2006\BBCP.
\newblock \JBOQ 高性能計算環境を用いた{W}ebからの大規模格フレーム構築\JBCQ\
\newblock \Jem{情報処理学会 自然言語処理研究会 2006-NL-171}, \mbox{\BPGS\
  67--73}.

\bibitem[\protect\BCAY{河原\JBA 黒橋\JBA 橋田}{河原\Jetal
  }{2002}]{Kawahara2002j}
河原大輔\JBA 黒橋禎夫\JBA 橋田浩一 \BBOP 2002\BBCP.
\newblock \JBOQ 「関係」タグ付きコーパスの作成\JBCQ\
\newblock \Jem{言語処理学会 第8回年次大会}, \mbox{\BPGS\ 495--498}.

\bibitem[\protect\BCAY{工藤\JBA 松本}{工藤\JBA 松本}{2002}]{Kudo2002}
工藤拓\JBA 松本裕治 \BBOP 2002\BBCP.
\newblock \JBOQ チャンキングの段階適用による係り受け解析\JBCQ\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 43}  (6), \mbox{\BPGS\ 1834--1842}.

\bibitem[\protect\BCAY{黒橋\JBA 長尾}{黒橋\JBA 長尾}{1994}]{Kurohashi1994}
黒橋禎夫\JBA 長尾眞 \BBOP 1994\BBCP.
\newblock \JBOQ 並列構造の検出に基づく長い日本語文の構文解析\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 1}  (1), \mbox{\BPGS\ 35--57}.

\bibitem[\protect\BCAY{南}{南}{1993}]{Minami1993}
南不二男 \BBOP 1993\BBCP.
\newblock \Jem{現代日本語文法の輪郭}.
\newblock 大修館書店.

\bibitem[\protect\BCAY{阿辺川\JBA 奥村}{阿辺川\JBA 奥村}{2005}]{Abekawa2005}
阿辺川武\JBA 奥村学 \BBOP 2005\BBCP.
\newblock \JBOQ 日本語連体修飾節と被修飾名詞間の関係の解析\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 12}  (1), \mbox{\BPGS\ 107--123}.

\bibitem[\protect\BCAY{阿辺川\JBA 奥村}{阿辺川\JBA 奥村}{2006}]{Abekawa2006}
阿辺川武\JBA 奥村学 \BBOP 2006\BBCP.
\newblock \JBOQ 共起情報及び複数格の組み合わせを考慮した係り受け解析\JBCQ\
\newblock \Jem{自然言語処理}, {\Bbf 13}  (2), \mbox{\BPGS\ 43--62}.

\end{thebibliography}

\begin{biography}

\bioauthor{河原　大輔}{
1997年京都大学工学部電気工学第二学科卒業．
1999年同大学院修士課程修了．2002年同大学院博士課程単位取得認定退学．
東京大学大学院情報理工学系研究科学術研究支援員を経て，2006年独立行政法人
情報通信研究機構研究員，現在に至る．構文解析，省略解析，知識獲得の研究に従事．}
\bioauthor{黒橋　禎夫}{
1989年京都大学工学部電気工学第二学科卒業．
1994年同大学院博士課程修了．
京都大学工学部助手，京都大学大学院情報学研究科講師，東京大学大学院情報理
工学系研究科助教授を経て，2006年京都大学大学院情報学研究科教授，現在に至る．
自然言語処理，知識情報処理の研究に従事．}
\end{biography}







\biodate


\end{document}
