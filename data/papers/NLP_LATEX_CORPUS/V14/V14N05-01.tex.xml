<?xml version="1.0" ?>
<root>
  <subsubsection title="Position of discourse marker because">InExperimentSet1,firstly,272examplesofdiscoursemarkerbecausewereused.Intheseexamples,69.1%(188/272)ofsubordinateclausesbeginningwithbecauseoccurinthesecondspan.Therefore,theerrorrateofthebaselinemodelis30.9%.InTable7,fourclassificationmodelslearnedfromR,All.w,All.ewand-I.ew(inboldtype)performbetterthanthebaselinemodel.Ofthesemodels,theonelearnedfromfeatureRisthebestclassificationmodelbecauseitperformssignificantlybetterthanthethreeothers.Allthefourlearnedmodelssaythatifthediscourserelationofthewholestructure(R)is``contrast'',``example''or``reason'',thenintheembeddedstructure,thesubordinateclausebeginningwithbecauseoccursinthefirstspan;otherwiseoccursinthesecondspan(Fig.4).InFig.5,the``reason''relationsignaledbybecausebetweenthesubordinateclauseB.1andthemainclauseB.2isthenucleusofthe``contrast''relationsignaledbydiscoursemarkerbut.Therefore,intheembeddedstructurewhichcontains``reason''relation,discoursemarkerbecauseisplacedinthefirstspan.ThesubordinateclauseB.1putsstrongemphasisontheresponsefromthepubliconglobalwarming,andprovidescontrastwiththeconsequencescausedbyglobalwarmingmentionedinsentenceA.TheexperimentresultsalsoshowthatfeatureRcanimproveperformanceofthelearnedmodels,becausetheclassificationmodelslearnedfromthefeaturesetsincludingfeatureR(i.e.R,All.w,All.ewand-I.ew)performbetterthanthebaselinemodel.Onthecontrary,thebaselinemodelperformsbetterthantheclassificationmodelslearnedfromthefeaturesetsnotincludingfeatureR(e.g.Mt,Main.eandEmb.w).Discoursemarkerbecauseoftenoccursinthesecondspan.Thisconclusionwasprovedthroughcorpusanalysisby.Intheircorpus,100%(13/13)ofsubordinateclausesbeginningwithbecauseoccurinthesecondspan.Inthisstudy,thisconclusionisprovedaswell,since69.1%(188/272)ofsubordinateclausesbeginningwithbecauseoccurinthesecondspanwithinTANN.Wealsodidanothersetofexperimentsusing120examples(Table8).Theresultdidnotchange.Thatis,theclassificationmodellearnedfromfeatureRisthebestperforminglearnedmodel.</subsubsection>
  <section title="Background">Itisestimatedthattheworldhasabout375millionpeoplewhospeakEnglishasafirstlanguage,andabout750millionmorepeoplewhospeakEnglishasaforeignlanguage.Innaturallanguageprocessing,althoughsometextgenerationsystemshadbeendeveloped,theirtargetuserswerenativespeakersofEnglish.Sincethepopulationofnon-nativespeakersishuge,textgenerationfornon-nativespeakerswhosereadingabilityislowerisapromisingapplicationarea.Now,wearedevelopingatextgenerationsystem(theSILKsystem)thatcangeneratetexts(domain:naturalandpurescience)appropriatefornon-nativeusersondiscourselevel.Inthisstudy,non-nativespeakersaredividedintothreelevels(seeSection2.2fordetails):primary(middleschoollevel),intermediate(highschoollevel)andadvanced(universitylevel).TheusersoftheSILKsystemareassumedtobeatintermediatelevel.Whilewritinganarticle,authorsoftensignaltherelationbetweendiscoursesbyprovidingexplicitdiscoursemarkers,suchasbecause,forexample,andif.Discoursemarkersplayanimportantroleinkeepingthecoherenceoftexts.Therefore,theresearchconcernedwithdiscoursemarkersisoneoftheimportantissuesinnaturallanguagegeneration.In,theauthorsmentionthreeaspectswhichneedtobeconsideredwhilegeneratingdiscoursemarkers:occurrence,whethertogenerateadiscoursemarkerornot;position,wheretoplacethediscoursemarker;andselection,whichdiscoursemarkertouse.Moreover,thestudyofputsforwardsomefactors,suchasthepositionofdiscoursemarkers,whichhaveinfluenceonreadabilityatdiscourselevel.AsthefirststepofdevelopingtheSILKsystem,thisstudyconcentratesoninvestigatingthepositionofdiscoursemarkerswithinthetextswhosetargetaudiencewasintermediatenon-nativespeakers.Forexample,fromtheviewpointoftextgeneration,text(a)and(b)belowhavethesamemeaningandabstractstructure.However,thepositionofdiscoursemarkerifisdifferent.Intext(a),ifisplacedinthefirstspan,whileintext(b),ifisplacedinthesecondspan.Whatwewanttoknowiswhichtextismoreappropriateforintermediatenon-nativespeakers.(a)~~Youfailedtheexam.Butifyoustudyhard,youcanmasterEnglish.(b)~~Youfailedtheexam.ButyoucanmasterEnglish,ifyoustudyhard.WeusemachinelearningprogramC4.5toinducetheclassificationmodelsofthepositionofsixdiscoursemarkers,andthenverifytheresultsofC4.5bySupportVectorMachine(SVM).Thesixdiscoursemarkersare:becauseandsince,whichrepresent``reason''relation;ifandwhen,whichrepresent``condition''relation;althoughandwhile,whichrepresent``contrast''relation.Therestofthepaperisarrangedasfollows.InSection2,wedescribehowtoinvestigatethepositionofdiscoursemarkers.Section3andSection4introducetheexperimentresultsofC4.5andSVMrespectively.Section5discussestheresultsofthisstudy.InSection6,weintroducetherelatedwork.Section7explainstheimportanceofthisstudy.InSection8,wedrawconclusion.</section>
  <section title="Investigating the position of discourse markers">Thissectiondescribeshowtoannotatediscoursemarkers,andtheexperimentsofinvestigatingthepositionofdiscoursemarkers.</section>
  <subsection title="Definition of discourse markers">Discoursemarkersfunction``withgreatreliabilityasamarkerofnewinformationandfocus''.Theirroleistoindicatehowonepieceofdiscourseisconnectedtoanotherpieceofdiscourse.Inthisstudy,wefollow(pp.66-67)toclassifydiscoursemarkersintofivesyntacticcategories:Coordinators.Theylinktheclauseswhichareequalconstituentsofasentence.Theyalwaysappearinbetweentheclausestheylink.Forexample:(c)~~Johnlikesteaandhissisterlikescoffee.Subordinators.``Theyintroducesubordinateclausesincomplexsentences.Thesubordinateclausecanbeontheleftortherightofthemainclause,butthesubordinatorisalwaysontheleftofthesubordinateclause''.Forexample:(d)~~Hewenttoschool,althoughhehadafever.Conjunctadverbs.``Theymodifywholeclauses,andcanappearatdifferentpointswithinthem,althoughthereisoftenadefaultpositionforparticularphrases''.Forexample:(e)~~Ihadacold.Therefore,Icouldn'tgoswimming.Prepositionalphrases.``Theyoftencontainpropositionalanaphorareferringbacktothepreviousclause''.Forexample:(f)~~Sheansweredthequestionswithoutdifficulty.Fromthenonsheknewshewouldpasstheexam.Phraseswhichtakesententialcomplements.``Theyoftenintroduceaparticularintentionalstancewithrespecttothecontentoftheclausetheyintroduce.''Forexample:(g)~~Onthemoon,theskylooksblackandthesunwhite.Thisisbecausethereisnoatmosphere.Comparedwithotherfoursyntacticcategories,mostsubordinatorshavenodefaultposition,soweinvestigatethepositionofsubordinators.Inthisstudy,discoursemarkersrefertosubordinators.ACTFLProficiencyGuidelines</subsection>
  <subsection title="Creating corpus TANN">ACTFLProficiencyGuidelinesweredevelopedbytheAmericanCouncilfortheTeachingofForeignLanguages(ACTFL).Theaimistoprovideameansofassessingtheproficiencyofaforeignlanguagespeaker.Nowtheguidelinesarewidelyappliedtoteachingandlearningofforeignlanguages(includeEnglish).Intheguidelines,non-nativespeakersaredividedintofivelevels:novice,intermediate,advanced,superioranddistinguished.Inthisstudy,primary,intermediateandadvancedrefertonovice,intermediateandthecombinationofadvanced,superioranddistinguishedprescribedintheguidelinesrespectively.TheintermediateproficiencyprescribedinACTFLProficiencyGuidelinescorrespondswiththeEnglishproficiencyofhighschoolstudentswhichprescribedinChinaandinJapan.Therefore,weselectedthetextsfromhighschoolstudents'Englishtextbookspublishedinthetwocountriesandcreatedacorpus.Usingtextbookspublishedindifferentnon-Englishspeakingcountriescanmaketheresultsofthisstudyhavegreatgenerality,i.e.theresultsmightbeappropriateforintermediatenon-nativeaudienceswithdifferentmothertongues.ThecorpuswecreatediscalledTANN(TargetAudiencewasintermediateNon-Nativespeakers)(size:200,000words,domain:naturalandpurescience),whichwasannotatedondiscourselevelbyRhetoricalStructureTheory(RST).ThemethodofcreatingTANNisasfollows.Thefirstauthorgotallselectedtextsintoelectronicformbyascanner.Sincescanningisnotacompletelyaccuratewayofmakingatextmachine-readable,thefirstauthorcheckedformisinterpretedcharacters,andcorrectedthemifnecessary.Andthen,anotherpersonwasaskedtochecktheelectronictextsagaintomakesurethatnomisinterpretedcharacterexistedinthecorpus.TANNconsistsofthreeparts(Table1).ThetextsofPartIwereselectedfrom15textbookspublishedinJapan.ThetextsofPartIIandIIIwereselectedfrom11textbooksand11supplementarytextbookspublishedinChina.Furthermore,theFleschReadingEasescore(thesixthrow)showsthatthethreepartshavethesamereadability.</subsection>
  <subsection title="Selecting discourse markers from TANN">92Englishdiscoursemarkersfunctioningassubordinatorsarelistedin(pp.161-169).WithinTANN,thesediscoursemarkersaredividedintofiveportions(Table2).Inthisstudy,weonlyexplorethepositionofsixdiscoursemarkersshowninPortion1.Wehavethefollowingfourreasonsofnotconsideringotherdiscoursemarkers.Discoursemarkeras(Portion2)causesambiguityeasilybecauseitcansignalthreerelations,i.e.``manner'',``reason''and``time''.Discoursemarkerssoandsothat(Portion3)havedefaultposition,i.e.theyalwaysoccurinthefinalposition.Timeclausesarenotverycommoninacademicprose.ThedomainofTANNisnaturalandpurescience,whichissimilartoacademicprose.Therefore,wedonotexplorethediscoursemarkerssignaling``time''relation,suchasafter,beforeanduntil(Portion4).ThefrequencyofthediscoursemarkersshowninPortion5islowerthan25,whichistoolowtoexplore.Table3showsthenumberofdiscoursemarkersselectedfromTANN.Forthediscoursemarkersthatcansignaltworelations,weuse``other''torepresentthediscourserelationwedonotconsider.Forexample,fordiscoursemarkerwhilewhichcansignal``contrast''and``time''relation,``other''refersto``time''relation.Moreover,wedonotconsiderthestructuressuchas``notbecause...butbecause''and``if...,orif...''aswell.Lastly,1072exampleswereselected.</subsection>
  <subsection title="Rhetorical Structure Theory">RhetoricalStructureTheory(RST)wasoriginallydevelopedfortextgenerationbyateamatInformationSciencesInstituteofUniversityofSouthernCalifornia.RSToffersanexplanationofthecoherenceoftexts,andisintendedtodescribetextstructure.ThemainopinionsofRSTareasfollows:1.Thediscourserelationsthatholdbetweentextspansmaketextcoherent.2.Eachtextspaniscategorizedasanucleusorasatellite.3.Comparedwithsatellites,nucleiplayacrucialroleinkeepingthecoherenceofatext.InFig.1,discoursemarkerbecauserepresents``reason''relationbetweenthemainclauseB.1(nucleus)andthesubordinateclauseB.2(satellite),i.e.B.2providesareasonforthesituationpresentedinB.1.Ontheotherhand,B.1andB.2constitutediscourseB.Discoursemarkerwhenrepresents``condition''relationbetweenthenon-finiteclauseA(satellite)anddiscourseB(nucleus).Thatis,thetruthmentionedinBisaconsequenceoffulfillmentoftheconditioninA.Thistextcanberepresentedschematicallybyatree(Fig.2).Inthetree,thenon-terminalnodes(i.e.Node0andNode1)represent``condition''and``reason''relation,whiletheterminalnodes(i.e.Node2,Node3andNode4)representA,B.1andB.2respectively.Inthisstudy,wedefinetwokindsofstructures.Oneisembeddedstructure,suchasB.1andB.2,whichisembeddedinthenucleusofa``condition''relation.Anotheriswholestructure,suchasthe``condition''relationthatissignaledbywhen.WehavethefollowingtworeasonstoapplyRSTtoannotation:1.RSTissuitableforrepresentingthediscoursestructureofanygenreoftexts.Therefore,itisnoproblemtouseRSTtoannotatethetextswhosedomainisnaturalandpurescience.2.InRST,thediscourserelationsinitiallydefinedisanopenset.Theresearcherscanaddormodifyrelationsaccordingtotheirneeds.Forexample,in,78discourserelationsweredefined.WithinRST-DTC,discoursemarkerbecauseandwhilesignalatleastfivediscourserelations.Discoursemarkerbecausecansignal``consequence-n'',``Cause-Result'',``reason'',``explanation-argumentative'',``result''and``cause''relation.Discoursemarkerwhilecansignal``temporal-same-time'',``circumstance'',``antithesis'',``comparison'',and``Contrast''relation.However,wedonotthinkitisnecessarytodefinesomanydiscourserelationsinthisstudy,becausethestructureoftextswithinTANNismuchsimpler.Wedefined12discourserelations:background,condition,contrast,elaboration,evaluation,example,list,purpose,reason,restatement,summary,time.Allrelationsexcept``list''aremononuclearrelations,thatis,theyhaveonenucleusandonesatellite,e.g.``condition''and``reason''relationshowninFig.2.``List''relationisamultinuclearrelation,thatis,ithastwonuclei.Inthisstudy,wedonotconsidertherelationhavingthreenucleiormore.</subsection>
  <subsection title="Annotating discourse markers by RST">Fig.3demonstratesthedefinitionof``example''relation.Wecanseethat``Computersarealreadybeingusedinagriculture.''isthenucleus(N),while``Forexample,ingreenhouses,computerscontrolthegrowingconditionsofvegetables.''isthesatellite(S)becauseitgivesanexampletothepropositionpresentedinthenucleus.Annotationcanbedividedintofoursteps.Annotatingthenucleus(N)andthesatellite(S)oftheembeddedstructureinround.E.g.``Whenexposedtoair,(thesubstanceexpands)-N--reason--S-(becauseitreactswithoxygen).''Annotatingtheboundaryofthenucleusandthesatelliteofthewholestructureinanglebrackets.E.g.``Whenexposedtoair,(thesubstanceexpands)-N--reason--S-(becauseitreactswithoxygen).''Labelingthediscourserelationofthewholestructure.E.g.``Whenexposedtoair,--condition--(thesubstanceexpands)-N-reason-S-(becauseitreactswithoxygen).''Annotatingthenucleusandthesatelliteofthewholestructure.E.g.``Whenexposedtoair,-S--condition--N-(thesubstanceexpands)-N--reason--S-(becauseitreactswithoxygen).''Twocoders(onewasmaincoder,anotherwasreliabilitycoder)tookpartinannotation.Inordertomaketheannotationresultspreciseandreliable,wewroteareferencemanual,inwhichweintroducedRSTanddefinitionsofthe12discourserelations(AconcisemanualisshowninAppendixA.Seeformoredetails).Beforeannotation,thetwocoderswereaskedtoreadthemanualandmarkedsomediscourserelationsinasmalltestcorpusaccordingtotheirunderstandingofthemanual.Wecomparedtheannotationresultsofthetwocodersandanalyzedtheproblemsthatcauseddisagreement,basedonwhichwerevisedthemanualandtrainedthecodersuntiltheagreementbecamesatisfactory(moredetailsabouttrainingthecoderscouldbefoundinAppendixB).Themaincoderannotatedallthe1072examples,whilethereliabilitycoderannotatedthefirst30examplesofeachdiscoursemarker.Intheexperiments,wewillusetheannotationresultsofthemaincoder.Wefollow'sapproachtoassessthereliabilityofannotation.Usingthefirst30examplesofeachdiscoursemarker,wecomparedtheannotationresultsofthemaincoderwiththoseofthereliabilitycoder.Sincethesubordinateclausesbeginningwiththediscoursemarkerstobeinvestigatedareincludedintheembeddedstructure,thediscourserelationsbetweenthemainclausesandthesubordinateclausesaredetermined.Forexample,for``reason''relationsignaledbybecause,itisnodoubtthatthemainclauseisthenucleusandthesubordinateclauseisthesatellite.Therefore,weonlyassessedtheannotationresultsofthewholestructureofthe180examplesfromthreeaspects:boundary,discourserelation,nucleusandsatellite.Table4showsthattherateofagreementofthetwocoderswas82.3%.Thisresultwashigherthanthatmentionedin.Wethinkthatthereferencemanualofannotationwasveryhelpfulforthecoders,becausetheprecisedefinitionofeachrelationavoidedmisunderstanding.Furthermore,thetwotrainedcodershadlinguisticbackground,sotheycouldquitegraspthemeaningofthemanual.</subsection>
  <subsection title="Features">Eachdatapointinourdatasetischaracterizedby18features.Featurevaluecaneitherbeanumericvalueorauser-definedsymbolicvalue.Inthisstudy,fourfeatureshavenumericvalueswithcontinuousranges,suchasMgandSg,whileothershavediscretevalues,suchasRandP.Wedividedthe18featuresintotwogroups:embeddedstructurefeaturesandwholestructurefeatures.Recallthattheembeddedstructureconsistsofthemainclauseandthesubordinateclause,andthesubordinateclausebeginswiththediscoursemarkertobeinvestigated.Ontheotherhand,theembeddedstructureisapartofthewholestructure.Thetwogroupsoffeaturesandtheirpossiblevaluesareasfollows:EmbeddedstructurefeaturesMt.Tenseofthemainclause:past,present,future.Mv.Voiceofthemainclause:active,passive.Mg.Lengthofthemainclause(inwords):integer.Ms.Structureofthemainclause:simple,other.Mi.Informationcontainedinthemainclause:new,old.St.Tenseofthesubordinateclause:past,present,future.Sv.Voiceofthesubordinateclause:active,passive.Sg.Lengthofthesubordinateclause(inwords):integer.Ss.Structureofthesubordinateclause:simple,other.Si:Informationcontainedinthesubordinateclause:new,old.WholestructurefeaturesR.Discourserelation:background,condition,contrast,elaboration,evaluation,example,list,purpose,reason,restatement,summary,time.X.Whetherthediscourserelationissignaledbydiscoursemarkerornot:yes,no.E.Roleoftheembeddedstructure:nucleus,satellite.P.Positionoftheembeddedstructure:firstspan,secondspan.Eg.Lengthofthespancontainingtheembeddedstructure:integer.Es.Structureofthespancontainingtheembeddedstructure:complex,other.Og.Lengthofthespannotcontainingtheembeddedstructure(inwords):integer.Os.Structureofthespannotcontainingtheembeddedstructure:simple,other.Asshownabove,thereare10embeddedstructurefeatures.MtandStrepresenttenseofthemainclauseandthesubordinateclauserespectively.Theirvaluescouldbe``past'',``present''or``future''.MvandSvrepresentvoiceofthemainclauseandthesubordinateclause.Theirvaluescouldbe``active''or``passive''.In,theauthorpresentsthatsentencelengthcouldaffectreadabilityondiscourselevel.Wethereforeconsideredlength(inwords)ofthemainclause(Mg)andthesubordinateclause(Sg).Moreover,structureofthemainclause(Ms)andthesubordinateclause(Ss)wereconsideredaswell.Theirvaluescouldbe``simplesentence''or``other''(i.e.structurewhichismorecomplicatedthansimplesentence,suchascompoundsentenceandcomplexsentence).In,theauthorsnotethatsometimesthepositionofdiscoursemarkersisconcernedwithinformationstructuring.Forexample,somesubordinateclausesinthefirstspancontainoldinformationthatmentionedintheprecedingdiscourse,whilethemainclausesinthesecondspancontainnewinformation.Onthecontrary,whenthemainclausescontainoldinformation,thesubordinateclauseswhichcontainnewinformationtendtobeinthesecondspan.Wethereforeconsideredtwofeaturesrelatedtoinformationstructuring:Mi(i.e.informationcontainedinthemainclause)andSi(i.e.informationcontainedinthesubordinateclause).ThevaluesofMiandSicouldbe``new''or``old''.Inaddition,thereare8wholestructurefeatures.Rrepresentsthediscourserelationlabeledonthewholestructure.Itsvaluecouldbeoneofthe12discourserelationswedefined.Xrepresentswhetherthewholestructureissignaledbydiscoursemarkerornot.Erepresentstheroleoftheembeddedstructurewhichisincludedinthewholestructure.Itsvaluecouldbe``nucleus''or``satellite''.Prepresentspositionoftheembeddedstructureinthewholestructure.Itsvaluecouldbe``firstspan''or``secondspan''.Moreover,lengthandstructureofthetwospansofthewholestructurewereconsidered.EgandEsrepresentthelengthandstructureofthespancontainingtheembeddedstructure.ThevalueofEscouldbe``complexsentence''or``other''(i.e.structurewhichismorecomplicatedthancomplexsentence).OgandOsrepresentlengthandstructureofthespannotcontainingtheembeddedstructure.ThevalueofOscouldbe``simplesentence''or``other''(i.e.allstructuresexceptsimplesentence).WeuseFig.1tointroducehowtorepresentthe18features(Table5).Here,weonlyexplain9featuresindetail.Forthemainclauseintheembeddedstructure(i.e.``thesubstanceexpands''),itstense(Mt)andvoice(Mv)are``present''and``active''respectively.Thelengthofthemainclause(Mg)is3,andthemainclauseisasimplesentence(Ms).Thesubjectofthemainclause(i.e.``thesubstance'')referstothesamethingintheprecedingdiscourse(i.e.``whenexposedtoair'')althoughitisdeletedthere.Sotheinformationcontainedinthemainclauseisold(Mi).Ontheotherhand,thediscourserelationofthewholestructure(R)is``condition''.Sincethisrelationissignaledbywhen,thevalueoffeatureXis``yes''.Theembeddedstructureisthenucleus(E)ofthe``condition''relation,andoccursinthesecondspan(P).Ofthe18features,7relatedtotheembeddedstructurecanbeextractedautomatically.Forexample,featuresMt,Mv,StandSvcanbeextractedbyasyntacticparsercalledSYNTPARSE.ThefeaturesMg,SgandEgcanbeextractedbyaprogram.However,11featuresrelatedtothewholestructurecannotbeextractedautomatically.Atpresent,althoughdiscourseparserSPADE(Sentence-levelPArsingforDiscoursE)canbepubliclyavailable,itcanonlybuildsentence-leveldiscourseparsetrees.Ifadiscourseparserthatcanparseatextcontainingseveralsentencesondiscourselevelcanbeobtainedinthefuture,thenallfeaturescanbeextractedautomatically.</subsection>
  <subsection title="Six sets of experiments">Wedosixsetsofexperimentstoinducetheclassificationmodelsofthepositionofthesixdiscoursemarkers.Eachsetofexperimentscontains38experimentsusingdifferentmodelsrepresentedbydifferentsubsetsofthe18features.Thefirst18experimentsusethemodelsrepresentedbyindividualfeatures,correspondingtoeachfeaturementionedinSection2.6.Another20experimentsusethemodelsrepresentedbythecombinationsoftheavailablefeatures(Table6).Thesemodelscanbedividedintothreeparts.Inthefirstpart,the8modelsconsiderthecombinationsoftheembeddedstructurefeatures.All.econtainsall10embeddedstructurefeatures.Main.eandSub.econtainthefeaturesrelatedtothemainclauseandthesubordinateclauserespectively.Len.eandStr.econtainthefeaturesrelatedtolengthandstructure.Inf.econtainsthefeaturesrelatedtoinformation.T+V.econtainsthefeaturesrelatedtotenseandvoice.I+L.econtainsthefeaturesrelatedtoinformationandlength.Inthesecondpart,the6modelsconsiderthecombinationsofthewholestructurefeatures.All.wcontainsall8wholestructurefeatures.Emb.wcontainsthefeaturesrelatedtotheembeddedstructure.Len.wandStr.wcontainthefeaturesrelatedtolengthandstructure.-R.wcontainsallwholestructurefeaturesexceptR.-RX.wcontainsallwholestructurefeaturesexceptRandX.Inthethirdpart,the6modelsconsiderthecombinationsofbothembeddedstructurefeaturesandwholestructurefeatures.All.ewcontainsall18features.Len.ewandStr.ewcontainthefeaturesrelatedtolengthandstructurerespectively.-R.ewcontainsallfeaturesexceptR.-RI.ewcontainsallfeaturesexceptR,MiandSi.-I.ewcontainsallfeaturesexceptMiandSi.Inordertomaketheexperimentresultsaccurateandreliable,weuseC4.5toinducetheclassificationmodels,andthenverifytheexperimentresultsofC4.5bySVM.Foreachdiscoursemarker,weusedatasetswithdifferentsizestoseeiftheresultschange.Ifthenumberofexamplesismorethan200,wefirstdoexperimentsusingallexamples,andthenrepeattheexperimentsusingasmallerdatasetcontaining120examples(thereasonisshowninStep1ofAppendixB).Ifthenumberofexamplesislessthan100,wefirstdotheexperimentsusingallexamples,andthenrepeattheexperimentsbyreducingthesizeofthedatasettilltheexperimentresultschange.</subsection>
  <section title="Experiment results of C4.5">C4.5isasetofcomputerprogramswhosemainfunctionisidentifyingandanalyzingpatternsinamountofdata.ThissectionintroducestheevaluationmethodofC4.5andtheresultsofsixsetsofexperiments.</section>
  <subsection title="Evaluation method">Withineachsetofexperiments,thebaselinecanbeobtainedbychoosingthemajorityclass.Forexample,inExperimentSet1,272examplesofdiscoursemarkerbecausewereused.Intheseexamples,69.1%(188/272)ofsubordinateclausesbeginningwithbecauseoccurinthesecondspan.Thatis,ifasubordinateclausebeginningwithdiscoursemarkerbecausewasplaceddirectlyinthesecondspan,onewouldbewrong30.9%ofthetimes.So30.9%istheerrorrateofthebaselinemodel.Inthisstudy,theerrorratesofthelearnedclassificationmodelsareestimatedbythemethodof10-foldcross-validation.Thatis,dataforlearningisrandomlydividedinto10testsets.Theprogramisrunfor10times,eachrunuses9testsetsasthetrainingsetandtheremainingoneasthetestset.Theerrorrateofaclassificationmodelobtainedbyusingthewholedatasetfortrainingisassumedtobetheaverageerrorrateonthetestsetoverthe10runs.Theadvantageofthismethodisthatallexamplesareeventuallyusedfortesting,andalmostallexamplesareusedinanygiventrainingrun.Foreachsetofexperiments,themethodofevaluatingandidentifyingthebestclassificationmodel(s)canbedividedintotwosteps.First,wecomputethe95%confidenceintervalforerrorrateofeachmodelby(1).wherexisaverageerrorrate(i.e.)ofalearnedclassificationmodel,``N-1''isdegreeoffreedom.SinceNis10inthisstudy,thedegreeoffreedomis9(i.e.10-1).A95%confidenceintervalforasamplerepresentsthatthetruepopulationmeanhasa95%chanceoffallingwithintheconfidenceinterval.Here,/2is0.025.Int-Table,tdistributionis2.262,S^2issamplevariance(2),i.e.Second,weidentifyandselectthebestlearnedmodel(s)bycomparingit(their)errorrate(s)withtheerrorratesoftheotherlearnedmodelsandwiththeerrorrateofthebaselinemodel.Wefollow'sapproachtodeterminewhethertwoerrorrates1and2aresignificantlydifferent.Thatis,iftheupperboundofthe95%confidenceintervalforerrorrate1islowerthanthelowerboundofthe95%confidenceintervalforerrorrate2,thenthedifferencebetween1and2isconsideredtobesignificant.</subsection>
  <subsection title="Experiment results">Foreachsetofexperiments,wewillreporttheerrorratesofalllearnedclassificationmodels.Toidentifythebestperforminglearnedmodel,wewillcomparetheerrorratesoflearnedmodelswitheachotherandwiththeerrorrateofthebaselinemodel.Inaddition,wewillrepresentthelearnedclassificationmodelthatperformsbetterthanthebaselinemodelbydecisiontree.</subsection>
  <section title="Verifying the experiment results of C4.5 by SVM">SVMissupervisedmachinelearningalgorithmthatisdesignedforbinaryclassification.Itmapsinputfeaturevectorstoahigh-dimensionalspace,anddividesthespaceintoapositiveclasssideandanegativeclassside.ThenSVMfindsahyperplanewiththemaximalmargininthishigh-dimensionalspace.Thatis,thehyperplaneseparatesthetrainingdataintotwoclasses,andthedistancebetweenthehyperplaneandthenearestpointsofthetwoclassesisthemaximal.</section>
  <section title="Discussion">Theexperimentresultsofthisstudyshowthatinformationstructuringplaysanimportantroleindeterminingthepositionofdiscoursemarkers.InExperimentSet2,thebestclassificationmodelofsinceislearnedfromfeatureMi(i.e.informationcontainedinthemainclause).InExperimentSet4and5,forbothwhenandalthough,thebestclassificationmodelsarelearnedfromInf.e(i.e.MiandSi).Theresultsofthisstudyalsoshowthatsince,if,whenandalthoughtendtobeplacedinthefirstspan.Onepossibleexplanationisthattheintermediatenon-nativespeakerssometimescannotunderstandthemeaningofthetextsquitewell.Placingdiscoursemarkersintheinitialpositioncannotonlyemphasizethepropositionofthesubordinateclausesbutalsoattracttheattentionoftheaudiencewhosereadingabilityislower.TheresultsofthisstudyandthoseofthepreviousonesweresummarizedinTable20.Althoughweinvestigatedthepositionofsixdiscoursemarkersbyexperiments,westilldonotknowiftheexperimentresultsareappropriateforintermediatenon-nativespeakers.Sowedesignedaquestionnaireandaskedthehumansubjectstoassessreadability.Inthequestionnaire,eachquestionhastwotexts:oneistheoriginaltextofBNC(BritishNationalCorpus),anotherisitsparaphrasedtextusingtheresultsofthisstudy.Thesubjectswereaskedtochooseonetextthathe/shepreferred.SincealmostallexamplesofdiscoursemarkerwhilewithinBNCoccurinthesecondspan,whichisnearlythesameastheresultofthisstudy,wedonotconsiderdiscoursemarkerwhile.Thequestionnairecontains20questions.4questionsweretestedforeachdiscoursemarker.Table21showsanexampletakenfromthequestionnaire.Inordertoemphasizethediscoursemarkersinvestigatedandmakehumansubjectsgetabetterunderstandingofthem,weunderlinedthediscoursemarkersinthequestionnaire.50intermediatenon-nativesubjects(25Chineseand25Japanese)answeredthequestionnaire.Broadlyspeaking,aperson'sEnglishproficiencyisdependentonhis/herschoolbackground.Inthisstudy,apersonwhoseschoolbackgroundislowerthanuniversityandhigherthanmiddleschoolisregardedtobeanintermediatenon-nativespeaker.Ofthesubjects,21werehighschoolstudents,11werejuniorcollegestudents,18graduatedfromjuniorcollege.Moreover,26weremale,24werefemale.Theageofthesubjectsrangedfrom17to53;themeanwas28.WecontactedwiththembyInternetandaskedthemtofinishthequestionnaireintheirsparetime.Table22showstheresultsofthequestionnaire.ItisobviousthatcomparedwiththeoriginaltextsofBNC,mosthumansubjectspreferredtheirparaphrasedtexts.Itmeansthattheresultsofthisstudycanimprovereadabilityandmakethetextseasytoreadforintermediatenon-nativespeakers.</section>
  <section title="Related work">Thissectionintroducestherelatedworkfromtwoaspects:oneistheresearchonthepositionofdiscoursemarkers,anotheristhestudyaboutmakingEnglishtextseasiertounderstandinnaturallanguagegeneration.Untilnow,someresearcheshadbeendoneonthepositionofdiscoursemarkers.Thestudyofexplorestheoccurrenceandpositionofdiscoursemarkersbycorpusanalysis.In,theauthorscomparethepositiondistributionofdiscoursemarkerbecausewiththatofdiscoursemarkersince.UsingC4.5,theauthorsofidentifythefeaturesthatpredicttheoccurrenceandpositionofdiscoursemarkersintutorialexplanations.Moreover,afull-scalestudyondiscoursemarkersisconductedin.Forexample,theauthorsexplorethepositionofdiscoursemarkersacrossfourregisters,i.e.conversation,fiction,newsandacademicprose.Theydiscussthefactorsthathaveinfluenceondeterminingthepositionofdiscoursemarkers,suchasinformationstructuring,cohesionandstructuralconsiderations.Theyalsoinvestigatetheusageofdiscoursemarkerswithmultiplesemanticroles,forexample,since(whichcanrepresent``reason''and``time''relation)andas(whichcanrepresent``manner'',``reason''and``time''relation).ThisstudycanberegardedasthefirststepofmakingEnglishtextseasiertounderstandforintermediatenon-nativespeakersondiscourselevel.FutureworkwillconcentrateongeneratingEnglishtextseasiertoreadbyplacingdiscoursemarkersinadequateposition.Innaturallanguagegeneration,manyothermethodsaboutmakingEnglishdocumentseasiertounderstandwereputforward.Forexample,generatingdiscoursemarkerswheneverpossiblecouldmakeatexteasiertocomprehend,substitutingcommonwordsforuncommonwords,reducingmultiple-clausesentencestosingle-clausesentences.Furthermore,thestudyofsimplifiesnewspaperarticlesforaphasicreaders(partialortotallossofabilitytospeakorunderstandspokenlanguage,causedbydamagetothebrain)bysimplificationofsyntacticstructuresandlexicalsimplification.In,theauthormentionsatleastthreeaspects(e.g.between-text-spanpunctuation,positionandselectionofdiscoursemarkers)thataffectreadabilityondiscourselevelforpoorreadersofnativespeakers(missedschool,learningdifficulties,short-termmemory,etc.).Recently,moreandmoreresearcherspayattentiontotheresearchongeneratingEnglishtextseasiertoreadfortheaudiencewhosereadingabilityislower.</section>
  <section title="Importance of the study">Atpresent,thepopulationofnon-nativespeakersistwicethatofnativespeakersofEnglish.Asatoolofglobalcommunication,Englishplaysanimportantroleinpeople'sdailylives.Therefore,itisnecessarytowriteEnglishinawaythatcanbeunderstoodquitewellbyinternationalaudience.Theresultsofthisstudycanmakepeoplebecomemoreawareoftheusageofdiscoursemarkers(especiallythepositionofdiscoursemarkers)withinthetextswhosetargetaudiencewasintermediatenon-nativespeakersofEnglish.Inaddition,theopinionofthisstudy(i.e.makingEnglishtextseasiertounderstandfornon-nativespeakerswhosereadingabilityislower)isimportantandmeaningfulaswell.Actually,thisstudyisonlyasmallsteponinvestigatingthewordusagefornon-nativespeakers.Wehopethatafull-scaleinvestigationcanbeconductedonthetextswhosetargetaudienceisintermediatenon-nativespeakersinthefuture(liketheprojectintroducedinLongmangrammarofspokenandwrittenEnglish).Ifitcomestrue,peoplecouldcreatehomepages(e.g.OfficialsiteofOlympicGamesandFIFAWorldCup)inthewaythatiseasytoreadfornon-nativespeakersthroughreferringtotheinvestigationresults.Thesehomepageswillattractcountlessnon-nativeusers.Ontheotherhand,forthemachinetranslationsystemswhosetargetlanguageisEnglish,suchasJapanese-Englishtranslationsystem,theirtargetusersareassumedtobegoodreadersofnativespeakersofEnglishatpresent.Researcherscoulddevelopgenerationrulesreferringtotheinvestigationresultstomakethetranslationresultsappropriateforintermediatenon-nativespeakers.Themachinetranslationsystemscanbeusedbynotonlynativespeakersbutalsoagreatnumberofnon-nativespeakersallovertheworld,forexample,Mongolian,Russian,andVietnamesewhoseEnglishlevelisnothigh.</section>
  <section title="Conclusion">Thepositionofdiscoursemarkersisoneofthefactorsthataffectreadabilityondiscourselevel.Thispaperintroducesthestudyoninvestigatingthepositionofdiscoursemarkerswithinthetextswhosetargetaudiencewasintermediatenon-nativespeakersofEnglish.Wedidexperimentstoinducetheclassificationmodelsofthepositionofsixdiscoursemarkers(i.e.because,since,if,when,althoughandwhile)byC4.5andSVM.Thefirsttwosetsofexperimentsinducedtheclassificationmodelsofthepositionofbecauseandsincewhichsignal``reason''relation.Fordiscoursemarkerbecause,thebestperformingclassificationmodelislearnedfromfeatureR.Discoursemarkerbecausetendstooccurinthesecondspan.Ontheotherhand,fordiscoursemarkersince,thebestperformingclassificationmodelislearnedfromfeatureMi.Discoursemarkersincehasaslightpreferenceofoccurringinthefirstspan.Thethirdandforthsetsofexperimentsinducedtheclassificationmodelsofthepositionofifandwhenwhichsignal``condition''relation.Fordiscoursemarkerif,nobestlearnedmodelwasobtained.Discoursemarkeriftypicallyoccursinthefirstspan.Ontheotherhand,thebestperformingclassificationmodelofwhenislearnedfromInf.e(i.e.MiandSi).Theinformationcontainedinthemainclause(Mi)andtheinformationcontainedinthesubordinateclause(Si)playanimportantroleindeterminingthepositionofwhen.Moreover,discoursemarkerwhenhasaslightpreferenceofoccurringinthefirstspan.Thefifthandsixthsetsofexperimentsinducedtheclassificationmodelsofthepositionofalthoughandwhilewhichsignal``contrast''relation.Fordiscoursemarkeralthough,thebestperformingclassificationmodelislearnedfromInf.e(i.e.MiandSi).Discoursemarkeralthoughhasstrongpreferenceofoccurringinthefirstspan.Ontheotherhand,fordiscoursemarkerwhile,nobestlearnedmodelwasobtained.Discoursemarkerwhiletypicallyoccursinthesecondspan.FutureworkwillconcentrateongeneratingEnglishtextsthatareeasiertoreadforintermediatenon-nativespeakersondiscourselevel.TheSILKsystem,whichwearedeveloping,cangeneratetextusingGeneticAlgorithm.Inthesystem,fourfactors(i.e.nucleusposition,between-text-spanpunctuation,embeddeddiscoursemarkersandpunctuationpattern)areregardedtoaffectreadabilityondiscourselevel.Wethinkthatitisthepreferencesamongthesefactorsratherthanthefactorsthemselvesthatdecidereadability.Forexample,ifthepositionofadiscoursemarkerisconsistentwiththeexperimentresultsofthisstudy,thenahighscorewillbeassigned.Inaddition,asmentionedabove,theresultsofthisstudycanbeappliedtootherfieldsinnaturallanguageprocessing,suchashomepagecreationandmachinetranslation.</section>
</root>
