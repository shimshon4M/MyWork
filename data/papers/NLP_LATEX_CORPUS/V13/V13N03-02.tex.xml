<?xml version="1.0" ?>
<root>
  <title>サポートベクタマシンを使った文書分類における	仮想事例の利用</title>
  <jabstract>本論文では，サポートベクタマシン(SVMs)を使った文書分類において仮想事例(virtualexamples)がどのように性能を改善するかを調べる．ある文書から少量の単語を追加したり削除したりしても，その文書が属するカテゴリは変化しないとの仮定を置いて，文書分類のために仮想事例を作る方法を提案する．提案手法をReuters-21758テストセットコレクションで評価した．実験により，仮想事例はサポートベクタマシンを使った文書分類の性能向上に役立つことが確認できた．特に，学習事例が少量の場合にその効果は顕著であった．</jabstract>
  <jkeywords>仮想事例，サポートベクタマシン，文書分類</jkeywords>
  <section title="はじめに">自然言語処理において高い性能を得ようとするとき，コーパスを使った教師あり学習(supervisedlearning)は，今や標準的な手法である．しかしながら，教師あり学習の弱点は一定量以上のタグ付きコーパスが必要なことである．仮によい教師あり学習の手法があったとしても，タグ付きコーパス無しでは高い性能は得られない．ここでの問題は，コーパスのタグ付けは労力がかかるものであり，非常に高くつくことである．この点を克服するためいくつかの手法が提案されている．最小限教師あり学習や能動学習(activelearning)(例えば)である．これらに共通する考え方は，貴重なラベル付き事例を最大限に活かそうということである．同じ考え方に沿う別の手法として，ラベル付き事例から生成された仮想事例(virtualexamples)を使う手法がある．この手法は，自然言語処理においてはあまり議論されていない．能動学習の観点から，LewisとGaleLewis1994が文書分類での仮想事例について少し触れたことがある．しかしながら，彼らはそれ以上仮想事例の利用については踏み込まなかった．このとき考えられた利用方法は，分類器(classifier)が自然言語で書かれた仮想的な文書例を作り，人間にラベル付けさせるものだったが，それは現実的ではないと考えられたからである．パターン認識の分野では，仮想事例はいくつかの種類について研究されている．SVMsとともに仮想事例を使う手法を最初に報告したのは，Sch&quot;olkopfらSchoelkopf1996である．彼らは，手書き文字認識タスクにおいて精度が向上したことを示した(第~節でも述べる)．このタスクでの次のような事前知識(priorknowledge)に基づいて，ラベル付き事例から仮想事例を作り出した．その事前知識とは，ある画像を少しだけ修正した画像(例えば，1ピクセル右にシフトさせた画像)であっても元の画像と同じラベルを持つということである．また，Niyogiらも事前知識を使って仮想事例を作り，それにより訓練事例の数を拡大する手法について議論している．我々の研究の大きな目的は，コーパスに基づく自然言語処理において，Sch&quot;olkopfらSchoelkopf1996がパターン認識で良好な結果を報告している仮想事例の手法の効果を調べることである．コーパスに基づく自然言語処理での仮想事例の利用については，バイオ文献中の固有表現認識を対象にした研究があるが，対象タスクも限られており，研究が十分に進んでいるとは言えない状況である．しかしながら，仮想事例を用いるアプローチを探求することは非常に重要である．なぜなら，ラベル付けのコストを削減することが期待できるからである．特に，我々はSVMsにおける仮想事例の利用に焦点をあてる．SVMは自然言語処理で最も成功している機械学習の手法の一つだからである．文書分類，チャンキング，係り受け解析などに適用されている．本研究では，文書分類タスクを自然言語処理における仮想事例の研究の最初の題材として選んだ．理由は大きく二つある．一つには，機械学習を用いた文書分類を実際に適用しようとすると，ラベル付けのコストの削減は重要な課題になるからである．もう一つには，ラベル付き事例から仮想事例を作り出す方法として，単純だが効果的なものが考えられるからである(第~節で詳細に述べる)．本論文では，仮想事例がSVMを使う文書分類の精度をどのように向上させるか，特に少量の学習事例を使った場合にどうなるかを示す．</section>
  <section title="サポートベクタマシン">本節では，サポートベクタマシン(SVMs)の理論的な枠組みを簡単に与える．訓練事例が以下のように与えられるとする:(x_1,y_1),,(x_i,y_i),,(_l,y_l),_i^n,y_i+1,-1.displaymathSVMの枠組みにおける決定関数(decisionfunction)gは次のように定義される:g()&amp;=&amp;sgn(f())()&amp;=&amp;_i=1^ly_i_iK(_i,)+beqnarrayここでKはカーネル関数，bRは閾値，_iは重みである．さらに，重み_iは次の制約も満たす:i:0_iCand_i=1^l_iy_i=0,displaymathここでCは誤分類のコストである．ゼロでない_iを持つ事例x_iはサポートベクタと呼ばれる．線形(linear)SVMでは，カーネル関数Kは次のように定義される:K(_i,)=_i.displaymathこのとき，式~()は次のように書き直すことができる:f(x)&amp;=&amp;wx+beqnarrayここでw=_i=1^ly_i_ix_iである．SVMの学習とは，次の最適化問題を解いて_iとbを求めることである．&amp;_i=1^l_i-12_i,j=1^l_i_jy_iy_jK(_i,_j)&amp;i:0_iCand_i=1^l_iy_i=0.eqnarray*この解は，最適超平面(optimalhyperplane)を与える．この超平面は二つのクラスの決定境界(decisionboundary)である．図~に最適超平面とサポートベクタの例を示す．</section>
  <section title="仮想事例と仮想サポートベクタ">仮想事例は，ラベル付き事例から生成されるとする．ターゲットとなるタスクの事前知識に基づいて，元になった事例のラベルと同じものを，仮想事例として生成された事例のラベルに設定する．例えば，手書き数字の認識では，上下左右の方向に1ピクセル移動させても事例に対するラベルは変化しないとの仮定を置いて，仮想事例を作ることができる．特にサポートベクタから作られた仮想事例は，仮想サポートベクタ(virtualsupportvectors)と呼ばれる．妥当な仮定に基づいて生成された仮想サポートベクタは，よりよい最適超平面を与えると期待される．仮想事例がターゲットとなるタスクにおける事例の自然なバリエーションを表現していると仮定すると，決定境界はより正確になるはずである．図~は仮想サポートベクタの例を示している．仮想サポートベクタが与えられた図~の例では，最適超平面が図~と異なっていることに注意されたい．</section>
  <section title="文書分類のための仮想事例">本節では，文書分類のための仮想事例の作り方の提案手法を述べる．まず，文書分類の事前知識から仮定を設定し，次にその仮定に基づく提案手法を述べる．ここでは，文書分類について次の仮定を置く:ある文書に付けられているカテゴリは，たとえ少量の単語を追加あるいは削除しても変化しない．assumptionこの仮定は十分妥当であろう．文書分類の典型的な適用場面では，大抵の文書は，カテゴリを暗示する数個以上のキーワードと，一定量のカテゴリによらない単語を含んでいる．少量の単語の追加削除の影響は多くの場合に限定的だと考えられる．仮定~に従って，文書分類のための仮想事例を生成する方法を二つ提案する．第一の方法は，少量の単語を文書から削除する方法である．仮想事例のラベルは，その仮想事例の元となった事例のラベルと同じであるとする．もう一つの方法は，少量の単語を文書に追加する方法である．仮想事例に追加される単語は，元となる文書と同じラベルを持つ文書群から選ぶ．仮定~に基づく仮想事例の作り方にはいろいろなものが考えられるが，本研究では非常に簡単なものをまず提案し，その効果を検証したい．提案手法を述べる前に，本研究で用いた文書の表現方法(textrepresentation)について述べる．一つの文書は一つの単語ベクタ(wordvector)で表現する．文書を単語に分割し，それらを小文字に統一，ストップワードを削除した．ストップワードのリストはfreeWAIS-sfのものを用いた．ステミングは行なっていない．各単語をバイナリ素性として表現している．単語の頻度は利用していない．このとき，文書集合全体にはm個の異なり単語w_1,w_2,,w_mがあるとすると，一つの文書は単語のベクタとして表現できる．以下では，文書に存在する単語をコンマで区切って並べ，[]で囲って単語ベクタを記述することにする．例えば，ある文書xが四つの単語w_1,w_3,w_4,w_6から構成されるとき，x=[w_1,w_3,w_4,w_6]と書く．それでは，二つの提案手法とを述べる．ある文書を表す単語ベクタxと，xから生成された単語ベクタx'があるとする．アルゴリズムは次の通り:xをx'にコピーする．x'のそれぞれの単語wについて，もしrand()tなら単語wをx'から削除する．ここでrand()は0から1の乱数を生成する関数，tはどの程度の素性を削除するかを決めるパラメータである．例を示す．表~にあるような文書集合があるとする．Document~1からアルゴリズムで生成される仮想事例としては([w_2,w_3,w_4,w_5],+1)や([w_1,w_3,w_4],+1)，([w_1,w_2,w_4,w_5],+1)などが考えられる．アルゴリズムは次の通り:訓練事例の中からxと同じラベルを持つ文書を集める．それら文書を表す単語ベクタを全てつなげて，単語の配列aを作る．xをx'にコピーする．xのそれぞれの単語wについて，もしrand()tなら配列aからランダムに一つの単語を選び，それをx'に加える．例を示す．表~のDocument~2からアルゴリズムを用いて仮想事例を作ろうとするとき，まず配列a=(w_1,w_2,w_3,w_4,w_5,w_2,w_4,w_5,w_6,w_2,w_3,w_5,w_6,w_7)を作る．このとき，アルゴリズムで作られる仮想事例として，([w_1,w_2,w_4,w_5,w_6],+1)や([w_2,w_3,w_4,w_5,w_6],+1)，([w_2,w_4,w_5,w_6,w_7],+1)などが考えられる．逆に，([w_2,w_4,w_5,w_6,w_10],+1)のような事例はDocument~2からは決して作られない．+1のラベルを持つ文書には，w_10は含まれていないからである．</section>
  <section title="評価実験と議論"/>
  <subsection title="対象データ">我々はReuters-21578データセットを提案手法の有効性の検証に使った．このデータセットには，訓練事例とテスト事例の分け方(split)にいくつかのバリエーションがある．今回我々は``ModApte''と呼ばれる分け方を用いた．文書分類の文献で最も広く使われているものである．``ModApte''では，訓練事例9,603，テスト事例3,299と分けられている．Reuters-21578には100以上のカテゴリが含まれているが，他の多くの文献と同様，我々も最も頻度が高い10カテゴリのみ利用した．表~に，その10カテゴリと，カテゴリごとの訓練事例数とテスト事例数を示す．</subsection>
  <subsection title="性能評価尺度">本研究では，F値(F-measure)を実験結果を評価する第一の尺度として用いる．F値は次のように定義される:F値&amp;=&amp;(1+^2)pq^2p+qeqnarrayここでpは適合率(precision)，qは再現率(recall)，は適合率と再現率の相対的な重みを決めるをパラメータである．pとqは次のように定義される:p&amp;=&amp;分類器の出力が+1でかつ正しい事例の数分類器の出力が+1であった事例の数&amp;=&amp;分類器の出力が+1でかつ正しい事例の数ラベルが+1である事例の数eqnarray*式~()では通常=1が用いられる．これは適合率と再現率に等しく重みを置くことを意味する．複数のカテゴリを持つデータセットに対して，分類器の性能を評価しようとするとき，F値を計算する方法としては二つある．マクロ平均(macro-averaging)とマイクロ平均(micro-averaging)である．前者はまずそれぞれのカテゴリに対してF値を計算し，平均する方法である．後者は全てのカテゴリ全体に対して適合率と再現率をまず計算し，それを使ってF値を計算する方法である．</subsection>
  <subsection title="SVM の設定">実験には我々が作成したSVMのツールを用いた．線形SVMを用い，誤分類のコストCは0.016541に設定した．この値は1/avg(xx)により決めた．ここでxは事例数9603の訓練事例に含まれる素性ベクタである．実験を単純にするため，Cの値は全ての実験において固定した．表~で示した10のカテゴリそれぞれに対して2値分類を行なう分類器を構築した．</subsection>
  <subsection title="実験結果と考察">まず，とをそれぞれ独立に用いて仮想事例を作って実験を行なった．なお，このときサポートベクタに対してのみ仮想事例を作った．全ての実験に対して，とのいずれに対しても，パラメータtは0.05とした．仮想事例を使ったSVMを学習して得るための手順は次の通り:(仮想事例を使わずに)SVMを訓練する．サポートベクタを抽出する．それらサポートベクタから仮想事例を生成する．元々の訓練事例と仮想事例とを合わせて使って新たなSVMを訓練する．訓練事例のサイズを変えて，との二つの手法の性能を評価した．7つのサイズ(9603,4802,2401,1200,600,300,150)を用意した&lt;．この二つの手法を用いた場合のマイクロ平均F値を表~に示す．表~の手法Bが，手法Cがである．この表から両手法ともオリジナルのSVM(手法A)よりも性能が良いことが分かる．訓練事例の事例数が少ないほうが，性能の向上が大きい．事例数9603の訓練事例の場合，によるF値向上は0.75(=90.17-89.42)であるが，一方，事例数150の訓練事例では，F値向上は6.88(=60.16-53.28)となっている．これらの結果から，事例数が少ない訓練事例には，よりよい決定境界を与えるのに十分なだけの事例のバリエーションが存在しておらず，それゆえ，事例数が少ない訓練事例では，仮想事例の効果が大きくなったと考えられる．上記結果より，との両手法が本タスクに対してはよい仮想事例を生成しており，それが精度向上につながったと結論付けてよいだろう．仮想事例を作り出す簡単な二つの方法とが効果的なことが分かったが，次にこれらを組み合わせた方法についても調べた．1つのサポートベクタにつき，2つの仮想事例を作ることにする．つまり，で1事例を作り，でもう1事例を作る．この組み合わせた手法を手法Dとし，そのマイクロ平均F値を表~に示す．この手法によるF値向上は，，それぞれを単独で用いた場合よりも大きい．さらに，1つの事例からで2つ，で2つ事例を作り出す手法についても実験を行なった．つまり，1つのサポートベクタから4つの仮想事例を作る．この手法を手法Eとし，そのF値を表~に示す．1つのサポートベクタから4つの仮想事例を作り出す手法が最もよい結果を得た．本節の以下の議論では，オリジナルのSVMと，1つのサポートベクタから生成された4つの仮想事例を使うSVM(以降と記す)の実験結果の比較に焦点をあてる．オリジナルSVMとの学習曲線を図~，図~に示す．マイクロ平均F値，マクロ平均F値の両方で，がオリジナルSVMより明らかに性能が良い．は，あるレベルのF値を得るのに，オリジナルSVMに比べて概ね半分以下の訓練事例数で済んでいる．例えば，オリジナルSVMでは，マイクロ平均F値64.44を得るのに300事例必要である(表~参照)．一方，では150事例で65.05を得ている．F値の改善は，ただ再現率が大きく改善したせいで実現され，その裏でエラー率が上昇している可能性もある．これを確認するため，32990のテスト(3299のテストを10カテゴリそれぞれについて)に対してのエラー率の変化を図~にプロットした．エラー率においても，がオリジナルSVMよりも優れている．10カテゴリそれぞれに対する性能の変化を表~，表~に示す．は殆どの場合でオリジナルSVMよりもよい．事例数9603での``interest''と``wheat''の場合のみ，が下回っているが，理由は不明である．頻度が小さい``ship''や``wheat''，``corn''といったカテゴリに対して，オリジナルSVMの性能は良くない．分類器が決して+1を出力しなかった場合，つまり再現率ゼロの場合も多い．これは，ラベルとして+1を持つ事例が非常に少ないバランスの悪い訓練事例のために，オリジナルSVMがよい超平面を見つけられなかったことを示している．これに対し，はそういうバランスの悪い訓練事例のような難しい場合でもよりよい結果を得ている．</subsection>
  <section title="関連研究との比較">自然言語処理においてSVMsを仮想事例とともに用いている研究として，Yiらの研究がある．ここで彼らの研究との違いをまとめておく．違いは大きく二つある．対象タスクと，仮想事例の元となる事例の選び方である．彼らは固有表現認識を対象とし，全ての事例から仮想事例を作っている．一方，我々の研究では，文書分類を対象とし，サポートベクタとなる事例からのみ仮想事例を作っている．サポートベクタ以外から仮想事例を作っても精度向上にはあまり影響せずlkopfは，手書き数字の認識タスクにおいて，全ての事例から仮想事例を作った場合は精度が向上しなかったと報告している．SVMでは，サポートベクタ以外の事例は最適超平面の位置を決めるのに影響しないので，サポートベクタ以外から仮想事例を作っても精度向上にあまり寄与しないのは納得できることである．，また事例数増加による学習時間増加のデメリットがあるので，本研究ではサポートベクタのみから仮想事例を作っている．なお，対象タスクが異なるので，仮想事例の作り方が異なるのは言うまでもない．彼らは，ある文中に現れた固有表現を，同じクラスを持つ別の固有表現で置き換えて新しい文を作り，これを仮想事例としている．</section>
  <section title="おわりに">我々は仮想事例がSVMsを使った文書分類においてどのように性能を改善するかについて調べた．文書分類において，ある文書のラベルは少量の単語を追加あるいは削除しても変化しないとの仮定を置いて，仮想事例を作り出す方法を提案した．実験結果によれば，我々の提案手法はSVMsを用いた文書分類の性能を向上させることが分かった．特に事例数の少ない場合に有効であった．提案手法が文書分類以外の自然言語処理タスクにすぐに適用可能というわけではないが，今回，今まで自然言語処理の分野で十分に議論されていなかった仮想事例の利用について実験的に評価したことは意味があると言える．将来的には，仮想事例を，ラベル付き事例とラベルなし事例を使う手法(など)と組み合わせることも興味深いだろう．この両者を組み合わせたアプローチは，少量のラベル付き事例しかない場合に対して，さらによい結果が得られる可能性がある．別の興味深い将来の研究の方向性は，他の自然言語処理のタスク(品詞タグ付けや構文解析など)に対しても仮想事例を作る方法を開発することであろう．自然言語処理のさまざまなタスクにおいても，事前知識をうまく使い，効果的な仮想事例を作る方法があると信じる．document</section>
</root>
