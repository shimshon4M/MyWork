<?xml version="1.0" ?>
<root>
  <title>動詞項構造辞書への大規模用例付与</title>
  <jabstract>本論文では，述語項構造解析の精度向上のために必要となる大規模な項構造タグ付き事例を効率的に作成する方法について議論する．項構造タグ付き事例の効率的な作成方法にはさまざまな方法が考えられるが，本論文では大規模平文コーパスから抽出した表層格パターンの用例集合をクラスタリングし，得られたクラスタに項構造タグを付与することでタグ付与コストを削減する手法を提案する．提案手法では，(i)表層格パターン同士の類似性と(ii)動詞間の類似性という2種類の類似性を利用してクラスタリングを行う．評価実験では，実際に提案手法を用いて8つの動詞の項構造タグ付き事例を作成し，それを用いた項構造解析の実験を行うことによって，提案手法のクラスタリングの性能や，人手でタグ付き事例を作成するコストと項構造解析精度の関係を調査した．</jabstract>
  <jkeywords>項構造解析，交替，用例クラスタリング</jkeywords>
  <section title="はじめに">述語項構造とは述語とその項の間の意味的な関係を表現する構造の一つである．例えば，「彼が扉をひらく」という文中の述語「ひらく」の項構造は[agent,theme]のように表すことができる．agent,themeは項が述語に対してどのような意味的関係となっているかを表す意味役割である．また，所与の文章中の各述語に対して，(1)述語が取り得る項構造のうち最も文の解釈に適った項構造を選択し，(2)その構造の各項に対応する要素を同定することで述語項構造を出力する処理を項構造解析と呼ぶ．例えば，文「彼が扉をひらく」を述語項構造解析する場合には，述語「ひらく」に対して図,に示すような項構造辞書から対応する項構造を選択し，入力文の格要素を各項に割り当てて構造[agent:彼，theme:扉]を得る．項構造解析を高精度で実現すれば，「彼が扉をひらく」「扉がひらく」のような交替に代表される表現の多様性を吸収でき，言い換えや情報抽出，質問応答などの自然言語処理技術を高度化できる．述語の項構造に関する研究は，の格文法など古くから関心を集めている．これらの研究は，項構造辞書の作成，項構造タグ付きコーパスの作成，項構造解析の三つの研究に大別でき，項構造辞書作成の研究では，近年，によって項構造辞書作成の方法論が開発されている．この研究成果から大規模な項構造辞書を作成する基盤ができてきた．また項構造情報を含む詳細な動詞辞書FrameNetや項構造タグ付きコーパスPropBankも報告されている．項構造解析の研究は国際会議CoNLLにおけるSharedTasksrlconll/として取り上げられるなど関心が集まっており，近年提案されている主な手法は教師なし手法と教師あり手法に大別できる．現状では，PropBankのような項構造タグ付きコーパスが作成されたこともあり，教師あり手法の研究が盛んである．教師なし手法では，のように項構造辞書の下位範疇化の構造を利用して擬似的に訓練事例を作成する手法などが提案されているが，一般に解析精度が低い．これに対して，，HaciogluらKadri:03やThompsonらCyn:03の提案する教師あり手法では，項構造タグが付与された学習コーパスから述語と文章中の要素との構文構造における位置関係などを素性として利用しており，教師なし手法よりも精度が高いという利点を持つ．しかし学習に用いるコーパス中の各述語に対し(i)取り得る項構造と項構造辞書中の項構造の対応付け，および(ii)選択した項構造の各項と文章中の要素の対応付け，という人手による項構造タグ付与作業が必要であるため作業コストが高いという問題がある．そこで本研究では，項構造タグ付き事例を効率的に作成する方法について議論する．項構造タグ付き事例の効率的な作成方法にはさまざまな方法が考えられるが，本論文では，学習に用いるコーパス中の各述語に項構造タグを付与する過程で生じる類似用例への冗長なタグ付与作業の問題に着目する．具体的には，大規模平文コーパスから抽出した表層格パターンの用例集合をクラスタリングし，得られたクラスタに項構造タグを付与することでタグ付与コストを削減する手法を提案する．提案手法では，(A)表層格パターン同士の類似性と(B)動詞間の類似性という2種類の類似性を利用してクラスタリングを行う．評価実験では，実際に提案手法を用いて8つの動詞の項構造タグ付き事例を作成し，それを用いた項構造解析の実験を行うことによって，提案手法のクラスタリングの性能や，人手でタグ付き事例を作成するコストと項構造解析精度の関係を調査した．</section>
  <section title="用例の類似性に基づく項構造タグ付与の効率化">入力文の各動詞の項構造を解析するタスクには，次の5種類の曖昧性の解消が必要である．この5種類の曖昧性のうち曖昧性(1)，(2)は，表層格レベルの問題であるため，河原らkawahara:02:aの手法のように全自動で収集した用例を使って解消できる可能性がある．すなわち，必ずしも項構造情報を教示したデータが必要とならない．一方，曖昧性(3)，(4)，(5)を解消するには述語の取り得る項構造と入力文とを照らし合わせるために，項構造情報のタグを付与したデータが必要となる．本論文では曖昧性(3)，(4)の解消に焦点をあて，項構造タグ付与作業の効率化を図る．具体的には，同じ項構造に対応する用例を自動的にひとまとめにすることでタグ付与作業のコスト削減を目指す．曖昧性（5）は，本論文では取り扱わないが，各接尾辞で項構造の意味役割と表層格の対応関係に規則性があり本論文で扱う項構造解析手法を拡張し解消できると考えられる．問題設定として，大量のタグなし用例と項構造辞書が与えられていると仮定する．ここで，用例とは係り受け解析結果から述語とその係り受けを取り出したものを指す．タグなし用例は，大規模な生コーパスの文書を係り受け解析することによって収集可能である．また，図,に示すような項構造辞書を仮定する．このような辞書は，Dorrの交替現象に基づいた大規模項構造辞書作成の研究により基盤ができているため，作成可能であると期待できる．この項構造辞書では，各述語に一つ以上の項構造が定義されており，各項構造に取りうる表層格パタンと小規模の用例が記述されているものとする．以上の仮定のもとで，大規模用例集合を次の二つの類似性に基づいてクラスタリングする．本論文では，類似性Aと類似性Bに基づいて用例をクラスタリングする．そしてクラスタに項構造を付与する作業はクラスタを代表する用例に対して項構造タグを付与し，それをクラスタの項構造タグと考える．つまり用例クラスタリングで得られたクラスタに対して人手でタグを付与するため，いかにして異なる項構造を持つ用例を1つのクラスタに含めることなく，できるだけ少数のクラスタに用例をまとめあげるかが課題となる．,で類似性A，,で類似性Bに基づく用例クラスタリングについて述べる．</section>
  <subsection title="格要素ベースクラスタリング">格要素ベースクラスタリングでは，類似性Aを利用することで，格の出現パタンや格要素が類似する用例（例えば，「女性が悲鳴をあげる」と「こどもが大声をあげる」）を自動的にまとめる．の大規模平文コーパスから表層格フレーム辞書を自動構築する研究は「動詞の用法を決定する重要な格要素は動詞の直前にくることが多く，動詞と直前の格要素をペアにして考えると動詞の用法はほとんど一意に決定される」という考えに基づいている．本論文でも，彼らと同様にこの考えに基づき，次の3つのステップでクラスタリングを行う．直前格とその要素が同じ用例のクラスタリング直前格が同じ用例のクラスタリング直前格が異なる用例のクラスタリング各ステップで対象のクラスタ（用例）間の類似度を計算し，設定する閾値を超えるクラスタ（用例）の組みの中で最も類似度の高い2つのクラスタをマージするボトムアップクラスタリングを行う．また，クラスタ（用例）間の類似度として用例収集に用いた大規模平文コーパス中での用例の出現回数を考慮した類似度計算式（詳細は付録,を参照）を用いる．この式は河原らによって提案されたものである．上の順序で段階的にクラスタリングを行うことで，常に動詞の直前格の出現回数が直前格以外の格の出現回数よりも多くなるように処理を進めることができる．その結果，類似度計算における動詞の直前格の重みが大きくなり，動詞の直前格を重視した用例クラスタリングが可能となる．クラスタリングの各ステップを例を用いて説明する．最初に，ステップ1では例1に示すように直前格要素が同じ用例だけを対象にクラスタリングする．例1では，一つ目の用例と二つ目の用例の類似度が高くこれらをマージした結果を示している．例1）..次に，ステップ2ではステップ1の結果を入力とし，例2に示すように直前格が同じ用例だけを対象にクラスタリングする．クラスタリングの例を例2に示す．例2）.flushright最後に，ステップ3ではステップ2の結果を入力とし，例3に示すように直前格が異なる用例だけを対象にクラスタリングする．このステップ3のクラスタリングによって，例3に示すような表層格の出現順が「に，を」「を，に」と順序が異なっている用例をマージ例えばできる．例3）.flushright正確に言えば，このクラスタリングは河原らが提案したクラスタリングとは異なる．本クラスタリング手法と河原らが提案した手法の主な異なりはステップ(1)の存在であり，河原らの手法にはステップ(2)と(3)しか存在しない．河原らの手法では動詞，動詞の直前格とその要素を最小単位と考えクラスタリングを開始する．つまり動詞，動詞の直前格とその要素が同じならば同じクラスタであると判断している．河原らは大規模平文コーパスからの表層格フレーム辞書自動構築を目的にクラスタリング手法を提案しており，このように判断することは大きな問題にならない．しかし，我々の目的は項構造を考慮したクラスタリングであり，動詞，動詞の直前格とその要素が同じならば同じクラスタであると判断することが大きな問題となる．そのためにステップ(1)を導入した．これ以外にも異なる項構造を持つ用例やクラスタが誤ってマージされないようにいくつか工夫する必要がある．詳細は,節で述べる．</subsection>
  <subsection title="動詞ベースクラスタリング">動詞ベースクラスタリングでは，類似性Bに基づき，同じ項構造に対応する意味的に類似する動詞の用例（例えば，「大統領が98年に計画を公表する」と「首相が10月にプランを発表する」）を自動的にまとめる．具体的には，動詞Tの用例をクラスタリングするのに動詞Tと類似する動詞S=S_1,S_2,...,S_nの用例を利用する．動詞集合Sをどのように選択するか，また各動詞S_iの用例をどのように利用するかにはさまざまな方法が考えられるが，今回は動詞を1つだけ用いることにしてクラスタリング手法を検討する．また，本クラスタリングは類似する動詞の一方の用例に項構造タグを付与した結果を利用する．つまり，すでに人手で項構造タグが用例に付与された動詞S_aを用いて，動詞S_aと類似する動詞Tの用例集合を次の3つのステップでクラスタリングする．なお，本クラスタリングの入力は格要素ベースクラスタリングの結果である．表層格が最も多い用例を動詞Tのクラスタを代表する用例として選択する．(1)で選択された用例と動詞S_aの用例の中で表層格パタンが同じでかつ最も類似する用例を対応付ける．動詞Tの異なるクラスタに属する用例が動詞S_aの同じ項構造の用例に対応付けられた場合に，動詞T側の2つのクラスタをマージする．まずステップ1では，格要素ベースクラスタリングによってできたクラスタにおいて，各クラスタを構成する用例で最も多くの表層格を持つ用例をそのクラスタを代表する用例とする．例えば，「首相が10月にプランを発表する」と「5月に計画を発表する」の用例で構成されるクラスタの例を考える．これらの用例の表層格はそれぞれ「が，に，を」と「に，を」であり，表層格数は前者が3，後者が2であるため，前者の用例をこのクラスタを代表する用例として選択する．図,では，ステップ1で動詞Tの1番目のクラスタの代表用例をT_1，2番目のクラスタの代表用例をT_2として選択したとする．ステップ2でT_1，T_2のそれぞれと最も類似度の高い用例を動詞S_a側の用例集合から選択し対応付ける．ここではそれぞれ用例S_a1と用例S_a2が対応付けられたとする．最後に，動詞S_a側で用例S_a1，S_a2が同じ項構造であるというタグ付与情報を利用して，1番目と2番目のクラスタをマージする．動詞ベースクラスタリングにおいても，用例間（動詞Tの用例と動詞S_aの用例）の類似度計算式として，格要素ベースクラスタリングと同じ計算式を用いる．但し本クラスタリングにおいては，表層格パタンが同一の用例のみを類似度計算の対象とした．動詞ベースクラスタリングでポイントとなるのはステップ3であり，本クラスタリングの狙いは次のとおりである．格要素クラスタリングでは対応する格の格要素の類似度だけを考慮しているが，実際には同じ項構造となる用例のなかには類似しない格要素を持つ用例も多い．つまり，述語とある意味的な関係を持つ要素の集合は，その要素自身が持つ意味だけでは表現することができないのである．例えば，図,の用例T_1「首相が10月にプランを発表する」とT_2「自衛隊が結果を発表する」は格要素の類似度に基づいたクラスタリングでは，マージされなかった用例である．しかしながら，我々人間には同じ項構造であることがわかる．このような格要素の類似性だけではマージできない用例を，類似した他の動詞の用例に人間が項構造を付与することで与えた情報を利用してクラスタリングを行なうのが動詞ベースクラスタリングの狙いである．</subsection>
  <section title="評価実験">前節で述べたクラスタリングの効果および大規模な訓練事例を利用することがどの程度項構造解析の精度向上に寄与するかを調査した．まず，両実験で使用する実験データと訓練事例作成のための用例クラスタリングの設定，項構造解析モデルについて説明し，最後に実験結果を示す．</section>
  <subsection title="評価実験データ">4つの動詞（「話す」，「発表する」，「発売する」，「増える」）を用いて評価した．これらの動詞は後述のテストデータのコーパス中に頻出する動詞であり，それぞれの動詞が持つ項構造数は「話す：5」，「発売する：1」，「発表する：3」，「増える：2」である．例として，表,に「話す」の項構造辞書の項目を示す．この項構造辞書はIPAL動詞辞書を基に今回収集した用例を参考に，それらの格交替を考慮しながら作成したものである．この4つの動詞に対して，毎日新聞社の新聞記事でテストデータ作成に用いた1ヶ月分を除いた，13年分の新聞記事から用例異なりを除いた8385用例を抽出した（抽出条件は,の用例の収集を参照）．この用例をクラスタリングし，各クラスタに項構造を対応付けて，項構造解析の訓練事例とした．項構造解析実験のテストデータとして，上の13年分の新聞記事から抜き出したある月の新聞記事から対象動詞の用例を抽出し，用例異なりを除いた220用例にひとつずつ人手で項構造タグを付与したものを用いる．ただし，,節で述べたように(1)「は」，「も」，「無格」が兼務する表層格の曖昧性，および(2)連体修飾節に関する曖昧性は表層格パターンを用いてある程度解析可能であると考えられるため，今回のテストデータについては「は」，「も」，「無格」の曖昧性は人手で解消し，連体修飾節の被修飾名詞は取り除き(3)，(4)の曖昧性の解消に焦点を当てて評価する．また，(5)の接尾辞を伴うことによる格交替の曖昧性については，文書中の約1割の述語が格交替を生じる接尾辞を伴って出現したが，訓練事例の抽出と同様に今回はそれらを除いて評価実験を行った．なお訓練事例，テストデータともに用例に項構造タグを付与する際，可能な項構造が複数あれば複数のタグを付与した．また項構造解析時には，,の項構造解析モデルで複数のタグを持つ用例が選択された場合，複数の項構造解析結果を出力する．表,に訓練事例，表,にテストデータ中の動詞とその項構造の出現回数を示す．各動詞の項構造番号は，表,や付録,に示した動詞項構造辞書の項目番号と対応している．評価実験では，動詞「増える」の場合，システムが出力すべき項構造の数は142個（5+7+65×2）である（表,参照）．</subsection>
  <subsection title="用例クラスタリングの設定"/>
  <subsubsection title="用例の収集">項構造と対応付けるために収集できる用例には「は」，「も」，「無格」を伴った用例があるが，これらは兼務する表層格の曖昧性があるため訓練事例としては収集しない．また，格交替が生じる可能性のある接尾辞「れる」，「られる」，「せる」，「させる」，「たい」，「ほしい」，「もらう」，「いただく」，「くれる」，「くださる」，「やる」，「あげる」，「できる」を伴う述語の用例や連体修飾節の被修飾名詞も訓練事例としては収集しない．</subsubsection>
  <subsection title="項構造解析モデル">項構造解析モデルとしては，用例に対応する項構造候補の選択に最近傍法を用い，また用例間の近さを計算するのにKurohashiらKurohashi:94が提案する計算方法を用いた．この計算方法は分類語彙表を利用して名詞間の類似度を定め，また用例間の類似度に名詞間の類似度の和を用いている．項構造解析の処理を説明する．入力文の格要素とタグ付き用例の対応付けを行う対応付けられたそれぞれの格要素について，入力文の名詞とタグ付き用例との間の類似度を計算する．類似度の値は分類語彙表における2つの名詞の分類コードの一致するレベルによって決定する．一致するレベルと類似度との関係を表,に示す．式1に従ってタグ付き用例と入力文の対応の評価値を計算し評価値の高い用例の持つ項構造から順に選択する．評価値=.eqnarrayn：対応付けられた格要素数l：n+(入力文側の対応付けられいない格要素数)m：n+(タグ付き用例側の対応付けられいない格要素数)sum：対応付けられた格要素の類似度の和</subsection>
  <subsection title="提案手法の有用性の評価実験">提案手法の有用性を示すために次の3点を経験的に明らかにする．(a)項構造タグ付与作業のコスト訓練事例作成のために，クラスタリングの結果得られるクラスタに項構造タグを人手で付与する必要がある．今回の実験では，クラスタに項構造を付与する作業はクラスタを代表する用例に対して項構造タグを付与し，それをクラスタの項構造タグと考える．そのためクラスタリング結果のクラスタ数でタグ付与作業のコストを評価する．(b)タグ付与の品質項構造タグ付与誤りを調査するために，人手で各用例に項構造タグを付与した．また提案手法によって得られたクラスタに項構造を付与する作業はクラスタを代表する用例に対して項構造タグを付与し，それをクラスタの項構造と考える．これらの結果を比較し，タグ付与誤りの割合でタグ付与の品質を評価する．(c)項構造解析精度項構造解析は一文ごとに処理を行うため，省略などによって文脈を見なくては項構造を一意に決定することができない．省略のある入力に対しては可能な項構造解析結果を漏れなく出力することが望まれる．そこで項構造解析の評価尺度として，類似度の順で解析結果を出力していき，正解を漏れなく答えたときの精度で評価する．つまり，再現率が100％のときの精度で項構造解析を評価する．なお評価は事例単位でなく，項構造単位で再現率と精度を計算した．例えば，入力「父が事件について話す」の項構造は，表,に示すように，項構造1[agent，theme，beneficiary]と項構造3[agent，beneficiary，theme，content]の可能性がある．このような入力に関して，項構造1と項構造3の両方の答えを出力するまでの解析結果の精度で評価する．ただし，タグ付き用例集合が入力文の正解を網羅していない場合は，その入力に対して可能なすべての項構造をシステムの出力とする．上の(a)項構造タグ付与作業のコスト，(b)タグ付与の品質，(c)項構造解析精度について以下の3つの手法を用いて訓練事例を作成し比較実験を行なった結果を表,に示す．ベースライン各用例に項構造タグを付与し訓練事例を作成．格要素ベースクラスタリング類似性A（ある動詞について同じ項構造を持つ用例は，格の出現パタンとそれぞれの格要素が類似している）に基づいた用例クラスタリングの結果に項構造タグを付与し訓練事例を作成．動詞ベースクラスタリング格要素ベースクラスタリングに加え，類似性B（意味的な類似性がある二つの動詞は，格の出現パタンとそれぞれの格要素が類似している）に基づいた用例クラスタリングの結果に項構造タグを付与し訓練事例を作成．表,の(a)項構造タグ付与作業のコストが示すように，格要素ベースクラスタリングによってベースラインの作業コストを約3分の1(2745/8385)に削減し，動詞ベースクラスタリングを用いてさらに半減（1505/2745）できた．この結果より，用例のクラスタリングに一般的な名詞の類似度を用いた手法に加え，類似する動詞のタグ付き用例を利用して，未知の動詞の用例をさらにマージすることができたと言える．また，動詞ベースクラスタリングは格要素ベースクラスタリングと比べ，タグ付与品質では多少の低下が見られるものの，項構造解析の精度にはほとんど影響しなかった．この結果から，項構造タグ付与作業済みの動詞が増えると，ある動詞と意味的に類似する動詞が増加するので，より多くの動詞ベースクラスタリングが可能になり，項構造解析精度を保ったままタグ付与作業のコストをさらに削減できると考えられる．また，ベースラインと格要素ベースクラスタリングにおける項構造解析精度の差は，,節で動詞ベースクラスタリングのねらいとして述べたように，述語とその項の間の意味的な関係を示す項構造の項となる要素の集合は，その要素自身が持つ意味だけでは表現することができないことを示す結果になっている．</subsection>
  <subsection title="用例規模の異なりによる評価実験">大規模な訓練事例を利用することがどの程度項構造解析精度の向上に寄与するかを評価するため，用例集合の規模を変化させたときの(a)クラスタ数と(c)項構造解析精度の変化を調べた．図，,は動詞ベースクラスタリングまで施したときの結果である．横軸は用例の規模（年単位）であり，棒グラフはそれぞれ用例異なり数とそれをクラスタリングすることによって得られるクラスタ数を示している．また折れ線グラフは項構造解析精度（図：テストデータの220用例に対する結果，図：訓練事例の8385用例の10分割交差検定の結果）である．なお図,のクラスタ数，項構造解析精度は交差検定の結果の平均を示している．図，,を見ると，用例規模が増加すると収集できる用例異なり数は増加し続けているのに対し，得られるクラスタ数は収束しつつある．すなわち，用例規模を増やしたときに得られる新規の用例は収集済みの用例と類似している可能性が高いため，項構造解析の精度向上に寄与する保証は必ずしもない．しかし，異なるデータセットを用いた実験の結果，図3，4に示すように，用例規模を増やせば項構造解析精度が向上するということが経験的に明らかになった．これは，項構造解析においてはクラスタの重心ではなく，最近傍の用例を参照しているためである．すなわち，用例規模を変化させたときのクラスタリングの結果に大きな違いがないとしても，クラスタの外延的定義はより緻密になっており，複数のクラスタ間の用例に対する類似度がより正確に見積もられていると解釈できる．ちなみに，「は」，「も」，「無格」の曖昧性を人手で解消せずに，KurohashiらKurohashi:94の手法で項構造解析と表層格の曖昧性解消を行った結果，項構造解析精度は90.8％であり，人手で曖昧性を解消した結果と比べ約7％低下している．この結果より，項構造解析精度を改善するにはこの種の多義性解消の問題に取り組む必要があることが明らかになった．「は」，「も」，「無格」の曖昧性を解消するためには，単純に用例を増やすだけでなく，ゼロ照応解析や連体修飾の解析との統合について検討すべきであると考えられる．</subsection>
  <section title="おわりに">本論文では，項構造解析の精度向上を目指して，用例と項構造を対応付けるタグ付与作業コストの削減について議論した．また，動詞に関する2種類の類似性に基づき用例をクラスタリングすることで作業コストを削減する一手法を提案した．提案手法を用いて実際にタグ付与作業を行ったところ，タグ付与の品質や項構造解析の精度を保ったまま，作業コストを約2割に削減できた．また，最近傍法を用いた項構造解析では，タグ付与された事例を増やすことで精度を向上できた．この結果より，解析精度の向上にはいかにコストをかけずに大規模な項構造タグ付き用例を収集するかが主要な問題であることがわかり，我々の提案手法はその問題の一つの解決策となっていることが確認できた．ただし，動詞それぞれについて網羅的に大規模な用例を作成するためには，項構造解析精度を低下させることなく選択的に用例をサンプリングするための評価尺度について検討したり，能動学習を採り入れるなど，さらなるコスト削減の方法を考える必要がある．そこで，提案した手法によって得られたクラスタすべてにタグを付与せず，クラスタを選択的にサンプリングし，一部の代表的なクラスタにタグを付与することで作業コストをさらに削減することを試みた．選択的サンプリングでは「いかに項構造解析に貢献するクラスタを選択するか」が課題となる．サンプルの選択基準は多々あるが，今回は動詞ベースクラスタリングの結果を利用し，サイズの大きいクラスタ（多くの用例から構成さているクラスタ）を優先した．,節の評価実験と同じ評価データ，クラスタリングの設定，項構造解析モデルで評価実験を行なった．結果を図,に示す．タグ付与を行ったクラスタ数（横軸）に対する，項構造解析精度とタグ付けされる用例数の変化を表している．結果から単にクラスタサイズに基づいてサンプリングするだけではさらなるコスト削減の方法として必ずしも良い結果が得られないことがわかった．今後，どのような基準でサンプリングするか，およびタグ付与作業の終了条件について検討を重ねる必要がある．また項構造解析精度を向上させるには「は」，「も」などの表層格の曖昧性解消や接尾辞を伴うことによる格交替の曖昧性の解消に今後取り組む必要がある．接尾辞を伴うことによる交替現象はある程度の文法規則によってとらえられると考えられるが，「は」，「も」の曖昧性は単純に用例を増やすだけでは解消できないことが今回の実験結果からわかる．この曖昧性を高精度で解析するためにはゼロ照応解析や連体修飾の解析も視野に入れた解析手法が必要であり，今後その問題にも取り組みたい．</section>
  <section title="用例間の類似度計算">は以下の類似度計算式を提案した．単語e_1,e_2の類似度sim(e_1,e_2)を，日本語語彙大系のシソーラスを利用して以下のように定義する．sim_e(e_1,e_2)&amp;=&amp;max_xs_1,ys_2sim(x,y)(x,y)&amp;=&amp;2Ll_x+l_yeqnarrayここで，x,yは意味属性を表し，s_i（i1,2）は単語e_iの意味属性の集合を表す．sim(x,y)は意味属性のx,y間の類似度であり，l_x,l_yはそれぞれ名詞意味属性の階層の根からx,yまでの深さを表し，Lは根からx,yまでの共通している階層の深さを表す．類似度sim(x,y)は0から1の値をとる．用例P_1,P_2の格の一致度csは，P_1,P_2に含まれるすべての格パタンに対する，P_1,P_2の共通格に含まれている格パタンの割合とし，cs&amp;=&amp;^n_i=1E_1cc_i+^n_i=1E_2cc_i^l_i=1E_1c1_i+^m_i=1E_2c2_ieqnarrayと定義する．ただし用例P_1中の格をc1_1,c1_2,,c1_l，用例P_2中の格をc2_1,c2_2,,c2_m，P_1とP_2の共通格をcc_1,cc_2,,cc_nとする．また，E_1cc_iはP_1内の格cc_iに含まれる格用例群であり，E_2cc_i,E_1c1_i,E_2c2_iも同様である．E_1cc_iはE_1cc_iの頻度を表す．用例P_1,P_2の共通格に含まれる格用例群の類似度sim_E(P_1,P_2)は，格用例の類似度の和を正規化したもので，sim_E(P_1,P_2)=^n_i=1^_e_1E_1cc_i^_e_2E_2cc_ie_1e_2sim_e(e_1,e_2)^n_i=1^_e_1E_1cc_i^_e_2E_2cc_ie_1e_2eqnarrayとする．用例P_1,P_2間の類似度は，格の一致度csとP_1,P_2の共通格の格用例群間の類似度の積とし，次のようにして計算する．類似度&amp;=&amp;cssim_E(P_1,P_2)eqnarray</section>
  <section title="その他の動詞の項構造辞書の項目">document</section>
</root>
