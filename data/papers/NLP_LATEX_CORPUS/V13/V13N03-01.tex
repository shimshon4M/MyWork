    \documentstyle[epsf,jnlpbbl]{jnlp_j_b5_2e_new}

\setcounter{page}{3}
\setcounter{巻数}{13}
\setcounter{号数}{3}
\setcounter{年}{2006}
\setcounter{月}{7}
\受付{2005}{9}{27}
\再受付{2006}{1}{26}
\採録{2006}{1}{27}
\setcounter{secnumdepth}{2}
\def\theaffi@footnote{}

\title{用例ベース翻訳の確率的モデル化}
\authorC{荒牧 英治\affiref{TOKYO} \and 黒橋 禎夫\affiref{KYOTO} \and 柏
岡 秀紀\affiref{NICT}\affiref{ATR} \and 加藤 直人\affiref{NHK}}
\headauthor{荒牧，黒橋，柏岡，加藤}
\headtitle{用例ベース翻訳の確率的モデル化}
\affilabel{TOKYO}
	{東京大学附属病院企画情報運営部}
	{Department of Planning, Information and Management, 
	University of Tokyo Hospital}
\affilabel{KYOTO}
	{京都大学大学院情報学研究科}
	{Graduate School of Informatics, 
	Kyoto University}
\affilabel{NICT}
	{独立行政法人情報通信研究機構}
	{National Institute of Information and Communications Technology}
\affilabel{ATR}
	{ATR音声言語コミュニケーション研究所}
	{ATR Spoken Language Translation Research Laboratories}
\affilabel{NHK}
	{NHK放送技術研究所}
	{Science and Technical Research Laboratories of NHK}

\jabstract{
用例ベース翻訳は，これまで，経験則にもとづく指標／基準により用例を選択
してきた．
しかし，経験則に頼った場合，その修正を行うのが困難であり，また，アルゴ
リズムが不透明になる恐れがある．
そこで，本研究では用例ベース翻訳を定式化するための確率モデルを提案する．
提案するモデルは，翻訳確率の最も高い用例の組み合わせを探索することで，
翻訳文を生成する．
さらに，本モデルは用例と入力文のコンテキストの類似度を自然に翻訳確率に取り込
む拡張も可能である．
実験の結果，本モデルを用いたシステムは，従来の経験則によるシステムの精
度を僅かに上回り，用例ベース翻訳の透明性の高いモデル化を実現することに
成功した．
}
\jkeywords{用例ベース翻訳，機械翻訳，確率モデル，コンテキストの類似，依存構造}

\etitle{Probabilistic Formalization for Example-based \\Machine Translation}
\eauthor{
	Eiji Aramaki\affiref{TOKYO} \and 
	Sadao Kurohashi\affiref{KYOTO} \and 
	Hideki Kashioka\affiref{NICT}\affiref{ATR} \and 
	Naoto Kato\affiref{NHK}}
\eabstract{
Example-based machine translation (EBMT) systems, so far, rely on
heuristic
measures in retrieving translation examples.
Such a heuristic measure costs time to adjust, and might make its
algorithm unclear.
This paper presents a probabilistic model for EBMT.
Under the proposed model, the system searches the translation example
combination which has the highest probability.
The proposed model clearly formalizes EBMT process.
In addition, the model can naturally incorporate the context similarity of
translation examples.
The experimental results demonstrate that the proposed model has a
slightly better translation quality than state-of-the-art EBMT systems.
}
\ekeywords{Example-based Machine Translation, 
	Machine Translation, 
	Probabilistic Model, 
	Context Similarity, 
	Depedency Structure}

\begin{document}
\maketitle
\thispagestyle{empty}

\section{はじめに}
近年，統計ベース翻訳\cite{Brown1993}や用例ベース翻訳\cite{Nagao1984}な
ど大量のテキストを用いた翻訳手法（コーパスベース翻訳）が注目されている．
我々は，用例ベース翻訳に焦点を当て研究を行っている．

用例ベース翻訳の基本的なアイデアは，入力文の各部分に対して\textbf{類似}
している用例を選択し，それらを組み合わせて翻訳を行うことである．
ここでいう\textbf{類似}とは，通常，入力文とできるかぎり大きく一致して
いればいるほど（一致する単語数または文節数が多いほど）よいと考えられて
きた．
これは，用例が大きくなればなるほど，より大きなコンテキスト
を扱うことになり，正確な訳につながるからである．
そのため，これまでの用例ベース翻訳は，大きな用例を優先する指標／基準
を用いて用例を選択してきた．

一方，統計ベース翻訳は，翻訳確率を緻密に計算するため，基本的には，翻訳
用例を小さな語／句単位に分解して学習を行う．
もちろん，最近の統計ベース翻訳では，より大きな単位を取り扱う試みも行わ
れている．
例えば，Och\cite{Och1999}等は，アライメントテンプレートという単位を導
入し，語列をまとめて学習した．
また，他にも多くの統計翻訳研究が語よりも大きな単位を学習に取り込む試みを行っている\cite{Koehn2003,Watanabe2003}．
しかし，入力文とできる限り大きく一致した用例を用いる用例ベース翻訳と比
べると，あらかじめ翻訳単位を設定する統計ベース翻訳の扱う単位は依然として小さいと
言える．

簡単に言うと，統計ベース翻訳と用例ベース翻訳は，以下の2点で異なる．

\begin{enumerate}
\item 用例ベース翻訳は，用例のサイズ（一致する単語数または文節数)を重視している．統計ベース翻訳は
      用例の頻度を重視している．
\item 用例ベース翻訳は，経験則による指標／基準にもとづいて動作している．
      統計ベース翻訳は確率的に定式化されている．
\end{enumerate}

本研究では，用例ベース翻訳の問題は，(2)経験則による指標／基準を用いて
いる点だと考える．
経験則による指標／基準は，調整や修正が困難であり，また，アルゴリズムが
不透明になる恐れがある．

そこで，本研究では，用例ベース翻訳を定式化するために，用例ベース翻訳の
ための確率モデルを提案する．
提案する翻訳モデルは，統計ベースのそれとは異なり，語や句単位の小さな単
位から，文全体まで，あらゆるサイズをカバーした翻訳確率を計算する．
この枠組みの上では，大きなサイズの用例は安定した翻訳先を伴うため，高い
翻訳確率を持つと考えられる．
したがって，翻訳確率が高い用例を選ぶことで，自然と用例のサイズを考慮し
た用例の選択が可能となる．

また，提案する翻訳確率は容易に拡張可能であり，用例と入力文のコンテキス
トの類似度を確率モデルに取り込むことも可能である．

実験の結果，提案手法は，従来の経験則に基づいた翻訳システムよりも僅かに
高い精度を得て，用例ベース翻訳の透明性の高いモデル化を実現することに
成功したので報告する．

提案手法は言語ペアを特定しないが，本稿は日英翻訳方向で説明し，実験を
行った．

本稿の構成は，以下のとおりである．
2章では，提案するモデルの基本的アイデアについて説明する．
3章では，アルゴリズムについて述べる．
4章では，実験について報告する．
5章では，関連研究を紹介し，6章に結論を述べる．

\section{提案手法}

	
	
	
	\begin{figure}
	\begin{center}
	\epsfxsize=120mm\epsfbox{f_prob5.eps}
	\end{center}
	\caption{翻訳のながれ}
	\label{f_prob.eps}
	{\footnotesize * 本稿の図では，依存構造木の親を左に，子を右に描く．
	また，本研究では，ノードの単位は日本語は文節，英語はbase-NP,
	またはbase-VPとする．\par}
	\end{figure}
	
	
	

用例ベース翻訳の基本的な原則はできるだけ大きなサイズの用例を用いて翻訳
文を生成することである．
これを確率的に定式化するためには，大きな用例を用いた翻訳結果が大きな翻訳確率を持
たなくてはならない．
本章では，これを実現するための基本アイデアを述べる．


まず，提案手法は入力文を可能なかぎりの部分木の組合せに分解する：
\begin{equation}
D= \{d_{1},...,d_{N}\}.
\end{equation}
ここで，$d_{i}$は入力文の分解のパターン，$D$は$d_{i}$の集合である．

次に，$d_{i}$は入力文を$M_{i}$個の部分木に分解しているとする:
\begin{equation}
d_{i}=\{s_{i1},s_{i2},...,s_{iM_{i}} \},
\end{equation}
ここで，$s_{ij}$は入力文の部分木である．

例えば，図\ref{f_prob.eps}左の入力文の場合，$d_{1},...,d_{4}$の4通りの
部分木の組合せで表現できる．
この例では，$d_{1}$ は入力文を3つの部分木$s_{11}$, $s_{12}$，$s_{13}$に分
解している.
また，$d_{2}$，$d_{3}$は，入力文を2つの部分木に分解している．
また，$d_{4}$のように，文そのものも分解パターンとして取り扱う．

次に，各部分木$s_{ij}$それぞれについて,もっとも翻訳確率$P( t_{ij} \mid
s_{ij} )$(この確率の計算方法は次節にて述べる)の高い用例を選び，それら
の積を翻訳文の翻訳確率$T_{P}(d_{i})$とする:
\begin{equation}
T_{P}(d_{i})=\prod_{s_{ij} \in d_{i}}  P( t_{ij} \mid s_{ij} ).
\end{equation}
ここで，$t_{i1},...,t_{iM{i}}$を$d_{i}$の翻訳とみなし，$T(d_{i})$と表
記する.

最後に，もっとも高い翻訳確率を持つ分解パターン（$d_m$）を以下の式によって探索し，最終
的な翻訳を$T(d_m)$とする：
\begin{equation}
d_m = \arg\max_{d_{i} \in D} T_{P}(d_{i}).
\end{equation}
簡単に言うと，提案手法は，入力文のある単位をどう翻訳するかと，どういう
単位で翻訳するかという2つ問題を解いている．
前者は，最も確率の高い用例を選択することで解決しており，基本的
な統計的翻訳と同様の考え方である．
後者は，入力文の分解パターンを選択することで解決している．


ここで重要なことは，本モデルの枠組みでは，大きな用例を用いた翻訳文が
優先されることである．
この理由は，大きな用例は安定した翻訳先を持つ傾向にあるため，高い翻訳確率
を持ち，当然，その積である翻訳文の確率$ T_{P}(d_{i})$ も自然と高くなる
からである．

例えば，日本語``かける''は，翻訳の際には大きな曖昧性があり，
``bet'',``run''や``play''など様々な英語表現が考えられる．

ここで，もし，$T(d_{1})$のように，入力文を小さな部分木に分解した場合は，適切な
訳である$P(play \mid かける )$の翻訳確率は低く，適切な翻訳は行われない．

一方，$T(d_{2})$では，より大きな表現``CDをかける''を用いた用例を探索している．
この用例の英語表現としては，ほとんどが``play''となり，用例の翻訳確率は
高くなる．
その結果，用例群の翻訳確率の積である$P(d_{2})$も高くなり，この結果が翻
訳として採用される．

また，図\ref{f_prob.eps}の$T(d_{4})$のように，大きすぎる単位で検索した
場合は，コーパス中に存在せず，確率が定義されない場合がある．



\subsection{パラメータの推定}




\begin{figure}
\begin{center}
    \epsfxsize=75mm\epsfbox{f_cs.eps}
\end{center}
\caption{コンテストの定義}
\label{f_cs.eps}
\end{figure}


\begin{table}
\caption{``かける''を含んだ用例とそのコンテキスト (コンテキス
	  トは括弧で示されている)}
\label{tc0}
\begin{center}
\begin{tabular}{ccc}
\hline   用例原言語側 & 用例目的言語側 & context\_sim \\
\hline
	(テープを)かける& play & 0.8				\\
	(ＣＤを)かける  & play & 0.8				\\
	(ＭＤを)かける  & put  & 0.8				\\
	(目覚ましを)かける& set  & 0.6				\\
            :           &  :   &  : \\
	(お金を)かける  & bet  & 0.4				\\
	(1万円を)かける& bet  & 0.4				\\
	(名誉を)かける  & bet  & 0.3				\\
\hline
\end{tabular}
\end{center}
{\footnotesize
* 実際には用例は木構造の形で扱われているが，表記を簡潔にするため，この
図では用例の構造は記していない.
}
\end{table}

本節では，用例の翻訳確率の推定方法を述べる．
まず，英語部分木$t$と日本語部分木$s$からなる用例があるとする．
この翻訳確率$P(t \mid s)$は，
アライメントされたコーパス中での対応$(t,s)$の出現頻度を直接数えて求める:
\begin{equation}
       P(t \mid s) = \frac{ count (t,s) }{ count (*,s)  },
\end{equation}
ここで，$count(t,s)$は，アライメントされたコーパスにおける対応$(t,s)$
の出現頻度，$count(*,s)$は日本語
部分木($s$)の出現頻度である\footnote
{後述する実験では，データスパースネスの問題に対処するため，$s$と$t$は内容語に
  汎化して集計を行った．}．

ただし，この頻度の計算にあたっては，次節に述べるコンテキストの情報を利
用した拡張が可能である．
\clearpage

\subsection{入力文と用例のコンテキストの類似度を取り込んだ確率モデル}



用例の選択にあたって重要な手がかりは入力文と用例の一致するサイズであり，
それは，2.1節で提案された翻訳確率の枠組みで実現されている．
しかし，用例のサイズに加えて，入力文と用例のコンテキストの類似も重要な手がかりである．
提案するモデルは，このようなコンテキストの類似を取り込む拡張を自然に行
うことができる．

まず，提案手法を説明する前に，用例と入力文のコンテキストを定義する．
図\ref{f_cs.eps}に示されるように，用例の原言語側が
$i_{1..3}$という3つの句と接続しているとする．
これらとそれと対応する入力文の$j_{1..3}$をコンテキストと考える．

そして，用例と入力文のコンテキストの類似度を次の式で定める:
\begin{equation}
context\_sim(s) = \sum_{ i \in N} sim (i,j),
\end{equation}
ここで，$i$ は用例Aの日本語側で翻訳に使う部分の周辺の句，$j$は$i$と対
応する入力文の句，$N$は$i$の集合，$sim(i,j)$ はシソーラス\cite{NTT}を用いて計算する
$i$と$j$の類似度(max=1)であり，以下の式で定義される: 
\begin{eqnarray}
 sim(i, j) = \frac{2d_c}{d_{i}+d_{j}},
\end{eqnarray}
ここで，$d_{i}$と$d_{j}$は，それぞれ$i$と$j$のシソーラス上での深さ，
$d_c$ は，$d_{i}$と$d_{j}$の共通するパスの深さである．



提案手法のポイントは，
高い類似度を持つ用例は，同じく高い類似度を持つ用例のみを用いて翻訳確率を計算する
点である．
すなわち，式5によって，ある用例の翻訳確率を計算する際には，$context\_sim(s)$以上
の類似度を持つ用例だけを集計して翻訳確率を計算し，$context\_sim(s)$未満の
類似度の用例は，用例の翻訳確率の計算には用いない．
この操作を用例のフィルタリングと呼ぶ．

このフィルタリングの操作は，用例のサイズごとに翻訳確率を計算する手法を，
類似度にまで拡大したものであり，自然な拡張であるといえる．
この拡張の結果，高い$context\_sim$を持つ用例は，
それよりも低い$context\_sim$を持つ用例の影響を受けず，多くの場合，高い
翻訳確率を持つことになる．

例えば，``レコードをかける''がコーパスに存在しない（しかし，``レコード''
と``かける''それぞれ単独では出現している）場合に，表\ref{tc0}の用例群
を用いて翻訳することを考える．前節までの手法では，このように，大きな
サイズで一致するものがない場合，``かける''単独で翻訳確率を計算すること
になり，``bet''など不適切な訳語が選ばれる可能性がある．

本節の提案手法では，用例``CDをかける''と入力文``レコードをかける''の$context\_sim$
が0.8であるとすると，同じく0.8以上の$context\_sim$を持つ用例だけを用いて翻訳
確率を計算する．
この場合，用例の数は3つだけとなるとが，その英語表現は安定しており，
$P(play \mid かける)=\frac{2}{3}$,  $P(put \mid かける)=\frac{1}{3}$と
なる.
このように類似したコンテキストを持つ用例の翻訳確率は自然と高くなる傾向をもつ．


また，この枠組では，類似度がもっとも高い用例が一つしかない場合，その翻
訳確率は最大の1となる．
これは，より大きな用例が利用可能であった場合に，その大きな用例よりも，類似している小さな用例
を優先しているかのように見える．
この問題は次のように解決されている．

まず，提案手法は用例を構築する際に，大きな用例を分解した一部分も独立した用
例として扱い，データベースに蓄える(3.1節ステップ3)．
よって，ある大きな用例が利用できる状態で，それよりも小さい，もっとも類似した用例
が一つしかない場合における，その一つしかない用例とは，大きな用例の一部分
から作られた用例となる．
というのは，大きな用例が利用可能であるならば，その分解から得られた用例は，
その周辺が入力文と同一であり，最大の類似度とるためである．
よって，この場合，大きな用例ともっとも類似している用例のどちらを採
用すると考えても，作られる翻訳は同じとなる．


\section{翻訳システムの構成}

\begin{figure*}
\begin{center}
\epsfxsize=100mm\epsfbox{f_te_c6_te.eps}
\end{center}
\caption{用例データベースの構築}
\label{f_te_c6_te.eps}
\end{figure*}

提案するシステムは，次の2つのモジュールから構成される：

\begin{enumerate}
\item \textbf{アライメント・モジュール}：コーパスから用例を構築するモジュール，
\item \textbf{翻訳モジュール}：翻訳を行うモジュール．
\end{enumerate}

\subsection{アライメント・モジュール}

\begin{description}
  \item \textbf{ステップ1：対訳文の依存構造への変換}\\
  まず，対訳文を日本語パーサKNP \cite{Kurohashi1994}と英語パーサ
  nl-parser\cite{Charniak2000}によって統語解析する．

  日本語の句の単位は，KNPの出力する文節とし，KNPの出力する依存構造をそ
  のまま以降の処理に用いる．

  英語パーサは句構造を出力するので，句構造中の主辞を決定して，出力結果
  を依存構造に変換する．
  この際，主辞の決定には人手で作成した規則を用い，句の単位はbase-NP，base-VPとした．
  \\
  \item \textbf{ステップ2：アライメント}\\
  次に，翻訳辞書を用いたアライメントを行い，両言語の句の対応関係を得る．
  これには，\cite{Aramaki2001}の手法をそのまま用いた．
  
  
  
  
  
  
  
  この手法は，辞書を使用するが，後述する実験では次の辞書を用いた：EDR電子化辞書
  \footnote{http://www2.nict.go.jp/kk/e416/EDR/J\_index.html}，
  EDICT\footnote{http://www.csse.monash.edu.au/~jwb/j\_edict.html}, 英
  辞郎\footnote{http://www.eijiro.jp/}.
  これらの辞書はのべ二百万項目を持つ．
  \\
  このステップの結果，システムは，図\ref{f_te_c6_te.eps}左のようなアライメントされた対訳文を得る．
  \\
  \item \textbf{ステップ3：用例データベースの構築}\\
  最後に，アライメントされた対訳文（図\ref{f_te_c6_te.eps}左）から，用例
  データベースを構築する．
  この際，システムは，あらゆる対応の組み合わせを生成し，その周辺の句
  （これはコンテキストの類似度を計算する際に用いる）とともにデータベー
  スに登録する（図\ref{f_te_c6_te.eps}右）．
\end{description}

\subsection{翻訳モジュール}

  \begin{description}
  \item \textbf{ステップ1：入力文の解析}\\
  まず，入力文を日本語パーサKNP\cite{Kurohashi1994}を用いて統語解析す
  る．
  \\
  \item \textbf{ステップ2：用例の選択}\\
  入力文のあらゆる可能な部分木の組み合わせに分解し
  （前章の図\ref{f_prob.eps}の左），それらの部分木それぞれについて，
  用例データベース中を検索し，前章の手法にて，その翻訳確率を計算する．
  そして，最も翻訳確率の高くなる用例の組み合わせを採用する．
  \\
  \item \textbf{ステップ3：翻訳文の生成}\\
  前ステップで採用された用例群を結合し，出力文の依存構造にまとめ上げる．
  この操作は次の2つの規則によって行われる．
  \vspace{2mm}
  \begin{enumerate}
    \item
    用例内部の依存構造は，出力文にそのまま用いる．
    例えば，2つの翻訳用例（TE1，TE2）を結合して翻訳文を生成する場
    合を考える（図\ref{f_d1.eps}）．
    ここで，TE1に含まれる2つの句($t_1$,$t_3$)の依存関係（太線
    で描かれている）は，そのまま翻訳文に用いられる．
    \\
    \item
    用例間の依存関係は，その用例が対応する入力文句の依存構造と同じ親子
    関係とする．
    例えば，図\ref{f_d1.eps}のTE1とTE2の間の依存関係について考える．
    TE2は入力文の$i_{2}$と対応しており，$i_{2}$は$i_{3}$と親子関係にある．
    よって，翻訳文側でも，$i_{2}$と対応する$t_{2}$は，$i_{3}$と対応する$t_{3}$
    と親子関係にあるものと考え，点線で描かれている依存関係を得る．
  \end{enumerate}
  
  \vspace{3mm}
  最後に，出力文の依存構造の語順を決定する．
  これは，先の依存構造の場合と同様に，用例の内部の語順は保存し，用例の
  つなぎ目の語順は，単語$n$-gram言語モデル\footnote{単語$n$-gramの学習
  は，後述する実験のトレーニングセット2万文を用いて$n=3$にて行った．}にて
  優先される語順を採用する．
  \end{description}

\begin{figure}
\begin{center}
    \epsfxsize=85mm\epsfbox{f_d1.eps}
\end{center}
\caption{出力文の生成}
\label{f_d1.eps}
\end{figure}


\section{実験}

\subsection{実験設定}


提案手法の妥当性を検証するため，用例ベース翻訳システム
\cite{Aramaki2004}の用例選択部分を提案手法に置き換えて実験を行った．

コーパスはIWSLT04\cite{WO_tsujii}にて配布されたコーパス(トレーニングセッ
トとテストセット)を用いた．
トレーニングセットは旅行対話ドメインの2万の日英対訳文からなる．
テストセットは日本語文($500$文)とそれらの16通りの英語翻訳($500 \times 16$文)からなる．

精度を比較した翻訳システムは次のとおりである．
\begin{enumerate}
\item {\sc PROPOSED:} 提案手法.
\item {\sc WITHOUT\_SIM:} シソーラスを用いない（コンテキストの
  類似を扱わない）提案手法.
\item {\sc BASIC:} 経験則によるメジャーにより用例を選択するシステム
  \cite{Aramaki2004}．
このシステムは，IWSLT04\cite{WO_tsujii}に参加し，高い翻訳精度を示した．
また，このシステムは，{\sc PROPOSED}と同じアライメント結果を用いている．
\item {\sc BASELINE:} 用例ベース翻訳のベースライン．このシステムは，最
  も編集距離が近い用例を探索し，その用例の英語文をそのまま出力する．
\item {\sc C1,C2:} ルールベース方式の商用翻訳システム．
\end{enumerate}

\subsection{評価}

評価は，表\ref{eval}の自動評価尺度を用い，IWSLT04\cite{WO_tsujii}と同
様の以下の条件で行った．

\begin{enumerate}
\item 大文字／小文字の差異の無視．
\item 記号／句読点（−．，？”）の無視．
\item 数字はスペルアウトする（20,000 → Twenty Thousand）．
\end{enumerate}

\subsection{結果}

各手法の精度を表\ref{t1}に示す．
表\ref{t1}に示されるように，
提案手法{\sc proposed}は，経験則による{\sc basic}と比べて僅かに高い精
度を持ち，提案する確率による選択が妥当であることを示している．

また，両者の精度は，商用システム({\sc C1},{\sc C2})や用例ベース翻訳の
ベースライン({\sc baseline})と比べてはるかに高く，現実的な精度上での
比較であることが分かる．

次に，コンテキストの類似度を考慮した効果について述べる．
これは，提案手法（{\sc proposed}）とシソーラスを用いない手法（{\sc
without\_sim}）の精度を比較することで調査できる(表\ref{t1})．
実験結果は，NISTにおいては{\sc proposed}が高く，BLEUにおいては{\sc
without\_sim}が僅かに高かった．
NISTは訳語選択に鋭敏な自動評価手法であるが，
このNISTで，{\sc proposed} が高い値を持つのは，
コンテキストの類似度の導入が訳語選択に貢献しているとためだと推測される．


結果をより具体的に比較するため，両手法で翻
訳結果が異なった例の一部を表\ref{tWithoutAndWithSim}に示す．

表最上部は「ありませんか」という訳し分けが必要な表現の例である．
この表現は，旅行ドメインでは，通常は``do you have''と訳すことが多いの
だが，「（施設／場所が）ありませんか」という場合にはこの訳は不適切とな
る．
このような場合でも，{\sc proposed}は，「ありませんか」を``are there''
用いて正しく訳せている．一方，コンテキストの類似度を考慮しない{\sc
without\_sim}は，``do you have''と不適切な翻訳を行ってしまう．


このように一部の翻訳で，{\sc proposed}がより適切な翻訳を行ったが，
表中段の``notify''と``contact''の差異など，両手法のどちらの訳語が適切
か判断が困難な例も数多く確認された．
この実験は，ドメインを旅行対話に絞った翻訳実験であり，訳し分けを必要す
る入力文が，ドメインを絞った時点で減っているのが，一因であると考えられ
る．





最後に，表\ref{tWithoutAndWithSim}下部のように{\sc proposed} 
の方が誤った訳を出力する場合も観察された．
これは，{\sc proposed}の選んだ用例にアライメント誤りが含まれている
ことが原因であった．
一方，{\sc without\_sim}は，同じ用例のサイズであれば，対応する頻度が高い用例を選ぶ．
複数の用例がみな同じアライメントの誤り方をするわけではないので，{\sc without\_sim}
は必然的にアライメント誤りの影響を受けにくいと考えられる．
この違いが原因で，一部の自動評価指標においては，{\sc without\_sim}の精度の方が
{\sc proposed}よりも高くなったと推測される．




このように，今回の実験では，{\sc proposed}がすべての面で優位であること
を示すことはできなかった．
しかし，(1)アライメント誤りによる精度の低下は，モデルの定式化の妥当性
とは別個の問題である点，また，(2)実験は，ドメインを絞った翻訳実験であ
り，コンテキストを考慮する必要性が少ない点，
これらの2点を考慮すると，コンテキストの
類似度の定式化の妥当性は，実験によって確かめられたと考えられる．
また，アライメント誤りに対する頑健性をどのように{\sc proposed}に持たせ
るかは，今後の課題としたい．



\begin{table}
\caption{proposedとwithout\_simの違い}
\begin{center}
\label{tWithoutAndWithSim}
\begin{tabular}{ll}
\hline
\hline
入力文             & この近くでいいレストランは\textbf{ありませんか}\\
{\sc proposed}     & \textbf{are there} any good restaurants in the neighborhood\\
{\sc without\_sim} & $\surd$\textbf{do you have} any good restaurants in the neighborhood\\
\hline
入力文             & このカートは\textbf{使えますか}\\
{\sc proposed}     & \textbf{can I use} this cart \\
{\sc without\_sim} & $\surd$\textbf{do you accept} this cart \\
\hline
入力文             & 警察へ\textbf{連絡して}ください\\
{\sc proposed}     & please \textbf{notify} the police\\
{\sc without\_sim} & please \textbf{contact} the police\\
\hline
入力文             & サイズが\textbf{わかりません}\\
{\sc proposed}     & \textbf{i 'm not sure of} this size\\
{\sc without\_sim} & \textbf{i do n't know} this size\\
\hline
入力文             & メニューを\textbf{お願いします}\\
{\sc proposed}     & \textbf{give me} the menu \textbf{please}\\
{\sc without\_sim} & \textbf{please} the menu\\
\hline
入力文             & \textbf{アクセサリー}はどこで\textbf{買えますか}\\
{\sc proposed}     & $\surd$where can i \textbf{buy \underline{clothes for} accessory}\\
{\sc without\_sim} & where can i \textbf{get accessory}\\
\hline
入力文             & \textbf{旅行の}目的は何ですか。\\
{\sc proposed}     & $\surd$what 's the purpose of \textbf{the \underline{travel agency}}\\
{\sc without\_sim} & what 's the purpose of \textbf{the trip}\\
\hline
\hline
\end{tabular}
\end{center}
{\footnotesize * \textbf{太字}は{\sc proposed}と{\sc without\_sim}の
翻訳が異なっている箇所を示す．$\surd$は誤りと評価された文を示す．
\underline{下線}はアライメント誤りを示す．}
\end{table}



	
	
	
	\begin{table}
	\caption{自動評価手法}
	\begin{center}
	\label{eval}
	\begin{tabular}{ll}
	\hline
	\textbf{BLEU} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  正解とのn-gram の適合率の相乗(幾何)平均\cite{Papineni2002}.
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{NIST} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  正解とのn-gram の適合率の相加(算術)平均\cite{Doddington2002}.
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{WER} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  Word Error Rate. 正解との編集距離\cite{Niessen2000}．
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{PER} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  Position Independent Word Error Rate.語順を用いない正解との編集距離\cite{Och2001}．
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\textbf{GTM} &
	  \begin{minipage}{105mm}
	  \vspace{1mm}
	  general text matcher.
	正解と一致した最長語列の適合率，再現率の調和平均\cite{Turian2003}．
	  \vspace{1mm}
	  \end{minipage}  \\
	\hline
	\end{tabular}
	\end{center}
	{\footnotesize 
	* BLEU, NIST,GTMについては大きな値ほど精度がよい．WER，PERにつ
	いては小さなほど精度がよい.
        }
	\end{table}
	
	
	


	
	
	
	\begin{table}
	\caption{実験結果}
	\begin{center}
	\label{t1}
	\begin{tabular}{rlllll}
	\hline
	                        & bleu & nist & wer  & per  & gtm \\
	\hline
	{\sc proposed}           & 0.41 & 8.04 & 0.52 & 0.44 & 0.67 \\
	{\sc without\_sim}       & 0.42 & 7.67 & 0.49 & 0.42 &0.68 \\
	{\sc basic}              & 0.39 & 7.92 & 0.52 & 0.44 & 0.67 \\
	{\sc baseline}           & 0.31 & 6.65 & 0.62 & 0.54 & 0.59 \\
	{\sc C1}                 & 0.13 & 5.47 & 0.75 & 0.60 & 0.56 \\
	{\sc C2}                 & 0.27 & 7.31 & 0.54 & 0.47 & 0.65 \\
	\hline
	\end{tabular}
	\end{center}
	\end{table}
	
	
	

\subsection{誤り分析}

{\sc proposed}のより具体的な分析のため，
{\sc proposed}の翻訳結果から，100翻訳文を無作為抽出し，それらを人手でチェックし
た．

この結果，49の翻訳文が正解であり，51の翻訳文が不正解であると判定された．
不正解であった原因を人手で分類した結果を表\ref{t3}に示す．

\begin{table}
\caption{誤り分析}
\begin{center}
\label{t3}
\begin{tabular}{rll}
\hline
数 & 分類	& 説明 \\
\hline
\hline
21 & DATA-SPARSENESS	& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  用例の数が足りないことが原因である翻訳誤り．
  この場合，システムは翻訳辞書 （アライメントの際に用いた辞書）を用い
  て訳語を得るが，しばしば不適切な訳語が得られる）	  
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
 6 & ZERO-PRONOUN & 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  ゼロ代名詞による翻訳誤り．
  ゼロ代名詞が入力文にだけ含まれており，用例には含まれていない場合．
  または，逆に，ゼロ代名詞が用例にだけ含まれて，入力文には含まれていな
  い場合に，翻訳文から代名詞が抜け落ちてしまう．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
 4 & ALIGNMENT-ERR		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
   アライメントが不適切な用例を用いたことによる翻訳誤り.
	  \vspace{1mm}
	  \end{minipage}
  \\
\hline
 3 & WORD-ORDER		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  語順がおかしい場合．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
 3 & SELECTION-ERR		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  適した用例が存在するが，それが選択されず，不適切な用例を用いた場合．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
12 & OTHERS		& 
	  \begin{minipage}{80mm}
	  \vspace{1mm}
  上記のさまざまな誤りが複数存在し，特定の原因に分類できない場合．
	  \vspace{1mm}
	  \end{minipage}  \\
\hline
\end{tabular}
\end{center}
\end{table}


\begin{table}
\caption{翻訳例}
\begin{center}
\label{翻訳例}
\begin{tabular}{ll}
\hline
判定     & 入力文         \\
誤り原因 & システム出力 \\
\hline
\hline
 & 市役所行きのバス停はどこですか。         \\
 & where is the bus stop for the city hall  \\
\hline
 & だいぶよくなったみたい。 \\
 & i feel much better \\
\hline
 & インストラクターを紹介していただけませんか。\\
 & would you please suggest a instructor\\
\hline
 & 歩いてどのくらいですか。\\
 & how long does it take to walk please\\
\hline
 & チェックインは何時からですか。\\
 & what is the check-in time     \\
\hline
$\surd$ & ひどい頭痛がしているんです。\\
ZERO-PRONOUN       & has a bad headache\\
\hline
 & バスでそこへ行けますか。\\
 & can i get there by bus\\
\hline
$\surd$ &あの棚の本を見たいのですが。\\
WORD-ORDER &i 'd like to see the rack that are a books\\
\hline
$\surd$ &なにかメッセージが届いていませんか。\\
ZERO-PRONOUN &have received any message for something\\
\hline
$\surd$ &この綿のセーターを試着してもよろしいですか。\\
DATA-SPARSENESS &i would like to try this sweater for an cotton\\
\hline
 & バス付きの二人部屋にします。\\
 & a two people room with a bath\\
\hline
 & 日本円をドルに替えてください。\\
 & change our japanese yen please into dollars\\
\hline
 & 切符売り場はどこでしょう。\\
 & where can i find the ticket office\\
\hline
\end{tabular}
\end{center}
{\footnotesize * $\surd$は誤りと評価された文を示す．}
\end{table}

表\ref{t3}に見られるように，DATA-SPARSENESSがもっとも顕著な問題である．
このことから，もし，より多くのコーパスが利用可能であれば，精度はさらに
向上すると考えられる．

また，次にZERO-PRONOUN（ゼロ代名詞の問題）が多い．
現在，提案手法はゼロ代名詞に関して，特別な処理を行っていないが，今後，
省略解析の技術を用いて，より注意深くゼロ代名詞を扱うことが必要であろう．

参考までに，表\ref{翻訳例}に翻訳例と分類結果の一部を示す．


\subsection{コーパスサイズと精度}

	
	
	
	\begin{figure}
	\begin{center}
	\epsfxsize=80mm\epsfbox{f_g1.eps}
	\end{center}
	\caption{コーパスサイズと精度(BLEU)}
	\label{f_g1.eps}
	\end{figure}
	
	
	

最後に，コーパスサイズ（トレーニングセットの対訳文数）と翻訳精度（BLEU）
の関係について調査した．
これは，{\sc proposed}と{\sc baseline}の2つのシステムを用いて行った
(図\ref{f_g1.eps}).

図\ref{f_g1.eps}に示されるように，{\sc proposed}と{\sc baseline}の差は
コーパスサイズが小さい場合($x\simeq5,000$)に大きいことが分かる．
このことから，{\sc proposed}の方が用例の不足に対してより頑健であること
が分かる．

また，スコアは今回の実験の最大の用例数($x=20,000$)で
飽和していない．
このことから，もし，より多くの用例を得ることができれば，より高い精度を
得ることが期待される．

\section{関連研究}

これまで様々な用例ベース翻訳システムが提案されてきたが，それらは経験則
\pagebreak
に基づいて用例を選択しており，提案手法のような確率的な尺度に注意を払っ
ていない．

例えば，\cite{Richardson2001}はマニュアルドメインの用例ベース翻訳シス
テムを提案した．
彼らのシステムは，用例と入力文の間で一致する部分のサイズのみを用いて用
例を選択している．

\cite{Furuse1994,Imamura2002}は，一致サイズとコンテキストの類似度の両
方を用いて用例を選択している．
\cite{aramaki2003}は，それらに加え，さらにアライメントのもっともらしさ
を用いて用例を選択している．
これらの手法では，複数の尺度をどのような重みで考慮するか，という重み付
けの問題が存在する．


\section{おわりに}

本稿では，大きな用例ほど翻訳確率が高くなるという考えに基づき，翻訳確率
だけを用いて用例を選択する用例ベース翻訳手法を提案した．
実験の結果は，従来の経験則による用例選択を行うシステムよりも僅かに高い精度を
得ることができ，提案手法の妥当性を示している．

本研究により，これまで，統計ベース翻訳と比べて不透明であった用例ベース翻訳のアルゴリズム
を定式化することでき，今後より一層緻密な用例ベース翻訳の議論が可能になると考えている．





\bibliographystyle{jnlpbbl}

\begin{thebibliography}{}

\bibitem[\protect\BCAY{Akiba, Federico, Kando, Nakaiwa, Paul, \BBA\
  Tsujii}{Akiba et~al.}{2004}]{WO_tsujii}
Akiba, Y., Federico, M., Kando, N., Nakaiwa, H., Paul, M., \BBA\ Tsujii, J.
  \BBOP 2004\BBCP.
\newblock \BBOQ Overview of the {IWSLT04} Evaluation Campaign\BBCQ\
\newblock In {\Bem Proceedings of the International Workshop on Spoken Language
  Translation (IWSLT2004)}, \mbox{\BPGS\ 1--12}.

\bibitem[\protect\BCAY{Aramaki \BBA\ Kurohashi}{Aramaki \BBA\
  Kurohashi}{2004}]{Aramaki2004}
Aramaki, E.\BBACOMMA\ \BBA\ Kurohashi, S. \BBOP 2004\BBCP.
\newblock \BBOQ Example-based Machine Translation using Structual Translation
  Examples\BBCQ\
\newblock In {\Bem Proceedings of the International Workshop on Spoken Language
  Translation (IWSLT2004)}, \mbox{\BPGS\ 91--94}.

\bibitem[\protect\BCAY{Aramaki, Kurohashi, Kashioka, \BBA\ Tanaka}{Aramaki
  et~al.}{2003}]{aramaki2003}
Aramaki, E., Kurohashi, S., Kashioka, H., \BBA\ Tanaka, H. \BBOP 2003\BBCP.
\newblock \BBOQ Word Selection for EBMT based on Monolingual Similarity and
  Translation Confidence\BBCQ\
\newblock In {\Bem Proceedings of the Human Language Technology conference and
  the North American chapter of the Association for Computational Linguistics
  (HLT-NAACL2003) Workshop on Building and Using Parallel Texts: Data Driven
  Machine Translation and Beyond}, \mbox{\BPGS\ 57--64}.

\bibitem[\protect\BCAY{Aramaki, Kurohashi, Sato, \BBA\ Watanabe}{Aramaki
  et~al.}{2001}]{Aramaki2001}
Aramaki, E., Kurohashi, S., Sato, S., \BBA\ Watanabe, H. \BBOP 2001\BBCP.
\newblock \BBOQ Finding Translation Correspondences from Parallel Parsed Corpus
  for Example-based Translation\BBCQ\
\newblock In {\Bem Proceedings of MT Summit VIII}, \mbox{\BPGS\ 27--32}.

\bibitem[\protect\BCAY{Brown, Pietra, cent J.~Della~Pietra, \BBA\ Mercer}{Brown
  et~al.}{1993}]{Brown1993}
Brown, P.~F., Pietra, S. A.~D., cent J.~Della~Pietra, V., \BBA\ Mercer, R.~L.
  \BBOP 1993\BBCP.
\newblock \BBOQ The Mathematics of Statistical Machine Translation: Parameter
  Estimation\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 19}  (2).

\bibitem[\protect\BCAY{Charniak}{Charniak}{2000}]{Charniak2000}
Charniak, E. \BBOP 2000\BBCP.
\newblock \BBOQ A maximum-entropy-inspired parser\BBCQ\
\newblock In {\Bem Proceedings of the North American chapter of the Association
  for Computational Linguistics (NAACL 2000)}, \mbox{\BPGS\ 132--139}.

\bibitem[\protect\BCAY{Doddington}{Doddington}{2002}]{Doddington2002}
Doddington, G. \BBOP 2002\BBCP.
\newblock \BBOQ Automatic evaluation of machine translation quality using
  n-gram co-occurrence statistics\BBCQ\
\newblock In {\Bem Proceedings of the Human Language Technology conference
  (HLT2002)}, \mbox{\BPGS\ 257--258}.

\bibitem[\protect\BCAY{Furuse \BBA\ Iida}{Furuse \BBA\ Iida}{1994}]{Furuse1994}
Furuse, O.\BBACOMMA\ \BBA\ Iida, H. \BBOP 1994\BBCP.
\newblock \BBOQ Constituent Boundary Parsing for Example-Based Machine
  Translation\BBCQ\
\newblock In {\Bem Proceedings of the International Conference on Computational
  Linguistics (COLING1994)}, \mbox{\BPGS\ 105--111}.

\bibitem[\protect\BCAY{Imamura}{Imamura}{2002}]{Imamura2002}
Imamura, K. \BBOP 2002\BBCP.
\newblock \BBOQ Application of Translation Knowledgeacquired by Hierarchical
  Phrase Alignment for Pattern-based MT\BBCQ\
\newblock In {\Bem Proceedings of the Conference on Theoretical and
  Methodological Issues in Machine Translation (TMI2002)}, \mbox{\BPGS\
  74--84}.

\bibitem[\protect\BCAY{Koehn, Och, \BBA\ Marcu}{Koehn et~al.}{2003}]{Koehn2003}
Koehn, P., Och, F.~J., \BBA\ Marcu, D. \BBOP 2003\BBCP.
\newblock \BBOQ Statistical phrase-based translation\BBCQ\
\newblock In {\Bem Proceedings of the Human Language Technology conference and
  the North American chapter of the Association for Computational Linguistics
  (HLT-NAACL2003)}, \mbox{\BPGS\ 48--54}.

\bibitem[\protect\BCAY{Kurohashi \BBA\ Nagao}{Kurohashi \BBA\
  Nagao}{1994}]{Kurohashi1994}
Kurohashi, S.\BBACOMMA\ \BBA\ Nagao, M. \BBOP 1994\BBCP.
\newblock \BBOQ A Syntactic Analysis Method of Long {J}apanese Sentences based
  on the Detection of Conjunctive Structures\BBCQ\
\newblock {\Bem Computational Linguistics}, {\Bbf 20}  (4).

\bibitem[\protect\BCAY{Nagao}{Nagao}{1984}]{Nagao1984}
Nagao, M. \BBOP 1984\BBCP.
\newblock \BBOQ A Framework of a Mechanical Translation between {J}apanese and
  {E}nglish by Analogy Principle\BBCQ\
\newblock In {\Bem Elithorn, A. and Banerji, R. (eds.): Artificial and Human
  Intelligence}, \mbox{\BPGS\ 173--180}.

\bibitem[\protect\BCAY{Niessen, F.~J.~Och, \BBA\ Ney}{Niessen
  et~al.}{2000}]{Niessen2000}
Niessen, S., F.~J.~Och, G.~L., \BBA\ Ney, H. \BBOP 2000\BBCP.
\newblock \BBOQ An evaluation tool for machine translation: Fast evaluation for
  machine translation research\BBCQ\
\newblock In {\Bem Proceedings of the international conference on Language
  Resources and Evaluation (LREC2000)}, \mbox{\BPGS\ 39--45}.

\bibitem[\protect\BCAY{Och, Tillmann, \BBA\ Ney}{Och et~al.}{1999}]{Och1999}
Och, F.~J., Tillmann, C., \BBA\ Ney, H. \BBOP 1999\BBCP.
\newblock \BBOQ Improved alignment models for statistical machine
  translation\BBCQ\
\newblock In {\Bem Proceedings of the Empirical Methods in Natural Language
  Processing and Very Large Corpora (EMNLP1999)}, \mbox{\BPGS\ 20--28}.

\bibitem[\protect\BCAY{Och, Uerng, \BBA\ Ney}{Och et~al.}{2001}]{Och2001}
Och, F.~J., Uerng, N., \BBA\ Ney, H. \BBOP 2001\BBCP.
\newblock \BBOQ An effcient a* search algorithm for statistical machine
  translation\BBCQ\
\newblock In {\Bem Proceedings of the Annual Conference of the Association for
  Computational Linguistics (ACL2001) Workshop on Data-Driven Machine
  Translation}, \mbox{\BPGS\ 55--62}.

\bibitem[\protect\BCAY{Papineni, Roukos, Ward, \BBA\ Zhu}{Papineni
  et~al.}{2002}]{Papineni2002}
Papineni, K., Roukos, S., Ward, T., \BBA\ Zhu, W.~J. \BBOP 2002\BBCP.
\newblock \BBOQ BLEU: a Method for Automatic Evaluation of Machine
  Translation\BBCQ\
\newblock In {\Bem Proceedings of the Annual Conference of the Association for
  Computational Linguistics (ACL2002)}, \mbox{\BPGS\ 311--318}.

\bibitem[\protect\BCAY{Richardson, Dolan, Menezes, \BBA\
  Corston-Oliver}{Richardson et~al.}{2001}]{Richardson2001}
Richardson, S.~D., Dolan, W.~B., Menezes, A., \BBA\ Corston-Oliver, M. \BBOP
  2001\BBCP.
\newblock \BBOQ Overcoming the customization bottleneck using example-based
  MT\BBCQ\
\newblock In {\Bem Proceedings of the Annual Conference of the Association for
  Computational Linguistics (ACL2001) Workshop on Data-Driven Methods in
  Machine Translation}, \mbox{\BPGS\ 9--16}.

\bibitem[\protect\BCAY{Turian, Shen, \BBA\ Melamed}{Turian
  et~al.}{2003}]{Turian2003}
Turian, J.~P., Shen, L., \BBA\ Melamed, I.~D. \BBOP 2003\BBCP.
\newblock \BBOQ Evaluation of machine translation and its evaluation\BBCQ\
\newblock In {\Bem Proceedings of MT Summmit IX}, \mbox{\BPGS\ 386--393}.

\bibitem[\protect\BCAY{Watanabe, Sumita, \BBA\ Okuno}{Watanabe
  et~al.}{2003}]{Watanabe2003}
Watanabe, T., Sumita, E., \BBA\ Okuno, H.~G. \BBOP 2003\BBCP.
\newblock \BBOQ Chunk-based Statistical Translation\BBCQ\
\newblock In {\Bem Proceedings of the Annual Conference of the Association for
  Computational Linguistics (ACL2003)}, \mbox{\BPGS\ 303--310}.

\bibitem[\protect\BCAY{池原悟\JBA 宮崎正弘\JBA 白井諭\JBA 横尾昭男\JBA
  中岩浩巳\JBA 小倉健太郎\JBA 大山芳史\JBA 林良彦}{池原悟\Jetal }{1997}]{NTT}
池原悟\JBA 宮崎正弘\JBA 白井諭\JBA 横尾昭男\JBA 中岩浩巳\JBA 小倉健太郎\JBA
  大山芳史\JBA 林良彦 \BBOP 1997\BBCP.
\newblock \Jem{日本語語彙大系}.
\newblock 岩波書店.

\end{thebibliography}



\begin{biography}
\biotitle{略歴}
\bioauthor{荒牧 英治}
{
	1998 年京都大学総合人間学部基礎科学科卒業．
	2005 年東京大学大学院情報理工学系研究科博士課程修了．博士(情報理工学).
	現在，東京大学附属病院企画情報運営部特任助手．
	機械翻訳，医療情報の研究に従事．
}
\bioauthor{黒橋 禎夫}
{
	1989年 京都大学工学部電気工学第二学科卒業．博士(工学).
	1994年 同大学院博士課程修了．
	京都大学工学部助手，京都大学情報学研究科講師，東京大学大学院情報理工学系研究科助教授を経て，
	2006年京都大学情報学研究科教授，現在に至る．
	自然言語処理，知識情報処理の研究に従事．
}
\bioauthor{柏岡 秀紀}
{
	1993年 大阪大学大学院基礎工学研究科博士後期課程修了.博士(工学).
	同年ATR音声翻訳通信研究所入社.
	1998年 同研究所主任研究員（現ATR音声言語コミュニケーション研究所).
	1999年 奈良先端科学技術大学院大学情報学研究科客員助教授.
	主に自然言語処理、機械翻訳の研究に従事.
}
\bioauthor{加藤 直人}
{
	1986年早稲田大学理工学部電気工学科卒業．1988年同大学院修士課程修了．
	同年日本放送協会(NHK)に入局．現在，NHK放送技術研究所に勤務．
	この間，ATR音声翻訳通信研究所，ATR音声言語コミュニケーション研究所に出向．
	博士(情報科学)．機械翻訳，対話処理，音声言語処理，自動要約の研究に従事．
}



\bioreceived{受付}
\biorevised{再受付}
\bioaccepted{採録}
\end{biography}
\end{document}
