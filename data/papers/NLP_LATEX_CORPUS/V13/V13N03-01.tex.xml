<?xml version="1.0" ?>
<root>
  <title>用例ベース翻訳の確率的モデル化</title>
  <jabstract>用例ベース翻訳は，これまで，経験則にもとづく指標／基準により用例を選択してきた．しかし，経験則に頼った場合，その修正を行うのが困難であり，また，アルゴリズムが不透明になる恐れがある．そこで，本研究では用例ベース翻訳を定式化するための確率モデルを提案する．提案するモデルは，翻訳確率の最も高い用例の組み合わせを探索することで，翻訳文を生成する．さらに，本モデルは用例と入力文のコンテキストの類似度を自然に翻訳確率に取り込む拡張も可能である．実験の結果，本モデルを用いたシステムは，従来の経験則によるシステムの精度を僅かに上回り，用例ベース翻訳の透明性の高いモデル化を実現することに成功した．</jabstract>
  <jkeywords>用例ベース翻訳，機械翻訳，確率モデル，コンテキストの類似，依存構造</jkeywords>
  <section title="はじめに">近年，統計ベース翻訳や用例ベース翻訳など大量のテキストを用いた翻訳手法（コーパスベース翻訳）が注目されている．我々は，用例ベース翻訳に焦点を当て研究を行っている．用例ベース翻訳の基本的なアイデアは，入力文の各部分に対して類似している用例を選択し，それらを組み合わせて翻訳を行うことである．ここでいう類似とは，通常，入力文とできるかぎり大きく一致していればいるほど（一致する単語数または文節数が多いほど）よいと考えられてきた．これは，用例が大きくなればなるほど，より大きなコンテキストを扱うことになり，正確な訳につながるからである．そのため，これまでの用例ベース翻訳は，大きな用例を優先する指標／基準を用いて用例を選択してきた．一方，統計ベース翻訳は，翻訳確率を緻密に計算するため，基本的には，翻訳用例を小さな語／句単位に分解して学習を行う．もちろん，最近の統計ベース翻訳では，より大きな単位を取り扱う試みも行われている．例えば，Och等は，アライメントテンプレートという単位を導入し，語列をまとめて学習した．また，他にも多くの統計翻訳研究が語よりも大きな単位を学習に取り込む試みを行っている．しかし，入力文とできる限り大きく一致した用例を用いる用例ベース翻訳と比べると，あらかじめ翻訳単位を設定する統計ベース翻訳の扱う単位は依然として小さいと言える．簡単に言うと，統計ベース翻訳と用例ベース翻訳は，以下の2点で異なる．用例ベース翻訳は，用例のサイズ（一致する単語数または文節数)を重視している．統計ベース翻訳は用例の頻度を重視している．用例ベース翻訳は，経験則による指標／基準にもとづいて動作している．統計ベース翻訳は確率的に定式化されている．本研究では，用例ベース翻訳の問題は，(2)経験則による指標／基準を用いている点だと考える．経験則による指標／基準は，調整や修正が困難であり，また，アルゴリズムが不透明になる恐れがある．そこで，本研究では，用例ベース翻訳を定式化するために，用例ベース翻訳のための確率モデルを提案する．提案する翻訳モデルは，統計ベースのそれとは異なり，語や句単位の小さな単位から，文全体まで，あらゆるサイズをカバーした翻訳確率を計算する．この枠組みの上では，大きなサイズの用例は安定した翻訳先を伴うため，高い翻訳確率を持つと考えられる．したがって，翻訳確率が高い用例を選ぶことで，自然と用例のサイズを考慮した用例の選択が可能となる．また，提案する翻訳確率は容易に拡張可能であり，用例と入力文のコンテキストの類似度を確率モデルに取り込むことも可能である．実験の結果，提案手法は，従来の経験則に基づいた翻訳システムよりも僅かに高い精度を得て，用例ベース翻訳の透明性の高いモデル化を実現することに成功したので報告する．提案手法は言語ペアを特定しないが，本稿は日英翻訳方向で説明し，実験を行った．本稿の構成は，以下のとおりである．2章では，提案するモデルの基本的アイデアについて説明する．3章では，アルゴリズムについて述べる．4章では，実験について報告する．5章では，関連研究を紹介し，6章に結論を述べる．</section>
  <section title="提案手法">							用例ベース翻訳の基本的な原則はできるだけ大きなサイズの用例を用いて翻訳文を生成することである．これを確率的に定式化するためには，大きな用例を用いた翻訳結果が大きな翻訳確率を持たなくてはならない．本章では，これを実現するための基本アイデアを述べる．まず，提案手法は入力文を可能なかぎりの部分木の組合せに分解する：ここで，d_iは入力文の分解のパターン，Dはd_iの集合である．次に，d_iは入力文をM_i個の部分木に分解しているとする:ここで，s_ijは入力文の部分木である．例えば，図左の入力文の場合，d_1,...,d_4の4通りの部分木の組合せで表現できる．この例では，d_1は入力文を3つの部分木s_11,s_12，s_13に分解している.また，d_2，d_3は，入力文を2つの部分木に分解している．また，d_4のように，文そのものも分解パターンとして取り扱う．次に，各部分木s_ijそれぞれについて,もっとも翻訳確率P(t_ij_ij)(この確率の計算方法は次節にて述べる)の高い用例を選び，それらの積を翻訳文の翻訳確率T_P(d_i)とする:ここで，t_i1,...,t_iMiをd_iの翻訳とみなし，T(d_i)と表記する.最後に，もっとも高い翻訳確率を持つ分解パターン（d_m）を以下の式によって探索し，最終的な翻訳をT(d_m)とする：簡単に言うと，提案手法は，入力文のある単位をどう翻訳するかと，どういう単位で翻訳するかという2つ問題を解いている．前者は，最も確率の高い用例を選択することで解決しており，基本的な統計的翻訳と同様の考え方である．後者は，入力文の分解パターンを選択することで解決している．ここで重要なことは，本モデルの枠組みでは，大きな用例を用いた翻訳文が優先されることである．この理由は，大きな用例は安定した翻訳先を持つ傾向にあるため，高い翻訳確率を持ち，当然，その積である翻訳文の確率T_P(d_i)も自然と高くなるからである．例えば，日本語``かける''は，翻訳の際には大きな曖昧性があり，``bet'',``run''や``play''など様々な英語表現が考えられる．ここで，もし，T(d_1)のように，入力文を小さな部分木に分解した場合は，適切な訳であるP(playかける)の翻訳確率は低く，適切な翻訳は行われない．一方，T(d_2)では，より大きな表現``CDをかける''を用いた用例を探索している．この用例の英語表現としては，ほとんどが``play''となり，用例の翻訳確率は高くなる．その結果，用例群の翻訳確率の積であるP(d_2)も高くなり，この結果が翻訳として採用される．また，図のT(d_4)のように，大きすぎる単位で検索した場合は，コーパス中に存在せず，確率が定義されない場合がある．</section>
  <subsection title="パラメータの推定">本節では，用例の翻訳確率の推定方法を述べる．まず，英語部分木tと日本語部分木sからなる用例があるとする．この翻訳確率P(ts)は，アライメントされたコーパス中での対応(t,s)の出現頻度を直接数えて求める:ここで，count(t,s)は，アライメントされたコーパスにおける対応(t,s)の出現頻度，count(*,s)は日本語部分木(s)の出現頻度である．ただし，この頻度の計算にあたっては，次節に述べるコンテキストの情報を利用した拡張が可能である．</subsection>
  <subsection title="入力文と用例のコンテキストの類似度を取り込んだ確率モデル">用例の選択にあたって重要な手がかりは入力文と用例の一致するサイズであり，それは，2.1節で提案された翻訳確率の枠組みで実現されている．しかし，用例のサイズに加えて，入力文と用例のコンテキストの類似も重要な手がかりである．提案するモデルは，このようなコンテキストの類似を取り込む拡張を自然に行うことができる．まず，提案手法を説明する前に，用例と入力文のコンテキストを定義する．図に示されるように，用例の原言語側がi_1..3という3つの句と接続しているとする．これらとそれと対応する入力文のj_1..3をコンテキストと考える．そして，用例と入力文のコンテキストの類似度を次の式で定める:ここで，iは用例Aの日本語側で翻訳に使う部分の周辺の句，jはiと対応する入力文の句，Nはiの集合，sim(i,j)はシソーラスを用いて計算するiとjの類似度(max=1)であり，以下の式で定義される:sim(i,j)=2d_cd_i+d_j,eqnarrayここで，d_iとd_jは，それぞれiとjのシソーラス上での深さ，d_cは，d_iとd_jの共通するパスの深さである．提案手法のポイントは，高い類似度を持つ用例は，同じく高い類似度を持つ用例のみを用いて翻訳確率を計算する点である．すなわち，式5によって，ある用例の翻訳確率を計算する際には，context_sim(s)以上の類似度を持つ用例だけを集計して翻訳確率を計算し，context_sim(s)未満の類似度の用例は，用例の翻訳確率の計算には用いない．この操作を用例のフィルタリングと呼ぶ．このフィルタリングの操作は，用例のサイズごとに翻訳確率を計算する手法を，類似度にまで拡大したものであり，自然な拡張であるといえる．この拡張の結果，高いcontext_simを持つ用例は，それよりも低いcontext_simを持つ用例の影響を受けず，多くの場合，高い翻訳確率を持つことになる．例えば，``レコードをかける''がコーパスに存在しない（しかし，``レコード''と``かける''それぞれ単独では出現している）場合に，表の用例群を用いて翻訳することを考える．前節までの手法では，このように，大きなサイズで一致するものがない場合，``かける''単独で翻訳確率を計算することになり，``bet''など不適切な訳語が選ばれる可能性がある．本節の提案手法では，用例``CDをかける''と入力文``レコードをかける''のcontext_simが0.8であるとすると，同じく0.8以上のcontext_simを持つ用例だけを用いて翻訳確率を計算する．この場合，用例の数は3つだけとなるとが，その英語表現は安定しており，P(playかける)=23,P(putかける)=13となる.このように類似したコンテキストを持つ用例の翻訳確率は自然と高くなる傾向をもつ．また，この枠組では，類似度がもっとも高い用例が一つしかない場合，その翻訳確率は最大の1となる．これは，より大きな用例が利用可能であった場合に，その大きな用例よりも，類似している小さな用例を優先しているかのように見える．この問題は次のように解決されている．まず，提案手法は用例を構築する際に，大きな用例を分解した一部分も独立した用例として扱い，データベースに蓄える(3.1節ステップ3)．よって，ある大きな用例が利用できる状態で，それよりも小さい，もっとも類似した用例が一つしかない場合における，その一つしかない用例とは，大きな用例の一部分から作られた用例となる．というのは，大きな用例が利用可能であるならば，その分解から得られた用例は，その周辺が入力文と同一であり，最大の類似度とるためである．よって，この場合，大きな用例ともっとも類似している用例のどちらを採用すると考えても，作られる翻訳は同じとなる．</subsection>
  <section title="翻訳システムの構成">figure*提案するシステムは，次の2つのモジュールから構成される：アライメント・モジュール：コーパスから用例を構築するモジュール，翻訳モジュール：翻訳を行うモジュール．</section>
  <subsection title="アライメント・モジュール"/>
  <subsection title="翻訳モジュール"/>
  <section title="実験"/>
  <subsection title="実験設定">提案手法の妥当性を検証するため，用例ベース翻訳システムの用例選択部分を提案手法に置き換えて実験を行った．コーパスはIWSLT04にて配布されたコーパス(トレーニングセットとテストセット)を用いた．トレーニングセットは旅行対話ドメインの2万の日英対訳文からなる．テストセットは日本語文(500文)とそれらの16通りの英語翻訳(50016文)からなる．精度を比較した翻訳システムは次のとおりである．PROPOSED:提案手法.WITHOUT_SIM:シソーラスを用いない（コンテキストの類似を扱わない）提案手法.BASIC:経験則によるメジャーにより用例を選択するシステム．このシステムは，IWSLT04に参加し，高い翻訳精度を示した．また，このシステムは，PROPOSEDと同じアライメント結果を用いている．BASELINE:用例ベース翻訳のベースライン．このシステムは，最も編集距離が近い用例を探索し，その用例の英語文をそのまま出力する．C1,C2:ルールベース方式の商用翻訳システム．</subsection>
  <subsection title="評価">評価は，表の自動評価尺度を用い，IWSLT04と同様の以下の条件で行った．大文字／小文字の差異の無視．記号／句読点（−．，？”）の無視．数字はスペルアウトする（20,000→TwentyThousand）．</subsection>
  <subsection title="結果">各手法の精度を表に示す．表に示されるように，提案手法proposedは，経験則によるbasicと比べて僅かに高い精度を持ち，提案する確率による選択が妥当であることを示している．また，両者の精度は，商用システム(C1,C2)や用例ベース翻訳のベースライン(baseline)と比べてはるかに高く，現実的な精度上での比較であることが分かる．次に，コンテキストの類似度を考慮した効果について述べる．これは，提案手法（proposed）とシソーラスを用いない手法（_sim）の精度を比較することで調査できる(表)．実験結果は，NISTにおいてはproposedが高く，BLEUにおいては_simが僅かに高かった．NISTは訳語選択に鋭敏な自動評価手法であるが，このNISTで，proposedが高い値を持つのは，コンテキストの類似度の導入が訳語選択に貢献しているとためだと推測される．結果をより具体的に比較するため，両手法で翻訳結果が異なった例の一部を表に示す．表最上部は「ありませんか」という訳し分けが必要な表現の例である．この表現は，旅行ドメインでは，通常は``doyouhave''と訳すことが多いのだが，「（施設／場所が）ありませんか」という場合にはこの訳は不適切となる．このような場合でも，proposedは，「ありませんか」を``arethere''用いて正しく訳せている．一方，コンテキストの類似度を考慮しない_simは，``doyouhave''と不適切な翻訳を行ってしまう．このように一部の翻訳で，proposedがより適切な翻訳を行ったが，表中段の``notify''と``contact''の差異など，両手法のどちらの訳語が適切か判断が困難な例も数多く確認された．この実験は，ドメインを旅行対話に絞った翻訳実験であり，訳し分けを必要する入力文が，ドメインを絞った時点で減っているのが，一因であると考えられる．最後に，表下部のようにproposedの方が誤った訳を出力する場合も観察された．これは，proposedの選んだ用例にアライメント誤りが含まれていることが原因であった．一方，without_simは，同じ用例のサイズであれば，対応する頻度が高い用例を選ぶ．複数の用例がみな同じアライメントの誤り方をするわけではないので，without_simは必然的にアライメント誤りの影響を受けにくいと考えられる．この違いが原因で，一部の自動評価指標においては，without_simの精度の方がproposedよりも高くなったと推測される．このように，今回の実験では，proposedがすべての面で優位であることを示すことはできなかった．しかし，(1)アライメント誤りによる精度の低下は，モデルの定式化の妥当性とは別個の問題である点，また，(2)実験は，ドメインを絞った翻訳実験であり，コンテキストを考慮する必要性が少ない点，これらの2点を考慮すると，コンテキストの類似度の定式化の妥当性は，実験によって確かめられたと考えられる．また，アライメント誤りに対する頑健性をどのようにproposedに持たせるかは，今後の課題としたい．														</subsection>
  <subsection title="誤り分析">proposedのより具体的な分析のため，proposedの翻訳結果から，100翻訳文を無作為抽出し，それらを人手でチェックした．この結果，49の翻訳文が正解であり，51の翻訳文が不正解であると判定された．不正解であった原因を人手で分類した結果を表に示す．表に見られるように，DATA-SPARSENESSがもっとも顕著な問題である．このことから，もし，より多くのコーパスが利用可能であれば，精度はさらに向上すると考えられる．また，次にZERO-PRONOUN（ゼロ代名詞の問題）が多い．現在，提案手法はゼロ代名詞に関して，特別な処理を行っていないが，今後，省略解析の技術を用いて，より注意深くゼロ代名詞を扱うことが必要であろう．参考までに，表に翻訳例と分類結果の一部を示す．</subsection>
  <subsection title="コーパスサイズと精度">							最後に，コーパスサイズ（トレーニングセットの対訳文数）と翻訳精度（BLEU）の関係について調査した．これは，proposedとbaselineの2つのシステムを用いて行った(図).図に示されるように，proposedとbaselineの差はコーパスサイズが小さい場合(x5,000)に大きいことが分かる．このことから，proposedの方が用例の不足に対してより頑健であることが分かる．また，スコアは今回の実験の最大の用例数(x=20,000)で飽和していない．このことから，もし，より多くの用例を得ることができれば，より高い精度を得ることが期待される．</subsection>
  <section title="関連研究">これまで様々な用例ベース翻訳システムが提案されてきたが，それらは経験則に基づいて用例を選択しており，提案手法のような確率的な尺度に注意を払っていない．例えば，はマニュアルドメインの用例ベース翻訳システムを提案した．彼らのシステムは，用例と入力文の間で一致する部分のサイズのみを用いて用例を選択している．は，一致サイズとコンテキストの類似度の両方を用いて用例を選択している．は，それらに加え，さらにアライメントのもっともらしさを用いて用例を選択している．これらの手法では，複数の尺度をどのような重みで考慮するか，という重み付けの問題が存在する．</section>
  <section title="おわりに">本稿では，大きな用例ほど翻訳確率が高くなるという考えに基づき，翻訳確率だけを用いて用例を選択する用例ベース翻訳手法を提案した．実験の結果は，従来の経験則による用例選択を行うシステムよりも僅かに高い精度を得ることができ，提案手法の妥当性を示している．本研究により，これまで，統計ベース翻訳と比べて不透明であった用例ベース翻訳のアルゴリズムを定式化することでき，今後より一層緻密な用例ベース翻訳の議論が可能になると考えている．document</section>
</root>
