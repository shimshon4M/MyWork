    \documentclass[japanese]{jnlp_1.4b}
\usepackage{jnlpbbl_1.3}
\usepackage[dvipdfm]{graphicx}
\usepackage{amsmath}
\usepackage{array}
\usepackage{hangcaption_jnlp}
\renewcommand{\BTR}{}           


\usepackage{multirow}
\def\FIGREF#1{}
\def\TABREF#1{}


\Volume{23}
\Number{1}
\Month{January}
\Year{2016}

\received{2015}{5}{12}
\revised{2015}{8}{4}
\accepted{2015}{9}{12}

\setcounter{page}{119}


\jtitle{「ロボットは東大に入れるか」プロジェクト：\\ 代ゼミセンター模試タスクにおけるエラーの分析}
\jauthor{松崎　拓也\affiref{Author_1} \and 横野　　光\affiref{Author_2} \and 宮尾　祐介\affiref{Author_2} \and 川添　　愛\affiref{Author_2} \and \\
	狩野　芳伸\affiref{Author_3} \and 加納　隼人\affiref{Author_1} \and 佐藤　理史\affiref{Author_1} \and 東中竜一郎\affiref{Author_4} \and 杉山　弘晃\affiref{Author_4} \and \\
	磯崎　秀樹\affiref{Author_5} \and 菊井玄一郎\affiref{Author_5} \and 堂坂　浩二\affiref{Author_6} \and 平　　博順\affiref{Author_7} \and \\
	南　　泰浩\affiref{Author_8} \and 新井　紀子\affiref{Author_2}}
\jabstract{
「ロボットは東大に入れるか」は，大学入試試験問題を計算機で解くという挑戦を通じ，
言語処理を含む AI 諸技術の再統合と，知的情報処理の新たな課題の発見を目指す
プロジェクトである．知的能力の測定を第一目的として設計された入試問題は，
AI 技術の恰好のベンチマークであるとともに，
人間の受験者と機械のエラー傾向を直接比較することが可能である．
本稿では，大手予備校主催のセンター試験形式模試を主たる評価データとして，
各科目の解答システムのエラーを分析し，高得点へ向けた今後の課題を明らかにする
とともに，分野としての言語処理全体における現在の課題を探る．
}
\jkeywords{総合的タスク，大学入試試験問題，エラー分析}

\etitle{The Todai Robot Project: \\ Error Analysis on the Results of the Yozemi Center Test}
\eauthor{Takuya Matsuzaki\affiref{Author_1} \and Hikaru Yokono\affiref{Author_2} \and Yusuke Miyao\affiref{Author_2} \and Ai Kawazoe\affiref{Author_2} \and Yoshinobu Kano\affiref{Author_3} \and Hayato Kanou\affiref{Author_1} \and Satoshi Sato\affiref{Author_1} \and Ryuichiro Higashinaka\affiref{Author_4} \and Hiroaki Sugiyama\affiref{Author_4} \and Hideki Isozaki\affiref{Author_5} \and Genichiro Kikui\affiref{Author_5} \and Koji Dosaka\affiref{Author_6} \and Hirotoshi Taira\affiref{Author_7} \and Yasuhiro Minami\affiref{Author_8} \and Noriko H. Arai\affiref{Author_2}}
\eabstract{
The Todai Robot Project aims at integrating various AI technologies including
natural language processing (NLP), as well as uncovering novel AI problems that 
have been missed while the fragmentation of the research field, through the development of 
software systems that solve university entrance exam problems.
Being primarily designed for the measurement of human intellectual abilities,
university entrance exam problems serve as an ideal benchmark for AI technologies.
They also enable a quantitative comparison between the AI systems and human test takers.
This paper analyzes the errors made by the software systems on the mock university entrance exams 
hosted by a popular preparatory school.
Based on the analyses, key problems towards higher system performances and the current issues 
in the field of NLP are discussed.
}
\ekeywords{Integrated AI Tasks, University Entrance Examinations, Error Analysis}

\headauthor{松崎，{\kern-0.5zw}横野，{\kern-0.5zw}宮尾，{\kern-0.5zw}川添，{\kern-0.5zw}狩野，{\kern-0.5zw}加納，{\kern-0.5zw}佐藤，{\kern-0.5zw}東中，{\kern-0.5zw}杉山，{\kern-0.5zw}磯崎，{\kern-0.5zw}菊井，{\kern-0.5zw}堂坂，{\kern-0.5zw}平，{\kern-0.5zw}南，{\kern-0.5zw}新井}
\headtitle{「ロボットは東大に入れるか」}

\affilabel{Author_1}{名古屋大学大学院工学研究科}{Graduate School of Engineering, Nagoya University}
\affilabel{Author_2}{国立情報学研究所}{National Institute of Informatics}
\affilabel{Author_3}{静岡大学情報学部}{Faculty of Informatics, Shizuoka University}
\affilabel{Author_4}{NTT コミュニケーション科学基礎研究所}{NTT Communication Science Laboratories, NTT Corporation}
\affilabel{Author_5}{岡山県立大学情報工学部}{Faculty of Computer Science and Systems Engineering, Okayama Prefectural University}
\affilabel{Author_6}{秋田県立大学システム科学技術学部}{Faculty of Systems Science and Technology, Akita Prefectural University}
\affilabel{Author_7}{大阪工業大学情報科学部}{Faculty of Information Science and Technology, Osaka Institute of Technology}
\affilabel{Author_8}{電気通信大学大学院情報システム学研究科}{Graduate School of Information Systems, The University of Electoro-Comunications}


\begin{document}
\maketitle


\section{はじめに}

\begin{table}[b]
\caption{2014年度 代ゼミセンター模試（第1回）に対する得点と偏差値}
\label{tab:intro:2014}
\input{05table01.txt}
\end{table}

「ロボットは東大に入れるか」（以下，「東ロボ」）は国立情報学研究所を中心とする長期プロジェクトである．
同プロジェクトは，AI技術の総合的ベンチマークとして大学入試試験問題に挑戦することを通じ，
自然言語処理を含む種々の知的情報処理技術の再統合および新たな課題の発見と解決を目指している．
プロジェクトの公式目標は2016年度に大学入試センター試験において高得点を挙げ，2021年度に東大2次試験合格レベルに
達することである．
プロジェクトでは，2016年度のセンター試験「受験」に至るまでの中間評価の一つとして，
2013年度，2014年度の2回に渡り代々木ゼミナール主催の全国センター模試（以下，代ゼミセンター模試）を
用いた各科目の解答システムの評価を行い，その結果を公表した．
\TABREF{tab:intro:2014}に2014年度の各科目の得点と偏差値を示す\footnote{
    数学・物理に関しては他の科目と異なり付加情報を含む入力に対する結果である．
    詳細はそれぞれに関する節を参照のこと．
    国語は，未着手の漢文を除いた現代文・古文の計150点に関する偏差値を示す．}．
2013年度の結果については文献\cite{arai}を参照されたい．

大学入試試験問題は志願者の知的能力を客観的に測定することを目的として設計されたデータであり，
通常ただ1回の試験によって，かつ，受験者間での公平性を担保しながら測定を行うために入念な検討が加えられている．
この点で，入試試験問題は言語処理を含む知的情報処理技術の総合的ベンチマークとして恰好の素材であるといえる．
特に，その大部分が選択式問題からなるセンター試験形式のテストは，ごく単純な表層的手がかりのみでは正解できないように
設計されていると考えられ，現在70\%から90\%の精度に留まっている種々の言語処理技術をより信頼性高く頑健なものへと
導くためのガイドラインとして好適である．
さらに，模試・入試によるシステムの性能測定結果は人間の受験生の正答率や誤りの傾向と直接比較することが可能である．
センター試験は毎年約50万人が受験し，予備校によるセンター試験模試も数千から数万人規模の参加者を集める．
このような大規模なサンプルから得られた「普通の人」「典型的な人」の像とシステムとの比較は，
人によるアノテーションに対する再現率に基づく通常の性能測定とは異なる達成度の指標となっている．

代ゼミセンター模試による2014年度の評価では，英語・国語・世界史Bで受験者平均を上回る得点を獲得するなど，
大きな成果があった一方で，その得点に端的に現れているように，残された課題も大きい．
本稿では，代ゼミセンター模試およびその過去問を主たる評価データとして各科目の解答システムのエラーを分析し，
各科目における今後の課題を明らかにするとともに，「普通の人」と比較した際の各科目・問題タイプにおける達成度に
関してひとつの見取り図を与えることを目指す．
「東ロボ」プロジェクトのひとつの特徴は，多様な科目・課題に並行的に取り組むことであり，
様々な課題に対する結果を通じて，現在のNLP/AI諸技術の達成度を可能な限り通覧することは
プロジェクト全体の目的でもある．
このため，本稿では問題タイプ毎のエラーに対する分析は主として解決への糸口となる傾向の分析までにとどめ，
多数の科目・問題タイプについてそのエラー傾向と今後の課題を示すことを主眼とした．
以下では，まず知的情報処理課題としてのセンター模試タスクの概要をまとめたのち，
英語，国語，数学，物理，日本史・世界史の各科目について分析結果を述べる．



\section{センター試験タスクの概要}

\TABREF{tab:overview:risha}，\TABREF{tab:overview:eikoku}に，
2014年度代ゼミセンター模試（第1回）の世界史B・日本史B・数学（I+A，II+Bの合計）・物理，国語・英語を対象とした問題分類の結果を示す．
表内の各数字は，各カテゴリに分類された問題数およびその割合（カッコ内）である．
ここでは，一つの問題が複数のカテゴリに属する場合も許している．
これらの分類は解答タイプ（解答形式および解答内容の意味的カテゴリ）と解答に必要となる知識のタイプに関するアノテーション\cite{MiyaoKawazoe2013IJCNLP}
から得られたものであるが，読みやすくするために，表中では各カテゴリにそれらのアノテーションを要約・再解釈したラベルを与えている．

\begin{table}[t]
\caption{問題分類（社会科目・理数系科目）}
\label{tab:overview:risha}
\input{05table02.txt}
\end{table}
\begin{table}[t]
\caption{問題分類（国語・英語）}
\label{tab:overview:eikoku}
\input{05table03.txt}
\end{table}

\TABREF{tab:overview:risha}に示されるように，社会科目ではほとんどの問題が教科書内の知識を正しく記憶しているかどうかを問う問題であり，
形式は真偽判定型とfactoid質問型が多い．
問題中で与えられた資料文に関する読解問題や一般常識の関わる問題の割合は低いことから，大多数の問題に対しては外部の知識源を適切に参照し，
要求される解答形式に合わせた出力へ加工することで解答できる可能性が示唆される．
すなわち，現行の質問応答および検索をベースとした方法によって解ける可能性がある．
他方，数学・物理に関しては，問題のすべてが「分野固有の推論」に分類されている．
すなわち，単に知識源を参照するだけでは解答できず，数理的演繹やオントロジーに基づく推論などが必要となることが示唆される．
特に，数学・物理の問題のほとんどが数値ないし数式を答える問題であるため，数値計算ないし数式処理は必須である．
言語処理と数値・数式処理の統合は，分野横断型の研究として興味深い．
数学・物理の間の違いとして，画像・図表の理解を必要とする問題の割合の差が見て取れる．
数学では数表および箱ひげ図の理解を要する大問が1題あったが，それ以外の図に関しては
必要な情報が全て問題文で与えられており，解答する上で図を理解する必要はない．
いっぽう物理では，問題文のみでは物理的状況を理解するのが困難で，画像の理解を必要とすると思われる問題がおよそ7割を占める．
このため，物理の解答システムでは将来的に画像理解と言語理解の融合が必要であると考えられる．


英語と国語の問題分類は，他科目とは大きく異なっている．
英語に関する節で述べるように，語彙知識，文法的知識を問う問題は，現在の言語処理技術の射程内のものが多数ある．
しかし，英語・国語で大きな割合を占める読解問題は，これを研究課題とする取り組みが近年開始されたものの\cite{Penas2011a,Penas2011b}，
言語処理・知的情報処理課題としての定式化を含め，未解決の部分が多いタイプの問題である．
さらに，英語問題には一般常識を問う問題，
新聞広告や手書きの問診票など独特の形式をもつ文書の理解を問う問題，
画像理解（絵の説明として適切なものを選ぶ問題など）などが含まれるが，これらは一部に研究課題として非常に難しいものを含んでいる．
この点で，少なくとも現時点では，英語で満点に近い高得点を得ることは困難であると考えられる．



\section{英語問題のエラー分析}

\subsection{はじめに}
\label{sec:eigo:introduction}

本節では，東ロボ英語チームの開発によるいくつかの解答システムのエラーを分析した結果について述べる．
特に，代ゼミセンター模試の6回分（2012第1回，2013第1回〜第4回，2014第1回）を中心に分析を行った．

\begin{table}[b]
\caption{代ゼミセンター模試 2014 英語の問題構成}
\label{tab:eigo:mondai}
\input{05table04.txt}
\end{table}

\TABREF{tab:eigo:mondai}に代ゼミセンター模試2014第1回の問題構成を示す．
今回の分析は現状一定の精度で解けている短文問題（すなわち，大問1から大問3）のみについて行っている．
また，短文問題の中で文脈に合わない文を選ぶという問題 (3B) については，
過去問に例が少なかったため未着手であり，分析対象としては触れていない．
また，意見要旨把握問題については，会話文完成問題と同じ解き方で解いているため，会話文完成問題の分析をもって，
この問題の分析とする．
点数にして約半分を占める読解問題に対しては，現在のシステム正答率がチャンスレベルに近いため，
エラー分析の対象とはしなかった．読解問題に関する見通しについては本節の最後で述べる．
なお，2014年度の代ゼミセンター模試の英語問題を解いた手法については，文献\cite{eigo}に詳述されているので参照されたい．


\subsection{発音・アクセント問題}
\label{sec:eigo:1ab}

ここ数年の発音・アクセント問題は発音箇所が異なる・同じ箇所や，アクセント位置が異なる・同じ箇所を選択す
る問題であり，音声認識用の辞書を用いることですべて解くことが出来ている．しかし，1987年から2009年まで
のセンター試験の発音アクセント問題は28/85（約32\%）しか解くことができていない．これらの問題は，
文中で強勢される単語を問うものが多く，
文脈を理解しないと解くことができない．

\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f1.eps}
\end{center}
\caption{強勢問題の例}
\label{fig:eigo:1ab} 
\end{figure}
\begin{table}[b]
\caption{発音・アクセント問題の分類}
\label{tab:eigo:1ab} 
\input{05table05.txt}
\end{table}

\FIGREF{fig:eigo:1ab}は強勢の問題の例である．下線部の単語のうち，強勢が置かれるものをそれぞれ選択す
る．(1)の下線部では，worse が正解となるが，worse を強く読むかどうかは文脈に依存する．

1999年までの発音・アクセント問題で解けていない問題を分析したものを\TABREF{tab:eigo:1ab}に示す．辞書やプログ
ラムの整備などにより対応できるものを短期に対応できる問題（18問），それ以外を長期間必要な問題（33問）
と分類した．また，例年であれば発音・アクセント問題が出現する箇所にそれ以外の問題が出題されるケースがあり，これらは6問あった．強勢の問題は近年
コーパスベースの手法で取り組んでいる文献\cite{kyosei}もあるが，まだ取り組みが少ないのが現状である．


\subsection{文法・語法・語彙問題}
\label{sec:eigo:2a}

文法・語法・語彙問題とは，文中の空欄に最もふさわしい語句を4つの候補の中から選ぶ問題である．代ゼミセン
ター模試の過去6回分には，このタイプの問題が合わせて60問出題されている．英語チームでは，単語N-gram を用いて，
最も確率が高くなる候補を選ぶ方法を用いた．本手法では，47問解くことができた．解くことが出来なかった問題の要因は
\TABREF{tab:eigo:grammar}の通りであった．

\begin{table}[b]
\caption{文法・語法・語彙問題のエラー要因\label{tab:eigo:grammar}}
\input{05table06.txt}
\end{table}

反実仮想のように，条件文に呼応する場合はそれを踏まえる必要があるが，N-gramではそれが捉えられていなかっ
た．また，複数文で前半部分を受けて後半の単語を選ぶ問題についても同様に答えられていない．遠い依存関係
はN-gram によって捉えにくいものであるが，今回の代ゼミセンター模試2014-1の2問については，
Dependency Language Model~\cite{deplm} に基づく手法で答えられることを確認した．
成句に関する問題は入試で頻出するが，新聞記事の出力分布からずれるために答えられていないと思われる．
関係代名詞の用法については，解くためには文法的な観点が必要と思われる．

今回の分析対象である60問で人間（受験生）とシステムの正答傾向に違いがあるかを分析した．
ここで，「人間の解答」として，受験生の選択した割合が最も高かったものを用いている．なお，人間は48問 (80\%) 正解している．
クロス表を作成したところ\TABREF{tab:eigo:bunpou:cross}の様になった．

\begin{table}[t]
\caption{人とシステムの正答傾向の比較（文法・語法・語彙問題）}
\label{tab:eigo:bunpou:cross}
\input{05table07.txt}
\end{table}
\begin{table}[t]
\caption{システムが正解し人間が不正解であった文法・語法・語彙問題の内容}
\label{tab:eigo:syshumcompare}
\input{05table08.txt}
\end{table}

システムと人間の両方が解けるものはある程度共通しているものの，それぞれ得意・不得意があることも分かる．
システムが正解することと，人間が正解することが独立であるか，本クロス表について
Fisher の正確確率検定を行ったところ $p=1$ であり人間・システムの正答の分布が
独立であることは棄却されなかった．
人間とシステムは異なる解き方をしており，正答・誤答の分布は独立であることが示唆される．

さらに60問の各設問について人間とシステムの選択肢の順序を求め，
代表的な順位相関係数であるSpearmanの$\rho$および Kendall の$\tau$の平均値を求めた．
ここで，人間の選択肢の順位とは選択した受験生の割合の順位であり，システム
の順序とは，N-gram確率によって得られる確率値の大きい順に並べたものである．その結果，$\rho$と$\tau$の
平均はそれぞれ0.07，0.06となり，ほぼ無相関であった．ここからも，人間とシステムは異なった解き方で問題を
解いていることが示唆される．

システムが正解し人間が不正解であった問題は10問であり，この内訳は
\TABREF{tab:eigo:syshumcompare}
の通りである．人間は英語の典型的
用法を知らないことで不正解になっているケースがほとんどであった．これらはシステムがデータ中心の解法により正解で
きるものである．また前置詞の用法も英語に慣れていないと難しく，受験生には解けなかったようである．

人間が正解しシステムが不正解であった11問，および，どちらも不正解だった2問(2013-1-A12,
2014-1-A14)は，システムが解けなかった問題として前掲した13問である．
\TABREF{tab:eigo:syshumcompare}と比較すると，
システムが正解・人が不正解であった問題は単語や成句・連語あるいは前置詞の選択など，
語彙的知識に関するものが多く，システムが不正解・人が正解であった問題は
意味的・文法的な整合性が関わるものが多いという傾向が見て取れる．


\subsection{語句整序完成問題}
\label{sec:eigo:2c}

語句整序完成問題とは，与えられた数個の単語を適切に並べ替えて，文法・意味的に
正しい文を完成させる問題である．我々は，文法・語法・語彙問題と同様にN-gram言語モデルを用いてこの問題に取り組んだ．
具体的には，単語列のすべての並びを列挙し，もっとも文としての確率が高いものを選ぶ手法を用いた．

分析対象とした代ゼミセンター模試過去問ではこのタイプの問題が18問あり，このうち，15問 (83\%) に対しシステムは正答することができた．正解でき
なかった3問についてはエラーの要因は\TABREF{tab:eigo:error:sort}の通りであった．

ここでの要因は，文法・語法・語彙問題とほぼ同様である．システムの正解率もほぼ同じであることか
ら，N-gramによって解くことのできる問題はおおよそ80\%であることが確認できる．

今回の分析対象である18問について，人間とシステムの正答傾向に違いがあるか分析した．
\TABREF{tab:eigo:cross:sort}はそのクロス表である．

\begin{table}[t]
\caption{語句整除完成問題のエラー要因}
\label{tab:eigo:error:sort}
\input{05table09.txt}
\end{table}
\begin{table}[t]
\caption{人とシステムの正答傾向の比較（語句整除完成問題）}
\label{tab:eigo:cross:sort}
\input{05table10.txt}
\end{table}

本クロス表について Fisher の正確確率検定を行ったところp値は0.06であり有意傾向にあった．これは，文法・
語法・語彙問題と異なるところであり，システムと人間はより近い解き方をしているのではないかと考察され
る．

人間が不正解でありシステムが正解したものは1問 (2012-1-A25-26) だった．
``all I could think about'' という構文が受験生にとっては難しいながら，
典型的なフレーズであり，システムにとってはN-gramで解ける問題だったことによる．


\subsection{会話文完成問題}
\label{sec:eigo:2b}

会話文完成問題は，二人の話者の会話の空所に適切な文を4つの選択肢から選び，
会話文を完成させる問題である．この問題を解くため，4つの選択肢の各場合に
ついて会話文の流れの自然さを推定し，最も自然な流れとなる選択肢を選ぶと
いう方法を用いた．会話文の流れの自然さは(a)発話意図（表明，評価など）の
流れの自然さと(b)感情極性（ポジティブかネガティブ）の流れの自然さから成
る．(a)はSwitchboard Dialog Act Corpus \cite{Jurafsky:97}から発話意図列
の識別モデルをCRFによって学習し，発話意図列の生起確率に基づいてスコアを
計算した．(b)は感情極性コーパス\cite{Pang+Lee:05a}からSVMにより識別モデ
ルを学習し，感情極性がポジティブあるいはネガティブである
スコアを計算した．それぞれのスコアの重み付き和を最終的なスコアとした．

エラー分析のため，代ゼミセンター6回分の問題について，会話中のすべての発
話および選択肢に対し，1名の評価者がアノテーションを行い，発話意図のラベ
ルと感情極性の度合を付与した．
アノテーションに基づき，(a), (b)のスコアを計算した．(a)は付
与された発話意図列のN-gram確率をコーパスから計算したものをスコアとした．
(b)は付与された感情極性の度合に基づいてスコアを計算した．
コーパスから学習したモデルに基づいてスコアを算出する場合（アノテーショ
ン無し）とアノテーションに基づいてスコアを算出する場合（アノテーショ
ン有り）を比較し，正解率がどう変わるかを検証した．その結果を
\TABREF{tab:eigo:2b}に示す．

\begin{table}[b]
\caption{アノテーションの有無による会話文完成問題の正解率の変化}
\label{tab:eigo:2b}
\input{05table11.txt}
\end{table}

表において，発話意図のスコアと感情極性のスコアの両方を使う場合は，正解
率が最大となるように重みを調整した．
表から分かるように，感情極性に関して，アノテーション無しの方がアノテー
ション有りの場合よりも正解率が若干高い．
アノテーション無しの場合は，感情極性コーパスを使うことにより，ポジティ
ブ／ネガティブな文に現れる単語の出現確率を考慮してスコアを計算している
ことに対して，アノテーション有りの場合は，そのような単語の出現確率を精
密に考慮できないことが性能低下につながった可能性がある．本質的にアノテー
ション無しの方が性能が良いかどうかはより多くのデータを使って判断するこ
とが必要である．

本手法は発話意図のスコアと感情極性のスコアの重み付き和で最終的なスコア
を計算しているが，どちらのスコアを優先すべきかは問題による．実際，発話
意図のスコアと感情極性のスコアのいずれかが最大となる選択肢を選ぶことが
できたすると，アノテーション無しでは18問中13問，アノテーション有りでは
18問中10問が正解となる．発話意図と感情極性のスコアのいずれを使って問題
を解くべきかを適切に判断することは今後の課題の一つである．

分析に用いた18問に対する受験生の平均正答率は62.2\%であった．
システムの正答率8/18 (=44.4\%)はそれより低いものの，チャンスレベルである25\%との差は
ほぼ有意であった（$p=0.06$，二項検定）．


\subsection{未知語（句）語義推測問題}
\label{sec:eigo:3a}

この問題は，出現頻度が低く一般にはあまり知られていないような文章中の単語またはフレーズについて語義を
推定し，与えられた選択肢の中から最も意味の近い語義を選択する問題である．今回，word2vec \cite{Mikolov13}を用い，未知の
語句と選択肢のベクトルをそれぞれ求め，コサイン類似度の高いものを選択する手法を用いた．なお，未知の単
語が慣用句の場合は，イディオム辞書によって事前に語釈文に置き換えた上でベクトルを算出している．

過去5回の代ゼミセンター模試の全12問について，9問 (75\%) 解くことができた．
これは同じ問題に対する受験生の平均正答率48\%を上回っている．
正解できなかった3つの問題の内訳を表\ref{tab:eigo:3a}に示す．
二つはイディオム辞書の不備に依る．今回は，Wiktionaryから作成したイディオム辞
書を用いたが，そのカバレッジが低かった．これらはよりカバレッジの大きいOxford English Dictionaryを用い
ることで解決できることが分かった．もう一つは単語``cognate''であるが，単語であっても，辞書の語釈文によって置き
換えてベクトルを算出することでこちらも解けることが分かった．すなわち，単語，イディオムについて，置き
換える・置き換えないという操作が正しくできれば，本問題については解くことができると言える．

\begin{table}[b]
\caption{未知語（句）語彙推測問題のエラー内訳}
\label{tab:eigo:3a} 
\input{05table12.txt}
\end{table}


\subsection{英語：まとめと今後の課題}
\label{sec:eigo:summary}

本稿では，東ロボプロジェクトにおいて英語チームが英語問題を解いたときのエラーを分析した結果について述べた．
長文読解問題はまだチャンスレベルに近い正答率であるため，今回は分析対象としなかったが，
今後解答できるようになっていくにつれ，エラーを分析していく予定である．

今回の分析対象とした短文問題に比べて，長文読解問題ソルバー開発の進行が遅れている理由としては，
問題内容自体の複雑さに加え以下のような理由が挙げられる．
まず，長文読解問題の約半数は，図表ないしイラストを含む問題，あるいは広告・カルテなど特殊なレイアウトを
含む実用文書を題材とする問題である．
これらの問題に対しては，テキスト処理に加えて画像理解や文書構造の理解が必要とされる．
特に自然画像ではないイラストの理解はそれ自体が未開拓の研究領域である．
これらの付加要素のうち表に関しては，情報抽出源として多くの研究があるものの，
テキスト理解と表の意味理解が複合した課題に関する取組は近年始まったばかりである\cite{pasupat2015compositional}．

多くの長文読解問題は，形式的には本文と選択肢の間の含意関係認識課題として捉えることが可能である．
しかし，Bag-of-words/phrases/dependencies など，表層に近い表現によるテキスト間類似性を用いた
手法と state-of-the-art との差が比較的小さい現在の含意関係認識手法の技術水準では，
英語読解問題で前提とされる種々の常識的知識を深い意味構造のレベルで取り扱うような手法がすぐに実現するとは考えにくく，
表層に近い表現によるテキスト間類似性定義をベースとして，英語読解問題の特性に見合った改良を
加えていく方向が有効であると思われる．
これに対し，図・表・イラストなどを含む問題は，数量の取扱いを始め，単純なテキスト間類似性を超える
推論を要することが多い点でも難しい課題であると言える．

なお，図などの付加要素を含まないタイプの長文読解問題において，特に問題だと考えている課題は3つある．
意味を反転させるような表現の扱い，共参照解析，メタ言語（文章自体への言及）である．
また，過去の代ゼミセンター模試の長文（特に大問6の論述に関する問題）を分析したところ，
選択肢に関連のある一文を長文から抽出できれば解ける問題が25問中11問あったが，
その他は複数の文の統合が必要なものであった．
選択肢に関連する一文を長文から抽出する課題はそれ自体が今後の研究課題である\cite{CLEF13Li}が，
それに加え，要約技術の適用や文の統合といった技術が必要になってくると思われる．


\vspace{0.5\Cvs}
\section{国語 評論問題のエラー分析}

\vspace{0.5\Cvs}
\subsection{センター試験『国語』評論傍線部問題}

本節では，主に大学入試センター試験『国語』評論の{\bf 傍線部問題}と呼ばれる問題を取り扱う．
傍線部問題の具体例を\FIGREF{fig:kokugo:up_example}に示す．
この図に示すように，傍線部問題は，何らかの評論から抜き出された文章（本文）を読んだ上で
設問文を読み，5つの選択肢のうちから正解の選択肢を1つ選ぶという選択式の問題である
（紙面の都合上，\FIGREF{fig:kokugo:up_example}には2つしか選択肢を記載していない）．
表 13 に示すように，傍線部問題は，センター試験『国語』評論の配点の約2/3を占めている．
紙幅の都合で取り上げなかったこれ以外の問題に関しては本節の最後で述べる．

\begin{figure}[t]
\begin{center}
\includegraphics{23-1ia5f2.eps}
\end{center}
\caption{評論傍線部問題の例（2007年本試験 第1問の問2）}
\label{fig:kokugo:up_example}
\end{figure}


\subsection{傍線部問題の解法}

東ロボ国語チームは，傍線部問題の自動解法として，
これまでに{\bf 本文照合法}\cite{BaseMethod}，
およびその一部を拡張した{\bf 節境界法}\cite{CLMethod}を提案，実装した．
本節ではこれらの解法について概説する．


\subsubsection{本文照合法}

本文照合法は，
\begin{itemize}
\item 正解選択肢を選ぶ根拠は，本文中に存在する\cite{Funaguchi,Itano}
\item 意味的に似ているテキストは，表層的にも似ていることが多い
\end{itemize}
という考え方（仮説）に基づく解法である．
具体的には，次のような方法で傍線部問題を解く．
\begin{enumerate}
\item {\bf 入力：} 本文，設問，選択肢集合を入力する．
\item {\bf 照合領域の決定：} 選択肢と照合する本文の一部（照合領域）を定める．
  照合領域は，本文中の傍線部を中心とした連続領域とする．
\item {\bf 選択肢の事前選抜：} 考慮の対象外とする選択肢を除外する．
  具体的には，ある選択肢について，自分以外の選択肢との文字の一致率の
  平均値が最も小さい選択肢を除外する．
\item {\bf 照合：} 考慮の対象とする選択肢をそれぞれ照合領域と比較し，照合スコアを求める．
  照合スコアには，照合領域とその選択肢との間の共通する要素の割合
  （オーバーラップ率\cite{Hattori2013}）を用いる．
\item {\bf 出力：} 照合スコアの最も高い選択肢を解答として出力する．
\end{enumerate}

この本文照合法には，以下の3つのパラメータが存在する．
\begin{itemize}
\item 照合領域として本文のどの範囲を選ぶか
\item 照合スコアをどのような単位で計算するか（何のオーバーラップ率をスコアとするか）
\item 選択肢の事前選抜を行うか
\end{itemize}
これらのパラメータは，以降で述べる節境界法にも共通する．


\subsubsection{節境界法}

節境界法は，長い文を複数のまとまりに区切るという戦略に基づき，
本文照合法の一部を拡張した解法である．
具体的には，本文照合法の照合ステップにおいて，
照合領域と選択肢に節境界検出に基づいた節分割を行い，
その結果を照合スコアの計算に利用する．
節は「述語を中心としたまとまり」\cite{KisoNihongo}と定義される文法単位であり，
おおよそ述語項構造に対応する．

節境界検出には，節境界検出プログラムRainbow \cite{Rainbow}を用いる．
Rainbowは，文の節境界の位置を検出し，節の種類のラベル（節ラベル）を付与するプログラムである．
Rainbowによって付与された節境界で区切られた部分を節とみなして，節分割を
行う\footnote{厳密には本来の節の定義からは外れる場合がある．}．

節境界法では，照合スコアを以下のような方法で計算する．
\begin{description}
\item[\textmd{Step1}] 照合領域$t$と選択肢$x$に節境界検出を行い，
  それぞれ節の集合$T$, $X$に変換する．
\item[\textmd{Step2}] $T$と$X$を用いて選択肢$x$の照合スコアを計算する．
  具体的には，$X$内の各節$c_x \in X$のスコアの平均値を，選択肢$x$のスコアとする．
  節$c_x$のスコアは，$c_x$と，$T$内の各節$c_t \in T$との類似度の最大値とする．
\end{description}

節同士の類似度は，節同士の共通する要素の割合（オーバーラップ率\cite{Hattori2013}）
と，2つの節の節ラベルが一致する場合のボーナスの和と定義する．


\subsection{評価実験}

センター試験の過去問および代ゼミセンター模試過去問（以下，代ゼミ模試とよぶ）
を用いて，本文照合法および節境界法の評価を行った．
センター過去問は10回分，代ゼミ模試は5回分の試験データを使用した．
傍線部問題の総数は，センター過去問が40問，代ゼミ模試が20問である．


\subsubsection{実験結果}

本文照合法ソルバーと節境界法ソルバーを，
センター過去問，および代ゼミ模試に適用した結果（正解数）を\TABREF{tab:kokugo:result}に示す．
この表のP-$m$-$n$は，照合領域（本文の傍線部の前後何段落を照合領域とするか）を表し，
$C^1$や$L$などは，オーバーラップ率として何の一致率を用いるかの単位を表す（たとえば$C^1$は
文字unigramを用いることを表す）．
また，選択肢の事前選抜を行う場合をps，行わない場合をnonで表す．これらのパラメータ
の組み合わせ56通りについて，正解数を調査した．

\begin{table}[b]
\caption{代ゼミセンター試験 2014 国語の問題構成}
\label{tab:kokugo:mondai}
\input{05table13.txt}
\end{table}
\begin{table}[b]
\hangcaption{センター過去問と代ゼミ模試に対する正解数（本文照合法／節境界法，上段がセンター40問，下段が代ゼミ模試20問に対する結果）}
\label{tab:kokugo:result}
\input{05table14.txt}
\end{table}

\TABREF{tab:kokugo:result}では，本文照合法ソルバー，節境界法ソルバーの
正解数を，この順に斜線で区切って示している．また，上段にはセンター過去問の正解数，
下段には代ゼミ模試の正解数を示している．
半数以上の問題に正解した場合の正解数は，ボールド体で示している．

\TABREF{tab:kokugo:result}を見ると，センター試験と代ゼミ模試の問題は，性質が異なる
ということがわかる．
センター過去問に関しては，多くのパラメータ(45/56)において，節境界法の正解数が
本文照合法の正解数以上となったのに対し，
代ゼミ模試に関しては，56通りすべてのパラメータにおいて，本文照合法の
正解数が節境界法の正解数以上となった．
また，本文照合法では2つの問題データ間で正解率があまり変わらないのに対し，
節境界法では全体的にセンター過去問よりも代ゼミ模試の正解率の方が低い．

ソルバーは，解答を出力する際，照合スコアの高い順に選択肢番号を出力するが，このとき，
スコア上位に正解が含まれた設問数を表\ref{tab:kokugo:rank_in}に示す．
パラメータは，センター過去問または代ゼミ模試で，比較的成績のよいものを3つ選んだ．
R@$n$は，スコア順位で$n$位までに正解が含まれたことを表す．
（節），（本）はそれぞれ節境界法，本文照合法を表す．

\begin{table}[t]
\caption{ソルバー出力の上位に正解が含まれる設問数}
\label{tab:kokugo:rank_in}
\input{05table15.txt}
\end{table}

\TABREF{tab:kokugo:rank_in}を見ると，ほとんどの問題で正解選択肢が
選択肢5つのうちの上位3位までには入ることがわかる．
スコア上位の選択肢に対して，本文と合致しない部分の検出ができれば，
より正解数が向上することが期待できる．


\subsubsection{典型的な難問例}

本文照合法，および節境界法は，いずれも文字列の表層的類似度を照合スコアに用いているため，
本文の解答根拠部分と選択肢との間で表層的に全く異なる言い回しが用いられているような
問題には正解できない．
センター過去問の40問の傍線部問題を調査したところ，そのような問題は多く存在した．
その中でも，以下の3つのタイプの問題は，ソルバーにとって特に難問であると考えられる．
\begin{itemize}
\item[A] 本文で抽象的に述べている内容を具体的に述べた選択肢を選ぶ設問（40問中2問）
\item[B] 本文で具体的に述べている内容を抽象的に述べた選択肢を選ぶ設問（40問中4問）
\item[C] 本文と選択肢の抽象度は同じだが，選択肢が本文の内容を，句以上の大きな単位で
    全面的に言い換えている設問（40問中16問）
\end{itemize}
タイプAの設問の例を\FIGREF{fig:kokugo:difficultA}に，タイプCの設問の例を\FIGREF{fig:kokugo:difficult}に示す．

\begin{figure}[t]
\begin{center}
\includegraphics{23-1ia5f3.eps}
\end{center}
\caption{タイプAの難問の例（2001年本試験 第1問の問2）}
\label{fig:kokugo:difficultA}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{23-1ia5f4.eps}
\end{center}
\caption{タイプCの難問の例（2005年本試験 第1問の問4）}
\label{fig:kokugo:difficult}
\end{figure}

タイプAおよびBの設問で求められる抽象と具体を結びつける能力は，
抽象語と具体例を結びつける辞書的なデータの作成や，
多数の抽象-具体テキストペアの蓄積が可能であるような，
ごく限定的な主題を除き，現在の言語処理・人工知能技術の射程外であろう．
タイプCの設問は，形式的には言い換え認識あるいは含意関係認識に近い問題であるものの，
最先端の手法と表層的類似度に基づく手法との差が小さい現在の技術水準\cite{RITE2}では，
やはり解決不可能な問題が多いと考えられる．


\subsubsection{人間の解答との比較}

代ゼミから提供されたデータを用いて，
ソルバーの解答傾向が人間（受験生）のそれと似ているかの比較を行った．
代ゼミ模試20問において，ソルバーの解答結果と，受験生の解答番号別マーク率を比較した．
受験生の選んだ選択肢$n$位までにソルバーの選んだ選択肢が含まれる設問数を
\TABREF{tab:kokugo:human1}に示す．この表のR@$n$は，受験生のマーク率順位の$n$位までに
ソルバー出力が含まれたことを表す．

\TABREF{tab:kokugo:human1}を見ると，節境界法に比べて，本文照合法の解答傾向の方が
受験生と似ている．
代ゼミ模試において節境界法より本文照合法の方が好成績であったことを考慮すると，
代ゼミ模試においては，受験生と解答傾向が似ているソルバーの方が，正解率が高くなると考えられる．

\begin{table}[t]
\caption{受験生の選んだ選択肢上位にソルバー出力が含まれる設問数}
\label{tab:kokugo:human1}
\input{05table16.txt}
\end{table}
\begin{table}[t]
\caption{人とシステムの正答傾向の比較（国語 評論傍線部問題）}
\label{tab:kokugo:cross}
\input{05table17.txt}
\end{table}

代ゼミ模試20問に対する，ソルバー（本文照合法P-0-0, $C^1$, ps）と受験生のマーク率1位の解答のクロス表は
\TABREF{tab:kokugo:cross}のようになった：
クロス表では，ソルバーが正解した問題では受験生も正解が多い傾向があるように見える．
しかし，Fisher の正確確率検定の結果は$p = 0.34$で，ソルバーと受験生の正答の分布が
独立であることは棄却できなかった．


\subsection{国語：まとめと今後の課題}

本節では，東ロボ国語チームが提案，実装した
評論傍線部問題の自動解法とその成績，および解答結果の分析について述べた．
実装した本文照合法，節境界法は，いずれも文字列の表層的類似度を用いる解法であり，
本質的に正解できない難問もあるものの，
ソルバーは，適切なパラメータさえ選べば，多くの問題に対して
スコア順位で上位に正解選択肢を出力できた．

現在のソルバーは，全ての傍線部問題に対して同じパラメータ，同じ解法で解答するが，
今後は，問題を換言型，理由型などいくつかの型に分類し，より適したパラメータ，
特徴を用いて解く必要があると考えられる．
たとえば，傍線部の理由を問う理由型の問題の場合，本文傍線部周辺の比較的狭い領域の，
因果関係を表す表現などが手がかりとなるであろう．
また，評論には例示や引用がしばしば用いられるため，
本文および選択肢を，本質的に重要な部分とそうでない部分に分け，
重要な部分のみで照合を行うようなアプローチも有用であると考えられる．

傍線部問題は小説を本文とする第 2 問でも大きなウェイトを占める．
小説の傍線部問題は形式的には評論のそれと類似しているものの，
本文には直接記述されない登場人物の感情・思考などが問われる問題が多く，
評論と同様の表層的類似度を用いた手法ではチャンスレベルと大差ない
正解率となることが分かっている\cite{BaseMethod}．
テキストから書き手の感情（極性）を推定する研究はこれまで非常に多くあるが，
小説の読解問題として問われるような細かな感情タイプを表層的手がかりから
得る技術の実現可能性は今のところ明らかでない．

漢字（評論）の問題は辞書を用いた手法で概ね十分な精度が出ている
（2013年度，2014年度とも代ゼミセンター模試で全問正解）．
語句の意味（小説）に関する問題に関しては，通常の語義を問う問題では
国語辞書を用いた手法で高い精度が得られている．
しかし，語句の意味に関する問題では，本文で比喩的に使われている語句の意味を
文脈に即して選ばせるタイプの問題がしばしば出題され，これらに対する正解率が低い．
このタイプの問題の解決には，語句が比喩的に用いられているか否かの識別とともに
比喩の内容を本文に即して解釈することが必要であり，特に後者は難しい課題である．

古文（第 3 問）の解釈問題に対しては，古文-現代語対訳コーパスから学習した
統計的機械翻訳モデルを利用し，本文を現代語訳した上で評論の傍線部問題と
同様の本文と選択肢の間の表層的類似度を用いた手法で50\%程度の正解率を得ている．
BLEUによる訳質評価および目視による主観評価の結果から，古文-現代文翻訳の
品質には向上の余地が認められる．
しかし一方で，機械翻訳の代わりに人手による参照訳を用いた比較実験では
正答率の向上が見られず，通常の意味での翻訳品質の向上は正解率の向上に
寄与しないことが示唆される．
翻訳品質が直接正答率に結び付かない要因としては，
小説の傍線部問題と同様に，直接記述されない心情を問う問題が多いことに加え，
現在用いている単純な表層的類似度では，例えば重要語句「をかし」の解釈などといった，
問題のポイントとなる部分がすくい取れていないことが考えられる．

評論・小説および古文の各大問の最後では，
表現の特徴・効果や議論の構成について問うタイプの問題が出題されるのが通例である．
しかし，これらの問題に関しては，文章ジャンルを問わず，ほぼ手つかずの状態にある．
表現の特徴・効果の理解は，現在の言語処理の主要な目標である文章の
意味そのものの理解を超える課題であり，当面，解決の見込みはないだろう．
議論の構成に関する問題は，自動要約や修辞構造解析など現在の言語処理に
おける取組みと重なり合う部分もあるものの，
抽出的でなく抽象度の高い要約を選択する，あるいは，
修辞構造の効果を内容に即して説明する選択肢を選ぶ，など，
既存の要素技術の組み合わせではカバーできない課題が多い．

最後に，漢文の解釈問題に関しては古文と同様に現代日本語訳を経由して，
翻訳された本文と選択肢との類似度に基づき解答する手法が考えられるが，
入手可能な対訳リソースが無いため手つかずの状態になっている．


\def\typename#1{}

\section{数学問題のエラー分析}
\label{sec:suugaku}

数学では，問題文からの情報抽出やデータベースからの情報検索のみで解答が得られる問題は例外的であり，
一般には計算や推論などの数理的操作によって解を導く必要がある．
このため，問題文を分析し，数理的操作の入力となる何らかの形式表現を得るステップが不可欠となる．
この中間的な形式表現としては，答えを直接導く計算式から論理式による問題全体の意味表現まで様々なものが考えられ，
言語処理部分でのアプローチも，ターゲットとなる形式表現の枠組みに応じ種々の手法があり得る．
適切な形式表現の枠組みを選ぶにあたって，まず考慮すべき点として，想定する問題の定型性が挙げられる．
例えば，Kushmanら\cite{Kushman2014}は対象とする問題を連立一次方程式で表現される代数の文章題に限定することで，
言語処理部分を問題テキスト中の名詞および数量と方程式中の変数および係数とを対応付ける学習問題に帰着している．
我々は多様な問題を同一のシステムでカバーすることを目的として論理式による表現を採用し，
文法主導の翻訳によって問題文から形式表現を得るアプローチを選択した．

\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f5.eps}
\end{center}
\caption{数学解答システムの概要\label{fig:mathoverview}}
\end{figure}

\FIGREF{fig:mathoverview}に示すように，解答システムは言語理解部と自動演繹部，および両者をつなぐ
意味表現の書き換え処理部からなる．
言語理解部の中心は組合せ範疇文法 (Combinatory Categorial Grammar, CCG) \cite{steedman2001syntactic,Bekki2010}による構文・意味解析である．
CCGによって導出された各文に対する意味表現は，共参照解析および文間関係の解析を経て，
問題テキスト全体に対応する意味表現へと合成される．

言語理解部の各処理コンポーネントは現在開発中の段階にある．
このため，代ゼミ模試による中間評価では，(1) 問題文中の数式部分に対する意味表現，(2) 文節間係り受け関係，(3) 共参照関係，(4) 文間の論理的関係，および (5) 評価時点のCCG辞書に含まれていなかった単語・語義，の5種のアノテーションを施した問題文を入力とした．
問題の意味表示は，これらのアノテーションを制約としてCCG導出木を探索し，導出木と文間の論理関係に沿って辞書中の単語の意味表示を合成することで半自動的に得た．
よって，模試による評価結果は，曖昧性解消処理および辞書の被覆率に関し理想化した場合の性能の上限値として解釈すべきものである．
手法および入力アノテーションの詳細については，文献\cite{Matsuzaki2013IJCNLP,Matsuzaki2014AAAI}を参照されたい．
今回，入力アノテーションで代替した処理に関する考察および見通しについては本節末で述べる．

\begin{table}[t]
\caption{数学(I+A, II+B)の失点要因}
\label{tab:suugaku:errortype}
\input{05table18.txt}
\end{table}

\TABREF{tab:suugaku:errortype}は，2014年度代ゼミ模試の「数学I+A」および「数学II+B」における失点105点の原因の内訳である．
以下では，アノテーションによって理想化された条件でも残るエラーのうち最も多くを占める2要因である，
「表現の冗長性による計算量の爆発」と
「行為・操作結果の表現」に関する問題について主として述べる．
これら以外で，言語処理に関係する主要な要因としては，確率・統計に関する問題に対して，
意味表現の設計を含め言語処理部分が未着手の状態であったことが挙げられる．
これは，確率・統計の問題では「ボールを取り出す／戻す／テーブルに置く」「サイコロを用いてゲームをする」等々，
あらかじめ形式的な定義を与えることが難しい要素が頻出するため，
本節で示した問題の論理表示を経由する形式的なアプローチはなじまないと考えたためである．
これとは異なるアプローチによる確率問題への取り組みについては別稿\cite{Kamiya2015}を参照されたい．


\subsection{意味表現の冗長性}

文法主導の方法で構成的に導出した意味表現は，非常に冗長になる傾向がある．
例として，「線分」という一般名詞を考えてみる．
「線分」に対応する意味表現は，あるモノが線分であることを表す一項述語（$\text{segment}(\cdot)$とする）であると考えるのが一般的である．
このとき，単語「線分」の一般的な用例に従い，述語$\text{segment}(\cdot)$は，縮退したケースすなわち両端が一致した線分（つまり一点）を除外するよう定義されるべきである．
この非縮退条件は，どのような文脈においても単語「線分」の翻訳が妥当なものとなるために必要である．

しかし，例えば「点(0,0)と点(1,1)を両端とする線分$L$」といったフレーズのように，非縮退条件は非常にしばしば文脈によって含意される．
左記のフレーズの場合，その形式表現は述語$\text{segment}(\cdot)$の定義から，おおむね「$L$は(0,0)と(1,1)を通る直線上で(0,0)と(1,1)の間にある点の集合で，
かつ点(0,0)と点(1,1)は異なる点である」という内容となり，「かつ」以下の部分が冗長である．
この例では，冗長な部分はそれ自体で自明に真であるが，一般には問題文中に現れるいくつかの条件を総合したときに
はじめて非縮退条件が満たされていることが分かる．
このため，自動演繹の過程では，問題を解く上で本質的な演繹と，冗長な非縮退条件が実際に成立していることの証明に
あたる非本質的な演繹が入り混じった形で行われることになり，演繹の計算コストが増大する．

ここまでは非縮退条件を例として説明したが，その他にも等号関係の伝播による冗長な表現 ($a=c \Leftrightarrow \exists b(a=b \wedge b=c)$) や
一般性を失う事なく除去できる対称性など，意味表現の冗長化の原因は複数ある．
これらはいずれも語彙の意味定義の文脈独立性および意味合成の構成性に起因するもので，本手法における意味解析の原理の副作用というべきものである．
2014年度の代ゼミセンター模試で正解できなかった問題の内，得点にして27\%（28点）が，冗長かつ複雑な意味表現を対象とする
演繹処理が制限時間内に終了しなかったことによるものであった．

ここで計算量が問題となっているのは実閉体の式に対する限量子除去と呼ばれる処理\cite{qebook-e,IwaneYAY13}であり，
用いているアルゴリズムの最悪計算量は式中の変数の数の 2 重指数のオーダーである．
このため，言語処理の結果出力される式から不要な変数を除去することは極めて重要となるが，
一方で，数式処理によってこれを実現する一般的な手法は存在しない（であろう）ことが分かる．
よって，式の冗長性の解決へ向けては，条件の対称性など問題の数理的特徴を利用した発見的手法とともに，
文法および意味合成手続きの特徴を考慮した，言語解析からの出力に特有の冗長性を除去する手法の開発が必要であろう．


\subsection{行為結果の表現}

現在の我々の意味表現体系で扱えない例として，行為や操作の結果を表す表現を取り上げる．
2014年度センター模試数学I・Aでは
\begin{center}
    104 を素因数分解すると{\setlength{\fboxsep}{0cm}\fbox{ア}}$^3$$\cdot${\setlength{\fboxsep}{0cm}\fbox{イウ}}である．
\end{center}
という文を含む出題があったが，現在の我々の文法体系ではこの文に対する意味合成ができない．
同様の「X を Vすると Y となる」という構造を持つ文（以下，「行為結果文」と呼ぶ）は
他にも
\begin{itemize}
    \item $n$ を2乗すると4の倍数となる．
    \item 放物線$C$を$y$軸方向に1だけ平行移動すると放物線Dとなる．
    \item 円の半径を2倍にすると面積は4倍になる．
    \item 方程式 $x^2+2x+1=0$ の左辺を因数分解すると$(x+1)^2=0$となる．
\end{itemize}
など種々あり，数学テキストでは比較的よく現れるタイプの文である．
2014年度の代ゼミ模試では，数に対する操作の表現を含む問題で上記の理由によって正解しなかったものが20点分，
類似の理由で，数式に対する操作の表現を含む問題で正解しなかったものが18点分あり，
合わせて失点全体の36\%を占めていた．

動詞「なる」および接続助詞「と」の通常の用法も考慮すると，
行為結果文「X を Vすると Yとなる」の
意味表現としてもっとも表層構造に忠実なのは以下のような内容のものだろう：
\begin{enumerate}
    \item 行為Vの前の世界$W_1$と行為後の世界$W_2$には，ともにモノXが存在する．そして，
    \item 行為Vの結果モノXの性質は変化し，行為後の世界$W_2$ではモノXとモノYは一致する，あるいはモノXは$W_2$では性質Yを満たす．
\end{enumerate}
ここでは行為Vの前・後における世界の変化を捉えるために，
ある種の時間の概念（ないし複数世界間の推移）が意味表示の体系に持ち込まれている．


しかし，実際に問題を解くために上記のような行為結果文から読み取る必要がある意味内容は，
通常の述語論理の枠組みで十分表現可能である．
例えば，上の箇条書きの最初に例に対しては「$n^2$は4で割り切れる」という表現で十分である．
また，明示的に時間の推移を表す「点$P$は速度$v$で動き，時刻$t$に点$Q$に到達する」
といった表現を含む問題は比較的少数であることも考えあわせると，
システムの現在の開発段階で意味表現に時間の概念を持ち込む利得は
意味表現・言語解析および推論の複雑化に見合わないと考える．


幸い，これまでに観察された行為結果文は定型的なものが多く，
時間の概念を含まない現在の枠組みでも，必要な意味表現を
合成することは多くの場合に可能であると思われる．
特に「X を Vすると Y となる」という形の文については，下記の2つの方針が考えられる：
\begin{description}
    \item[方針1] 主節「Yとなる」はガ格のゼロ代名詞を持ち，そのゼロ代名詞は間接照応で「XをVした結果」を指すと考える．
            この方針では節「XをVすると」は意味表現に直接は寄与せず（翻訳されず），「XをVした結果がYとなる」に
            相当する意味表現が作られる．
    \item[方針2] 句「Vすると」は右にガ格を欠いた一項述語を項として取り，左にヲ格名詞句を項として取ると考える
        （即ち，「Vすると」は範疇 \typename{S{\backslash}NP_{o}/(S{\backslash}NP_{ga}})を持つ）．
\end{description}

方針1のゼロ照応の解決は，行為結果文の定型性を利用することで比較的容易に実現できると予想される．
方針2の利点としては，ゼロ照応解決に依らず，CCGによる解析の枠組み内で全ての意味合成が行えることに加え，
例えば「2乗すると10を超える奇数」のような連体修飾の形も上記の範疇を持つ「Vすると」の語彙項目によって
同時に扱える点が挙げられる（\FIGREF{fig:suugaku:action:relative}）．

\begin{figure}[t]
\begin{center}
\includegraphics{23-1ia5f6.eps}
\end{center}
\caption{連体修飾の形の行為結果文の解析\label{fig:suugaku:action:relative}}
\end{figure}


\subsection{数学：まとめと今後の課題}

本節では，入力アノテーションによって言語処理とくに曖昧性解消処理の大部分を代替した
理想化された状況でもなお残る数学解答システムのエラーに関して解説を行った．
意味表現の冗長性に起因する計算量の増大は，言語処理と自動演繹の両者にまたがる
タスク設定に特有の課題であり，解決に向けては，文法・意味合成の特性を踏まえた
数式処理技術など分野融合的な研究が必要となる．
行為結果文の分析に関する課題では，いわゆる ``generalization to the worst case'' の
問題をどう回避するか，という点が本質的である．
これは，大多数の文の構造は典型的ないくつかの文法・意味現象の組み合わせとして分析可能であるにもかかわらず，
多様な言語現象をカバーするための分析枠組みの下では，具体的な分析対象がどのような文であっても，
その意味表現が一様に（かつ，枠組みが対象とする現象の数に関して組合せ的に）増大するという問題である．
本稿では，数学テキストでの行為結果文の定型性を利用した分析の単純化を一つの解として提示した．

言語系・社会系の科目に比べ数学解答システムの言語処理部の開発は遅れている．
数学解答システムの開発では，これまで，自然言語から構成的に導出が可能で，
かつ数理処理部への入力として適した意味表現の設計に注力してきたことが，
言語処理部の開発の遅れの主たる理由である．
これを裏返して言えば，数学のように形式的な意味表示のための体系がほぼ確立した分野に対しても，
言語から意味表示を導出するための中間的な意味表示体系として直接利用できるような枠組みは
存在しなかったということであり，言語処理と自動演繹という人工知能の 2 つの下位分野をつなぐ
領域は大きく欠落していたと言ってよいだろう．

言語処理部分の自動化に向けた主要な課題は，(i) 既存技術の数学テキストへの分野適応，
(ii) 既存技術・コーパスでは対象とされていない現象の解析，
(iii) 文法の被覆率の向上，に分けられる．
(i) に関しては，例えば，係り受け解析器 cabocha \cite{cabocha}に対して，
数学問題テキスト約10,000文に対する係り受けアノテーションを用いた追加訓練を行うことで
数学問題テキストに対する解析精度を追加訓練前の87〜90\%から94\%程度まで向上できることが分かっている．
このように，分野適応によって，新聞テキスト等に比べ高い解析精度が得られる処理ステップが存在する一方で，
数学問題を解くという目的に向けては，さらに残る解析エラーをゼロに近づけることが必要である．
上記の係り受け解析に関する結果からも示唆されるように，エラーをゼロに近づける段階では，
「汎用」の分野適応手法ではなく，分野特有の知識や数理処理の結果のフィードバック等を
用いた手法が必要となることが予想される．

(ii) に関しては，例えば，命題を指す参照表現（「このとき」「そのとき」）や，
不飽和名詞・関係名詞に係る「ノ格」のゼロ照応解決（例「平面上に直角三角形ABCがある．斜辺BCは…」）など，
日本語共参照・照応解決のための学習・評価データとして近年ひろく用いられている
NAISTテキストコーパス\cite{NTC2015}ではアノテーションの対象となっていない現象の解析が必要であり，
既存のツール・データをそのまま利用した解決は事実上不可能である．
また，文間の論理関係の解析に関しては，修辞構造解析・談話構造解析など，
形式的には類似のタスクに関する研究があるが，変数のスコープ解決を含め，
文間の詳細な論理的関係の解析を対象とする研究は我々の知る限り存在しない．
これらの課題に関しては，まず，分野知識を前提としたルールベースの手法による達成率を調査し，
その後，必要であればテキストアノテーションを介した統計手法との組み合わせを検討することが
目標の実現へ向けた戦略としては妥当であろう．

(iii) の文法の被覆率の向上に関しては，現在のところ見通し不明であると言わざるを得ない．
名詞・動詞など内容語に関しては，辞書見出し語による文表層形の被覆率を測定することで，
必要な語彙のうち辞書に未収録なものの概数が分かる．
しかし，機能語は同一表層形のものが多数の異なる統語的特性および意味をもつため，
被覆率の測定のためには，文が解析可能であるか否かに加え，得られた意味表示が正しいことを確認する必要がある．
このため，構文解析すら自動化されていない現段階では，少数のサンプルを超えて大規模な被覆率の測定を行うことは難しい．
今後は，言語解析の結果から得た解答のチェックを通じて，間接的に被覆率の測定や
機能語の未知の用法の検出を行うといった工夫が必要になると考えている．



 \section{物理問題のエラー分析}

 大学入試における物理の問題の多くは，
 問題に記述された状況において，ある物理現象が起きたときの物理量について
 のもの（e.g. ``物体が停止した時間''）や，物理現象が起きるための条件となる
 物理量についてのもの（e.g. ``棒がすべり出さないための静止摩擦力''）である．
 本研究ではこの種の問題解答に向けて，物理シミュレーションによって問題に書かれている状況を
 再現し，得られた結果を用いて解答を行うアプローチで取り組んでいる\cite{yokno2014}．

 解答器は自然言語で記述された問題を入力として受け取り，まず意味解析を行い，
 状況の記述と解答形式の記述からなる形式表現を生成する．次に形式表現を元
 に物理シミュレーションを行い，得られた結果から問題に記述されている物理
 現象が起きた時刻における物理量を特定し，解答形式にあわせて出力すること
 で問題に解答する．

 2014年度の代ゼミセンター模試による評価では形式表現からシミュレーション結果の取得に焦点を当て，
 人手で記述した問題の形式表現を入力とし，得られたシミュレーション結果から解答が導ける
 かどうかを人が判断するという設定とした．
 この設定においても正解が得られなかった問題とは，シミュレーション自体が行えなかった問題であり，
 大別すると (i) 形式表現による記述が困難な状況設定を含む問題 
 (ii) 電磁誘導などシミュレーションが困難な物理現象を含む問題，の2種類がある．
 本稿では(i)に焦点を当て，その詳細について述べる．


\subsection{形式表現}

  本手法で用いている形式表現は一階述語論理の形式で記述している．定義して
  いる述語は物体，物理量，物体に対する操作，物理現象を表す4種類のもので
  ある．このうち物体に対する操作と物理現象を表す述語に関しては，事象が起
  きた時間関係を明示するためにイベント変数を導入している．
  形式表現に用いる述語セットは過去のセンター試験問題を対象とした調査結果を基に人手で定義した．

  現時点における形式表現の定義でどの程度の問題が記述できるかを
  2013，2014年度の代ゼミセンター模試5回分を用いて評価した．結果を
  \TABREF{fig:butsuri:mondaibunrui}に示す．状況記述の項は実際に形式表現
  で記述できた小問の数を示している．
  状況記述の項の``+''以降の値は新しく述語を定義することで状況の記述が可能となった問題の数を示す．

\begin{table}[b]
\caption{形式記述の分析（試験5回分）}
\label{fig:butsuri:mondaibunrui}
\input{05table19.txt}
\end{table}

  状況の記述ができないと判断された問題は全部で25問あり，その理由の内訳は，
  シミュレーションモデルの不足によるものが12問，
  画像で形状が指定されるオブジェクトをシミュレータに入力できないことによるものが8問，
  その他の理由によるものが5問であった．
  以下では，上位2つの原因について詳細を述べる．

  

\subsection{シミュレーションモデルの不足}
\label{sec:butsuri:complicated}

  物理問題の形式表現では，数学における集合論のように，全ての問題を記述しうる表現の枠組みを考えることは現実的でない．
  このことは，例えば力学，電磁気，波動（音波，光，弦の振動）といった多様な分野の問題を
  一様に「原子レベル」で記述することの非現実性から明らかだろう．
  すなわち，物理では各分野および問題タイプごとに適切な抽象度の物理モデルを用いる必要がある．
  これらのモデルには，力学や電気回路など，比較的多様な問題をひとつのモデルでカバーするものから，
  「両端が固定された弦の振動」といった単一の現象のみを対象とするものまで様々な抽象度のものが含まれる．

  ゆえに，物理問題に対する形式表現の記述とシミュレータでの実行は，(i) 適切な物理モデルの選択と 
  (ii) 選ばれた物理モデルの枠組みの中での問題の解釈，という 2 つの側面を含む．
  この 2 つの側面は不可分であり，問題に対して適切な抽象度の物理モデルが事前に存在しない場合は，
  問題に対する形式的記述がそもそもできない．
  定性推論\cite{forbus1984}などのように，基礎的なレベルの状況記述から，
  より抽象的で演繹に適したモデルを自動的に生成することを目指す研究は存在するものの，
  広範囲の物理問題に適用可能な解答プログラムの開発を5〜10年のスパンで目指す本研究では
  スコープ外の目標と見なすべきであろう．

  \TABREF{tab:butsuri:riyuu}の「シミュレーションモデルの不足」は，上記の意味で適切な
  物理モデルが評価時に存在しなかった問題である．
  ここに分類された問題のうち半分以上（12問中9問）は，例えば，
  「一定の風速および方向の風が吹く中で伝わる音波のドップラー効果」や
  「質量$2~m$の重りをつるすと切れる糸を用いた円錐振り子」のように，
  現在の音波の伝達モデルや力学モデルを拡張することで表現が可能になる問題である．
  しかし，そもそもどのような抽象化をすべきか現段階では明らかでない
  「伏せたコップを水中に沈め，水圧によってコップの下端から$x$cmの高さまで水が入りこんだ状態」の
  ような問題も含まれている．

\begin{table}[b]
\caption{状況記述ができない理由}
\label{tab:butsuri:riyuu}
\input{05table20.txt}
\end{table}

  本研究では力学に関係したモデルから開発を始めたため，力学に関しては記述可能な問題の割合が相対的に大きい．
  今後は，「切れる糸」など力学モデルの中で例外的な扱いが必要な現象を洗い出し，
  モデルに取り込むとともに，現象に対し個別的なモデルが必要な問題が多い波動などの分野に関して，
  どの程度のモデル数が必要か，現実的に実現可能なモデル数に収まるのかを見定める必要がある．


  \subsection{自由形状の入力}

  問題には「平らな床の上に置かれた立方形の台」のように基本的な小数の要素で構成可能な
  状況だけでなく，\FIGREF{fig:butsuri:fig1}のように画像によって与えられた複雑な形状の要素が
  出現するものがある．
  これらは原理的には力学モデル内で扱うことが可能であるが，
  シミュレータへと状況を入力するために画像処理を必要とし，さらに自由形状のオブジェクトを
  取り扱うためのシミュレータ機能の実現コストが大きいため，現在は未着手の状態にある．
  
\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f7.eps}
\end{center}
\caption{複雑な形状の例}
\label{fig:butsuri:fig1}
\end{figure}


  \subsection{物理：まとめと今後の課題}

  物理問題の多くは問題で与えられた状況に対して起きた物理現象について，
  その時の物理量やその物理現象が成立するための条件を問うものである．
  このような問題に対して，我々は問題に書かれている状況を認識し，その状況を起点とする
  物理シミュレーションを行い，得られた物理量をもとに解答するというアプローチで取り組んでいる．
  これまで，十分な範囲の問題を記述することができ，かつ，その情報から物理
  シミュレーションが可能となるような形式表現の定義を行ってきた．
  \TABREF{fig:butsuri:mondaibunrui}に示すように，まだ記述できない問題は残っ
  ているため，今後も定義を改良する必要があるが，同時に自然文として記述さ
  れたテキストからこの形式表現への変換にも取り組む予定である．

  問題テキストから形式表現への変換は，現在さかんに研究が進められている
  semantic parsing の一例と見なすことも可能ではある．しかし，これまでの
  semantic parsing のタスク設定では，翻訳の目的言語となる形式表現の
  セマンティクスがあらかじめ固定されているのに対し，物理問題の状況理解では
  目的言語を定める物理モデルの選択が形式表現への翻訳と一体になっている点が大きく異なる．
  これによって，物理問題の意味解析には，例えば「鉄球」という語に対し「質点」を表す表現を
  割り当てるのか，あるいは大きさを持つ剛体を表す表現を割り当てるのか，という訳語選択に
  当たるレベルの曖昧性解消だけでなく，「時刻$t$に車のサイレンが発した音波」といった表現から
  「気圧の周期変動の伝播」としての音波ではなく，音源から音波があたかも「物質のように」
  放出される音波モデルを選択すべきことを識別する，といったテキスト解析に基づく
  物理モデルの選択の問題が含まれる．

  また，現時点では，数値データとして出力されるシミュレーション結果を
  人手で解釈して解答しているが，最終的にはこの部分も自動化する必要がある．
  この部分は，センター試験形式の物理問題では，選択肢として与えられる式やグラフ，
  あるいは選択肢および本文における自然言語による状況記述と，
  物理的状況を表す数値データとの整合性ないし含意関係を判定する問題である．
  このうち，自然言語による記述と数値データを比較判定する問題は，問題の状況理解と
  ほぼ裏表の関係にあり，例えば「止まる」「離れる」等々といった状況を表す語に対し
  数値（時系列）データに対する条件を結びつけた辞書を用いて，数値データと言語記述の
  整合性を判定する手法の開発を進めている\cite{YokonoNLP2013}．

  また，物理の問題には問題文とともに状況を示した図が添付されていることが多い．
  この中には，\ref{sec:butsuri:complicated}節で挙げたように，物体の形状が図でのみ与えられるなど，
  図の解釈が必須となる問題も存在するが，テキストで与えられた状況記述の曖昧性を
  除去する目的で図が添えられた問題も多数存在する．
  後者のタイプの問題に対しては，画像理解とテキスト理解を融合した状況理解の手法の開発とともに，
  言語理解に基づくシミュレーション結果がテキストでの記述と合致するか，など
  画像理解以外の手段でテキスト解釈を補う技術を開発することを試みている．



\section{世界史・日本史のエラー分析}

本節では，2014年度の代ゼミセンター模試に対し，狩野\cite{kano2014jsai}のシステ
ムが出力した解答のエラー分析について報告する．本システムは，山川出版社
の世界史または日本史の用語集を知識源とし，設問から抽出したキーワードが
知識源の中でどのように分布しているかをスコアとして算出し，解答を選択す
る．具体的には，設問および知識源に対して以下の各処理を行い，解答の選択
を行う\footnote{本システムは図表の処理は行っておらず，図表に対して人手
  でアノテーションされたテキストを利用して解答を行う．}．
\begin{enumerate}
\item 問題文解析：問題文のテキストを前処理し，キーワード抽出を行う対象
  テキストを切り出す．一般に，設問は背景説明のテキストや導入文，実際に
  正誤判定の対象となる文など，複数のテキストから構成される．そこで，こ
  れらのテキストから後段の処理で必要となるテキスト箇所を抽出する必要が
  ある．
\item キーワード抽出：前処理した問題文テキストから，スコア付けに用いる
  キーワードを抽出する．キーワードリストとして，Wikipedia の見出し語か
  ら自動抽出した語句を人手でクリーニングしたものを用い，単純なマッチン
  グでキーワード抽出を行った．
\item 知識源検索：抽出したキーワードで知識源を検索し，キーワードに合致
  するテキストを得る．
\item スコア付け：キーワードと検索結果テキストとの一致度をスコア付けす
  る．後述するように，センター試験では文の正誤を判定する問題が多い．誤
  りを含む文では，知識源のまとまった範囲内にキーワードが出現せず，別の
  場所に出現すると考えられる．したがって，検索結果テキストにキーワードが含
  まれない場合は，ペナルティとして負のスコアを与える．
\item 解答選択：文の正誤を判定するタイプの問題に対しては，スコアが大き
  いものを正しい文として解答を選択する．語句を解答するタイプの問題（い
    わゆるfactoid型質問応答に相当）に対しては，選択肢に挙げられた
  語句を問題文テキストに埋め込み，文の正誤判定問題に帰着して解答を行う．
  年代を解答する問題については，検索結果テキスト中の年代表現を抽出する
  ことで解答を行う．
\end{enumerate}

このシステムは，2013 年度および 2014 年度の代ゼミ模試「世界史」・「日本史」において最も高い性能を示したものである．
また，同システムは，
センター試験の世界史過去問を用いた競争型ワークショップである
NTCIR-11 QA-Lab Task \cite{Shibuki2014} にも参加している\footnote{
    ただし，NTCIR-11 QA-Lab Task では用語集ではなく教科書を知識源として用いている．}．
同ワークショップに参加した他のシステムにも本システムと同様にキーワードないし係り受け関係を
クエリとした検索を基礎とするシステムが多数あった．
これらのことから，本節で分析対象とするシステムは，分野特有の処理に依存しない，
検索をベースとした汎用的なシステムとしては比較的高性能なものであると考えてよいだろう．


\TABREF{tab:sekaishi:errors}に世界史，\TABREF{tab:nihonshi:errors}に日
本史の問題タイプとエラー分析結果を示す．センター試験の世界史・日本史で
は，選択肢として与えられた文に対して正誤を判定するタイプの問題が大きな
割合を占める（例えば図\ref{fig:problem_analysis_error}）．語句や年代を
解答するタイプの問題（例えば図\ref{fig:ontology_error}）はいわゆる
factoid型質問応答に見えるが，知識源中の解答に関連する記述は多くの場合
一つしか無く，大規模テキストを利用した解答の aggregation といった技術
は利用できない．したがって，語句・年代と問題文との組合せの正誤を判定す
るタスクに帰着される．このように，知識源を的確に参照しつつ，文の正誤を
判定するという処理は，上記のようにテキストの前処理，キーワード抽出，検
索，スコア付け等，複合的な処理が必要であり，また各処理で高い精度が要求
される．各処理は当然不完全なものであり，必ずしも排他的な関係にあるわけ
でもない．よって，最終的に誤答が出力された要因を単一の原因に帰着するこ
とは難しいため，\TABREF{tab:sekaishi:errors}，
\TABREF{tab:nihonshi:errors}では，複数の要因は別個にカウントしてエラー
の分類を行った．

\begin{table}[t]
\caption{世界史の問題タイプと誤答の要因}
\label{tab:sekaishi:errors}
\input{05table21.txt}
\end{table}
\begin{table}[t]
\caption{日本史の問題タイプと誤答の要因}
\label{tab:nihonshi:errors}
\input{05table22.txt}
\end{table}
\begin{figure}[t]
\begin{center}
\includegraphics{23-1ia5f8.eps}
\end{center}
\caption{問題文解析の誤りの例}
\label{fig:problem_analysis_error}
\end{figure}

「問題文解析」は，問題に解答するための情報が書かれた問題文テキストを切
り出す処理に起因するエラーである．図\ref{fig:problem_analysis_error}に
例を示す\footnote{問題例を挙げる際には，紙面の都合上，選択肢の一部の
  み抜粋する．}．この問題では，問題文中に「ノモス」「王国」「古代エジプ
  ト」といったキーワードが現れるが，実はこれらの情報は選択肢の正誤判定
には無関係である．つまり，選択肢の文のみを用いて正誤の判定を行うことが
できる．一方，問題によっては問題文中のキーワードが正誤判定に必要な場合
や，さらに背景説明のテキストも参照する必要があることもある．次のエラー
要因とも関連するが，どこまでのテキストをキーワード抽出の対象とすべきか
は単純には決定できない．

「キーワード抽出」は，当該問題を解くのに必要・不必要なキーワードを分別
できていないことに起因するエラーである．図
\ref{fig:keyword_extraction_error}に例を示す．この例では，2 は誤った文
であるが，「君」「直」などがキーワードとして認識されず，これらの語が知
識源に現れなかったにも関わらずペナルティがかからなかったため，正しい文
と判定されてしまった．これ以外にも，例えば「法制」「編集」といった一般
語がその問題文中では重要なキーワードとなっているような場合や，逆に「ア
  ジア系」のような専門用語らしい語が知識源には明示的に書かれていないた
め，ペナルティがかかってしまった例がある．世界史・日本史の知識がある程
度ある人間が読めば，重要なキーワードと重要ではない（知識源に明示的に書
  かれていなくても正誤判定には影響しない）キーワードがある程度区別でき
るが，これを実現するのは容易ではない．

\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f9.eps}
\end{center}
\caption{キーワード抽出の誤りの例}
\label{fig:keyword_extraction_error}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f10.eps}
\end{center}
\caption{データベース・オントロジー的知識が利用できる例}
\label{fig:ontology_error}
\end{figure}

「一般知識」は，解答のために必要な知識が明示的に知識源に記述されていな
いことに起因するエラーである．世界や日本の地理・時代に関する知識，一般
常識に照らした判断，等が必要とされる．単純な例としては，図
\ref{fig:ontology_error}のように，「岩宿遺跡」がどの時代の遺跡か，とい
う知識を予め用意しておけば解答できるような問題もある．このような知識は
必ずしも教科書・用語集に明示されているわけではないが，データベースなど
の形式で整理しておくことは可能である．より困難な例を図
\ref{fig:knowledge_error}に示す．この場合，知識源の文章を読めば，「北
  海道に水稲耕作は及ばず」が妥当であることが分かるが，この判断のために
は農耕，狩猟，水稲といった概念の知識と，それらを対比して判定を行う処理
が必要である．このように知識源の記述と設問の記述が直接一致しないケース
は特に日本史の問題に多い．

\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f11.eps}
\end{center}
\caption{一般知識が必要な例}
\label{fig:knowledge_error}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f12.eps}
\end{center}
\caption{言語知識が必要な例}
\label{fig:linguistic_knowledge_error}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{23-1ia5f13.eps}
\end{center}
\caption{言語構造が必要な例}
\label{fig:linguistic_structure_error}
\end{figure}

「言語知識」および「言語構造」は，自然言語処理技術の利用・高精度化によ
り解決できる可能性のあるエラーである．前者は，例えば「解読」と「未解読」
が反義語であるといった語彙知識や，「収穫した稲の脱穀」と「精穀具」のパ
ラフレーズ関係など，言語知識を利用することで正答が得られる可能性がある
ものである．「解読」「未解読」のような例であれば，言語リソースの整備に
より解決できる可能性が高い．しかし，図
\ref{fig:linguistic_knowledge_error}に示すような例はパラフレーズ認識あ
るいはテキスト間含意関係認識に相当するものもあり，必ずしも容易に解決で
きるものではない．後者は，係り受け解析，述語項構造解析，否定の解析など
によって，文の意味の違いを認識することが必要とされるものである．典型的
には，文章中に複数の命題が記述されている場合がある．図
\ref{fig:linguistic_structure_error}に示す例では，正解は 2 であるが，4
のキーワードも同一文章中に含まれているため，スコアが同率となり，最終的
に誤った解答を選択してしまっている．この例は係り受けあるいは述語項構造
が正確に得られれば正しい解答が得られると期待される．また，図
\ref{fig:linguistic_knowledge_error}の例では，システムは2を選択したが，
これは知識源には「田植えをした可能性も高まった．」と記述されており，否
定やモダリティの正確な解析によって正答が得られる可能性がある．ただし，
このような言語知識・言語解析は新たなエラー要因を持ち込むため，単純にこ
れらの技術を導入することでは全体の正答率が下がる可能性が高い．必要な場
面で適切かつ正確に言語処理技術を利用する必要がある．

最後に，2014年度代ゼミセンター模試「世界史B」36問について，システム出力と
受験生の選択率一位の解答（「人間」）とを比較したクロス表を\TABREF{tab:shakai:cross:sekaishi}に示す．
全体の問題数は少ないが，人間が正解・不正解だった問題グループそれぞれに
対するシステムの解答は正解・不正解がおよそ半数ずつになっており，
人間とシステムの正解分布は独立であることがうかがわれる．
実際に，Fisher の正確確率検定を適用した結果は $p = 0.68$ であり，
人間・システムの正解・不正解が独立であることは棄却されなかった．
また，人間が不正解かつシステムが正解した3問
（受験生の正答率はそれぞれ22.5\%，35.3\%，14.9\%）では，
いずれもシステムは知識源から妥当なテキストを取得しており，
単なる偶然ではなくシステムの性能が発揮された形で大多数の受験生が
誤った問題に正解している．

\begin{table}[t]
\caption{人とシステムの正答傾向の比較（世界史）}
\label{tab:shakai:cross:sekaishi}
\input{05table23.txt}
\end{table}


\subsection{世界史・日本史：まとめと今後の課題}

本節では，世界史・日本史の試験問題を対象に，狩野\cite{kano2014jsai}の
システムのエラー分析を行った．本システムは構文解析，意味解析等の自然言
語処理を行わず，設問と知識源とのキーワードの一致をスコア付けする方式を
とっている．自然言語処理の立場からは，より深い言語処理技術を利用するこ
とで正答率を上げるというアプローチが考えられるが，エラー分析の結果から
は，それにより正答できる問題はそれほど多くなく，また精度が不十分な言語
リソース・言語解析を導入することによる副作用も懸念される．一方，問題文
の前処理やキーワード抽出に起因するエラーはまだ一定数残っており，これら
は改善の余地があると考えられる．また，特に日本史では一般知識・常識や，
知識源に直接記述されていない知識を統合的に利用する必要がある問題が見ら
れる．これを解決することは容易ではないが，自然言語理解の興味深い未解決
問題の一つと見ることもできる．


\section{おわりに}

本稿では大学入試センター試験形式の模試問題データを主たる対象として，
英語・国語（現代文評論）・数学・物理・日本史・世界史の各科目に
対する解答システムのエラーを分析した．

本稿でエラー分析を行った問題タイプのうち，現時点でもっとも解答精度が高いのは，
英語の「発音・アクセント」「文法・語法・語彙」「語句整除完成」「未知語（句）語義推測」であった．
これらの問題タイプでは，辞書ベースの手法が非常に有効であった「発音・アクセント」を例外として，
いずれも巨大なテキストデータを利用した手法 (N-gram, word2vec) によって高い正答率を得ている．
また，「発音・アクセント」の強勢の予測に関する問題を例外として，他 3 つの問題タイプでは，
マルコフ仮定から大きく外れる文法的な依存関係に起因するエラーを
構文解析を利用して解消する，低頻度語（句）は辞書の語釈文で置き換えた上で類似度を算出する，など，
エラー傾向の分析によって，ある程度まで解決へ向けた方針が明らかになっている．

これに対し，国語現代文（評論）の読解問題では，50\%程度の解答精度は実現できており，
現在の技術レベルを大きく超えると思われるいくつかの問題タイプを特定することまではできているものの，
解決可能性のあるエラータイプを言語現象と結びつけた形で類型化することは現在できていない．
そのひとつの原因は，シンプルではあるが挙動の直観的把握が難しい，表層類似度に基づく手法を用いていることにある．
予備校による模試と実際のセンター試験で，相性のよい手法が異なるといった発見もあったが，
同様の理由でその原因の特定には至っていない．
今後，本文の修辞構造の解析などと組み合わせ，手法を改善するにつれ，より詳細なエラー分析が可能になることが期待される．

数学および物理では，これまで主として中間表現の設計および言語処理と数理的演繹システムとの
接続部分に注力して研究を進めており，システム全体の自動化に関しては他科目に比べ遅れている．
他のテキストドメインに比べ，はるかに明確な意味表示を持つと考えられる数学や物理においても，
言語からの翻訳を考慮した中間的な意味表示の体系が，再利用可能な形で存在しなかったことは，
これまでのNLP/AIにおける欠落といってよいだろう．
中間表現の設計が物理に比べやや進んでいる数学に関しては，言語処理と演繹処理の接続に由来する
エラーとして，表現の冗長性による計算量の爆発の問題があることを示し，
分野融合的な解決が必要であることを述べた．

日本史・世界史のエラー分析では，問題文および知識源テキストの言語解析や，
分野知識・言語知識・一般的な知識など種々のタイプの知識の利用など，
エラー要因あるいは改善へ向けた要素が多岐に渡ることを示した．
また分析の結果から，現在のシステムで最も改善が有効であろうポイントとして，
選択肢からのキーワード抽出および問題文の前処理を挙げた．
いずれも本質的には歴史分野に関する一定の知識・理解を要する処理であり，
ノイズを含む知識リソースの導入などによる新たなエラーの発生に関する懸念はあるものの，
知識リソースや要素技術自体の改良と，それらの追加要素の，解答システムへの取捨選択的な
導入が改良へ向けた唯一の方策だろう．


いくつかの科目・問題タイプの解答システムの分析では，最も多数の受験生が選択した
解答（以下，単に「人の解答」とよぶ）とシステムの出力との比較を行った．
統計的検定の結果，システムと人の解答の正答・誤答の分布が独立であるという帰無仮説が
ほぼ棄却 ($p=0.06$)されたのは英語の語句整除完成問題に対してのみであった．
予備調査として，自動的な解答システムの完成には至っていない数学・物理に関しても，
演繹部の能力と中間表現の複雑さと正答率との関係を見るために
システムの正解率と受験生の正答率の関係を調べた．
しかし，現在のところ両者に特に顕著な関係は無いようであった．
「人のように考える」システムあるいは「人のように間違える」システムはもとより
我々の目標ではない．
しかし，人とシステムにとっての難易の差について今後より詳細な分析を行うことで，
システムの改良に関して，
更なる知見が得られることが期待される．


本稿で主として取り上げた問題タイプ，また今後の課題などとして簡単に触れた科目・問題タイプを通覧すると，
まず，大きな傾向として漢字やアクセント・発音，文法問題など，個別的な言語知識に関する問題については
人間の平均あるいはそれ以上の精度を達成しているものが多数ある一方で，英語・国語の長文読解に
代表される総合的な能力を要する問題では良くても人間の平均レベルにとどまっていることが指摘できる．
また，個別的な言語知識に関する問題以外では，数学・物理など，解答システムの開発スピードは遅いが，
少なくとも現状問題となっている点について現象レベルの説明が可能である科目と，
国語現代文（評論），世界史・日本史など，自動システムの完成までの開発は速かったが，
エラー要因の類型化が難しい，あるいはエラー要因が多岐に渡る科目との対照が明らかである．
これは科目ごとに各開発チームが最も有効であると判断した手法を選択した結果であり，
形式的な演繹に基づく手法と表層的手がかりによる手法の比較にみられる一般的な傾向である．
しかし，例えば行為結果文についての分析から示唆されるように，
数学においても出現する構文パターンに大きな偏りがあるなど，
表層的な手がかりに基づく手法が有効であろう側面も確かに存在する．
逆に，分析結果から示されたように，世界史・日本史にも詳細な言語解析が有効に働くであろう設問も一定数存在する．
今後，各科目ともより多角的なエラー分析と総合的な問題の把握を進める上では，
点数・開発スピードでは最適といえずとも，現状のアプローチとは異なる手法による
結果との比較分析が有効であることが示唆される．





\acknowledgment

本研究を推進するにあたって，大学入試センター試験問題のデータをご提供下さった独立行政法人大学入試セン
ターおよび株式会社ジェイシー教育研究所に感謝いたします．また，模擬試験データおよび解答分布データを
ご提供下さった学校法人高宮学園に感謝いたします．
また，日本史および世界史用語集の電子データをご提供くださった山川出版社に感謝いたします．

\bibliographystyle{jnlpbbl_1.5}
\newcommand{\bibsort}[1]{}
\begin{thebibliography}{}

\bibitem[\protect\BCAY{新井}{新井}{2014}]{arai}
新井紀子 \BBOP 2014\BBCP.
\newblock \Jem{ロボットは東大に入れるか}.
\newblock イースト・プレス.

\bibitem[\protect\BCAY{戸次}{戸次}{2010}]{Bekki2010}
戸次大介 \BBOP 2010\BBCP.
\newblock \Jem{日本語文法の形式理論}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{Caviness \BBA\ Johnson}{Caviness \BBA\
  Johnson}{1998}]{qebook-e}
Caviness, B.\BBACOMMA\ \BBA\ Johnson, J.\BEDS\ \BBOP 1998\BBCP.
\newblock {\Bem Quantifier Elimination and Cylindrical Algebraic
  Decomposition}.
\newblock Texts and Monographs in Symbolic Computation. Springer-Verlag.

\bibitem[\protect\BCAY{Forbus}{Forbus}{1984}]{forbus1984}
Forbus, K.~D. \BBOP 1984\BBCP.
\newblock \BBOQ Qualitative Process Theory.\BBCQ\
\newblock {\Bem Artificial Intelligence}, {\Bbf 24}  (1-3), \mbox{\BPGS\
  85--168}.

\bibitem[\protect\BCAY{船口}{船口}{1997}]{Funaguchi}
船口明 \BBOP 1997\BBCP.
\newblock \Jem{きめる！センター国語現代文}.
\newblock 学研教育出版.

\bibitem[\protect\BCAY{Gubbins \BBA\ Vlachos}{Gubbins \BBA\
  Vlachos}{2013}]{deplm}
Gubbins, J.\BBACOMMA\ \BBA\ Vlachos, A. \BBOP 2013\BBCP.
\newblock \BBOQ Dependency Language Mmodels for Sentence Completion.\BBCQ\
\newblock In {\Bem Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, \mbox{\BPGS\ 1405--1410}.

\bibitem[\protect\BCAY{服部\JBA 佐藤}{服部\JBA 佐藤}{2013}]{Hattori2013}
服部昇平\JBA 佐藤理史 \BBOP 2013\BBCP.
\newblock 多段階戦略に基づくテキストの意味関係認識：RITE2 タスクへの適用.\
\newblock 情報処理学会研究報告\ 2013-NL-211 No.4/2013-SLP-96 No.4,
  情報処理学会.

\bibitem[\protect\BCAY{加納\JBA 佐藤}{加納\JBA 佐藤}{2014}]{Rainbow}
加納隼人\JBA 佐藤理史 \BBOP 2014\BBCP.
\newblock 日本語節境界検出プログラム Rainbow の作成と評価.\
\newblock \Jem{FIT2014 講演論文集第 2 分冊}, \mbox{\BPGS\ 215--216}.

\bibitem[\protect\BCAY{東中\JBA 杉山\JBA 磯崎\JBA 菊井\JBA 堂坂\JBA 平\JBA
  南}{東中 \Jetal }{2015}]{eigo}
東中竜一郎\JBA 杉山弘晃\JBA 磯崎秀樹\JBA 菊井玄一郎\JBA 堂坂浩二\JBA 平博順\JBA
  南泰浩 \BBOP 2015\BBCP.
\newblock センター試験における英語問題の回答手法.\
\newblock \Jem{言語処理学会第 21 回年次大会 (NLP2015)}.

\bibitem[\protect\BCAY{飯田\JBA 小町\JBA 井之上\JBA 乾\JBA 松本}{飯田 \Jetal
  }{2010}]{NTC2015}
飯田龍\JBA 小町守\JBA 井之上直也\JBA 乾健太郎\JBA 松本裕治 \BBOP 2010\BBCP.
\newblock 述語項構造と照応関係のアノテーション：NAIST
  テキストコーパス構築の経験から.\
\newblock \Jem{自然言語処理}, {\Bbf 17}  (2), \mbox{\BPGS\ 25--50}.

\bibitem[\protect\BCAY{板野}{板野}{2010}]{Itano}
板野博行 \BBOP 2010\BBCP.
\newblock \Jem{ゴロゴ板野のセンター現代文解法パターン集}.
\newblock 星雲社.

\bibitem[\protect\BCAY{Iwane, Yanami, Anai, \BBA\ Yokoyama}{Iwane
  et~al.}{2013}]{IwaneYAY13}
Iwane, H., Yanami, H., Anai, H., \BBA\ Yokoyama, K. \BBOP 2013\BBCP.
\newblock \BBOQ An Effective Implementation of Symbolic-numeric Cylindrical
  Algebraic Decomposition for Quantifier Elimination.\BBCQ\
\newblock {\Bem Theoretical Computer Science}, {\Bbf 479}, \mbox{\BPGS\
  43--69}.

\bibitem[\protect\BCAY{Jurafsky, Shriberg, \BBA\ Biasca}{Jurafsky
  et~al.}{1997}]{Jurafsky:97}
Jurafsky, D., Shriberg, E., \BBA\ Biasca, D. \BBOP 1997\BBCP.
\newblock \BBOQ Switchboard SWBD-DAMSL Shallow-Discourse-Function Annotation
  Coders Manual, Draft 13.\BBCQ\
\newblock \BTR\ Technical Report 97-02, University of Colorado, Boulder.
  Institute of Cognitive Science.

\bibitem[\protect\BCAY{神谷\JBA 松崎\JBA 佐藤}{神谷 \Jetal }{2015}]{Kamiya2015}
神谷翼\JBA 松崎拓也\JBA 佐藤理史 \BBOP 2015\BBCP.
\newblock 数学確率文章題の自動解答システムの開発.\
\newblock \Jem{言語処理学会第 21 回年次大会 (NLP2015)}.

\bibitem[\protect\BCAY{狩野}{狩野}{2014}]{kano2014jsai}
狩野芳伸 \BBOP 2014\BBCP.
\newblock 大学入試センター試験歴史科目の自動解答.\
\newblock \Jem{2014 年度人工知能学会全国大会（第28回）}.

\bibitem[\protect\BCAY{加納\JBA 佐藤\JBA 松崎}{加納 \Jetal }{2015}]{CLMethod}
加納隼人\JBA 佐藤理史\JBA 松崎拓也 \BBOP 2015\BBCP.
\newblock 節境界検出を用いたセンター試験『国語』評論傍線部問題ソルバー.\
\newblock 情報処理学会研究報告\ 2015-NLP-220, 情報処理学会.

\bibitem[\protect\BCAY{工藤\JBA 松本}{工藤\JBA 松本}{2002}]{cabocha}
工藤拓\JBA 松本裕治 \BBOP 2002\BBCP.
\newblock チャンキングの段階適用による日本語係り受け解析.\
\newblock \Jem{情報処理学会論文誌}, {\Bbf 43}  (6), \mbox{\BPGS\ 1834--1842}.

\bibitem[\protect\BCAY{Kushman, Artzi, Zettlemoyer, \BBA\ Barzilay}{Kushman
  et~al.}{2014}]{Kushman2014}
Kushman, N., Artzi, Y., Zettlemoyer, L., \BBA\ Barzilay, R. \BBOP 2014\BBCP.
\newblock \BBOQ Learning to Automatically Solve Algebra Word Problems.\BBCQ\
\newblock In {\Bem Proceedings of the 52nd Annual Meeting of the Association
  for Computational Linguistics}, \mbox{\BPGS\ 271--281}.

\bibitem[\protect\BCAY{Li, Ran, Nguyen, Miyao, \BBA\ Aizawa}{Li
  et~al.}{2013}]{CLEF13Li}
Li, X., Ran, T., Nguyen, N.~L., Miyao, Y., \BBA\ Aizawa, A. \BBOP 2013\BBCP.
\newblock \BBOQ Question Answering System for Entrance Exams in QA4MRE.\BBCQ\
\newblock In {\Bem CEUR Workshop Proceedings: Working Notes for CLEF 2013
  Conference}, \lowercase{\BVOL}\ 1179.

\bibitem[\protect\BCAY{益岡\JBA 田窪}{益岡\JBA 田窪}{1992}]{KisoNihongo}
益岡隆志\JBA 田窪行則 \BBOP 1992\BBCP.
\newblock \Jem{基礎日本語文法—改訂版—}.
\newblock くろしお出版.

\bibitem[\protect\BCAY{Matsuzaki, Iwane, Anai, \BBA\ Arai}{Matsuzaki
  et~al.}{2013}]{Matsuzaki2013IJCNLP}
Matsuzaki, T., Iwane, H., Anai, H., \BBA\ Arai, N. \BBOP 2013\BBCP.
\newblock \BBOQ The Complexity of Math Problems -- Linguistic, or
  Computational?\BBCQ\
\newblock In {\Bem Proceedings of the 6th International Joint Conference on
  Natural Language Processing}, \mbox{\BPGS\ 73--81}.

\bibitem[\protect\BCAY{Matsuzaki, Iwane, Anai, \BBA\ Arai}{Matsuzaki
  et~al.}{2014}]{Matsuzaki2014AAAI}
Matsuzaki, T., Iwane, H., Anai, H., \BBA\ Arai, N.~H. \BBOP 2014\BBCP.
\newblock \BBOQ The Most Uncreative Examinee: A First Step toward Wide Coverage
  Natural Language Math Problem Solving.\BBCQ\
\newblock In {\Bem Proceedings of the 28th AAAI Conference on Artificial
  Intelligence}, \mbox{\BPGS\ 1098--1104}.

\bibitem[\protect\BCAY{Mikolov, Sutskever, Chen, Corrado, \BBA\ Dean}{Mikolov
  et~al.}{2013}]{Mikolov13}
Mikolov, T., Sutskever, I., Chen, K., Corrado, G., \BBA\ Dean, J. \BBOP
  2013\BBCP.
\newblock \BBOQ Distributed Representations of Words and Phrases and their
  Compositionality.\BBCQ\
\newblock In {\Bem Advances in Neural Information Processing Systems 26},
  \mbox{\BPGS\ 3111--3119}.

\bibitem[\protect\BCAY{Miyao \BBA\ Kawazoe}{Miyao \BBA\
  Kawazoe}{2013}]{MiyaoKawazoe2013IJCNLP}
Miyao, Y.\BBACOMMA\ \BBA\ Kawazoe, A. \BBOP 2013\BBCP.
\newblock \BBOQ University Entrance Examinations as a Benchmark Resource for
  NLP-based Problem Solving.\BBCQ\
\newblock In {\Bem Proceedings of the 6th International Joint Conference on
  Natural Language Processing}, \mbox{\BPGS\ 1357--1365}.

\bibitem[\protect\BCAY{Pang \BBA\ Lee}{Pang \BBA\ Lee}{2005}]{Pang+Lee:05a}
Pang, B.\BBACOMMA\ \BBA\ Lee, L. \BBOP 2005\BBCP.
\newblock \BBOQ Seeing Stars: Exploiting Class Relationships For Sentiment
  Categorization With Respect To Rating Scales.\BBCQ\
\newblock In {\Bem Proceedings of the 43rd Annual Meeting on Association for
  Computational Linguistics}, \mbox{\BPGS\ 115--124}.

\bibitem[\protect\BCAY{Pasupat \BBA\ Liang}{Pasupat \BBA\
  Liang}{2015}]{pasupat2015compositional}
Pasupat, P.\BBACOMMA\ \BBA\ Liang, P. \BBOP 2015\BBCP.
\newblock \BBOQ Compositional Semantic Parsing on Semi-Structured Tables.\BBCQ\
\newblock In {\Bem Proceedings of the 53rd Annual Meeting of the Association
  for Computational Linguistics and the 7th International Joint Conference on
  Natural Language Processing}, \mbox{\BPGS\ 1470--1480}.

\bibitem[\protect\BCAY{Pe{\~n}as, Hovy, Forner, Rodrigo, Sutcliffe, Forascu,
  \BBA\ Sporleder}{Pe{\~n}as et~al.}{2011a}]{Penas2011a}
Pe{\~n}as, A., Hovy, E., Forner, P., Rodrigo, {\'A}., Sutcliffe, R., Forascu,
  C., \BBA\ Sporleder, C. \BBOP 2011a\BBCP.
\newblock \BBOQ Overview of QA4MRE at CLEF 2011: Question Answering for Machine
  Reading Evaluation.\BBCQ\
\newblock In {\Bem CLEF 2011 Labs and Workshop Notebook Papers}, \mbox{\BPGS\
  19--22}.

\bibitem[\protect\BCAY{Pe{\~n}as, Hovy, Forner, Rodrigo, Sutcliffe, Sporleder,
  Forascu, Benajiba, \BBA\ Osenova}{Pe{\~n}as et~al.}{2011b}]{Penas2011b}
Pe{\~n}as, A., Hovy, E., Forner, P., Rodrigo, {\'A}., Sutcliffe, R., Sporleder,
  C., Forascu, C., Benajiba, Y., \BBA\ Osenova, P. \BBOP 2011b\BBCP.
\newblock \BBOQ Overview of QA4MRE at CLEF 2012: Question Answering for Machine
  Reading Evaluation.\BBCQ\
\newblock In {\Bem CLEF 2011 Labs and Workshop Notebook Papers}, \mbox{\BPGS\
  303--320}.

\bibitem[\protect\BCAY{佐藤\JBA 加納\JBA 西村\JBA 駒谷}{佐藤 \Jetal
  }{2014}]{BaseMethod}
佐藤理史\JBA 加納隼人\JBA 西村翔平\JBA 駒谷和範 \BBOP 2014\BBCP.
\newblock 表層類似度に基づくセンター試験『国語』現代文傍線部問題ソルバー.\
\newblock \Jem{自然言語処理}, {\Bbf 21}  (3), \mbox{\BPGS\ 465--483}.

\bibitem[\protect\BCAY{Shibuki, Sakamoto, Kano, Mitamura, Ishioroshi, Itakura,
  Wang, Mori, \BBA\ Kando}{Shibuki et~al.}{2014}]{Shibuki2014}
Shibuki, H., Sakamoto, K., Kano, Y., Mitamura, T., Ishioroshi, M., Itakura,
  K.~Y., Wang, D., Mori, T., \BBA\ Kando, N. \BBOP 2014\BBCP.
\newblock \BBOQ Overview of the NTCIR-11 QA-Lab Task.\BBCQ\
\newblock In {\Bem Proceedings of the 11th NTCIR Conference}, \mbox{\BPGS\
  518--529}.

\bibitem[\protect\BCAY{Steedman}{Steedman}{2001}]{steedman2001syntactic}
Steedman, M. \BBOP 2001\BBCP.
\newblock {\Bem The Syntactic Process}.
\newblock Bradford Books. Mit Press.

\bibitem[\protect\BCAY{Watanabe, Miyao, Mizuno, Shibata, Kanayama, Lee, Lin,
  Shi, Mitamura, Kando, Shima, \BBA\ Takeda}{Watanabe et~al.}{2013}]{RITE2}
Watanabe, Y., Miyao, Y., Mizuno, J., Shibata, T., Kanayama, H., Lee, C.-W.,
  Lin, C.-J., Shi, S., Mitamura, T., Kando, N., Shima, H., \BBA\ Takeda, K.
  \BBOP 2013\BBCP.
\newblock \BBOQ Overview of the Recognizing Inference in Text (RITE-2) at
  NTCIR-10.\BBCQ\
\newblock In {\Bem Proceedings of the 10th NTCIR Conference}, \mbox{\BPGS\
  385--404}.

\bibitem[\protect\BCAY{横野\JBA 稲邑}{横野\JBA 稲邑}{2013}]{YokonoNLP2013}
横野光\JBA 稲邑哲也 \BBOP 2013\BBCP.
\newblock 物理問題解答に向けた物理量の変化に着目した動作表現の解釈.\
\newblock \Jem{言語処理学会第 19 回年次大会発表論文集}.

\bibitem[\protect\BCAY{横野\JBA 稲邑}{横野\JBA 稲邑}{2014}]{yokno2014}
横野光\JBA 稲邑哲也 \BBOP 2014\BBCP.
\newblock 論理演算と物理シミュレーションの結合による物理問題解答.\
\newblock \Jem{2014 年度人工知能学会全国大会}.

\bibitem[\protect\BCAY{Zang, Wu, Meng, Jia, \BBA\ Cai}{Zang
  et~al.}{2014}]{kyosei}
Zang, X., Wu, Z., Meng, H., Jia, J., \BBA\ Cai, L. \BBOP 2014\BBCP.
\newblock \BBOQ Using Conditional Random Fields to Predict Focus Word Pair in
  Spontaneous Spoken English.\BBCQ\
\newblock In {\Bem 15th Annual Conference of the International Speech
  Communication Association}, \mbox{\BPGS\ 756--760}.

\end{thebibliography}

\begin{biography}
\bioauthor{松崎　拓也}{
2002年東京大学工学部システム創成学科卒業．2007年同大大学院情報理工学系研究科にて博士号（情報理工学）取得．
同大学助教，国立情報学研究所特任准教授を経て，2014年より名古屋大学大学院工学研究科准教授．
言語処理学会，人工知能学会，情報処理学会各会員．
}
\bioauthor{横野　　光}{
2003年岡山大学工学部情報工学科卒業．2008年同大大学院自然科学研究科産業創成工学専攻単位取得退学．
同年東京工業大学精密工学研究所研究員，2011年国立情報学研究所特任研究員，2014年同研究所特任助教，
現在に至る．博士（工学）．自然言語処理の研究に従事．情報処理学会，
人工知能学会各会員． 
}
\bioauthor{宮尾　祐介}{
1998年東京大学理学部情報科学科卒業．2006 年同大学大学院にて
博士号（情報理工学）取得．2001 年より同大学にて助手，のち助教．2010 年
より国立情報学研究所准教授．構文解析とその応用の研究に従事．人工知能
学会，情報処理学会，ACL 各会員．
}
\bioauthor{川添　　愛}{
1996年九州大学文学部文学科卒（言語学専攻）．2002年九州大学大学院文学研究科博士課程単位取得退学，2005年同大学より博士（文学）取得．2002年より2008年まで国立情報学研究所研究員，2008年から2011年まで津田塾大学女性研究者支援センター特任准教授を経て，2012年より国立情報学研究所社会共有知研究センター特任准教授．人工知能学会会員．
}
\bioauthor{狩野　芳伸}{
2001年東京大学理学部物理学科卒業，2007年東京大学情報理工学系研究科博士課程単位取得退学． 同研究科にて博士（情報理工学）． 同研究科特任研究員，科学技術振興機構さきがけ研究者等を経て，2014年より静岡大学情報学部准教授． 言語処理学会，情報処理学会，人工知能学会各会員．
}
\bioauthor{加納　隼人}{
2010年名古屋大学工学部電気電子・情報工学科入学．2014 年同学科卒業．
現在，名古屋大学大学院工学研究科電子情報システム専攻在学中．
}
\bioauthor{佐藤　理史}{
1988 年京都大学大学院工学研究科博士後期課程電気工学第二専攻
研究指導認定退学．京都大学工学部助手，北陸先端科学技術大学院大学助教
授，京都大学大学院情報学研究科助教授を経て，2005 年より名古屋大学大学
院工学研究科教授．工学博士．現在，本学会理事．
}
\bioauthor{東中竜一郎}{
1999年慶應義塾大学環境情報学部卒業，2001年同大学大学院政策・メディア研究科修士課程，2008年博士課程修了．
2001年日本電信電話株式会社入社．現在，NTTメディアインテリジェンス研究所に所属．
質問応答システム・音声対話システムの研究開発に従事．博士（学術）．言語処理学会，
人工知能学会，情報処理学会，電子情報通信学会各会員．
}
\bioauthor{杉山　弘晃}{
2007年東京大学工学部機械情報工学科卒業．2009年同大学院情報理工学系研究科知能機械情報学専攻修士課程修了．同年日本電信電話株式会社入社．
現在，奈良先端科学技術大学院大学情報科学研究科博士後期課程在学中．人と自然な対話を行う雑談対話システムの研究に従事．
}
\bioauthor{磯崎　秀樹}{
1983年東京大学工学部計数工学科卒業．1986年同大学院修士課程修了．
同年日本電信電話株式会社入社．2011年より岡山県立大学情報工学部教授．
博士（工学）．言語処理学会，ACM，情報処理学会，人工知能学会，電子情報通信学会各会員．
}
\bioauthor{菊井玄一郎}{
1984年京都大学工学部電気工学科卒．1986年同大学大学院工学研究科修士課程電気工学第二専攻修了．
同年日本電信電話株式会社入社，2011年より岡山県立大学情報工学部情報システム工学科教授．
博士（情報学）．現在，本学会理事．
}
\bioauthor{堂坂　浩二}{
1984年大阪大学基礎工学部情報工学科卒業．1986年同大大学院修士課程修了．
同年日本電信電話株式会社入社．2012年より秋田県立大学システム科学技術学
部教授．博士（情報科学）．言語処理学会，人工知能学会，情報処理学会，ACM各会員．
}
\bioauthor{平　　博順}{
1994年東京大学理学部卒業．1996年同大学院修士課程修了．
同年日本電信電話株式会社入社．1996年NTTコミュニケーション科学
研究所，2005年NTTデータ 技術開発本部，2007年NTTコミュニケーション科学
基礎研究所，2014年大阪工業大学情報科学部准教授．博士（工学）．
2013年言語処理学会優秀論文賞受賞．言語処理学会，人工知能学会，
情報処理学会各会員．
}
\bioauthor{南　　泰浩}{
1986 年慶應大学理工学部電気工学科卒業．1991 年同大学院博士課程
修了．同年日本電信電話株式会社入社．2014 年より電気通信大学大学院情報 システム学研究科教授．
博士（工学）．言語処理学会，IEEE，情報処理学会，電子情報通信学会，音響学会各会員．
}
\bioauthor{新井　紀子}{
1984年イリノイ大学数学科卒業．1990年同大学院博士課程修了．
1994年広島市立大学情報科学部助手．2001年国立情報学研究所情報基礎研究系助教授．
2006年同情報社会相関系教授．2008年同社会共有知研究センター長．博士（理学），
2010年文部科学省科学技術分野の文部科学大臣表彰．日本数学会，人工知能学会，
情報処理学会各会員．
}
\end{biography}


\biodate



\end{document}
