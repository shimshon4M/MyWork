<?xml version="1.0" ?>
<root>
  <section title="Introduction">Wordalignmentisanimportantcomponentinstatisticalmachinetranslation(SMT).Forinstancephrase-basedSMTisbasedontheconceptofphrasepairsfrombilingualdatawithwordalignmentannotation.Similarly,themodelforhierarchicalphrase-basedSMTisbuiltfromexhaustivelyextractedphrasesthatare,inturn,heavilyreliantonwordalignment.TheGenerativewordalignmentmodels,suchastheIBMModelsandHMM,arepopularmethodsforautomaticallyaligningbilingualtexts.However,theyarerestrictedtorepresentone-to-manycorrespondenceofeachword.Toresolvethisweakness,varioussymmetrizationmethodsareproposed.OchandNey(2003)andKoehnetal.(2003)proposevariousheuristicmethodstocombinetwodirectionalmodelstorepresentmany-to-manyrelationships.Asanalternativetoheuristicmethods,filteringmethodsemployathresholdtocontrolthetrade-offbetweenprecisionandrecallbasedonascoreestimatedfromtheposteriorprobabilitiesfromtwodirectionalmodels.proposedarithmeticmeansoftwomodelsasascoreforthefiltering,whereasreportedbetterresultsusinggeometricmeans.Thejointtrainingmethodenforcesagreementbetweentwodirectionalmodels.Posteriorregularizationisanalternativeagreementmethodwhichdirectlyencodesagreementduringtraining.DeNeroandMacherey(2011)andalsoenforceagreementduringinference,nottraining.However,theseagreementmodelsdonottakeintoaccountthedifferenceinlanguagepairs,whichiscrucialforlinguisticallydifferentlanguagepairs,suchasJapaneseandEnglish:althoughcontentwordsmaybealignedwitheachotherbyintroducingsomeagreementconstraints,functionwordsaredifficulttoalign.Thisisbecausethefunctionwordshavemanyrolesinasingleword.reportedlargergainsagainstaheuristicbaselinebyaspecialtreatmentforfunctionwords.Howevertheirmethodreliedondependencyanalysisfordiscriminatingfunctionwords.Wefocusontheposteriorregularizationframeworkandimproveuponthepreviousworkbyproposingnewconstraintfunctionsthattakeintoaccountthedifferenceinlanguagesintermsofcontentwordsandfunctionwords.Inparticular,weconcentrateonamethodwhichdoesnotrelyondeepersyntacticanalysisanddifferentiatecontentwordsandfunctionwordsbythefrequencyinbilingualdata,followingSetiawanetal.(2007).Inthiswork,contentwordsandfunctionwordsarediscriminatedbasedonthefrequencyonagivendatabytreatinghighfrequentwordsasfunctionwordsandlowfrequentwordsascontentwords.Thedifferenceofafunctionwordandacontentwordisdirectlyreflectedbyourproposedthreeconstraints:f2fconstraintrewardsposteriorprobabilityofalignmentsbetweenafunctionwordandafunctionword,c2cconstraintrewardsposteriorprobabilityofalignmentsbetweentwocontentwords,f2cconstraintpenalizeposteriorprobabilityofalignmentsbetweenafunctionwordandacontentword.Thesethreefinegrainedagreementconstraintsareusedasasymmetricconstraintfortheposteriorregularizationframework.ExperimentalresultsshowthattheproposedmethodsachievedbetteralignmentqualitiesontheFrench-EnglishHansarddataandtheJapanese-EnglishKyotofreetranslationtask(KFTT)measuredbyAERandF-measure.Intranslationevaluations,weachievedstatisticallysignificantgainsinBLEUscoresintheNTCIR10Japanese-EnglishtaskandWMT06Spanish-Englishtask.Theremainderofthispaperisorganizedasfollows.Sectiondescribestherelatedworkofone-directionalandbidirectionalwordalignment.SectiondescribesthesummaryofPosteriorRegularizationFrameworkandGanchev'ssymmetricconstraint.Sectiondescribesourproposedtwoconstraintfunctions,matchingandmismatchingconstraintfunctions.Sectiondescribesthecomparisonbetweenprevioussymmetricfunctionandourproposedconstraintfunctionsagainstvariouslanguagepairs.SectiondescribestheanalysisanddiscussionoftheresultsofExperiments.Sectiondescribestheconclusionandfuturework.Thispaperisanextensionofourpriorworkwithmoredetailsandexperiments.</section>
  <section title="Related Work">IBMModelsandHMMarepopulargenerativemodelsforrepresentingwordalignmentinbilingualtexts.Oneoftheshortcomingsofthesemodelsistheone-to-manyrestriction,inwhicheachtargetwordcanbealignedtojustasinglesourceword.Asaresult,OchandNey(2003)andKoehnetal.(2003)presentedvarioussymmetrizationmethodsinwhichViterbialignmentsfromtwodirectionalmodelsareheuristicallycombinedtoyieldmany-to-manyalignments.Theirheuristicmethodsworkmostlyfinethoughtheycannotclearlytakeintoaccounttheposteriorprobabilityofwordalignmentsonvariousgranularities.Somegenerativemodelscandirectlyinducephrasalstructureswithoutone-to-manywordalignmentconstraints.Thesemethodscanlearncompactphrasepairswithcomparativetranslationqualityagainstheuristicextractionmethods.Howeverthesemethodstakelongtimeforinference.Fromthesereasons,heuristicextractionsarestillusedinvariousNLPtasks.Asanalternativetoheuristicmethods,filteringmethodsemployathresholdtocontrolthetrade-offbetweenprecisionandrecallbasedonascoreestimatedfromtheposteriorprobabilitiesfromtwodirectionalmodels.Matusovetal.(2004)proposedarithmeticmeansoftwomodelsasascoreforthefiltering,whereasLiangetal.(2006)reportedbetterresultsusinggeometricmeans.Bothmethodscangeneratebidirectionalalignmentsbasedonposteriorprobabilitywithvariousgranularities.However,thesemodelsstillseparatelylearningthetwodirectionalalignmentmodels.Forthisreason,bothmodelssometimesmisalignthebidirectionalalignments.Insteadoftrainingtwomodelsindependently,Liangetal.(2006)proposesimultaneoustrainingoftwomodels,inaparallelmanner,bymaximizingtheproductofthetwomodelsduringtheM-stepintheEM-algorithm.TheE-stepisintractableevenwithasimplervariantofIBMModels,sincesummingoverallpossiblealignmentspaceinvolvesenumerationofallbidirectionalalignmentsets.Tosolvetheproblem,theyuseaheuristicapproximationbysimplyconsideringtheproductoftwomodels.Model-BasedAlignerCombinationenforcesagreementduringtheinferencestep.Sincetheinferenceovertwodirectionalmodelsisintractable,theyemploydualdecompositionasanapproximatedinference.ConstrainedViterbiRelaxationallowsevenfasterinferencewithguaranteedoptimality.Ganchevetal.(2010)introduceaposteriorregularizationframeworkthatinvolvesregularizationofposteriorprobabilitiestomatchacertainconstraintduringtheE-stepintheEM-algorithm.Usingtheapproximationthroughdualdecomposition,thisframeworkcanusevariousconstraintsasafunctiontoincorporatepriorknowledge.Theyproposeagreementconstraints,orfeatures,oftwowordalignmentmodels,whichcancorrecttheposteriorprobabilityofawordalignmentduringtraining.Ganchevetal.(2010)andDeNeroandMacherey(2011)aresimilarinthespiritofgeneratingbidirectionallyagreedwordalignment.However,theydifferinthatGanchevetal.(2010)enforcesagreementoftwodirectionalmodelsusingdualdecompositioninthetrainingstep,whereasthatofDeNeroandMacherey(2011)isintheinferencestep.proposedamethodtoimprovewordalignmentaccuraciesbydifferentiatingfunctionwordsusingdependencytrees.However,theirmethodstronglyreliesontheaccuraciesofdependencytreesandsuchtreesmaynotbeavailabletounder-resourcedlanguages.</section>
  <section title="Statistical Word Alignment with Posterior Regularization Framework"/>
  <subsection title="Overview">PosteriorregularizationframeworkisaninstanceofconstrainedEMalgorithminwhichpriorknowledgecanbeeasilyintroducedasasoftconstraint.InE-stepofEMalgorithm,posteriorregularizationframeworkmodifytheposteriorprobabilitysuchthatitmaynotviolateagivenconstraint.Inwordalignmenttask,asymmetricconstraintisusedtoenforcetwoindependentdirectionalalignmentmodelstoagreewitheachotherbymovingtheposteriorprobabilitiesforeveryalignmentbetweenasourcewordandatargetword.FigureshowsanexampleofsymmetricconstraintunderposteriorregularizationframeworkforaJapanese-Englishsentencepair,``kuroiinuganihikiita.''and``Thereweretwoblackdogs.''witheachbarrepresentingtheposteriorprobabilityforeachwordalignment.ThemassinthetopleftaretheposteriorprobabilitiesforEnglish-to-Japanesealignmentmodeldenotedasp,andthemassinthetoprightarethoseforJapanese-to-Englishalignmentmodeldenotedasp.Thetwodistributionsaretransferredasnewposteriorprobabilitiesafteragreementunderposteriorregularizationdenotedbyq.TheprobabilityofalignmentbetweenJapaneseword``hiki''andEnglishword``two''islowerthanthatofJapaneseword``hiki''andEnglishword``dogs''inJapanese-to-Englishalignment.Ontheotherhand,theprobabilityofalignmentbetweenJapaneseword``hiki''andEnglishword``two''islowerthanthatofJapaneseword``hiki''andEnglishword``There''inEnglish-to-Japanesealignment.ThesymmetricconstraintenforcesweightedarithmeticmeansoftheprobabilityofbothJapanese-to-EnglishandEnglish-to-Japanesealignmentsasaposteriorprobabilityofbidirectionalalignmentduringtraining.Throughthetrainingwithsymmetricconstraint,theprobabilityofalignmentbetweenJapaneseword``hiki''andEnglishword``two''ishigherthanthatof``hiki''and``dogs''and``hiki''and``There''intheagreedbidirectionalalignment.</subsection>
  <subsection title="Symmetric Constraint">Inthissection,weexplainthedetailofsymmetricconstraintunderposteriorregularizationframework.Givenabilingualsentencex=(x^s,x^t)wherex^sandx^tdenoteasourceandtargetsentence,respectively,andthebilingualsentenceisalignedbyawordalignmentdenotedbyy.Inparticular,y_i,j=1,ifasourcewordx^s_iisalignedtoatargetwordx^t_j(otherwisey_i,j=0)wherewedefinetheindexofx^t,x^sasi,j(1i|x^t|,1j|x^s|).Werepresentposteriorprobabilitiesfromtwodirectionalwordalignmentmodelsasp_(y|x)andp_(y|x)witheacharrowindicatingaparticulardirection,andusetodenotetheparametersofthemodels.Toexplainthedirectionalmodels,weadditionallydenoteadirectionalwordalignmentasa.Notethatanalignmenta_i=jisequivalenttoy_i,j=1.Forinstance,aisasetofthealignmentfromx^stox^tunderthemodelofp(x^t,y|x^s)inwhicheachtargetwordisalignedwithatmostonesourceword.InthecaseofIBMModel1,leta_iisanalignmentoftargetwordx^t_iandp_tisawordtranslationprobability,themodelisrepresentedasfollows:NotethatEquation()assumesaspecialNULLsymbollocatedatthe0thpositioninx^sdenotedasx_0^s.Themodelfortheinversedirectionp(x^s,y|x^t)isdefinedsimilarlyusingaspecialNULLsymbolforx_0^t.Theposteriorprobabilitiesaredefinedasfollows:wherej'(0j'|x^s|)isanindexofx^s.Wedenoteasetofalignmentsgeneratedbyasource-to-targetmodelasYandbyatarget-to-sourcealignmentmodelasY.Herein,weassumethattheposteriorprobabilityforbothdirectionalalignmentiszero(i.e.,p(y|x)=0foryY),inwhichanalignmentmaybepossibleinonedirection,butnotintheotherduetotheone-to-manyrestriction.Giventhetwodirectionalmodels,wedefineasymmetricfeatureforeachtarget/sourcepositionpair,i,jasfollows:whereZ(i,j)=(yY)(y_i,j=1)andZ(i,j)=(yY)(y_i,j=1).Thefeatureassigns1toanalignmentofY,butassigns-1toanelementofY.Asaresult,ifawordpairi,jisalignedwithequalposteriorprobabilitiesintwodirections,expectationofthefeaturevaluewillbezero.Wedefineajointmodelthatcombinestwodirectionalmodelsbyarithmeticmeans:Undertheposteriorregularizationframework,weinsteaduseqparameterizedbyforeachbilingualdataxasfollows:tosatisfythefollowingconstraint:IntheE-stepofEM-algorithm,weemployq_insteadofp_toaccumulatefractionalcountsforitsuseintheM-step.intheq_controlsthetwodirectionalposteriorprobabilitiesp_andp_forasymmetricalwordalignment.Forexample,alarge_i,jincreasesq__i,j(y_i,j=1|x)anddecreasesq__i,j(y_i,j=1|x).Conversely,asmall_i,jdecreasesq__i,j(y_i,j=1|x)andincreasesq__i,j(y_i,j=1|x).Whentheconstraint()issatisfied,q__i,j(y_i,j=1|x)andq__i,j(y_i,j=1|x)aresymmetrical.isefficientlyestimatedbythegradientascentforeachbilingualsentencex.Notethatposteriorregularizationisperformedduringparameterestimation,andnotduringtesting.</subsection>
  <section title="Posterior Regularization with Frequency Constraint">ThesymmetricconstraintmethodrepresentedinEquation()assumesastrongone-to-onerelationforanyword,anddoesnottakeintoaccountthedivergenceinlanguagepairs.Forlinguisticallydifferentlanguagepairs,suchasJapanese-English,contentwordsmaybeeasilyalignedone-to-one,butfunctionwordsarenotalwaysalignedtogether.FigureisanexampleofawrongalignmentbetweenanEnglishfunctionword``There''toaJapanesecontentword``hiki''.NotethatJapaneseword``hiki''isacounterword.Theseerrorsmayimpacttheend-to-endtranlslationqualities.Inordertosolvetheproblem,weimproveGanchev'ssymmetricconstraintsothatitcanconsiderthedifferencebetweencontentwordsandfunctionwordsineachlanguage.Inparticular,wefollowthefrequency-basedideaofSetiawanetal.(2007)thatdiscriminatescontentwordsandfunctionwordsbytheirfrequencies.Weproposeconstraintfeaturesthattakeintoaccountthedifferencebetweencontentwordsandfunctionwords,determinedbyafrequencythreshold.</section>
  <subsection title="Discriminating Content Words and Function Words">Setiawanetal.(2007)discriminatedcontentwordsandfunctionwordsbytheirfrequencyusingathreshold,andsuccessfullyemployedtheknowledgeforabetterhierarchicalgrammar.Intuitively,thefrequencyforfunctionwordsishighwhereasthatforcontentwordsislow.However,theyemployedafixedconstantasthethresholdparameter,whichislargelyinfluencedbythedatasize.BisazzaandFederico(2012)solvedthisproblembyintroducingathresholddeterminedbytheratioofveryfrequentwords.Inparticular,thethresholdthisdeterminedasthemaximumfrequencythatsatisfiesthefollowingcondition:Here,weempiricallysetr=0.5.Ifawordhashigherfrequencythanthethresholdth,wetreatthewordasafunctionword,otherwise,wetreatthewordasacontentword.</subsection>
  <subsection title="Mismatching Constraint">First,weproposeamismatchingconstraintthatpenalizeswordalignmentbetweencontentwordsandfunctionwordsbydecreasingthecorrespondingposteriorprobabilities.Thisconstraintfunctionpenalizesalignmentforfunctiontocontentorcontenttofunctionwordmatching,namelyf2c.FigureisanexampleofposteriorprobabilityofanalignmentbetweenanEnglishfunctionword``There''toaJapanesecontentword``hiki''.Inthisexample,theposteriorprobabilityofJapanese-to-Englishdirectionislowerthantheother,andthustheposteriorprobabilityisloweredforthebidirectionalmodelunderthemismatchingconstraint.UsingfunctionsZ(i,j)=(yY)(y_i,j=1)andZ(i,j)=(yY)(y_i,j=1)bothdefinedinEquation(),andF2C(x^t_i,x^s_j)=((x^t_iF^tx^s_jC^s)(x^t_iC^tx^s_jF^s)),thef2cconstraintfunctionforawordpair(x^t_i,x^s_j)isformallydefinedasfollows:where_i,j(x,y)=p_(y_i,j=1|x)-p_(y_i,j=1|x)isthedifferenceintheposteriorprobabilitiesbetweenthesource-to-targetandthetarget-to-sourcealignments.C^sandC^trepresentcontentwordsinthesourcesentenceandtargetsentence,respectively.Similarly,F^sandF^tarefunctionwordsinthesourceandtargetsentence,respectively.Intuitively,whenthereexistsamismatchincontentwordandfunctionwordforawordpair(x^t_i,x^s_j),theconstraintfunctionreturnsanon-zerovalueforthemodelwiththehighestposteriorprobability.Whencoupledwiththeconstraintsuchthattheexpectationofthefeaturevalueiszero,theconstraintfunctiondecreasestheposteriorprobabilityofthehighestdirectionanddiscouragesagreementwitheachotherformatchingwithacontentwordandafunctionword.Similarlythesymmetricconstraint,controlsthetwodirectionalposteriorprobabilitiesq_andq_forpenalizingwordalignmentbetweencontentwordsandfunctionwords.Forexample,when(i,j)isawordpairbetweenacontentwordandafunctionword,andq__i,j(y_i,j=1|x)islargerthanq__i,j(y_i,j=1|x),thefirstandthethirdruleswouldfiresuchthatincreased_i,jmightpenalizeq__i,j(y_i,j=1|x)untilitreachesq__i,j(y_i,j=1|x).Similarly,thesecondandfourthruleswouldfirewhenq__i,j(y_i,j=1|x)islargerthanq__i,j(y_i,j=1|x),whichmightleadtodecreased_i,jtopenalizeq__i,j(y_i,j=1|x).Ify_i,jdoesnotsatisfyF2C(x^t_i,x^s_j),ourconstraint^f2c_i,joperatessimilarlyto^sym_i,jaccordingtothelastthreerules.</subsection>
  <subsection title="Matching Constraint">Incontrasttothemismatchingconstraint,oursecondconstraintfunctionrewardsalignmentforfunctiontofunctionwordmatching,namelyf2fandforcontenttocontentwordmatching,namelyc2c.isanexampleofposteriorprobabilityofanalignmentbetweenaEnglishcontentword``dogs''toaJapanesecontentword``inu''.Inthisexample,theposteriorprobabilityofEnglish-to-Japanesedirectionishigherthantheother;weprefertheEnglish-to-Japanesedirectionastheposteriorprobabilityforthebidirectionallyagreedmodel.UsingfunctionsZ(i,j)=(yY)(y_i,j=1)andZ(i,j)=(yY)(y_i,j=1)bothdefinedinEquation(),andC2C(x^t_i,x^s_j)=(x^t_iC^tx^s_jC^s),thec2cconstraintfunctionforawordpair(x^t_i,x^s_j)formallydefinedasfollows:Thisconstraintfunctionreturnsanon-zerovalueforawordpair(x^t_i,x^s_j)whentheyarecontentwords.Asaresult,pairsofcontentwordsareencouragedtoagreewitheachother,buttheotherpairs.Thefunctiontofunctionwordmatchingfunctionf2fcanbedefinedsimilarlybyreplacingC^sandC^tbyF^sandF^t,respectively.Likewise,thefunctiontocontentwordmatchingfunctionf2cisdefinedbyconsideringthematchingofcontentwordsandfunctionwordsintwolanguages.Similarlythesymmetricconstraint,controlsthetwodirectionalposteriorprobabilitiesq_andq_forencouragingwordalignmentbetweencontentwordsandfunctionwords.Forexample,when(i,j)isawordpairbetweenacontentwordandacontentword,andq__i,j(y_i,j=1|x)islargerthanq__i,j(y_i,j=1|x),thefirstandthethirdruleswouldfiresuchthatdecreased_i,jmightincreaseq__i,j(y_i,j=1|x)untilitreachesq__i,j(y_i,j=1|x).Similarly,thesecondandfourthruleswouldfirewhenq__i,j(y_i,j=1|x)islargerthanq__i,j(y_i,j=1|x),whichmightleadtoincreased_i,jtoincreaseq__i,j(y_i,j=1|x).Ify_i,jdoesnotsatisfyC2C(x^t_i,x^s_j),ourconstraint^c2c_i,joperatessimilarlyto^sym_i,jaccordingtothelastthreerules.</subsection>
  <section title="Experiment"/>
  <subsection title="Experimental Setup">WeusedFrench-EnglishHansardCorpusandJapanese-EnglishKyotofreetranslationtask(KFTT)forwordalignmentevaluation.Inthemachinetranslationevaluation,weusedtheGerman-English,Spanish-EnglishandFrench-EnglishWMT06witheuroparl-v7trainingdatasetandJapanese-EnglishNTCIR10.TheKFTTisderivedfromJapaneseWikipediaarticlesrelatedtoKyoto,whichistranslatedintoEnglishbyexperttranslators.NTCIR10comesfrompatentdataemployedinamachinetranslationsharedtask.ThestatisticofthesedataispresentedinTableand.Sentencesofover40wordsonbothsourceandtargetsidesareremovedfortrainingalignmentmodels.WeusecicadafortrainingtheHMMandIBMModel4withourproposedmethods.TrainingisbootstrappedfromIBMModel1,followedbyHMMandIBMModel4.Inbothwordalignmentandtranslationevaluation,weusedfilteringmethodwiththresholdparameter0.1fordetailedanalysis.Thisthresholdvaluewereselectedfrom0.1to0.9withinterval0.1throughpreliminarytests.</subsection>
  <subsection title="Word Alignment Evaluation">WemeasuretheimpactofourproposedmethodsonthequalityofwordalignmentmeasuredbyAERandF-measure.Weusedonlysurealignmentforcalculatingprecision,recallandF-measure.Forthedetailedanalysis,wealsoevaluatedwordalignmentsbyfocusingonparticularinstances,i.e.,function-to-function,content-to-contentandothercombinations(function-to-contentandcontent-to-function).TheseevaluationswereconductedforasubsetofwordsinbothreferenceandsystemoutputselectedbyPOS.Forexample,infunction-to-functionevaluation,weusedalignmentsbetweensourcesidefunctionwordsandtargetsidefunctionwords.Content-to-contentandfunction-to-contentwereevaluatedinthesamewayasthefunction-to-functionevaluation.Inthefunction-to-contentevaluation,weusednotonlyalignmentsbetweensourcesidefunctionwordandtargetsidecontentwords,butalsousedalignmentsbetweensourcesidecontentwordsandtargetsidefunctionwords.Fordescriminatingfunctionwordsfromcontentwords,weusedtheStanfordPOSTaggerforFrenchandEnglishsentences,andusedKyTeaforJapanesesentences.InFrenchandEnglishsentences,wetreatedawordwithalabelinasetCC,CD,TO,DT,UH,EX,IN,LS,WDT,MD,WP,WP,WRB,PDT,PRP,PRP,RP,SYM,TO,UHasafunctionword,andasetVB,VBD,VBG,JJ,VBN,JJR,VBP,JJS,VBZ,NN,NNS,NNP,NNPS,RB,RBR,RBSasacontentword.InJapanesesentences,wetreatedawordwithalabelinaset代名詞(pronoun),接続詞(conjunction),感動詞(interjection),助動詞(auxiliaryverb),助詞(particle),接頭辞(prefix),接尾辞(postfix),記号(symbol),補助記号(diacriticalmark)asafunctionword,andaset名詞(noun),連体詞(pre-nounadjectival),副詞(adverb),形容詞(adjective),形状詞(adjectivenoun),動詞(verb)asacontentword.Whengeneratingthefinalbidirectionalwordalignment,weusedagrow-diag-finalheuristicfortheJapanese-EnglishtaskandanintersectionheuristicfortheFrench-Englishtask,basedonpreliminarystudies.Tablesummarizesourresultsagainstallwordalignmentsinthereferences.TheGDFinthetablesdenotesaheuristitcextractionmethodgrow-diag-final,andFiltereddenotesthefilteringmethod.ThebaselinemethodissymmetricconstraintshowninTable.Thenumbersinboldandinitalicsindicatethebestscoreandthesecondbestscore,respectively.IntermsofF-measure,itisclearthatthef2fisthemosteffectiveconstraintforHansardwhileweachievedthebestscoreforthef2cinKFTT,andbothmethodsexceedtheoriginalposteriorregularizedmodelofGanchevetal.(2010).IntermsofAER,ourproposedf2cconstrainthaslittlegainagainstbaselinesymmetricconstraint.Ontheotherhand,ourproposedconstraintshavenogainagainstbaselineinHansardcorpus.Table,andsummarizesourresultsbydifferentiatingwordalignmenttypes,i.e.,function-to-function,content-to-contentandothers,respectively.Fromtheseresults,wecanobservethatourproposedconstraintfunctionsareeffectiveforfunction-to-functionandfunction-to-contentwordalignmentsinHansard,andfunction-to-functionandcontent-to-contentwordalignmentsinKFTT.Theseresultsmatchwithourexpectationthatthebaselinesymmetricconstraintisdifficulttoalignthefunctionwordpairs,comparedwithourproposedconstraints,asdiscussedintheintroductionsection.Figure~--arerecall-precisiongraphforeachcombinationofcorpusandmodels.Weplottedtherecallandprecisionbychangingthethresholdvalueoffilteringmethodoninterval0.01.FromFigure,theprecisionvalueofourproposedf2fconstraintunderHMMisbetterthanthatofthebaselinesymmetricconstraintatlowrecallarea.FromFigure,incontrasttotheHMM,theprecisionvaluesoff2fandf2cconstraintsunderIBMModel4arebetterthanthebaselinesymmetricconstraintathighrecallarea.However,fromFigureand,weobservedunstableperformanceforHansardtaskbothonHMMandIBMModel4anditishardtotellanysignificantdifferencewitheachother.Theseresultsmayindicatethatourproposedconstraintissuitableforgrammaticallydifferentlanguagepairs,suchasJapaneseandEnglish,underwordalignmenttask.WewillprovidemoredetailsinSection.</subsection>
  <subsection title="Translation Evaluation">Next,weperformedatranslationevaluation,measuredbyBLEU.Weusedthegrow-diag-finalandfilteringmethodforcreatingphrasetables.Thethresholdforthefilteringfactorwassetto0.1.FromtheEnglishsideofthetrainingdata,wetraineda5-gramlanguagemodelswithSRILM.``Moses''toolkitwasusedasaphrasebaseddecoderandthemodelparametersweretunedbyk-bestMIRA.Wesetthedistortion-limitas-1(infinite).WeusedotherparameterswithMosesdefaultvalues.Inordertoavoidtuninginstability,weevaluatedtheaverageoffiveruns.TheresultsaresummarizedinTable.Thenumbersinboldstylearenotsignificantlydifferentfromthebestresults(p-value&lt;0.05).Weusedstatisticalbootstrappingmethodforsignificancetest.OurproposedconstraintsachievedsignificantimprovementagainstbaselinesymmetricconstraintinNTCIR10taskandeuroparl-v7Spanish-English,butobservednogainintheotherlanguagepairsofeuroparl-v7.Theseresultsclearlyshowthatourproposedconstraintsareeffectiveongrammaticallydifferentlanguagepairsasobservedinthewordalignmentevaluation.TheBLEUscoreofgrow-diag-finalisbetterthanthatoffilteredmethodinNTCIR10,whereastheotherlanguagepairshavenodifference.TheBLEUscoresofIBMModel4andHMMarenotdifferentfromeachotherexceptforNTCIR10.Fromtheseresults,wecanconcludethattheIBMModel4combinedwithourproposedconstraintsundergrow-diag-finalisthemostrobustmethodtoperformwordalignmentforgrammaticallydifferentlanguagepairsindicatedbytheend-to-endevaluation.</subsection>
  <section title="Analysis">Wefoundthatourproposedmethodsweresuperiortothestrongbaselineintermsofrecall-precisionandAERforKFTTinthewordalignmentevaluations.However,inHansardFr-En,proposedconstraintshavelittleadvantageagainstthebaseline.Ourf2f,c2candf2cconstraintscanperformaccuratewordalignmenteitherbyrewardingorpenalisingcertainpairingsoffunctionandcontentwords.Inagrammaticallydifferentlanguagepairs,suchasJapaneseandEnglish,functionwordsandcontentwordsaresometimesmisalignedduetotheone-to-manylimitationofgenerativemodels,Asaresult,theproposedconstraintsmayworkbetteronKFTTJapanese-Englishcorpus.FigureandshowexamplesofwordalignmentproducedbyIBMModel4,inwhichcirclesandsquaresindicatewordalignmentwithandwithoutf2fconstraints,respectively.Thecirclesandsquarespaintedinblackrepresentthedifferencebetweenwithandwithoutf2fconstraints.InFigure,Japanesewords``muromachi''and``dai''shouldbecorrectlyalignedto``NULL''andanEnglishword``the''.Thebaselinesymmetricconstraintmisaligned``muromachi''and``the''.Ontheotherhand,thef2fconstraintcorrectlyaligned``dai''and``the''byrewardingthepairofhighlyfrequentwords.InFigure,Japanesewords``ninmei''and``rare''shouldbecorrectlyalignedtoEnglishwords``succeeded''and``were''.AlthoughtheJapaneseword``rare''andtheEnglishword``were''werecorrectlyalignedunderthef2fconstraint,misalignmentwasobservedfortheJapaneseword``ninmei''andtheEnglishword``post''.Sinceboth``rare''and``were''arefunctionwordsandusedforapassivevoice,ourproposedconstraintcaneasilyalignthetwowords.However,atthealignmentof``ninmeisare''and``succeeded'',``ninmeisare''isapassivevoiceand``succeeded''isanactivevoice.Becauseofthis,ourproposedconstraintcannoteasilyalignthesewords.Inadditiontothisdifficulty,astheJapanesephrase``kouninnokanreiniwayoshimasaganinmeisare''aretranslatedintoEnglishphrase``yoshimasasucceededtothepostofkanrei''byexperttranslators,ourf2fconstraintcouldnotcorrectthemissedalignment.Ingeneral,itisdifficulttoperformcorrectwordalignmentforthosephraseologicalexpressionsespeciallywhenmodelsarestronglyrestrictedtoone-to-manycorrespondence.</section>
  <section title="Conclusion">Inthispaper,weproposednewconstraintfunctionsundertheposteriorregularizationframework.Ourconstraintfunctionsintroducefine-grainedagreementconstraintconsideringthefrequencyofwords,assumingthatthehighfrequencywordscorrespondtofunctionwordswhereasthelessfrequentwordsmaybetreatedascontentwords,basedonthepreviouswork.ExperimentsonwordalignmenttasksshowedbetteralignmentqualitiesmeasuredbyF-measureandAERonKFTT.WealsoobservedlargegaininBLEU,0.2onaverage,whencomparedwiththepreviousposteriorregularizationmethodunderNTCIR10task.Fromtheanalysisofourconstraint,wecanconcluedthatconsideringphrasestructureisnecessaryforbetteralignmentandtranslationqualitiy.Asourfuturework,wewillinvestigatethephrasestructureconstraint,inreferencetothepreviousmany-to-manywordalignmentresearch,suchasITGbasedorsyntactictreebasedmodels.Ourproposedconstraintsarebasedonfeaturefunctions,andthesefunctionsareusedinacombinatorialmanneronvariousNLPtasks.However,weusedasinglefeaturefunctionforgeneratingwordalignments.Wewillalsoinvestigatethecombinatoryuseofourproposedconstraintsforbetteralignmentandtranslationqualitiy.wouldliketothankthereviewersfortheirdetailedcommentsandsuggestions,whicharehelpfultoimproveourmanuscripts.*document</section>
</root>
