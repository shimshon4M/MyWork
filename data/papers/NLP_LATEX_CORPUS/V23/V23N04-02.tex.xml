<?xml version="1.0" ?>
<root>
  <jtitle>統語ベース翻訳のための構文解析器の自己学習</jtitle>
  <jauthor>森下睦赤部晃一波多腰優斗GrahamNeubig吉野幸一郎中村哲</jauthor>
  <jabstract>構文情報を考慮する機械翻訳手法である統語ベース翻訳では，構文解析器の精度が翻訳精度に大きな影響を与えることが知られている．また，構文解析の精度向上を図る手法の一つとして，構文解析器の出力を学習データとして用いる構文解析器の自己学習が提案されている．しかし，構文解析器が生成する構文木には誤りが存在することから，自動生成された構文木が常に精度向上に寄与するわけではない．そこで本論文では，機械翻訳における自動評価尺度を用いて，このような誤った構文木を学習データから取り除き，自己学習の効果を向上させる手法を提案する．具体的には，解析されたn-best構文木それぞれを用いて統語ベース翻訳を行い，それぞれの翻訳結果に対し，自動評価尺度でリスコアリングする．この中で，良いスコアを持つ構文木を自己学習に使用することで，構文構造はアノテーションされていないが，対訳が存在するデータを用いて，構文解析・機械翻訳の精度を向上させることができる．実験により，本手法で自己学習したモデルを用いることで，統語ベース翻訳システムの翻訳精度が2つの言語対で有意に向上し，また構文解析自体の精度も有意に向上することが確認できた．</jabstract>
  <jkeywords>機械翻訳，構文解析，自己学習</jkeywords>
  <section title="はじめに">統計的機械翻訳(StatisticalMachineTranslation,SMT)では，翻訳モデルを用いてフレーズ単位で翻訳を行い，並べ替えモデルを用いてそれらを正しい語順に並べ替えるフレーズベース翻訳(PhraseBasedMachineTranslation)，構文木の部分木を翻訳に利用する統語ベース翻訳などの翻訳手法が提案されている．一般的に，フレーズベース翻訳は英仏間のような語順が近い言語間では高い翻訳精度を達成できるものの，日英間のような語順が大きく異なる言語間では翻訳精度は十分でない．このような語順が大きく異なる言語対においては，統語ベース翻訳の方がフレーズベース翻訳と比べて高い翻訳精度を達成できることが多い．統語ベース翻訳の中でも，原言語側の構文情報を用いるTree-to-String(T2S)翻訳は，高い翻訳精度と高速な翻訳速度を両立できる手法として知られている．ただし，T2S翻訳は翻訳に際して原言語の構文解析結果を利用するため，翻訳精度は構文解析器の精度に大きく依存する．この問題を改善する手法の一つとして，複数の構文木候補の集合である構文森をデコード時に利用するForest-to-String(F2S)翻訳が挙げられる．しかし，F2S翻訳も翻訳精度は構文森を作成した構文解析器の精度に大きく依存し，構文解析器の精度向上が課題となる．構文解析器の精度を向上させる手法の一つとして，構文解析器の自己学習が提案されている．自己学習では，アノテーションされていない文を既存のモデルを使って構文解析し，自動生成された構文木を学習データとして利用する．これにより，構文解析器は自己学習に使われたデータに対して自動的に適応し，語彙や文法構造の対応範囲が広がり，解析精度が向上する．しかし，自動生成された構文木は多くの誤りを含み，それらが学習データのノイズとなることで自己学習の効果を低減させてしまうという問題が存在する．Katz-Brownらは構文解析器の自己学習をフレーズベース翻訳のための事前並べ替えに適用する手法を提案している．フレーズベース翻訳のための事前並べ替えとは，原言語文の単語を目的言語の語順に近くなるように並べ替えることによって，機械翻訳の精度を向上させる手法である．この手法では，構文解析器を用いて複数の構文木候補を出力し，この構文木候補を用いて事前並べ替えを行う．その後，並べ替え結果を人手で作成された正解並べ替えデータと比較することによって，各出力にスコアを割り振る．これらの並べ替え結果のスコアを基に，構文木候補の中から最も高いスコアを獲得した構文木を選択し，この構文木を自己学習に使用する．このように，学習に用いるデータを選択し，自己学習を行う手法を標的自己学習(TargetedSelf-Training)という．Katz-Brownらの手法では，正解並べ替えデータを用いて，自己学習に使用する構文木を選択することで，誤った並べ替えを行う構文木を取り除くことができ，学習データのノイズを減らすことができる．また，Liuらは，単語アライメントを利用して構文解析器の標的自己学習を行う手法を提案している．一般に，構文木と単語アライメントの一貫性が取れている場合，その構文木は正確な可能性が高い．そのため，この一貫性を基準として構文木を選択し，それらを用いて構文解析器を学習することでより精度が向上することが考えられる．以上の先行研究を基に，本論文では，機械翻訳の自動評価尺度を用いた統語ベース翻訳のための構文解析器の標的自己学習手法を提案する．提案手法は，構文解析器が出力した構文木を基に統語ベース翻訳を行い，その翻訳結果を機械翻訳の自動評価尺度を用いて評価し，この評価値を基にデータを選択し構文解析器の自己学習を行う．統語ベース翻訳では，誤った構文木が与えられた場合，翻訳結果も誤りとなる可能性が高く，翻訳結果を評価することで間接的に構文木の精度を評価することができる．以上に加え，提案手法は大量の対訳コーパスから自己学習に適した文のみを選択し学習を行うことで，自己学習時のノイズを減らす効果がある．Katz-Brownらの手法と比較して，提案手法は事前並べ替えだけでなく統語ベース翻訳にも使用可能なほか，機械翻訳の自動評価尺度に基づいてデータの選択を行うため，対訳以外の人手で作成された正解データを必要としないという利点がある．これにより，既存の対訳コーパスが構文解析器の標的自己学習用学習データとして使用可能になり，構文解析器の精度やF2S翻訳の精度を幅広い分野で向上させることができる．また，既に多く存在する無償で利用可能な対訳コーパスを使用した場合，本手法におけるデータ作成コストはかからない．さらに，Liuらの手法とは異なり，翻訳器を直接利用することができる利点もある．このため，アライメント情報を通して間接的に翻訳結果への影響を計測するLiuらの手法に比べて，直接的に翻訳結果への影響を構文木選択の段階で考慮できる．実験により，提案手法で学習した構文解析器を用いることで，F2S翻訳システムの精度向上と，構文解析器自体の精度向上が確認できた．</section>
  <section title="Tree-to-String翻訳">SMTでは，原言語文fが与えられた時に，目的言語文eへと翻訳される確率Pr(e|f)を最大化するeを推定する問題を考える．様々な手法が提案されているSMTの中でも，T2S翻訳は原言語文の構文木T_fを使用することで，原言語文に対する解釈の曖昧さを低減し，原言語と目的言語の文法上の関係をルールとして表現することで，より精度の高い翻訳を実現する．T2S翻訳は下記のように定式化される．e&amp;_ePr(e|f)&amp;=_e_T_fPr(e|f,T_f)Pr(T_f|f)&amp;_e_T_fPr(e|T_f)Pr(T_f|f)&amp;_ePr(e|T_f)alignただし，T_fは構文木の候補の中で，最も確率が高い構文木であり，下記の式で表される．図に示すように，T2S翻訳で用いられる翻訳ルールは，置き換え可能な変数を含む原言語文構文木の部分木と，目的言語文単語列の組で構成される．図の例では，x_0，x_1が置き換え可能な変数である．これらの変数には，他のルールを適用することにより翻訳結果が挿入され，変数を含まない出力文となる．訳出の際は，翻訳ルール自体の適用確率や言語モデル，その他の特徴などを考慮して最も事後確率が高い翻訳結果を求める．また，ビーム探索などを用いることで確率の高いn個の翻訳結果を出力することが可能であり，これをn-best訳という．T2S翻訳では，原言語文の構文木を考慮することで，語順が大きく異なる言語対の翻訳がフレーズベース翻訳と比べて正確になる場合が多い．しかし，T2S翻訳は翻訳精度が構文解析器の精度に大きく依存するという欠点がある．この欠点を改善するために，複数の構文木を構文森と呼ばれる超グラフ(Hyper-Graph)の構造で保持し，複数の構文木を同時に翻訳に使用するF2S翻訳が提案されている．この場合，翻訳器は複数ある構文木の候補から構文木を選択することができ，翻訳精度の改善が期待できる．F2S翻訳はeとT_fの同時確率の最大化として下記のように定式化される．e,T_f&amp;_e,T_fPr(e,T_f|f)&amp;_e,T_fPr(e|T_f)Pr(T_f|f)alignしかし，節で述べたとおりF2S翻訳であっても翻訳精度は構文森を生成する構文解析器の精度に大きく依存する．そこで，この問題を解決するため，自己学習によって構文解析器の精度を向上する手法について説明する．</section>
  <section title="構文解析の自己学習"/>
  <subsection title="自己学習の概要">構文解析器の自己学習とは，既存のモデルで学習した構文解析器が解析・生成した構文木を学習データとして用いることで，構文解析器を再学習する手法である．言い換えると，自己学習対象の各文に対して，式()に基づいて確率が最も高い構文木T_fを求め，この構文木を構文解析器の再学習に用いる．この手法は追加のアノテーションを必要としないため，構文解析器の学習データ量が大幅に増え，解析精度が向上する．Charniakは，WallStreetJournal(WSJ)コーパスによって学習された確率文脈自由文法(ProbabilisticContext-FreeGrammar,PCFG)モデルを用いた構文解析器では，自己学習の効果は得られなかったと報告している．一方で，潜在クラスを用いることで構文解析の精度を向上させたPCFG-LA(PCFGwithLatentAnnotations)モデルは自己学習により大幅に解析精度が向上することが知られている．これは，PCFG-LAモデルを用いることで自動生成された構文木の精度が比較的高くなることに加え，PCFG-LAモデルが通常のPCFGモデルと比べて多くのパラメータを持つので，学習データが増加する恩恵が大きいことが理由として挙げられる．これらの先行研究を基にして，本論文ではPCFG-LAモデルを用いた構文解析器の自己学習を考える．</subsection>
  <subsection title="機械翻訳における構文解析器の自己学習と効果"/>
  <subsubsection title="事前並べ替えのための標的自己学習">節でも述べたように，構文解析器の自己学習により機械翻訳精度を改善した研究が存在する．Katz-Brownらは，自己学習に使用する構文木を外部評価指標を用いて選択する手法を提案し，これにより翻訳精度自体も向上したと報告している．この手法の概要を図に示す．この研究では，構文解析器により複数の構文木候補を自動生成し，これらの候補を基にした事前並べ替えの結果が人手で作成した正解並べ替えデータに最も近いものを選択し，自己学習に使用する．これにより，構文木の候補からより正しい構文木を選択することができるため，自己学習の効果が増すと報告されている．このように一定の基準を基に学習データを選択し，自己学習を行う手法を標的自己学習(TargetedSelf-Training)という．事前並べ替えでは，構文木T_fに基づいて，並べ替えられた原言語文f'を生成する並べ替え関数reord(T_f)を定義し，システムによる並べ替えを正解並べ替えf'^*と比較するスコア関数score(f'^*,f')で評価する．学習に使われる構文木T_fは，構文木の候補T_fから以下の式によって選択される．本論文ではこれらの先行研究を基に，統語ベース翻訳のための構文解析器の標的自己学習手法を提案する．節以降において，提案手法の詳細を示し，実験により提案手法の効果を検証する．</subsubsection>
  <subsubsection title="フロンティアノードを利用した構文解析器の標的自己学習">統語ベース翻訳を利用して構文解析器の標的自己学習を行う手法として，フロンティアノード(FrontierNode)を利用する手法が提案されている．一般に，構文木と単語アライメントの一貫性が取れている場合，その構文木は正確な可能性が高い．この一貫性を評価する指標として，フロンティアノードの数が挙げられる．フロンティアノードとは，対象ノードから翻訳ルールを抽出できるノードのことを指す．例として，5つのフロンティアノードを持つ構文木を図に示す．図中の灰色で示されたノードがフロンティアノードである．各ノード中の数字は上から順にスパン(span)，補完スパン(complementspan)を示している．ノードNのスパンとは，ノードNから到達可能な全ての目的言語単語の最小連続単語インデックスの集合であり，ノードNの補完スパンとは，NおよびNの子孫ノード以外のノードに対応する，目的言語単語インデックスの和集合とする．フロンティアノードは，スパンと補完スパンが重複しておらず，かつスパンがnullでないという条件を満たすノードのことを指す．フロンティアノードの数が多いほど，構文木と単語アライメントの一貫性が取れているといえる．例えば，「助詞のP」のスパンは3-5であり，``ofthisrestaurant''に対応する．また，補完スパンは1-2,4であり，``thespeciality'',``this''に対応する．この場合，3-5のスパンと，4の補完スパンが部分的に重複しているためフロンティアノードではない．Liuらの手法では，構文解析結果の5-bestの中からフロンティアノードの数が最も多くなる構文木を選択し，選ばれた構文木を自己学習に使用する．これにより，5-best中で最も精度が高いと考えられる構文木を選択することができ，従来の自己学習手法よりも効果が高くなる．この手法で自己学習した構文解析器により，統語ベース翻訳の翻訳精度が有意に改善されたと報告されている．本論文では，Liuらの手法も比較対象として実験を行う．</subsubsection>
  <section title="統語ベース翻訳のための構文解析器の標的自己学習">標的自己学習において，どのように自己学習用のデータを選択するかは最も重要な点である．本論文ではF2S翻訳の精度を向上させるために，自己学習に使用する構文木および文の選択法をいくつか提案する．構文木の選択法を用いることで，一つの文の構文木候補から精度向上につながる構文木を選択し，文の選択法を用いることで，コーパス全体から精度向上に有効な文のみを選択する．以降ではそれぞれの手法について説明する．</section>
  <subsection title="構文木の選択法">節で述べたように，Katz-Brownらによって提案された標的自己学習手法では，自動生成された構文木と人手で作成した正解並べ替えデータを比較することにより，n-best候補の中から最も評価値の高い構文木を選択する．しかし，人手で正解並べ替えデータを作成するには大きなコストがかかるため，この手法のために大規模なデータセットを作成することは現実的でない．一方で，統計的機械翻訳は対訳コーパスの存在を前提としており，対訳データは容易に入手できることが多い．そこで，この問題を解決するために，対訳コーパスのみを使用して構文木を選択する方法を2つ提案する．一つは，翻訳器によって選択された1-best訳に使われた構文木を自己学習に使用する手法である（翻訳器1-best）．もう一つは，n-best訳の中から，最も参照訳に近い訳（Oracle訳）を自動評価尺度により選択し，Oracle訳に使われた構文木を自己学習に使用する手法である（自動評価尺度1-best）．</subsection>
  <subsubsection title="翻訳器1-best">節でも述べたように，F2S翻訳では，構文森から翻訳確率が高くなる構文木を翻訳器が選択する．先行研究では，翻訳ルールや言語モデルの確率を使用することで，F2S翻訳器は構文森から正しい構文木を選択する能力があることが報告されている．翻訳器の事後確率を用いることで，構文解析器だけでは考慮できない特徴を使用して構文木を選択するため，F2S翻訳器が出力した1-best訳に使われた構文木は，構文解析器が出力した1-best構文木よりも自己学習に効果的だと考えられる．この際の自己学習に使われる構文木は式()のT_fとなる．</subsubsection>
  <subsubsection title="自動評価尺度1-best">翻訳の際，翻訳器は複数の翻訳候補の中から，最も翻訳確率が高い訳を1-best訳として出力する．しかし，実際には翻訳候補であるn-best訳の方が，翻訳器が出力した1-best訳よりも翻訳精度が高いと考えられる場合が存在する．そこで本論文では，翻訳候補の集合Eの中から最も参照訳e^*に近い訳をOracle訳eと定義し，eに使われた構文木を自己学習に使用する．翻訳候補eと参照訳e^*の類似度を表す評価関数score()を用いて，Oracle訳eは下記の通り表される．</subsubsection>
  <subsection title="文の選択法">節では，1つの対訳文のn-best訳から学習に有用だと考えられる構文木を選択する方法について述べた．しかし，正しい訳がn-best訳の中に含まれていない場合もあり，これらの例を学習に用いること自体が構文解析器の精度低下を招く可能性がある．そのため，n-best訳の中に良い訳が含まれていない場合その文を削除するように，学習データ全体から自己学習に用いる文を選択する手法を提案する．具体的には，翻訳文の自動評価値が一定の閾値を超えた文のみを学習に使用する（自動評価値の閾値）．また，学習データ全体から翻訳精度を改善すると考えられる構文木を選択する手法も提案する．具体的には，翻訳器1-best訳とOracle訳の自動評価値の差が大きい文のみを使用する（自動評価値の差）．従来の標的自己学習手法では，構文木の選択手法は提案されていたものの，文の選択手法については検討されていなかった．本論文では，この文の選択手法についても検討を進める．文の選択法を使用する場合は，構文木の選択法として，自動評価尺度1-bestを使用する．自動評価尺度1-bestを用いて構文木を選択する手法と，文の選択法を組み合わせた提案手法を図にすると，図のようになる．図のように原言語文を構文解析器に入力し，出力された構文森を翻訳器に入力する．これによりn-best訳と，翻訳に使われた構文木のペアが出力される．その後，参照訳を基に自動評価尺度を用いてn-best訳をリスコアリングする．これを基に学習データを選択し，自己学習を行う．</subsection>
  <subsubsection title="自動評価値の閾値">本節では，学習のノイズとなる誤った構文木を極力除外するために，自動評価値を基にデータを選択する手法を提案する．コーパスの中には，翻訳器が正しく翻訳することができず，自動評価値が低くなってしまう文が存在する．自動評価値が低くなる原因としては以下のような理由が考えられる．誤った構文木が翻訳に使用された．翻訳モデルが原言語文の語彙やフレーズに対応できていない．自動評価値を計算する際に用いられる参照訳が，意訳となっていたり，誤っていたりするため，翻訳器が参照訳に近い訳を出力することができない．このような場合は，たとえOracle訳であっても自動評価値は低くなってしまうことがある．これらのデータは，F2S翻訳器が正しい構文木を選択することができていない場合や，自動評価尺度が実際の翻訳品質との相関が低い場合があるため，Oracle訳で使われた構文木であっても誤った構文情報を持つ可能性がある．そのため，これらのデータを学習データから取り除くことで，学習データ中のノイズが減ると考えられる．そこで，より正確な構文木のみを使用するために，Oracle訳の自動評価値が一定の閾値を超えた文のみ学習に使用する手法を提案する．自己学習に使用される構文木T_f^(i)の集合は下記の式のように定義される．ここで，tは閾値，e^*(i)は文iの参照訳，e^(i)は文iのOracle訳，EはOracle訳全体の集合，score(e)は訳の自動評価関数を示す．</subsubsection>
  <subsubsection title="自動評価値の差">本節では，翻訳結果を大きく改善すると考えられる構文木を中心に選択する手法を提案する．この際に着目した指標は，翻訳器1-best訳とOracle訳の自動評価値の差である．構文解析器により誤った構文木が高い確率を持った構文森が出力された場合，翻訳器は誤った構文木を選択し，誤った翻訳を1-best訳として出力することが多い．一方，Oracle訳では構文森の中から正しい構文木が使われた可能性が高い．そのため，翻訳器1-best訳とOracle訳の自動評価値の差が大きい場合，Oracle訳に使われた構文木を学習データとして使用することで，構文解析器が出力する確率が正しい値へ改善される可能性がある．これにより，自己学習した構文解析器を用いた翻訳システムは正しい訳を1-best訳として出力するようになり，翻訳精度が向上すると考えられる．文を選択するために，翻訳器1-best訳e^(i)とOracle訳e^(i)の自動評価値の差を表す関数gain(e^(i),e^(i))を定義し，式()と同様に，自動評価値の差が大きい文の構文木を選択する．自動評価値の差を表す関数gain(e^(i),e^(i))は下記のように定義される．本手法ではこれに加えて，学習に用いる文の長さの分布をコーパス全体と同様に保つため，Gasc'oらによって提案された下記の式を用いて，文の長さに応じて選択数を調節する．以下の式では，|e|は目的言語文eの長さ，|f|は原言語文fの長さ，N_c(|e|+|f|)はコーパス全体で目的言語文，原言語文の長さの和が|e|+|f|となる文の数，N_cはコーパス全体の文数を表す．N_tを自己学習データ全体の文数とすると，自己学習データの内，目的言語文，原言語文の長さの和が|e|+|f|となる文数N_t(|e|+|f|)は下記の式で表される．</subsubsection>
  <section title="評価"/>
  <subsection title="実験設定">本論文では，日本語の構文解析器を用いる日英・日中翻訳（それぞれJa-En，Ja-Zhと略す）を対象に実験を行った．翻訳データとして，科学論文を抜粋した対訳コーパスであるASPECを用いた．ASPECに含まれる対訳文数を表に示す．自己学習の効果を検証するためのベースラインシステムとして，アジア言語間での翻訳ワークショップWorkshoponAsianTranslation2014(WAT2014)において高い精度を示した，Neubigのシステムを用いた．デコーダにはTravatarを用い，F2S翻訳を行った．構文解析器にはで最も高い日英翻訳精度を実現したPCFG-LAモデルに基づくEgretを用い，日本語係り受けコーパス(JDC)（約7,000文）に対してTravatarの主辞ルールで係り受け構造を句構造に変換したものを用いて学習したモデルを，ベースラインの構文解析器として使用した．構文森は100-best構文木に存在するhyper-edgeのみで構成し，その他については枝刈りした．機械翻訳の精度はBLEUとRIBESの2つの自動評価尺度，Acceptabilityという人手評価尺度を用いて評価した．また，文単位の機械翻訳精度はBLEU+1を用いて評価した．自己学習に用いるデータは既存のモデルで使用しているJDCに加え，ASPECのトレーニングデータの中から選択されたものとした．自己学習したモデルは，テスト時にDevセット，Testセットを構文解析する際のみに使用し，TrainセットについてはJDCで学習した既存のモデルで行った．Trainセットについても自己学習したモデルで構文解析することにより，さらなる精度向上の可能性はあるが，翻訳器を学習し直すには多くの計算量が必要になってしまう．そのため，本実験ではDevセット，Testセットについてのみ自己学習したモデルで構文解析を行った．実験で得られた結果は，ブートストラップ・リサンプリング法により統計的有意差を検証した．次節では，下記の手法を比較評価する．なお文をランダムに抽出する場合は，日英翻訳では全トレーニングデータの1/20，日中翻訳では1/10を抽出した．また，他の手法とほぼ同様の文数となるように，BLEU+1Gainに関しては上位10万文を抽出した．以下，節では，自己学習した構文解析モデルを使用して翻訳を行った際の翻訳器の精度評価，節では，構文解析器の精度評価を行う．</subsection>
  <subsection title="翻訳器の精度評価">各手法で自己学習した構文解析器を用いて，翻訳精度の変化を確認する．節では自動評価尺度を用いた評価結果を示し，節で人手評価による評価結果を示す．また，節では提案手法により改善された翻訳例を示し，どのような場合に提案手法が有効かを検討する．</subsection>
  <subsubsection title="自動評価尺度による翻訳精度の評価">日英・日中翻訳の実験結果を表に示す．表中の短剣符は，提案手法の翻訳精度がベースラインシステムと比較して統計的に有意に高いことを示す(:p&lt;0.05,:p&lt;0.01)．また，表中の星印は，提案手法の翻訳精度がLiuらの手法（手法(c)）と比較して統計的に有意に高いことを示す(:p&lt;0.05,:p&lt;0.01)．表中の(b),(c),(d),(e)の手法で自己学習に使用している文は，Egretが構文解析に失敗した場合を除いて同一である．なお，表中の``文数''は自己学習に使用した文数を示し，既存モデルで使用しているJDCの文数は含まない．本実験では，BLEU+1を文や構文木選択を行う際の指標としたため，以降では，主にBLEUスコアに着目して分析を行う．実験により，以下の3つの仮説について検証を行った．構文木の選択法を用いた標的自己学習（節）は翻訳精度向上に効果があるのか文の選択法（節）は学習データ中のノイズを減らし，精度を向上させる効果があるのか標的自己学習したモデルは目的言語に依存するのか，多言語に渡って使用できるのか構文木の選択法による効果：Parser1-bestの構文木を自己学習に使用する手法では，日英，日中翻訳ともにBLEUスコアの向上は見られなかった（表(b)）．FrontierNode1-bestを用いた場合，Parser1-bestを用いた手法と比較して多少の精度向上は見られたものの，ベースラインとの有意な差は見られなかった（表(c)）．また，日英翻訳でMT1-bestを自己学習に用いた手法では，Parser1-bestを用いた手法と比較すると精度は向上したもののベースラインシステムと比較すると精度は向上しなかった（表(d)）．日中翻訳では，MT1-bestを使用した手法はParser1-bestを用いた手法とほぼ同じ結果となった（表(d)）．この際に自己学習に用いられた構文木を確認したところ，正しい構文木もあるが誤った構文木も散見され，精度向上が確認できなかったのは誤った構文木が学習の妨げになったからだと考えられる．次にBLEU+11-bestを用いた手法では，Oracle訳に使われた構文木が選択されることにより，BLEUスコアが日英，日中翻訳ともに向上していることがわかる（表(e)）．特に，日中翻訳についてはベースラインより有意に精度が向上している．図に，この手法で自己学習に使われたOracle訳のBLEU+1スコア分布を示す．横軸の値xは，x以上x+0.1未満のBLEU+1を持つ文を表しており，縦軸が該当する文の数である．この図からもわかるように，Oracle訳であってもBLEU+1スコアが低い文は多く存在する．このため，節の文選択を実施した．文の選択法による効果：次に，BLEU+1スコアの閾値を用いた文選択手法の効果を確認する．結果から，日英翻訳，日中翻訳ともに，この手法は効果的であることがわかった（表(f),(g),(h)）．Liuらの手法（表(c)）と比較を行った場合でも，提案手法の一部では有意に高い精度が得られている．この結果から，自己学習を行う際には，精度が低いと思われる構文木を極力取り除き，精度が高いと思われる構文木のみを学習データとして使用することが重要であると言える．さらに，翻訳器1-best訳とOracle訳でBLEU+1スコアの差が大きい文のみを使用する手法でも，BLEU+1スコアの閾値を用いた手法と同程度の精度向上を達成することができた（表(i)）．目的言語への依存性：最後に，日英対訳文で自己学習し，日英翻訳の精度改善に貢献した構文解析器のモデルを，他の言語対である日中翻訳に使用した場合の翻訳精度の変化を検証した．興味深いことに，この場合でも直接日中対訳文で自己学習したモデルとほぼ同程度の翻訳精度の改善が見られた（表(j)）．これにより，学習されたモデルの目的言語に対する依存性はさほど強くなく複数の目的言語のデータを合わせて学習データとすることで，さらに効果的な自己学習が行える可能性があることが示唆された．</subsubsection>
  <subsubsection title="人手による翻訳精度の評価">提案手法によりBLEUスコアは改善されたが，自動評価尺度は完璧ではなく，実際にどの程度の質で翻訳できたか明確に判断することは難しい．そのため，人手評価による翻訳精度の評価を行い，実際にどの程度翻訳の質が改善されたかを確認した．評価基準は，意味伝達と訳の自然性を両方加味するAcceptabilityとした．本研究と関わりが無いプロの翻訳者に各翻訳文に対し評価基準を基に5段階のスコアをつけてもらい，これらの平均を評価値とする．評価は日英翻訳システムを対象とし，Testセットからランダムで抽出した200文について評価を行った．各システムの評価結果を表に示す．既存の自己学習手法で学習したモデルでは，ベースラインシステムと比較して有意な翻訳精度向上は確認できなかった（表(b)）．一方，提案手法で自己学習したモデルでは，ベースラインシステムより有意に良い翻訳精度が実現できており，かつ既存の自己学習手法と比較してもp&lt;0.1水準ではあるが精度が向上している（表(c)）．このように，自動評価尺度だけでなく，人手評価でも提案手法で自己学習したモデルを用いることにより，有意に翻訳精度が向上することが確認できた．</subsubsection>
  <subsubsection title="自己学習による訳出改善の例">構文解析器の自己学習によって改善された日英訳の例を表に示す．また，表の訳出の際に使用された構文木を図に示す．この文では，「C投与群」と「Rの活動」という名詞句が含まれている．ベースラインシステムの構文木は，これらの名詞句を正しく解析できておらず，この構文解析誤りが翻訳結果にも悪影響を与えてしまっている．一方，提案手法で自己学習したシステムでは，これらの名詞句を正しく解析できており，翻訳も正しく行われている．これはMcCloskyらが報告していたように，既存モデルで使用しているJDCで既知の単語が，ASPECで異なる文脈で現れた際に解析精度が向上した結果であると考えられる．</subsubsection>
  <subsection title="構文解析器の精度評価">次に，提案手法により自己学習した構文解析器自体の精度を測定した．ASPECに含まれる日英対訳データの内，Testセット中の100文を人手でアノテーションを行い，正解構文木を作成した．その後，各構文解析器の精度をEvalbを用いて測定した．評価には，再現率，適合率，およびそれぞれの調和平均であるF値を用いる．表に構文解析器の精度評価結果を示す．表からもわかるように，Parser1-bestを用いて自己学習したモデルはベースラインシステムと比較してp&lt;0.05水準で有意に精度が向上している．これに加えて，FrontierNode1-bestを用いた手法や提案手法で自己学習したモデルはp&lt;0.01水準で有意に精度が向上している．これらの結果から，提案手法は機械翻訳の精度だけでなく，構文解析器自体の精度もより向上させることがわかった．よって，本手法は構文解析器を分野適応させる場合においても有効であるといえる．</subsection>
  <subsection title="翻訳器の精度が低い場合の自己学習効果">提案手法では，翻訳結果を用いて間接的に構文木を評価し構文解析器を改良する．そのため，使用する翻訳器の精度によっては十分な学習効果が得られない可能性がある．本節では，精度が低い翻訳器を使用し構文解析器の自己学習を行い，翻訳精度と自己学習効果の依存性について検討する．なお本実験では日英翻訳のみを対象として実験を行った．</subsection>
  <subsubsection title="実験結果，考察">低精度翻訳器を自己学習時に使用し，自己学習した構文解析器を用いて翻訳器を構築しその精度を測定した．この実験結果を表に示す．また，構文解析器自体の精度も節と同様に測定した．測定結果を表に示す．結果は，低精度翻訳器を使用した場合でも，以前の高精度翻訳器を使用して自己学習を行った場合（表(b)）と遜色ない自己学習効果が得られた．構文解析器の精度自体も，高精度翻訳器を用いた場合（表(b)）と大きな差は無いことがわかった．これらの結果から，提案手法は既存翻訳器の翻訳精度に依存しないことが示された．これは，翻訳器が出した500-bestの中からOracle訳を選択しており，翻訳器が低精度の場合でも500-bestの中にはある程度誤りが少ない訳が含まれているため，比較的正確な構文木が選択できたからだと考えられる．そのため，n-bestのnを変えるとこの結果は多少変化する可能性がある．</subsubsection>
  <subsection title="自己学習を繰り返し行った場合の効果">構文解析器の自己学習では，1回自己学習を行った構文解析器をベースラインとして使用し2回目の自己学習を行うことで，さらなる精度向上が期待できる．本節では，自己学習を繰り返し行うことで，翻訳精度および構文解析精度にどのような影響が及ぶかを検証する．なお本実験では日英翻訳のみを対象として実験を行った．本実験では，1回自己学習を行ったものの構文解析モデルとして，表中の(g)のモデルを用いる．その他の実験設定は節と同一である．自己学習を2回行った構文解析モデルを使用して翻訳精度を測定した結果を表に示す．また，構文解析器の精度自体も節と同様に測定した．測定結果を表に示す．実験より，2回の繰り返し学習を行っても，1度のみの場合と比較して翻訳精度，構文解析精度ともに向上は見られなかった．これは，学習時に500-bestの中からOracle訳を選択しているため，1度目でも既にある程度精度の高い構文木が選ばれていたことが原因として考えられる．また，スコアを基に学習データを制限しているため，2度目の学習時に改善された構文木であっても，翻訳結果がスコアの制限を満たさず学習データとして使われなかった可能性がある．そのため，本手法では繰り返し学習の効果は薄いと考えられる．</subsection>
  <section title="おわりに">本論文では，統語ベース翻訳で用いられる構文解析器の標的自己学習手法を提案し，これによりF2S翻訳および構文解析の精度が向上することを検証した．具体的には，日英，日中翻訳を対象に実験を行い，本手法で標的自己学習した構文解析器を用いることで，ベースラインシステムと比較して有意に高精度な翻訳結果を得られるようになったことが確認できた．また，日英で自己学習した構文解析器のモデルを，日中の翻訳の際に用いても同様に精度が向上することが確認できた．日英翻訳については訳の人手評価も実施し，人手評価においても有意に翻訳精度の改善が見られた．さらに，提案手法では翻訳精度だけでなく，構文解析の精度自体も向上することを実験により検証した．また，既存翻訳器の精度が十分でない場合でもこの手法は適用可能であることを確認した．本手法の繰り返し適用に関する検討も行ったが，本手法では繰り返し学習の効果は薄いと考えられる．今後の課題としては，さらに多くの言語対で提案手法が適用可能であることを確認することが挙げられる．また，自己学習による効果は目的言語によらないという可能性が示唆されたため，実際に多言語で学習データを集めて適用することで，より翻訳精度および構文解析精度を向上させることが期待される．さらに，対訳コーパスに対して他の複数の構文解析器を用いて解析し，それらの解析結果が一致している文を正解とみなして構文解析器の学習に使用するtri-trainingとの比較についても検討を行いたいと考えている．</section>
</root>
