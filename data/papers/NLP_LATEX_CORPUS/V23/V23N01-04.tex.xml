<?xml version="1.0" ?>
<root>
  <jtitle>機械翻訳システムの誤り分析のための誤り箇所選択手法</jtitle>
  <jauthor>赤部晃一GrahamNeubigSakrianiSakti戸田智基中村哲</jauthor>
  <jabstract>複雑化する機械翻訳システムを比較し，問題点を把握・改善するため，誤り分析が利用される．その手法として，様々なものが提案されているが，多くは単純にシステムの翻訳結果と正解訳の差異に着目して誤りを分類するものであり，人手による分析への活用を目的とするものではなかった．本研究では，人手による誤り分析を効率化する手法として，機械学習の枠組みを導入した誤り箇所選択手法を提案する．学習によって評価の低い訳出と高い訳出を分類するモデルを作成し，評価低下の手がかりを自動的に獲得することで，人手による誤り分析の効率化を図る．実験の結果，提案法を活用することで，人手による誤り分析の効率が向上した．</jabstract>
  <jkeywords>統計的機械翻訳，誤り分析，誤り検出，評価尺度，コーパス</jkeywords>
  <section title="スコアに基づく誤り候補n">-gramの順位付けblack機械翻訳の誤り箇所を自動的に提示する際に，単純に誤り箇所を列挙するのではなく，より誤りの可能性が高い箇所から順に示すことができれば，後の人手による誤り分析の効率が上がると考えられる．本節では，機械翻訳結果に含まれるn-gramに対して，分析の優先度に対応するスコアを与える手法を提案する．分析者はこのスコアを参考にし，最初に分析する箇所を決定する．図にn-gramのスコアに基づく誤り分析の例を示す．この例では，提案法によってい．」が最も優先的に分析すべきn-gramと判断されているため，最初に機械翻訳結果全体からこのn-gramが含まれる箇所を見つけ，誤り分析をする．分析が終了したら，次に優先度の高いれるがを，最後にられる。を分析する．あるn-gramを提示した際に，もし分析者が機械翻訳の誤りでない箇所を分析対象としてしまうと，余計な分析作業を行うこととなり，分析効率が低下する原因となる．このため，効率的な誤り分析が行われるためには，最初に提示されるn-gramほどシステムの特徴的な誤りを捉えていることが望ましい．</section>
  <section title="はじめに">最新の機械翻訳システムは，年々精度が向上している反面，システムの内部は複雑化しており，翻訳システムの傾向は必ずしも事前に把握できるわけではない．このため，システムによってある文章が翻訳された結果に目を通すことで，そのシステムに含まれる問題点を間接的に把握し，システム同士を比較することが広く行われている．このように，単一システムによって発生する誤りの分析や，各システムを比較することは，各システムの利点や欠点を客観的に把握し，システム改善の手段を検討することに役立つ．ところが，翻訳システムの出力結果を分析しようとした際，機械翻訳の専門家である分析者は，システムが出力した膨大な結果に目を通す必要があり，その作業は労力がかかるものである．この問題を解決するために，機械翻訳の誤り分析を効率化する手法が提案されている．この手法の具体的な手続きとして，機械翻訳結果を人手により翻訳された参照訳と比較し，機械翻訳結果のどの箇所がどのように誤っているかを自動的にラベル付けする．さらに，発見した誤りを既存の誤り体系に従って「挿入・削除・置換・活用・並べ替え」のように分類することで，機械翻訳システムの誤り傾向を自動的に捉えることができる．blackしかし，このような自動分析で誤りのおおよその傾向をつかめたとしても，機械翻訳システムを改善する上で，詳細な翻訳誤り現象を把握するためには，人手による誤り分析が欠かせない．blackところが，先行研究と同じように，参照文と機械翻訳結果を比較して差分に基づいて誤りを集計する手法で詳細な誤り分析を行おうとした際に，問題が発生する．具体的には，機械翻訳結果と参照訳の文字列の不一致箇所を単純な方法でラベル付けすると，人間の評価と一致しなくなる場合がある．つまり，機械翻訳結果が参照訳と同様の意味でありながら表層的な文字列が異なる換言の場合，先行研究では不一致箇所を誤り箇所として捉えてしまう．このような誤った判断は，誤り分析を効率化する上で支障となる．black本研究では，前述の問題点を克服し，機械翻訳システムの誤りと判断されたものの内，より誤りの可能性が高い箇所を優先的に捉える手法を提案する．図に本研究の概略を示す．まず，対訳コーパスに対して翻訳結果を生成し，翻訳結果と参照訳を利用して誤り分析を優先的に行うべき箇所を選択する．次に，重点的に選択された箇所を中心に人手により分析を行う．誤りの可能性が高い箇所を特定するために，機械翻訳結果に含まれるn-gramを，誤りの可能性の高い順にスコア付けする手法を提案する（節）．また，誤りかどうかの判断を単純な一致不一致より頑健にするために，与えられた機械翻訳結果と正解訳のリストから，機械翻訳文中の各n-gramに対して誤りらしさと関係のあるスコア関数を設計する．設計されたスコア関数を用いることで，誤りn-gramを誤りらしさに基づいて並べ替えることができ，より誤りらしい箇所を重点的に分析することが可能となる．単純にスコアに基づいて選択を行った場合，正解訳と一致するような明らかに正しいと考えられる箇所を選択してしまう恐れがある．この問題に対処するため，正解訳を利用して誤りとして提示された箇所をフィルタリングする手法を提案し，選択精度の向上を図る（節）．実験では，まず節〜節で提案法の誤り箇所選択精度の測定を行い，単一システムの分析，及びシステム間比較における有効性の検証を行う．実験の後半では，提案法の課題を分析し（節），提案法を機械翻訳システムの改善に使用した場合の効果について検討を行う（節）．</section>
  <section title="機械翻訳の自動評価と問題点">本節では，従来から広く行われている機械翻訳の自動評価について説明し，その問題点を明らかにする．</section>
  <subsection title="評価の手順">機械翻訳システムに「原文f」を与えることで，「機械翻訳結果e」が得られたとする．評価方法として「自動評価尺度」を用いる場合，事前に人手により翻訳された「参照訳r」を与える．自動評価尺度は，機械翻訳結果eと参照訳rの差異に基づき機械翻訳結果の良し悪しをスコアとして計算するものである．また，「品質推定」と呼ばれる技術は，参照訳を利用せずに評価を行う．具体的には，誤りのパターンを学習したモデルによって機械翻訳文の精度を推定することや，翻訳結果の精度を部分的に評価することが行われている．自動評価尺度を利用する場合は参照訳を用意する必要があるが，翻訳精度の計算を翻訳システムに依らず一貫して行える利点がある．一方，品質推定は参照訳を必要としない分，翻訳精度を正しく推定することが比較的困難である．本研究は，参照訳が与えられた状況で機械翻訳の誤り分析を行う場合を対象とする．</subsection>
  <subsection title="代表的な自動評価尺度">機械翻訳の自動評価尺度は，様々なものが提案されており，尺度ごとに異なった特徴がある．BLEUは機械翻訳の文章単位の自動評価尺度として最も一般的に使われるものであり，参照訳rと機械翻訳結果eの間のn-gramの一致率に基づきスコアを計算する．機械翻訳結果と参照訳が完全に一致すれば1となり，異なりが多くなるに連れて0に近くなる．BLEUを文単位の評価に対応させたものにBLEU+1がある．BLEUやBLEU+1は，eとrの表層的な文字列の違いにしか着目しないため，eがrの換言である場合にスコアが不当に低くなる場合がある．BLEUとは異なり，評価尺度自体が換言に対応したものに，METEORがある．METEORを利用する場合，単語やフレーズの換言を格納したデータベースを事前に用意しておく．これにより，参照訳と機械翻訳結果のn-gramが一致しない場合であっても，データベース中に含まれる換言を利用することで一致する場合，スコアの低下を小さくすることが可能となる．</subsection>
  <subsection title="自動評価の課題">表に，英日翻訳における原文，機械翻訳結果，参照訳の例を示す．機械翻訳システムとして，句構造に基づく機械翻訳システムを利用した．自動評価尺度の一例として，BLEU+1スコアを示す．また，図はシステムが翻訳結果を出力した際の導出過程の一部である．自動評価尺度を用いることで，翻訳システムの性能を数値で客観的に比較することが可能であるが，この例から自動評価尺度に頼り切ることの危険性も分かる．前節で述べたように，自動評価尺度は人間の評価と必ずしも一致しない評価を行う場合がある．表の例では，``Forthisreason''が機械翻訳で「このため」と正しく翻訳されているが，参照訳では「それゆえ」と翻訳されているため，文字列の表層的な違いにしか着目しないBLEU+1では誤訳と判断されて，スコアが不当に低くなる．METEORを用いた場合，換言によるスコアの低下は発生しにくくなるが，逆に誤った換言が使用され，スコアが不当に高くなることも考えられる．自動評価尺度は，機械翻訳結果の正確さを判断する上で有用であるが，その結果からシステムの特徴を把握することは困難である．しかし，このように翻訳結果に目を通すことで，自動評価尺度の数値だけからは分からない情報を把握することが可能となる．</subsection>
  <subsubsection title="ランダム選択">ランダム選択は，n-gramの順位付けを一切行わずに誤り分析を進めることに等しい．章で誤り候補のフィルタリングの説明を行うが，フィルタリングを一切行わない場合はチャンスレートとなる．また，ランダム選択と参照訳を用いた厳密一致フィルタリングを組み合わせた場合は，先行研究で提案されている参照訳との差分に基づく分析となる．</subsubsection>
  <subsubsection title="誤り頻度に基づく選択">誤り頻度に基づく手法は，機械翻訳結果に多く含まれ，正解訳に含まれない回数が多いn-gramは重点的に分析すべきという考え方に基づく．n-gramのスコア計算では，あるn-gramxが機械翻訳結果e_MT(n)に含まれていて，かつ正解訳e_C(n)に含まれていない回数を計算し，スコアとする．ここで[~]_+はヒンジ関数である．このスコアが低いn-gramから順に選択することで，誤って出現した回数が多いn-gramを優先的に分析することとなる．しかし，頻繁に発生する誤りが必ずしも分かりやすく有用な誤りとは限らない．表は，ある英日機械翻訳システムが出力した翻訳結果に含まれ，参照訳には含まれなかったn-gramを，回数が多いものから順に一覧にしたものである．この表で，右側の数字はテストコーパス内で誤って出現した回数を示している．この表を見ると，単純に頻繁に検出される誤りは目的言語に頻繁に出現するものに支配されており，この結果だけからは翻訳システムの特徴を把握しにくいことが分かる．</subsubsection>
  <subsubsection title="自己相互情報量に基づく選択">誤り頻度に基づいてn-gramの選択を行った場合，表に示したように誤りとして検出されるものの多くは単純に目的言語の特徴を捉えたものとなってしまう．本研究ではこの問題に対処するため，出現頻度より正しく，あるn-gramが誤った文の特徴であるかどうかを判断する手法を提案する．最初のスコア付け基準として，自己相互情報量(PMI:PointwiseMutualInformation)に基づく手法を提案する．PMIは，2つの事象の関係性を計る尺度であり，本研究では与えられたn-gramと機械翻訳結果との関係性をスコアとして定式化する．機械翻訳結果と関係が強いn-gramは，正解訳との関係は逆に弱くなる．PMIは以下の式によって計算される．PMI(x,e_MT)&amp;=p(e_MT,x)p(e_MT)p(x)&amp;=p(e_MT|x)p(e_MT)align*ここで，各原文につき機械翻訳結果と正解訳が1つずつ与えられるため，p(e_MT)=1/2である．条件付き確率p(e_MT|x)は以下の式で計算される．[p(e_MT|x)=_n_x(e_MT(n))_n_x(e_MT(n))+_x(e_C(n))]最終的に，自己相互情報量の期待値に比例する以下の値をスコアとし，スコアが低いものから順にn-gramを選択する．S(x)&amp;=_x(e_MT(n))(-PMI(x,e_MT))&amp;p(x,e_MT)(-PMI(x,e_MT))align</subsubsection>
  <subsubsection title="平滑化された条件付き確率に基づく選択">「誤り頻度に基づく選択」では，目的言語に頻繁に出現するn-gramが分析対象の上位を占めてしまう問題があった．そこで，2つ目のスコア付け基準は，誤り頻度を全体の出現回数で正規化し，条件付き確率として定式化することを考える．平滑化された条件付き確率に基づく選択では，あるn-gramがシステム出力に含まれながら参照文に含まれない確率をスコアとし，このスコアが高いものを優先的に分析する．まず，以下の関数を定義する．F_MT(x)&amp;=_n[_x(e_MT(n))-_x(e_C(n))]_+_C(x)&amp;=_n[_x(e_C(n))-_x(e_MT(n))]_+align*ここで，F_MT(x)は誤り頻度に基づく選択で利用した式()に等しい．また，F_C(x)はn-gramが正解訳により多く出現した回数を表す．あるn-gramを選択した際，そのn-gramが正解訳に多く含まれる条件付き確率は以下の通りである．しかし，確率を最尤推定で計算すると，正解訳として出現せず，機械翻訳結果に1回しか出現しないような稀なn-gramの確率が1となり，頻繁に選択されてしまう．上述の問題点を解決するために，確率の平滑化を行う．文献では平滑化の手法としてディリクレ分布を事前分布として確率を推定しており，本手法もこれに習う．平滑化を用いた際のn-gramxについての評価関数は式()の通りであり，S(x)が低いものを代表的なn-gramとする．ただし，[P_MT=_xF_MT(x)_xF_MT(x)+_xF_C(x)]このとき平滑化係数を決定する必要がある．n-gramを利用して参照文もしくはシステム出力文を選択する際，選択される文の種類がディリクレ過程に従うと仮定すると，コーパス全体に対する尤度は式()で表される．式()のPが最大化されるようなをパラメーターとする．Pは全区間で微分可能であり，唯一の極があるとき，その点で最大値となる．よってはPの微分からニュートン法により計算できる．</subsubsection>
  <subsubsection title="識別言語モデルの重みに基づく選択">最後に，識別言語モデルの重みに基づくスコア付け基準を提案する．識別言語モデルは，自然な出力言語文の特徴を捉えるように学習される通常の言語モデルとは異なり，ある特定のシステムについて，起こりやすい出力誤りを修正するように学習される．さらに学習時に正則化を行えば，モデルのサイズが小さくなり，少ない修正で出力を改善するような効率的な修正パターンが学習される．誤り分析の観点から見ると，モデルによって学習された効率的な修正パターンに目を通せば，システムの特徴的な誤りを発見できると考えられる．[b]t=1Tn=1NE^*_EE(n)EV(E)E_EE(n)w(E)ww+(E^*)-(E)algorithmicalgorithm○構造化パーセプトロンによる識別言語モデル識別言語モデルの学習は構造学習の一種である．先行研究では，構造学習の最も単純な手法である構造化パーセプトロンを，識別言語モデルの学習において有用な手法であると示している．構造化パーセプトロンでは，black候補集合の中で誤りの修正先として学習される目標E^*を定める．本研究では目標として，機械翻訳結果のn-bestの中で評価尺度が最も高かった文（オラクル訳，節参照）を選択する．学習では，モデルによって最も大きなスコアが与えられる現在の仮説EとE^*の素性列を比較する．1回の更新において，EとE^*の差分を用いて重みwを更新する．重みが更新されると，重みと素性列から計算されるスコアが変化し，仮説Eが更新される．EとE^*が等しいときは差分が0のため更新を行わない．重みの更新はコーパス全体に対して一文ごとに逐次的に行い，反復回数や重みの収束といった終了条件が満たされるまで反復する．学習のアルゴリズムをAlgorithm~に示す．ここで，E(n)はn番目の文に対応する機械翻訳結果のn-bestリスト，Tは反復回数である．また，EV(E)は機械翻訳結果Eの翻訳精度を評価するための自動評価尺度である．○L1正則化による素性選択機械翻訳システムの誤り傾向をより明確にするため，重みの学習時にL1正則化を行う．L1正則化は，重みベクトルに対してL1ノルム|w|_1=_i|w_i|に比例するペナルティを与える．L1正則化を用いる時に，重みwの中で多くの素性に対応するものが0となるため，識別能力に大きな影響を与えない素性をモデルから削除することが可能となる．L1正則化された識別モデルを学習する簡単かつ効率的な方法として，前向き後ろ向き分割(forward-backwardsplitting;FOBOS)アルゴリズムがある．一般的なパーセプトロンでは正則化を重みの更新時に行うが，FOBOSでは重みの更新と正則化の処理を分割し，重みの利用時に前回からの正則化分をまとめて計算し，効率化を図る．○識別言語モデルの素性識別言語モデルの素性として様々な情報を利用できるが，本研究ではn-gramに基づく選択を行うため，以下の3種類の素性を利用する．n-gramの選択時には，識別言語モデルによって学習された重みが低いものを優先的に選択する．</subsubsection>
  <subsection title="厳密一致フィルタリング">このフィルタリングは，機械翻訳結果中のあるn-gramが誤り箇所として選択された際に，そのn-gramがblack正解訳の一部に厳密一致するかどうかを確認し，一致する場合は選択を行わないようにする．フィルタリングの具体例を表に示す．n-gram「、右」が誤り箇所の候補とされた際，1つ目の例では機械翻訳結果の一致箇所が選択されるが，2つ目の例では正解訳に同一のn-gramがあるため，誤り箇所の候補から除外される．これは，正解訳に含まれている文字列は翻訳誤りではないだろうという直感に基づく．</subsection>
  <subsection title="換言によるフィルタリング">機械翻訳結果と正解訳の文字列が，表層的に異なりながら意味が等しい場合，厳密一致フィルタリングを用いただけでは選択された箇所が正解訳に含まれず，誤選択を回避することができない．この問題を解決するため，本研究では正解訳の換言を用いたフィルタリングを行う．換言によるフィルタリングの例を図に示す．正解訳として``Idon'tlikeIT!''が与えられている中，機械翻訳結果が``Ilikeinformationtechnology!''となり，``likeinformation''が誤りの候補として挙げられたとする．換言によるフィルタリングでは，まず正解訳に含まれる全ての部分単語列を用意した換言データベースの中から検索し，ある閾値以上の確率で置換可能な換言を抽出する．次に，抽出された換言を利用して参照訳のパラフレーズラティスを構築する．最後にラティス上を探索し，誤りの候補として挙げられたn-gram``likeinformation''が見つかった場合は，このn-gramを誤りの候補から除外する．</subsection>
  <subsection title="フィルタリングに用いる正解訳の選択">節で，スコア計算に用いる正解訳として参照訳またはオラクル訳を利用するが，フィルタリングの際にも正解訳としてblack参照訳のみ用いた場合と，参照訳に加えてオラクル訳を用いた場合で比較を行う．オラクル訳の選択では，機械翻訳の自動評価尺度を用いるが，本研究では以下の2つの評価尺度で選択を行った場合の比較を行う．</subsection>
  <section title="実験">本節では，各実験を通して，提案法を利用することで機械翻訳の誤り分析をより効率的に行えることを示す．まず，各スコア基準に従って単一の機械翻訳システム（節）及び複数の機械翻訳システム（節）の誤り箇所選択を行い，人手評価を行う．これにより，提案法の選択精度とシステム間比較における有効性を検証する．次に，誤りとして選択された箇所のフィルタリングを複数の手法によって行い，フィルタリングの効果を自動評価によって測定する（節）．さらに，提案法が翻訳誤りでない箇所を誤選択する場合についても分析を行い，提案法が抱える課題を明らかにし，その改善策について検討する（節）．また，提案法によって発見された翻訳誤りを修正した際の効果について検討する（節）．</section>
  <subsection title="選択された誤り箇所の調査">本節では，各手法によって順位付けされた誤りn-gramを人手で分析する．人手評価の方法は赤部,Neubig,Sakti,戸田,中村(2014a)akabe14signl216に従い2段階で行う．まず，各誤り箇所選択手法によって選択された箇所に対し，分析者はその箇所が機械翻訳の誤り箇所を捉えているかどうかをアノテーションする．これにより，優先的に選択された上位k個のn-gramについて，誤り箇所の適合率を測定することが可能となる．次に，誤り箇所を捉えている場合は，以下に示す誤りの種類をアノテーションする．これにより，選択された誤り箇所の誤り傾向を把握する．これらの結果を元に，翻訳システムの比較を行う．</subsection>
  <subsubsection title="実験設定">すべての実験で京都フリー翻訳タスク(KFTT)の日英翻訳を利用した．コーパスの大きさを表に示す．単一の機械翻訳システムを用いた実験では，Travatarツールキットに基づくforest-to-string(f2s)システムを利用した．システム間比較では，f2sシステムに加え，Mosesツールキットに基づくフレーズベース翻訳(pbmt)システム及び階層的フレーズベース(hiero)システムを利用した．翻訳システムを構築する上で，f2sシステムでは単語間アラインメントにNileを利用し，構文木の生成にはEgretを利用した．pbmtシステムとhieroシステムでは，単語間アラインメントにGIZA++を利用した．チューニングにはMERTを利用し，評価尺度をBLEUとした．n-gramの選択には章で説明したスコア計算法を利用した．実験を行ったスコア計算法とスコアの学習に利用したデータの組み合わせを表に示す．n-bestによる識別言語モデルの学習は，反復回数を100回とした．学習時にFOBOSによるL1正則化を行った．正則化係数は10^-7--10^-2の中から選び，KFTTのテストセットに対して高い精度を示す値を利用した．学習には1-gramから3-gramまでのn-gramをblack長さによる区別を行わずに利用した．オラクル文の選択にはBLEU+1を利用し，選択されるn-gramの誤り傾向を分析した．各手法で，参照訳を用いた厳密一致フィルタリングを行った．</subsubsection>
  <subsubsection title="システム間比較">black分析対象とするシステムによって，含まれる誤りの分布が異なる．本節では，提案法によって検出される誤りが，本来の誤り分布を適切に捉えることを確認する．具体的には，pbmt，hiero，f2sの3つの翻訳システムで日英・英日の両方向に対して翻訳を行い，単一システムの評価を行った際と同様に，識別言語モデルの重みに基づく誤り箇所選択法を利用して抽出された上位30個の誤りn-gramに対し，分析を行った．その結果を表に示す．この結果から，pbmtとhieroの両システムでは，並べ換え誤りが上位の誤りとして検出されている一方，f2sシステムの特に英日翻訳では下位の誤りとして検出された．一般的に，統語情報を使った翻訳システムは並べ換え誤りに強いことが知られており，本結果はこれを裏付けることとなった．次に，日英翻訳では挿入誤りが多く検出され，逆に英日翻訳では日本語で多様な活用誤りが多く検出されていることが分かる．このように僅か30個の誤りn-gramに目を通すだけで，各翻訳システムが苦手とする分野に目を通すことがある程度できたことが分かる．</subsubsection>
  <subsection title="選択された箇所に対するフィルタリングの効果">本節では，翻訳誤りとして選択された箇所に対し，各フィルタリング法を適用した際の効果について，誤り箇所アノテーションコーパスを用いた自動評価により検証する．自動評価には，先行研究で提案されている機械翻訳結果を後編集した際の編集パターンを利用した手法(赤部,Neubig,Sakti,戸田,中村2014b)を利用する．akabe14signl219評価の際は，事前に選択精度評価用の機械翻訳結果を後編集したコーパスを作成する．後編集のパターンから，機械翻訳結果の各部分に対して，挿入誤り，削除誤り，置換誤り，並べ換え誤りのラベルを付与することが可能である．これを誤り箇所の正解ラベルとし，評価用の機械翻訳結果に対して各誤り箇所選択法を適用した際に，誤り箇所の正解ラベルをどの程度予測できるかを適合率と再現率により評価する．</subsection>
  <subsubsection title="参照訳による厳密一致フィルタリングの効果">予備実験として，コーパス全体をランダムに選択した場合と，参照訳によるフィルタリングを行った場合で，誤り箇所の選択精度がどのようになるか確認を行った．表はすべての箇所をランダムに分析した場合の結果である．「フィルタリングなし」はチャンスレート，「フィルタリングあり」は分析の際にフィルタリングを行った結果である．この表から，参照訳によるフィルタリングを行うだけでも，再現率の低下を抑えつつ適合率が大きく改善したことが分かる．</subsubsection>
  <subsubsection title="換言を考慮した正解訳の効果">各正解訳（参照訳，black参照訳+オラクル訳）を用いたフィルタリング法を，換言あり・なしの場合について適用した実験を行った．表は各設定における誤り箇所適合率と再現率の結果である．この表から，フィルタリングに用いる正解訳として，black参照訳のみを用いた場合に比べてBLEU+1によるオラクル訳をblack加えた方が適合率が高く，またblack評価尺度としてMETEORを用いた場合は，BLEU+1blackを用いた場合に比べ更にblack適合率が高くなったことが分かる．このことから，METEORにより選択されたオラクル訳は，機械翻訳の1-best出力で利用される語彙に似ており，換言表現が含まれにくくなっていることが分かる．次に正解訳の換言を用いた場合の結果を見ても，選択箇所の誤り箇所適合率が高くなっていることが分かる．これらから，正解訳の換言を用いたフィルタリングを行うことによって，機械翻訳の誤り箇所がより適切に捉えられるようになったことが分かる．一方，再現率について注意しなければならない点がある．特にオラクル訳を正解訳として利用した場合に，誤り箇所選択の再現率が大きく低下している．これは，オラクル訳は機械翻訳システムが出力した文であり，1-bestと同様の誤りが発生する場合があるためである．しかし，今回提案した各手法は，コーパスの中の少なくとも20%の誤り箇所を捉えており，提案法を利用する際には大きな問題とはならないと考えられる．誤り分析を効率的に行う際には，適合率の高い手法から先に利用し，選択された箇所を全て分析してしまった場合は順次再現率の高い選択法に切り替えることが可能である．表にフィルタリングされた箇所の例を示す．1つ目の日英翻訳の例では，``foundationof''が誤り箇所の候補として選択されている．しかし参照訳に含まれる``afoundationfor''は換言データベースによると``afoundationof''に置き換えることが可能である．その結果，``foundationof''は誤りの候補から正しく除外された．2つ目の英日翻訳の例では，換言データベースにより句点「、」が削除されたことで，不適切な選択箇所が正しく除外された．この際注意すべきこととして，生成されたパラフレーズラティスが言語的に正しいものとは限らないという点が挙げられる．このため，誤った翻訳が発生している箇所が候補から除外される可能性もあることに注意されたい．</subsubsection>
  <subsubsection title="換言テーブルのドメインの影響">次に，日英翻訳において異なる換言データベースを使用した際の選択精度の調査を行った．前節の実験で利用した英語PPDBには，分析対象であるKFTTのデータが含まれていない．このため，KFTTのデータが含まれている日本語PPDBの構築データを利用して英語のPPDBを新たに作成した．前者を「ドメイン外」，新しく作成した後者を「ドメイン内」とし，評価結果を表に示す．この表から，分析対象のドメインのデータが含まれた換言データベースを利用することで，誤り箇所選択の適合率が向上したことが分かる．換言データベースは機械翻訳のパラレルデータがあれば容易に作成可能なため，誤り分析で利用する際には独自に作成することが望ましいと言える．</subsubsection>
  <subsubsection title="選択された誤り箇所の分布">誤り箇所選択法によって見つかった誤りの傾向が，本来の誤り傾向と異なる場合，機械翻訳システムの傾向を正しく把握できないことにつながる．このため，誤り分析コーパスに含まれる誤りの分布と，各誤り箇所選択法によって見つかった誤りの分布の比較を行った．各手法によって見つかった誤りの統計を図に示し，表にKLダイバージェンスD_KL(P_corpus|P_select)を示す．ここで，P_corpusはコーパスに含まれる誤りの分布，P_selectは各手法によって見つかった誤りの分布である．この結果から，参照訳を用いたフィルタリング法によって検出される誤りが，翻訳システムの誤り傾向を最も正確に捉えていると言えるが，他の手法でもKLダイバージェンスの値が0.001程度に収まっている．この結果から，いずれの手法においても選択された誤りの種類に大きな偏りが生じず，機械翻訳システムの誤り傾向を適切に捉えていることが分かった．</subsubsection>
  <subsection title="誤選択箇所の分析">節及び節の実験から，各誤り箇所選択法が誤って正しい翻訳箇所を選択する場合，またはフィルタリングによって誤り箇所が選択できなくなってしまう場合が存在することが明らかとなった．また，誤り箇所選択の自動評価の際，後編集結果に基づいて誤り箇所がアノテーションされたコーパスを用いるが，そもそもこのコーパスに誤りが含まれている場合は，精度評価が正しく行えないと考えられる．本節では，節と同様に，日英翻訳の誤り箇所アノテーションコーパスを用いて誤り箇所選択を行い，自動評価によって誤選択と判断された箇所について原因の調査を行った．</subsection>
  <subsubsection title="誤選択された正しい翻訳箇所に対する分析">誤り箇所選択法は，優先的に分析すべきと判断された箇所を選択するが，選択された箇所が本当は誤りでない場合がある．このような誤選択の分析を行うため，各手法により誤り箇所選択を行い，さらに選択箇所の自動評価を行った際に，誤選択と判断された部分について以下のアノテーションを人手で行う．○実験設定京都フリー翻訳タスク(KFTT)の日英データで構築されたf2sシステムに対し，「識別言語モデルの重みに基づく誤り箇所選択」を行い，再現率が5%となる上位のn-gramについて分析を行った．選択の際，各手法によりフィルタリングを行った．オラクル訳を選択する際の評価尺度としてBLEU+1を利用した．○実験結果まず，選択箇所のフィルタリングを一切しない場合に検出された誤選択箇所の内訳を表に示す．誤選択と判断された箇所の内，誤り箇所アノテーションコーパスの誤りであり，誤選択ではなかったものが僅か3%であり，後編集による自動評価が十分効果的であると言える．次に，各フィルタリング法を適用した場合に検出されたblack誤選択箇所の個数を表に示す．この結果から，識別言語モデルの重みに基づく誤り箇所選択を行った際に，参照訳を用いたフィルタリングを行うことによって4割以上の誤選択を回避できることが分かった．また，誤選択された箇所が正解訳の換言に含まれる場合，参照訳の換言を用いたフィルタリングblackによって3割以上，さらにオラクル訳やオラクル訳の換言を用いたフィルタリングを合わせることで8割以上の誤選択を回避できることが分かった．オラクル訳を正解訳としてフィルタリングを行った場合の「正解訳の誤り」がフィルタリングをしなかった場合に比べて多く現れている．これは，オラクル訳に含まれる誤りが参照訳に対して多いためである．また，「厳密一致」に分類される誤選択箇所であっても，フィルタリングで除外されない誤りがある．これは短いn-gramで一致していても，長いn-gramでは一致しない場合にフィルタリングを通過し，誤選択されてしまうためである．表に誤り箇所の誤選択例を示す．「black統語的換言」に分類された例を見ると，機械翻訳結果の``1392,started''が誤り箇所として選択されている．これは参照訳の統語的な換言であり，実験で使用したPPDBでは対応できないため，参照訳のみを正解訳とした場合は誤り箇所として扱われてしまう．しかし，オラクル訳は機械翻訳結果と同じ文の構造をしており，``began''を``started''に置き換えるだけで選択箇所に一致する．このため，オラクル訳の換言を使ったフィルタリングによって分析対象から除外可能となる．</subsubsection>
  <subsubsection title="選択されなかった誤り箇所に対する分析">誤り箇所選択によって選択された箇所に対してフィルタリング法を適用することで，正解訳に一致するn-gramや正解訳の換言に含まれるn-gramを誤り箇所から除外することができる．しかしそれらの手法によって，逆に正しく選択されるべき機械翻訳の誤り箇所を誤り箇所の候補から除外する場合があり，再現率の低下として現れている．このような問題の分析を行うため，誤り箇所アノテーションコーパスで誤りとされている箇所で，フィルタリングにより選択できなくなる部分について，以下の基準に従って分類を行う．○実験設定節で利用した日英機械翻訳の誤り箇所アノテーションコーパスについて，「参照訳を用いた厳密一致フィルタリング」及び「参照訳のパラフレーズを用いたフィルタリング」を適用し，選択されなくなってしまう誤り箇所の調査を行った．○実験結果各フィルタリング法を適用することによって選択されなくなった誤り箇所の統計を表に示す．この結果から，参照訳のみによるフィルタリングを行った場合，選択されなくなる箇所の約3割は誤り箇所アノテーションコーパスの誤りによるもの，約6割は姓名の順序の違いに起因する誤りであり，実用上問題となる誤り箇所がほとんど除外されていないことが分かった．次に，参照訳の換言によるフィルタリングを適用した場合の結果を見ると，間違った換言が使用されたことによる誤選択が20%以上あることが分かった．また，誤り箇所アノテーションコーパスの誤りにより誤り箇所として誤判断された箇所が約3割検出されており，各選択法の再現率を評価する際，無視できないほどの影響が出ることが分かった．</subsubsection>
  <subsection title="誤り箇所選択の誤り分析における効果">本節では，実際の誤り分析を想定し，各誤り箇所選択法を用いて一定時間分析を行った際の効果を検証する．図は本節の実験の手順を示す．まず，章で述べた各手法によってn-gramにスコアを与え，優先的に分析すべきn-gramを順に抽出する．次に，機械翻訳の訳出の中で各n-gramが含まれている文を列挙し，n-gramに一致する箇所を選択する．blackその際，章で述べたフィルタリング処理を行う．分析シートは，n-gramが正解訳に含まれないものを先に表示し，正解訳に含まれるものを後に表示するようにした．このようにすることで，分析者はフィルタリングの対象とならなかった結果を優先的に分析しつつ，分析者の時間が許せば，誤ってフィルタリングされた機械翻訳文も分析対象とすることができる．分析者は各n-gramが選択した箇所について誤り分析を行い，翻訳時に誤って使用された翻訳ルールを記録する．その際，誤り箇所が節で述べた「文脈依存誤り」か「文脈非依存誤り」かを記録しておくことで，翻訳ルールそのものが誤っているのか，あるいはモデル化が誤っているのかが把握可能となる．1個のn-gramにより複数の文が選択された場合は，実際の誤り分析と同様に，分析者の判断ですべての文を見ずに分析を中断しても良いこととする．最後に，各n-gram毎に誤り分析に要した時間を記録する．</subsection>
  <subsubsection title="実験結果">各手法を利用して誤り分析を行った際に，経過した分析時間と誤って使用された翻訳ルールが発見された個数の関係を図(a)に示す．また図(b)は発見された誤りの中でも文脈非依存誤りの原因となるルールが見つかった個数を示す．グラフの傾きが大きいほど，誤りルールを効率的に発見できることを意味する．これらの結果から，各手法とも分析時間と誤りルール発見数の間に大きな違いは見られなかった．一方で，文脈非依存誤りの原因に限って見れば，識別言語モデルの重みに基づく誤り箇所選択では，他の手法に比べて早い段階から誤りが見つかることが分かった．文脈非依存誤りは，その誤りを修正しようとした際に文脈を考慮する必要がないため，文脈依存誤りに比べて誤りを容易に修正できる．このため，識別言語モデルの重みに基づく手法を利用することで，修正が容易な誤りを早期に発見することができ，システムの改善を比較的効率良く行うことができると言える．次に，文脈非依存誤りの原因として記録された翻訳ルールを機械翻訳システムから削除することによって，システムをどの程度改善できるかを見積もった．KFTTのテストセット1,160文を機械翻訳した際，21,080個の翻訳ルールが使用された．この内，各手法で文脈非依存誤りの原因として記録されたルールが使用された回数を表に示す．この結果から，文脈非依存の誤りの原因となるルールを具体的に記録しても，そのルールが機械翻訳システムで使用されることは稀であることが分かる．翻訳システムの誤りを修正する際には，見つかった誤りルールを1つずつ修正するのではなく，見つかった誤りルールを一般化し，テストセットにおけるカバー率を向上させる必要がある．</subsubsection>
  <section title="おわりに">本論文では，機械翻訳システムの比較・改善のための誤り分析を効率的に行うことを目的として，機械学習の枠組みを利用した機械翻訳の誤り箇所選択法，及び選択箇所のフィルタリング法を提案した．その結果，人手評価において従来法に比べて高い精度で適切な誤り箇所を捉えることに成功した．また，優先的に選択された少量の誤り箇所を分析するだけで，各システムの誤り傾向を捉えることができ，システム間比較の効率化に貢献した．次に，機械翻訳の誤り箇所選択法が誤選択した箇所の分析を行ったところ，オラクル訳や換言を利用したフィルタリングは適合率の向上に効果的であるが，誤った換言が使用されることによる再現率の低下が明らかとなった．最後に，今回の提案法を実際の誤り分析に利用した場合の効果を検証した．その結果，翻訳システムを容易に修正可能な文脈非依存誤りについては，提案法により比較的早い段階から捉えることが可能であることが分かった．一方ですべての種類の誤りについて見ると，各手法とも誤りの発見数に大きな違いが見られなかった．blackこの理由として，各手法によって選択された誤り箇所の特徴が挙げられる．誤り頻度に基づき選択された誤り箇所は，識別言語モデルの重みに基づいて選択された箇所に比べ，目的言語に頻繁に出現するn-gramを多く含む．このため，識別言語モデルの重みに基づく手法を利用した際，誤り分析者が比較的効率良く選択箇所に目を通すことができたと考えられる．今回の実験では，目を通した文の数については記録を行っていないため，今後の調査項目として検討する必要がある．また，発見したルールを単独で見ても，システム全体から見ればそのような翻訳ルールが使用されることはごく稀であることが分かった．一方で，具体的な誤りルールを一般化することで，同様の翻訳ルールをまとめて修正することは可能と考えられる．今後の課題として，見つかった具体的な誤りをどのように一般化するかを検討する必要がある．具体的には，見つかった翻訳ルールを品詞列などのより抽象的な情報に自動的に変換することや，誤ったルールを元に，人手によって複数の修正ルールを列挙する手法が考えられる．</section>
</root>
