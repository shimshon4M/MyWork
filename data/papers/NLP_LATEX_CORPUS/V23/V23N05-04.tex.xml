<?xml version="1.0" ?>
<root>
  <jtitle>文書間類似度について</jtitle>
  <jauthor>浅原正幸加藤祥</jauthor>
  <jabstract>文書間類似度は，内容の類似度と表現の類似度の二つの側面を持っている．自動要約や機械翻訳ではシステム出力の内容評価を行うために参照要約（翻訳）との類似度を評価する尺度が提案されている．一方，表現を対照比較するための手段として，形態素（列）を特徴量とする空間上の計量が用いられる．本稿では，さまざまな文書間類似度について，距離・類似度・カーネル・順序尺度・相関係数の観点から，計量間の関係や同値性を論じた．さらに内容の同一性保持を目標として構築したコーパスを用いて，内容の差異と表現の差異それぞれに対する各計量のふるまいを調査し，文書間類似度に基づく自動評価の不安定さを明らかにした．</jabstract>
  <jkeywords>文書間類似度，距離空間，カーネル，順序尺度，文体</jkeywords>
  <subsection title="BCCWJ-SUMM_C">BCCWJ-SUMM_Cは『現代日本語書き言葉均衡コーパス』(BCCWJ)の新聞記事（PNサンプル）の要約をYahoo!クラウドソーシング（15歳以上の男女）により被験者実験的に作成したものである．BCCWJの1サンプルには複数の記事が含まれており，それを記事単位に分割したうえで元文書集合19文書を構築した．元文書集合はBCCWJコアデータPNサンプル（優先順位A）から選択した．40文字毎に改行した元文書を画像として提供し，実験協力者に50--100文字に要約せよという指示で収集した．自動要約の本来のあり方としては，文字数の削減ではなく，読み手の読み時間の削減が本質であると考えるが，実験の都合上，文字数による制限を課した．実験協力者の環境はPCに限定した．元文書毎に約100--200人の実験協力者が要約に従事した．実験実施時期は2014年9月である．得られたデータには，文字数制限を守っていないもの・実験の趣旨を理解していないもの・既に実験を行った実験協力者から同一回答を提供されたと考えられるものなどが含まれており，これらを排除したものを有効要約とする．統計分析においてこの有効要約のみを用いる．</subsection>
  <section title="はじめに">文書間類似度がはかるものとして「伝える内容の一致」（内容一致）だけでなく「伝える表現の一致」（表現一致）がある．文書間類似度は自動要約や機械翻訳ではシステム出力の内容評価を行うために参照要約（翻訳）との差異を評価する指標として用いられる．一方，文書間類似度は表現の差異を評価することを目的としてテキストの文体の計量比較にも用いられる．本稿では，文書間類似度の数理的構造の説明し，様々な内容もしくは文体が同じであることが想定されるテキストを用いて，各計量の特性について検討する．は2008年時点での自動要約の評価指標についての評価をまとめている．2008年以降に提案された語順を考慮した内容評価のための指標を含めて，語順に対する順序尺度を含めた距離空間・類似度・カーネル・相関係数などの尺度を用いて，数理的構造について整理する．具体的には，一致部分文字列による尺度・一致部分列による尺度・ベクトル型順序尺度・編集型順序尺度の四つに分類し議論する．これらの四つの尺度に基づき，内容一致（内容の同一性）と表現一致（文体の類似性）の観点から，言語生産過程の多様性を評価する．複数人が同一課題を実施した場合の各評価尺度の分散や，同一人が同一課題を繰り返し実施した場合の各評価尺度の分散などを検討する．生産過程においては口述・筆術・タイプ入力の三種類について評価し，課題においては要約・語釈・再話について評価する．要約は長い文書を同等の内容で短く言い換えることを目的とする言語生産過程であるが，語釈は短い単語が指し示す意味と同等の内容を長く言い換えることを目的とする言語生産過程であることから，要約は語釈の逆写像の一般化ととらえることができる．また，再話は長い文書を再度同等の内容でそのまま提示することを目的とする言語生産過程であることから，要約の一般化であるととらえることができる．この評価を通して，四つの指標における差異がどのような生産過程の差異に現れるのかを調査する．また同一言語生産課題に対する生成物の多様性についても議論する．表現一致をつかさどるものとして，情報の提示順序を含む修辞法(rhetoric)・使用域(register)や位相(phase)に内在する文体・個人に内在する文体などが考えられる．要約を評価するにあたり，内容一致は重要であると考えるが，表現一致はどの程度重要であるのだろうか．さらにこれらはどの評価尺度に表出するのだろうか．対照比較を介して，各言語生産過程に共通のふるまいを示す評価尺度と課題に特有のふるまいを示す評価尺度について調査する．自動要約評価のための参照文書は一般に口述筆記の専門家や記者経験者などにより作成され，統制された少数のものが提供される．自動翻訳評価においても職業翻訳家等により限られた数の参照文書が作成される．統制は距離空間上の凸問題として課題を設定し，その課題設定の枠組内で評価したい工学研究者の都合で行われているものである．さらに，工学研究者は参照文書の差異がユークリッド距離空間上に規定され，文書間類似度で比較可能なレベルで統制できうるものだと考えているきらいがある．一方，文書を介したコミュニケーションにおいて，言語生産者ではない者による受容過程は統制されるものではなく，複数の受容者間で共有されるものではない．一人の受容者においても時間的経過などで統制できるものでもない．本稿では，人間の要約作成時の不安定な言語受容過程において文書の重要箇所選択がどの程度ゆれるものなのかを評価するとともに，そのゆれは評価指標を構成するどの尺度に表れるのかを調査する．この調査を通して，本来誤りでないものが課題設定の時点で誤りになっている可能性があるという実態を明らかにする．本稿の貢献は以下のとおりである：既存の文書要約や機械翻訳の自動評価に利用される評価指標と，距離空間・類	似度・カーネル空間・順序尺度・相関係数などの尺度との関係を整理した同一課題について複数人の言語生産者間で生成される文書のゆれを定量的に評価	した課題ごとに同一人の言語生産者の課題試行間で生成される文書のゆれを定量的に	評価した上に述べたゆれの評価に基づき，内容評価と表現評価の尺度上のふるまいの不安定さを明らかにした尚，本稿では，「評価指標」と「尺度」を区別して用いる．自動要約や機械翻訳ではシステム出力の内容評価を行うためのROUGEやBLEUなど広く知られているものを表す際に「評価指標」と呼び，「評価指標」を構成する距離空間・類似度・カーネル・相関係数などを「尺度」と呼ぶ．「評価指標」が単一の「尺度」から構成されることもあり，「評価指標」=「尺度」である場合もある．以下，節では既存の自動評価指標を距離・類似度・カーネル・順序尺度・相関係数により説明することで，文書間類似度を四つに分類し整理する．3節では尺度を適用して比較するさまざまな言語生成過程を記録した言語資源について説明する．4節では評価尺度の定性的な評価について示す．5節にまとめと今後の研究の方向性について示す．</section>
  <section title="評価指標と距離・類似度・カーネル・順序尺度・相関係数"/>
  <subsection title="本節の趣旨">本節では，過去に提案されている自動要約と機械翻訳の評価指標を距離・類似度・カーネル・順序尺度・相関係数などの尺度により説明することを試みる．この説明の過程で，いくつかの評価指標が擬距離の公理の対称性，三角不等式や，距離の公理の非退化性を満たさないことに言及する．まず，部分文字列(substring)と部分列(subsequence)の違いを明確にするため，2.2節で部分文字列と部分列に基づく類似度について解説する．2.3節で先行研究で言及されている評価指標について解説する．2.4節で関連するカーネル・順序尺度について示す．2.5節で指標の一般化について述べる．評価指標においては，二つのデータ比較という観点から，単一の参照テキストと単一のシステム出力テキストの対の文書間類似度に限定して議論する．複数の参照テキストを考慮する場合には退化性等を考慮する必要がある．尚，本節で用いる用語や記号の定義は節にまとめてある．</subsection>
  <subsection title="LCSubstrとLCS"/>
  <subsubsection title="記号列と文字列と部分文字列と部分列">評価指標の議論を始める前に，記号列，文字列，部分文字列，部分列の違いについて確認する．何らかの全順序が付与されている記号集合のことを記号列と呼ぶ．本稿では記号列ベクトルs=s_1,,s_m,t=t_1,,t_mなどで表現する．参照テキスト，システム出力テキストは，ともに文字(character)ベースの記号列もしくは形態素解析後の形態素(morpheme)ベースの記号列とみなすことができる．評価する記号列上の連続列のことを文字列(string)と呼ぶ．記号列の要素が文字(character)である場合を「文字ベースの文字列(character-basedstring)」，記号列の要素が形態素(morpheme)である場合を「形態素ベースの文字列(morpheme-based)」と呼ぶこととする．記号列に対して隣接性と順序を保持した部分的記号列のことを部分文字列(substring)と呼ぶ．長さnの部分文字列を特にn-gram部分文字列と呼ぶ．記号列sのi番目の要素からはじまるn-gram部分文字列をs_ii+n-1で表現する．記号列に対して順序を保持した部分的記号列のことを部分列(subsequence)と呼ぶ．隣接性は保持しなくてよい．長さpの部分列を特にp-mer部分列と呼ぶ．記号列sのp-mer部分列を，インデックスベクトルi=i_1,,i_p(1i_1&lt;i_2&lt;&lt;i_p|s|)を用いて，s[i]と表す．</subsubsection>
  <subsubsection title="最長共通部分文字列(Longest Common Substring: LCSubstr)長">最長共通部分文字列(LongestCommonSubstring)の略称はLCSだが，一般には節に示す最長共通部分列(LongestCommonSubsequence)のことをLCSと呼ぶことが多い．本稿では前者をLCSubstr,後者をLCSと呼び，区別する．記号列s,tを与えた際の最長共通部分文字列を次式で定義する：[(s,t)=_s_ii+n-1|j,s_ii+n-1=t_jj+n-1n]記号列s,tを与えた際の最長共通部分文字列長（LCSubstr長）を次式で定義する：[|(s,t)|=_i,j,s_i+n-1=t_jj+n-1n]これを[0,1]区間に正規化すると以下のようになる：[_(s,t)=2|(s,t)||s|+|t|]</subsubsection>
  <subsubsection title="最長共通部分列(Longest Common Subsequence: LCS)長とLevenshtein距離">記号列s,tを与えた際の最長共通部分列(LongestCommonSubsequence:LCS)を次式で定義する：[(s,t)=_s[i]j,s[i]=t[j]|i|]記号列s,tを与えた際の最長共通部分列長（LCS長）を次式で定義する：[|(s,t)|=_i,j:s[i]=t[j]|i|][0,1]区間に正規化すると，以下のようになる：[_(s,t)=2|(s,t)||s|+|t|]なお，挿入のコストを1，削除のコストを1，代入のコストを2（もしくは代入を禁止）とした場合のLevenshtein距離（編集型距離）とLCS長の関係は以下のようになる：[_(s,t)=|s|+|t|-2|(s,t)|]さらにLCSは節で示すとおり，対称群上の編集型距離のうちのUlam距離と深く関連し，一種の順序尺度であるとも考えられる．</subsubsection>
  <subsubsection title="ギャップ加重最長共通部分列長による指標">部分列LCSは部分文字列LCSubstrと異なり，ギャップを伴う．ギャップが多いLCSに減衰させた値を割り当てるために，「LCSの記号列上の長さ」に対して加重を行うことができる．「LCSの記号列上の長さ」は参照テキスト側（|(C,R)|_Rで表す）とシステム出力テキスト側（|(C,R)|_Cで表す）とで異なるために，それぞれ計算する必要がある．|(C,R)|_R=_(j_|j|-j_1)|i,j,C[i]=R[j]|j||(C,R)|_C=_(i_|i|-i_1)|i,j,C[i]=R[j]|i|gather*参照テキスト側で重みを付けて正規化する再現率的な指標を_(C,R)とし，システム出力テキスト側で重みを付けて正規化する精度的な指標を_(C,R)とすると以下のようになる．_(C,R)=^|(C,R)|_R-|(C,R)||(C,R)||R|[1ex]_(C,R)=^|(C,R)|_C-|(C,R)||(C,R)||C|gather*全体を正規化すると以下のようになる．[^()_(C,R)=(1+^2)R_(C,R)P_(C,R)R_(C,R)+^2P_(C,R)]ここでは_と_のどちらを重視するかの混ぜ合わせ係数である．</subsubsection>
  <subsection title="自動評価指標">次に自動要約と機械翻訳の自動評価指標を確認するが，基本的には文単位の評価かつ参照テキストが一つであるという仮定をおく．</subsection>
  <subsubsection title="要約の評価指標">ROUGE-Lは，システム出力テキストと参照テキストの最長共通部分列(LCS)長を指標として正規化したものである．[^()_(C,R)=(1+^2)R_(C,R)P_(C,R)R_(C,R)+^2P_(C,R)]ここで再現率に相当するR_(C,R)と精度に相当するP_(C,R)は以下のように定義する：R_(C,R)=|||R|[1ex]P_(C,R)=|||C|gather*上記指標は文単位のものであり，文書レベルに拡張するために，システム出力テキスト中の文c_iCと参照テキスト中の文r_jRのLCS記号列中の記号の集合和を用いて評価する．同様の議論が他の指標においても行われているが，以下本稿ではこの議論を省略する．ROUGE-WROUGE-Wは，ギャップ加重最長共通部分列長に似た概念である．違いとしては「LCSの記号列上の長さ」を参照テキスト側とシステム出力テキスト側|(C,R)|_R+|(C,R)|_Cでとった上で，加重関数f(x):f(x+y)&gt;f(x)+f(y),x&gt;0,y&gt;0,xN,yN（Nは自然数）を別に定義して「LCSの記号列上の長さ」に対して加重を行う．ROUGE-Wの実装ではf(x)=x^という多項式を用いており，ギャップ加重最長共通部分列長^()_(C,R)の変種と考えることができる．ROUGE-NROUGE-Nはn-gramの一致度を指標として用いるものである．[^(R)_(C,R)=_e((C)(R))(|e|_C,|e|_R)_e(R)|e|_R]但し，(C)はシステム出力テキストC中のn-gram集合，(R)は参照テキストR中のn-gram集合，|e|_CはCに含まれるeの要素数（のべ出現数），|e|_RはRに含まれるeの要素数とする．ROUGE-S(U)ROUGE-Sは，2-merの部分列の一致度を指標として用いるものである．[^()_(C,R)=(1+^2)P_S(C,R)R_S(C,R)R_S(C,R)+^2P_S(C,R)]ここで精度に相当するP_S(C,R)と再現率に相当するR_S(C,R)は以下のように定義する：P_S(C,R)&amp;=_e(_C_R)(|e|_C,|e|_R)_e(C)|e|_C_S(C,R)&amp;=_e(_C_R)(|e|_C,|e|_R)_e(R)|e|_Ralign*但し，(C)はC中のp-mer集合，(R)は参照テキストR中のp-mer集合とする．ROUGE-SUは上のROUGE-Sのp=2をp2に拡張したものである．ESKESKは畳み込みカーネルの一つである拡張文字列カーネルのうち，ギャップ加重p-mer部分列カーネルを評価指標として定義したものである．[&amp;^_(C,R)&amp;=_u(C)_v(R)^|u|-p(u,v)|u||v|(_u,u'(C)^(|u|-p)|u||u'|)+(_v,v'(R)^(|v|-p)|v||v'|)split]では2-merの部分列に制限するほか，文単位に比較し精度重視の指標と再現度重視の指標の二つの重みつき調和平均(01)を定義している．ESKは他に各形態素に付与される意味ラベルを考慮した評価指標を提案しているが，本稿で用いるESKは意味ラベルを考慮しない形態素基本形に基づくものとする．</subsubsection>
  <subsubsection title="翻訳の評価指標">BLEUBLEUは機械翻訳評価のための指標で，nの値を変えたn-gramの精度系指標の重み(_n)付き相乗平均により指標を定義する．P^_(C,R)&amp;=_e((C)(R))(|e|_C,|e|_R)_e(C)|e|_(C,R)&amp;=BP(C,R)(^N_n=1_nP^_(C,R))align*ここで相乗平均の計算を簡単にするために^N_n=1_n=1という制約がある．短いシステム出力テキストに対して高い精度が出やすいこの精度系の指標に対し，精度と再現率の重み付き調和平均という方法を取らず，BrevityPenalty(BP)という項を入れて補正している．[(C,R)=.]IMPACTIMPACTはLCSに基づく指標ではなく，LCSubstrの再帰的な取得による指標である．R_IP(C,R)&amp;=(^_r=0(^r_e(C^(r),R^(r))|e|^)|R|^)^1[1ex]P_IP(C,R)&amp;=(^_r=0(^r_e(C^(r),R^(r))|e|^)|C|^)^1align*ここではイテレート回数r(r)に対する重み(&lt;1.0)，はLCSubstr長に対する重み(&gt;1.0)，C^(1)=C，R^(1)=R，C^(r)=C^(r-1)(C^(r-1),R^(r-1))，R^(r)=R^(r-1)(C^(r-1),R^(r-1))とする．[_=(1+^2)R_P_R_+^2P_]この指標は節に示す文字列長加重全部分文字列カーネルに関連がある．文字列長加重全部分文字列カーネルに対して，再帰的にLCSubstrを選択する際に既選択のLCSubstrを排除し，再帰の回数をRNで制限するという制約を入れたものである．RIBESRIBES(平尾,磯崎,須藤,Duh,塚田,永田2014)は，hirao-2014-JNLP-journalシステム出力テキストと参照テキストのアラインメントをとったうえで，語順の編集型順序尺度を考慮したものである．[_&amp;=(d_(_(C,R)))&amp;(P_(C,R))^((C,R))^split]ここでd_(,)は節で定義する順位ベクトル,に対するKendall距離，_(,)は元論文のworderで出力されるアラインメントされた二つの順序ベクトルの対を表す．右辺2項目は1-gram（単語ベースのもの）精度とよびP_(C,R)=|_(C,R)||C|とする．|_(,)|はworderで出力されるアラインメントされた順序ベクトルの長さ（二つ出力されるが等しい）である．は1-gram精度に対する重み，はBLEUで用いられたBPに対する重みである．なお，P_(C,R)は，それぞれの記号列に重複する記号がない場合，以下が成り立つ：P_(C,R)&amp;=^(P)_(C,R)[1ex]=&amp;_e((C)(R))(|e|_C,|e|_R)_e(R)|e|align*LRscoreLRscoreも同様に，アラインメントをとったうえで，語順の順序尺度を考慮したものである．順序尺度としてベクトル型であるHamming距離と編集型であるKendall距離を用いている．^_(C,R)&amp;=BP(C,R)d_(C,R)+(1-)_(C,R)[1.5ex]^_(C,R)&amp;=BP(C,R)d_(C,R)+(1-)_(C,R)align*は語順をどの程度考慮するかの重みつけ係数．</subsubsection>
  <subsection title="関連するカーネル・順序尺度">上に述べた指標は，基本的には以下のカーネルおよび順序尺度の組み合わせで構成することができる．以下では，各種指標に関連するカーネルおよび順序尺度について確認する．</subsection>
  <subsubsection title="カーネル・距離（文字列の共有）">畳み込みカーネルのうち系列データに対するカーネルは，共通する部分文字列・部分列を数え上げる．いずれも効率よく計数する方法が提案されている(Shawe-TaylorandCristianini,大北訳2010)Taylor-2010．また，適切に正規化することにより部分文字列・部分列の共有についての距離や指標を規定することができる．様々なカーネルの説明に入る前に，[0,1]区間正規化について示す．カーネルの[0,1]区間正規化はカーネルの研究分野でよく用いられており以下の式により行われる：[_K_-(s,t)=K_-(s,t)||K_-(s,s)||||K_-(t,t)||]各種指標のように，再現率--精度間の重みを入れたい場合には以下のようにする：[^()_K_-(s,t)=(1+^2)K_-(s,t)(K_-(s,s))^2+^2(K_-(t,t))^2]全部分文字列カーネルと文字列長加重全部分文字列カーネル全部分文字列カーネル(AllStringKernelorExactMatchingKernel)は共通する全ての部分文字列の数を数える．任意の長さの部分文字列uの出現数を座標軸とする特徴量空間F_を考える．^*_:^*&amp;F_R^||^*^*_(s)&amp;=(^*_u(s))_u^*^*_u(s)&amp;=|i|s_i*=u|_(s,t)&amp;=^*_(s),^*_(t)_F_&amp;=_u^*^*_u(s)^*_u(t)align*カーネル関数を直接計算すると以下のようになる：[K_(s,t)=^(|s|,|t|)_n=1^|s|-n+1_i=1^|t|-n+1_j=1(s_ii+n-1,t_jj+n-1)]ここではクロネッカーのデルタとする．言語処理の場合，得られるn-gramに対して加重をかけることが一般に行われている．文字列長に対して加重をかけたものを文字列長加重全部分文字列カーネル(LengthWeightedAllStringKernelorLengthWeightedExactMatchingKernel)と呼ぶ．[&amp;K_(s,t)&amp;=^(|s|,|t|)_n=1^|s|-n+1_i=1^|t|-n+1_j=1_|s|(s_ii+n-1,t_jj+n-1)split]ここで_nは長さnに対する重みを表す．節で述べたIMPACTはこのカーネルの特殊形とみなすことができる．このカーネルと次のn-スペクトラムカーネルはSuffixTreeを用いて効率よく計算する方法が提案されている．n-スペクトラムカーネルn-スペクトラムカーネル(SpectrumKernel)は共通する長さnの部分文字列(n-gram)の数を数える．長さnの部分文字列uの出現数を座標軸とする特徴量空間F_を考える．^n_:^n&amp;F_R^||^n^n_(s)&amp;=(^n_u(s))_u^n^n_u(s)&amp;=|i|s_ii+n-1=u|_(s,t)&amp;=^n_(s),^n_(t)_F_&amp;=_u^n^n_u(s)^n_t(t)align*直接計算すると以下のようになる：[K_(s,t)=^|s|-n+1_i=1^|t|-n+1_j=1(s_ii+n-1,t_jj+n-1)]ROUGE-Nは，分子にK_(C,R)より小さい値を持ち，分母に参照テキストののべ出力n-gram数を持つことから，再現率として正規化したものに相当する．通常の正規化したK_(s,t)は再現率と精度の調和平均と解釈できる．また1-gramスペクトラムカーネルは1-mer部分列カーネルと同値で，これらは近似的にBLEUなどで利用されているBP相当の値を計算すると考える．全部分列カーネル全部分列カーネルは共通するすべての部分列の数を数える．任意の長さの部分列vの出現数を座標軸とする特徴量空間F_を考える．^*_:^*&amp;F_R^||^^*_(s)=&amp;(^*_v(s))_v^*^*_v(s)=&amp;|i|s[i]=v|_(s,t)=&amp;^*_(s),^*_(t)_F_=&amp;_v^*^*_v(s)^*_v(t)align*K_(s,t)は以下のように再帰的に計算することによりO(|s||t|)で計算することができる．を空記号列とするとK_(s,)=K_(t,)=1とし，K_(s,t)が求まるとK_(sa,t)=K_(s,t)+_1i|t|,j:t_j=aK_(s,t_ij-1)とs再帰的に定義できる．さらにK_(sa,t)=K_(s,t_ij-1)とすると，K_(sa,tb)=K_(sa,t)+(a,b)K_(s,t)とt再帰的に定義できる．固定長部分列カーネル固定長部分列カーネルは共通する長さpの部分列(p-mer)の数を数えあげる．長さpの部分文字列vの出現数を座標軸とする特徴量空間F_を考える．^p_:^p&amp;F_R^||^p^p_(s)&amp;=(^p_v(s))_v^p^p_v(s)&amp;=|i|s[i]=v|_(s,t)&amp;=^p_(s),^p_(t)_F_&amp;=_v^p^p_v(s)^p_v(t)align*ROUGE-Sは，分子にK_(C,R)より小さい値を持ち，分母に参照テキストののべ出力2-mer数を持つことから，再現率として正規化したものに相当する．ROUGE-SUは，分子にK_(C,R)より小さい値を持ち，分母に参照テキストののべ出力1-mer,2-mer数を持つことから，再現率として正規化する．通常の正規化したK_(s,t)は再現率と精度の調和平均と解釈できる．ギャップ加重部分列カーネルギャップ加重部分列カーネルはp-merの部分列の数え上げの際に隣接性を考慮して重みを加重する．ESKは，このカーネルを用いた尺度である．長さpの部分列vを座標とする特徴量空間F_を考える．K_(s,t)&amp;=^gap_p_(s),^gap_p_(t)_F_&amp;=_v^p^gap_p_v(s)^gap_p_v(t)align*ここで^gap_p_v(s)=_i:v=s[i]^l(i)とし，l(i)=|s_i_1i_|v||(i=i_1,,i_|v|)とする．</subsubsection>
  <subsubsection title="順序尺度">以下では順序尺度について考えるが，文献に詳しい解説がある．基本的には同じ長さmの二つの順位ベクトル,S_mに対する2種類の距離を考える．順位ベクトル型距離一つ目の距離は「順位ベクトル型」の距離で順位ベクトルをm次元空間中の点を表すベクトルとみなし，ベクトル空間上の距離を定義する．ベクトル空間上の-ノルムを用いると以下のようになる：[d_||||_(,)=(^m_i=1|(i)-(i)|^)^1/]ここで=1の場合，特にSpearmanfootruleと呼ぶ．[d_(,)=(^m_i=1|(i)-(i)|)]=2の場合は通常のEuclid距離だが，このEuclid距離を2乗したものを特にSpearman距離と呼ぶ．[d_(,)=(^m_i=1|(i)-(i)|^2)]Spearman距離は，距離の公理のうち対称性と正定値性を満たす．しかし，Euclid距離を2乗したものなので三角不等式を満たさないが，慣習的に距離として扱われる．さらに[-1,1]区間に正規化したものはSpearmanの順位相関係数として知られている．[;=1-6d_(,)m^3-m]この値は順序尺度に基づく二つの順位ベクトル,のPearson相関係数と等しい．その他，順位ベクトルの同一順位のものが同じ要素である要素数を数えたHamming距離がある．[d_(,)=^m_i=1((i),(i))]Hamming距離は文字列上で代入（コスト1）のみを許した編集距離としても解釈できる．また，距離_||||_，d_，d_，d_に対応するスコア_||||_，_，_，_を次のように規定することができる．[_-=11+d_-]対称群上の編集型距離二つ目の距離は「編集型」の距離である．順序ベクトルを記号列とみなした場合，順位ベクトルをもうひとつの順位ベクトルに変換するために必要な最小操作数を意味するLevenshtein距離について述べた．以下では，順序ベクトルを対称群とみなした場合の編集型距離について述べる．編集に許される操作によっていくつかの距離のバリエーションがある．Kendall距離：距離d_(,)は順序ベクトルを対称群とみなした際に隣接互換で置換する最小回数によって定義される．言い換えると隣接する対象対を交換(Swap)する操作の最小回数を用いたものである．Kendall距離は，二つの順位ベクトル中のm(m-1)2個の対象対のうち逆順になっている対の数に等しい．d_(,)=(_q((^q_q=1_2(k_q,k_q+1)),))_(,)=^m_i=1^m_j=i+1(i,j)gather*ここで，k_qは順位ベクトルのインデックス．また，は対象対i,jが同順のとき0，逆順のとき1を返す指示関数：[=.]_2=(i,i+1)は隣接する二つの元のみを入れ替えて他の元は変えない操作である隣接互換を意味する．これを指標として使いやすくするために[0,1]区間の範囲に正規化すると以下のようになる：[_(,)=1-2d_(,)m^2-m]これを[-1,1]区間の範囲に正規化したものはKendallの順位相関係数として知られている．[;=1-4d_(,)m^2-m]Cayley距離：距離d_は順序ベクトルを対称群とみなした際に互換で置換する最小回数によって定義される．言い換えると隣接していなくても良い対象対を交換(Swap)する最小回数を用いたものである．[d_(,)=(_q((^q_q=1_2(k_q,l_q)),))]ここで，k_q,l_qは順位ベクトルのインデックス．_2=(i,j)は二つの元のみを入れ替えて他の元は変えない操作である互換を意味する．Ulam距離：距離d_は順序ベクトルを対称群とみなした際に連続した順序ベクトル部分列i,i+1,,j-1,jの巡回置換の操作のみで置換する最小回数によって定義される．これは「本棚の本の入れ換え」で例えられる．順位ベクトルで並んでいる本棚の本を順位ベクトルに並べ替えるために，ある要素を抜いて別の場所に挿入するということを行う．Ulam距離は同じ要素が記号列に存在しないという前提のもと，最長一致部分列長と以下の関係にあることが知られている．[d_(,)=m-|(,)|]これを[0,1]区間の範囲に正規化すると以下のように正規化最大共通部分列と同じになる：_(,)&amp;=1-d_(,)m&amp;=|(,)|m&amp;=_(,)align*図に順序ベクトルによる置換により表現した編集型距離の例を示す．編集型距離の定義で許される編集の回数を数えると，順序ベクトル(1,4,3,2)と(1,2,3,4)のKendall距離は3，Caylay距離は1，Ulam距離は2となる．また，順序ベクトル(2,3,1,4)と(1,2,3,4)のKendall距離は2，Caylay距離は2，Ulam距離は1となる．以下は，我々の意見だが，言語生産時の編集作業の工数を評価する場合には，のswapに代表されるようなKendall距離のような編集よりもUlam距離のような編集を考慮すべきであると考える．言語生産時に，Kendall距離で考慮される列内絶対位置よりも，Ulam距離で考慮される列内相対位置を考えながら編集を行う方が人にとって自然な処理であると考える．順序尺度間の関係ベクトル型の;と;との間には以下のDanielsの不等式が成立する：[-13(m+2)m-2-2(m+1)m-21]mの極限をとると-13-21が成り立つ．このことから二つの相関係数の間の相関が高いことが示される．距離の観点からは，d_d_が成り立つ．さらにFootrule距離とKendall距離とCayley距離の間に以下の不等式が成り立つ(Diaconis-Grahaminequality):[d_+d_d_2d_]またSpearman距離とKendallの距離の間には以下の不等式が成り立つ(Durbin-Stuartinequality):[43d_(1+d_m)d_]つまり，評価指標のデザインにおける順序尺度の選択による差異は，これらの不等式の範囲によって制限される．</subsubsection>
  <subsection title="指標の一般化">以上，評価指標・距離・カーネル・相関係数を議論してきた．まとめると付記B表のようになる．各指標と人手の評価結果をできるかぎり合わせるという観点からすると，のように，表にあげたすべての尺度_-_*の加重相乗平均（下式）を考え，加重_-と各指標に付随するパラメータを，各指標の従属性や相関に注意しながら人手の評価結果との回帰により求めれば良い．_*=[_-]^_-_-_*=1_-(w_-_-)gather*この指標のあり方については注意すべき点がいくつかある．substring（部分文字列：n-gram系）とsubsequence（部分列：p-mer系）との違いを踏まえる．最長一致部分長は対称群上の編集型距離であるUlam距離と深く関連する．順序に対する順位ベクトル型距離と編集型距離の間には節に示される関係が成り立つ．本稿では，先に述べた四つの尺度がそれぞれどのような特性があるかを明らかにすることを目的としており，最適な指標の組み合わせについては検討を行わない．次節以降，各尺度がさまざまな言語資源上でどのようなふるまいをするのかについてみていきたい．</subsection>
  <section title="評価に用いる言語資源">ここでは様々な言語生成過程を記録した言語資源におけるテキスト対の尺度の差異を検証することにより，各尺度がとらえようとしているものが何なのかを分析する．表に，利用する言語資源について示す．まず言語生産過程として，要約(BCCWJ-SUMM)と語釈(GLOSS)と再話(RETELLING)の3種類の言語資源を用いる．要約は長い元文書を短くする情報提示手法である．語釈は短い単語を長い文書で説明する情報提示手法である．再話は長い元文書をできるだけその内容を保存したまま示す情報提示手法である．情報提示手法を比較することで，各尺度が何を評価しているのかを明らかにすることを試みる．要約と語釈については，クラウドソーシングにより安価で大量にデータを得る手法（タイプ入力）と実験室にて被験者に繰り返し同一課題を依頼してデータを得る手法（筆述）の2種類の方法を用いた．再話のデータについては既存のデータを用い，筆述による形態と口述による形態のデータを準備した．言語生産形態として，タイプ入力・筆術・口述の3種類のデータを対照比較する．これは評価尺度が，要約の内容の類似度だけでなく，個人の文体の類似度を評価してしまう部分を分析するために準備した．それぞれ文体の統制が可能なレベルが異なっており，評価尺度に影響を与えるものだと考え，これを評価することを試みる．さらに，大勢の実験協力者に同じタスクを行わせる場合の協力者間の尺度のふるまいと，同一の実験協力者に同じタスクを複数回行わせる場合の尺度のふるまいを検証し，どの尺度にゆれが生じるかを明らかにする．以下各言語資源について解説する．</section>
  <section title="尺度の定性的な分析"/>
  <subsection title="尺度の分析方法">本節では前節で述べたコーパスを用いて各尺度がどのように振る舞うかを観察する．利用する尺度は以下の30種類である．n-gramスペクトラム(1,2,3,4)(char/mrph)n-gram以下スペクトラム(2,3,4)(char/mrph)p-mer部分列(2,3,4)(char/mrph)p-mer以下部分列(2,3,4)(char/mrph)1-gramスペクトラム+Footrule(char/mrph)(=Spearman)1-gramスペクトラム+Kendall(char/mrph)付記C表,に各コーパス中の2サンプル間の尺度の平均値(Mean)と標準偏差(SD)を示す．スコアについて(char)``_c''は文字単位の記号列として評価したもの，(mrph)``_m''は形態素単位の記号列(MeCab-0.98+IPADIC-2.7.0による)として評価したものである．括弧内の数字は部分文字列長（n-gramにおけるn）もしくは部分列長（p-merにおけるp）を示す．シャピロ・ウィルク検定の結果，ほとんどの場合p値が0.05未満であり，正規分布とはいえない傾向が見られた．</subsection>
  <subsection title="尺度のグラフ">図に形態素単位に評価した，n-gram(1),n-gram(2),p-mer(2),Kendallの尺度のタスク毎の平均値グラフを示す．エラーバーは標準誤差を表す．unigram(n-gram(1))を用いた場合，要約と語釈は中程度，再話はかなり高い値である．GLOSS_L(T)がほぼ再話と同程度の値である一方，BCCWJ-SUMM_L(T)が低いことから，要約を繰り返す際の言語生産の特殊性が見られる．要約を繰り返す際には，回数毎に文章中の重要箇所を変更するサンプル・被験者が存在し，標準偏差も高くなっている．bigram(n-gram(2)),skip-bigram(p-mer(2))を用いた場合，異なる被験者間と繰り返し間との間に差が見られるようになる．これは何らかの個人の文体差が形態素の連接に影響を与えているのではないかと考える．bigram(n-gram(2))とskip-bigram(p-mer(2))の間の差として，語釈の場合のみbigramの値が下がった．語釈という課題の性質上，物語や要約と異なり，情報の提示順が変わることも考えられる．しかし，順序尺度であるKendallの値ではbigramの値ほど顕著な差が見られなかった．単語の隣接性が語釈のみ下がるという値のふるまいについては今後検討していきたい．クラウドソーシングと研究室内被験者実験との差(BCCWJ-SUMM_CBCCWJ-SUMM_L(P),GLOSS_CGLOSS_L(P))については，各尺度・各課題（要約・語釈）で差が見られなかった．</subsection>
  <subsection title="課題間の評価">以下，課題間を比較するために，6種類の評価軸を分析する．ほとんどの場合，正規分布であることも等分散であること（F検定による）も仮定できない．ここではウィルコクソンの順位和検定（0.05未満で2群の代表値が左右にずれている）を行う．多重比較に対応するためにBonferroni法を用いた．付記C表に結果のまとめを示す．実験室における複数人の課題間の違いの評価	BCCWJ-SUMM_L(P)GLOSS_L(P)	RETELLING_K(P)RETELLING_M(P)		BCCWJ-SUMM_L(P)GLOSS_L(P)文字単位の評価の場合n-gram(2,3,4)_charに	有意差が見られた．	形態素単位の評価の場合	n-gram(2,3,4)_mrphに有意差が見られた．	BCCWJ-SUMM_L(P)RETELLING_K(P)n-gram(4)_char,n-gram(3,4)_mrph以外で有意差が見られた．	BCCWJ-SUMM_L(P)RETELLING_K(M)n-gram(4)_mrph以外で有意差が見られた．	GLOSS_L(P)RETELLING_K,M(P)	全ての尺度について，有意差が見られた．	RETELLING_K(P)RETELLING_M(P)	全ての尺度について，有意差が見られなかった．		要約語釈間はn-gram(1)で有意差が見られなかった．	同じ文字・同じ形態素を使うという観点では一致度のレベルが	等しいが，語の連接が入ると有意差が見られることがわかっ	た．グラフからは語釈の方が語の連接や順序尺度の一致度が低い．これは語釈の目的としては情報の提示順に重要性のないことが伺える．	要約再話，語釈再話の間において	は有意差が見られた．再話は同じ話をするという特性から一致度が高	くなる一方，要約・語釈は目的を達成するがために同じ表現を用いなけ	ればならないという制約がなく，一致度が低くなる傾向にある．	また同一課題の語釈間では有意差はなかった．実験室における単一人の回数間距離の課題間の違いの評価	BCCWJ-SUMM_L(T)GLOSS_L(T)	RETELLING_I(T)RETELLING_K(T)	RETELLING_M(T)		BCCWJ-SUMM_L(T)GLOSS_L(T)文字単位の評価の場合n-gram(1,2,3,4)_char,	p-mer(2,3,4,2,3,4)_charに有意差があった．	形態素単位の評価の場合	n-gram(1,2,3)_mrph,Kendall_mrphに有意差があった．	BCCWJ-SUMM_L(T)RETELLING_I,K,M(T)	n-gram(4)_char(BCCWJ-SUMM_L(T)	RETELLING_K(T)),n-gram(4)_mrph(BCCWJ-SUMM_L(T)	RETELLING_K,M(T))以外の全ての尺度について，有意差が見られた．	GLOSS_L(T)RETELLING_I,K,M(T)	全ての尺度について，有意差があった．	RETELLING_I(T)RETELLING_K(T)n-gram(1)_mrphについてのみ有意差があった．	RETELLING_I(T)RETELLING_M(T)文字単位の評価の場合n-gram(4)_char,footrule_char,	kendall_char以外に有意差があった．	形態素単位の評価の場合，	kendall_mrph以外に有意差があった．	RETELLING_I(T)RETELLING_M(T)文字単位の評価の場合全ての尺度に有意差がなかった．	形態素単位の評価の場合，n-gram(2,3,4)_mrph,footrule_mrph,kendall_mrph以外に有意差があった．		複数人間の評価ではなく，複数回間の評価でも同じ傾向が見ら	れる．	再話課題間については，形態素単位の評価において，三課題のうち	どの二つ組においても有意差が出る傾向にある．	口述による再話(RETELLING_I,K)の方が筆述による再話	(RETELLING_M)より一致度が高くなる．	また口述による再話においては，自身の体験に基づく再話	(RETELLING_I)の方が，他者から聞いた話の再話(RETELLING_K)よりも	一致度の高くなることが認められた．クラウドソーシングにおける課題間の違いの評価	BCCWJ-SUMM_CGLOSS_Cについて，全	ての尺度について，有意差があった．	クラウドソーシングにおける課題間の違いについても，前項と同じ傾向	が見られる．要約課題においてクラウドソーシングと実験室との違いの評価（複数	人間）	BCCWJ-SUMM_CBCCWJ-SUMM_L(P)について，	n-gram(2)_char,n-gram(3)_char,n-gram(4)_charにのみ	有意差があった．	これは，タイプ入力(BCCWJ-SUMM_C)と筆述(BCCWJ-SUMM_L(P))とで，	表記ゆれ統制の差の影響が考えられる．語釈課題においてクラウドソーシングと実験室との違いの評価（複数	人間）	GLOSS_CGLOSS_L(P)について，	n-gram(2,3,4)_char,	n-gram(2,3,4)_mrph,	Footrule_mrph,Kendall_mrph以外について有意差があった．		語釈においては，クラウドソーシングの場合wikipediaや辞書サイト	からのコピーが行われる傾向にある一方，実験室の場合は特にリファレ	ンスもなく筆述で行うために差が出たのではないかと考える．複数人間距離と単一人の回数間距離の違いの評価	BCCWJ-SUMM_L(P)BCCWJ-SUMM_L(T),	GLOSS_L(P)GLOSS_L(T),	RETELLING_K(P)RETELLING_K(T),	RETELLING_M(P)RETELLING_M(T)について，全	ての尺度について有意差があった．	基本的に単一人が実施したほうが一致度が高いと考えられるが，統計分	析の結果からもそれが確認できる．</subsection>
  <subsection title="各評価尺度の特性">課題間の議論から考えられる各尺度の特性について論じる．まず，文字n-gramはタイプ入力と筆述入力の差として認められることから，表記ゆれレベルで一致度の下がる特性があると考える．形態素n-gramは再話と繰り返しで顕著に高くなったことから，個人の文体などを反映していると考える．p-mer,Footrule,Kendallなどは語順の一致を反映していると考えられるが，ストーリー性がある要約・再話で一致度が高い一方，語釈などにおいては低い傾向にあることがわかった．語順に対して，ストーリーの一致を評価するのか，説明の順序を評価するのかについて深く検討する必要があると考える．ストーリーの一致についてはにおいて，被験者実験的に人が何を同一の物語とみなすかについて検討されている．また，語釈などにおいても情報提示順序により伝わりやすさが変わることが報告されている．自動要約の評価尺度で導入された語順の尺度については，ストーリーの一致（内容一致）を目的とするのか，伝わりやすさの一致（表現一致）を目的とするのかについては言及されていない．今回の調査では，タスクの設定によりこれらを切り分けることを試みたが，タスク間の差異は確認できなかった．n-gram,p-merともにn,pの値が高くなるにつれて尺度の値が低くなる．このために有意差が出にくくなる傾向にある．n-gram,p-merともにn(orp)以下の尺度として設定した場合に，より低いn(orp)の方が一致が多くなる傾向にあるために，より高いn(orp)の差異が見られなくなる傾向がある．これは尺度の自然な解釈であると考えられるが，何らかの用途で長いn-gram,p-merを重要視する場合には部分（文字）列長に対して加重を行う必要があるだろう．n-gram(1)_*とKendall_*と比較した場合，n-gram(1)_*では有意差が出るが，順序尺度を入れたKendall_*では有意差が出ない尺度の組み合わせがいくつかあった．これは文字順・語順の一致度が低い場合に，順序尺度を掛けあわせたがために全体の一致度の差がなくなったことが考えられる．</subsection>
  <section title="おわりに">本稿では，まず自動要約・機械翻訳で用いられている評価指標の数理的構造を説明した．評価指標がどのカーネル・距離・相関係数などの尺度と対応しているのかを説明し，n-gram系，p-mer系，ベクトル型順序尺度，編集型順序尺度の四つに抽象化した．次に様々な言語資源を用いて各指標を構成する尺度の特性を明らかにした．要約・語釈・再話からなる7種類の言語資源を用いて，課題・多人数産出・複数回産出・産出手段（口述・筆述・タイプ）の軸を用いて，どのような分散が観察されるかを確認した．結果，各評価尺度において，表現一致と内容一致の識別は困難であり，評価の識別限界としての分散があることを示した．今後の展開として以下の五つを考えている．一つ目は要約評価に求められる尺度とは何かを明らかにすることである．尺度が捉える言語の特性については明らかにしたが，自動要約に必要な内容評価と読みやすさの観点については何も言っていないに等しい．現在，収集した要約に対して，以下の五つの軸で人手による評価を付与している．文法性(Grammaticality):誤字・文法的でない文が含まれていないか非冗長性(Non-redundancy):全く同じ情報が繰り返されていないか指示詞の明解さ(Referentialclarity):先行詞のない指示詞（代名詞）が含まれていないか焦点(Focus):要約全体と無関係な情報が含まれていないか構造と一貫性(StructureandCoherence):接続詞を補ったり削除したりする必要のある箇所はないか人手による評価を悉皆的に付与したうえで，各評価軸がどの尺度に表れるのかを引き続き分析していきたい．二つ目は情報構造アノテーションとの重ね合わせである．尺度において，語順の評価を入れるかどうかが一つの論点であった．日本語において語順を決める一つの要素として情報構造がある．情報構造は言語生産者側の観点である情報状態speaker-new,speaker-oldと言語受容者側の観点である共有性hearer-new,hearer-oldの区別を行い，後者については被験者実験的にアノテーションを行う．これらのアノテーション結果を用いて，なぜ要約文はその順序で情報を提示する必要があるのかについて検討する．三つ目は要約文の言語受容者側の観点からの認知的な評価である．今回は元文書の言語受容者であり要約文の言語生産者側の観点からの認知的な評価を主に扱った．生産された要約文が他の言語受容者にとって同じ話として認定されるかを検討していきたい．一方，日本語複数文書要約についての拡張も考えられるが，元文書側の言語生産者が複数人になるという問題がある．複数の言語生産者側が考慮している情報構造が，要約作成者と要約受容者にどのように受容されるか追跡可能な認知実験手法を検討する．四つ目は人文系の研究者が評価する文体についての尺度を明らかにすることである．文体の研究は使用域(register)や位相(phase)などに着目して行われるが，現在のところ役割語など単一の語についての研究がほとんどである．語の連接や語の順序などの使用域や位相を，先に述べた尺度で捉えることを目標とする．五つ目は同じ話とは何かということを定量的に評価する手法の提案である．内容を捉える尺度と表現を捉える尺度を分離することで，人が内容が一致していると認知できる表現のゆれを捉えることを目標とする．既に同じ話を構成する要素について，様々な分析を進めているが，これらの結果が尺度にどのように表れるのかについて分析を行う．</section>
  <section title="指標・スコア・距離・カーネル・相関係数の関係まとめ"/>
  <section title="言語生成過程と尺度">表に節で行った検定の結果のまとめを示す．表に要約課題・語釈課題と各尺度の比較を表に再話課題と各尺度の比較を示す．標準偏差はBCCWJ-SUMM_L(T)が最も大きい．これは繰り返し要約する際に全く同じ要約文を再生産する被験者と全く異なる要約文を再生産する被験者とが存在するからだと考えられる．しかし，他の再話(RETELLING_K(T),RETELLING_M(T))でも被験者間の標準偏差と比して高いことから要約文特有の現象ではないと考える．document</section>
</root>
