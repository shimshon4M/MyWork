    \documentclass[japanese]{jnlp_1.4}
\usepackage{jnlpbbl_1.3}
\usepackage[dvipdfm]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{hangcaption_jnlp}


\Volume{23}
\Number{5}
\Month{December}
\Year{2016}

\received{2016}{3}{24}
\revised{2016}{7}{3}
\accepted{2016}{8}{26}

\setcounter{page}{407}

\jtitle{特許請求項に特有の文構造に基づく英中日特許請求項翻訳}
\jauthor{富士　　秀\affiref{Author_1}\affiref{Author_2} \and 藤田　　篤\affiref{Author_1} \and 内山　将夫\affiref{Author_1} \and 隅田英一郎\affiref{Author_1} \and 松本　裕治\affiref{Author_2}}
\jabstract{
近年の統計的機械翻訳の進展によって特許文翻訳の精度は大きく向上したが，特許文中で特に重要性の高い特許請求項文に対する翻訳精度は依然として低い．特許請求項文は，(1) 
極めて長い1文から構成される，(2) 
特殊な文構造を持っている，という2つの特徴を持つサブ言語であるとみなせる．そしてこれらが翻訳精度の低さの原因となっている．本論文では，サブ言語に特有の特徴を処理する枠組みの導入によって，特許請求項の翻訳精度を向上させる手法について述べる．提案手法では，同期文脈自由文法を用いて原言語文が持つサブ言語に特有の文構造を目的言語側の文構造に変換することにより，適切な文構造を持った訳文を生成する．さらに本手法では，文全体ではなく，文を構成する構造部品を翻訳の処理単位とすることにより長文の問題に対処する．英日・日英・中日・日中の4翻訳方向で評価実験を行ったところ，全翻訳方向においてRIBES値が25ポイント以上向上し，本手法によって訳文品質が大幅に改善したことがわかった．英日・日英翻訳ではさらにBLEU値が5ポイント程度，中日・日中では1.5ポイント程度向上した．}
\jkeywords{文構造，統計的機械翻訳，特許請求項文，同期文脈自由文法}

\etitle{Patent Claim Translation based on Sublanguage-specific Sentence Structure}
\eauthor{Masaru Fuji\affiref{Author_1}\affiref{Author_2} \and Atsushi Fujita\affiref{Author_1} \and Masao Utiyama\affiref{Author_1} \and Eiichiro Sumita\affiref{Author_1} \and \\
	Yuji Matsumoto\affiref{Author_2}} 
\eabstract{
Patent claim sentences, despite their legal importance in patent documents, 
still pose difficulties for state-of-the-art statistical machine translation 
(SMT) systems owing to their extreme lengths and their special sentence 
structure. This paper describes a method for improving the translation 
quality of claim sentences, by taking into account the features specific to 
the claim sublanguage. Our method overcomes the issue of special sentence 
structure, by transferring the sublanguage-specific sentence structure from 
the source language to the target language, using a set of synchronous 
context-free grammar rules. Our method also overcomes the issue of extreme 
lengths by taking the sentence components to be the processing unit for SMT. 
An experiment demonstrates that our proposed method significantly improves 
the translation quality in terms of RIBES scores by over 25 points, in all 
of the four translation directions i.e., 
English-to-Japanese, Japanese-to-English, Chinese-to-Japanese and 
Japanese-to-Chinese directions. Alongside the improvement in RIBES 
scores, improvements of approximately five points in BLEU scores are 
observed for English-to-Japanese and Japanese-to-English directions, and that of 
1.5 points are observed for Chinese-to-Japanese and Japanese-to-Chinese 
directions.
}
\ekeywords{Sentence Structure, Statistical Machine Translation, Patent Claim Sentences, Synchronous Context-free Grammar}

\headauthor{富士，藤田，内山，隅田，松本}
\headtitle{特許請求項に特有の文構造に基づく英中日特許請求項翻訳}

\affilabel{Author_1}{国立研究開発法人情報通信研究機構}{National Institute of Information and Communications Technology}
\affilabel{Author_2}{奈良先端科学技術大学院大学}{Nara Institute of Science and Technology}



\begin{document}
\maketitle


\section{はじめに}

日英間や日中間のような，文法構造の大きく異なる言語間における特許文書を対象とした統計的機械翻訳の精度は，利用可能な特許対訳コーパスのデータ量の増加に加え，構文解析にもとづく単語並べ替え技術 (Isozaki, Sudoh, Tsukada, and Duh 2010b; de Gispert, Iglesias, and Byrne 2015) の進展によって大きく向上した (Goto, Utiyama, Sumita, and Kurohashi 2015)．しかし特許明細書中の請求項文は，特に重要性が高いにもかかわらず，明細書中の他の文と比較しても依然として翻訳が困難である．

特許請求項文は，以下の2つの特徴を持つサブ言語 (Buchmann, Warwick, and Shann 1984; Luckhardt 
1991) と考えることができる．1つ目の特徴は，非常に長い単一文で構成されることであり，2つ目の特徴は，対象言語に依存しない部品のセットから構成されるということである．特許請求項翻訳の困難さは，まさにこれらの2つの特徴に根差している．1つ目の特徴である特許請求項文の長さによって，事前並べ替え等で用いられる構文解析器が解析誤りを生じる可能性が高くなり，ひいては事前並べ替えの精度が下がる．2つ目の特徴であるサブ言語に特有の文構造は，特許明細書の他の部分で学習された統計的機械翻訳を用いるだけでは正確にとらえることができない．

本稿では，特許請求項文に対する統計的機械翻訳の精度を向上させるための手法について述べる．なお以降の説明では，特許請求項を構成する要素を「構造部品」と呼ぶ．我々は，前述の特許請求項文の特徴に起因する問題を解決するためのモジュールを追加した統計的機械翻訳の枠組みを構築した．サブ言語に特有の文構造に基づく我々の手法は2つの狙いがある．(1) 
事前並べ替えおよび統計的機械翻訳処理を，入力文全体にではなく，文の構造部品を単位として実行する．この構成により事前並べ替えおよび機械翻訳への入力を実質的に短縮し，結果として翻訳精度を向上させる．(2)特許請求項文の文構造を明示的に捉えた上で翻訳を行うことにより構造的に自然な訳文を生成できるようにする．具体的には，言語非依存の構造部品を得るための同期文脈自由文法規則および正規表現を人手で構築し，これら構造部品を非終端記号とした同期文脈自由文法を用いることによって，原文の文構造を訳文の文構造に反映させる．

我々は，英日・日英・中日・日中の4言語対の翻訳について上記提案手法を適用し，その効果を定量的に評価した．提案手法を事前並べ替えと併用した場合に，英日・日英・中日・日中の4言語方向すべての翻訳実験において翻訳品質がRIBES値 (Isozaki, 
Hirao, Duh, Sudoh, and Tsukada 
2010a) で25ポイント以上向上した．これに加えて，英日・日英翻訳ではBLEU値が5ポイント程度，中日・日中翻訳では1.5ポイント程度向上した．英中日3言語の請求項文構造を記述するための共通の構造部品は5種類のみであり，これら構造部品を単位として記述した英日・日英・中日・日中の4言語方向の同期文脈自由文法の規則はそれぞれ10個以内である．非常に少ない数で，この翻訳精度改善を実現することができた．


\section{関連研究}

語順の大きく異なる言語間の機械翻訳の品質は，構文情報を取り込む近年の研究によって大幅に向上した (Collins, 
Koehn, and Kucerova 2005; Quirk, Menezes, and Cherry 2005; Katz-Brown and 
Collins 2008; Sudoh, Suzuki, Tsukada, Nagata, Hoshino, and Miyao 2013; 
Hoshino, Miyao, Sudoh, and Nagata 2013; Cai, Utiyama, Sumita, and Zhang 
2014; Goto, Utiyama, Sumita, and Kurohashi 
2015)．この構文情報を取り込む手法を産業文書等のサブ言語を構成する文書に適用するためには，サブ言語に特有の情報を取り込む必要があると考えられている (Buchmann 
et al. 1984; Luckhardt 
1991)．産業文書等に見られるサブ言語の特徴としては，一文が非常に長いことと，特殊な文構造を持っていることがあげられる．このため，長文を含む入力においてサブ言語に特有の文構造を適切に扱うことが課題となる．

ヨーロッパ言語間のように語順が近い言語間では，長文を構成する複数の節を連結する談話連結詞 (discourse 
connective) の曖昧性を解決することによって訳文の文構造が改善することがわかっている (Miltsakaki, 
Dinesh, Prasad, Joshi, and Webber 2005; Pitler and Nenkova 2009; Meyer, 
Popescu-Belis, Zufferey, and Cartoni 2011; Hajlaoui and Popescu-Belis 2012; 
Meyer, Popescu-Belis, Hajlaoui, and Gesmundo 
2012)．これに対して語順の大きく異なる言語間では，談話連結詞を扱うだけでは不十分であり，例えば長い並列句を含むような原文の文構造を把握して訳文の文構造に変換するような，文構造変換を行う必要がある．

文構造変換の1つの手法として，入力文に対する何らかの解析を行ってから訳文構造に変換する様々な研究が行われてきた．初期の研究では，日英翻訳における文構造変換を目的として，修辞構造理論 (RST: 
rhetorical structure 
theory)に基づくパーザを用いて得られた入力文の修辞構造を目標言語の構造に変換する手法が提案されている (Marcu, 
Carlson, and Watanabe 
2000)．これを発展させた研究としては，RSTパーザで得られた結果から目標言語構造への変換規則を自動獲得する研究も行われている (Kurohashi 
and Nagao 1994; Wu and Fung 2009; Joty, Carenini, Ng, and Mehdad 2013; Tu, 
Zhou, and Zong 2013)．骨格構造 (skeleton) を用いる手法 (Mellebeek, 
Owczarzak, Grobes, Van Ganabith, and Way 2006; Xiao, Zhu, and Zhang 
2014) では，入力文の構文解析結果から文の骨格を形成するキー要素やキー構造を抽出し，原言語文と目的言語文それぞれから抽出した骨格構造同士を一般文同士の場合と同様の手段で学習させる．翻訳実行時には，入力文から骨格構造を抽出して骨格構造翻訳を行い，最後に骨格以下の構造を翻訳して訳文を生成する．分割翻訳 (divide-and-translate) (金, 
江原1994; Jin and Liu 2010; Shinmori, Okumura, Marukawa, and Iwayama 2003; 
Xiong, Xu, Mi, Liu, and Liu 2009; Sudoh, Duh, Tsukada, Hirao, and Nagata 
2010; Bui, Nguyen, and Shimazu 
2012) では，入力文を句や節の単位に分割してそれぞれを目標言語に翻訳し，最後にこれら翻訳された分割部品を結合して訳文を生成する手法である．ルールベース翻訳による分割翻訳では，接続構造を用いて分割を行う手法 (金, 
江原1994) や，概念素性を用いて分割する手法 (Jin and Liu 
2010) 等が提案されている．並列構造解析に基づく翻訳 (Roh, Lee, Choi, Kwon, 
and Kim 
2008) では，入力文の解析結果から並列構造を見つけ出し，これをもとに訳文構造への変換を行う．以上述べてきた文構造変換の手法は，パーザを用いて入力文を解析するため，特許請求項のような長文を多く含むサブ言語ではパーザの解析精度が低く，結果として訳文の品質も低くなるという問題がある．

文構造変換のもう1つの手法としてはパターン翻訳の研究がある (Xia and McCord 
2004; 池原, 阿部, 徳久, 村上2004; 中澤, 黒橋2008; Murakami, Tokuhisa and 
Ikehara 2009; 西村, 村上, 徳久, 池原2010; Murakami, Fujiwara and Tokuhisa 
2013; 坂田, 徳久, 
村上2014) ．パターン翻訳では，原文側と訳文側それぞれについて固定部と変数部を持つパターンを用意しておき，入力文が原文側パターンにマッチしたら変数部を自動翻訳して訳文側固定部に埋め込んで出力する．この手法は，パターンにマッチさえすれば原文全体を構文解析することなく翻訳できるため，長文におけるパーザの解析精度の問題を回避することができる反面，表層的な手がかりをもとに入力文とのマッチを行うので長文に頻出する並列構造や階層を適切に扱うことができないという問題がある．


\section{サブ言語に特有の文構造の変換}

特許請求項は，特許明細書文書の他の部分と比べて，使われている語彙や表現は共通である一方，請求項固有の記述スタイルで記述されるという特徴がある．このことから，請求項自体が1つのサブ言語を構成しているとみなす．この請求項特有の記述方法は，特許出願の歴史の中で徐々に形成され，最近では公的な特許文書の執筆基準書等でも取り上げられるようになってきた．国際特許機関WIPOの特許執筆基準 (WIPO 
2014) によると，英語の請求項は，次の3つの部品から構成される1文として記述されなければならない．
\[
\mathrm{S} \rightarrow \text{PREA\ TRAN\ BODY}
\]

ここで，Sは請求項文，PREAは前提部，TRANは移行部，BODYは本体部をそれぞれ表す．図~1 に英語・日本語・中国語それぞれの，前提部，移行部，本体部の例を示す．前提部は特許発明の範疇を表す導入的な要素であり，本体部は特許発明の中心部であって発明の構成要素や目的を表し，移行部は前提部と本体部を接続する役割を担っている．なお，実際の特許請求項における本体部は，発明を構成する要素である「構成要素」，もしくは発明の目的を説明する「目的部」のいずれかとして記述される．以降の図や例では，構成要素をELEMで，目的部をPURPで表す．

\begin{figure}[t]
\begin{center}
\includegraphics[scale=0.9]{23-5ia2f1.eps}
\end{center}
\caption{英語・日本語・中国語の請求項の例}
\label{fig01}
\end{figure}

図~1 
(a)は，典型的な英語請求項の構造の例である．この例では，本体部は構成要素から構成されている．図~1 
(b)は，(a)の英語請求項構造に対応した日本語請求項構造であり，図~1 (c)は，(a)の英語請求項構造に対応した中国語請求項構造である．ここで，3言語の構造において用いられている構造部品のセットは共通である一方，言語によって構造部品の出現する順番は異なることがわかる．

以降では，英語請求項と日本語請求項の対を例に，提案手法の概要を説明する．図~1 (a)および(b)から，両言語において用いられる構造部品のセットは限定されていることがわかったが，さらに我々の調査から，両言語にはそれぞれ厳密な生成規則が存在することがわかった．図~1 (a)の英語請求項文は，図~2 (a)の英語生成規則によって表される．ここで，ELEMは図~1 (a)における構成要素を表し，記号``$+$''は左に隣接する要素が1回以上繰り返されることを表す．図~2 (b)はこれに対応する日本語規則であり，同一の構造部品セットで構成される．

\begin{figure}[b]
\begin{center}
\includegraphics[scale=0.9]{23-5ia2f2.eps}
\end{center}
\caption{英語・日本語の生成規則とそこから得られたSCFG規則}
\label{fig02}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{23-5ia2f3.eps}
\end{center}
\caption{英日対訳の請求項文の例}
\label{fig03}
\end{figure}

このようにして，特許請求項は言語に関わりなく文構造の規則性が高いことから，我々は言語間の構造変換のために，同期文脈自由文法 (synchronous 
context-free grammar: 
SCFG) を用いることとした．例えば，図~2 (a)と(b)の対応する規則を接続することによって，図~2 (c)のSCFGを獲得できる．ここで，添字の数字は，両木構造における対応する非終端記号間の関係を表す．我々は特許請求項の翻訳のために，このようなSCFG規則を人手で構築した．詳細については4.1節において述べる．

図~3 は英日対訳の請求項文の例である．ここで，PREA，TRAN，BODYはこれら請求項文の構造部品名を表すが，構造部品の出現順は英日で逆順となっていることがわかる．例えば，分割翻訳等の従来の翻訳手法では，分割して得られた入力文の分割要素をどのような順番で出力するかを制御することが困難である．請求項の翻訳では，入力文の文構造を認識し，それに対応する目的言語の文構造で出力する必要がある．


\section{請求項翻訳のための処理パイプライン}

特許請求項文は，文構造が特殊である一方，文中で使われる語彙や表現は他の特許明細書文と共通である．このため本研究の実験では，特許請求項文のための文構造変換機能を前処理モジュールとして用意し，その後段として特許明細書用にチューニングした従来の機械翻訳エンジンをつなげたパイプラインを構築した．具体的には以下に示す3ステップから構成されるパイプラインを構築し，特許請求項文が入力されると，特許請求項に対応した文構造変換が行われ，事前並べ替えを経て，統計的機械翻訳による翻訳が行われる（図~4）．

\begin{itemize}
\item \textbf{ステップ1 文構造変換}：入力文に対して，人手で構築したSCFG規則を搭載したパーザを用いて解析を行う．ここでの目的は，入力文に対する精緻な構文木を得ることではなく，図~1 に示すようなサブ言語に特有の文構造を入力文の中で見つけ出し，この文構造に沿って出力の文構造を生成することにある．同時文脈自由文法を用いることにより，入力文の構造部品を認識すると同時に出力側での文構造を生成する．（図~4 (a) $\to $ (b), (c)）
\item \textbf{ステップ2 事前並べ替え}：上述の各構造部品について単語の事前並べ替えを行い，原言語文の単語を，目的言語の語順に即して並べ替える．ここで使う事前並べ替えは，句構造解析をベースにしたものである．なお，上記ステップ1の出力が当事前並べ替えへの入力となるため，結果として高い解析結果が得られる．（図~4 (c) $\to $ (d)）
\item \textbf{ステップ3 統計的機械翻訳による翻訳：}各構造部品について統計的機械翻訳による翻訳を行う．上述のように特許請求項文は，文構造は特殊でも語彙や表現は他の特許明細書文と共通であるため，特許明細書用にチューニングした統計的機械翻訳をそのまま用いている．ここでも，ステップ1において得られた短い文が入力となるため翻訳品質が向上する．（図~4 (d) $\to $ (e)）
\end{itemize}

以降では，上記ステップ1およびステップ2の詳細について述べる．

\begin{figure}[t]
\begin{center}
\includegraphics{23-5ia2f4.eps}
\end{center}
\caption{翻訳パイプラインの概要}
\label{fig04}
\end{figure}


\subsection{文構造変換}

1章で述べたように，特許請求項翻訳における大きな課題は，特許明細書の他の項目を用いて学習させた統計的機械翻訳では，請求項サブ言語に特有の文構造を正確に捉えてこの文構造を目的言語に正確に伝えることができないということである．

本ステップは，入力請求項文の文構造を認識し，これに対応する出力側の文構造を同時に生成することを目的とする．本ステップは，人手で作成したSCFG規則を用いて実行される．我々は，これら規則を以下の手順で作成した．最初に，開発セット中の英中日それぞれの特許請求項を人手で分析することにより，文構造を構成する構造部品は一定であること，ならびに，これら構造部品のセットは英中日の3言語で共通であることがわかった．このようにして我々が抽出した構造部品セットUは次のとおりである．
\[
\mathrm{U} \in  \{\text{PREA,\ TRAN,\ BODY,\ ELEM,\ PURP}\}
\]

ここで，これら5項目（PREAは前提部，TRANは移行部，BODYは本体部，ELEMは構成要素，PURPは目的部をそれぞれ表す）はすべて前章で説明したとおりである．

次に，構造部品セットUを非終端記号とする英語生成規則および日本語生成規則を作成し，対応する英語生成規則と日本語生成規則を組み合わせることによって，英日翻訳用および日英翻訳用のSCFG規則を作成した．図 
5は，このようにして作成した英日翻訳用のすべてのSCFG規則のセットである．同様にして，構造部品セットUから中国語生成規則を作成し，対応する中国語生成規則と日本語生成規則を組み合わせることによって，中日翻訳用および日中翻訳用のSCFG規則を作成した．日英翻訳・中日翻訳・日中翻訳のためのSCFG規則は付録を参照されたい．付録には日英翻訳のためのSCFG規則に対応する日英対訳例文も掲載している．規則の数は，英日翻訳用8個，日英翻訳用10個，中日翻訳用6個，日中翻訳用10個である．

\begin{figure}[b]
\begin{center}
\includegraphics{23-5ia2f5.eps}
\end{center}
\hangcaption{英日翻訳のためのSCFG規則一覧（日英・中日・日中翻訳のためのSCFG規則は付録に掲載している）}
\label{fig05}
\end{figure}

図 5は，英日翻訳用SCFG規則であるR$_{\mathrm{ej}2}$の処理対象となるような対訳の例である．入力英文においてPREA・TRAN・BODY・TRAN・BODYの順番で出現する構造部品が，日本語ではBODY・TRAN・BODY・TRAN・PREAの順番に並べ替えられることによって，日本語として適切な文構造となることがわかる．

今回作成したSCFG規則では，規則適用で曖昧性が生じるのは終端記号に対応する規則であり，これ以外は決定的に動作する解析アルゴリズムとなっている．実際のSCFG規則の実装では，終端記号とのマッチングに正規表現を用いることによって，各規則について高々1回のマッチのみを認め，終端記号においても決定的に動作するような設計とした．決定的な動作を行うためには対象言語の主辞方向性を用いており，例えば主辞先導型言語の英語と中国語では最も文頭に近いTRAN一つを採用し，主辞後置型言語の日本語では最も文末に近いTRANを採用している．例えば，英語の入力特許請求項文中に文字列``comprising''が複数回出現する場合には，入力文中の最初の``comprising''のみとマッチするような正規表現を用意した．実際の特許請求項では，執筆者が最初の表現がTRANとなるように意識して書くことが多いため，最初のTRANを採用することでほぼ誤りなくマッチする．以下に，Perl言語風の英語と日本語の正規表現の例を示す．``$+$''は最長マッチ，``$+$?''は最短マッチを表す．
\begin{gather*}
\text{({\$}prea,\ {\$}tran,\ {\$}body)} = /\text{\textasciicircum} (.+?) (\text{comprising})  (.+){\$}/; \\
\text{({\$}body,\ {\$}tran,\ {\$}prea)} = /\text{\textasciicircum} (.+)  (\text{備えることを特徴とする})(.+?){\$}/;
\end{gather*}

このようにして作成したヒューリスティック規則はほぼ誤りなくマッチするが，マッチしない場合には入力文をそのまま返す仕様としている．

\begin{figure}[t]
\begin{center}
\includegraphics{23-5ia2f6.eps}
\end{center}
\caption{SCFG規則R$_{\mathrm{ej2}}$に対応する英日対訳文の例}
\label{fig06}
\end{figure}


\subsection{事前並べ替え}

既存の事前並べ替え技術は，句構造解析技術に基づくもの (Isozaki et al. 2010b; 
Goto et al. 2015; Hoshino, Miyao, Sudoh, Hayashi, and Nagata 
2015) と依存構造に基づくもの (Yang, Li, Zhang, and Yu 2012; Lerner and 
Petrov 2013; Jehl, de Gispert, Hopkins, and Byrne 2014; de Gispert et al. 
2015) が多い．以下では，句構造解析技術に基づく例で説明する．英日機械翻訳では，例えば，入力文``He 
likes apples.''に対してまず，図~7 に示すような二分木構造を得る．次に，分類器によって，特定の内部ノードの2つのノードを入れ替えることによって単語の並べ替えを行う．図~7 の例では，分類器の判定によって，VPノードの2つの子ノードであるVBZとNPの入れ替えが行われる．子ノードを2つのみ持つすべてのノードについて，入れ替えをすべきかどうかの判定が分類器によって行われ，入れ替えが行われると，結果として``He 
apples 
likes.''のような日本語の語順に近い英語文が得られる．2つの子ノードを入れ替えるか否かは，ルールに基づく手法 (Isozaki 
et al. 2010b) や，語順の順位相関係数$\tau 
$を指標として原言語文と目的言語文の語順が近くなるよう並べ替えを実現する統計的なモデル化 (Goto 
et al. 2015; Hoshino et al. 
2015) などが考えられる．評価実験では後者の統計的なモデル化を採用した．詳しくは5.3節を参照されたい．ただし，提案手法自体は特定の事前並べ替え手法に依存しない．

\begin{figure}[t]
\begin{center}
\includegraphics{23-5ia2f7.eps}
\end{center}
\caption{``He likes apples.''の二分木構造と入れ替え結果}
\label{fig07}
\end{figure}

1章で説明したように，請求項翻訳におけるもう1つの課題は，極端な文の長さへの対処である．上述のような事前並べ替え技術は，ある程度正しい構文解析結果が得られることを前提としているが，極めて長い文が入力された場合に構文解析が失敗し，結果として並べ替え精度が低くなる．この問題に対して，本ステップでは，長い入力文全体ではなく，前ステップで認識された各構造部品に対して既存の事前並べ替え手法を適用することによって，構文解析の精度の向上，ならびに事前並べ替えの精度の向上を図る．


\section{評価実験}

文構造変換と事前並べ替えによる翻訳品質の向上度合いを定量的に評価するための評価実験を行った．第4章でも述べているように，本実験は既存統計的機械翻訳への付加モジュールとして実現しているため，既存のフレーズベース統計的機械翻訳 (Koehn, 
Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 
Dyer, Bojar, Constantin, and Herbst 2007) をベースラインとして設定した．


\subsection{データ}

統計的機械翻訳の学習には特許文のコーパスを使っている．中日・日中翻訳では，特許請求項文だけで大量の対訳コーパスを作ることができたが，英日・日英翻訳では，特許請求項文のみでは分量が不十分のため特許全体から作成したコーパスと特許請求項文から作成したコーパスを併用した．最終的に，英日・日英・中日・日中翻訳の4つの設定で訓練コーパスの規模（文数）が同じになるようにして実験を行った．

英日・日英の統計的機械翻訳の学習には2種類のコーパスを利用した．1種類目は，NTCIR-9ワークショップの特許翻訳タスク (PatentMT) (Goto 
et al. 
2011) において提供された約320万文対の日英特許翻訳データから無作為に抽出した300万文対である．以降，この対訳コーパスをコーパスAと呼ぶ．コーパスAを用いて統計的機械翻訳を学習させることによって，請求項翻訳においても語彙選択の面では良好な性能が得られるが，これは語彙や表現は特許文書全体で共通であり，コーパスAによって大部分がカバーされるからである．しかしながら，コーパスAは請求項文を含まないため，請求項特有の文構造を適切に扱うことができない．このため，請求項文特有の文構造を取り込むために，100万文の請求項対訳文から構成されるコーパスBを用意し，これをコーパスAと併用した．コーパスBの請求項対訳文は，文アラインメント手法 (Utiyama 
and Isahara 
2007) を用いて英日対訳特許文書から抽出したものである．英日対訳特許文書とは，日本国特許庁が提供する日本語特許明細書データと米国特許庁が提供する英語特許明細書データとを出願番号を用いて対応付けたものであり，2013年提供分までのデータを対応付けの対象としている．コーパスAとコーパスBを結合して学習コーパスを作成し，この学習データを用いて，ベースラインシステムおよび提案手法を組み込んだシステムのための統計的機械翻訳を学習させた．

中日・日中の統計的機械翻訳の学習にはALAGIN 
言語資源・音声資源として提供されるJPO中日対訳コーパス\footnote{ALAGIN 言語資源・音声資源サイトのJPO中日対訳コーパス https://alaginrc.nict.go.jp/resources/jpo-info/\linebreak[2]jpo-outline.html{\#}jpo-zh-ja}の特許請求項文から作成したコーパスのみを用いた．前述の英日・日英用のコーパスBと同様の方法によって中日対訳の特許請求項文から400万文対を抽出した．

開発データおよびテストデータについては，英日・日英・中日・日中の4言語対について，上述の学習データとは独立に次の手順で構築した．まず，学習データより後の特定の年（2014年）の米国特許明細書データから，明細書毎に最大5個の請求項文を抽出した．具体的には，明細書中の請求項が5個以内の場合はすべての請求項を抽出し，6個以上の場合は5個目までを抽出している．次に，ここから無作為に2,000文を抽出し，機械翻訳の学習やチューニングで用いるという用途を伏せて，特許翻訳専門の翻訳者に依頼して日本語訳文および中国語訳文を作成した．このようにして作成した2,000文の英中日多言語コーパスを1,000文ずつ2つに分けて開発用とテスト用とした．なお上記翻訳作業では，各英語原文について1文の訳文を作成した．


\subsection{システム}

本評価実験では，統計的機械翻訳のツールキットであるMosesのフレーズベース翻訳 (Koehn, 
Och, and Marcu 2003) および階層的フレーズベース翻訳 (Chiang 
2005) をベースラインとして用いた．文構造変換，事前並べ替えおよび両者の組み合わせについて，ベースラインとの比較を行った．

すべての実験において，言語モデルの学習にKenLM (Heafield, Pouzyrevsky, Clark, 
and Koehn 2013) を，単語アラインメントにSyMGIZA$++$ (Junczys-Dowmunt and 
Sza{\l} 2010) を用いた．モデルの重みづけでは，BLEU値 (Papineni, Roukos, Ward, 
and Zhu 2002) を指標としてn-best batch MIRA (Cherry and Foster 
2012) によるチューニングを行った．各評価実験において，重み付けチューニングを3回繰り返し，開発セットにおいて最大のBLEU値を獲得した重み設定を採用した．ベースラインとしてのフレーズベース翻訳では，歪み範囲(d)が6の場合と20の場合の測定を行った．Mosesのデフォルトの歪み範囲である6と，それに対する長めの歪み範囲として20を選んだ．

なお，テストデータに対して文構造変換を行う実験構成でも，学習データに対しては文構造変換を行わずにモデルの学習を行った．文構造変換を行うためには学習データとして請求項文を用いる必要があるが，今回扱わなかった他の言語も含め，請求項文の入手可否は対象言語によって変わってくるため，比較のために一律の構成とした．この実験構成にしたことによって，Mosesの学習段階における長文除去処理で除外される文は発生する．


\subsection{事前並べ替え}

本評価実験では，構文解析パーザとしてBerkeley Parser (Petrov, Barret, Thibaux, and Klein 2006) を用いて，提案手法によって分割された各構造部品に対して事前並べ替えを行った．この基本的な構成は，4言語方向いずれも同じである．なお，学習データは二分化されたものを用いている．

Berkeley 
Parserのドメイン適応では自己学習の手法を用いた．具体的には，最初に，初期モデルを用いて200,000文の特許文の解析を行い，次に，得られた200,000件の構文解析結果から構文解析モデルを学習することにより，特許文に適応した解析モデルを構築した．英語の初期モデルについては，Penn 
Treebankの文，および我々が人手で木構造を記述した3,000文の特許文を用いて学習した．日本語の初期モデルについては，EDRコーパス\footnote{EDRコーパス https://www2.nict.go.jp/out-promotion/techtransfer/EDR/JPN/Struct/Struct-CPS.html}の200,000文を用いて学習させた．中国語の初期モデルについては，CTB-6 (Zhang 
and Xue 
2012) の文を用いて学習させた．日本語および中国語のモデル学習では特許文は用いていない．

並べ替えモデルの学習では，内製の大規模な特許文対訳コーパスを用いて次の手順によって事前並べ替えモデルを学習させた (de 
Gispert et al. 2015) ．

\begin{itemize}
\item[1.] 対訳コーパスの原言語文を構文解析する
\item[2.] 対訳コーパスに対して単語アラインメントを行う
\item[3.] 原言語文と目的言語文の間でケンドールの順位相関係数$\tau $が最大化されるような原言語文に対する並べ替えを行う．このようにして各2分ノードは，子ノードの入れ替えを行うことを表すSWAPと，入れ替えを行わないことを表すSTRAIGHTに分類される．
\item[4.] 上記のデータを用いて，各ノードのSWAP，STRAIGHTを判定するためのニューラルネットワーク分類器を学習する．
\end{itemize}

上述のように，各ノードのSWAP，STRAIGHTの判定を二値分類問題としてニューラルネットワーク学習器に学習させるが，本実験では，ニューラルネットワーク学習器としてオープンソースのNeural 
Probabilistic Language Model Toolkit (NPLM)\footnote{Neural Probabilistic Language Model Toolkit http://nlg.isi.edu/software/nplm/}を用いた．基本的な構成はデフォルト構成をそのまま使ったが，出力層ではSWAPとSTRAIGHTに対応した2個の出力を用いた．入力層では，以下を入力としている：親の親，親，自分，直前の兄弟，直後の兄弟，左の子供，右の子供，左の子供のスパンの左端の前終端記号と単語，左の子供のスパンの右端の前終端記号と単語，右の子供のスパンの左端の前終端記号と単語，右の子供のスパンの右端の前終端記号と単語．


\subsection{評価指標}

各システムは，BLEU (Papineni et al. 2002) とRIBES (Isozaki et al. 
2010a) の2種類の評価指標を用いて評価した．これは，n-gramベースの評価手法であるBLEUのみでは長距離の関係を十分に評価することができず，本研究が目標としている構造レベルの改善を十分に測定できないと考えたからである．RIBESは順位相関係数に基づく自動評価手法であり，評価対象の機械翻訳出力文中の語順と，参照訳中の語順の比較を行う．RIBESのこのような特性によって，語順の大きく異なる言語間で頻繁に発生する，構造部品の入れ替えを評価することができると考えられる．なお，RIBESは，NTCIR-9ワークショップの特許翻訳タスク (PatentMT) (Goto 
et al. 
2011) 等においても，英日・日英の翻訳方向において，人間評価との高い相関性が報告されている．

実験で得られた各BLEU値とRIBES値は，MTEval\footnote{MTEval Toolkit https://github.com/odashi/mteval}を用いた反復数1,000回の100分割ブートストラップ検定を行ってベースラインとの有意差を調べた．


\subsection{自動評価結果}

\begin{table}[p]
\caption{英日翻訳の評価結果（N/Aは評価対象外を表す）}
\label{tab01}
\input{02table01.txt}
\vspace{-0.3\Cvs}
\end{table}
\begin{table}[p]
\caption{日英翻訳の評価結果（N/Aは評価対象外を表す）}
\label{tab02}
\input{02table02.txt}
\vspace{-0.3\Cvs}
\end{table}
\begin{table}[p]
\caption{中日翻訳の評価結果（N/Aは評価対象外を表す）}
\label{tab03}
\input{02table03.txt}
\vspace{-0.3\Cvs}
\end{table}
\begin{table}[p]
\caption{日中翻訳の評価結果（N/Aは評価対象外を表す）}
\label{tab04}
\input{02table04.txt}
\end{table}

本評価実験の結果を表~1，表~2，表~3，表~4 に示す．表中，PBおよびHPBは各々，Mosesのフレーズベース翻訳および階層的フレーズベース翻訳を表し，PBにおけるdは歪み範囲の値を表す．カッコ内の数値はベースラインであるフレーズベース翻訳 (P1) との差分を表す．また，P1'からP4のそれぞれについて，ベースラインに対して5{\%}水準で有意差があるものに\textdagger 
を，1{\%}水準で有意差があるものに\textdaggerdbl 
を付してある．テスト文としては5.1節で述べた1,000文を使っているが，参考情報として，この1,000文からトークン数が200以下の文を抜き出して使った場合の結果も併記している．これは，P3の事前並べ替えで用いている句構造パーザ (Berkeley 
Parser) に入力長制限があり，1,000文全文に対する事前並べ替えを行うことができないためである．このため，テスト文全文を使った評価ではP3は評価対象外としており，表ではこれをN/Aで表している．


表から，文構造変換と事前並べ替えの組み合わせであるP4において，英日・日英・中日・日中翻訳すべての翻訳方向において，RIBES値およびBLEU値に大幅な上昇がみられる．有意差検定からも，P4のみが，すべての翻訳方向のRIBES値およびBLEU値の双方において，P1と比較して1{\%}水準で有意に上昇している．文構造解析のみを用いたP2，および事前並べ替えのみを用いたP3でもRIBES値は大幅に上昇しているが，BLEU値の上昇は限定的である．文構造解析と事前並べ替えを併用したときに大きなBLEU値の上昇がみられるが，これは文構造解析と事前並べ替えの相乗効果によるものと考えられる．

参考情報として掲載した，200トークン以内の文に対する翻訳でも，全文を用いた場合と同様の傾向がみられるが，200トークンを超える長文を含まないため，ほぼすべてのシステムに対して高い評価値となっている．言語によって事前並べ替えの精度に差があり，特に日英，中日翻訳ではP3の方がP4よりも高い評価値を達成している場合がある．ただし，P4における文構造変換と事前並べ替えの組み合わせでは，P3の精度に差に関わらず安定した精度向上がみられる．


\subsection{考察}

前述の評価結果から，翻訳方向に関わらず，文構造解析と事前並べ替えによって翻訳品質が大幅に改善することがわかった．以下ではまず，当初の課題としてあげていた特許請求項文の長さと特有の文構造の問題が，文構造変換と事前並べ替えの導入によっていかに改善されたか分析する．また，文構造解析の副次的な効果である文短縮についても分析する．さらに，翻訳方向に固有の翻訳特性について述べる．


\subsubsection{文構造変換と事前並べ替えの相補的効果}

\begin{figure}[t]
\begin{center}
\includegraphics{23-5ia2f8.eps}
\end{center}
\hangcaption{典型的な日英翻訳の例（P2とP4の部品ラベルはシステムが自動的に付与したものだが，それ以外の部品ラベルは，意味的に対応する部分に人手で付与している）}
\label{fig08}
\end{figure}

図~8 は，日英翻訳における4つの実験設定 (P1，P2，P3，P4) の典型的な出力例である．図では一貫してラベル付き括弧表示を用いて請求項の構造部品を表している．文構造変換および事前並べ替えによる効果について以下に述べる．

\begin{itemize}
\item[1.] \textbf{文構造解析の効果}： P1では入力文と比較して構造部品の順番に変化がみられないが，P2では文構造解析を導入することによって構造部品が英語の順番に並べなおされていることがわかる．これによって，移行部である ``comprising'' が生成されるようになり，文全体の可読性が上がっている．一方，P1とP2を比較したときに，各構造部品の翻訳品質は顕著には向上していない．これに対して，P4ではP3と比較して2番目の要素の翻訳品質が向上している．このことから，文構造変換は事前並べ替えと併用したときに効果的に動作することがわかる．
\item[2.] \textbf{事前並べ替えの効果}：従来研究でも示されているとおり，事前並べ替え手法を用いることによって，目的言語の語順に即した訳文を生成することができる．図中の例でも，P3は，P1と比較して単語がより適切に並んでおり，英語としてより自然な訳文が得られている．しかしながら，前提部が2回出現するなど，構造部品が適切に配置されておらず，文構造の観点からは不適切である．これに対して，P4のように文構造変換を用いて文構造を明示的に指定することによって，このような不適切な現象を抑制することができる．さらに，入力文をより短い構造部品に分解することにより，各構造部品中の単語が適切に並べ替えられるようになる．
\end{itemize}
\vspace{1\Cvs}

以上の分析から，構造的かつ語順的に適切な訳文を生成する過程において，文構造変換と事前並べ替えが相補的に動作することが確認できた．


\subsubsection{文短縮の効果}

これまで述べたように，事前並べ替えは，入力文全体に対してよりも文構造解析で得られた構造部品に対して，より適切に機能する．文構造変換による文短縮の効果を見積もるために，まずは実験に用いた構文解析パーザの解析精度を文長毎に評価した．表~5 は，英日翻訳のテストセット全文から無作為に抽出した100文を対象に，事前並べ替えで用いる英語構文解析器の解析成功率を集計した結果である．構文解析結果を目視でチェックし，文中で1か所でも誤った構成素があれば誤りとしてカウントし，すべて正しい場合に正解としてカウントした．表から，短い入力文に対する解析精度は高いものと比較して，長い入力文に対する解析精度が著しく低いことがわかる．特に，80トークンを超える長さの入力文では，正しい構文解析結果を得られた文が16文中1文のみと，きわめて正解率が低い．

\begin{table}[b]
\caption{英日翻訳における英語パーザの解析精度}
\label{tab05}
\input{02table05.txt}
\end{table}

\begin{figure}[p]
\begin{center}
\includegraphics{23-5ia2f9.eps}
\end{center}
\caption{入力文の累積比率と文構造解析結果の累積比率}
\label{fig09}
\end{figure}

次に，分割前であるP1と分割後であるP2の双方の実験設定において，後段処理への入力となる文字列のトークン数の分布を比較した．図~9 は，(a) 英語入力文，(b) 日本語入力文，(c) 
中国語入力文のそれぞれについて，入力文の累積比率と文構造解析結果の累積比率をそれぞれ表した図である．なお，日英翻訳と日中翻訳では入力日本語文に対して同じ分割結果が得られる．例えば 
(a) 
英語入力文では，80トークンを超える長さの入力文が，分割前では全体の31{\%}を占めていたのに対して，分割後では全体の3{\%}と大幅に減少している．上述の文長毎の解析精度と併せて考えると，分割によって入力文が高精度に解析される可能性が大幅に高くなったことがわかる．

\begin{table}[b]
\caption{入力文および構造解析後の構造部品数}
\label{tab06}
\input{02table06.txt}
\end{table}
\begin{table}[b]
\caption{文構造解析の成功数・失敗数（100文あたり）}
\label{tab07}
\input{02table07.txt}
\end{table}

なお参考情報として，表~6に，入力文数と文構造解析によって得られた構造部品の数を載せている．言語によって出現する構造部品の分布は異なるものの，いずれの言語でも入力文1,000文に対して4,000個前後の構造部品が得られており，1入力文が平均して4構造部品に分割されていることがわかる．また，表~7 には，入力文100文に対する文構造解析の成功および失敗数を言語毎に載せている．英語と中国語の成功率が高いのは，これらの言語における請求項の記述の定型性の高さが要因にあると思われる．機械翻訳の精度評価では，日本語を原言語とした言語対においても，英語や中国語を原言語としたときと同等の翻訳精度が得られていることから，文構造解析の失敗は影響の少ないものが多いと考えられる．


\subsubsection{言語方向による傾向}

実験では，提案手法によって英日・日英・中日・日中すべての翻訳方向においてRIBES値が25ポイント以上と大幅に向上している．これは，英日・日英・中日・日中のすべての翻訳方向において構造部品の並べ替えが必要であるが，提案手法によって構造部品が適切に並べ替えられた結果，長距離の並びの適切さを反映するRIBES値に表れたものと考えられる．

一方，BLEU値の向上は，中日・日中で1.5ポイント程度と十分に大きな値が得られたが，英日・日英では5ポイント程度と極めて大きな向上となった．各構造部品の内部では事前並べ替えが行われるが，中日と日中翻訳では動詞の移動が中心であるのに対して，英日と日英翻訳では動詞の移動に加えて修飾方向の移動も関わるため，事前並べ替えの難易度はより高い．このため，英日と日英翻訳において，文短縮による事前並べ替えの効果が大きく表れたものと考えられる．


\section{おわりに}

本論文では，英日・日英・中日・日中の特許請求項翻訳において，サブ言語に特有の文構造を，原言語側から目標言語側に変換するための手法について述べた．我々の手法では，これらの品質向上を，非常に少数の同期文脈自由文法規則を用いて実現した．評価実験を行ったところ，文構造変換と事前並べ替えの組み合わせを用いた場合に，英日・日英・中日・日中の4方向の翻訳においてRIBES値で25ポイントという大幅な訳質向上が見られた．これに加えてBLEU値では，英日・日中の翻訳で5ポイント程度，中日・日中の翻訳で1.5ポイントの大幅な向上が見られた．

本手法により，特許請求項翻訳の翻訳品質を，特許明細書中の他の部分の翻訳品質と同水準に引き上げることができた．今後の研究では，特許請求項の中でも特に長文で複雑な，独立請求項文の翻訳に注力したい．

\acknowledgment

本論文は，国際会議The Machine Translation Summit 
XVで発表した論文に基づいて日本語で書き直し，説明や評価を追加したものである (Fuji, 
Fujita, Utiyama, Sumita, and Matsumoto 2015) ．


\begin{thebibliography}{}

\item
Buchmann, B., Warwick, S., and Shann, P. (1984). ``Design of a Machine 
Translation System for a Sublanguage.'' In \textit{Proceedings of the 9th International Conference on Computational Linguistics}, pp. 334--337.

\item
Bui, T. H., Nguyen, M., L., and Shimazu, A. (2012). ``Divide and Translate 
Legal Text Sentence by Using its Logical Structure.'' In \textit{Proceedings of 7th International Conference on Knowledge, Information and Creativity Support Systems}, pp. 18--23.

\item
Cai, J., Utiyama, M., Sumita, E., and Zhang, Y. (2014). ``Dependency-based 
Pre-ordering for Chinese-English Machine Translation.'' In \textit{Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics}, pp. 155--160.

\item
Cherry, C. and Foster, G. (2012). ``Batch Tuning Strategies for Statistical 
Machine Translation.'' In \textit{Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pp. 427--436.

\item
Chiang, D. (2005). ``A Hierarchical Phrase-Based Model for Statistical 
Machine Translation.'' In \textit{Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics}, pp. 263--270.

\item
Collins, M., Koehn, P., and Kucerova, I. (2005). ``Clause Restructuring for 
Statistical Machine Translation.'' In \textit{Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics}, pp. 531--540.

\item
de Gispert, A., Iglesias, G., and Byrne, B. (2015). ``Fast and Accurate 
Preordering for SMT using Neural Networks.'' In \textit{Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies}, pp. 1012--1017.

\item
Fuji, M., Fujita, A., Utiyama, M., Sumita, E., and Matsumoto, Y. (2015). 
``Patent Claim Translation based on Sublanguage-specific Sentence 
Structure.'' In \textit{Proceedings of the Machine Translation Summit XV}, pp. 1--16.

\item
Goto, I., Lu, B., Chow, K. P., Sumita, E., and Tsou, B. K. (2011). ``Overview 
of the Patent Machine Translation Task at the NTCIR-9 Workshop.'' In 
\textit{Proceedings of the 9th NII Test Collection for Information Resources (NTCIR) Conference}, pp. 559--578.

\item
Goto, I., Utiyama, M., Sumita, E., Kurohashi, S. (2015). ``Preordering using 
a Target-Language Parser via Cross-Language Syntactic Projection for 
Statistical Machine Translation.'' In \textit{ACM Transactions on Asian and Low-Resource Language Information Processing}, Vol. 14, No. 3, Article 13, pp. 
1--23.

\item
Hajlaoui, N. and Popescu-Belis, A. (2012). ``Translating English Discourse 
Connectives into Arabic: A Corpus-based Analysis and an Evaluation Metric.'' 
In \textit{Proceedings of the Workshop on Computational Apagesroaches to Arabic Script-based Languages}, pp. 1--8.

\item
Heafield, K., Pouzyrevsky, I., Clark, J. H., Koehn, P. (2013). ``Scalable 
Modified Kneser-Ney Language Model Estimation.'' In \textit{Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics}, pp. 13--21.

\item
Hoshino, S., Miyao, Y., Sudoh, K., Hayashi, K., and Nagata, M. (2015). 
``Discriminative Preordering Meets Kendall's $\tau $ Maximization.'' In 
\textit{Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing}, pp. 139--144.

\item
Hoshino, S., Miyao, Y., Sudoh, K., and Nagata, M. (2013). ``Two-Stage 
Pre-ordering for Japanese-to-English Statistical Machine Translation.'' In 
\textit{Proceedings of the International Joint Conference on Natural Language Processing}, pp. 1062--1066.

\item
池原悟，阿部さつき，徳久雅人，村上仁一 (2004)．非線形な表現構造に着目した日英文型パターン化．情報処理学会研究報告2004-NL-160(8)，pp. 
49--56.

\item
Isozaki, H., Hirao, T., Duh, K., Sudoh, K., Tsukada, H. (2010a). ``Automatic 
Evaluation of Translation Quality for Distant Language Pairs.'' In 
\textit{Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing}, pp. 944--952.

\item
Isozaki, H., Sudoh, K., Tsukada, H., and Duh, K. (2010b). ``Head 
Finalization: A Simple Reordering Rule for SOV Languages.'' In \textit{Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR}, pp. 
244--251.

\item
Jehl, L., de Gispert, A., Hopkins, M., and Byrne, W. (2014). ``Source-side 
Preordering for Translation using Logistic Regression and Depth-first 
Branch-and-Bound Search.'' In \textit{Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics}, pp. 239--248.

\item
Jin, Y. and Liu, Z. (2010). ``Improving Chinese-English Patent Machine 
Translation Using Sentence Segmentation.'' In \textit{Proceedings 2010 International Conference on Natural Language Processing and Knowledge Engineering}, pp. 1--6.

\item
Joty, S., Carenini, G., Ng, R., and Mehdad, Y. (2013). ``Combining Intra- 
and Multi-sentential Rhetorical Parsing for Document-level Discourse 
Analysis.'' In \textit{Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics}, pp. 486--496.

\item
Junczys-Dowmunt, M. and Sza\l , A. (2010). ``SyMGiza$++$: A Tool for 
Parallel Computation of Symmetrized Word Alignment Models.'' In \textit{Proceedings of the International Multiconference on Computer Science and Information Technology}, pp. 
397--401.

\item
Katz-Brown, J. and Collins, M. (2008). ``Syntactic Reordering in 
Preprocessing for Japanese-English Translation: MIT System Description for 
NTCIR-7 Patent Translation Task.'' In \textit{Proceedings of the NTCIR-7 Workshop Meeting}, pp. 409--414.

\item
金淵培，江原暉将 (1994)．日英機械翻訳のための日本語長文自動短文分割と主語の補完．情報処理学会論文誌，\textbf{35} 
(6)，pp. 1018--1028.

\item
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, 
N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., 
Constantin, A., Herbst, E. (2007). ``Moses: Open Source Toolkit for 
Statistical Machine Translation.'' In \textit{Proceedings of the Association for Computational Linguistics Demo and Poster Sessions}, pp. 177--180.

\item
Koehn, P., Och, F. J., and Marcu, D. (2003). ``Statistical Phrase-Based 
Translation.'' In \textit{Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology}, pp. 48--54.

\item
Kurohashi, S. and Nagao, M. (1994). ``Automatic Detection of Discourse 
Structure by Checking Surface Information in Sentences.'' In \textit{Proceedings of the 15th International Conference on Computational Linguistics}, pp. 
1123--1127.

\item
Lerner, U. and Petrov, S. (2013). ``Source-Side Classifier Preordering for 
Machine Translation.'' In \textit{Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing}.

\item
Luckhardt, H. D. (1991). ``Sublanguages in Machine Translation.'' In 
\textit{Proceedings of the 5th Conference of the European Chapter of the Association for Computational Linguistics}, pp. 306--308.

\item
Marcu, D., Carlson, L., and Watanabe, M. (2000). ``The Automatic Translation 
of Discourse Structures.'' In \textit{Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference}, pp. 9--17.

\item
Mellebeek, B., Owczarzak, K., Groves, D., Van Genabith, J., and Way, A. 
(2006). ``A Syntactic Skeleton for Statistical Machine Translation.'' In 
\textit{Proceedings of the 11th Conference of the European Association for Machine Translation}, pp. 195--202.

\item
Meyer, T., Popescu-Belis, A., Hajlaoui, N., and Gesmundo, A. (2012). 
``Machine Translation of Labeled Discourse Connectives.'' In \textit{Proceedings of the 10th Biennial Conference of the Association for Machine Translation in the Americas}, 10 pages.

\item
Meyer, T., Popescu-Belis, A., Zufferey, S., and Cartoni, B. (2011). 
``Multilingual Annotation and Disambiguation of Discourse Connectives for 
Machine Translation.'' In \textit{Proceedings of 12th SIGdial Meeting on Discourse and Dialogue}, pp. 194--203.

\item
Miltsakaki, E., Dinesh, N., Prasad, R., Joshi, A., and Webber, B. (2005). 
``Experiments on Sense Annotations and Sense Disambiguation of Discourse 
Connectives.'' In \textit{Proceedings of the 4th Workshop on Treebanks and Linguistic Theories}.

\item
Murakami, J., Fujiwara, I., and Tokuhisa, M. (2013). ``Pattern-Based 
Statistical Machine Translation for NTCIR-10 PatentMT.'' In \textit{Proceedings of the 10th NTCIR Conference}, pp. 350--355.

\item
Murakami, J., Tokuhisa, M., Ikehara, S. (2009). ``Statistical Machine 
Translation adding Pattern-based Machine Translation in Chinese-English 
Translation.'' In \textit{Proceedings of 6th International Workshop on Spoken Language Translation}, pp. 107--112.

\item
中澤敏明，黒橋禎夫 (2008)．自動学習された機能語の翻訳パターンを用いた用例ベース機械翻訳．言語処理学会第14回年次大会発表論文集，pp. 
37--40.

\item
西村拓哉，村上仁一，徳久雅人，池原悟 (2010)．文単位のパターンを用いた統計翻訳．言語処理学会第16回年次大会発表論文集，pp. 
676--679.

\item
Papineni, K., Roukos, S., Ward, T., and Zhu, W. J. (2002). ``BLEU: A Method 
for Automatic Evaluation of Machine Translation.'' In \textit{Proceedings of the 40th Annual Meeting of the \mbox{Association} for Computational Linguistics}, pp. 311--318.

\item
Petrov, S., Barrett, L., Thibaux, R., and Klein, D. (2006). ``Learning 
Accurate, Compact, and Interpretable Tree Annotation.'' In \textit{Proceedings of the 21st International Conference on \mbox{Computational} Linguistics and 44th Annual Meeting of the Association for Computational \mbox{Linguistics}}, pp. 433--440.

\item
Pitler, E. and Nenkova, A. (2009). ``Using Syntax to Disambiguate Explicit 
Discourse Connectives in Text.'' In \textit{Proceedings of the Joint conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing}, Short Papers, pp. 13--16.

\item
Quirk, C., Menezes, A., and Cherry, C. (2005). ``Dependency Treelet 
Translation: Syntactically Informed Phrasal SMT.'' In \textit{Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics}, pp. 271--279.

\item
Roh, Y. H., Lee, K. Y., Choi, S. K., Kwon, O. W., and Kim, Y. G. (2008). 
``Recognizing Coordi\-nate Structures for Machine Translation of English 
Patent Documents.'' In \textit{Proceedings of the 22nd Pacific Asia Conference on Language, Information and Computation}, pp. 460--466.

\item
坂田純，徳久雅人，村上仁一 (2014)，意味的等価変換方式による句レベルパターン翻訳方式の調査．言語処理学会第18 
回年次大会発表論文集，pp. 1--20.

\item
Shinmori, A., Okumura, M., Marukawa, Y., Iwayama, M. (2003). ``Patent Claim 
Processing for Readability---Structure Analysis and Term Explanation---.'' 
In \textit{Proceedings of the Workshop on Patent Corpus Processing, Association for Computational Linguistics}, pp. 56--65.

\item
Sudoh, K., Duh, K., Tsukada, H., Hirao, T., and Nagata, M. (2010). ``Divide 
and Translate: Improving Long Distance Reordering in Statistical Machine 
Translation.'' In \textit{Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR}, pp. 418--427.

\item
Sudoh, K., Suzuki, J., Tsukada, H., Nagata, M., Hoshino, S., and Miyao, Y. 
(2013). ``NTT-NII Statistical Machine Translation for NTCIR-10 PatentMT.'' 
In \textit{Proceedings of 9th NTCIR Conference 2013}, pp. 294--300.

\item
Tu, M., Zhou, Y., and Zong, C. (2013). ``A Novel Translation Framework Based 
on Rhetorical Structure Theory.'' In \textit{Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics}, pp. 370--374.

\item
Utiyama, M. and Isahara, H. (2007). ``A Japanese-English Patent Parallel 
Corpus.'' In \textit{Proceedings of the 11th Machine Translation Summit}, pp. 475--482.

\item
The World Intellectual Property Organization (WIPO) (2014). ``WIPO Patent 
Drafting Manual.'' In \textit{IP Assets Management Series}.

\item
Wu, D. and Fung, P. (2009). ``Semantic Roles for SMT: A Hybrid Two-Pass 
Model.'' In \textit{Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics}, Companion Volume: Short Papers, pp. 13--16.

\item
Xia, F. and McCord, M. (2004). ``Improving A Statistical MT System with 
Automatically Learned Rewrite Patterns.'' In \textit{Proceedings of the 20th International Conference on Computational Linguistics}, pp. 508--514.

\item
Xiao, T., Zhu, J., and Zhang, C. (2014). ``A Hybrid Approach to 
Skeleton-based Translation.'' In \textit{Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics}, pp. 563--568.

\item
Xiong, H., Xu, W., Mi, H., Liu, Y., and Liu, Q. (2009). ``Sub-Sentence 
Division for Treebased Machine Translation.'' In \textit{Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing Conference Short Papers}, pp. 137--140.

\item
Yang, N., Li, M., Zhang, D. and Yu, N. (2012). ``A Ranking-based Approach to 
Word Reordering for Statistical Machine Translation.'' In \textit{Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics}, pp. 912--920.

\item
Zhang, X. and Xue, N. (2012). ``Extending and Scaling up the Chinese 
Treebank Annotation.'' In \textit{Proceedings of the 2nd CIPS-SIGHAN Joint Conference on Chinese Language Processing}, pp. 27--34.

\end{thebibliography}




\appendix

\section{実験に用いたSCFG規則}

\begin{figure}[b]
\begin{center}
\includegraphics{23-5ia2f10.eps}
\end{center}
\caption{日英翻訳のためのSCFG規則一覧}
\label{fig10}
\end{figure}
\begin{figure}[b]
\begin{center}
\includegraphics{23-5ia2f11.eps}
\end{center}
\caption{中日翻訳のためのSCFG規則一覧}
\label{fig11}
\end{figure}

\begin{figure}[t]
\begin{center}
\includegraphics{23-5ia2f12.eps}
\end{center}
\caption{日中翻訳のためのSCFG規則一覧}
\label{fig12}
\end{figure}
\begin{figure}[t]
\begin{center}
\includegraphics{23-5ia2f13.eps}
\end{center}
\caption{日英翻訳用SCFG規則R$_{\mathrm{je2}}$に対応する日英対訳例}
\label{fig13}
\end{figure}

本研究の実験で用いた，日英翻訳用，中日翻訳用，日中翻訳用のSCFG規則一覧を図~10，図~11，図~12に示す．なお，英日翻訳用のSCFG規則一覧は図 5に掲載している．図~13には，日英翻訳用SCFG規則R$_{\mathrm{je}2}$に対応する日英対訳例を掲載している．この例では，入力日本語文で文頭と文末に重複して現れるPREAの構造部品が，対応する英語文では一つのPREAとなっているような，典型的な特許請求項の対訳文を示している．


\vspace{2\Cvs}

\begin{biography}
\bioauthor{富士　　秀}{
1987年英国王立ロンドン大学キングス校工学部卒業．1988年より株式会社富士通研究所研究員，シニアリサーチャー．2014年より国立研究開発法人情報通信研究機構に出向中．2015年より奈良先端科学技術大学院大学博士後期課程在学中．機械翻訳，多言語処理の研究に従事．情報処理学会，言語処理学会，AAMT，日本言語類型論学会等各会員．}

\bioauthor{藤田　　篤}{
2000年九州工業大学情報工学部卒業．2005年奈良先端科学技術大学院大学情報科学研究科博士後期課程修了．博士（工学）．現在，国立研究開発法人情報通信研究機構主任研究員．自然言語処理，主に言い換え表現の生成と認識，機械翻訳の研究に従事．情報処理学会，言語処理学会等各会員．}

\bioauthor{内山　将夫}{
1992年筑波大学卒業．1997年同大学院工学研究科修了．博士（工学）．現在，国立研究開発法人情報通信研究機構主任研究員．主な研究分野は機械翻訳．情報処理学会，言語処理学会等各会員．}

\bioauthor{隅田英一郎}{
1982年電気通信大学大学院修士課程修了．1999年京都大学大学院博士（工学）取得．1982年〜1991年（（株）日本アイ・ビー・エム東京基礎研究所研究員．1992年〜2009年国際電気通信基礎技術研究所研究員，主幹研究員，室長．2007年〜国立研究開発法人情報通信研究機構(NICT) 
，現在，先進的音声翻訳研究開発推進センター(ASTREC)副センター長．2016年NICTフェロー．機械翻訳の研究に従事．}

\bioauthor{松本　裕治}{
1977年京都大学工学部情報工学科卒．1979年同大学大学院工学研究科修士課程情報工学専攻修了．同年電子技術総合研究所入所．1984〜85年英国インペリアルカレッジ客員研究員．1985〜87年（財）新世代コンピュータ技術開発機構に出向．京都大学助教授を経て，1993年より奈良先端科学技術大学院大学教授，現在に至る．工学博士．専門は自然言語処理．情報処理学会，人工知能学会，AAAI, 
ACL, ACM各会員．情報処理学会フェロー．ACL Fellow．}

\end{biography}


\biodate



\end{document}


